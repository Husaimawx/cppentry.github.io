---
layout:     post
title:      hadoop环境安装
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p><strong><strong><strong>一、服务器系统设置<br>
  1、添加HADOOP用户<br>
     useradd hadoop<br>
     passwd hadoop<br>
  2、为HADOOP用户分配sudoer权限<br>
     用root用户修改visudo，在（root    ALL=(ALL)       ALL）下面添加（ hadoop  ALL=(ALL)       ALL ）<br>
  3、设置主机名master hadoop1 hadoop2 hadoop3 (vi /etc/sysconfig/network)修改主机名<br>
     克隆会遇到eth0不见的问题:｛<br>
        直接修改  /etc/sysconfig/network-script/ifcfg-eth0<br>
        删掉UUID  HWADDR<br>
        配置静态地址<br>
        然后：<br>
        rm -rf 　/etc/udev/rules.d/70-persistent-net.rules<br>
        然后 reboot<br>
      ｝<br>
  4、配置内网域名映射：修改(vi /etc/hosts)<br>
     添加<br>
     192.168.1.130 master<br>
     192.168.1.131 hadoop1<br>
     192.168.1.132 hadoop2<br>
     192.168.1.133 hadoop3<br>
  配置ssh免密登陆<br>
    1、ssh-keygen 一直回车<br>
    2、ssh-copy-id master<br>
         ssh-copy-id hadoop1<br>
         ssh-copy-id hadoop2<br>
         ssh-copy-id hadoop3<br>
    3、测试是否可以名密成功登录 ssh master<br>
  配置防火墙<br>
    1、相看是否开启 service iptablse status<br>
    2、关闭 service iptablse stop<br>
  <br>
二、HADOOP安装部署<br>
   1、上传HADOOP安装包  <br>
   2、规划安装目录  /home/hadoop/apps/hadoop-2.6.1<br>
   3、解压安装包<br>
   4、配置环境变量<br>
       export JAVA_HOME=/usr/local/jdk1.8.0_191<br>
       export HADOOP_HOME=/home/hadoop/hadoop-2.6.4<br>
       export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin<br>
   <br>
   4、修改hadoop-2.6.4/etc/hadoop/hadoop-env.sh环境变量位置   <br>
            export JAVA_HOME=/usr/local/jdk1.8.0_191<br>
   5、修改hadoop-2.6.4/etc/hadoop/core-site.xml <br>
       &lt;configuration&gt;<br>
        &lt;property&gt;<br>
            &lt;name&gt;fs.default.name&lt;/name&gt;<br>
            &lt;value&gt;hdfs://master:9000&lt;/value&gt;<br>
        &lt;/property&gt;<br>
        <br>
        &lt;property&gt;<br>
            &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;<br>
            &lt;value&gt;/home/HADOOP/apps/hadoop-2.6.1/tmp&lt;/value&gt;<br>
        &lt;/property&gt;<br>
        <br>
       &lt;/configuration&gt;<br>
       <br>
   6、修改hadoop-2.6.4/etc/hadoop/hdfs-site.xml <br>
        &lt;configuration&gt;<br>
        &lt;property&gt;<br>
            &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;<br>
            &lt;value&gt;/home/hadoop/data/name&lt;/value&gt;<br>
        &lt;/property&gt;<br>
        &lt;property&gt;<br>
            &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;<br>
            &lt;value&gt;/home/hadoop/data/data&lt;/value&gt;<br>
        &lt;/property&gt;</strong></strong></strong></p>

<p><strong><strong><strong>        &lt;property&gt;<br>
            &lt;name&gt;dfs.replication&lt;/name&gt;<br>
            &lt;value&gt;3&lt;/value&gt;<br>
        &lt;/property&gt;</strong></strong></strong></p>

<p><strong><strong><strong>        &lt;property&gt;<br>
            &lt;name&gt;dfs.secondary.http.address&lt;/name&gt;<br>
            &lt;value&gt;master:50090&lt;/value&gt;<br>
        &lt;/property&gt;<br>
        &lt;/configuration&gt;  <br>
        <br>
   7、修改hadoop-2.6.4/etc/hadoop/mapred-site.xml<br>
       &lt;configuration&gt;<br>
        &lt;property&gt;<br>
            &lt;name&gt;mapreduce.framework.name&lt;/name&gt;<br>
            &lt;value&gt;yarn&lt;/value&gt;<br>
        &lt;/property&gt;<br>
       &lt;/configuration&gt;   <br>
       <br>
   8、修改hadoop-2.6.4/etc/hadoop/yarn-site.xml<br>
       &lt;configuration&gt;<br>
        &lt;property&gt;<br>
            &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;<br>
            &lt;value&gt;master&lt;/value&gt;<br>
        &lt;/property&gt;</strong></strong></strong></p>

<p><strong><strong><strong>        &lt;property&gt;<br>
            &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;<br>
            &lt;value&gt;mapreduce_shuffle&lt;/value&gt;<br>
        &lt;/property&gt;<br>
      &lt;/configuration&gt;   <br>
  拷贝到相关主机 </strong></strong></strong>scp -r hadoop-2.6.4 test1:/home/hadoop/<br><strong><strong><strong>   9、修改hadoop-2.6.4/etc/hadoop/slaves<br>
      去掉localhost<br>
      添加hadoop1 hadoop2 hadoop3<br>
    <br>
   10、初始化HDFS<br>
      hadoop  namenode  -format<br>
   11、启动和停止<br>
      1、启动start-all.sh <br>
      2、停止stop-all.sh <br>
   <br>
 查看hdfs文件<br>
    hadoop fs -ls /<br>
上传文件测试<br>
    hadoop fs -put test.avi /<br>
查看文件    <br>
    hadoop fs -cat /test.avi   <br>
取文件    <br>
    hadoop fs -get /test.avi     </strong></strong></strong></p>

<p>查看hdfs文件<br>
    hadoop fs -ls /<br>
上传文件测试<br>
    hadoop fs -put test.avi /<br>
查看文件    <br>
    hadoop fs -cat /test.avi   <br>
取文件    <br>
    hadoop fs -get /test.avi   <br>
创建文件夹<br>
    hadoop fs -mkdir -p  /wordcount/input<br>
    hadoop fs -put a.txt b.txt /wordcount/input<br>
    <br>
    hadoop jar hadoop-mapreduce-examples-2.6.4.jar wordcount /wordcount/input /wordcount/output<br>
    hadoop fs -cat /wordcount/output/part-r-0000<br>
   <br>
java.io.IOException: There appears to be a gap in the edit log.  We expected txid 1, but got txid 16.<br>
namenode进程中出现如下报错信息<br>
原因：namenode元数据被破坏，需要修复<br>
解决：恢复一下namenode<br>
hadoop namenode -recover<br>
一路选择c，一般就OK了<br><strong><strong><strong>   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   <br>
   </strong></strong></strong></p>

<p> </p>            </div>
                </div>