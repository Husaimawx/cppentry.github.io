---
layout:     post
title:      执行Spark任务: 客户端
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/weixin_37243717/article/details/79519007				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-number">1</span>、Spark Submit工具：提交Spark的任务（jar文件）
        （*）spark提供的用于提交Spark任务工具
        （*）example：/root/training/spark-<span class="hljs-number">2.1</span><span class="hljs-number">.0</span>-bin-hadoop2<span class="hljs-number">.7</span>/examples/jars/spark-examples_2<span class="hljs-number">.11</span>-<span class="hljs-number">2.1</span><span class="hljs-number">.0</span><span class="hljs-preprocessor">.jar</span>
        （*）SparkPi<span class="hljs-preprocessor">.scala</span> 例子：蒙特卡罗求PI

             bin/spark-submit --master spark://bigdata11:<span class="hljs-number">7077</span> --class org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.spark</span><span class="hljs-preprocessor">.examples</span><span class="hljs-preprocessor">.SparkPi</span> examples/jars/spark-examples_2<span class="hljs-number">.11</span>-<span class="hljs-number">2.1</span><span class="hljs-number">.0</span><span class="hljs-preprocessor">.jar</span> <span class="hljs-number">100</span>

             Pi is roughly <span class="hljs-number">3.1419547141954713</span>

             bin/spark-submit --master spark://bigdata11:<span class="hljs-number">7077</span> --class org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.spark</span><span class="hljs-preprocessor">.examples</span><span class="hljs-preprocessor">.SparkPi</span> examples/jars/spark-examples_2<span class="hljs-number">.11</span>-<span class="hljs-number">2.1</span><span class="hljs-number">.0</span><span class="hljs-preprocessor">.jar</span> <span class="hljs-number">300</span>

            Pi is roughly <span class="hljs-number">3.141877971395932</span></code></pre>



<h3 id="蒙特卡罗求pi">蒙特卡罗求PI</h3>

<p><img src="https://img-blog.csdn.net/20180311191848454?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VpeGluXzM3MjQzNzE3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<pre class="prettyprint"><code class=" hljs livecodeserver">
<span class="hljs-number">2</span>、Spark Shell 工具：交互式命令行工具、作为一个Application运行
        两种模式：（<span class="hljs-number">1</span>）本地模式
                        bin/spark-<span class="hljs-built_in">shell</span> 
                        日志：Spark context available <span class="hljs-keyword">as</span> <span class="hljs-string">'sc'</span> (master = <span class="hljs-built_in">local</span>[*], app id = <span class="hljs-built_in">local</span>-<span class="hljs-number">1518181597235</span>).


                  （<span class="hljs-number">2</span>）集群模式
                        bin/spark-<span class="hljs-built_in">shell</span> <span class="hljs-comment">--master spark://bigdata11:7077</span>
                        日志：Spark context available <span class="hljs-keyword">as</span> <span class="hljs-string">'sc'</span> (master = spark://bigdata11:<span class="hljs-number">7077</span>, app id = app-<span class="hljs-number">20180209210815</span>-<span class="hljs-number">0002</span>).

            对象：Spark context available <span class="hljs-keyword">as</span> <span class="hljs-string">'sc'</span>
                  Spark session available <span class="hljs-keyword">as</span> <span class="hljs-string">'spark'</span> <span class="hljs-comment">---&gt; 在Spark 2.0后，新提供</span>
                                                          是一个统一的访问接口：Spark Core、Spark SQL、Spark Streaming


            sc.textFile(<span class="hljs-string">"hdfs://bigdata11:9000/input/data.txt"</span>) 通过sc对象读取HDFS的文件
              .flatMap(_.<span class="hljs-built_in">split</span>(<span class="hljs-string">" "</span>))  分词操作、压平
              .map((_,<span class="hljs-number">1</span>))  每个单词记一次数
              .reduceByKey(_+_)  按照key进行reduce，再将<span class="hljs-built_in">value</span>进行累加
              .saveAsTextFile(<span class="hljs-string">"hdfs://bigdata11:9000/output/spark/day0209/wc"</span>)

            多说一句：
            .reduceByKey(_+_)
            完整
            .reduceByKey((<span class="hljs-operator">a</span>,b) =&gt; <span class="hljs-operator">a</span>+b)

            Array((Tom,<span class="hljs-number">1</span>),(Tom,<span class="hljs-number">2</span>),(Mary,<span class="hljs-number">3</span>),(Tom,<span class="hljs-number">6</span>))

                  (Tom,(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">6</span>))
                       <span class="hljs-number">1</span>+<span class="hljs-number">2</span> = <span class="hljs-number">3</span>
                       <span class="hljs-number">3</span>+<span class="hljs-number">6</span> = <span class="hljs-number">9</span>

<span class="hljs-number">3</span>、开发WordCount程序
        <span class="hljs-keyword">http</span>://spark.apache.org/docs/<span class="hljs-number">2.1</span><span class="hljs-number">.0</span>/api/scala/index.html<span class="hljs-comment">#org.apache.spark.package</span>
        （<span class="hljs-number">1</span>）Scala版本: 在IDEA中
        （<span class="hljs-number">2</span>）Java版本（比较麻烦） ：在eclipse中</code></pre>

<pre class="prettyprint"><code class="language-scala hljs "><span class="hljs-keyword">package</span> mydemo
<span class="hljs-comment">/*
提交
bin/spark-submit --master spark://bigdata11:7077 --class mydemo.MyWordCount /root/temp/MyWordCount.jar hdfs://bigdata11:9000/input/data.txt hdfs://bigdata11:9000/output/spark/day0209/wc1
 */</span>

<span class="hljs-keyword">import</span> org.apache.spark.{SparkConf, SparkContext}

<span class="hljs-comment">//开发一个Scala版本的WordCount</span>
<span class="hljs-class"><span class="hljs-keyword">object</span> <span class="hljs-title">MyWordCount</span> {</span>
  <span class="hljs-keyword">def</span> main(args: Array[String]): Unit = {
    <span class="hljs-comment">//创建一个Config</span>
    <span class="hljs-keyword">val</span> conf = <span class="hljs-keyword">new</span> SparkConf().setAppName(<span class="hljs-string">"MyScalaWordCount"</span>)

    <span class="hljs-comment">//核心创建SparkContext对象</span>
    <span class="hljs-keyword">val</span> sc = <span class="hljs-keyword">new</span> SparkContext(conf)

    <span class="hljs-comment">//使用sc对象执行相应的算子（函数）</span>
    sc.textFile(args(<span class="hljs-number">0</span>))
      .flatMap(_.split(<span class="hljs-string">" "</span>))
      .map((_,<span class="hljs-number">1</span>))
      .reduceByKey(_+_)
      .saveAsTextFile(args(<span class="hljs-number">1</span>))

    <span class="hljs-comment">//停止SparkContext对象</span>
    sc.stop()

  }
}
</code></pre>

<pre class="prettyprint"><code class="language-java hljs "><span class="hljs-keyword">package</span> demo;

<span class="hljs-keyword">import</span> java.util.Arrays;
<span class="hljs-keyword">import</span> java.util.Iterator;
<span class="hljs-keyword">import</span> java.util.List;

<span class="hljs-keyword">import</span> org.apache.spark.SparkConf;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.JavaPairRDD;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.JavaRDD;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.JavaSparkContext;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.function.FlatMapFunction;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.function.Function2;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.function.PairFunction;

<span class="hljs-keyword">import</span> scala.Tuple2;

<span class="hljs-comment">/*
 * 执行
 * bin/spark-submit --master spark://bigdata11:7077 --class demo.JavaWordCount /root/temp/MyJavaWordCount.jar hdfs://bigdata11:9000/input/data.txt
 */</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JavaWordCount</span> {</span>

    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span>(String[] args) {
        <span class="hljs-comment">//创建一个Config对象：配置参数</span>
        SparkConf conf = <span class="hljs-keyword">new</span> SparkConf().setAppName(<span class="hljs-string">"MyJavaWordCount"</span>);

        <span class="hljs-comment">//创建一个SparkContext对象：JavaSparkContext</span>
        JavaSparkContext context = <span class="hljs-keyword">new</span> JavaSparkContext(conf);

        <span class="hljs-comment">//读入数据</span>
        JavaRDD&lt;String&gt; lines = context.textFile(args[<span class="hljs-number">0</span>]);

        <span class="hljs-comment">//分词</span>
        <span class="hljs-comment">/*
         * FlatMapFunction&lt;String, U&gt; 
         * String 读入的每一句话
         * U（String）：返回值
         */</span>
        JavaRDD&lt;String&gt; words = lines.flatMap(<span class="hljs-keyword">new</span> FlatMapFunction&lt;String, String&gt;() {

            <span class="hljs-annotation">@Override</span>
            <span class="hljs-keyword">public</span> Iterator&lt;String&gt; <span class="hljs-title">call</span>(String line) <span class="hljs-keyword">throws</span> Exception {
                <span class="hljs-comment">//数据: I love Beijing</span>
                <span class="hljs-comment">// 如何进行分词操作</span>
                <span class="hljs-keyword">return</span> Arrays.asList(line.split(<span class="hljs-string">" "</span>)).iterator();
            }

        });

        <span class="hljs-comment">//每个单词记一次数</span>
        <span class="hljs-comment">//  Beijing  ---&gt; (Beijing,1)</span>
        <span class="hljs-comment">/*
         * new PairFunction&lt;String, K2, V2&gt;
         * String: 每个单词
         * K2, V2  ---&gt; 相当于是Map的输出
         */</span>
        JavaPairRDD&lt;String, Integer&gt; wordOne = words.mapToPair(<span class="hljs-keyword">new</span> PairFunction&lt;String, String, Integer&gt;() {

            <span class="hljs-annotation">@Override</span>
            <span class="hljs-keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="hljs-title">call</span>(String word) <span class="hljs-keyword">throws</span> Exception {
                <span class="hljs-comment">// Beijing  ---&gt; (Beijing,1)</span>
                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Tuple2&lt;String, Integer&gt;(word, <span class="hljs-number">1</span>);
            }
        });

        <span class="hljs-comment">//执行Reduce操作</span>
        JavaPairRDD&lt;String, Integer&gt;  count = wordOne.reduceByKey(<span class="hljs-keyword">new</span> Function2&lt;Integer, Integer, Integer&gt;() {

            <span class="hljs-annotation">@Override</span>
            <span class="hljs-keyword">public</span> Integer <span class="hljs-title">call</span>(Integer a, Integer b) <span class="hljs-keyword">throws</span> Exception {
                <span class="hljs-keyword">return</span> a + b;
            }
        });

        <span class="hljs-comment">//执行计算，执行action：把结果直接打印在屏幕上</span>
        <span class="hljs-comment">//           k4      v4</span>
        List&lt;Tuple2&lt;String, Integer&gt;&gt; result = count.collect();

        <span class="hljs-comment">//输出到屏幕</span>
        <span class="hljs-keyword">for</span>(Tuple2&lt;String, Integer&gt; tuple: result){
            System.out.println(tuple._1+<span class="hljs-string">"\t"</span>+tuple._2);
        }

        <span class="hljs-comment">//停止SparkContext对象</span>
        context.stop();
    }
}</code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>