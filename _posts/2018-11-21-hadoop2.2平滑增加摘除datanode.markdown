---
layout:     post
title:      hadoop2.2平滑增加摘除datanode
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>主要配置文件hdfs-site.xml：</p>
<p>&lt;property&gt;</p>
<p>      &lt;!--要增加的datanode--&gt;<br>
      &lt;name&gt;dfs.hosts&lt;/name&gt;<br>
      &lt;value&gt;/app/soft/hadoop/etc/hadoop/hosts&lt;/value&gt;<br>
&lt;/property&gt;</p>
<p> </p>
<p>&lt;property&gt;</p>
<p>      &lt;!--要摘除的datanode--&gt;<br>
      &lt;name&gt;dfs.hosts.exclude&lt;/name&gt;<br>
      &lt;value&gt;/app/soft/hadoop/etc/hadoop/exclude&lt;/value&gt;<br>
&lt;/property&gt;</p>
<p>增加节点：</p>
<p>如原集群有3个节点node1,node2,node3,现在要增加node4,那么需要追加node4到/app/soft/hadoop/etc/hadoop/hosts文件：</p>
<p>node1</p>
<p>node2</p>
<p>node3</p>
<p><span style="color:#ff6666;">node4</span></p>
<p>增加后执行：hdfs dfsadmin -refreshNodes进行节点刷新，这样就能重新加载hosts配置文件，刷新后到新增节点上执行$HADOOP_HOME/sbin/hadoop-daemon.sh start datanode，此时用hdfs dfsadmin -report就会看到新增加的节点已经生效，如果想使数据均衡，那么可以执行hdfs balancer  -threshold 10(注：hdoop1使用命令为：<span>start-balancer.sh –t 10%</span>)，即发现磁盘使用率偏差在10%以上的就会进行数据均衡，此过程有点漫长，要有耐心！</p>
<p> </p>
<p>摘除节点：</p>
<p>如原集群有4个节点node1,node2,node3，现在要将故障节点node2摘除，那么需要再exclude文件中增加node2,执行hdfs dfsadmin -refreshNodes,再到故障节点执行hadoop-daemon.sh stop datanode(如直接停机自然可省略这步).</p>
            </div>
                </div>