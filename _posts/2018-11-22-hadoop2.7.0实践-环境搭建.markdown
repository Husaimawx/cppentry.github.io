---
layout:     post
title:      hadoop2.7.0实践-环境搭建
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p><strong>文档说明</strong> <br>
本文档为hadoop搭建实践文档，相关理论可到hadoop官网查看学习。 <br>
操作系统：Ubuntu14 x64位 <br>
Hadoop：Hadoop 2.7.0</p>

<p>Ubuntu官网：<a href="http://www.ubuntu.com/download/desktop" rel="nofollow">http://www.ubuntu.com/download/desktop</a> <br>
下载地址： <br>
<a href="http://211.167.105.77:83/1Q2W3E4R5T6Y7U8I9O0P1Z2X3C4V5B/releases.ubuntu.com/14.04.2/ubuntu-14.04.2-desktop-amd64.iso" rel="nofollow">http://211.167.105.77:83/1Q2W3E4R5T6Y7U8I9O0P1Z2X3C4V5B/releases.ubuntu.com/14.04.2/ubuntu-14.04.2-desktop-amd64.iso</a> <br>
Hadoop官网：<a href="http://hadoop.apache.org/releases.html" rel="nofollow">http://hadoop.apache.org/releases.html</a> <br>
单机版配置官网说明 <br>
<a href="http://hadoop.apache.org/docs/r2.7.0/hadoop-project-dist/hadoop-common/SingleCluster.html" rel="nofollow">http://hadoop.apache.org/docs/r2.7.0/hadoop-project-dist/hadoop-common/SingleCluster.html</a></p>

<p><strong>1.安装Ubuntu</strong> <br>
可以将iso文件格式化到U盘中，安装Ubuntu系统，具体实施步骤可自行百度。</p>

<p><strong>2.安装配置Jdk</strong> <br>
步骤参见：<a href="http://wxinpeng.iteye.com/blog/2098955" rel="nofollow">http://wxinpeng.iteye.com/blog/2098955</a>。</p>

<p><strong>2.1.下载jdk-7u79-linux-x64.tar.gz</strong>  <br>
下载网址： <br>
<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html" rel="nofollow">http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html</a></p>

<p><strong>2.2.解压JDK</strong></p>

<pre class="prettyprint"><code class=" hljs lasso"><span class="hljs-variable">$sudo</span> tar zxvf jdk<span class="hljs-subst">-</span><span class="hljs-number">7</span>u79<span class="hljs-attribute">-linux</span><span class="hljs-attribute">-x64</span><span class="hljs-built_in">.</span>tar<span class="hljs-built_in">.</span>gz <span class="hljs-attribute">-C</span> /usr/lib/jvm</code></pre>

<p><strong>2.3.设置环境变量（全局）</strong> <br>
$sudo gedit /etc/profile <br>
打开profile文件输入</p>

<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-keyword">export</span> JAVA_HOME=/usr/lib/jvm/jdk1.<span class="hljs-number">7.0</span>_79
<span class="hljs-keyword">export</span> CLASSPATH=<span class="hljs-string">".:<span class="hljs-variable">$JAVA_HOME</span>/lib:<span class="hljs-variable">$CLASSPATH</span>"</span>
<span class="hljs-keyword">export</span> PATH=<span class="hljs-string">"<span class="hljs-variable">$JAVA_HOME</span>/bin:<span class="hljs-variable">$PATH</span>"</span></code></pre>

<p><strong>2.4.设置系统默认JDK</strong></p>



<pre class="prettyprint"><code class=" hljs lasso"><span class="hljs-variable">$sudo</span> update<span class="hljs-attribute">-alternatives</span> <span class="hljs-subst">--</span>install /usr/bin/java java /usr/lib/jvm/jdk1<span class="hljs-number">.7</span><span class="hljs-number">.0</span>_79/bin/java <span class="hljs-number">300</span>
<span class="hljs-variable">$sudo</span> update<span class="hljs-attribute">-alternatives</span> <span class="hljs-subst">--</span>install /usr/bin/javac javac /usr/lib/jvm/jdk1<span class="hljs-number">.7</span><span class="hljs-number">.0</span>_79/bin/javac <span class="hljs-number">300</span>
<span class="hljs-variable">$sudo</span> update<span class="hljs-attribute">-alternatives</span> <span class="hljs-subst">--</span>config java</code></pre>

<p><strong>2.5.验证JDK</strong></p>



<pre class="prettyprint"><code class=" hljs lasso"><span class="hljs-variable">$java</span> <span class="hljs-attribute">-version</span></code></pre>

<p><strong>3.安装配置hadoop</strong></p>

<p><strong>3.1.下载hadoop</strong></p>

<p><strong>3.2.配置对应包</strong></p>



<pre class="prettyprint"><code class=" hljs bash">$ <span class="hljs-built_in">sudo</span> apt-get install ssh
$ <span class="hljs-built_in">sudo</span> apt-get install rsync</code></pre>

<p><strong>3.3.配置etc/hadoop/hadoop-env.sh</strong></p>



<pre class="prettyprint"><code class=" hljs ruby"><span class="hljs-comment"># set to the root of your Java installation</span>
export <span class="hljs-constant">JAVA_HOME</span>=<span class="hljs-regexp">/usr/lib</span><span class="hljs-regexp">/jvm/jdk</span>1.<span class="hljs-number">7.0_79</span></code></pre>

<p><strong>3.4.测试一下</strong></p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-variable">$bin</span>/hadoop</code></pre>

<p><strong>3.5.运行简单例子</strong></p>



<pre class="prettyprint"><code class=" hljs ruby"><span class="hljs-variable">$ </span>mkdir input
<span class="hljs-variable">$ </span>cp etc/hadoop/*.xml input
<span class="hljs-variable">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-<span class="hljs-number">2.7</span>.<span class="hljs-number">0</span>.jar grep input output <span class="hljs-string">'dfs[a-z.]+'</span>
<span class="hljs-variable">$ </span>cat output/*</code></pre>

<p><strong>3.6.配置相关文件</strong> <br>
文件etc/hadoop/core-site.xml:</p>



<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>hdfs://localhost:9000<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>

<p>文件etc/hadoop/hdfs-site.xml:</p>



<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>

<p><strong>3.7.检测ssh</strong></p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-variable">$ssh</span> localhost</code></pre>

<p><strong>3.8.执行mapreduce job</strong> <br>
1)格式化文件系统</p>



<pre class="prettyprint"><code class=" hljs ruby"> <span class="hljs-variable">$ </span>bin/hdfs namenode –format</code></pre>

<p>2)启动服务</p>



<pre class="prettyprint"><code class=" hljs ruby"><span class="hljs-variable">$ </span>sbin/start-dfs.sh</code></pre>

<p>3)浏览网页 <br>
NameNode - <a href="http://localhost:50070/" rel="nofollow">http://localhost:50070/</a> <br>
4)创建目录</p>



<pre class="prettyprint"><code class=" hljs ruby"><span class="hljs-variable">$ </span>bin/hdfs dfs -mkdir /user
<span class="hljs-variable">$ </span>bin/hdfs dfs -mkdir /user/jsl</code></pre>

<p>5)复制文件</p>



<pre class="prettyprint"><code class=" hljs ruby"><span class="hljs-variable">$ </span>bin/hdfs dfs -put etc/hadoop input</code></pre>

<p>6)执行程序</p>



<pre class="prettyprint"><code class=" hljs lasso">$ bin/hadoop jar share/hadoop/mapreduce/hadoop<span class="hljs-attribute">-mapreduce</span><span class="hljs-attribute">-examples</span><span class="hljs-subst">-</span><span class="hljs-number">2.7</span><span class="hljs-number">.0</span><span class="hljs-built_in">.</span>jar grep input output <span class="hljs-string">'dfs[a-z.]+'</span></code></pre>

<p>7)查看结果</p>



<pre class="prettyprint"><code class=" hljs ruby"><span class="hljs-variable">$ </span>bin/hdfs dfs -get output
<span class="hljs-variable">$ </span>cat output/*</code></pre>

<p>8)退出服务</p>



<pre class="prettyprint"><code class=" hljs lasso"><span class="hljs-variable">$sbin</span>/stop<span class="hljs-attribute">-dfs</span><span class="hljs-built_in">.</span>sh</code></pre>

<p><strong>4.配置yarn</strong> <br>
Yarn是hadoop的资源调度器，可以配置mapreduce job基于yarn运行。 <br>
1)配置etc/hadoop/mapred-site.xml</p>



<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>

<p>2)配置etc/hadoop/yarn-site.xml</p>



<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>

<p>3)启动服务</p>



<pre class="prettyprint"><code class=" hljs ruby"><span class="hljs-variable">$ </span>sbin/start-yarn.sh</code></pre>

<p>4)浏览检测 <br>
ResourceManager - <a href="http://localhost:8088/" rel="nofollow">http://localhost:8088/</a> <br>
5)退出服务</p>



<pre class="prettyprint"><code class=" hljs ruby"><span class="hljs-variable">$ </span>sbin/stop-yarn.sh</code></pre>

<p><strong>常见问题及命令</strong> <br>
1)查看对应hadoop版本</p>



<pre class="prettyprint"><code class=" hljs java">file lib/<span class="hljs-keyword">native</span>/libhadoop.so<span class="hljs-number">.1</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span></code></pre>

<p>2)查看操作系统对应版本</p>



<pre class="prettyprint"><code class=" hljs ">cat /etc/issue</code></pre>

<p>3)版本不一致时调整 <br>
删除临时目录</p>



<pre class="prettyprint"><code class=" hljs lasso">cd /tmp/hadoop<span class="hljs-attribute">-jsl</span>/dfs/<span class="hljs-built_in">data</span>
rm <span class="hljs-attribute">-rf</span> current</code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>