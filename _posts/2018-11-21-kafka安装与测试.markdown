---
layout:     post
title:      kafka安装与测试
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>kafka安装: <br>
很简单这里就不说了。 <br>
启动kafka服务器: <br>
1.启动zookeeper: <br>
使用kafka自带zookeeper <br>
在kafka安装目录下运行命令:</p>

<pre class="prettyprint"><code class=" hljs avrasm">bin/zookeeper-server-start<span class="hljs-preprocessor">.sh</span> config/zookeeper<span class="hljs-preprocessor">.properties</span> </code></pre>

<p>(默认zookeeper绑定在2181端口上)</p>

<p>2.启动kafka broker</p>



<pre class="prettyprint"><code class=" hljs axapta">bin/kafka-<span class="hljs-keyword">server</span>-start.sh config/<span class="hljs-keyword">server</span>.properties </code></pre>

<p>3.创建一个Topic名字为Husin</p>



<pre class="prettyprint"><code class=" hljs brainfuck"><span class="hljs-comment">bin/kafka</span><span class="hljs-literal">-</span><span class="hljs-comment">topics</span><span class="hljs-string">.</span><span class="hljs-comment">sh</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">create</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">zookeeper</span> <span class="hljs-comment">localhost:2181</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">replication</span><span class="hljs-literal">-</span><span class="hljs-comment">factor</span> <span class="hljs-comment">1</span> <span class="hljs-comment">\</span>
&gt; <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">partitions</span> <span class="hljs-comment">1</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">topic</span> <span class="hljs-comment">Husin</span></code></pre>

<p>4.验证topic是否创建成功</p>



<pre class="prettyprint"><code class=" hljs brainfuck"><span class="hljs-comment">bin/kafka</span><span class="hljs-literal">-</span><span class="hljs-comment">topics</span><span class="hljs-string">.</span><span class="hljs-comment">sh</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">list</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">zookeeper</span> <span class="hljs-comment">localhost:2181</span></code></pre>

<p>5.启动一个Producer并发送消息</p>



<pre class="prettyprint"><code class=" hljs lasso">bin/kafka<span class="hljs-attribute">-console</span><span class="hljs-attribute">-producer</span><span class="hljs-built_in">.</span>sh <span class="hljs-subst">--</span>broker<span class="hljs-attribute">-list</span> localhost:<span class="hljs-number">9092</span> <span class="hljs-subst">--</span>topic Husin</code></pre>

<p>(注意,通信的端口是在9092不是2181)</p>

<p>6.启动一个consumer接收消息</p>



<pre class="prettyprint"><code class=" hljs brainfuck"><span class="hljs-comment">bin/kafka</span><span class="hljs-literal">-</span><span class="hljs-comment">console</span><span class="hljs-literal">-</span><span class="hljs-comment">consumer</span><span class="hljs-string">.</span><span class="hljs-comment">sh</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">zookeeper</span> <span class="hljs-comment">localhost:2181</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">topic</span> <span class="hljs-comment">Husin</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">from</span><span class="hljs-literal">-</span><span class="hljs-comment">beginning</span></code></pre>

<p>(注意,启动的通信服务端口是2181不是9092)</p>

<p>7.关闭zookeeper和kafka</p>



<pre class="prettyprint"><code class=" hljs vbscript">停止kafka
bin/kafka-<span class="hljs-built_in">server</span>-<span class="hljs-keyword">stop</span>.sh
停止zookeeper
bin/zookeeper-<span class="hljs-built_in">server</span>-<span class="hljs-keyword">stop</span>.sh</code></pre>

<p>(ps:不知道为什么服务端口不统一,可能是配置的问题,定义其他的端口号是无法接收的,而且,producer必须是9092,consumer必须是2181,奇怪了!)</p>

<p>更新: <br>
没错的确是这样,producer的端口是在9092,consumer的端口必须是在2181,这是分布式消息系统,不需要producer和consumer端口对应的. <br>
实际原因是kafka是生产者,zookeeper是消费者.</p>

<p>下面这篇文章介绍了kafka相关的命令操作,值得学习: <br>
<a href="http://www.cnblogs.com/qizhelongdeyang/p/7354315.html" rel="nofollow">http://www.cnblogs.com/qizhelongdeyang/p/7354315.html</a></p>

<p>Java下使用kafka API</p>

<p>这是一个单线程发送接收的kafka实例:</p>

<p>producer端代码:</p>



<pre class="prettyprint"><code class=" hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> kafkaProducer
{
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span>(String[] args){
        Properties props = <span class="hljs-keyword">new</span> Properties();
        props.put(<span class="hljs-string">"bootstrap.servers"</span>, <span class="hljs-string">"localhost:9092"</span>);
        props.put(<span class="hljs-string">"acks"</span>, <span class="hljs-string">"all"</span>);
        props.put(<span class="hljs-string">"retries"</span>, <span class="hljs-number">0</span>);
        props.put(<span class="hljs-string">"batch.size"</span>, <span class="hljs-number">16384</span>);
        props.put(<span class="hljs-string">"linger.ms"</span>, <span class="hljs-number">1</span>);
        props.put(<span class="hljs-string">"buffer.memory"</span>, <span class="hljs-number">33554432</span>);
        props.put(<span class="hljs-string">"key.serializer"</span>, <span class="hljs-string">"org.apache.kafka.common.serialization.StringSerializer"</span>);
        props.put(<span class="hljs-string">"value.serializer"</span>, <span class="hljs-string">"org.apache.kafka.common.serialization.StringSerializer"</span>);

        Producer&lt;String, String&gt; producer = <span class="hljs-keyword">new</span> KafkaProducer&lt;&gt;(props);
        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i&lt;<span class="hljs-number">100</span>; i++) {
            System.<span class="hljs-keyword">out</span>.println(i);
            producer.send(<span class="hljs-keyword">new</span> ProducerRecord&lt;&gt;(<span class="hljs-string">"test"</span>, Integer.toString(i), Integer.toString(i)));
        }
    }
}

</code></pre>

<p>consumer端代码:</p>



<pre class="prettyprint"><code class=" hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> kafkaConsumer {

        <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span>(String[] args) {
            Properties props = <span class="hljs-keyword">new</span> Properties();
            props.put(<span class="hljs-string">"bootstrap.servers"</span>, <span class="hljs-string">"localhost:2181"</span>);
            props.put(<span class="hljs-string">"group.id"</span>, <span class="hljs-string">"test-consumer-group"</span>);
            props.put(<span class="hljs-string">"enable.auto.commit"</span>, <span class="hljs-string">"true"</span>);
            props.put(<span class="hljs-string">"auto.commit.interval.ms"</span>, <span class="hljs-string">"1000"</span>);
            props.put(<span class="hljs-string">"key.deserializer"</span>, <span class="hljs-string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);
            props.put(<span class="hljs-string">"value.deserializer"</span>, <span class="hljs-string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);
            KafkaConsumer&lt;String, String&gt; consumer = <span class="hljs-keyword">new</span> KafkaConsumer&lt;&gt;(props);
            consumer.subscribe(Arrays.asList(<span class="hljs-string">"test"</span>, <span class="hljs-string">"test"</span>));
            <span class="hljs-keyword">while</span>(<span class="hljs-keyword">true</span>) {
                ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="hljs-number">100</span>);
                <span class="hljs-keyword">for</span> (ConsumerRecord&lt;String, String&gt; record: records){
                    System.<span class="hljs-keyword">out</span>.printf(<span class="hljs-string">"offset = %d, key = %s, value = %s%n"</span>, record.offset(), record.key(), record.<span class="hljs-keyword">value</span>());
                }
            }
        }
}</code></pre>

<p>Maven工程依赖:</p>



<pre class="prettyprint"><code class=" hljs xml">    <span class="hljs-comment">&lt;!--这是kafka依赖--&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">dependency</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">groupId</span>&gt;</span>org.apache.kafka<span class="hljs-tag">&lt;/<span class="hljs-title">groupId</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">artifactId</span>&gt;</span>kafka_2.11<span class="hljs-tag">&lt;/<span class="hljs-title">artifactId</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">version</span>&gt;</span>1.0.0<span class="hljs-tag">&lt;/<span class="hljs-title">version</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">dependency</span>&gt;</span></code></pre>

<p><strong>kafka Java Api使用遇到的坑:</strong> <br>
producer能正常发送消息 , 但是consumer接受不到消息。换了一个版本可以正常发送消息 , Java producer发送的消息能被控制台开启的consumer接收到，但是java consumer一直接收不到消息。 <br>
原因： <br>
代码本身没有问题，问题出在consumer的配置上。 <br>
consumer没有配置 <br>
props.put(“auto.offset.reset”, “earliest”); <br>
网上大多数的demo都没有这个配置，真不知道他们的结果从哪来的。</p>

<p>//该配置的解释 <br>
该参数表示当前groupId下的消费者，在ZK中没有offset值时(比新的groupid，或者是zk数据被清空)，consumer应该从哪个offset开始消费，第二个参数若是latest则表示接受接收最大的offser(即最新消息)，earliest表示最小offset，即从topic的开始位置消费所有消息，最好设置为earliest，这样新的分组才能从最开始进行处理。</p>

<p><strong>kafka的消息发送机制及其原理：</strong> <br>
   每当用户往topic发送数据时,数据会被hash到不同的partition,这些partition位于不同的集群节点上(也就是说发送的消息是被分布式存储在不同机器上的),所以每个消息都会被记录一个offset消息号,随着消息的增加offset也会增加.消费者就是通过这个offset号去查询读取这个消息的。 <br>
   消息会均匀的发送到不同的partition中,也就是机器的存储压力是均匀的。 <br>
   消费者有组的概念,首先每一个组都能完全的接受到topic的全部消息,但是组内会竞争消费消息,比如topic有10条消息,有A B两个消费组,AB组都能接收到这10条消息,但是并不是AB组内所有消费者都能接收到这10条消息。</p>

<p><strong>kafka java 配置详解</strong> <br>
生产者： <br>
* bootstrap.servers：Kafka集群连接串，可以由多个host:port组成。 <br>
* acks：broker消息确认的模式，有三种： <br>
0：不进行消息接收确认，即Client端发送完成后不会等待Broker的确认； <br>
1：由Leader确认，Leader接收到消息后会立即返回确认信息； <br>
all：集群完整确认，Leader会等待所有in-sync的follower节点都确认收到消息后，再返回确认信息； <br>
我们可以根据消息的重要程度，设置不同的确认模式。默认为1。 <br>
* retries：发送失败时Producer端的重试次数，默认为0 <br>
* batch.size：当同时有大量消息要向同一个分区发送时，Producer端会将消息打包后进行批量发送。如果设置为0，则每条消息都独立发送。默认为16384字节 <br>
* linger.ms：发送消息前等待的毫秒数，与batch.size配合使用。在消息负载不高的情况下，配置linger.ms能够让Producer在发送消息前等待一定时间，以积累更多的消息打包发送，达到节省网络资源的目的。默认为0 <br>
* key.serializer/value.serializer：消息key/value的序列器Class，根据key和value的类型决定 <br>
* buffer.memory：消息缓冲池大小。尚未被发送的消息会保存在Producer的内存中，如果消息产生的速度大于消息发送的速度，那么缓冲池满后发送消息的请求会被阻塞。默认33554432字节（32MB）</p>

<p>消费者常用配置： <br>
* bootstrap.servers/key.deserializer/value.deserializer：和Producer端的含义一样，不再赘述 <br>
* fetch.min.bytes：每次最小拉取的消息大小（byte）。Consumer会等待消息积累到一定尺寸后进行批量拉取。默认为1，代表有一条就拉一条 <br>
* max.partition.fetch.bytes：每次从单个分区中拉取的消息最大尺寸（byte），默认为1M <br>
* group.id：Consumer的group id，同一个group下的多个Consumer不会拉取到重复的消息，不同group下的Consumer则会保证拉取到每一条消息。注意，同一个group下的consumer数量不能超过分区数。 <br>
* enable.auto.commit：是否自动提交已拉取消息的offset。提交offset即视为该消息已经成功被消费，该组下的Consumer无法再拉取到该消息（除非手动修改offset）。默认为true <br>
* auto.commit.interval.ms：自动提交offset的间隔毫秒数，默认5000。offset就是向系统提交的确认信息。</p>

<p>说明： <br>
本 例中采用的是自动提交offset，Kafka client会启动一个线程定期将offset提交至broker。假设在自动提交的间隔内发生故障（比如整个JVM进程死掉），那么有一部分消息是会被 重复消费的。要避免这一问题，可使用手动提交offset的方式。构造consumer时将enable.auto.commit设为false，并在代 码中用consumer.commitSync()来手动提交。</p>

<p>更多的Producer配置见官网 <br>
<a href="http://kafka.apache.org/documentation.html#producerconfigs" rel="nofollow">http://kafka.apache.org/documentation.html#producerconfigs</a></p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>