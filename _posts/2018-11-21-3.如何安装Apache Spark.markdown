---
layout:     post
title:      3.如何安装Apache Spark
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<h2>如何安装Apache Spark</h2>
<hr><p><code>1</code> Why Apache Spark<br><code>2</code> 关于Apache Spark<br><code>3</code> 如何安装Apache Spark<br><code>4</code> Apache Spark的工作原理<br><code>5</code> spark弹性分布式数据集<br><code>6</code> RDD持久性<br><code>7</code> spark共享变量<br><code>8</code> Spark SQL<br><code>9</code> Spark Streaming</p>
<p>原文链接：http://blogxinxiucan.sh1.newtouch.com/2017/07/23/%E5%A6%82%E4%BD%95%E5%AE%89%E8%A3%85Apache-Spark/</p>
<p>下表列出了一些重要的链接和先决条件：</p>
<table><thead><tr class="header"><th>当前版本</th>
<th>1.0.1 @ http://d3kbcqa49mib13.cloudfront.net/spark-1.0.1.tgz</th>
</tr></thead><tbody><tr class="odd"><td>下载页面</td>
<td>https://spark.apache.org/downloads.html</td>
</tr><tr class="even"><td>JDK版本（必填）</td>
<td>1.6以上</td>
</tr><tr class="odd"><td>Scala版本（必填）</td>
<td>2.10以上</td>
</tr><tr class="even"><td>Python（可选）</td>
<td>[2.6,3.0）</td>
</tr><tr class="odd"><td>简单构建工具（必需）</td>
<td>http://www.scala-sbt.org</td>
</tr><tr class="even"><td>开发版本</td>
<td>git clone git：//github.com/apache/spark.git</td>
</tr><tr class="odd"><td>Building说明</td>
<td>https://spark.apache.org/docs/latest/building-with-maven.html</td>
</tr><tr class="even"><td>Maven</td>
<td>3.0以上</td>
</tr></tbody></table><p><strong>Apache Spark可以配置为独立运行，也可以在Hadoop V1 SIMR或Hadoop 2 YARN / Mesos上运行。Apache Spark需要Java，Scala或Python中等技能。这里我们将看到如何在独立配置中安装和运行Apache Spark。</strong></p>
<ol><li>安装JDK 1.6+，Scala 2.10+，Python [2.6,3）和sbt </li><li>下载Apache Spark 1.0.1发行版 </li><li>
<p>在指定的目录中解压缩并解压缩spark-1.0.1.tgz</p>
<pre><code>akuntamukkala@localhost~/Downloads$ pwd 
   /Users/akuntamukkala/Downloads akuntamukkala@localhost~/Downloads$ tar -zxvf spark- 1.0.1.tgz -C /Users/akuntamukkala/spark</code></pre>
<p>4、 从＃4转到目录并运行sbt来构建Apache Spark</p>
<pre><code>akuntamukkala@localhost~/spark/spark-1.0.1$ pwd /Users/akuntamukkala/spark/spark-1.0.1 akuntamukkala@localhost~/spark/spark-1.0.1$ sbt/sbt assembly</code></pre>
<p>5、 启动Apache Spark独立REPL对于Scala，请使用：<br><code>/ Users / akuntamukkala / spark / spark - 1.0。1 / bin / spark - shell</code><br>
对于Python，请使用：<br><code>/Users/akuntamukkala/spark/spark-1.0.1/bin/ pyspark</code></p>
</li></ol><p>6.、转到SparkUI @ http：// localhost：4040</p>
<hr><p><strong>公众号：it全能程序猿</strong><br><img src="http://osausq2jb.bkt.clouddn.com/qrcode_for_gh_f8de8f2a2436_344.jpg" alt="qrcode_for_gh_f8de8f2a2436_344.jpg"></p>
<hr>            </div>
                </div>