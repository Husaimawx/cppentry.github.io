---
layout:     post
title:      Spark修炼之道（进阶篇）——Spark入门到精通：第十三节 Spark Streaming—— Spark SQL、DataFrame与Spark Streaming
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/lovehuangjiaju/article/details/50096995				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h2 id="主要内容">主要内容</h2>

<ol>
<li>Spark SQL、DataFrame与Spark Streaming</li>
</ol>

<h2 id="1-spark-sqldataframe与spark-streaming">1. Spark SQL、DataFrame与Spark Streaming</h2>

<p>源码直接参照：<a href="https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala" rel="nofollow">https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala</a></p>

<pre class="prettyprint"><code class=" hljs scala"><span class="hljs-keyword">import</span> org.apache.spark.SparkConf
<span class="hljs-keyword">import</span> org.apache.spark.SparkContext
<span class="hljs-keyword">import</span> org.apache.spark.rdd.RDD
<span class="hljs-keyword">import</span> org.apache.spark.streaming.{Time, Seconds, StreamingContext}
<span class="hljs-keyword">import</span> org.apache.spark.util.IntParam
<span class="hljs-keyword">import</span> org.apache.spark.sql.SQLContext
<span class="hljs-keyword">import</span> org.apache.spark.storage.StorageLevel

<span class="hljs-class"><span class="hljs-keyword">object</span> <span class="hljs-title">SqlNetworkWordCount</span> {</span>
  <span class="hljs-keyword">def</span> main(args: Array[String]) {
    <span class="hljs-keyword">if</span> (args.length &lt; <span class="hljs-number">2</span>) {
      System.err.println(<span class="hljs-string">"Usage: NetworkWordCount &lt;hostname&gt; &lt;port&gt;"</span>)
      System.exit(<span class="hljs-number">1</span>)
    }

    StreamingExamples.setStreamingLogLevels()

    <span class="hljs-comment">// Create the context with a 2 second batch size</span>
    <span class="hljs-keyword">val</span> sparkConf = <span class="hljs-keyword">new</span> SparkConf().setAppName(<span class="hljs-string">"SqlNetworkWordCount"</span>).setMaster(<span class="hljs-string">"local[4]"</span>)
    <span class="hljs-keyword">val</span> ssc = <span class="hljs-keyword">new</span> StreamingContext(sparkConf, Seconds(<span class="hljs-number">2</span>))

    <span class="hljs-comment">// Create a socket stream on target ip:port and count the</span>
    <span class="hljs-comment">// words in input stream of \n delimited text (eg. generated by 'nc')</span>
    <span class="hljs-comment">// Note that no duplication in storage level only for running locally.</span>
    <span class="hljs-comment">// Replication necessary in distributed scenario for fault tolerance.</span>
    <span class="hljs-comment">//Socke作为数据源</span>
    <span class="hljs-keyword">val</span> lines = ssc.socketTextStream(args(<span class="hljs-number">0</span>), args(<span class="hljs-number">1</span>).toInt, StorageLevel.MEMORY_AND_DISK_SER)
    <span class="hljs-comment">//words DStream</span>
    <span class="hljs-keyword">val</span> words = lines.flatMap(_.split(<span class="hljs-string">" "</span>))

    <span class="hljs-comment">// Convert RDDs of the words DStream to DataFrame and run SQL query</span>
    <span class="hljs-comment">//调用foreachRDD方法，遍历DStream中的RDD</span>
    words.foreachRDD((rdd: RDD[String], time: Time) =&gt; {
      <span class="hljs-comment">// Get the singleton instance of SQLContext</span>
      <span class="hljs-keyword">val</span> sqlContext = SQLContextSingleton.getInstance(rdd.sparkContext)
      <span class="hljs-keyword">import</span> sqlContext.implicits._

      <span class="hljs-comment">// Convert RDD[String] to RDD[case class] to DataFrame</span>
      <span class="hljs-keyword">val</span> wordsDataFrame = rdd.map(w =&gt; Record(w)).toDF()

      <span class="hljs-comment">// Register as table</span>
      wordsDataFrame.registerTempTable(<span class="hljs-string">"words"</span>)

      <span class="hljs-comment">// Do word count on table using SQL and print it</span>
      <span class="hljs-keyword">val</span> wordCountsDataFrame =
        sqlContext.sql(<span class="hljs-string">"select word, count(*) as total from words group by word"</span>)
      println(s<span class="hljs-string">"========= $time ========="</span>)
      wordCountsDataFrame.show()
    })

    ssc.start()
    ssc.awaitTermination()
  }
}


<span class="hljs-javadoc">/** Case class for converting RDD to DataFrame */</span>
<span class="hljs-class"><span class="hljs-keyword">case</span> <span class="hljs-keyword">class</span> <span class="hljs-title">Record</span><span class="hljs-params">(word: String)</span></span>


<span class="hljs-javadoc">/** Lazily instantiated singleton instance of SQLContext */</span>
<span class="hljs-class"><span class="hljs-keyword">object</span> <span class="hljs-title">SQLContextSingleton</span> {</span>

  <span class="hljs-annotation">@transient</span>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">var</span> instance: SQLContext = _

  <span class="hljs-keyword">def</span> getInstance(sparkContext: SparkContext): SQLContext = {
    <span class="hljs-keyword">if</span> (instance == <span class="hljs-keyword">null</span>) {
      instance = <span class="hljs-keyword">new</span> SQLContext(sparkContext)
    }
    instance
  }
}</code></pre>

<p>运行程序后，再运行下列命令</p>

<pre class="prettyprint"><code class=" hljs livecodeserver">root@sparkmaster:~<span class="hljs-comment"># nc -lk 9999</span>
Spark is <span class="hljs-operator">a</span> fast <span class="hljs-operator">and</span> general cluster computing <span class="hljs-keyword">system</span> <span class="hljs-keyword">for</span> Big Data
Spark is <span class="hljs-operator">a</span> fast <span class="hljs-operator">and</span> general cluster computing <span class="hljs-keyword">system</span> <span class="hljs-keyword">for</span> Big Data
Spark is <span class="hljs-operator">a</span> fast <span class="hljs-operator">and</span> general cluster computing <span class="hljs-keyword">system</span> <span class="hljs-keyword">for</span> Big Data
Spark is <span class="hljs-operator">a</span> fast <span class="hljs-operator">and</span> general cluster computing <span class="hljs-keyword">system</span> <span class="hljs-keyword">for</span> Big Data
Spark is <span class="hljs-operator">a</span> fast <span class="hljs-operator">and</span> general cluster computing <span class="hljs-keyword">system</span> <span class="hljs-keyword">for</span> Big Data
Spark is <span class="hljs-operator">a</span> fast <span class="hljs-operator">and</span> general cluster computing <span class="hljs-keyword">system</span> <span class="hljs-keyword">for</span> Big Data
Spark is <span class="hljs-operator">a</span> fast <span class="hljs-operator">and</span> general cluster computing <span class="hljs-keyword">system</span> <span class="hljs-keyword">for</span> Big Data
</code></pre>

<p>处理结果：</p>



<pre class="prettyprint"><code class=" hljs asciidoc">
<span class="hljs-header">========= 1448783840000 ms =========
+---------+-----+</span>
<span class="hljs-header">|     word|total|
+---------+-----+</span>
|    Spark|   12|
|   system|   12|
|  general|   12|
|     fast|   12|
|      and|   12|
|computing|   12|
|        a|   12|
|       is|   12|
|      for|   12|
|      Big|   12|
|  cluster|   12|
<span class="hljs-header">|     Data|   12|
+---------+-----+</span>

<span class="hljs-header">========= 1448783842000 ms =========
+----+-----+</span>
<span class="hljs-header">|word|total|
+----+-----+</span>
<span class="hljs-code">+----+</span>-----+

<span class="hljs-header">========= 1448783844000 ms =========
+----+-----+</span>
<span class="hljs-header">|word|total|
+----+-----+</span>
<span class="hljs-code">+----+</span>-----+
</code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>