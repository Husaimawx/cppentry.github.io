---
layout:     post
title:      一起学Spark (1) -- spark介绍与初始化
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/qq_32023541/article/details/79129076				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h5>                                               Spark介绍与初始化</h5><div>参考资料《Spark 大数据集群计算的生产实践》与《Spark快速大数据分析》</div><div><br></div><div>spark是大数据的下一代数据处理引擎。支持三种语言，Python，Java 以及它的原生语言Scala。我主要介绍的是python语言编写的spark，因为我工作中也主要是spark批处理数据，当然对于scala来说，对spark的支持也会更加灵活(比如流处理，这个以后有机会再写一个spark streaming系列)。然而我工作中接触最多的是python 大数据批运算。</div><div><br></div><div>我工作中的集群是 yarn集群，作为练习，可以就使用 Spark Standalone 集群。也就是Spark自带的单机集群，我代码示例都是基于yarn集群。</div><div><br></div><div>现在介绍一下 Spark 的基本组件：</div><div><br></div><div>1.Spark Core：</div><div>   Spark Core 实现了Spark 的基本功能，包含任务调度，内存管理，错误恢复等。Spark Core中还包含了对弹性分布式数据集（RDD）的API定义。</div><div><br></div><div>2.Spark SQL</div><div>  处理结构化数据的程序包，基本是对Hive的操作。但功能不如MapReduce稳定。</div><div>3.Spark Streaming </div><div>  处理流式数据，python不支持。</div><div>4.MLlib</div><div>  机器学习算法</div><div><br></div><div>介绍一下集群管理器：</div><div>我们知道对于单机，都有一个操作系统OS，集群管理器就是相当于一个集群的操作系统，管理一个集群的资源分配，任务调度等。Spark设计可以高效的在一个计算节点到数千个计算节点之间伸缩计算，为了实现这样的要求，Spark支持在各种集群管理器上运行，包括Hadoop YARN，Apache Mesos，以及spark自带的一个简易调度器。</div><div><br></div><div>理解集群资源：</div><div><br></div><div>1.磁盘存储</div><div>   对于任何的Spark应用而言，磁盘都是至关重要的，因为它存储了持久化的数据，中间计算的结果和系统状态。在单机中，是文件系统，在集群中，是分布式文件系统HDFS</div><div>2.CPU核</div><div>  计算上的CPU是真正执行计算的处理器，如今的CPU往往有多个CPU核，意味着他们可以并行执行多个进程。在一个集群中，有多台计算机，每个计算机有多个CPU核。在单机上，操作系统处理进程间的通信和资源共享，在分布式环境中，集群管理器为任务分配CPU资源。</div><div> 当构建Spark应用时，把CPU核的数量和程序的并行度联系起来，Spark是建立在弹性分布式数据集RDD上的，RDD是一种抽象，它把分布式数据看做是一个包含多个分区的单一实体。在Spark中，一个Spark任务(task)将在一个CPU核上处理一个RDD的一个分区。</div><div>3.内存</div><div>  内存对所有的Spark应用而言都是至关重要的，Spark中像shuffle 这样的内部机制要用到内存，而JVM堆空间则用于将持久化的RDD放到内存中，最小化磁盘I/O,从而获得极大的性能提升</div><div><br></div><h6>                                                      关于提交spark作业的应用参数</h6><p>spark-submit 是spark提供的一个程序接口，用于提交我们的spark作业。部分参数如下：</p><p>--master 集群URL，设定集群主节点</p><p>--executor-memory 每个执行器的内存用量，一些集群会限制为8G(我工作中用到的是 2G）</p><p>--deploy-mode 两种将运用连接到集群的模式 （客户端模式和集群模式）客户端模式：驱动器程序运行在提交的机器上。集群模式：驱动器程序运行在一个yarn容器内。</p><p>--num-executors JVM数</p><p>--executor-cores JVM核心数</p><p>--driver-memory driver内存用于存储累加器变量以及 collect()操作的输出，默认为 1G</p><p>启动Spark Schell 中的pyspark 固然可以作为python的一个API，但有时候是需要独立的调用Spark，这时，如果需要用到文件RDD编程，必须初始化SparkContext对象：</p><pre><code class="language-python">from pyspark import SparkConf,SparkContext
conf = SparkConf.setMaster("yarn-client").setAppName("MY_APP") #应用名可帮助在集群管理器界面找到应用
#或者写成 
conf.set("spark.master","yarn-client")
conf.set("spark.app.name","my_app")       
sc = SparkContext(conf = conf)</code></pre><p>优先级最高的是用户在代码中显式调用set方法设置的选项，其次是通过spark-submit 传递的参数，再次是写在配置文件中的值，最后才是系统默认值。</p><p><br></p><p>spark优缺点：<br>     spark的主要贡献在于，它提供了一个强大而且简单的API，能对分布式数据执行复杂的分布式操作。用户能够像为单机写代码一样简单的开发spark程序，但是实际上程序是在集群中运行的。<br>     Spark 并不是所有的任务都适用，它的长处是批处理，即以分布式的方式高效的处理大量数据，批处理的缺点是引入较高的延迟。即使是Spark Streaming 模式，也只能做到秒级。因此不适用于低延迟，高吞吐量的应用。</p><br><div><br></div><div><br></div><div><br></div><div><br></div>            </div>
                </div>