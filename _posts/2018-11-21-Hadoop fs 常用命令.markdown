---
layout:     post
title:      Hadoop fs 常用命令
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/Stars_Zhang/article/details/81702875				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>操作hdfs系统可以使用<code>hadoop fs</code> 也可以使用 <code>hdfs dfs</code> ,两者效果一样。</p>

<p>Hadoop启动：</p>

<pre class="prettyprint"><code class=" hljs sql"><span class="hljs-operator"><span class="hljs-keyword">start</span>-<span class="hljs-keyword">all</span>.sh 等价于 <span class="hljs-keyword">start</span>-dfs.sh + <span class="hljs-keyword">start</span>-yarn.sh
一般不推荐使用<span class="hljs-keyword">start</span>-<span class="hljs-keyword">all</span>.sh</span></code></pre>

<p>常用命令：</p>

<pre class="prettyprint"><code class=" hljs lasso">hadoop fs <span class="hljs-attribute">-ls</span> hdfs_path <span class="hljs-comment">//查看HDFS目录下的文件和子目录</span>

hadoop fs –lsr  <span class="hljs-comment">//循环列出目录、子目录及文件信息   </span>

hadoop fs <span class="hljs-attribute">-mkdir</span> hdfs_path <span class="hljs-comment">//在HDFS上创建文件夹</span>

hadoop fs <span class="hljs-attribute">-rm</span> hdfs_path <span class="hljs-comment">//删除HDFS上的文件</span>

hadoop fs <span class="hljs-attribute">-rmr</span> hdfs_path <span class="hljs-comment">//删除HDFS上的文件夹</span>

hadoop fs <span class="hljs-attribute">-put</span> local_file hdfs_path <span class="hljs-comment">//将本地文件copy到HDFS上</span>

hadoop fs <span class="hljs-attribute">-get</span> hdfs_file local_path <span class="hljs-comment">//复制HDFS文件到本地</span>

hadoop fs <span class="hljs-attribute">-cat</span> hdfs_file <span class="hljs-comment">//查看HDFS上某文件的内容</span></code></pre>

<pre class="prettyprint"><code class=" hljs lasso">hadoop fs <span class="hljs-attribute">-cat</span> hdfs_path <span class="hljs-comment">//将路径指定的文件内容输出到 stdout</span>

hadoop fs <span class="hljs-attribute">-tail</span> hdfs_path <span class="hljs-comment">//将文件尾部1k字节的内容输出到 stdout</span>

hadoop fs <span class="hljs-attribute">-stat</span> hdfs_path <span class="hljs-comment">//返回指定路径的统计信息</span>

hadoop fs <span class="hljs-attribute">-du</span> hdfs_path <span class="hljs-comment">//返回目录中所有文件的大小，或者只指定一个文件时，显示该文件的大小</span>

hadoop job –kill  <span class="hljs-preprocessor">[</span>job<span class="hljs-attribute">-id</span><span class="hljs-preprocessor">]</span><span class="hljs-markup"> //将正在运行的hadoop作业kill掉</span></code></pre>

<p>fs 查看目录下文件夹或者文件的大小：</p>

<pre class="prettyprint"><code class=" hljs mel"><span class="hljs-comment">//单位Byte：</span>
hadoop fs -du / | <span class="hljs-keyword">sort</span> -n
<span class="hljs-comment">//单位MB：</span>
hadoop fs -du / | awk -F ‘ ‘ ‘{printf “<span class="hljs-variable">%.</span><span class="hljs-number">2</span>fMB\t\t<span class="hljs-variable">%s</span>\n”, <span class="hljs-variable">$1</span>/<span class="hljs-number">1024</span>/<span class="hljs-number">1024</span>,<span class="hljs-variable">$2</span>}’ | <span class="hljs-keyword">sort</span> -n
<span class="hljs-comment">//单位GB，大于1G：</span>
hadoop fs -du / | awk -F ‘ ‘ ‘{num=<span class="hljs-variable">$1</span>/<span class="hljs-number">1024</span>/<span class="hljs-number">1024</span>/<span class="hljs-number">1024</span>; <span class="hljs-keyword">if</span>(num&gt;<span class="hljs-number">1</span>){printf “<span class="hljs-variable">%.</span><span class="hljs-number">2</span>fGB\t\t<span class="hljs-variable">%s</span>\n”, num, <span class="hljs-variable">$2</span>} }’ | <span class="hljs-keyword">sort</span> -n</code></pre>

<p><code>sort -n</code> 表示按照文件大小，从小到大排列顺序。</p>



<pre class="prettyprint"><code class=" hljs lasso">hadoop fs <span class="hljs-attribute">-du</span> <span class="hljs-attribute">-h</span> hdfs_path    
<span class="hljs-comment">// 使用 -h 显示 hdfs 对应路径下每个文件夹和文件的大小,文件的大小用方便阅读的形式表示，例如用64M代替67108864</span></code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>