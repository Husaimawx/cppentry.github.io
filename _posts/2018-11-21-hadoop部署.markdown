---
layout:     post
title:      hadoop部署
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>集群信息如下：</p>

<table><tbody><tr><td>
			<p>主机名</p>
			</td>
			<td>
			<p>Hadoop角色</p>
			</td>
			<td>
			<p>Hadoop jps命令结果</p>
			</td>
			<td>
			<p>Hadoop用户</p>
			</td>
			<td>
			<p>Hadoop安装目录</p>
			</td>
		</tr><tr><td>
			<p>master</p>
			</td>
			<td>
			<p>Master</p>

			<p>slaves</p>
			</td>
			<td>
			<p>NameNode</p>

			<p>DataNode</p>

			<p>JobTracker</p>

			<p>TaskTracker</p>

			<p>SecondaryNameNode</p>
			</td>
			<td colspan="1" rowspan="3">
			<p>创建相同的用户的组名：hadoop。</p>

			<p>安装hadoop-0.20.2时使用hadoop用户，并且hadoop的文件夹归属也是hadoop：hadoop</p>
			</td>
			<td colspan="1" rowspan="3">
			<p>/opt/hadoop</p>
			</td>
		</tr><tr><td>
			<p>slave1</p>
			</td>
			<td>
			<p>slaves</p>
			</td>
			<td>
			<p>DataNode</p>

			<p>TaskTracker</p>
			</td>
		</tr><tr><td>
			<p>slave2</p>
			</td>
			<td>
			<p>slaves</p>
			</td>
			<td>
			<p>DataNode</p>

			<p>TaskTracker</p>
			</td>
		</tr></tbody></table><p>　　注：master即使master又是slave.master即使master又是slave.<font style="vertical-align:inherit;"><font style="vertical-align:inherit;">。</font></font></p>

<p>步骤</p>

<p>1, 修改机器名，设置固定IP，创建hadopp用户组和用户</p>

<p>2, 修改地址解析文件/etc/hosts (host屏蔽172 只保留master 和节点的IP,可用命令设置禁止重起后修改hosts：chkconfig NetworkManager off ）</p>

<p>3, 安装JDK，hadoop ,设置/etc/bash_profile环境变量</p>

<p>4,修改hadoop配置文件（注意:缺少mapred-site.xml，可复制mapred-site.xml.templace重命名），配置hadoop-env.sh、yarn-env.sh的JAVA_HOME，否则启动时会报error</p>

<p>5,设置SSH无密码接入（注意master也需要配置,和配置600权限）</p>

<p>7, 用scp把master的hadoop目录复制到节点上, scp –r /opt/hadoop hadoop@slave1:/opt/hadoop (提示没有权限可在节点上先创建目录赋予hadoop用户权限, 注意节点和master的目录配置是完全一样的,无需修改IP)</p>

<p>6,主服务器master上执行bin/hdfs namenode -format进行初始化</p>

<p>7,master上启动hadoop .sbin目录下执行 ./start-all.sh 可以使用jps查看信息。停止的话，输入命令，sbin/stop-all.sh</p>

<p>8, <a href="" rel="nofollow">http://master_ip:50070</a>   <a href="" rel="nofollow">http://master_ip:8088</a> </p>

<p>9, 节点宕机可在master执行start-all.sh 启动，会忽略已启动的节点 </p>

<p>参考：</p>

<p><a href="http://www.07net01.com/2015/07/874408.html" rel="nofollow">http://www.07net01.com/2015/07/874408.html</a> </p>

<p><a href="http://www.cnblogs.com/liuling/archive/2013/06/16/2013-6-16-01.html" rel="nofollow">http://www.cnblogs.com/liuling/archive/2013/06/16/2013-6-16-01.html</a></p>

<p><a href="http://jingyan.baidu.com/article/f00622283a76c0fbd3f0c839.html" rel="nofollow">http://jingyan.baidu.com/article/f00622283a76c0fbd3f0c839.html</a></p>

<p><a href="http://blog.csdn.net/ab198604/article/details/8250461" rel="nofollow">http://blog.csdn.net/ab198604/article/details/8250461</a></p>

<p><a href="http://www.aboutyun.com/thread-7513-1-1.html" rel="nofollow">http://www.aboutyun.com/thread-7513-1-1.html</a></p>

<p></p>            </div>
                </div>