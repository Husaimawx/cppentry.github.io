---
layout:     post
title:      0000 0001  、HDFS 和 MapReduce
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/cheng1483/article/details/54287097				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>HDFS 和 MapReduce</p>



<pre class="prettyprint"><code class=" hljs ">HDFS 负责存储
MapReduce 负责任务的分解与结果的汇总</code></pre>

<hr>

<p><strong>HDFS 部分</strong></p>

<ul>
<li>HDFS 中的角色： <br>
<strong>名称结点</strong>：【NameNode】HDFS 中的管理者，负责文件系统的命名空间，集群配置信息，存储块信息的复制，保存每个块文件的 Metadata（文件信息保存在内存中） <br>
<strong>数据结点</strong>：【DataNode】HDFS 中的文件存储基本单元，存储每个块的metadata ,周期性的报告所存块的信息给 NameNode（心跳包） <br>
<strong>客户端</strong>：【】需要获取分布式文件系统的应用程序</li>
</ul>

<p><strong>HDFS 数据存储【 数据的读取 / 数据的写入 】</strong></p>

<ul>
<li>HDFS 文件读取过程: <br>
<img src="https://img-blog.csdn.net/20170109110550124?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2hlbmcxNDgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></li>
</ul>



<pre class="prettyprint"><code class=" hljs ">Client 向NameNode 发起文件读取的请求。
NameNode 返回文件存储的 DataNode 的信息【元数据 Metadata 】。
Client 读取文件信息</code></pre>

<p>HDFS 写入文件过程 <br>
<img src="https://img-blog.csdn.net/20170109110619500?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2hlbmcxNDgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>



<pre class="prettyprint"><code class=" hljs axapta"><span class="hljs-keyword">client</span> 向 NameNode 发起文件写入请求。
NameNode 根据文件大小和文件块配置情况，向<span class="hljs-keyword">client</span>返回它所管理的 DataNamed 的信息【元数据 Metadata 】
Client 将文件划分为多个Block ，根据DataName 的地址信息，按顺序写入DataNode中
DataNode直接进行流水线复制，完成收相NameNode 更新元数据</code></pre>

<p>关于分块的大小，可以通过设置 dfs.block.size的值进行分块，不设置，使用默认大小</p>

<hr>

<p><strong>MapReduce 模型部分</strong></p>

<p>Hadoop 通过自动分割将要执行的问题（程序）、拆解成Map(映射) 和 Reduce(化简) <br>
     在自动分割后通过Map 程序将数据映射成为不相关的区块，分配（调度）给大量的计算机进行处理以达到分散运算的效果，再通过Reduce程序将结果汇合整合，输出开发者需要的结果。</p>

<pre><code> 用户只需编写Map 和 Reduce 函数，这两个函数运行在 键-值对基础上的，
 数据切分，节点之间的通信调度都是由Hadoop框架本身负责。
</code></pre>

<p>MapReduce 软件实现： <br>
     指定一个map函数，把键值对（key/value）映射成新的键值对（key/value ），形成一系列中间结果形式的键值对（key/value）, <br>
     然后把他们传给Reduce(归约)函数，把具有相同中间形式key的value 合并在一起。 <br>
Map  和 Reduce 函数具有一定的关联性，其算法描述为：</p>



<pre class="prettyprint"><code class=" hljs coffeescript">Map<span class="hljs-function"><span class="hljs-params">(k,v)</span> -&gt;</span> list(k1,v1)
Reduce<span class="hljs-function"><span class="hljs-params">(k1,list(v1))</span> -&gt;</span>list(v1)</code></pre>

<p>在Map过程中将数据并行【把数据用映射函数规则分开】 <br>
在Reduce 把分开的数据用归约函数规则合在一起。 <br>
（Map 是一个分的过程，reduce 是一个合的过程）</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>