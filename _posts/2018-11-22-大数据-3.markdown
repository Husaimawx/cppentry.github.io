---
layout:     post
title:      大数据-3
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/qq_38262266/article/details/79154554				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>1、HDFS架构（<a href="http://blog.csdn.net/suifeng3051/article/details/48548341" rel="nofollow">Hadoop核心之HDFS架构设计</a>）</p>

<pre class="prettyprint"><code class=" hljs livecodeserver"><span class="hljs-operator">a</span>、hdfs定义

hdfs是被设计成适合运行在通用硬件上、具有高容错性、提供高吞吐量数据访问、以流的形式访问数据、的分布式文件系统。</code></pre>

<p>b、Namenode、SecondaryName、Datanode</p>



<pre class="prettyprint"><code class=" hljs ">HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master/slave模式运行的，其中NameNode、SecondaryNameNode 运行在master节点，DataNode运行slave节点。</code></pre>



<pre class="prettyprint"><code class=" hljs ">NameNode管理着文件系统命名空间，它维护这文件系统树及树中的所有文件和目录。NameNode也负责维护所有这些文件或目录的打开、关闭、移动、重命名等操作。对于实际文件数据的保存与操作，都是由DataNode负责。当一个客户端请求数据时，它仅仅是从NameNode中获取文件的元信息，而具体的数据传输不需要经过NameNode，是由客户端直接与相应的DataNode进行交互。

NameNode保存元信息的种类有：
文件名目录名及它们之间的层级关系
文件目录的所有者及其权限
每个文件块的名及文件有哪些块组成</code></pre>



<pre class="prettyprint"><code class=" hljs ">DataNode是hdfs中的worker节点，它负责存储数据块，也负责为系统客户端提供数据块的读写服务，同时还会根据NameNode的指示来进行创建、删除、和复制等操作。此外，它还会通过心跳定期向NameNode发送所存储文件块列表信息。当对hdfs文件系统进行读写时，NameNode告知客户端每个数据驻留在哪个DataNode，客户端直接与DataNode进行通信，DataNode还会与其它DataNode通信，复制这些块以实现冗余。</code></pre>



<pre class="prettyprint"><code class=" hljs ">SecondaryNameNode并不是NameNode的备份。所有HDFS文件的元信息都保存在NameNode的内存中。在NameNode启动时，它首先会加载fsimage到内存中，在系统运行期间，所有对NameNode的操作也都保存在了内存中，同时为了防止数据丢失，这些操作又会不断被持久化到本地edits文件中。

总结一下整个过程中涉及到NameNode中的相关文件
fsimage ：保存的是上个检查点的HDFS的元信息
edits ：保存的是从上个检查点开始发生的HDFS元信息状态改变信息
fstime：保存了最后一个检查点的时间戳
</code></pre>

<p>2、元数据块（<a href="http://blog.csdn.net/xiaming564/article/details/23165253" rel="nofollow">HDFS元数据解析</a>）</p>

<pre class="prettyprint"><code class=" hljs lasso">Namenode维护元数据（所谓元数据是指描述文件的数据，如文件名，文件大小，文件创建时间等）
DataNode存放实际数据（即文件内容本身）


元数据有三类重要信息：
第一类是文件和目录自身的属性信息，例如文件名、目录名、父目录信息、文件大小、创建时间、修改时间等。
第二类记录文件内容存储相关信息，例如文件块情况、副本个数、每个副本所在的<span class="hljs-built_in">Data</span> Node 信息等。
第三类用来记录HDFS中所有<span class="hljs-built_in">Data</span> Node信息，用于<span class="hljs-built_in">Data</span> Node管理。</code></pre>

<p>3、HDFS数据块（<a href="http://blog.csdn.net/baidu_35570545/article/details/73557973" rel="nofollow">为什么HDFS中的块如此之大？</a>）</p>

<pre class="prettyprint"><code class=" hljs avrasm">HDFS也是采用块管理的，但是比较大，在Hadoop1<span class="hljs-preprocessor">.x</span>中默认大小是<span class="hljs-number">64</span>M，Hadoop2<span class="hljs-preprocessor">.x</span>中大小默认为<span class="hljs-number">128</span>M

与单一磁盘上的文件系统相似，HDFS上的文件也被划分为块大小的多个分块（chunk），作为独立存储单元。但与其它文件系统不同的是，HDFS中小于一个块大小的文件不会占据整个块的空间。

HDFS的块比磁盘块大，其目的是为了最小化寻址开销。如果块设置得足够大，从磁盘传输数据的时间可以明显大于定位这个块开始位置所需的时间。这样，传输一个由多个块组成的文件的时间取决于磁盘传输速率。 
</code></pre>

<p>4、HDFS读取策略（Hadoop核心之HDFS 架构设计）</p>



<pre class="prettyprint"><code class=" hljs markdown">HDFS文件读取过程
hdfs有一个FileSystem实例，客户端通过调用这个实例的open()方法就可以打开系统中希望读取的文件。hdfs通过rpc调用NameNode获取文件块的位置信息，对于文件的每一个块，NameNode会返回含有该块副本的DataNode的节点地址，另外，客户端还会根据网络拓扑来确定它与每一个DataNode的位置信息，从离它最近的那个DataNode获取数据块的副本，最理想的情况是数据块就存储在客户端所在的节点上。

hdfs会返回一个FSDataInputStream对象，FSDataInputStream类转而封装成DFSDataInputStream对象,这个对象管理着与DataNode和NameNode的I/O，具体过程是：

<span class="hljs-bullet">1. </span>客户端发起读请求
<span class="hljs-bullet">2. </span>客户端与NameNode得到文件的块及位置信息列表
<span class="hljs-bullet">3. </span>客户端直接和DataNode交互读取数据
<span class="hljs-bullet">4. </span>读取完成关闭连接
当FSDataInputStream与DataNode通信时遇到错误，它会选取另一个较近的DataNode，并为出故障的DataNode做标记以免重复向其读取数据。FSDataInputStream还会对读取的数据块进行校验和确认，发现块损坏时也会重新读取并通知NameNode。

这样设计的巧妙之处：

让客户端直接联系DataNode检索数据，可以使hdfs扩展到大量的并发客户端，因为数据流就是分散在集群的每个节点上的，在运行MapReduce任务时，每个客户端就是一个DataNode节点。
NameNode仅需相应块的位置信息请求（位置信息在内存中，速度极快），否则随着客户端的增加，NameNode会很快成为瓶颈。
</code></pre>

<p>HDFS文件写入过程</p>



<pre class="prettyprint"><code class=" hljs markdown">hdfs有一个DistributedFileSystem实例，客户端通过调用这个实例的create()方法就可以创建文件。DistributedFileSystem会发送给NameNode一个RPC调用，在文件系统的命名空间创建一个新文件，在创建文件前NameNode会做一些检查，如文件是否存在，客户端是否有创建权限等，若检查通过，NameNode会为创建文件写一条记录到本地磁盘的EditLog，若不通过会向客户端抛出IOException。创建成功之后DistributedFileSystem会返回一个FSDataOutputStream对象，客户端由此开始写入数据。

同读文件过程一样，FSDataOutputStream类转而封装成DFSDataOutputStream对象,这个对象管理着与DataNode和NameNode的I/O，具体过程是：

<span class="hljs-bullet">1. </span>客户端在向NameNode请求之前先写入文件数据到本地文件系统的一个临时文件
<span class="hljs-bullet">2. </span>待临时文件达到块大小时开始向NameNode请求DataNode信息
<span class="hljs-bullet">3. </span>NameNode在文件系统中创建文件并返回给客户端一个数据块及其对应DataNode的地址列表（列表中包含副本存放的地址）
<span class="hljs-bullet">4. </span>客户端通过上一步得到的信息把创建临时文件块flush到列表中的第一个DataNode
<span class="hljs-bullet">5. </span>当文件关闭，NameNode会提交这次文件创建，此时，文件在文件系统中可见
上面第四步描述的flush过程实际处理过程比较负杂，现在单独描述一下：

<span class="hljs-bullet">1. </span>首先，第一个DataNode是以数据包(数据包一般4KB)的形式从客户端接收数据的，DataNode在把数据包写入到本地磁盘的同时会向第二个DataNode（作为副本节点）传送数据。
<span class="hljs-bullet">2. </span>在第二个DataNode把接收到的数据包写入本地磁盘时会向第三个DataNode发送数据包
<span class="hljs-bullet">3. </span>第三个DataNode开始向本地磁盘写入数据包。此时，数据包以流水线的形式被写入和备份到所有DataNode节点
<span class="hljs-bullet">4. </span>传送管道中的每个DataNode节点在收到数据后都会向前面那个DataNode发送一个ACK,最终，第一个DataNode会向客户端发回一个ACK
<span class="hljs-bullet">5. </span>当客户端收到数据块的确认之后，数据块被认为已经持久化到所有节点。然后，客户端会向NameNode发送一个确认
<span class="hljs-bullet">6. </span>如果管道中的任何一个DataNode失败，管道会被关闭。数据将会继续写到剩余的DataNode中。同时NameNode会被告知待备份状态，NameNode会继续备份数据到新的可用的节点
<span class="hljs-bullet">7. </span>数据块都会通过计算校验和来检测数据的完整性，校验和以隐藏文件的形式被单独存放在hdfs中，供读取时进行完整性校验</code></pre>

<p>hdfs文件删除过程</p>

<pre class="prettyprint"><code class=" hljs markdown">hdfs文件删除过程一般需要如下几步：

<span class="hljs-bullet">1. </span>一开始删除文件，NameNode只是重命名被删除的文件到/trash目录，因为重命名操作只是元信息的变动，所以整个过程非常快。在/trash中文件会被保留一定间隔的时间（可配置，默认是6小时），在这期间，文件可以很容易的恢复，恢复只需要将文件从/trash移出即可。
<span class="hljs-bullet">2. </span>当指定的时间到达，NameNode将会把文件从命名空间中删除
<span class="hljs-bullet">3. </span>标记删除的文件块释放空间，HDFS文件系统显示空间增加
</code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>