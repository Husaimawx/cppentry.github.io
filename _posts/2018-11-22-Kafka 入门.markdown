---
layout:     post
title:      Kafka 入门
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>Kafka    A distributed streaming platform.</p><p>     使用心得：很多大数据的框架都会使用到kafka，核心是在业务高峰的时候起到了缓冲的作用，避免计算压力过大；其次kafka能做到分布式的、高效的消息系统。</p><p><br></p><p><strong>1）Kafka 两种案例说明</strong></p><p></p><p>    Kafka is generally used for two broad classes of applications:<span style="white-space:pre;">	</span></p><p>        -- Building real-time streaming data pipelines that reliably get data between systems or applications</p><p>            实时的流式数据管理，应用于系统与应用之间通信（重点）<br></p><p>        -- Building real-time streaming applications that transform or react to the streams of data </p><p>            构建实时的数据应用去转化数据。（用的场景并不多，应倾向于打造Spark为主的框架）</p><p><span style="background-color:rgb(255,255,255);"><span style="color:#ff0000;">    总结：应用场景：作为消息中间件，一般部署在流式组件前一个，主要为了避免高峰期计算来的压力</span></span></p><p><span style="background-color:rgb(255,255,102);">    Q：Maxwell---------------------------------&gt;存储平台</span></p><p><span style="background-color:rgb(255,255,102);">          Maxwell--&gt;Kafka--&gt;Spark streaming--&gt;存储平台  的转变？</span></p><p><span style="background-color:rgb(255,255,102);">    A：因为Maxwell是单点的，所以其实也是为了缓冲压力</span></p><p><span style="background-color:rgb(255,255,102);"><br></span></p><p><strong>2）Zookeeper 介绍</strong></p><p>    Zookeeper: http://zookeeper.apache.org/ </p><p>    总结：就是分布式的协调服务，一般用于做HA；建议使用3.4.6 / 3.4.10稳定版本（有apache和CDH版本）</p><p><br></p><p><strong>3）Zookeeper 部署</strong><br></p><p>    下载：wget    http://mirror.bit.edu.cn/apache/zookeeper/stable/zookeeper-3.4.10.tar.gz<br></p><p>    解压：tar -zxvf zookeeper-3.4.10.tar.gz<br></p><p>    授权：chown -R root:root zookeeper-3.4.10<br></p><p>    软连接：ln -s zookeeper-3.4.10 zookeeper</p><p><br></p><p><strong>4）Zookeeper 配置</strong><br></p><p>    cp zoo_simple.cfg zoo.cfg<br></p><p>    --dataDir=/opt/software/zookeeper/data    该目录用于存储快照</p><p>    --server.1=hadoop000:2888:3888<br></p><p>    --server.2=hadoop001:2888:3888<br></p><p>    --server.3=hadoop002:2888:3888     <br></p><p>    touch data/myid<br></p><p>    echo 1 &gt; data/myid    把配置的id写入对应机器的myid文件<br></p><p>    配置环境变量<br></p><p><br></p><p><strong>5）Zookeeper 启动</strong><br></p><p>    ./zkServer.sh start<br></p><p>    ./zkServer.sh status    查看状态</p><p><br></p><p><strong>6）Zookeeper 场景</strong></p><p>    无论是Apache 还是CDH，比如HDFS HA、YARN HA损坏，Kafka、HBase 都在ZK</p><p></p><p>        a. zkCli.sh 进入当前机器的localhost模式去连接</p><p>        b. 假如localhost模式进不去，可使用ZooKeeper -server host:port </p><p>        c. 命令帮助 进人console，输入help</p>           常用命令：ls /<br>                           ls /zookeeper<br><p>                           rmr path</p><p><br></p><p><strong>7）配置java、scala环境</strong></p><p>    jdk：  路径:  /usr/java/     因为CDH优先读取这个</p><p></p><p>    jdbc：路径:  /usr/share/java  </p><p>    Scala: 2.11.8 </p><p><br></p><p><strong>8）Kafka 部署</strong></p><p>    Kafka: 0.8 与 0.10 的对比   https://spark.apache.org/docs/2.2.0/streaming-kafka-integration.html</p><p>    解压：tar -zxvf kafa_2.11-0.10.0.1.tgz</p><p>    软连接：ln -s kafa_2.11-0.10.0.1 kafa<br></p><p><br></p><p><strong>9）Kafka 配置</strong></p><p>    vi server.properties<br></p><p>    --broker.id=1    设置唯一ID<br></p><p>    --port=9092</p><p>    --host.name=192.168.96.1     </p><p>    --log.dirs=/opt/software/kafka/logs<br></p><p>    --zookeeper.connect=hadoop000:2181,hadoop001:2181,hadoop002:2181</p><p>      注意：zookeeper.connect=192.168.137.141:2181,192.168.137.142:2181,192.168.137.143:2181/kafka </p><p>               就是创建kafka这个文件夹，不然子文件夹会打散出来</p><p>    mkdir /opt/software/kafka/logs<br></p><p>    配置环境变量</p><p><br></p><p><strong>10）Kafka 启动  </strong></p><p>    nohup kafka-server-start.sh config/server.properties &amp;    以后台模式执行</p><p>    nohup:ignoring input and appending output to 'nohup.out'</p><p><br></p><p><strong>11）Kafka 理解</strong></p><p>        Kafka部署完成的进程，broker<br></p><p>        producer（Flume）---》broker cluster（Kafka） --》 consumer（Spark Streaming）</p><p>        导航日志 --》Kafka（Topic:DH） --》 计算程序 </p><p>        企业预警日志--》Kafka （Topic:AlertLog）<br></p><p><span style="background-color:rgb(255,255,102);">        Q：什么是topic？</span></p><p><span style="background-color:rgb(255,255,102);">        A：能理解为一个文件夹，把指定到该topic的数据写到这个文件夹。根据不同的业务来分组，创建多个topic</span></p><p><span style="background-color:rgb(255,255,102);"><br></span></p><p><strong>12）Kafka 测试案例</strong></p><p>    create：{</p><p>        bin/kafka-topics.sh --create \</p><p>            --zookeeper 192.168.137.141:2181,192.168.137.142:2181,192.168.137.143:2181 \</p><p>            --replication-factor 3 --partitions 3 --topic test</p><p>    }<br></p><p></p><p>    producer：{</p><p>        bin/kafka-producer.sh \</p><p>            --broker-list 192.168.137.141:9092,192.168.137.142:9092,192.168.137.143:9092 --topic test</p><p>    }</p><p>   consumer：{</p><p>         bin/kafka-console-consumer.sh \</p><p>            --zookeeper 192.168.137.141:2181,192.168.137.142:2181,192.168.137.143:2181 \</p><p>            --from-beginning --topic test</p><p>    }</p><p><br></p><p><strong>13）拓展</strong></p><p>    kill -9 $(grep -f zookeeper)    批量杀程序<br></p>    zookeeper部署台数公式：生产上少于100台机器，部署7台；大于100台，部署9-11台<br><br><br>            </div>
                </div>