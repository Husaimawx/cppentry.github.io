---
layout:     post
title:      Spark安装
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p><span style="font-family:'Microsoft YaHei';font-size:16px;">之前一直用的<span style="color:rgb(51,51,51);text-indent:28px;background-color:rgb(255,255,255);"><strong>hadoop，</strong></span>最近用到Spark觉得很惊艳。<span style="color:rgb(51,51,51);background-color:rgb(255,255,255);">Spark 是一种与 </span><a href="https://baike.baidu.com/item/Hadoop" rel="nofollow" style="color:rgb(19,110,194);text-indent:28px;background-color:rgb(255,255,255);">Hadoop</a><span style="color:rgb(51,51,51);text-indent:28px;background-color:rgb(255,255,255);"> 相似的开源集群计算环境，但是Spark 启用了内存分布数据集，除了能够提供交互式查询外，它还可以优化迭代工作负载。</span></span></p><p><span style="font-family:'Microsoft YaHei';font-size:16px;"><span style="color:rgb(51,51,51);text-indent:28px;background-color:rgb(255,255,255);">正如下图所示<span style="color:rgb(69,69,69);text-indent:28px;background-color:rgb(255,255,255);"><strong>spark和<span style="color:rgb(69,69,69);text-indent:28px;background-color:rgb(255,255,255);"><strong>Hadoop的关系</strong></span></strong></span><span style="font-weight:700;">，</span></span><span style="background-color:rgb(255,255,255);color:rgb(69,69,69);font-weight:700;text-indent:28px;">spark的分析大多依赖于Hadoop的分布式文件系统HDFS</span><span style="background-color:rgb(255,255,255);font-weight:700;text-indent:28px;"><span style="color:#333333;">，</span></span><span style="background-color:rgb(255,255,255);color:rgb(69,69,69);font-weight:700;">Hadoop的Mapreduce与spark都可以进行数据计算，而相比于Mapreduce，spark的速度更快并且提供的功能更加丰富。</span></span></p><p><span style="color:rgb(51,51,51);text-indent:28px;background-color:rgb(255,255,255);"><span style="font-family:'Microsoft YaHei';font-size:16px;"><img src="https://img-blog.csdn.net/20180209173817703?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYWxpY2Vfd29uZGVybGFuZF8yMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></span></span></p><p><span style="color:rgb(51,51,51);text-indent:28px;"><span style="color:rgb(51,51,51);text-align:left;"><span style="color:rgb(51,51,51);text-align:left;"><span style="background-color:rgb(255,255,255);"><span style="font-family:'Microsoft YaHei';font-size:16px;"><span style="color:rgb(69,69,69);background-color:rgb(255,255,255);"><strong>下面就开始安装</strong></span><span style="background-color:rgb(255,255,255);color:rgb(51,51,51);"><strong>Spark。</strong></span>spark的安装比较简单，只需要<strong>Java JDK、hadoop</strong>的支持。</span></span></span></span></span></p><p><span style="color:rgb(51,51,51);text-indent:28px;"><span style="color:rgb(51,51,51);text-align:left;"><span style="color:rgb(51,51,51);text-align:left;"><span style="font-family:'Microsoft YaHei';font-size:16px;"><span style="background-color:rgb(255,255,255);color:rgb(51,51,51);text-indent:28px;">我是安装在linux系统下，已装有</span><span style="color:rgb(51,51,51);"><span style="background-color:rgb(254,254,254);">Hadoop 2.7.3，</span><span style="text-align:left;"><span style="background-color:rgb(254,254,254);">Java JDK 1.7。</span></span></span></span></span></span></span></p><h2><span style="color:rgb(51,51,51);text-indent:28px;"><span style="color:rgb(51,51,51);text-align:left;"><span style="color:rgb(51,51,51);text-align:left;"><span style="color:rgb(51,51,51);"><span style="text-align:left;"><span style="background-color:rgb(254,254,254);"><span style="font-family:'Microsoft YaHei';"><span style="font-size:18px;">1.从官网下载</span></span></span></span></span></span></span></span></h2><p><span style="color:rgb(51,51,51);text-indent:28px;"><span style="color:rgb(51,51,51);text-align:left;"><span style="color:rgb(51,51,51);text-align:left;"><span style="color:rgb(51,51,51);"><span style="text-align:left;"><span style="background-color:rgb(254,254,254);"><span style="font-family:'Microsoft YaHei';font-size:16px;"><img src="https://img-blog.csdn.net/20180209175702238?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYWxpY2Vfd29uZGVybGFuZF8yMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></span></span></span></span></span></span></span></p><p><span style="color:rgb(51,51,51);text-indent:28px;"><span style="color:rgb(51,51,51);text-align:left;"><span style="color:rgb(51,51,51);text-align:left;"><span style="color:rgb(51,51,51);"><span style="text-align:left;"><span style="background-color:rgb(254,254,254);"><span style="font-family:'Microsoft YaHei';font-size:16px;">首先到<a href="https://spark.apache.org" rel="nofollow">官网</a>下载<span style="color:rgb(0,0,0);letter-spacing:.16px;background-color:rgb(255,255,255);">一份打包好的spark，如果不使用HDFS，可以随便下载一个适配任何Hadoop的版本的Spark。</span></span></span></span></span></span></span></span></p><p><span style="color:rgb(51,51,51);text-indent:28px;"><span style="color:rgb(51,51,51);text-align:left;"><span style="color:rgb(51,51,51);text-align:left;"><span style="color:rgb(51,51,51);"><span style="text-align:left;"><span style="background-color:rgb(254,254,254);"><span style="font-family:'Microsoft YaHei';font-size:16px;"><span style="color:rgb(0,0,0);letter-spacing:.16px;background-color:rgb(255,255,255);"><br></span></span></span></span></span></span></span></span></p><h2><span style="color:rgb(51,51,51);text-indent:28px;"><span style="color:rgb(51,51,51);text-align:left;"><span style="color:rgb(51,51,51);text-align:left;"><span style="color:rgb(51,51,51);"><span style="text-align:left;"><span style="background-color:rgb(254,254,254);"><span style="color:rgb(0,0,0);letter-spacing:.16px;background-color:rgb(255,255,255);"><span style="font-family:'Microsoft YaHei';"><span style="font-size:18px;">2.下载完毕之后使用xftp直接复制到/home/hadoop目录下并解压</span></span></span></span></span></span></span></span></span></h2><pre><code class="language-python">sudo tar -zxf ~/spark-2.2.1-bin-hadoop2.7.tgz</code></pre><span style="font-family:'Microsoft YaHei';font-size:16px;">这一步见仁见智，安装xftp后上载下载都很直观</span><p></p><h2><span style="font-size:18px;"><span style="font-family:'Microsoft YaHei';">3.解压完成后即可</span></span></h2><h2><span style="font-size:18px;"><span style="font-family:'Microsoft YaHei';"><br></span><span style="color:rgb(51,51,51);text-indent:28px;background-color:rgb(255,255,255);"><span style="color:rgb(51,51,51);text-align:left;background-color:rgb(254,254,254);"><span style="color:rgb(51,51,51);text-align:left;background-color:rgb(254,254,254);"><span style="background-color:rgb(255,255,255);"><span style="color:rgb(51,51,51);background-color:rgb(254,254,254);"><span style="text-align:left;"><span style="font-family:'Microsoft YaHei';">4.试试<span style="color:rgb(69,69,69);text-align:left;background-color:rgb(255,255,255);"><span style="color:rgb(69,69,69);text-align:left;background-color:rgb(255,255,255);">在命令行输入：spark-shell</span></span></span></span></span></span></span></span></span></span></h2><p><span style="color:rgb(51,51,51);text-indent:28px;background-color:rgb(255,255,255);"><span style="color:rgb(51,51,51);text-align:left;background-color:rgb(254,254,254);"><span style="color:rgb(51,51,51);text-align:left;background-color:rgb(254,254,254);"><span style="background-color:rgb(255,255,255);"><span style="color:rgb(51,51,51);background-color:rgb(254,254,254);"><span style="text-align:left;"><span style="color:rgb(69,69,69);text-align:left;background-color:rgb(255,255,255);"><span style="color:rgb(69,69,69);text-align:left;background-color:rgb(255,255,255);"><span style="font-family:'Microsoft YaHei';font-size:16px;"><img src="https://img-blog.csdn.net/20180307163746629?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYWxpY2Vfd29uZGVybGFuZF8yMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></span></span></span></span></span></span></span></span></span></p><p><span style="color:rgb(51,51,51);text-indent:28px;background-color:rgb(255,255,255);"><span style="color:rgb(51,51,51);text-align:left;background-color:rgb(254,254,254);"><span style="color:rgb(51,51,51);text-align:left;background-color:rgb(254,254,254);"><span style="background-color:rgb(255,255,255);"><span style="color:rgb(51,51,51);background-color:rgb(254,254,254);"><span style="text-align:left;"><span style="font-family:'Microsoft YaHei';font-size:16px;">出现这样就恭喜你安装成功啦(●'◡'●)</span></span></span></span></span></span></span></p><p><span style="color:rgb(51,51,51);text-indent:28px;background-color:rgb(255,255,255);"><span style="color:rgb(51,51,51);text-align:left;background-color:rgb(254,254,254);"><span style="color:rgb(51,51,51);text-align:left;background-color:rgb(254,254,254);"><span style="background-color:rgb(255,255,255);"><span style="color:rgb(51,51,51);background-color:rgb(254,254,254);"><span style="text-align:left;"><span style="font-family:'Microsoft YaHei';font-size:16px;"><br></span></span></span></span></span></span></span></p><p><span style="color:rgb(51,51,51);text-indent:28px;background-color:rgb(255,255,255);"><span style="color:rgb(51,51,51);text-align:left;background-color:rgb(254,254,254);"><span style="color:rgb(51,51,51);text-align:left;background-color:rgb(254,254,254);"><span style="background-color:rgb(255,255,255);"><span style="color:rgb(51,51,51);background-color:rgb(254,254,254);"><span style="text-align:left;"><span style="font-family:'Microsoft YaHei';font-size:16px;"><br></span></span></span></span></span></span></span></p><p><span style="font-family:'Microsoft YaHei';font-size:16px;">sparksql和任务划分在学习中，之后要是有总结再整理吧~~</span></p><p><br></p>            </div>
                </div>