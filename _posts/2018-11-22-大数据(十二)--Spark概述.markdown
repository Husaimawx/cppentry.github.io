---
layout:     post
title:      大数据(十二)--Spark概述
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文版权归宋坤所有，转载请注明出处					https://blog.csdn.net/skisqibao/article/details/84130389				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-light">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p></p><div class="toc"><h3>Spark概述</h3><ul><li><a href="#Spark__2" rel="nofollow">Spark 简介</a></li><li><a href="#Spark__22" rel="nofollow">Spark 历史</a></li><li><a href="#Spark__30" rel="nofollow">Spark 技术栈</a></li><li><a href="#SparkHadoop_69" rel="nofollow">Spark相较于Hadoop的优点</a></li></ul></div><p></p>
<h1><a id="Spark__2"></a>Spark 简介</h1>
<p>  Spark官网为: <a href="http://spark.apache.org/" rel="nofollow">http://spark.apache.org/</a>, Spark也是用于海量数据处理的计算框架. 官方对Spark的定义是:</p>
<blockquote>
<p>Apache Spark™ is a unified analytics engine for large-scale data processing.<br>
翻译过来是: Spark是用于大规模数据处理的统一分析引擎。</p>
</blockquote>
<p>  Spark最初由美国加州伯克利大学（UCBerkeley）的AMP（Algorithms, Machines and People）实验室于2009年开发. Spark是基于内存计算的大数据并行计算框架, 可用于构建大型的、低延迟的数据分析应用程序. 2013年, Spark加入Apache孵化器项目后, 开始迅猛发展, 如今已成为Apache软件基金会最重要的三大分布式计算系统开源项目之一.</p>
<p>  Spark作为大数据计算平台的后起之秀, 在2014年打破了Hadoop保持的基准排序 (Sort Benchmark) 纪录, 使用206个节点在23分钟的时间里完成了100TB数据的排序; 而Hadoop则是使用2000个节点在72分钟的时间里完成同样数据的排序. 也就是说, Spark仅使用了Hadoop十分之一的计算资源, 获得了比Hadoop快3倍的速度. 新纪录的诞生, 使得Spark获得多方追捧, 也表明了Spark可以作为一个更加快速、高效的大数据计算平台.</p>
<p>  Spark具有如下几个主要特点:</p>
<ol>
<li>运行速度快, 高效: Spark使用先进的DAG(Directed Acyclic Graph, 有向无环图)执行引擎, 以支持循环数据流与内存计算, 减少了迭代过程中的数据落地. 基于内存的执行速度可比MapReduce快上百倍, 基于磁盘的执行速度能快十倍;</li>
<li>容易使用: Spark支持使用Scala、Java、Python和R语言进行编程, 简洁的API设计有助于用户轻松构建并行程序, 并且可以通过Spark Shell进行交互式编程;</li>
<li>通用性: Spark提供了完整而强大的技术栈, 包括SQL查询、流式计算、机器学习和图算法组件, 这些组件可以无缝整合在同一个应用中, 足以应对复杂的计算;</li>
<li>运行模式多样: Spark有4中运行模式, 分别是Local(多用于测试环境), Standalone(Spark自带资源调度器), Yarn(生产环境使用最多), Mesos. 其中Standalone, Yarn和Mesos都是资源调度器.</li>
</ol>
<p>  Spark源码托管在Github中，截至2018年11月，共有超过1300名来自不同公司的开发人员贡献了23000多次代码提交，可见Spark的受欢迎程度是非常高的。<a href="https://github.com/apache/spark" rel="nofollow">Spark源码仓库</a></p>
<h1><a id="Spark__22"></a>Spark 历史</h1>
<p>  Spark相比于Hadoop, 其发展更加迅速. Hadoop 已经有12年的历史而Spark只有6年(2012开始), 但Spark在应用上逐渐取代Hadoop.</p>
<p><img src="https://img-blog.csdnimg.cn/20181118165519681.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NraXNxaWJhbw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>
  截至到目前为止, Spark已经更新到2.4.0版本. 目前常用的稳定版本是1.6.3, 初步学习也是建议使用这个版本.</p>
<h1><a id="Spark__30"></a>Spark 技术栈</h1>
<p>  Spark诞生于AMP实验室, APM实验室在做数据分析时使用到的技术基本就是我们将要学习的技术. 接下来看看都有哪些技术:<br>
<img src="https://img-blog.csdnimg.cn/20181118155016359.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NraXNxaWJhbw==,size_16,color_FFFFFF,t_70" alt="技术栈"></p>
<p>  从下往上来看:</p>
<ul>
<li>Mesos(了解): 对Spark集群资源进行管理的工具, 其功能于Hadoop集群中Yarn的作用相似, 但国内用的较少, 基本上还是使用Yarn来进行集群资源管理.</li>
<li>HDFS: Hadoop生态圈中用来存储的分布式文件系统, HDFS是基于磁盘来进行存储的. 在之前的博客中已经做过详细介绍, 可查看: <a href="https://blog.csdn.net/skisqibao/article/details/82990636" rel="nofollow"><em>分布式文件系统</em></a> 一文.</li>
<li>Tachyon(了解): 基于内存的分布式存储系统.</li>
<li>HadoopMR: Hadoop生态圈中用来进行批量处理的计算框架. 可查看: <a href="https://blog.csdn.net/skisqibao/article/details/83097826" rel="nofollow"><em>分布式计算框架MapReduce</em></a> 一文.</li>
<li>Hive: 构建数据仓库的工具, Hive是基于HDFS和MR的, 它支持编写SQL语句同时支持创建多种类型的表.</li>
<li>Strom: 流式计算框架, 由于SparkStreaming的出现, Strom逐渐被SparkStreaming代替.</li>
<li>MPI(了解): 基于消息传递的分布式计算框架.</li>
<li>Spark Core: Spark的核心部分, 这是学习下面技术的基础, 我们会在之后进行重点讲解.</li>
<li>SparkStreaming: 流式计算框架, 能轻松构建可扩展的容错流应用程序.</li>
<li>SparkMlib(MLbase): Spark提供的可扩展机器学习库, 里面封装了大量用于机器学习的方法.</li>
<li>SparkSQL(Shark): 是Spark用于处理结构化数据的模块, SparkSQL除了支持编写SQL语句之外, 还可以操作Hive中的数据源.</li>
<li>GraphX: Spark用于图形和图形并行计算的API。</li>
<li>BlinkDB: 可指定容错率的数据库, 即在使用SQL语句查询时, 查询结果可以有一部分是错误的, 这部分数据量的比重可以指定.</li>
</ul>
<p>  了解技术栈之后, 就可以明白下面这句话了.</p>
<blockquote>
<p>One stack rule them all.<br>
  即一栈式解决所有大数据的处理场景.</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/20181118161810971.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NraXNxaWJhbw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>  常见大数据处理场景以及对应解决的技术:</p>

<table>
<thead>
<tr>
<th align="center">场景</th>
<th align="center">Spark出现之前的技术</th>
<th align="center">Spark中的技术</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">批处理</td>
<td align="center">MapReduce</td>
<td align="center">SparkCore</td>
</tr>
<tr>
<td align="center">流式处理</td>
<td align="center">Strom</td>
<td align="center">SparkStreaming</td>
</tr>
<tr>
<td align="center">交互式处理</td>
<td align="center">Hive</td>
<td align="center">SparkSQL</td>
</tr>
<tr>
<td align="center">机器学习</td>
<td align="center">Mahout</td>
<td align="center">SparkMLib</td>
</tr>
</tbody>
</table><p>  Spark之前的每个技术都需要搭建一套服务, MR需要搭建高可用的Hadoop集群, Strom也要搭建, Hive也需要安装工具, 然后再整合Mahout.<br>
  像这样集群搭建过多,容易带来许多问题: 1. 资源抢占; 2. 搭建成本高; 3.维护成本高.</p>
<p>  如果选择Spark, 则只需要搭建一套Spark集群即可. SparkStreaming, SparkSQL与SparkCore之间的关系就类似于Struts2, SpringMVC和Servlet的关系. SparkCore和Servlet两者都是基础, 是核心部分.</p>
<h1><a id="SparkHadoop_69"></a>Spark相较于Hadoop的优点</h1>
<p>  Hadoop虽引领大数据技术并成为大数据技术的标准, 但其本身还存在诸多不足, 最主要问题是MR计算框架的高延迟, 无法满足实时、快速计算的需求, 只适用离线批处理的场景.</p>
<p>  MapReduce在其工作流程中存在如下缺点：</p>
<ol>
<li>表达能力有限.  --计算需要转化成Map和Reduce两个操作, 但这并不适合所有的情况, 难以描述复杂的数据处理过程;</li>
<li><strong>磁盘IO开销大</strong>.  --每次执行时都需要从磁盘读取数据, 并且在计算完成后需要将中间结果写入到磁盘中, IO开销较大;</li>
<li>延迟高.  --一次计算可能需要分解成一系列按顺序执行的MR任务, 任务之间的衔接涉及IO开销, 从而产生较高延迟. 而且, 在前一个任务执行完成之前, 其他任务无法开始, 难以胜任复杂、多阶段的计算任务.</li>
<li>MR使用细粒度资源调度, 每一个Job都需要单独申请资源.</li>
</ol>
<p>  Spark在借鉴MR优点的同时, 又很好地解决了MR所面临的问题. 相比于MR, Spark主要具有如下优点：</p>
<ol>
<li>Spark的计算模式也属于MR, 但不局限于Map和Reduce操作. 它还提供了多种数据集(RDD, DataFrame, DStream等)操作类型, 编程模型比MR更加灵活;</li>
<li>Spark支持内存计算, 中间结果直接放内存中, 带来了更高的迭代运算效率;</li>
<li>Spark基于DAG的任务调度执行机制, 要优于MR的迭代执行机制;</li>
<li>Spark支持粗粒度资源调度, Spark Application在执行时, 一次申请资源可以多个Job复用;</li>
<li>Spark可根据不同场景选择不同的shuffle(SortShuffle, HashShuffle).</li>
</ol>
<p>  Spark最大的优势就是将计算数据、中间结果都存储在内存中, 大大减少IO开销. 因此, Spark更适合于迭代运算比较多的数据挖掘与机器学习运算. 在使用Hadoop进行迭代计算时非常耗资源, 因为每次迭代都需要从磁盘中读取、写入中间数据, IO开销大. 而Spark将数据载入内存后, 之后的迭代计算都可以直接使用内存中的中间结果作运算, 避免了从磁盘中频繁读取数据.<br>
<img src="https://img-blog.csdnimg.cn/20181118185454419.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NraXNxaWJhbw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>  在实际进行开发时, 使用Hadoop需要编写许多相对底层的代码, 不够高效. 相对而言, Spark提供了多种高层次、简洁的API, 通常情况下, 对于实现相同功能的应用程序, Spark的代码量要比Hadoop少2-5倍. 更重要的是, Spark提供了实时交互式编程反馈, 可以方便地验证、调整算法.</p>
<p>  尽管Spark相对于Hadoop而言具有较大优势, 但Spark并不能完全替代Hadoop, 主要用于替代Hadoop中的MapReduce计算模型. 实际上, Spark已经很好地融入了Hadoop生态圈, 并成为其中的重要一员, 它可以借助于Yarn实现资源调度管理, 借助于HDFS实现分布式存储. 此外, 虽然Hadoop可以使用廉价、异构的机器来做分布式存储与计算, 但Spark对硬件的要求较高, 对内存与CPU有一定的要求.</p>

            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>