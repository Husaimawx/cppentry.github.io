---
layout:     post
title:      ubuntu-14.04.3上单机安装hadoop2.6
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>ubuntu 14.04.3</p>
<p>hadoop 2.6.3<br></p>
<p><br></p>
<p>1.<strong>创建hadoop用户名</strong><br></p>
<p><strong> </strong>#sudouseradd -m hadoop -s /bin/bash   <br></p>
<p>/*创建了hadoop 用户，并使用 /bin/bash 作为 shell。</p>
<p><strong>#</strong> sudopasswd hadoop</p>
<p>#sudoadduser hadoop sudo</p>
<p>在登陆界面使用刚创建的 hadoop 用户进行登陆。</p>
<p><br></p>
<p>2.<strong>更新apt</strong><br></p>
#sudoapt-get update
<p>可能会出现下面error:</p>
<p>/var/lib/apt/lists/cn.archive.ubuntu.com_ubuntu_dists_trusty_main_i18n_Translation-en</p>
<p>解决方法：sudo rm /var/lib/apt/lists/* -vfR删除apt-getinstall 的所有软件状态包。然后再次执行sudoapt-get update</p>
<p><br></p>
<p>3.<strong>安装SSH、配置SSH无密码登陆</strong></p>
<p>#sudoapt-get install openssh-server<br></p>
<p>安装之后，可以使用命令登录本机：#ssh localhost ，登录成功后exit退出ssh,/home/hadoop/下会自动创建一个.ssh文件夹（隐藏的）</p>
<p></p>
<p># cd /home/hadoop/.ssh <br></p>
<p>#ssh-keygen-t rsa              # 会有提示，一路按回车就可以</p>
<p>#cat ./id_rsa.pub &gt;&gt; ./authorized_keys  # 加入授权</p>
<p>此后，再用 sshlocalhost 命令，无需输入密码就可以登录了</p>
<p><br></p>
<p>4.<strong>Java环境</strong><br>
#sudoapt-get install openjdk-7-jre openjdk-7-jdk</p>
<p>#默认安装位置为 /usr/lib/jvm/java-7-openjdk-amd64</p>
<p>#dpkg -L openjdk-7-jdk| grep '/bin/javac'        #查询安装路径</p>
<p>接着配置 JAVA_HOME 环境变量<br></p>
<p>#vim /home/hadoop/.bashrc</p>
<p></p>
<p>在文件最前面添加:</p>
<p>exportJAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64</p>
<p><br></p>
<p>让环境变量生效并查询：</p>
<p>#source /home/hadoop/.bashrc</p>
#echo $JAVA_HOME<br><p><br></p>
<p></p>
<p><strong>5.安装 Hadoop 2.6.3</strong></p>
<p><a href="http://mirrors.cnnic.cn/apache/hadoop/common/" rel="nofollow"><span style="color:#0000FF;">http://mirrors.cnnic.cn/apache/hadoop/common/</span></a> 下载
<strong>hadoop-2.6.3.tar.gz</strong> 这个文件</p>
<p></p>
<p># 解压到/usr/local中<br></p>
<p>#sudotar -zxf   /下载目录/hadoop-2.6.3.tar.gz-C /usr/local    <br></p>
<p>#cd/usr/local/</p>
<p>#sudo mv  ./hadoop-2.6.3/  ./hadoop            # 将文件夹hadoop-2.6.3改为hadoop</p>
<p>#sudo chown -R hadoop:hadoop ./hadoop        # 修改文件权限</p>
<br><p>#cd/usr/local/hadoop</p>
<p></p>
<p>#./bin/hadoopversion    #检查 Hadoop 是否可用<br></p>
<p><br></p>
<p>修改PATH环境变量。（和JAVA_HOME一样）</p>
<p></p>
<p>#vim /home/hadoop/.bashrc</p>
<p>在JAVA_HOME下面添加:</p>
<p>exportPATH=$PATH:/usr/local/hadoop/sbin:/usr/local/hadoop/bin</p>
<p>#source /home/hadoop/.bashrc<br></p>
<p><br></p>
<p>6.<strong>Hadoop单机配置</strong></p>
<p></p>
<p># cd/usr/local/hadoop</p>
<p>#mkdir./input</p>
<p>#cp./etc/hadoop/*.xml ./input   # 将配置文件作为input</p>
<p>#./bin/hadoopjar  ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep ./input./output 'dfs[a-z.]+'</p>
<p>#cat./output/*         # 查看运行结果</p>
<p>现实 dfsadmin 出现了1次</p>
<p>7.<strong>Hadoop伪分布式配置</strong></p>
<p></p>
<p>Hadoop 在单节点上以伪分布式的方式运行，节点既作为 NameNode 也作为 DataNode，同时，读取的是HDFS 中的文件。</p>
<p>Hadoop 的配置文件在 /usr/local/hadoop/etc/hadoop中，伪分布式需要修改2个配置文件 <strong>core-site.xml</strong> 和<strong>hdfs-site.xml</strong> 。</p>
<br><p>(1)修改配置文件<strong>core-site.xml</strong>：</p>
<p>&lt;configuration&gt;</p>
<p>    &lt;property&gt;</p>
<p>        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</p>
<p>       &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;</p>
<p>        &lt;description&gt;test&lt;/description&gt;</p>
<p>    &lt;/property&gt;</p>
<p>    &lt;property&gt;</p>
<p>        &lt;name&gt;fs.defaultFS&lt;/name&gt;</p>
<p>       &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</p>
<p>    &lt;/property&gt;</p>
<p>&lt;/configuration&gt;</p>
<p><br></p>
<p><br></p>
<p>(2)修改配置文件<strong>hdfs-site.xml</strong>：</p>
<p>&lt;configuration&gt;</p>
<p>    &lt;property&gt;</p>
<p>       &lt;name&gt;dfs.replication&lt;/name&gt;</p>
<p>        &lt;value&gt;1&lt;/value&gt;</p>
<p>    &lt;/property&gt;</p>
<p>    &lt;property&gt;</p>
<p>        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</p>
<p>       &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;</p>
<p>    &lt;/property&gt;</p>
<p>    &lt;property&gt;</p>
<p>       &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</p>
<p>       &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;</p>
<p>    &lt;/property&gt;</p>
<p>&lt;/configuration&gt;</p>
<p><br></p>
<p><br></p>
<p>(3)执行NameNode 的格式化:</p>
<p>#./bin/hdfsnamenode -format</p>
<p>“successfully formatted” 和“Exitting with status 0″ 的提示则表示成功</p>
<p>（4）开启 NaneNode 和 DataNode 守护进程。</p>
<p>#./sbin/start-dfs.sh</p>
<p>出现SSH连接提示，输入yes</p>
<p><br></p>
<p>（5）命令jps 来判断是否成功启动</p>
<p>若成功启动则会列出如下进程: “NameNode”、”DataNode”和 “SecondaryNameNode”</p>
<p><br></p>
<p>（6）访问Web 界面 <a href="http://localhost:50070" rel="nofollow"><span style="color:#0000FF;">http://localhost:50070</span></a>查看 NameNode 和 Datanode 信息，</p>
<p><br></p>
<p><strong>（7）运行Hadoop伪分布式实例</strong></p>
<p>之前的单机模式下，grep的例子读取的是本地的数据，伪分布式则读取的是 HDFS 上的数据。</p>
<p>要使用 HDFS，</p>
<p>a.需要在HDFS 中创建用户目录：</p>
<p>#./bin/hdfsdfs -mkdir -p /user/hadoop</p>
<p><br></p>
<p>b.将./etc/hadoop 中的 xml 文件作为输入文件复制到分布式文件系统(/user/hadoop/input)</p>
<p># ./bin/hdfsdfs -mkdir input</p>
<p>#./bin/hdfsdfs -put  ./etc/hadoop/*.xml input</p>
<p>#./bin/hdfsdfs -ls input   (查看复制结果）<br></p>
<p>执行下面命令来启动<strong>实例</strong><br></p>
<p># ./bin/hadoopjar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep input output'dfs[a-z.]+'</p>
<p>查看运行结果的命令</p>
<p>#./bin/hdfsdfs -cat output/*</p>
<p><br></p>
<p>我们也可以将运行结果取回到本地：</p>
<p>#rm-r ./output    # 先删除本地的 output 文件夹（如果存在）</p>
<p>#/bin/hdfsdfs -get output ./output     # 将 HDFS 上的 output 文件夹拷贝到本机</p>
<p># cat./output/*</p>
<br><p>c.停止hadoop<br></p>
<p>#./sbin/stop-dfs.sh</p>
<p><em>注意</em>:下次启动 hadoop 时，运行 ./sbin/start-dfs.sh 就可以</p>
<p><strong>8.启动YARN</strong></p>
(1).修改配置文件./etc/hadoop/mapred-site.xml:
<p>&lt;configuration&gt;</p>
<p>    &lt;property&gt;</p>
<p>       &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</p>
<p>        &lt;value&gt;yarn&lt;/value&gt;</p>
<p>    &lt;/property&gt;</p>
<p>&lt;/configuration&gt;</p>
<p>(2)修改配置文件<strong>yarn-site.xml</strong>：</p>
<p>&lt;configuration&gt;</p>
<p>    &lt;property&gt;</p>
<p>       &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</p>
<p>       &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</p>
<p>        &lt;/property&gt;</p>
<p>&lt;/configuration&gt;</p>
<p><br></p>
<p>(3)启动YARN 了（需要先执行过 ./sbin/start-dfs.sh）：</p>
<p># ./sbin/start-yarn.sh      $ 启动YARN</p>
<p>#./sbin/mr-jobhistory-daemon.shstart historyserver  # 开启历史服务器</p>
<p><br></p>
<p>(4)jps命令 查看到多了 NodeManager 和ResourceManager 两个后台进程</p>
<p><br></p>
<p>（5）访问Web 界面<a href="http://localhost:8088/cluster" rel="nofollow"><span style="color:#0000FF;">http://localhost:8088/cluster</span></a>查看任务运行信息<br></p>
<p><br></p>
<p>到这里ubuntu-14.04.3上单机安装hadoop2.6就成功了。</p>
<p><br></p>
            </div>
                </div>