---
layout:     post
title:      (五)、HDFS 简介
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/u010850265/article/details/50546988				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>HDFS 是一种分布式文件系统.</p>

<p>常见的分布式文件系统有, GFS、HDFS、Lustre 、Ceph 、GridFS 、mogileFS、TFS、FastDFS等; <br>
各自适用于不同的领域, 它们都不是系统级的分布式文件系统, 而是应用级的分布式文件存储服务.</p>

<p><strong>什么是分布式文件系统?</strong></p>

<p>数据量越来越多, 在一个操作系统管辖的范围存不下了, 那么就分配到更多的操作系统管理的磁盘中, 但是不方便管理和维护, 因此迫切需要一种系统来管理多台机器上的文件, 这就是分布式文件管理系统.</p>

<p>它是一种允许文件通过网络在多台主机上分享的文件系统, 可让多机器上的多用户分享文件和存储空间.</p>

<p>通透性. 让实际上是通过网络来访问文件的动作, 由程序与用户看来, 就像是访问本地的磁盘一般.</p>

<p>容错. 即使系统中有某些节点脱机, 整体来说系统仍然可以持续运作而不会有数据损失.</p>

<p>分布式文件管理系统很多, hdfs 只是其中一种. 适用于一次写入多次查询的情况, 不支持并发写情况, 不合适存储小文件. <br>
一次写入即写入后无法更新, 只能删除重写, 2.0 好像支持追加内容. <br>
不支持并发写并不是指不能同时存储多份文件, 而是指, 一份大文件被分成多个块时, 是一个块写满再写另一个块的, 不能同时写所有的块. <br>
不合适存储小文件只限于 hadoop 1.0, 因为就算是很小的文件, 它也会分配一个块给它, 2.0 中对它进行了一些修改.</p>

<p>下面是一张 HDFS 的简单示图, 参考下:</p>

<p><img src="http://i61.tinypic.com/dwcpw9.jpg" alt="HDFS" title=""></p>

<p>当 Client 需要存储一份文件的时候, 如 a.log (200M), Client 先和 HDFS 中的 NameNode 取得联系, NameNode 从自己的集群中找到一个可以存储的 DataNode 并告诉 Client, Clint 开始向指定的 DataNode 存储数据. <br>
存储数据的时候, 会根据文件的大小分块存储(2.0 默认 128M), 当存储完一个块后, DataNode 会检查 NameNode 中设置的副本数量, 如果不止一份的话, 当前 DataNode 就会水平传递(pipline)块给其他的 DataNode, 然后再 <br>
申请另一个块, 继续存储剩余的文件内容…以此类推.</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>