---
layout:     post
title:      spark sql
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p style="color:rgb(51,51,51);text-indent:28px;font-family:'宋体';font-size:14px;line-height:28px;background-color:rgb(248,248,248);">
Spark SQL 的前身是Shark，它发布时Hive 可以说是SQL on Hadoop 的唯一选择（Hive 负责将SQL 编译成可扩展的MapReduce 作业），鉴于Hive 的性能以及与Spark 的兼容，Shark 由此而生。</p>
<p style="color:rgb(51,51,51);text-indent:28px;font-family:'宋体';font-size:14px;line-height:28px;background-color:rgb(248,248,248);">
Shark 即Hive on Spark，本质上是通过Hive 的HQL 进行解析，把HQL 翻译成Spark 上对应的RDD 操作，然后通过Hive 的Metadata 获取数据库里的表信息，实际为HDFS 上的数据和文件，最后由Shark 获取并放到Spark 上运算。Shark 的最大特性就是速度快，能与Hive 的完全兼容，并且可以在Shell 模式下使用rdd2sql 这样的API，把HQL 得到的结果集继续在Scala环境下运算，支持用户编写简单的机器学习或简单分析处理函数，对HQL 结果进一步分析计算。</p>
<p style="color:rgb(51,51,51);text-indent:28px;font-family:'宋体';font-size:14px;line-height:28px;background-color:rgb(248,248,248);">
在2014 年7 月1 日的Spark Summit 上，Databricks 宣布终止对Shark 的开发，将重点放到Spark SQL 上。在此次会议上，Databricks 表示，Shark 更多是对Hive 的改造，替换了Hive 的物理执行引擎，使之有一个较快的处理速度。然而，不容忽视的是，Shark 继承了大量的Hive代码，因此给优化和维护带来大量的麻烦。随着性能优化和先进分析整合的进一步加深，基于MapReduce 设计的部分无疑成为了整个项目的瓶颈。因此，为了更好的发展，给用户提供一个更好的体验，Databricks
 宣布终止Shark 项目，从而将更多的精力放到Spark SQL 上。</p>
<p style="color:rgb(51,51,51);text-indent:28px;font-family:'宋体';font-size:14px;line-height:28px;background-color:rgb(248,248,248);">
Spark SQL 允许开发人员直接处理RDD，同时也可查询在 Hive 上存在的外部数据。SparkSQL 的一个重要特点是能够统一处理关系表和RDD，使得开发人员可以轻松地使用SQL 命令进行外部查询，同时进行更复杂的数据分析。Spark SQL 的特点如下。</p>
<p style="color:rgb(51,51,51);text-indent:28px;font-family:'宋体';font-size:14px;line-height:28px;background-color:rgb(248,248,248);">
引入了新的RDD 类型SchemaRDD，可以像传统数据库定义表一样来定义SchemaRDD。SchemaRDD 由定义了列数据类型的行对象构成。SchemaRDD 既可以从RDD 转换过来，也可以从Parquet 文件读入，还可以使用HiveQL 从Hive 中获取。</p>
<p style="color:rgb(51,51,51);text-indent:28px;font-family:'宋体';font-size:14px;line-height:28px;background-color:rgb(248,248,248);">
内嵌了Catalyst 查询优化框架，在把SQL 解析成逻辑执行计划之后，利用Catalyst 包里的一些类和接口，执行了一些简单的执行计划优化，最后变成RDD 的计算。</p>
<p style="color:rgb(51,51,51);text-indent:28px;font-family:'宋体';font-size:14px;line-height:28px;background-color:rgb(248,248,248);">
在应用程序中可以混合使用不同来源的数据，如可以将来自HiveQL的数据和来自SQL的数据进行Join 操作。Shark 的出现使得SQL-on-Hadoop 的性能比Hive 有了10～100 倍的提高，那么，摆脱了Hive 的限制，Spark SQL 的性能又有怎么样的表现呢？虽然没有Shark 相对于Hive 那样瞩目的性能提升，但也表现得优异，如图1-10 所示（其中，右侧数据为Spark SQL）。<br style="clear:both;width:0px;"></p>
<p style="color:rgb(51,51,51);text-indent:28px;font-family:'宋体';font-size:14px;line-height:28px;background-color:rgb(248,248,248);">
<a href="http://s4.51cto.com/wyfs02/M02/8D/F5/wKioL1iw9AbSZwJAAAAwz5q005U910.jpg" rel="nofollow" style="color:rgb(0,66,118);"><img class="fit-image" title="" border="0" alt="" src="http://s4.51cto.com/wyfs02/M02/8D/F5/wKioL1iw9AbSZwJAAAAwz5q005U910.jpg" width="486" height="260" style="border:0px;text-align:center;"></a></p>
<p style="color:rgb(51,51,51);text-indent:28px;font-family:'宋体';font-size:14px;line-height:28px;background-color:rgb(248,248,248);">
为什么Spark SQL 的性能会得到这么大的提升呢？主要是Spark SQL 在以下几点做了优化。</p>
<p style="color:rgb(51,51,51);text-indent:28px;font-family:'宋体';font-size:14px;line-height:28px;background-color:rgb(248,248,248);">
内存列存储（In-Memory Columnar Storage）：Spark SQL 的表数据在内存中存储不是采用原生态的JVM 对象存储方式，而是采用内存列存储。</p>
<p style="color:rgb(51,51,51);text-indent:28px;font-family:'宋体';font-size:14px;line-height:28px;background-color:rgb(248,248,248);">
字节码生成技术（Bytecode Generation）：Spark 1.1.0 在Catalyst 模块的Expressions 增加了Codegen 模块，使用动态字节码生成技术，对匹配的表达式采用特定的代码动态编译。另外对SQL 表达式都做了CG 优化。CG 优化的实现主要还是依靠Scala 2.10运行时的反射机制（Runtime Reflection）。</p>
<p style="color:rgb(51,51,51);text-indent:28px;font-family:'宋体';font-size:14px;line-height:28px;background-color:rgb(248,248,248);">
Scala 代码优化：Spark SQL 在使用Scala 编写代码的时候，尽量避免低效的、容易GC的代码；尽管增加了编写代码的难度，但对于用户来说接口统一。</p>
            </div>
                </div>