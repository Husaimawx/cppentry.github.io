---
layout:     post
title:      实时分析
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/vitaair/article/details/80220633				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                实时分析<br><span style="white-space:pre;">	</span>1.kafka中创建主题<br><span style="white-space:pre;">		</span><br><span style="white-space:pre;">	</span>2.storm从kafka中消费数据<br><span style="white-space:pre;">		</span>storm提供了storm从kafka消费数据的jar包<br><span style="white-space:pre;">			</span>storm开发包<br><span style="white-space:pre;">			</span>kafka开发包<br><span style="white-space:pre;">			</span>storm连接kafka的开发包<br><span style="white-space:pre;">			</span>其他包<br><span style="white-space:pre;">			</span>**注意可能要删除重复的log4j相关的包<br><br><br><span style="white-space:pre;">		</span>导入相关jar包 按照文档编写代码即可实现storm从kafka消费数据<br><br><br><span style="white-space:pre;">		</span>方式一：可以自己开发spout利用kafka提供的api消费数据<br><span style="white-space:pre;">		</span>方式二：利用storm提供的kafka扩展包连接<br><span style="white-space:pre;">			</span>String topic = "flux";<br><span style="white-space:pre;">			</span>BrokerHosts hosts = new ZkHosts("hadoop01,hadoop02,hadoop03:2181");<br><span style="white-space:pre;">			</span>SpoutConfig spoutConfig = new SpoutConfig(hosts,topic, "/" + topic, UUID.randomUUID().toString());<br><span style="white-space:pre;">			</span>spoutConfig.scheme = new SchemeAsMultiScheme(new StringScheme());<br><span style="white-space:pre;">			</span>KafkaSpout spout = new KafkaSpout(spoutConfig);<br><br><br><span style="white-space:pre;">	</span>3.处理业务逻辑<br><span style="white-space:pre;">		</span>数据清洗<br><span style="white-space:pre;">			</span>"url","urlname","uvid","sid","scount","stime","cip"<br><span style="white-space:pre;">		</span>pv<br><span style="white-space:pre;">			</span>用户一次访问就是一个pv 直接将每次访问都记为1个pv即可<br><span style="white-space:pre;">		</span>uv<br><span style="white-space:pre;">			</span>独立访客数 - 当前这个uvid 在今天的数据中是否是第一次出现 如果是记为1 否则为0<br><span style="white-space:pre;">				</span>-应该将每条记录都存入hbase作为uv计算的依据<br><span style="white-space:pre;">				</span>-每条记录过来时用uvid和数据库中今天的uvid进行比较 如果发现匹配 则uvid为0 匹配不到则记为1<br><br><br><span style="white-space:pre;">			</span>设计hbase表结果：<br><span style="white-space:pre;">				</span>列族的设计：<br><span style="white-space:pre;">					</span>设计一个列族名为cf1即可<br><span style="white-space:pre;">				</span>行键的设计：<br><span style="white-space:pre;">					</span>"url","urlname","uvid","sid","scount","stime","cip"<br><span style="white-space:pre;">					</span>time_uvid_cip_rand<br><span style="white-space:pre;">					</span>1495244059010_45189712356761262218_0:0:0:0:0:0:0:1_xxxxx(5)<br><span style="white-space:pre;">					</span>^\d+_xxxxx_.*$<br><span style="white-space:pre;">					</span>^\d+_\d+_xxxx_.*$<br><span style="white-space:pre;">					</span>^\d+_xxxx_.*$<br><br><br><span style="white-space:pre;">			</span>create 'flux','cf1';<br><br><br><span style="white-space:pre;">		</span>vv<br><span style="white-space:pre;">			</span>当前访问是否是一个新的会话 - 是 则 vv为1 否则为0<br><span style="white-space:pre;">				</span><br><span style="white-space:pre;">		</span>newip<br><span style="white-space:pre;">			</span>当前的访问是否是一个历史上从未出现过的ip - 是 newip 为1 否则为0<br><span style="white-space:pre;">			</span><br><span style="white-space:pre;">		</span>newcust<br><span style="white-space:pre;">			</span>当前的访问是否是一个历史上从未出现过的uvid - 是 newcust 为1 否则为0<br><br><br><span style="white-space:pre;">		</span>-------------------<br><span style="white-space:pre;">		</span>br<br><span style="white-space:pre;">			</span>跳出率 - 一段时间内 跳出的会话总数/所有的会话总数 得到的比率 - 由于不能根据一条日志 立即推断出是否是一个跳出的会话 所以这个参数不适合用实时计算<br><br><br><span style="white-space:pre;">		</span>avgtime<br><span style="white-space:pre;">			</span>平均在线时长 - 一段时间内 所有的会话在线时长的平均值 - 由于不能根据一条日志 立即推断出是否是一个会话的完结 所以这个参数不适合用实时计算<br><br><br><span style="white-space:pre;">		</span>avgdeep<br><span style="white-space:pre;">			</span>平均访问深度 - 一段时间内所有的会话访问深度的平均值 - 由于不能根据一条日志 立即推断出是否是一个会话的结束 所以这个参数不适合用实时计算<br><br><br><span style="white-space:pre;">		</span>以上的参数都是需要积累一段时间数据后 基于这一段时间内数据来进行计算的 更适合于通过离线计算来实现<br><span style="white-space:pre;">		</span>但是其实在现实情况中 如果想要在较短的时间段内进行如上参数的统计 每次都去启动离线分析是 不太效率的做法 甚至可能无法按时完成任务 像这种情况下人们还是期望能够以更类似于实时计算的方式来对数据做处理 虽然是一段时间内的数据的数据的处理 但是由于时间段比较小 数据量也不算太大 更像一个实时分析的场景<br><span style="white-space:pre;">		</span>那么如何实现以上利用实时分析计算一段时间内数据的需求呢？<br><span style="white-space:pre;">		</span>可以设计一个特殊的spout 内置一个定时器 每隔指定的时长就向后发送一个tuple表示时间到了 要求后续的bolt们进行计算 后续的bolt收到这个消息后 开始计算这段时间内收集到的数据<br><br><br><span style="white-space:pre;">		</span>===Storm的tick机制--定时触发任务机制======================<br><span style="white-space:pre;">			</span>storm在0.8以上的版本中提供了tick机制实现定时任务。<br><span style="white-space:pre;">			</span>它能够让任何bolt的所有task每隔一段时间（精确到秒级，用户可以自定义）收到一个来自_systemd的_tick stream的tick tuple，bolt收到这样的tuple后可以根据业务需求完成相应的处理。<br><span style="white-space:pre;">			</span>方式一：为某一个特定的bolt指定定时任务<br><span style="white-space:pre;">				</span>在bolt中覆盖getComponentConfiguration，在其中设置conf的属性TOPOLOGY_TICK_TUPLE_FREQ_SECS设置为指定时间间隔<br><span style="white-space:pre;">					</span>@Override<br><span style="white-space:pre;">					</span>public Map&lt;String, Object&gt; getComponentConfiguration() {<br><span style="white-space:pre;">						</span>Config conf = new Config();<br><span style="white-space:pre;">						</span>conf.put(conf.TOPOLOGY_TICK_TUPLE_FREQ_SECS, 900);<br><span style="white-space:pre;">						</span>return conf;<br><span style="white-space:pre;">					</span>}<br><span style="white-space:pre;">				</span>这样这个bolt将会在程序启动后每隔指定时长都会收到一个定时发送tuple来触发程序<br><span style="white-space:pre;">				</span>在execute方法中可以使用如下判断获知是否是定时任务出发的代码：<br><span style="white-space:pre;">					</span>if (tuple.getSourceComponent().equals(Constants.SYSTEM_COMPONENT_ID)  &amp;&amp; tuple.getSourceStreamId().equals(Constants.SYSTEM_TICK_STREAM_ID)){<br><span style="white-space:pre;">						</span>//是定时tuple触发的<br><span style="white-space:pre;">					</span>}else{<br><span style="white-space:pre;">						</span>//是普通tuple触发的<br><span style="white-space:pre;">					</span>}<br><span style="white-space:pre;">			</span>方式二：可以为整个topology指定定时任务，这样整个topology中的所有bolt都会定时收到tuple<br><span style="white-space:pre;">				</span>代码如下<br><span style="white-space:pre;">					</span>Config conf = new Config();<br><span style="white-space:pre;">					</span>conf.put(conf.TOPOLOGY_TICK_TUPLE_FREQ_SECS, 7);<br><span style="white-space:pre;">				</span>如果即设置了全局定时器 又为某个bolt单独制定定时器，则单独启动的起作用。<br><span style="white-space:pre;">		</span>==================================================<span style="white-space:pre;">		</span><br><br><br><span style="white-space:pre;">	</span>4.结果存储到mysql中<br><span style="white-space:pre;">		</span>create database fluxdb;<br><span style="white-space:pre;">		</span>use fluxdb;<br><span style="white-space:pre;">		</span>create table tongji_2(<br><span style="white-space:pre;">			</span>stime DateTime,<br><span style="white-space:pre;">			</span>pv int,<br><span style="white-space:pre;">			</span>uv int,<br><span style="white-space:pre;">			</span>vv int,<br><span style="white-space:pre;">			</span>newip int,<br><span style="white-space:pre;">			</span>newcust int<br><span style="white-space:pre;">		</span>);<br><br><br><span style="white-space:pre;">		</span>create table tongji_3(<br><span style="white-space:pre;">			</span>stime DateTime,<br><span style="white-space:pre;">			</span>br double,<br><span style="white-space:pre;">			</span>avgtime double,<br><span style="white-space:pre;">			</span>avgdeep double<br><span style="white-space:pre;">		</span>);            </div>
                </div>