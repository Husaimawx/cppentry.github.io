---
layout:     post
title:      大数据十一 Spark
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h2><a id="spark_0"></a>spark简介</h2>
<p>Spark 是专为大规模数据处理而设计的快速通用的计算引擎</p>
<p>Spark是UC Berkeley AMP lab (加州大学伯克利分校的AMP实验室)所开源的类Hadoop MapReduce的通用并行框架，是一种“One Stack to rule them all”通用的大数据计算框架，期望使用一个技术栈就完美地解决大数据领域的各种计算任务</p>
<p>Spark 支持 scala，java，python 和 R 等开发语言，因为 spark 底层是使用scala语言实现，所以用 scala 和 java 来开发 spark 程序效率比较高，因为 java 和 scala 都是基于 JVM的编程语言</p>
<p>Spark 的速度比 MapReduce 快</p>
<blockquote>
<p>–MR计算模型计算中间会产生很多 shuffle，shuffle 中间的过程都是基于磁盘来读写的，这是最耗性能的部分<br>
–Spark 使用 DAG 有向无环图，切割 job，划分 stage，task 间是 pipeline 计算模式，减少磁盘落地<br>
–Spark 支持基于内存迭代，当然，因为Spark是基于内存进行计算的，如果数据量太大，没有调优的情况下，会出现OOM<br>
–Spark 采用粗粒度的资源调度，实现资源复用<br>
–Spark 可以根据不同情况选择不同的 shuffle</p>
</blockquote>
<h2><a id="Spark_shuffle_16"></a>Spark shuffle</h2>
<p>spark 支持 HashShuffle 和 SortShuffle 两种 shuffle</p>
<h3><a id="HashShuffle_19"></a>HashShuffle</h3>
<p>spark 前期默认使用 HashShuffle，这里我们看图，假设每个 Executor 使用1个核，这样同一时刻每个 Executor 就只能执行一个 task</p>
<p>在 stage 之间存在 shuffle 过程，首先是 shuffle write 阶段，task 处理完的数据会按照 key 的 hash 值与 reduce task 的个数取模从而将其分区，不同分区的数据写入不同的磁盘文件，写磁盘之前会先写入buffer，buffer写满后溢写到磁盘</p>
<p>然后是 shuffle read 阶段：reduce task 拉取各个节点上同一分区的数据，先写入 buffer 中，拉取数据的同时会对数据进行聚合操作，直到数据拉取完毕</p>
<p><img src="https://img-blog.csdnimg.cn/2018111620003861.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpbmd5YW8yMzE=,size_16,color_FFFFFF,t_70" alt="hashshuffle"></p>
<p>此时我们会发现1个 task 会产生 reduce.num 个磁盘小文件，总共会产生 m*r 个磁盘小文件，m 指 map task 的个数，r 指 reduce task 的个数，真实情况中这会产生大量的磁盘小文件，就会导致 shuffle 过程中创建大量的读写文件的对象及进行很多次磁盘和网络IO，严重影响性能</p>
<h3><a id="HashShuffle__31"></a>HashShuffle 优化</h3>
<p>鉴于上述问题，官方对 HashShuffle 做出了优化，引入了 Consolidate 机制：在 shuffle write 阶段，复用 buffer，将 task 处理的结果写到一个文件中，减少磁盘小文件的数量</p>
<p>如图，我们可以看到磁盘小文件变成2个了，但是如果 Executor 有2个 CPU core 的话，那么磁盘小文件就会变成4个；由此可以发现，优化后的 HashShuffle 中间过程会产生 c*r 个磁盘文件，c 指程序运行使用到的 CPU 核数</p>
<blockquote>
<p>Executor 有2个 CPU core，表示同一时刻可以有2个 task 并行执行<br>
通常 1个 CPU core 会分配到 2~3个 task，所以该优化确实可以减少磁盘小文件的个数（从总数上）</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/20181119191957409.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpbmd5YW8yMzE=,size_16,color_FFFFFF,t_70" alt="shuffle 优化"></p>
<h3><a id="SortShuffle_42"></a>SortShuffle</h3>
<p>spark1.2 之后，官方使用 SortShuffle 替换了原来默认的 HashShuffle</p>

            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>