---
layout:     post
title:      spark 源码分析
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<ol>
<li><p>spark 整体架构 <br>
 <img src="https://img-blog.csdn.net/20160929115530337" alt="这里写图片描述" title=""> <br>
 spark 四块最重要的：</p>

<ol><li>sparkSql</li>
<li>spark流处理</li>
<li>机器学习</li>
<li>图计算</li></ol></li>
<li><p>spark 2.0 源码结构 <br>
<img src="https://img-blog.csdn.net/20160929135257157" alt="这里写图片描述" title=""> <br>
spark最核心的代码：<a href="https://github.com/apache/spark" rel="nofollow">https://github.com/apache/spark</a></p></li>
<li><p>分析源码的方法</p>

<ol><li>从bin 文件夹开始，我们同常会打开一个spark-shell, 提交任务spark-sbumit, <br>
加入我们执行spark-submit, 那么打开spark-submit</li>
<li>spark-submit 实际上执行了： org.apache.spark.deploy.SparkSubmit 这个类文件</li>
<li>org.apache.spark.deploy.SparkSubmit 的源码路径：core/src/main/scala/org/apache/spark/deploy/SparkSubmit.scala</li>
<li>然后打开：core/src/main/scala/org/apache/spark/deploy/SparkSubmit.scala</li>
<li>这样我们就进入了源码内部</li></ol></li>
<li><p>举例分析—-spark-submit 到底干了什么？</p>

<ol><li>spark-submit 参数检测，添加jar 包</li>
<li>触发 –class 对应的类，执行我们自己代码的逻辑</li>
<li>代码逻辑中的每一个acction 操作都会触发 sparkContext 的runJob方法</li>
<li>随即触发dagScheduler.runJob， runJob 会 调用submitJob, 等待回调结果</li></ol></li>
</ol>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>