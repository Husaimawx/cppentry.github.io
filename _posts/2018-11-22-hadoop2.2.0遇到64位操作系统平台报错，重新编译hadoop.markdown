---
layout:     post
title:      hadoop2.2.0遇到64位操作系统平台报错，重新编译hadoop
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/tanqingru/article/details/13506893				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>hadoop cmake  maven protobuf</p>
<h2>问题描述</h2>
<p>在64位linux装的hadoop，在很多地方会遇到<span style="color:#FF0000;">libhadoop.so.1.0.0 which might have disabled stack guard</span>. 是因为hadoop是32位的，需要手工编译hadoop。</p>
<p>hadoop为2.2.0，操作系统为oracle linux 6.3 64位。<br></p>
<p>说明：经过实测，hadoop2.6.0在Oracle Linux也能用同样的方法编译。</p>
<h2>实例和解决过程。</h2>
<h3>遇到的问题</h3>
<p>[hadoop@hadoop01 input]$ hadoop dfs -put ./in</p>
<p>DEPRECATED: Use of this script to executehdfs command is deprecated.</p>
<p>Instead use the hdfs command for it.</p>
<p> </p>
<p><span style="color:#FF0000;">Java HotSpot(TM) 64-BitServer VM warning: You have loaded library/app/hadoop/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might havedisabled stack guard. The VM will try to fix the stack guard now.</span></p>
<p><span style="color:#FF0000;">It's highly recommendedthat you fix the library with 'execstack -c &lt;libfile&gt;', or link it with'-z noexecstack'.</span></p>
<p>13/10/24 04:08:55 WARNutil.NativeCodeLoader: Unable to load native-hadoop library for yourplatform... using builtin-java classes where applicable</p>
<p>put: `in': No such file or directory</p>
<p> </p>
<h3>查看本地文件</h3>
<p>[hadoop@hadoop01 input]$ <span style="color:#FF0000;">file /app/hadoop/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0</span></p>
<p>/app/hadoop/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0:E<span style="color:#FF0000;">LF 32-bit LSB</span> shared object, Intel 80386,version 1 (SYSV), dynamically linked, not stripped</p>
<p> </p>
<h3>貌似是32位和64位的原因</h3>
<p>http://mail-archives.apache.org/mod_mbox/hadoop-user/201208.mbox/%3C19AD42E3F64F0F468A305399D0DF39D92EA4521578@winops07.win.compete.com%3E</p>
<p>http://www.mail-archive.com/common-issues@hadoop.apache.org/msg52576.html</p>
<p>操作系统64位，软件是32位。悲剧了。。。装好的集群没法用。</p>
<p> </p>
<p> </p>
<h3>解决方法：重新编译hadoop</h3>
<p>解决方法，就是重新编译hadoop软件：</p>
<h4>下载程序代码</h4>
<p>机器得连网，如果没联网找可以联网的机器下载，但是编译时还是要下载一些东西，所以，实在不行。最好找相同平台（可以是虚拟机）能上网的机器做下面工作，弄好了再拷回来。</p>
<p> </p>
<p># <span style="color:#FF0000;">svn checkout'http://svn.apache.org/repos/asf/hadoop/common/tags/release-2.2.0'</span></p>
<p> </p>
<p>都下载到这了：</p>
<p>[hadoop@hadoop01 hadoop]$ ls</p>
<p>BUILDING.txt       hadoop-common-project     hadoop-maven-plugins  hadoop-tools</p>
<p>dev-support        hadoop-dist               hadoop-minicluster    hadoop-yarn-project</p>
<p>hadoop-assemblies  hadoop-hdfs-project       hadoop-project        pom.xml</p>
<p>hadoop-client      hadoop-mapreduce-project  hadoop-project-dist</p>
<h4>安装开发环境</h4>
<h5>1.必要的包</h5>
<p>[root@hadoop01 /]# yum install svn </p>
<p>[root@hadoop01 ~]# yum install autoconf automake libtool cmake </p>
<p>root@hadoop01 ~]# yum install ncurses-devel</p>
<p>root@hadoop01 ~]# yum install openssl-devel</p>
<p>root@hadoop01 ~]# yum install gcc*</p>
<h5>2.安装maven</h5>
<p>下载，并解压</p>
<p>http://maven.apache.org/download.cgi</p>
<p> </p>
<p>[root@hadoop01 stable]# mvapache-maven-3.1.1 /usr/local/</p>
<p>将/usr/local/apache-maven-3.1.1/bin加到环境变量中</p>
<h5>3.安装protobuf</h5>
<p> </p>
<p><strong>没装 protobuf,后面编译做不完，结果如下：</strong></p>
<p>[INFO] ---hadoop-maven-plugins:2.2.0:protoc (compile-protoc) @ hadoop-common ---</p>
<p>[WARNING] [protoc, --version] failed:java.io.IOException: Cannot run program "protoc": error=2, No suchfile or directory</p>
<p>[ERROR] stdout: []</p>
<p>……………………</p>
<p>[INFO] Apache Hadoop Main................................ SUCCESS [5.672s]</p>
<p>[INFO] Apache Hadoop Project POM......................... SUCCESS [3.682s]</p>
<p>[INFO] Apache Hadoop Annotations......................... SUCCESS [8.921s]</p>
<p>[INFO] Apache Hadoop Assemblies.......................... SUCCESS [0.676s]</p>
<p>[INFO] Apache Hadoop Project Dist POM.................... SUCCESS [4.590s]</p>
<p>[INFO] Apache Hadoop Maven Plugins....................... SUCCESS [9.172s]</p>
<p>[INFO] Apache Hadoop Auth................................ SUCCESS [10.123s]</p>
<p>[INFO] Apache Hadoop Auth Examples....................... SUCCESS [5.170s]</p>
<p><span style="color:#FF0000;">[INFO] Apache HadoopCommon .............................. FAILURE [1.224s]</span></p>
<p>[INFO] Apache Hadoop NFS................................. SKIPPED</p>
<p>[INFO] Apache Hadoop Common Project...................... SKIPPED</p>
<p>[INFO] Apache Hadoop HDFS................................ SKIPPED</p>
<p>[INFO] Apache Hadoop HttpFS.............................. SKIPPED</p>
<p>[INFO] Apache Hadoop HDFS BookKeeperJournal ............. SKIPPED</p>
<p>[INFO] Apache Hadoop HDFS-NFS............................ SKIPPED</p>
<p>[INFO] Apache Hadoop HDFS Project........................ SKIPPED</p>
<h6>安装protobuf过程</h6>
<p>下载：https://protobuf.googlecode.com/files/protobuf-2.5.0.tar.gz</p>
<p>https://code.google.com/p/protobuf/downloads/list</p>
<p>[root@hadoop01 protobuf-2.5.0]# pwd</p>
<p>/soft/protobuf-2.5.0</p>
<p><strong>依次执行下面的命令即可</strong></p>
<p><span style="color:#FF0000;">./configure</span></p>
<p><span style="color:#FF0000;">make </span></p>
<p><span style="color:#FF0000;">make check </span></p>
<p><span style="color:#FF0000;">make install</span></p>
<p>[root@hadoop01 protobuf-2.5.0]# protoc--version</p>
<p>libprotoc 2.5.0</p>
<p> </p>
<h5>4.cmake安装</h5>
<p><span style="color:#FF0000;">CMAKE</span><span style="color:#FF0000;">报错：</span></p>
<p>main:</p>
<p>   [mkdir] Created dir:/soft/hadoop/hadoop-tools/hadoop-pipes/target/native</p>
<p>    [exec] -- The C compiler identification is GNU</p>
<p>    [exec] -- The CXX compiler identification is GNU</p>
<p>    [exec] -- Check for working C compiler: /usr/bin/gcc</p>
<p>    [exec] -- Check for working C compiler: /usr/bin/gcc -- works</p>
<p>    [exec] -- Detecting C compiler ABI info</p>
<p>    [exec] -- Detecting C compiler ABI info - done</p>
<p>    [exec] -- Check for working CXX compiler: /usr/bin/c++</p>
<p>    [exec] -- Check for working CXX compiler: /usr/bin/c++ -- works</p>
<p>    [exec] -- Detecting CXX compiler ABI info</p>
<p>    [exec] -- Detecting CXX compiler ABI info - done</p>
<p>    [exec] CMake Error at /usr/share/cmake/Modules/FindOpenSSL.cmake:66(MESSAGE):</p>
<p>    [exec]   Could NOT find OpenSSL</p>
<p>    [exec] Call Stack (most recent call first):</p>
<p>    [exec]   CMakeLists.txt:20(find_package)</p>
<p>    [exec] </p>
<p>    [exec] </p>
<p>    [exec] -- Configuring incomplete, errors occurred!</p>
<p>[INFO] Apache Hadoop Gridmix............................. SUCCESS [12.062s]</p>
<p>[INFO] Apache Hadoop Data Join........................... SUCCESS [8.694s]</p>
<p>[INFO] Apache Hadoop Extras.............................. SUCCESS [6.877s]</p>
<p>[INFO] Apache Hadoop Pipes ...............................FAILURE [5.295s]</p>
<p>[INFO] Apache Hadoop Tools Dist.......................... SKIPPED</p>
<p>[INFO] Apache Hadoop Tools............................... SKIPPED</p>
<p>[INFO] Apache Hadoop Distribution........................ SKIPPED</p>
<p>[INFO] Apache Hadoop Client.............................. SKIPPED</p>
<p>[INFO] Apache Hadoop Mini-Cluster........................ SKIPPED</p>
<p> </p>
<p><strong>需要安装</strong></p>
<p>root@hadoop01 ~]# yum install ncurses-devel</p>
<p>root@hadoop01 ~]# yum install openssl-devel</p>
<p> </p>
<h4>编译hadoop</h4>
<p> </p>
<p>[hadoop@hadoop01 hadoop]$ pwd</p>
<p>/soft/hadoop</p>
<p>[hadoop@hadoop01 hadoop]$ ls</p>
<p>BUILDING.txt       hadoop-client          hadoop-hdfs-project       hadoop-minicluster   hadoop-tools</p>
<p>dev-support        hadoop-common-project  hadoop-mapreduce-project  hadoop-project       hadoop-yarn-project</p>
<p>hadoop-assemblies  hadoop-dist            hadoop-maven-plugins      hadoop-project-dist  pom.xml</p>
<p>[hadoop@hadoop01 hadoop]$ <span style="color:#FF0000;">mvn package -Pdist,native -DskipTests -Dtar</span></p>
<p> </p>
<p>编译是个很耗时的工作呀。。。。</p>
<p> </p>
<p><strong>下面是做完成功的结果</strong></p>
<p>[INFO] Reactor Summary:</p>
<p>[INFO] </p>
<p>[INFO] Apache Hadoop Main................................ SUCCESS [6.600s]</p>
<p>[INFO] Apache Hadoop Project POM......................... SUCCESS [3.974s]</p>
<p>[INFO] Apache Hadoop Annotations......................... SUCCESS [9.878s]</p>
<p>[INFO] Apache Hadoop Assemblies.......................... SUCCESS [0.856s]</p>
<p>[INFO] Apache Hadoop Project Dist POM.................... SUCCESS [4.750s]</p>
<p>[INFO] Apache Hadoop Maven Plugins....................... SUCCESS [8.720s]</p>
<p>[INFO] Apache Hadoop Auth................................ SUCCESS [10.107s]</p>
<p>[INFO] Apache Hadoop Auth Examples....................... SUCCESS [5.734s]</p>
<p>[INFO] Apache Hadoop Common.............................. SUCCESS [4:32.636s]</p>
<p>[INFO] Apache Hadoop NFS................................. SUCCESS [29.700s]</p>
<p>[INFO] Apache Hadoop Common Project...................... SUCCESS [0.090s]</p>
<p>[INFO] Apache Hadoop HDFS................................ SUCCESS [6:15.394s]</p>
<p>[INFO] Apache Hadoop HttpFS.............................. SUCCESS [1:09.238s]</p>
<p>[INFO] Apache Hadoop HDFS BookKeeperJournal ............. SUCCESS [27.676s]</p>
<p>[INFO] Apache Hadoop HDFS-NFS............................ SUCCESS [13.954s]</p>
<p>[INFO] Apache Hadoop HDFS Project........................ SUCCESS [0.212s]</p>
<p>[INFO] hadoop-yarn....................................... SUCCESS [0.962s]</p>
<p>[INFO] hadoop-yarn-api................................... SUCCESS [1:48.066s]</p>
<p>[INFO] hadoop-yarn-common................................ SUCCESS [1:37.543s]</p>
<p>[INFO] hadoop-yarn-server................................ SUCCESS [4.301s]</p>
<p>[INFO] hadoop-yarn-server-common......................... SUCCESS [29.502s]</p>
<p>[INFO] hadoop-yarn-server-nodemanager.................... SUCCESS [36.593s]</p>
<p>[INFO] hadoop-yarn-server-web-proxy...................... SUCCESS [13.273s]</p>
<p>[INFO] hadoop-yarn-server-resourcemanager................ SUCCESS [30.612s]</p>
<p>[INFO] hadoop-yarn-server-tests.......................... SUCCESS [4.374s]</p>
<p>[INFO] hadoop-yarn-client................................ SUCCESS [14.115s]</p>
<p>[INFO] hadoop-yarn-applications.......................... SUCCESS [0.218s]</p>
<p>[INFO]hadoop-yarn-applications-distributedshell ......... SUCCESS [9.871s]</p>
<p>[INFO] hadoop-mapreduce-client........................... SUCCESS [1.095s]</p>
<p>[INFO] hadoop-mapreduce-client-core...................... SUCCESS [1:30.650s]</p>
<p>[INFO]hadoop-yarn-applications-unmanaged-am-launcher .... SUCCESS [15.089s]</p>
<p>[INFO] hadoop-yarn-site.................................. SUCCESS [0.637s]</p>
<p>[INFO] hadoop-yarn-project............................... SUCCESS [25.809s]</p>
<p>[INFO] hadoop-mapreduce-client-common.................... SUCCESS [45.919s]</p>
<p>[INFO] hadoop-mapreduce-client-shuffle................... SUCCESS [14.693s]</p>
<p>[INFO] hadoop-mapreduce-client-app....................... SUCCESS [39.562s]</p>
<p>[INFO] hadoop-mapreduce-client-hs........................ SUCCESS [19.299s]</p>
<p>[INFO] hadoop-mapreduce-client-jobclient................. SUCCESS [18.549s]</p>
<p>[INFO] hadoop-mapreduce-client-hs-plugins................ SUCCESS [5.134s]</p>
<p>[INFO] Apache Hadoop MapReduce Examples.................. SUCCESS [17.823s]</p>
<p>[INFO] hadoop-mapreduce.................................. SUCCESS [12.726s]</p>
<p>[INFO] Apache Hadoop MapReduce Streaming................. SUCCESS [19.760s]</p>
<p>[INFO] Apache Hadoop Distributed Copy.................... SUCCESS [33.332s]</p>
<p>[INFO] Apache Hadoop Archives............................ SUCCESS [9.522s]</p>
<p>[INFO] Apache Hadoop Rumen............................... SUCCESS [15.141s]</p>
<p>[INFO] Apache Hadoop Gridmix............................. SUCCESS [15.052s]</p>
<p>[INFO] Apache Hadoop Data Join........................... SUCCESS [8.621s]</p>
<p>[INFO] Apache Hadoop Extras.............................. SUCCESS [8.744s]</p>
<p>[INFO] Apache Hadoop Pipes............................... SUCCESS [28.645s]</p>
<p>[INFO] Apache Hadoop Tools Dist.......................... SUCCESS [6.238s]</p>
<p>[INFO] Apache Hadoop Tools............................... SUCCESS [0.126s]</p>
<p>[INFO] Apache Hadoop Distribution........................ SUCCESS [1:20.132s]</p>
<p>[INFO] Apache Hadoop Client.............................. SUCCESS [18.820s]</p>
<p>[INFO] Apache Hadoop Mini-Cluster........................ SUCCESS [2.151s]</p>
<p>[INFO]------------------------------------------------------------------------</p>
<p>[INFO] BUILD SUCCESS</p>
<p>[INFO]------------------------------------------------------------------------</p>
<p>[INFO] Total time: 29:07.811s</p>
<p>[INFO] Finished at: Thu Oct 24 09:43:18 CST2013</p>
<p>[INFO] Final Memory: 78M/239M</p>
<p>[INFO]------------------------------------------------------------------------</p>
<p><br></p>
<p>编译完后的文件位置：./hadoop-dist/target/下    hadoop-2.2.0.tar.gz</p>
<p><br></p>
<h3>使用用编译好的软件再执行一次</h3>
<p>[hadoop@hadoop01 input]$ hadoop dfs -put ./in</p>
<p>DEPRECATED: Use of this script to executehdfs command is deprecated.</p>
<p>Instead use the hdfs command for it.</p>
<p> </p>
<p>13/10/24 15:12:53 <span style="color:#FF0000;">WARNutil.NativeCodeLoader: Unable to load native-hadoop library for yourplatform... using builtin-java classes where applicable</span></p>
<p>put: `in': No such file or directory</p>
<p> </p>
<p>64位平台的问题解决了。还有1个问题，需要继续解决，参见我写的另外1个文章：</p>
<p> <a href="http://blog.csdn.net/bamuta/article/details/13506843" rel="nofollow">http://blog.csdn.net/bamuta/article/details/13506843</a></p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<br>            </div>
                </div>