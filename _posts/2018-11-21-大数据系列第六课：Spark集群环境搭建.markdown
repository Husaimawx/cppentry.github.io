---
layout:     post
title:      大数据系列第六课：Spark集群环境搭建
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p><span style="font-size:14px;">第一阶段：</span><span style="font-size:14px;font-family:'Times New Roman';">Spark streaming</span><span style="font-size:14px;font-family:'宋体';">、</span><span style="font-size:14px;font-family:'Times New Roman';">spark sql</span><span style="font-size:14px;font-family:'宋体';">、</span><span style="font-size:14px;font-family:'Times New Roman';">kafka</span><span style="font-size:14px;font-family:'宋体';">、</span><span style="font-size:14px;font-family:'Times New Roman';">spark</span><span style="font-size:14px;font-family:'宋体';">内核原</span><span style="font-size:14px;">
  理（必须有一个大型项目经验）；</span></p>
<p><span style="font-size:14px;">第二阶段：<span style="font-family:'Times New Roman';">spark</span><span style="font-family:'宋体';">运行的各种环境，各种故障的解决，性能</span>  优化（精通<span style="font-family:'Times New Roman';">spark</span><span style="font-family:'宋体';">内核、运行原理）；</span></span></p>
<p><span style="font-size:14px;">第三阶段：流处理、机器学习为鳌头，需要首先掌握前两个  阶段的内容；</span></p>
<p><span style="color:rgb(255,0,0);">跟随王家林老师的零基础讲解，注重动手实战，成为<span style="font-family:'Times New Roman';">spark</span><span style="font-family:'宋体';">高手，笑傲大数据之林！</span></span></p>
<p><span style="color:rgb(255,0,0);">第一部分：学习笔记</span></p>
<p>1 <span style="font-family:'宋体';">关于虚拟机与</span><span style="font-family:'Times New Roman';">Linux</span></p>
<p>2 Hadoop<span style="font-family:'宋体';">集群的搭建和配置</span></p>
<p>3 Spark<span style="font-family:'宋体';">集群的搭建和配置</span></p>
<p>4<span style="font-family:'宋体';">，讨论与作业</span></p>
<p><span style="font-family:'宋体';"></span></p>
<p>（1）首先安装<span style="font-family:'Times New Roman';">VMware Workstation12</span></p>
<img src="https://img-blog.csdn.net/20160108191315738?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br><p><span style="font-family:'宋体';">（2）安装好Ubuntu14：Master和Worker</span></p>
<p><span style="font-family:'宋体';"><img src="https://img-blog.csdn.net/20160108191538828?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p>
<p><span style="font-family:'宋体';">安装ssh（遇到如下问题）</span></p>
<p><span style="font-family:'宋体';"><img src="https://img-blog.csdn.net/20160108191813881?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p>
<p><span style="font-family:'宋体';"></span></p>
<p>1.一个彻底去掉这个提示的方法是，修改/etc/ssh/ssh_config文件（或$HOME/.ssh/config）中的配置，添加如下两行配置：</p>
<p><span></span>StrictHostKeyChecking no</p>
<p><span></span>UserKnownHostsFile /dev/null</p>
<p>修改/etc/ssh/sshd-config文件，将其中的PermitRootLogin no修改为yes，PubkeyAuthentication yes修改为no，AuthorizedKeysFile .ssh/authorized_keys前面加上#屏蔽掉，PasswordAuthentication no修改为yes就可以了。
</p>
<p>2. apt-get install aptitude </p>
<p>  aptitude install openssh-server</p>
<p>3.安装ssh无秘钥登录</p>
<p><img src="https://img-blog.csdn.net/20160108192341244?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></p>
（3）安装Java
<p><span style="font-family:'宋体';"><img src="https://img-blog.csdn.net/20160108192213650?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p>
<p><span style="font-family:'宋体';">Java -version后，显示Java版本</span></p>
<p><span style="font-family:'宋体';">（4）</span><span style="font-family:'宋体';">安装</span><span style="font-family:'Times New Roman';">Hadoop</span><span style="font-family:'宋体';">并运行</span><span style="font-family:'Times New Roman';">Wordcount</span><span style="font-family:'宋体';">程序</span></p>
<p><span style="font-family:'宋体';"><img src="https://img-blog.csdn.net/20160108192620130?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p>
<p><span style="font-family:'宋体';"></span></p>
<p>（5）配置伪分布式</p>
<p>core-site.xml</p>
<p>Mapred-site.xml</p>
<p>Hdfa-site.xml</p>
<img src="https://img-blog.csdn.net/20160108192939273?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br><p><span style="font-family:'宋体';">（7）安装Scala</span></p>
<p><span style="font-family:'宋体';"><img src="https://img-blog.csdn.net/20160108194344076?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p>
<p><span style="font-family:'宋体';">（8）安装启动Spark</span></p>
<p><span style="font-family:'宋体';"><img src="https://img-blog.csdn.net/20160108194620982?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p>
<p><span style="font-family:'宋体';"><img src="https://img-blog.csdn.net/20160108194740220?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p>
<p><span style="font-family:'宋体';">（9）测试Spark</span></p>
<p><span style="font-family:'宋体';"><img src="https://img-blog.csdn.net/20160108195328066?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p>
<p><span style="font-family:'宋体';">（10）SparkPi</span></p>
<p><span style="font-family:'宋体';"></span></p><pre><code class="language-java">object SparkPi {
  def main(args: Array[String]) {
    val conf = new SparkConf().setAppName("Spark Pi")
    val spark = new SparkContext(conf)
    val slices = if (args.length &gt; 0) args(0).toInt else 2
    val n = math.min(100000L * slices, Int.MaxValue).toInt // avoid overflow
    val count = spark.parallelize(1 until n, slices).map { i =&gt;
      val x = random * 2 - 1
      val y = random * 2 - 1
      if (x*x + y*y &lt; 1) 1 else 0
    }.reduce(_ + _)
    println("Pi is roughly " + 4.0 * count /</code></pre><br><br><p><span style="font-family:'宋体';"><br></span></p>
<p><span style="font-family:'宋体';"><br></span></p>
<p><span style="font-family:'宋体';"><br></span></p>
<p><span style="font-family:'宋体';"><br></span></p>
<p><span style="font-family:'宋体';"><br></span></p>
<p><span style="font-family:'宋体';"><br></span></p>
<p><span style="font-family:'宋体';"><br></span></p>
<p><span style="font-family:'宋体';"><br></span></p>
<p><span style="font-family:'宋体';"><br></span></p>
<p><span style="font-family:'宋体';"><br></span></p>
            </div>
                </div>