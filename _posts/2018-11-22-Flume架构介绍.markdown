---
layout:     post
title:      Flume架构介绍
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h3 id="flume架构介绍">Flume架构介绍</h3>

<ol>
<li><p>Flume概念</p>

<p>​        分布式的日志收集系统，将服务器中的数据收集起来送到指定的地方去，比如说hdfs</p>

<p><img src="https://img-blog.csdn.net/20170620221358612?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2FuZHJhX2NzZG4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p></li>
<li><p>Event概念</p>

<p>​       flume的核心是把数据从数据源(source)收集过来，再将收集到的数据送到指定的目的地(sink)。为了保证输送的过程一定成功，在送到目的地(sink)之前，会先缓存数据(channel),待数据真正到达目的地(sink)后，flume再删除自己缓存的数据。 </p>

<p>​        在整个数据的传输的过程中，流动的是event，即事务保证是在event级别进行的。那么什么是event呢？—–event将传输的数据进行封装，是flume传输数据的基本单位，如果是文本文件，通常是一行记录。event也是事务的基本单位。event从source，流向channel，再到sink，本身为一个字节数组，并可携带headers(头信息)信息。event代表着一个数据的最小完整单元，从外部数据源来，向外部的目的地去。</p>

<p><img src="https://img-blog.csdn.net/20170620221421207?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2FuZHJhX2NzZG4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>一个event=event header +event body+event信息</p></li>
<li><p>Flume架构介绍</p>

<p>Flume的逻辑架构：</p>

<p><img src="https://img-blog.csdn.net/20170620221436393?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2FuZHJhX2NzZG4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>分层架构：agent，collector和storage</p>

<p>flume使用两个组件：Master和Node，Node根据在Mastershell或web中动态配置，决定是作为Agent或Collector</p>

<p>1)   Agent：</p>

<p>运行在日志收集节点的java进程</p>

<p>agent三个核心组件：source-channel-sink  生产者-仓库-消费者</p>

<p>source：用来收集数据，各种格式avro、thrift、exec、jms、spooling、directory、netcat、sequence generator、syslog、http、legacy，自定义等。</p>

<p><a href="http://www.cnblogs.com/zhangmiao-chp/archive/2011/05/18/2050465.html" rel="nofollow">http://www.cnblogs.com/zhangmiaochp/archive/2011/05/18/2050465.html</a></p>

<p>channel：source组件把数据收集来以后，临时存放在channel中，即channel组件在agent中是专门用来存放临时数据的——对采集到的数据进行简单的缓存，可以存放在memory、jdbc、file等等。</p>

<p>Sink: sink组件是用于把数据发送到目的地的组件，目的地包括hdfs、logger、avro、thrift、ipc、file、null、Hbase、solr、自定义。</p>

<p><a href="http://www.cnblogs.com/zhangmiao-chp/archive/2011/05/18/2050472.html" rel="nofollow">http://www.cnblogs.com/zhangmiaochp/archive/2011/05/18/2050472.html</a></p>

<p>2）Collector</p>

<p>collector的作用是将多个agent的数据汇总后，加载到storage它的source和sink与agent类似</p>

<p>3）storage</p>

<p>storage是存储系统，可以是一个普通file，也可以是HDFS,HIVE,HBase</p>

<p>4）Master</p>

<p>Master是管理协调agent和collector的配置信息，是flume集群的控制器</p>

<p><strong>注：Flume框架对hadoop和zookeeper的依赖只是在jar包上，并不要求flume启动时必须将hadoop和zookeeper服务也启动。</strong></p></li>
<li><p>Flume的广义用法</p>

<p>flume之所以这么神奇—-其原因也在于flume可以支持多级flume的agent，即flume可以前后相继，例如sink可以将数据写到下一个agent的source中，这样的话就可以连成串了，可以整体处理了。flume还支持扇入(fan-in)、扇出(fan-out)。所谓扇入就是source可以接受多个输入，所谓扇出就是sink可以将数据输出多个目的地destination中。</p></li>
<li><p>Flume应用-日志采集</p>

<p>flume提供了大量内置的Source、Channel和Sink类型。而且不同类型的Source、Channel和Sink可以自由组合—–组合方式基于用户设置的配置文件，非常灵活。比如：Channel可以把事件暂存在内存里，也可以持久化到本地硬盘上。Sink可以把日志写入HDFS, HBase，甚至是另外一个Source等等。</p>

<p>flume使用方法：书写一个配置文件，在配置文件当中描述source、channel与sink的具体实现，而后运行一个agent实例，在运行agent实例的过程中会读取配置文件的内容，这样flume就会采集到数据</p>

<p>配置文件编写原则：</p>

<ol><li><p>整体上描述代理agent中sources、sinks、channels所涉及到的组件</p>

<blockquote>
  <p>a1.sources = r1</p>
  
  <p>a1.sinks = k1</p>
  
  <p>a1.channels = c1</p>
</blockquote></li>
<li><p>详细描述agent中每一个source、sink与channel的具体实现</p>

<p>​</p>

<blockquote>
  <p>describe/configure the source</p>
  
  <p>a1.sources.r1.type = netcat</p>
  
  <p>a1.sources.r1.bind = localhost</p>
  
  <p>a1.sources.r1.port = 44444</p>
  
  <p>#describe the sinl</p>
  
  <p>a1.sinks.k1.type = logger</p>
  
  <p>#use a channel with buffers events inmemory</p>
  
  <p>a1.resources.c1.type = memory</p>
  
  <p>a1.channels.c1.capacity = 1000</p>
  
  <p>a1.channels.c1.transactionCapacity = 100</p>
</blockquote></li>
<li><p>通过channel将source和sink连接起来</p>

<blockquote>
  <p>a1.sources.r1.channels = c1</p>
  
  <p>a1.sinks.k1.channel = c1</p>
</blockquote></li>
<li><p>启动agent的shell操作</p>

<blockquote>
  <p>flume-ng agent –n a1 –c ../conf –f../conf/example.file-Dflume.root.logger=DEBUG,console</p>
  
  <p>-n :指定agent的名称</p>
  
  <p>-c:指定flume中配置文件的目录</p>
  
  <p>-f:指定配置文件</p>
  
  <p>-Dflume.root.logger=DEBUG,console</p>
  
  <p>设置日志登记</p>
</blockquote></li></ol></li>
<li><p>设计目标</p>

<p>（1）  可靠性：当节点出现故障时，日志能够被传送到其他节点上而不会丢失。Flume提供了三种级别的可靠性保障，从强到弱依次分别为：end-to-end（收到数据agent首先将event写到磁盘上，当数据传送成功后，再删除；如果数据发送失败，可以重新发送。），Store on failure（这也是scribe采用的策略，当数据接收方crash时，将数据写到本地，待恢复后，继续发送），Best effort（数据发送到接收方后，不会进行确认）</p>

<p>（2）  可扩展性</p>

<p>Flume采用了三层架构，分别为agent，collector和storage，每一层均可以水平扩展。其中，所有agent和collector由master统一管理，这使得系统容易监控和维护，且master允许有多个（使用ZooKeeper进行管理和负载均衡），这就避免了单点故障问题。</p>

<p>（3）  可管理性</p>

<p>所有agent和colletor由master统一管理，这使得系统便于维护。多master情况，Flume利用ZooKeeper和gossip，保证动态配置数据的一致性。用户可以在master上查看各个数据源或者数据流执行情况，且可以对各个数据源配置和动态加载。Flume提供了web 和shell script command两种形式对数据流进行管理。</p></li>
</ol>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>