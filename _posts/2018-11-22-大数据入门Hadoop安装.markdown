---
layout:     post
title:      大数据入门Hadoop安装
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：自由云网络版权所有					https://blog.csdn.net/fpga_zy/article/details/81077877				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>解压hadoop<br>
    tar -zxvf h     -C app/<br>
hadoop文件目录结构解析:<br>
bin:可执行脚本<br>
sbin:系统脚本,启动停止hadoop的脚本<br>
etc:hadoop的配置文件<br>
lib:hadoop的本地库<br>
include:本地库包含文件<br>
share:包含了hadoop的jar包和一些说明文档,我们可以删除说明文档,精简hadoop</p>

<p><br>
进入hadoop的配置文件去更改设置<br>
    1.hadoop-env.sh(写死一个jkd的目录进去,因为有的时候找不见)<br>
    2.echo $JAVA_HOME<br>
    /home/hadoop/app/jdk1.7.0_65<br>
    2.本机的javahome为    /home/hadoop/app/jdk1.7.0_65<br>
    3.export JAVA_HOME=/home/hadoop/app/jdk1.7.0_65</p>

<p>伪分布式:就是所有的程序都在一台主机上跑,完全是分布式的工作模式,但是不是真正的分布式<br>
    先上传hadoop的安装包到服务器上去/home/hadoop/<br>
    注意：hadoop2.x的配置文件$HADOOP_HOME/etc/hadoop<br>
    伪分布式需要修改5个配置文件<br>
    3.1配置hadoop</p>

<p><br>
    第一个：hadoop-env.sh<br>
        vim hadoop-env.sh<br>
        #第27行<br>
        export JAVA_HOME=/home/hadoop/app/jdk1.7.0_65<br>
        <br>
    第二个：core-site.xml<br>
        &lt;!-- 指定HADOOP所使用的文件系统schema（URI），HDFS的老大（NameNode）的地址 --&gt;<br>
        vim core-site.xml<br>
        &lt;property&gt;<br>
            &lt;name&gt;fs.defaultFS&lt;/name&gt;<br>
            &lt;value&gt;hdfs://weekend110:9000/&lt;/value&gt;<br>
        &lt;/property&gt;<br>
        &lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;<br>
        &lt;property&gt;<br>
            &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;<br>
            &lt;value&gt;/home/hadoop/hadoop-2.4.1/data/&lt;/value&gt;<br>
    &lt;/property&gt;<br>
        </p>

<p>vi hdfs-site.xml</p>

<p>    第三个：hdfs-site.xml  <br>
        vim hdfs-site.xml<br>
        &lt;property&gt;<br>
            &lt;!-- 指定HDFS副本的数量 --&gt;<br>
            &lt;name&gt;dfs.replication&lt;/name&gt;<br>
            &lt;!-- 因为只有一台机器,所以配置为1 --&gt;<br>
            &lt;value&gt;1&lt;/value&gt;<br>
    &lt;/property&gt;<br>
        <br>
        yaant运行必须的配置文件<br>
        首先修改文件呢的名字,不然hadoop不会读取的</p>

<p>    第四个：mapred-site.xml (mv mapred-site.xml.template mapred-site.xml)</p>

<p>        mv mapred-site.xml.template mapred-site.xml<br>
        vim mapred-site.xml<br>
        &lt;!-- 指定mr运行在yarn上 --&gt;<br>
        &lt;property&gt;<br>
            &lt;name&gt;mapreduce.framework.name&lt;/name&gt;<br>
            &lt;value&gt;yarn&lt;/value&gt;<br>
        &lt;/property&gt;<br>
        <br>
    第五个：yarn-site.xml<br>
    vim yarn-site.xml<br>
        &lt;!-- 指定YARN的老大（ResourceManager）的地址 --&gt;<br>
        &lt;property&gt;<br>
            &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;<br>
            &lt;value&gt;weekend110&lt;/value&gt;<br>
    &lt;/property&gt;<br>
        &lt;!-- reducer获取数据的方式 --&gt;<br>
    &lt;property&gt;<br>
            &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;<br>
            &lt;value&gt;mapreduce_shuffle&lt;/value&gt;<br>
     &lt;/property&gt;</p>

<p>     现在关闭Hadoop服务器的防火墙:<br>
     sudo service iptables stop<br>
     查看状态<br>
     sudo service iptables status<br>
     </p>

<p>     查看Liunx防火墙的自启动服务设置<br>
         sudo chkconfig iptables --list<br>
    关掉Liunx防火墙的自启动服务设置<br>
         sudo chkconfig iptables off</p>

<p>     第一次启动注意要格式化文件系统</p>

<p><br>
     方便执行bin下的指令<br>
    3.2将hadoop添加到环境变量<br>
    <br>
    sudo vi /etc/profile<br>
        export HADOOP_HOME=/home/hadoop/app/hadoop-2.4.1<br>
        export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</p>

<p>    source /etc/profile<br>
    <br>
    hadoop namenode -format</p>

<p>    3.3格式化namenode（是对namenode进行初始化）<br>
        hdfs namenode -format (hadoop namenode -format)<br>
        修改主机名称<br>
        vi sla</p>

<p>    3.4启动hadoop<br>
        先启动HDFS<br>
        sbin/start-dfs.sh<br>
        <br>
        再启动YARN<br>
        sbin/start-yarn.sh<br>
        <br>
    3.5验证是否启动成功<br>
        jps<br>
        使用jps命令验证<br>
        27408 NameNode<br>
        28218 Jps<br>
        27643 SecondaryNameNode<br>
        28066 NodeManager<br>
        27803 ResourceManager<br>
        27512 DataNode<br>
    <br>
        http://192.168.2.100:50070 （HDFS管理界面）<br>
        http://192.168.2.100:8088 （MR管理界面）<br>
        </p>

<p>        <br>
4.配置ssh免登陆<br>
    #生成ssh免登陆密钥<br>
    #进入到我的home目录<br>
    cd ~/.ssh</p>

<p>    ssh-keygen -t rsa （四个回车）<br>
    执行完这个命令后，会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）<br>
    将公钥拷贝到要免登陆的机器上<br>
    ssh-copy-id localhost</p>

<p>hadoop</p>            </div>
                </div>