---
layout:     post
title:      【十八掌●武功篇】第十二掌：Flume之安装和测试使用
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/chybin500/article/details/78680263				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p><strong>这一篇博文是【大数据技术●降龙十八掌】系列文章的其中一篇，点击查看目录：<img src="https://img-blog.csdn.net/20171116204808649?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2h5YmluNTAw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""><a href="http://blog.csdn.net/chybin500/article/details/78551867" rel="nofollow">大数据技术●降龙十八掌</a><strong></strong></strong></p>

<hr>

<dl>
<dt>系列文章：</dt>
<dd><a href="http://blog.csdn.net/chybin500/article/details/78678517" rel="nofollow">【十八掌●武功篇】第十二掌：Flume之工作原理与使用</a> <br>
<a href="http://blog.csdn.net/chybin500/article/details/78680152" rel="nofollow">【十八掌●武功篇】第十二掌：Flume之Source、Channel、Sink</a> <br>
<a href="http://blog.csdn.net/chybin500/article/details/78680263" rel="nofollow">【十八掌●武功篇】第十二掌：Flume之安装和测试使用</a></dd>
</dl>

<p>选用CDH版本的Flume</p>



<h4 id="1-下载flume安装包">1、 下载Flume安装包</h4>

<p><a href="http://archive.cloudera.com/cdh5/cdh/5/flume-ng-1.5.0-cdh5.3.6.tar.gz" rel="nofollow">http://archive.cloudera.com/cdh5/cdh/5/flume-ng-1.5.0-cdh5.3.6.tar.gz</a></p>



<h4 id="2-解压安装包">2、 解压安装包</h4>

<p>tar -zxvf /opt/software/flume-ng-1.5.0-cdh5.3.6.tar.gz -C /opt/modules/</p>



<h4 id="3-配置">3、 配置</h4>

<p>拷贝配置文件 <br>
cp flume-env.sh.template flume-env.sh <br>
cp flume-conf.properties.template flume-conf.properties <br>
配置flume-env.sh <br>
export JAVA_HOME=/opt/modules/jdk1.7.0_67</p>



<h4 id="4-测试运行netcat-source-memory-channel-logger-sink">4、 测试运行（netcat source + memory channel + logger sink）</h4>

<p>这个例子中source类型为netcat（监听Socket）、channel类型为memory（存入内存）、sink类型为logger（写入日志），结构图如下所示：</p>

<p><img src="https://img-blog.csdn.net/20171130195936245?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2h5YmluNTAw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>(1) 配置source、channel、sink。官网有个例子如下：</p>



<pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment"># example.conf: A single-node Flume configuration</span>

<span class="hljs-comment"># Name the components on this agent</span>
<span class="hljs-comment">#a1是agent名称。</span>
<span class="hljs-comment">#a1.sources执行名为a1的agent的source是哪些，如果有多个，就在r1后面添加一个空格后，添加第二个名称</span>
<span class="hljs-comment">#a1.sources=r1 r2 r3</span>
a1.sources = r1
a1.sinks = k1
a1.channels = c1

<span class="hljs-comment"># Describe/configure the source</span>
<span class="hljs-comment">#r1.type是netcat，是个socket服务器</span>
a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = <span class="hljs-number">44444</span>

<span class="hljs-comment"># Describe the sink</span>
<span class="hljs-comment">#写到日志里去</span>
a1.sinks.k1.type = logger

<span class="hljs-comment"># Use a channel which buffers events in memory</span>
<span class="hljs-comment">#c1.type是memory是将数据放入内存</span>
a1.channels.c1.type = memory
a1.channels.c1.capacity = <span class="hljs-number">1000</span>
a1.channels.c1.transactionCapacity = <span class="hljs-number">100</span>

<span class="hljs-comment"># Bind the source and sink to the channel</span>
<span class="hljs-comment">#将source、channel、sink连接起来</span>
<span class="hljs-comment">#sources可以将数据传入多个channel</span>
<span class="hljs-comment">#sinks只能从一个channel里读取数据</span>
<span class="hljs-comment">#channel可以将数据发送到多个sink中</span>
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
<span class="hljs-comment"># example.conf: A single-node Flume configuration</span>

<span class="hljs-comment"># Name the components on this agent</span>
<span class="hljs-comment">#a1是agent名称。</span>
<span class="hljs-comment">#a1.sources执行名为a1的agent的source是哪些，如果有多个，就在r1后面添加一个空格后，添加第二个名称</span>
<span class="hljs-comment">#a1.sources=r1 r2 r3</span>
a1.sources = r1
a1.sinks = k1
a1.channels = c1

<span class="hljs-comment"># Describe/configure the source</span>
<span class="hljs-comment">#r1.type是netcat，是个socket服务器</span>
a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = <span class="hljs-number">44444</span>

<span class="hljs-comment"># Describe the sink</span>
<span class="hljs-comment">#写到日志里去</span>
a1.sinks.k1.type = logger

<span class="hljs-comment"># Use a channel which buffers events in memory</span>
<span class="hljs-comment">#c1.type是memory是将数据放入内存</span>
a1.channels.c1.type = memory
a1.channels.c1.capacity = <span class="hljs-number">1000</span>
a1.channels.c1.transactionCapacity = <span class="hljs-number">100</span>

<span class="hljs-comment"># Bind the source and sink to the channel</span>
<span class="hljs-comment">#将source、channel、sink连接起来</span>
<span class="hljs-comment">#sources可以将数据传入多个channel</span>
<span class="hljs-comment">#sinks只能从一个channel里读取数据</span>
<span class="hljs-comment">#channel可以将数据发送到多个sink中</span>
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
</code></pre>

<p>在conf目录下创建一个配置文件：demo.conf，将上面的配置内容拷贝到demo.conf配置文件中。</p>

<p>(2) 启动flume agent：</p>

<p>/opt/modules/apache-flume-1.5.0-cdh5.3.6-bin/bin/flume-ng agent –name a1 –conf conf/ –conf-file conf/demo.conf -Dflume.root.logger=INFO,console <br>
使用bin目录下的flume-ng脚本启动agent； <br>
–name是agent的名称，要跟配置文件demo.conf中定义的agent名称一致。 <br>
–conf是指定flume的配置文件路径，注意并不是flume agent的配置文件。 <br>
–conf-file是指定flume agent的配置文件路径。 <br>
–Dflume.root.logger是指定打印的日志。 <br>
启动后，是处于阻塞状态的，这个agent的source是个socket，所以在等待socket输入。</p>

<p>(3) 查看44444端口是否已经成功启动：</p>

<p>netstat -tlnup |grep 44444</p>

<p>(4) 测试发送信息</p>

<p>使用nc工具发送socket信息： <br>
nc localhost 44444 <br>
在flume agent的窗口可以看到Flume的sink已经输出到了发送的数据。</p>



<h4 id="5-测试运行avro-source-file-channel-hdfs-sink">5、 测试运行（avro source + file channel + hdfs sink ）</h4>

<p>(1) 结构图如下所示：</p>

<p><img src="https://img-blog.csdn.net/20171130200106880?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2h5YmluNTAw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>(2) 配置如下：</p>



<pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment"># example.conf: A single-node Flume configuration</span>

<span class="hljs-comment"># Name the components on this agent</span>
<span class="hljs-comment">#a1是agent名称。</span>
<span class="hljs-comment">#a1.sources执行名为a1的agent的source是哪些，如果有多个，就在r1后面添加一个空格后，添加第二个名称</span>
<span class="hljs-comment">#a1.sources=r1 r2 r3</span>
a1.sources = r1
a1.sinks = k1
a1.channels = c1

<span class="hljs-comment"># Describe/configure the source</span>
<span class="hljs-comment">#配置source类型为avro,avro服务在本地，端口号为4141</span>
a1.sources.r1.type = avro
a1.sources.r1.bind = localhost
a1.sources.r1.port = <span class="hljs-number">4141</span>

<span class="hljs-comment"># Describe the sink</span>
<span class="hljs-comment">#配置sink类型为hdfs、文件写入的路径</span>
a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.path = hdfs://bigdata-<span class="hljs-number">51</span>cdh.chybinmy.com:<span class="hljs-number">8020</span>/flume/demo
<span class="hljs-comment"># default:FlumeData</span>
<span class="hljs-comment">#定义hdfs文件名的前缀</span>
a1.sinks.k1.hdfs.filePrefix = my-
<span class="hljs-comment">#配置是否使用本地时间戳，应该设置为true</span>
a1.sinks.k1.hdfs.useLocalTimeStamp = true
<span class="hljs-comment">#文件达到什么条件后创建一个新的文件，rollInterval、rollCount、rollSize只能选其一</span>
<span class="hljs-comment">#rollInterval是当间隔多长时间分割一个新的文件，如果是0就是不启用这个策略</span>
a1.sinks.k1.hdfs.rollInterval = <span class="hljs-number">0</span>
<span class="hljs-comment">#rollCount是写入的次数，达到指定次数后就新建一个文件</span>
a1.sinks.k1.hdfs.rollCount = <span class="hljs-number">0</span>
<span class="hljs-comment">#rollSize是文件大小，当文件达到指定大小后就新建一个文件</span>
a1.sinks.k1.hdfs.rollSize = <span class="hljs-number">10240</span>
<span class="hljs-comment">#文件格式，可以选择的有：SequenceFile、DataStream、CompressedStream</span>
<span class="hljs-comment">#SequenceFile是键值对形式的数据</span>
<span class="hljs-comment">#DataStream是文本类型的数据</span>
<span class="hljs-comment">#CompressedStream是压缩格式的数据，这种格式下，需要设置压缩格式。</span>
a1.sinks.k1.hdfs.fileType = DataStream

<span class="hljs-comment"># Use a channel which buffers events in memory</span>
<span class="hljs-comment">#c1.type是file是将数据放入文件中</span>
a1.channels.c1.type = file
<span class="hljs-comment">#设置file channel的checkpoint目录</span>
a1.channels.c1.checkpointDir = /opt/modules/apache-flume-<span class="hljs-number">1.5</span><span class="hljs-number">.0</span>-cdh5<span class="hljs-number">.3</span><span class="hljs-number">.6</span>-bin/my_check_file
<span class="hljs-comment">#设置file存储的目录</span>
a1.channels.c1.dataDirs = /opt/modules/apache-flume-<span class="hljs-number">1.5</span><span class="hljs-number">.0</span>-cdh5<span class="hljs-number">.3</span><span class="hljs-number">.6</span>-bin/my_data

<span class="hljs-comment"># Bind the source and sink to the channel</span>
<span class="hljs-comment">#将source、channel、sink连接起来</span>
<span class="hljs-comment">#sources可以将数据传入多个channel</span>
<span class="hljs-comment">#sinks只能从一个channel里读取数据</span>
<span class="hljs-comment">#channel可以将数据发送到多个sink中</span>
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
</code></pre>

<p>(3) 启动agent</p>



<pre class="prettyprint"><code class="language-sh hljs lasso">/opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/bin/flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-attribute">-name</span> a1 <span class="hljs-attribute">-c</span> /opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/conf<span class="hljs-subst">/</span> <span class="hljs-attribute">-conf</span><span class="hljs-attribute">-file</span> /opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/conf/demo2<span class="hljs-built_in">.</span>conf <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>INFO,console</code></pre>

<p>(4) 检查端口4141是否启动</p>

<p>netstat -tlnup | grep 4141</p>

<p>(5) 发送avro数据</p>

<p>/opt/modules/apache-flume-1.5.0-cdh5.3.6-bin/bin/flume-ng avro-client -H localhost -p 4141 -F /home/hadoop/input.txt <br>
使用flume自带的avro client将文件input.txt发送到4141端口，flume的avro source接受到数据后，通过file channel，使用hdfs sink发送到配置到好的hdfs路径上去。</p>

<p>(6) 查看HDFS的数据</p>

<p>hadoop fs -ls hdfs://bigdata-51cdh.chybinmy.com:8020/flume/demo <br>
hadoop fs -cat /flume/demo/my-.1502151699610.tmp</p>



<h4 id="6-测试运行spooldir-source-memory-channel-hdfs-sink">6、 测试运行（spooldir source + memory channel + hdfs sink ）</h4>

<p>(1) 结构图如下所示</p>

<p><img src="https://img-blog.csdn.net/20171130200225298?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2h5YmluNTAw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>(2) 配置如下</p>



<pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment"># example.conf: A single-node Flume configuration</span>

<span class="hljs-comment"># Name the components on this agent</span>
<span class="hljs-comment">#a1是agent名称。</span>
<span class="hljs-comment">#a1.sources执行名为a1的agent的source是哪些，如果有多个，就在r1后面添加一个空格后，添加第二个名称</span>
<span class="hljs-comment">#a1.sources=r1 r2 r3</span>
a1.sources = r1
a1.sinks = k1
a1.channels = c1

<span class="hljs-comment"># Describe/configure the source</span>
<span class="hljs-comment">#配置source类型为spooldir,监控本地目录，一有新的文件就读取</span>
a1.sources.r1.type = spooldir
<span class="hljs-comment">#要监控的目录</span>
a1.sources.r1.spoolDir = /opt/modules/apache-flume-<span class="hljs-number">1.5</span><span class="hljs-number">.0</span>-cdh5<span class="hljs-number">.3</span><span class="hljs-number">.6</span>-bin/myspoolfils
<span class="hljs-comment">#是否将信息头里的信息放入</span>
a1.sources.r1.fileHeader = true
a1.sources.r1.fileHeaderKey = file

<span class="hljs-comment"># Describe the sink</span>
<span class="hljs-comment">#配置sink类型为hdfs、文件写入的路径</span>
a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.path = hdfs://bigdata-<span class="hljs-number">51</span>cdh.chybinmy.com:<span class="hljs-number">8020</span>/flume/spoolfile
<span class="hljs-comment"># default:FlumeData</span>
<span class="hljs-comment">#定义hdfs文件名的前缀</span>
a1.sinks.k1.hdfs.filePrefix = spoolfile -
<span class="hljs-comment">#配置是否使用本地时间戳，应该设置为true</span>
a1.sinks.k1.hdfs.useLocalTimeStamp = true
<span class="hljs-comment">#文件达到什么条件后创建一个新的文件，rollInterval、rollCount、rollSize只能选其一</span>
<span class="hljs-comment">#rollInterval是当间隔多长时间分割一个新的文件，如果是0就是不启用这个策略</span>
a1.sinks.k1.hdfs.rollInterval = <span class="hljs-number">0</span>
<span class="hljs-comment">#rollCount是写入的次数，达到指定次数后就新建一个文件</span>
a1.sinks.k1.hdfs.rollCount = <span class="hljs-number">0</span>
<span class="hljs-comment">#rollSize是文件大小，当文件达到指定大小后就新建一个文件</span>
a1.sinks.k1.hdfs.rollSize = <span class="hljs-number">10240</span>
<span class="hljs-comment">#文件格式，可以选择的有：SequenceFile、DataStream、CompressedStream</span>
<span class="hljs-comment">#SequenceFile是键值对形式的数据</span>
<span class="hljs-comment">#DataStream是文本类型的数据</span>
<span class="hljs-comment">#CompressedStream是压缩格式的数据，这种格式下，需要设置压缩格式。</span>
a1.sinks.k1.hdfs.fileType = DataStream

<span class="hljs-comment"># Use a channel which buffers events in memory</span>
<span class="hljs-comment">#c1.type是memory是将数据放入内存中</span>
a1.channels.c1.type = memory
a1.channels.c1.capacity = <span class="hljs-number">1000</span>
a1.channels.c1.transactionCapacity = <span class="hljs-number">100</span>

<span class="hljs-comment"># Bind the source and sink to the channel</span>
<span class="hljs-comment">#将source、channel、sink连接起来</span>
<span class="hljs-comment">#sources可以将数据传入多个channel</span>
<span class="hljs-comment">#sinks只能从一个channel里读取数据</span>
<span class="hljs-comment">#channel可以将数据发送到多个sink中</span>
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

</code></pre>

<p>(3) 启动agent</p>



<pre class="prettyprint"><code class="language-sh hljs lasso">/opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/bin/flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-attribute">-name</span> a1 <span class="hljs-attribute">-c</span> /opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/conf<span class="hljs-subst">/</span> <span class="hljs-attribute">-conf</span><span class="hljs-attribute">-file</span> /opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/conf/demo3<span class="hljs-built_in">.</span>conf <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>INFO,console</code></pre>

<p>(4) 将文件拷贝进监听目录</p>

<p>cp /home/hadoop/actionlog2016-08-20.txt /opt/modules/apache-flume-1.5.0-cdh5.3.6-bin/myspoolfils/</p>

<p>(5) 查看HDFS文件</p>

<p>hadoop fs -ls /flume/spoolfile <br>
spoolfile source监听目录，有了新文件就读取后存入hdfs上指定的目录中。</p>



<h4 id="7-测试运行多个agent汇集到一个agent">7、 测试运行（多个agent汇集到一个agent）</h4>

<p>(1) 结构</p>

<p>三个agent：http source + memory channel + avro sink <br>
汇集agent：avro source + file channel + hdfs sink</p>

<p><img src="https://img-blog.csdn.net/20171130200335600?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2h5YmluNTAw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>(2) 配置 <br>
a1、a2、a3配置如下：（注意a2、a3要将agent名字应该分别为a3、a4，另外http source监听的端口号应该不同）</p>



<pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment"># example.conf: A single-node Flume configuration</span>

<span class="hljs-comment"># Name the components on this agent</span>
<span class="hljs-comment">#a1是agent名称。</span>
<span class="hljs-comment">#a1.sources执行名为a1的agent的source是哪些，如果有多个，就在r1后面添加一个空格后，添加第二个名称</span>
<span class="hljs-comment">#a1.sources=r1 r2 r3</span>
a1.sources = r1
a1.sinks = k1
a1.channels = c1

<span class="hljs-comment"># Describe/configure the source</span>
<span class="hljs-comment">#配置source类型为http,监控一个端口的http请求</span>
a1.sources.r1.type = http
<span class="hljs-comment">#a1监听的是5140端口,a2、a3应该监听其他端口号，比如a2监听5141，a3监听5142</span>
a1.sources.r1.port = <span class="hljs-number">5140</span>
<span class="hljs-comment">#数据格式为json</span>
a1.sources.r1.handler = org.apache.flume.source.http.JSONHandler

<span class="hljs-comment"># Describe the sink</span>
<span class="hljs-comment">#配置sink类型为avro，以便传递给下一个汇集agent a4</span>
a1.sinks.k1.type = avro
<span class="hljs-comment">#传递给avro的主机</span>
a1.sinks.k1.hostname = localhost
<span class="hljs-comment">#avro的端口号</span>
a1.sinks.k1.port = <span class="hljs-number">4545</span>

<span class="hljs-comment"># Use a channel which buffers events in memory</span>
<span class="hljs-comment">#c1.type是memory是将数据放入内存中</span>
a1.channels.c1.type = memory
a1.channels.c1.capacity = <span class="hljs-number">1000</span>
a1.channels.c1.transactionCapacity = <span class="hljs-number">100</span>

<span class="hljs-comment"># Bind the source and sink to the channel</span>
<span class="hljs-comment">#将source、channel、sink连接起来</span>
<span class="hljs-comment">#sources可以将数据传入多个channel</span>
<span class="hljs-comment">#sinks只能从一个channel里读取数据</span>
<span class="hljs-comment">#channel可以将数据发送到多个sink中</span>
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
</code></pre>

<p>a4配置</p>



<pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment"># example.conf: A single-node Flume configuration</span>

<span class="hljs-comment"># Name the components on this agent</span>
<span class="hljs-comment">#a4是agent名称。</span>
<span class="hljs-comment">#a4.sources执行名为a4的agent的source是哪些，如果有多个，就在r1后面添加一个空格后，添加第二个名称</span>
<span class="hljs-comment">#a4.sources=r1 r2 r3</span>
a4.sources = r1
a4.sinks = k1
a4.channels = c1

<span class="hljs-comment"># Describe/configure the source</span>
<span class="hljs-comment">#配置source类型为avro,avro服务在本地，端口号为4141</span>
a4.sources.r1.type = avro
a4.sources.r1.bind = localhost
a4.sources.r1.port = <span class="hljs-number">4545</span>

<span class="hljs-comment"># Describe the sink</span>
<span class="hljs-comment">#配置sink类型为hdfs、文件写入的路径</span>
a4.sinks.k1.type = hdfs
a4.sinks.k1.hdfs.path = hdfs://bigdata-<span class="hljs-number">51</span>cdh.chybinmy.com:<span class="hljs-number">8020</span>/flume/collect/%Y-%m-%d
<span class="hljs-comment"># default:FlumeData</span>
<span class="hljs-comment">#定义hdfs文件名的前缀</span>
a4.sinks.k1.hdfs.filePrefix = collect-
<span class="hljs-comment">#配置是否使用本地时间戳，应该设置为true</span>
a4.sinks.k1.hdfs.useLocalTimeStamp = true
<span class="hljs-comment">#文件达到什么条件后创建一个新的文件，rollInterval、rollCount、rollSize只能选其一</span>
<span class="hljs-comment">#rollInterval是当间隔多长时间分割一个新的文件，如果是0就是不启用这个策略</span>
a4.sinks.k1.hdfs.rollInterval = <span class="hljs-number">0</span>
<span class="hljs-comment">#rollCount是写入的次数，达到指定次数后就新建一个文件</span>
a4.sinks.k1.hdfs.rollCount = <span class="hljs-number">0</span>
<span class="hljs-comment">#rollSize是文件大小，当文件达到指定大小后就新建一个文件</span>
a4.sinks.k1.hdfs.rollSize = <span class="hljs-number">10240</span>
<span class="hljs-comment">#文件格式，可以选择的有：SequenceFile、DataStream、CompressedStream</span>
<span class="hljs-comment">#SequenceFile是键值对形式的数据</span>
<span class="hljs-comment">#DataStream是文本类型的数据</span>
<span class="hljs-comment">#CompressedStream是压缩格式的数据，这种格式下，需要设置压缩格式。</span>
a4.sinks.k1.hdfs.fileType = DataStream

<span class="hljs-comment"># Use a channel which buffers events in memory</span>
<span class="hljs-comment">#c1.type是memory是将数据放入内存中</span>
<span class="hljs-comment">#c1.type是file是将数据放入文件中</span>
a4.channels.c1.type = file
<span class="hljs-comment">#设置file channel的checkpoint目录</span>
a4.channels.c1.checkpointDir = /opt/modules/apache-flume-<span class="hljs-number">1.5</span><span class="hljs-number">.0</span>-cdh5<span class="hljs-number">.3</span><span class="hljs-number">.6</span>-bin/my_check_file
<span class="hljs-comment">#设置file存储的目录</span>
a4.channels.c1.dataDirs = /opt/modules/apache-flume-<span class="hljs-number">1.5</span><span class="hljs-number">.0</span>-cdh5<span class="hljs-number">.3</span><span class="hljs-number">.6</span>-bin/my_data

<span class="hljs-comment"># Bind the source and sink to the channel</span>
<span class="hljs-comment">#将source、channel、sink连接起来</span>
<span class="hljs-comment">#sources可以将数据传入多个channel</span>
<span class="hljs-comment">#sinks只能从一个channel里读取数据</span>
<span class="hljs-comment">#channel可以将数据发送到多个sink中</span>
a4.sources.r1.channels = c1
a4.sinks.k1.channel = c1
</code></pre>

<p>(3) 启动agent</p>



<pre class="prettyprint"><code class="language-sh hljs lasso">/opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/bin/flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-attribute">-n</span> a1 <span class="hljs-attribute">-c</span> /opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/conf<span class="hljs-subst">/</span> <span class="hljs-attribute">-f</span> /opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/conf/a1<span class="hljs-built_in">.</span>conf <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>INFO,console <span class="hljs-subst">&amp;</span>
/opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/bin/flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-attribute">-n</span> a2 <span class="hljs-attribute">-c</span> /opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/conf<span class="hljs-subst">/</span> <span class="hljs-attribute">-f</span> /opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/conf/a2<span class="hljs-built_in">.</span>conf <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>INFO,console <span class="hljs-subst">&amp;</span>
/opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/bin/flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-attribute">-n</span> a3 <span class="hljs-attribute">-c</span> /opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/conf<span class="hljs-subst">/</span> <span class="hljs-attribute">-f</span> /opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/conf/a3<span class="hljs-built_in">.</span>conf <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>INFO,console <span class="hljs-subst">&amp;</span>
/opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/bin/flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-attribute">-n</span> a4 <span class="hljs-attribute">-c</span> /opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/conf<span class="hljs-subst">/</span> <span class="hljs-attribute">-f</span> /opt/modules/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-attribute">-bin</span>/conf/a4<span class="hljs-built_in">.</span>conf <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>INFO,console <span class="hljs-subst">&amp;</span>
</code></pre>

<p>(4) 发送post 请求</p>



<pre class="prettyprint"><code class="language-sh hljs erlang">curl -<span class="hljs-variable">X</span> <span class="hljs-variable">POST</span> -d'[<span class="hljs-tuple">{<span class="hljs-string">"headers"</span> : <span class="hljs-tuple">{<span class="hljs-string">"timestamp"</span> : <span class="hljs-string">"434324343"</span>,<span class="hljs-string">"host"</span> :<span class="hljs-string">"random_host.example.com"</span>}</span>,<span class="hljs-string">"body"</span> : <span class="hljs-string">"random_body"</span>}</span>,<span class="hljs-tuple">{<span class="hljs-string">"headers"</span> : <span class="hljs-tuple">{<span class="hljs-string">"namenode"</span> : <span class="hljs-string">"namenode.example.com"</span>,<span class="hljs-string">"datanode"</span> :<span class="hljs-string">"random_datanode.example.com"</span>}</span>,<span class="hljs-string">"body"</span> :<span class="hljs-string">"really_random_body"</span>}</span>]' localhost:<span class="hljs-number">5140</span></code></pre>

<p>(5) 查看HDFS上数据</p>

<p>hadoop fs -ls /flume/collect/2017-08-08 <br>
hadoop fs -cat /flume/collect/2017-08-08/collect-.1502177104663.tmp</p>

<hr>

<p><strong>这一篇博文是【大数据技术●降龙十八掌】系列文章的其中一篇，点击查看目录：<img src="https://img-blog.csdn.net/20171116204808649?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2h5YmluNTAw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""><a href="http://blog.csdn.net/chybin500/article/details/78551867" rel="nofollow">大数据技术●降龙十八掌</a><strong></strong></strong></p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>