---
layout:     post
title:      Spark-sql 入门
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/qq_21989939/article/details/79485061				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h1><strong>2<span style="font-family:'宋体';">、</span><span style="font-family:'Times New Roman';">Spark SQL</span></strong></h1><h2><strong>2.1<span style="font-family:'黑体';">、</span><span style="font-family:Arial;">Spark SQL</span><span style="font-family:'黑体';">概述</span></strong></h2><h3><strong>2.1.1<span style="font-family:'宋体';">、什么是</span><span style="font-family:'Times New Roman';">Spark SQL</span></strong></h3><p> </p><p>Spark SQL<span style="font-family:'宋体';">是</span><span style="font-family:'Times New Roman';">Spark</span><span style="font-family:'宋体';">用来处理结构化数据的一个模块，它提供了一个编程抽象叫做</span><span style="font-family:'Times New Roman';">DataFrame</span><span style="font-family:'宋体';">并且作为分布式</span><span style="font-family:'Times New Roman';">SQL</span><span style="font-family:'宋体';">查询引擎的作用。</span></p><h3><strong>2.1.2<span style="font-family:'宋体';">、为什么要学习</span><span style="font-family:'Times New Roman';">Spark SQL</span></strong></h3><p><span style="font-family:'宋体';">我们已经学习了</span>Hive<span style="font-family:'宋体';">，它是将</span><span style="font-family:'Times New Roman';">Hive SQL</span><span style="font-family:'宋体';">转换成</span><span style="font-family:'Times New Roman';">MapReduce</span><span style="font-family:'宋体';">然后提交到集群上执行，大大简化了编写</span><span style="font-family:'Times New Roman';">MapReduce</span><span style="font-family:'宋体';">的程序的复杂性，由于</span><span style="font-family:'Times New Roman';">MapReduce</span><span style="font-family:'宋体';">这种计算模型执行效率比较慢。所有</span><span style="font-family:'Times New Roman';">Spark SQL</span><span style="font-family:'宋体';">的应运而生，它是将</span><span style="font-family:'Times New Roman';">Spark SQL</span><span style="font-family:'宋体';">转换成</span><span style="font-family:'Times New Roman';">RDD</span><span style="font-family:'宋体';">，然后提交到集群执行，执行效率非常快！</span></p><p>1.<span style="font-family:'宋体';">易整合</span></p><p> </p><p>2.统一的数据访问方式</p><p> </p><p>3.<span style="font-family:'宋体';">兼容</span>Hive</p><p> </p><p>4.标准的数据连接</p><p> </p><h2><strong>2.2<span style="font-family:'黑体';">、</span><span style="font-family:Arial;">DataFrames</span></strong></h2><h3><strong>2.2.1<span style="font-family:'宋体';">、什么是</span><span style="font-family:'Times New Roman';">DataFrames</span></strong></h3><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:Helvetica;">与</span>RDD类似，DataFrame也是一个分布式数据容器。然而DataFrame更像传统数据库的二维表格，除了数据以外，还</span><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:'宋体';">记录</span></span><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:Helvetica;">数据的结构信息，即</span>schema。同时，与Hive类似，DataFrame也支持嵌套数据类型（struct、array和map）。从API易用性的角度上 看，DataFrame API提供的是一套高层的关系操作，比函数式的RDD API要更加友好，门槛更低。由于与R和Pandas的DataFrame类似，Spark DataFrame很好地继承了传统单机数据分析的开发体验。</span></p><p> </p><h3><strong>2.2.2<span style="font-family:'宋体';">、创建</span><span style="font-family:'Times New Roman';">DataFrames</span></strong></h3><p> 在Spark SQL<span style="font-family:'宋体';">中</span>SQLContext是创建DataFrames<span style="font-family:'宋体';">和执行</span><span style="font-family:'Times New Roman';">SQL</span><span style="font-family:'宋体';">的入口，在</span><span style="font-family:'Times New Roman';">spark-1.5.2</span><span style="font-family:'宋体';">中已经内置了一个</span><strong>sqlContext</strong></p><p><strong> </strong></p><p>1.<span style="font-family:'宋体';">在本地创建一个文件，有三列，分别是</span>id<span style="font-family:'宋体';">、</span><span style="font-family:'Times New Roman';">name</span><span style="font-family:'宋体';">、</span><span style="font-family:'Times New Roman';">age</span><span style="font-family:'宋体';">，用空格分隔，然后上传到</span><span style="font-family:'Times New Roman';">hdfs</span><span style="font-family:'宋体';">上</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">hdfs dfs -put person.txt /</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><p>2.<span style="font-family:'宋体';">在</span><span style="font-family:'Times New Roman';">spark shell</span><span style="font-family:'宋体';">执行下面命令，读取数据，将每一行的数据使用列分隔符分割</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">val lineRDD = sc.textFile("hdfs://node1.itcast.cn:9000/person.txt").map(_.split(" "))</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><p>3.<span style="font-family:'宋体';">定义</span><span style="font-family:'Times New Roman';">case class</span><span style="font-family:'宋体';">（相当于表的</span><span style="font-family:'Times New Roman';">schema</span><span style="font-family:'宋体';">）</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">case class Person(id:Int, name:String, age:Int)</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><p>4.<span style="font-family:'宋体';">将</span>RDD<span style="font-family:'宋体';">和</span><span style="font-family:'Times New Roman';">case class</span><span style="font-family:'宋体';">关联</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">val personRDD = lineRDD.map(x =&gt; Person(x(0).toInt, x(1), x(2).toInt))</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><p>5.<span style="font-family:'宋体';">将</span>RDD<span style="font-family:'宋体';">转换成</span><span style="font-family:'Times New Roman';">DataFrame</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">val personDF = personRDD.toDF</span></p><p align="justify"> </p><p>6.<span style="font-family:'宋体';">对</span><span style="font-family:'Times New Roman';">DataFrame</span><span style="font-family:'宋体';">进行处理</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">personDF.show</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><h2><strong>2.3<span style="font-family:'黑体';">、</span><span style="font-family:Arial;">DataFrame</span><span style="font-family:'黑体';">常用操作</span></strong></h2><h3><strong>2.3.1<span style="font-family:'宋体';">、</span><span style="font-family:'Times New Roman';">DSL</span><span style="font-family:'宋体';">风格语法</span></strong></h3><p>//<span style="font-family:'宋体';">查看</span><span style="font-family:'Times New Roman';">DataFrame</span><span style="font-family:'宋体';">中的内容</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">personDF.show</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><p>//<span style="font-family:'宋体';">查看</span><span style="font-family:'Times New Roman';">DataFrame</span><span style="font-family:'宋体';">部分列中的内容</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">personDF.select(personDF.col("name")).show</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">personDF.select(col("name"), col</span><span style="color:rgb(51,51,51);background:rgb(255,255,255);">(</span><span style="color:rgb(51,51,51);background:rgb(255,255,255);">"age"</span><span style="color:rgb(51,51,51);background:rgb(255,255,255);">)</span><span style="color:rgb(51,51,51);background:rgb(255,255,255);">).show</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">personDF.select("name").show</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><p>//<span style="font-family:'宋体';">打印</span><span style="font-family:'Times New Roman';">DataFrame</span><span style="font-family:'宋体';">的</span><span style="font-family:'Times New Roman';">Schema</span><span style="font-family:'宋体';">信息</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">personDF.printSchema</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><p>//<span style="font-family:'宋体';">查询所有的</span><span style="font-family:'Times New Roman';">name</span><span style="font-family:'宋体';">和</span><span style="font-family:'Times New Roman';">age</span><span style="font-family:'宋体';">，并将</span><span style="font-family:'Times New Roman';">age+1</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">personDF.select(col("id"), col("name"), col("age") + 1).show</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">personDF.select(personDF("id"), personDF("name"), personDF("age") + 1).show</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><p>//<span style="font-family:'宋体';">过滤</span><span style="font-family:'Times New Roman';">age</span><span style="font-family:'宋体';">大于等于</span><span style="font-family:'Times New Roman';">18</span><span style="font-family:'宋体';">的</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">personDF.filter(col("age") &gt;= 18).show</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><p>//<span style="font-family:'宋体';">按年龄进行分组并统计相同年龄的人数</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">personDF.groupBy("age").count().show()</span></p><p> </p><h3><strong>2.3.2<span style="font-family:'宋体';">、</span><span style="font-family:'Times New Roman';">SQL</span><span style="font-family:'宋体';">风格语法</span></strong></h3><p><span style="font-family:'宋体';">如果想使用</span>SQL<span style="font-family:'宋体';">风格的语法，需要将</span><span style="font-family:'Times New Roman';">DataFrame</span><span style="font-family:'宋体';">注册成表</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">personDF.registerTempTable("t_person")</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><p>//<span style="font-family:'宋体';">查询年龄最大的前两名</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">sqlContext.sql("select * from t_person order by age desc limit 2").show</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><p>//<span style="font-family:'宋体';">显示表的</span><span style="font-family:'Times New Roman';">Schema</span><span style="font-family:'宋体';">信息</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">sqlContext.sql("desc t_person").show</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><h1><strong>3<span style="font-family:'宋体';">、以编程方式执行</span><span style="font-family:'Times New Roman';">Spark SQL</span><span style="font-family:'宋体';">查询</span></strong></h1><h2><strong>3.1<span style="font-family:'黑体';">、编写</span><span style="font-family:Arial;">Spark SQL</span><span style="font-family:'黑体';">查询程序</span></strong></h2><p><span style="font-family:'宋体';">前面我们学习了如何在</span>Spark Shell<span style="font-family:'宋体';">中使用</span><span style="font-family:'Times New Roman';">SQL</span><span style="font-family:'宋体';">完成查询，现在我们来实现在自定义的程序中编写</span><span style="font-family:'Times New Roman';">Spark SQL</span><span style="font-family:'宋体';">查询程序。首先在</span><span style="font-family:'Times New Roman';">maven</span><span style="font-family:'宋体';">项目的</span><span style="font-family:'Times New Roman';">pom.xml</span><span style="font-family:'宋体';">中添加</span><span style="font-family:'Times New Roman';">Spark SQL</span><span style="font-family:'宋体';">的依赖</span></p><p> </p><table><tbody><tr><td valign="top"><p><span style="color:rgb(0,0,0);background:rgb(239,239,239);">&lt;</span><strong><span style="color:rgb(0,0,128);background:rgb(239,239,239);">dependency</span></strong><span style="color:rgb(0,0,0);background:rgb(239,239,239);">&gt;</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><span style="color:rgb(0,0,0);background:rgb(239,239,239);">&lt;</span><strong><span style="color:rgb(0,0,128);background:rgb(239,239,239);">groupId</span></strong><span style="color:rgb(0,0,0);background:rgb(239,239,239);">&gt;</span><span style="color:rgb(0,0,0);">org.apache.spark</span><span style="color:rgb(0,0,0);background:rgb(239,239,239);">&lt;/</span><strong><span style="color:rgb(0,0,128);background:rgb(239,239,239);">groupId</span></strong><span style="color:rgb(0,0,0);background:rgb(239,239,239);">&gt;</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><span style="color:rgb(0,0,0);background:rgb(239,239,239);">&lt;</span><strong><span style="color:rgb(0,0,128);background:rgb(239,239,239);">artifactId</span></strong><span style="color:rgb(0,0,0);background:rgb(239,239,239);">&gt;</span><span style="color:rgb(0,0,0);">spark-sql_2.10</span><span style="color:rgb(0,0,0);background:rgb(239,239,239);">&lt;/</span><strong><span style="color:rgb(0,0,128);background:rgb(239,239,239);">artifactId</span></strong><span style="color:rgb(0,0,0);background:rgb(239,239,239);">&gt;</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><span style="color:rgb(0,0,0);background:rgb(239,239,239);">&lt;</span><strong><span style="color:rgb(0,0,128);background:rgb(239,239,239);">version</span></strong><span style="color:rgb(0,0,0);background:rgb(239,239,239);">&gt;</span><span style="color:rgb(0,0,0);">1.5.2</span><span style="color:rgb(0,0,0);background:rgb(239,239,239);">&lt;/</span><strong><span style="color:rgb(0,0,128);background:rgb(239,239,239);">version</span></strong><span style="color:rgb(0,0,0);background:rgb(239,239,239);">&gt;</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);background:rgb(239,239,239);">&lt;/</span><strong><span style="color:rgb(0,0,128);background:rgb(239,239,239);">dependency</span></strong><span style="color:rgb(0,0,0);background:rgb(239,239,239);">&gt;</span></p></td></tr></tbody></table><p> </p><h3><strong>3.2<span style="font-family:'宋体';">、通过反射推断</span><span style="font-family:'Times New Roman';">Schema</span></strong></h3><p><span style="font-family:'宋体';">创建一个</span>object<span style="font-family:'宋体';">为</span><span style="font-family:'Times New Roman';">cn.itcast.spark.sql.InferringSchema</span></p><table><tbody><tr><td valign="top"><p><strong><span style="color:rgb(0,0,128);">package </span></strong><span style="color:rgb(0,0,0);">cn.itcast.spark.sql</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);"><br></span><strong><span style="color:rgb(0,0,128);">import </span></strong><span style="color:rgb(0,0,0);">org.apache.spark.{SparkConf, SparkContext}</span><span style="color:rgb(0,0,0);"><br></span><strong><span style="color:rgb(0,0,128);">import </span></strong><span style="color:rgb(0,0,0);">org.apache.spark.sql.SQLContext</span><span style="color:rgb(0,0,0);"><br></span><em><span style="color:rgb(128,128,128);"><br></span></em><strong><span style="color:rgb(0,0,128);">object </span></strong><span style="color:rgb(0,0,0);">InferringSchema {</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">  </span><strong><span style="color:rgb(0,0,128);">def </span></strong><span style="color:rgb(0,0,0);">main(args: Array[</span><span style="color:rgb(32,153,157);">String</span><span style="color:rgb(0,0,0);">]) {</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//创建SparkConf()并设置App名称</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">conf = </span><strong><span style="color:rgb(0,0,128);">new </span></strong><span style="color:rgb(0,0,0);">SparkConf().setAppName(</span><strong><span style="color:rgb(0,128,0);">"SQL-1"</span></strong><span style="color:rgb(0,0,0);">)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//SQLContext要依赖SparkContext</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">sc = </span><strong><span style="color:rgb(0,0,128);">new </span></strong><span style="color:rgb(0,0,0);">SparkContext(conf)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//创建SQLContext</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">sqlContext = </span><strong><span style="color:rgb(0,0,128);">new </span></strong><span style="color:rgb(0,0,0);">SQLContext(sc)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//从指定的地址创建RDD</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">lineRDD = sc.textFile(args(</span><span style="color:rgb(0,0,255);">0</span><span style="color:rgb(0,0,0);">)).map(_.split(</span><strong><span style="color:rgb(0,128,0);">" "</span></strong><span style="color:rgb(0,0,0);">))</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//创建case class</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    //将RDD和case class关联</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">personRDD = lineRDD.map(x =&gt; </span><em><span style="color:rgb(0,0,0);">Person</span></em><span style="color:rgb(0,0,0);">(x(</span><span style="color:rgb(0,0,255);">0</span><span style="color:rgb(0,0,0);">).toInt, x(</span><span style="color:rgb(0,0,255);">1</span><span style="color:rgb(0,0,0);">), x(</span><span style="color:rgb(0,0,255);">2</span><span style="color:rgb(0,0,0);">).toInt))</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//导入隐式转换，如果不到人无法将RDD转换成DataFrame</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    //将RDD转换成DataFrame</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">import </span></strong><span style="color:rgb(0,0,0);">sqlContext.implicits._</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">personDF = personRDD.toDF</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//注册表</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><span style="color:rgb(0,0,0);">personDF.registerTempTable(</span><strong><span style="color:rgb(0,128,0);">"t_person"</span></strong><span style="color:rgb(0,0,0);">)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//传入SQL</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">df = sqlContext.sql(</span><strong><span style="color:rgb(0,128,0);">"select * from t_person order by age desc limit 2"</span></strong><span style="color:rgb(0,0,0);">)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//将结果以JSON的方式存储到指定位置</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><span style="color:rgb(0,0,0);">df.write.json(args(</span><span style="color:rgb(0,0,255);">1</span><span style="color:rgb(0,0,0);">))</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//停止Spark Context</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><span style="color:rgb(0,0,0);">sc.stop()</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">  }</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">}</span><span style="color:rgb(0,0,0);"><br></span><em><span style="color:rgb(128,128,128);">//case class一定要放到外面</span><span style="color:rgb(128,128,128);"><br></span></em><strong><span style="color:rgb(0,0,128);">case class </span></strong><span style="color:rgb(0,0,0);">Person(id: Int, name: </span><span style="color:rgb(32,153,157);">String</span><span style="color:rgb(0,0,0);">, age: Int)</span></p><p> </p></td></tr></tbody></table><p><span style="font-family:'宋体';">将程序打成</span>jar<span style="font-family:'宋体';">包，上传到</span><span style="font-family:'Times New Roman';">spark</span><span style="font-family:'宋体';">集群，提交</span><span style="font-family:'Times New Roman';">Spark</span><span style="font-family:'宋体';">任务</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">/usr/local/spark-1.5.2-bin-hadoop2.6/bin/spark-submit \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">--class cn.itcast.spark.sql.InferringSchema \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">--master spark://node1.itcast.cn:7077 \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">/root/spark-mvn-1.0-SNAPSHOT.jar \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">hdfs://node1.itcast.cn:9000/person.txt \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">hdfs://node1.itcast.cn:9000/out </span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><p>查看运行结果</p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">hdfs dfs -cat  hdfs://node1.itcast.cn:9000/out/part-r-*</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><h3><strong>3.3<span style="font-family:'宋体';">、通过</span><span style="font-family:'Times New Roman';">StructType</span><span style="font-family:'宋体';">直接指定</span><span style="font-family:'Times New Roman';">Schema</span></strong></h3><p><span style="font-family:'宋体';">创建一个</span>object<span style="font-family:'宋体';">为</span><span style="font-family:'Times New Roman';">cn.itcast.spark.sql.SpecifyingSchema</span></p><table><tbody><tr><td valign="top"><p><strong><span style="color:rgb(0,0,128);">package </span></strong><span style="color:rgb(0,0,0);">cn.itcast.spark.sql</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);"><br></span><strong><span style="color:rgb(0,0,128);">import </span></strong><span style="color:rgb(0,0,0);">org.apache.spark.sql.{Row, SQLContext}</span><span style="color:rgb(0,0,0);"><br></span><strong><span style="color:rgb(0,0,128);">import </span></strong><span style="color:rgb(0,0,0);">org.apache.spark.sql.types._</span><span style="color:rgb(0,0,0);"><br></span><strong><span style="color:rgb(0,0,128);">import </span></strong><span style="color:rgb(0,0,0);">org.apache.spark.{SparkContext, SparkConf}</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);"><br></span><em><span style="color:rgb(128,128,128);">/**</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">  * Created by ZX on 2015/12/11.</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">  */</span><span style="color:rgb(128,128,128);"><br></span></em><strong><span style="color:rgb(0,0,128);">object </span></strong><span style="color:rgb(0,0,0);">SpecifyingSchema {</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">  </span><strong><span style="color:rgb(0,0,128);">def </span></strong><span style="color:rgb(0,0,0);">main(args: Array[</span><span style="color:rgb(32,153,157);">String</span><span style="color:rgb(0,0,0);">]) {</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//创建SparkConf()并设置App名称</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">conf = </span><strong><span style="color:rgb(0,0,128);">new </span></strong><span style="color:rgb(0,0,0);">SparkConf().setAppName(</span><strong><span style="color:rgb(0,128,0);">"SQL-2"</span></strong><span style="color:rgb(0,0,0);">)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//SQLContext要依赖SparkContext</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">sc = </span><strong><span style="color:rgb(0,0,128);">new </span></strong><span style="color:rgb(0,0,0);">SparkContext(conf)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//创建SQLContext</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">sqlContext = </span><strong><span style="color:rgb(0,0,128);">new </span></strong><span style="color:rgb(0,0,0);">SQLContext(sc)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//从指定的地址创建RDD</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">personRDD = sc.textFile(args(</span><span style="color:rgb(0,0,255);">0</span><span style="color:rgb(0,0,0);">)).map(_.split(</span><strong><span style="color:rgb(0,128,0);">" "</span></strong><span style="color:rgb(0,0,0);">))</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//通过StructType直接指定每个字段的schema</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">schema = </span><em><span style="color:rgb(0,0,0);">StructType</span></em><span style="color:rgb(0,0,0);">(</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">      </span><em><span style="color:rgb(102,14,122);">List</span></em><span style="color:rgb(0,0,0);">(</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">        </span><em><span style="color:rgb(0,0,0);">StructField</span></em><span style="color:rgb(0,0,0);">(</span><strong><span style="color:rgb(0,128,0);">"id"</span></strong><span style="color:rgb(0,0,0);">, IntegerType, </span><strong><span style="color:rgb(0,0,128);">true</span></strong><span style="color:rgb(0,0,0);">),</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">        </span><em><span style="color:rgb(0,0,0);">StructField</span></em><span style="color:rgb(0,0,0);">(</span><strong><span style="color:rgb(0,128,0);">"name"</span></strong><span style="color:rgb(0,0,0);">, StringType, </span><strong><span style="color:rgb(0,0,128);">true</span></strong><span style="color:rgb(0,0,0);">),</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">        </span><em><span style="color:rgb(0,0,0);">StructField</span></em><span style="color:rgb(0,0,0);">(</span><strong><span style="color:rgb(0,128,0);">"age"</span></strong><span style="color:rgb(0,0,0);">, IntegerType, </span><strong><span style="color:rgb(0,0,128);">true</span></strong><span style="color:rgb(0,0,0);">)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">      )</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    )</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//将RDD映射到rowRDD</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">rowRDD = personRDD.map(p =&gt; </span><em><span style="color:rgb(0,0,0);">Row</span></em><span style="color:rgb(0,0,0);">(p(</span><span style="color:rgb(0,0,255);">0</span><span style="color:rgb(0,0,0);">).toInt, p(</span><span style="color:rgb(0,0,255);">1</span><span style="color:rgb(0,0,0);">).trim, p(</span><span style="color:rgb(0,0,255);">2</span><span style="color:rgb(0,0,0);">).toInt))</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//将schema信息应用到rowRDD上</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">personDataFrame = sqlContext.createDataFrame(rowRDD, schema)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//注册表</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><span style="color:rgb(0,0,0);">personDataFrame.registerTempTable(</span><strong><span style="color:rgb(0,128,0);">"t_person"</span></strong><span style="color:rgb(0,0,0);">)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//执行SQL</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">df = sqlContext.sql(</span><strong><span style="color:rgb(0,128,0);">"select * from t_person order by age desc limit 4"</span></strong><span style="color:rgb(0,0,0);">)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//将结果以JSON的方式存储到指定位置</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><span style="color:rgb(0,0,0);">df.write.json(args(</span><span style="color:rgb(0,0,255);">1</span><span style="color:rgb(0,0,0);">))</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//停止Spark Context</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><span style="color:rgb(0,0,0);">sc.stop()</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">  }</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">}</span></p><p> </p></td></tr></tbody></table><p><span style="font-family:'宋体';">将程序打成</span>jar<span style="font-family:'宋体';">包，上传到</span><span style="font-family:'Times New Roman';">spark</span><span style="font-family:'宋体';">集群，提交</span><span style="font-family:'Times New Roman';">Spark</span><span style="font-family:'宋体';">任务</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">/usr/local/spark-1.5.2-bin-hadoop2.6/bin/spark-submit \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">--class cn.itcast.spark.sql.InferringSchema \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">--master spark://node1.itcast.cn:7077 \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">/root/spark-mvn-1.0-SNAPSHOT.jar \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">hdfs://node1.itcast.cn:9000/person.txt \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">hdfs://node1.itcast.cn:9000/out1 </span></p><p> </p><p>查看结果</p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">hdfs dfs -cat  hdfs://node1.itcast.cn:9000/out1/part-r-*</span></p><p> </p><h1><strong>4<span style="font-family:'宋体';">、数据源</span></strong></h1><h2><strong>4.1<span style="font-family:'黑体';">、</span><span style="font-family:Arial;">JDBC</span></strong></h2><p>Spark SQL<span style="font-family:'宋体';">可以通过</span><span style="font-family:'Times New Roman';">JDBC</span><span style="font-family:'宋体';">从关系型数据库中读取数据的方式创建</span><span style="font-family:'Times New Roman';">DataFrame</span><span style="font-family:'宋体';">，通过对</span><span style="font-family:'Times New Roman';">DataFrame</span><span style="font-family:'宋体';">一系列的计算后，还可以将数据再写回关系型数据库中。</span></p><h3><strong>4.2.1<span style="font-family:'宋体';">、从</span><span style="font-family:'Times New Roman';">MySQL</span><span style="font-family:'宋体';">中加载数据（</span><span style="font-family:'Times New Roman';">Spark Shell</span><span style="font-family:'宋体';">方式）</span></strong></h3><p>1.<span style="font-family:'宋体';">启动</span>Spark Shell<span style="font-family:'宋体';">，必须指定</span><span style="font-family:'Times New Roman';">mysql</span><span style="font-family:'宋体';">连接驱动</span><span style="font-family:'Times New Roman';">jar</span><span style="font-family:'宋体';">包</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">/usr/local/spark-1.5.2-bin-hadoop2.6/bin/spark-shell \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">--master spark://node1.itcast.cn:7077 \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">--jars /usr/local/spark-1.5.2-bin-hadoop2.6/mysql-connector-java-5.1.35-bin.jar \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">--driver-class-path /usr/local/spark-1.5.2-bin-hadoop2.6/mysql-connector-java-5.1.35-bin.jar</span> </p><p> </p><p>2.<span style="font-family:'宋体';">从</span>mysql<span style="font-family:'宋体';">中加载数据</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">val jdbcDF = sqlContext.read.format("jdbc").options(Map("url" -&gt; "jdbc:mysql://192.168.10.1:3306/bigdata", "driver" -&gt; "com.mysql.jdbc.Driver", "dbtable" -&gt; "person", "user" -&gt; "root", "password" -&gt; "123456")).load()</span></p><p> </p><p>3.执行查询</p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">jdbcDF</span><span style="color:rgb(51,51,51);background:rgb(255,255,255);">.show()</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"> </span></p><h3><strong>4.1.2<span style="font-family:'宋体';">、将数据写入到</span><span style="font-family:'Times New Roman';">MySQL</span><span style="font-family:'宋体';">中（打</span><span style="font-family:'Times New Roman';">jar</span><span style="font-family:'宋体';">包方式）</span></strong></h3><p>1.<span style="font-family:'宋体';">编写</span>Spark SQL<span style="font-family:'宋体';">程序</span></p><table><tbody><tr><td valign="top"><p><strong><span style="color:rgb(0,0,128);">package </span></strong><span style="color:rgb(0,0,0);">cn.itcast.spark.sql</span></p><p><span style="color:rgb(0,0,0);"><br></span><strong><span style="color:rgb(0,0,128);">import </span></strong><span style="color:rgb(0,0,0);">java.util.Properties</span><span style="color:rgb(0,0,0);"><br></span><strong><span style="color:rgb(0,0,128);">import </span></strong><span style="color:rgb(0,0,0);">org.apache.spark.sql.{SQLContext, Row}</span><span style="color:rgb(0,0,0);"><br></span><strong><span style="color:rgb(0,0,128);">import </span></strong><span style="color:rgb(0,0,0);">org.apache.spark.sql.types.{StringType, IntegerType, StructField, StructType}</span><span style="color:rgb(0,0,0);"><br></span><strong><span style="color:rgb(0,0,128);">import </span></strong><span style="color:rgb(0,0,0);">org.apache.spark.{SparkConf, SparkContext}</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);"><br></span><strong><span style="color:rgb(0,0,128);">object </span></strong><span style="color:rgb(0,0,0);">JdbcRDD {</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">  </span><strong><span style="color:rgb(0,0,128);">def </span></strong><span style="color:rgb(0,0,0);">main(args: Array[</span><span style="color:rgb(32,153,157);">String</span><span style="color:rgb(0,0,0);">]) {</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">conf = </span><strong><span style="color:rgb(0,0,128);">new </span></strong><span style="color:rgb(0,0,0);">SparkConf().setAppName(</span><strong><span style="color:rgb(0,128,0);">"MySQL-Demo"</span></strong><span style="color:rgb(0,0,0);">)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">sc = </span><strong><span style="color:rgb(0,0,128);">new </span></strong><span style="color:rgb(0,0,0);">SparkContext(conf)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">sqlContext = </span><strong><span style="color:rgb(0,0,128);">new </span></strong><span style="color:rgb(0,0,0);">SQLContext(sc)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//通过并行化创建RDD</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">personRDD = sc.parallelize(</span><em><span style="color:rgb(0,0,0);">Array</span></em><span style="color:rgb(0,0,0);">(</span><strong><span style="color:rgb(0,128,0);">"1 tom 5"</span></strong><span style="color:rgb(0,0,0);">, </span><strong><span style="color:rgb(0,128,0);">"2 jerry 3"</span></strong><span style="color:rgb(0,0,0);">, </span><strong><span style="color:rgb(0,128,0);">"3 kitty 6"</span></strong><span style="color:rgb(0,0,0);">)).map(_.split(</span><strong><span style="color:rgb(0,128,0);">" "</span></strong><span style="color:rgb(0,0,0);">))</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//通过StructType直接指定每个字段的schema</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">schema = </span><em><span style="color:rgb(0,0,0);">StructType</span></em><span style="color:rgb(0,0,0);">(</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">      </span><em><span style="color:rgb(102,14,122);">List</span></em><span style="color:rgb(0,0,0);">(</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">        </span><em><span style="color:rgb(0,0,0);">StructField</span></em><span style="color:rgb(0,0,0);">(</span><strong><span style="color:rgb(0,128,0);">"id"</span></strong><span style="color:rgb(0,0,0);">, IntegerType, </span><strong><span style="color:rgb(0,0,128);">true</span></strong><span style="color:rgb(0,0,0);">),</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">        </span><em><span style="color:rgb(0,0,0);">StructField</span></em><span style="color:rgb(0,0,0);">(</span><strong><span style="color:rgb(0,128,0);">"name"</span></strong><span style="color:rgb(0,0,0);">, StringType, </span><strong><span style="color:rgb(0,0,128);">true</span></strong><span style="color:rgb(0,0,0);">),</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">        </span><em><span style="color:rgb(0,0,0);">StructField</span></em><span style="color:rgb(0,0,0);">(</span><strong><span style="color:rgb(0,128,0);">"age"</span></strong><span style="color:rgb(0,0,0);">, IntegerType, </span><strong><span style="color:rgb(0,0,128);">true</span></strong><span style="color:rgb(0,0,0);">)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">      )</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    )</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//将RDD映射到rowRDD</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">rowRDD = personRDD.map(p =&gt; </span><em><span style="color:rgb(0,0,0);">Row</span></em><span style="color:rgb(0,0,0);">(p(</span><span style="color:rgb(0,0,255);">0</span><span style="color:rgb(0,0,0);">).toInt, p(</span><span style="color:rgb(0,0,255);">1</span><span style="color:rgb(0,0,0);">).trim, p(</span><span style="color:rgb(0,0,255);">2</span><span style="color:rgb(0,0,0);">).toInt))</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//将schema信息应用到rowRDD上</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">personDataFrame = sqlContext.createDataFrame(rowRDD, schema)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//创建Properties存储数据库相关属性</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><strong><span style="color:rgb(0,0,128);">val </span></strong><span style="color:rgb(0,0,0);">prop = </span><strong><span style="color:rgb(0,0,128);">new </span></strong><span style="color:rgb(0,0,0);">Properties()</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    prop.put(</span><strong><span style="color:rgb(0,128,0);">"user"</span></strong><span style="color:rgb(0,0,0);">, </span><strong><span style="color:rgb(0,128,0);">"root"</span></strong><span style="color:rgb(0,0,0);">)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    prop.put(</span><strong><span style="color:rgb(0,128,0);">"password"</span></strong><span style="color:rgb(0,0,0);">, </span><strong><span style="color:rgb(0,128,0);">"123456"</span></strong><span style="color:rgb(0,0,0);">)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//将数据追加到数据库</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><span style="color:rgb(0,0,0);">personDataFrame.write.mode(</span><strong><span style="color:rgb(0,128,0);">"append"</span></strong><span style="color:rgb(0,0,0);">).jdbc(</span><strong><span style="color:rgb(0,128,0);">"jdbc:mysql://192.168.10.1:3306/bigdata"</span></strong><span style="color:rgb(0,0,0);">, </span><strong><span style="color:rgb(0,128,0);">"bigdata.person"</span></strong><span style="color:rgb(0,0,0);">, prop)</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">    </span><em><span style="color:rgb(128,128,128);">//停止SparkContext</span><span style="color:rgb(128,128,128);"><br></span><span style="color:rgb(128,128,128);">    </span></em><span style="color:rgb(0,0,0);">sc.stop()</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">  }</span><span style="color:rgb(0,0,0);"><br></span><span style="color:rgb(0,0,0);">}</span></p><p> </p></td></tr></tbody></table><p> </p><p>2.<span style="font-family:'宋体';">用</span>maven<span style="font-family:'宋体';">将程序打包</span></p><p> </p><p>3.<span style="font-family:'宋体';">将</span>Jar<span style="font-family:'宋体';">包提交到</span><span style="font-family:'Times New Roman';">spark</span><span style="font-family:'宋体';">集群</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">/usr/local/spark-1.5.2-bin-hadoop2.6/bin/spark-submit \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">--class cn.itcast.spark.sql.JdbcRDD \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">--master spark://node1.itcast.cn:7077 \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">--jars /usr/local/spark-1.5.2-bin-hadoop2.6/mysql-connector-java-5.1.35-bin.jar \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">--driver-class-path /usr/local/spark-1.5.2-bin-hadoop2.6/mysql-connector-java-5.1.35-bin.jar \</span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);">/root/spark-mvn-1.0-SNAPSHOT.jar </span></p><p> </p><p> </p>            </div>
                </div>