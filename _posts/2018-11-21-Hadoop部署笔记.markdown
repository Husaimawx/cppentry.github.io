---
layout:     post
title:      Hadoop部署笔记
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p><strong>资料整理 </strong>
----------------------------------------------------------------------------------------------------------</p>
<p> </p>
<p>Hadoop Wiki：<span>		</span>
<a href="http://wiki.apache.org/hadoop/" rel="nofollow">http://wiki.apache.org/hadoop/</a>
</p>
<p><strong><span style="color:#993300;">Hadoop部署教程：     <a href="http://cn.hadoop.org/?p=21" rel="nofollow">http://cn.hadoop.org/?p=21</a>
</span>
</strong>
</p>
<p>HDFS Architecture：    <a href="http://hadoop.apache.org/common/docs/current/hdfs_design.html" rel="nofollow">http://hadoop.apache.org/common/docs/current/hdfs_design.html</a>
</p>
<p>Google Mapreduce 论文：<span>	</span>
 <a href="http://research.google.com/archive/mapreduce-osdi04.pdf" rel="nofollow">MapReduce: Simplified Data Processing on Large Clusters</a>
</p>
<p> </p>
<p><strong>速查手册 </strong>
----------------------------------------------------------------------------------------------------------</p>
<p> </p>
<p><strong>1.查看hadoop的状态。</strong>
</p>
<p>$ bin/hadoop dfsadmin -report</p>
<p>web方式查看： http://name.node.addr:50070/,  http://job.tracker.addr:50030/ </p>
<p> </p>
<p><strong>2.添加新节点。</strong>
配置好slave node,并在slave node上启动datanode和tasktracker：<br>
$ bin/hadoop-daemon.sh start datanode<br>
$ bin/hadoop-daemon.sh start tasktracker</p>
<p> </p>
<p><strong>3.HiveServer启动。</strong>
为了使用JDBC连接Hive数据库，需要先启动HiveServer。默认使用10000端口。</p>
<p>$ bin/hive --service hiveserver</p>
<p> </p>
<p><strong>部署经验 </strong>
----------------------------------------------------------------------------------------------------------</p>
<p> </p>
<p>1.网上资料都强调使用主机名或域名进行部署，使用IP可能会出问题。</p>
<p> </p>
<p>2.start-all的时候出现Name and service not known，无法启动DataNode。尚未解决。尝试在slaves文件中使用IP或域名。</p>
<p> </p>
<p>3.出现端口冲突，检查是否有尚未停掉的Hadoop进程。</p>
<p> </p>
<p>4.start-all的时候显示DataNode已启动，但DataNode未连接，log显示Server at [host:port] not available yet, Zzzzz...说明NameNode已连接到DataNode，但是DataNode不能连接回来。检查master文件和fs.default.name设置是否正确。尝试使用IP或域名。fs.default.name的格式为hdfs://[host]:[port]/</p>
<p> </p>
<p>5.hive能启动，并且能创建table，并不代表Hadoop正确部署。我遇到一次能够load data，能够select *（没有mapreduce操作）。但是select count(1)就出现dfs错误。尚未解决。应该是mapreduce的tasktracker工作不正常。</p>
<p> </p>
<p>6.新添加一个节点到集群当中时，HDFS不会自动地移动文件块到新节点当中去平衡磁盘空间。然而，新创建的文件将会使用新节点的磁盘。<br>
有几种方法可以手动进行平衡。1）将文件复制一份，然后删掉源文件。2）将磁盘块满的节点关掉，然后等待直到文件块自动复制完成，再把节点加回去。这样，冗余数量变得过多，系统将会随机删去多余的冗余。3）运行bin/start-balancer.sh命令。</p>
<p> </p>
<p>7.配置Hadoop的时候有许多路径要配置，其中一些是本地路径，而一些是HDFS的路径。</p>            </div>
                </div>