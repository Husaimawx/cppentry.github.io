---
layout:     post
title:      hdfs命令学习
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/caixiaowang/article/details/79681480				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h3 id="把一个本地文件上传到hdfs">把一个本地文件上传到hdfs</h3>



<pre class="prettyprint"><code class=" hljs livecodeserver">hdfs dfs -<span class="hljs-built_in">put</span> <span class="hljs-operator">a</span>.txt b.txt</code></pre>

<p>a.txt在本地，b.txt是要传到的hdfs路径。</p>



<h3 id="从hdfs导出文件到本地">从hdfs导出文件到本地</h3>



<pre class="prettyprint"><code class=" hljs cs">hdfs dfs -<span class="hljs-keyword">get</span> wordcountout/part-<span class="hljs-number">0000</span>* /tmp/output</code></pre>



<h3 id="hdfs的shell脚本">Hdfs的shell脚本</h3>

<p>hdfs提供了很多shell命令来实现访问文件系统的功能，hadoop自带的shell脚本叫hadoop。如果需要获取文件系统的所有命令，可以通过hadoop fs。</p>



<pre class="prettyprint"><code class=" hljs ">hadoop fs</code></pre>



<h3 id="help">help</h3>

<p>使用help选项可以获得对某个具体命令的详细说明</p>



<pre class="prettyprint"><code class=" hljs mel">hadoop fs -<span class="hljs-keyword">help</span> <span class="hljs-keyword">ls</span></code></pre>



<h3 id="创建文件夹">创建文件夹</h3>



<pre class="prettyprint"><code class=" hljs lasso">hadoop fs <span class="hljs-attribute">-mkdir</span> <span class="hljs-attribute">-p</span> /<span class="hljs-built_in">data</span>/weblogs</code></pre>



<h3 id="本地文件拷贝到hdfs">本地文件拷贝到hdfs</h3>



<pre class="prettyprint"><code class=" hljs haskell"><span class="hljs-title">hadoop</span> fs -copyFromLocal weblog_entries.txt /<span class="hljs-typedef"><span class="hljs-keyword">data</span>/weblogs</span></code></pre>



<h3 id="列出文件的信息">列出文件的信息</h3>



<pre class="prettyprint"><code class=" hljs haskell"><span class="hljs-title">hadoop</span> fs -ls /<span class="hljs-typedef"><span class="hljs-keyword">data</span>/weblogs/weblog_entries.txt</span></code></pre>



<h3 id="集群间数据复制">集群间数据复制</h3>

<p>通过distcp实现hadoop集群间复制大量数据。 <br>
distcp是通过启动mapreduce实现数据复制的。 <br>
使用distcp，需要关闭源集群map任务的推测机制，在mapred-site.xml中将mapred.map.tasks.speculative.execution的值设为false，避免在map任务失败时产生不可知的行为。</p>

<ul>
<li><p>将集群a的weblogs文件夹复制到集群b上</p>

<pre class="prettyprint"><code class=" hljs haskell"><span class="hljs-title">hadoop</span> distcp hdfs://namenodeA/<span class="hljs-typedef"><span class="hljs-keyword">data</span>/weblogs hdfs://namenodeB/<span class="hljs-keyword">data</span>/weblogs</span>
</code></pre></li>
<li><p>将集群a的weblogs文件夹复制到集群b并覆盖已存在的文件</p>

<pre class="prettyprint"><code class=" hljs ruby">hadoop distcp -overwrite <span class="hljs-symbol">hdfs:</span>/<span class="hljs-regexp">/namenodeA/data</span><span class="hljs-regexp">/weblogs hdfs:/</span><span class="hljs-regexp">/namenodeB/</span> data/weblogs
</code></pre></li>
<li><p>同步集群a和集群b之间的weblogs文件夹</p>

<pre class="prettyprint"><code class=" hljs haskell"><span class="hljs-title">hadoop</span> distcp -update hdfs://namenodeA/<span class="hljs-typedef"><span class="hljs-keyword">data</span>/weblogs hdfs://namenodeB/<span class="hljs-keyword">data</span>/  weblogs</span>
</code></pre></li>
<li><p>原理 <br>
在源集群，待复制的文件夹的内容会被复制为一个临时的大文件。并且会启动一个只有map的mapreduce作业。每个map会被分配256M的分文件。 <br>
比如，如果weblogs文件夹总大小为10g，那么会启动40个map，每个map复制256M数据。 <br>
也可以通过参数设置启动的map数量。</p></li>
</ul>



<pre class="prettyprint"><code class=" hljs ruby">hadoop distcp -m <span class="hljs-number">10</span> <span class="hljs-symbol">hdfs:</span>/<span class="hljs-regexp">/namenodeA/data</span><span class="hljs-regexp">/weblogs hdfs:/</span><span class="hljs-regexp">/namenodeB/data</span><span class="hljs-regexp">/ weblogs</span></code></pre>

<p>这里，启动10个map，如果weblogs一共10G，那么每个map复制1G。</p>



<h3 id="递归查看一个文件夹">递归查看一个文件夹</h3>



<pre class="prettyprint"><code class=" hljs lasso">hadoop fs <span class="hljs-attribute">-lsr</span> /<span class="hljs-built_in">data</span>/weblogs/<span class="hljs-keyword">import</span></code></pre>

<h3 id="拷贝文件">拷贝文件</h3>

<pre class="prettyprint"><code class=" hljs avrasm">hadoop fs -<span class="hljs-keyword">cp</span> src dst</code></pre>

<h3 id="移动文件">移动文件</h3>

<pre class="prettyprint"><code class=" hljs lasso">hadoop fs <span class="hljs-attribute">-mv</span> src dst</code></pre>

<h3 id="查看文件内容">查看文件内容</h3>

<pre class="prettyprint"><code class=" hljs livecodeserver">hadoop fs -cat /user/hadoop/<span class="hljs-operator">a</span>.txt</code></pre>

<h3 id="删除文件">删除文件</h3>

<pre class="prettyprint"><code class=" hljs livecodeserver">hadoop fs -rm /user/hadoop/<span class="hljs-operator">a</span>.txt</code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>