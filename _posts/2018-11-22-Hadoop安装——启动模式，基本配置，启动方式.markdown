---
layout:     post
title:      Hadoop安装——启动模式，基本配置，启动方式
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/b_x_p/article/details/78410990				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>推荐直接看<a href="http://hadoop.apache.org/docs/r2.8.2/hadoop-project-dist/hadoop-common/SingleCluster.html#Standalone_Operation" rel="nofollow">官方文档</a></p>



<h2 id="hadoop三种启动模式">Hadoop三种启动模式</h2>



<pre class="prettyprint"><code class=" hljs mathematica">    Local (Standalone) <span class="hljs-keyword">Mode</span>
    Pseudo-<span class="hljs-keyword">Distributed</span> <span class="hljs-keyword">Mode</span>
    Fully-<span class="hljs-keyword">Distributed</span> <span class="hljs-keyword">Mode</span></code></pre>



<h2 id="standalone-operation">Standalone Operation</h2>



<pre class="prettyprint"><code class="language-shell hljs ruby"><span class="hljs-variable">$ </span>mkdir input
<span class="hljs-variable">$ </span>cp etc/hadoop/*.xml input
<span class="hljs-variable">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-<span class="hljs-number">2.8</span>.<span class="hljs-number">2</span>.jar grep input output <span class="hljs-string">'dfs[a-z.]+'</span>
<span class="hljs-variable">$ </span>cat output/*</code></pre>



<h2 id="pseudo-distributed-operation">Pseudo-Distributed Operation</h2>

<p><strong>1.配置etc/hadoop/core-site.xml:</strong></p>



<pre class="prettyprint"><code class="language-xml hljs ">##配置namenode所在主机
<span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>hdfs://bxp:8020<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span>
##配置文件临时目录
<span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>/usr/lib/hadoop-2.5.0-cdh5.3.6/data/tmp<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span>
</code></pre>

<p><strong>2. 配置etc/hadoop/hdfs-site.xml:</strong></p>



<pre class="prettyprint"><code class=" hljs xml">##配置文件备份数量
<span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span>
</code></pre>

<p><strong>3. Format the filesystem:</strong></p>



<pre class="prettyprint"><code class=" hljs rsl">bin/hdfs namenode -<span class="hljs-built_in">format</span></code></pre>

<p><strong>4. Start NameNode daemon and DataNode daemon:</strong></p>



<pre class="prettyprint"><code class=" hljs sql">sbin/hadoop-daemon.sh <span class="hljs-operator"><span class="hljs-keyword">start</span> namenode
sbin/hadoop-daemon.sh <span class="hljs-keyword">start</span> datanode</span></code></pre>

<p><strong>5.浏览器访问：<a href="http://localhost:50070" rel="nofollow">http://localhost:50070</a>，查看hdf</strong> <br>
我使用的时centos7操作系统，发现防火墙已经关闭，但是不能够访问50070端口，于是在<code>etc/hodoop/hdfs-site.xml</code>中手动配置hdfs地址，最终可以访问</p>



<pre class="prettyprint"><code class=" hljs xml">    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.http.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>localhost:50070<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>

<p><strong>6.创建hdfs文件目录：</strong></p>



<pre class="prettyprint"><code class=" hljs lasso">bin/hdfs dfs <span class="hljs-attribute">-mkdir</span> <span class="hljs-attribute">-p</span> /user/bxp/mapreduce/wordcount/input</code></pre>

<p><strong>7.命令行查看hdfs文件系统目录结构：</strong></p>



<pre class="prettyprint"><code class=" hljs lasso">bin/hdfs dfs <span class="hljs-attribute">-ls</span> <span class="hljs-attribute">-R</span> <span class="hljs-subst">/</span></code></pre>

<p><strong>8.上传文件到hdfs文件系统(下载的命令为get，查看为cat)</strong></p>



<pre class="prettyprint"><code class=" hljs livecodeserver">bin/hdfs dfs -<span class="hljs-built_in">put</span> input/test /user/bxp/mapreduce/wordcount/input</code></pre>

<p><strong>9.运行</strong></p>



<pre class="prettyprint"><code class=" hljs lasso">bin/hadoop jar share/hadoop/mapreduce/hadoop<span class="hljs-attribute">-mapreduce</span><span class="hljs-attribute">-examples</span><span class="hljs-subst">-</span><span class="hljs-number">2.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.3</span><span class="hljs-number">.6</span><span class="hljs-built_in">.</span>jar wordcount /user/bxp/mapreduce/wordcount/input /user/bxp/mapreduce/wordcount/output</code></pre>

<p><strong>10.查看运行结果</strong></p>



<pre class="prettyprint"><code class=" hljs lasso">bin/hdfs dfs <span class="hljs-attribute">-cat</span> /user/bxp/mapreduce/wordcount/output/part<span class="hljs-attribute">-r</span><span class="hljs-subst">-</span><span class="hljs-number">00000</span></code></pre>

<p>此时运行的结果和本地启动时运行的结果相同，不同的是输入的数据源一个是在本地，一个是在hdfs文件系统中。当在etc/hadoop/core-site.xml中配置文件系统时，去寻找配置的文件系统，当没有进行配置，默认会去寻找本地文件系统（file:///）。</p>



<h3 id="yarn-on-single-node">YARN on Single Node</h3>

<p><strong>1.在etc/hadoop/yarn-env.sh中配置JAVA_HOME</strong> <br>
<strong>2.配置etc/hadoop/yarn-site.xml:</strong></p>



<pre class="prettyprint"><code class=" hljs xml">配置yarn上运行mapreduce
<span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
配置resourcemanager所在主机地址
  <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>localhost<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>

<p><strong>3.在etc/hadoop/slaves文件中配datanode和nodemamager所在主机的主机名或ip（默认datanode和nodemanager在同一台主机上）</strong> <br>
<code>localhost</code> <br>
<strong>4.启动yarn</strong></p>



<pre class="prettyprint"><code class=" hljs sql">sbin/yarn-daemon.sh <span class="hljs-operator"><span class="hljs-keyword">start</span> resourcemanager
sbin/yarn-daemon.sh <span class="hljs-keyword">start</span> nodemanager</span></code></pre>

<p><strong>5.浏览器查看yarn的监控界面：8088</strong> <br>
<strong>6.进行将mapreduce程序运行在yarn上的配置.</strong> <br>
（1）配置etc/hadoop/mapred-env.sh中的JAVA_HOME <br>
（2）重命名mapred-site.xml.template为mapred-site.xml并配置etc/hadoop/mapred-site.xml</p>



<pre class="prettyprint"><code class=" hljs xml">##将mapreduce运行在yarn上，默认值是local
<span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>

<p><strong>7.运行程序</strong></p>



<pre class="prettyprint"><code class=" hljs lasso">bin/hadoop jar share/hadoop/mapreduce/hadoop<span class="hljs-attribute">-mapreduce</span><span class="hljs-attribute">-examples</span><span class="hljs-subst">-</span><span class="hljs-number">2.6</span><span class="hljs-number">.5</span><span class="hljs-built_in">.</span>jar wordcount /user/bxp/mapreduce/wordcount/input /user/bxp/mapreduce/wordcount/output</code></pre>

<p><strong>8.查看运行结果</strong></p>



<pre class="prettyprint"><code class=" hljs lasso">bin/hdfs dfs <span class="hljs-attribute">-cat</span> /user/bxp/mapreduce/wordcount/output/part<span class="hljs-attribute">-r</span><span class="hljs-subst">-</span><span class="hljs-number">00000</span></code></pre>

<p>此时的运行结果不变，不同的是之前的mapreduce程序运行在本地，此时的mapreduce程序运行在yarn上 。</p>



<h2 id="配置并启动mapreduce历史服务器">配置并启动mapreduce历史服务器</h2>

<ul>
<li>启动mapreduce历史服务器</li>
</ul>



<pre class="prettyprint"><code class=" hljs lasso">sbin/mr<span class="hljs-attribute">-jobhistory</span><span class="hljs-attribute">-daemon</span><span class="hljs-built_in">.</span>sh start historyserver</code></pre>

<ul>
<li>配置yarn日志的聚集 <br>
聚集：应用运行完成以后，将日志信息上传到HDFS文件系统中 <br>
在etc/hdoop/yarn-site.xml</li>
</ul>



<pre class="prettyprint"><code class=" hljs applescript"><span class="hljs-comment">###配置日志聚集</span>
&lt;<span class="hljs-keyword">property</span>&gt;
        &lt;<span class="hljs-property">name</span>&gt;yarn.<span class="hljs-command">log</span>-aggregation-enable&lt;/<span class="hljs-property">name</span>&gt;
        &lt;value&gt;<span class="hljs-constant">true</span>&lt;/value&gt;
&lt;/<span class="hljs-keyword">property</span>&gt;
<span class="hljs-comment">###配置日志在文件系统中存放的秒数（604800为7天）</span>
&lt;<span class="hljs-keyword">property</span>&gt;
        &lt;<span class="hljs-property">name</span>&gt;yarn.<span class="hljs-command">log</span>-aggregation.retain-seconds&lt;/<span class="hljs-property">name</span>&gt;
        &lt;value&gt;<span class="hljs-number">604800</span>&lt;/value&gt;
&lt;/<span class="hljs-keyword">property</span>&gt;</code></pre>

<p>配置完成后需要将resourcemanager和mapreduce历史任务进行重启才会生效</p>



<pre class="prettyprint"><code class=" hljs lasso">sbin/yarn<span class="hljs-attribute">-daemon</span><span class="hljs-built_in">.</span>sh stop resourcemanager
sbin/yarn<span class="hljs-attribute">-daemon</span><span class="hljs-built_in">.</span>sh stop nodemanager
sbin/mr<span class="hljs-attribute">-jobhistory</span><span class="hljs-attribute">-daemon</span><span class="hljs-built_in">.</span>sh stop historyserver

sbin/yarn<span class="hljs-attribute">-daemon</span><span class="hljs-built_in">.</span>sh start resourcemanager
sbin/yarn<span class="hljs-attribute">-daemon</span><span class="hljs-built_in">.</span>sh start nodemanager
sbin/mr<span class="hljs-attribute">-jobhistory</span><span class="hljs-attribute">-daemon</span><span class="hljs-built_in">.</span>sh start historyserver</code></pre>



<h2 id="hadoop配置文件">Hadoop配置文件</h2>

<ul>
<li>默认配置文件,在share/hadoop四个模块相对应的jar包中</li>
</ul>



<pre class="prettyprint"><code class=" hljs haskell"><span class="hljs-title">core</span>-<span class="hljs-default"><span class="hljs-keyword">default</span>.xml</span>
<span class="hljs-title">hdfs</span>-<span class="hljs-default"><span class="hljs-keyword">default</span>.xml</span>
<span class="hljs-title">yarn</span>-<span class="hljs-default"><span class="hljs-keyword">default</span>.xml</span>
<span class="hljs-title">mapred</span>-<span class="hljs-default"><span class="hljs-keyword">default</span>.xml</span></code></pre>

<ul>
<li>自定义配置文件,在etc/hadoop</li>
</ul>



<pre class="prettyprint"><code class=" hljs lasso">core<span class="hljs-attribute">-site</span><span class="hljs-built_in">.</span><span class="hljs-built_in">xml</span>
hdfs<span class="hljs-attribute">-site</span><span class="hljs-built_in">.</span><span class="hljs-built_in">xml</span>
yarn<span class="hljs-attribute">-site</span><span class="hljs-built_in">.</span><span class="hljs-built_in">xml</span>
mapred<span class="hljs-attribute">-site</span><span class="hljs-built_in">.</span><span class="hljs-built_in">xml</span></code></pre>

<p>每次启动程序的时候，系统会首先加载jar包，读取jar包中的默认配置，之后才会读取用户自定义配置，用户自定义配置会覆盖默认配置。 <br>
一般在配置的时候，会在<a href="http://hadoop.apache.org/docs/r2.6.5/hadoop-project-dist/hadoop-common/SingleCluster.html" rel="nofollow">官方文档</a>和默认配置文件中查找配置信息，默认配置中会有对配置属性的描述。</p>



<h2 id="配置hdfs垃圾回收时间分钟">配置HDFS垃圾回收时间（分钟）</h2>

<p>在core-site.xml配置文件中进行增加属性</p>



<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>fs.trash.interval<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>7*24*60<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
</code></pre>



<h2 id="hadoop启动的三种方式">hadoop启动的三种方式</h2>



<h4 id="1各个服务组建逐个启动">1.各个服务组建逐个启动</h4>

<p><strong>hdfs</strong></p>



<pre class="prettyprint"><code class=" hljs smalltalk">hadoop-daemon.sh start<span class="hljs-localvars">|stop namenode|datanode|secondarynamenode</span></code></pre>

<p><strong>yarn</strong></p>



<pre class="prettyprint"><code class=" hljs smalltalk">yarn-daemon.sh start<span class="hljs-localvars">|stop resourcemanager|nodemanager</span></code></pre>

<p><strong>mapreduce</strong></p>



<pre class="prettyprint"><code class=" hljs lasso">mr<span class="hljs-attribute">-jobhistory</span><span class="hljs-attribute">-daemon</span><span class="hljs-built_in">.</span>sh start<span class="hljs-subst">|</span>stop historyserver</code></pre>



<h4 id="2各个模块分开启动">2.各个模块分开启动</h4>

<p><strong>hdfs</strong></p>



<pre class="prettyprint"><code class=" hljs avrasm">start-dfs<span class="hljs-preprocessor">.sh</span>
stop-dfs<span class="hljs-preprocessor">.sh</span></code></pre>

<p><strong>yarn</strong></p>



<pre class="prettyprint"><code class=" hljs avrasm">start-yarn<span class="hljs-preprocessor">.sh</span>
stop-yarn<span class="hljs-preprocessor">.sh</span></code></pre>

<p><strong>mapreduce</strong></p>



<pre class="prettyprint"><code class=" hljs lasso">mr<span class="hljs-attribute">-historyserver</span><span class="hljs-attribute">-daemon</span><span class="hljs-built_in">.</span>sh start<span class="hljs-subst">|</span>stop historyserver</code></pre>

<p>分模块启动，他的启动方式是：启动命令在主结点上运行，然后通过ssh协议去链接自己和相关将要启动的从结点，从而逐个启动。使用ssh协议时每次都需要输入密码。所以需要配置ssh无密钥登陆。 <br>
配置无密钥登陆：(客户端生成公钥和私钥，将公钥给交给链接的机器) <br>
(1) 客户端生成密钥。 <br>
进入到用户的主目录下的.ssh目录中 <br>
使用命令：ssh-keygen -t rsa，回车4下 <br>
(2) copy公钥 <br>
使用命令ssh-copy-id hostname(将要拷贝到的机器的hostname)就会将公钥拷贝到所有的用户名相同的主机上的.ssh目录下authorized_key。</p>



<h4 id="3一起启动">3.一起启动</h4>



<pre class="prettyprint"><code class=" hljs sql"><span class="hljs-operator"><span class="hljs-keyword">start</span>-<span class="hljs-keyword">all</span>.sh
stop-<span class="hljs-keyword">all</span>.sh</span></code></pre>

<p>此方式不推荐，此方式要求namenode和resourcemanager在相同的主机上，因为在实际的环境中，namenode和resourcemanager在不同的主机上。</p>



<h2 id="细节回顾">细节回顾</h2>

<ul>
<li>namenode所在主机通过etc/hadoop/core-site.xml中指定</li>
</ul>



<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>hdfs://bxp:8020<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>

<ul>
<li>slaves文件中指定的是datanode和noderesource所在的主机</li>
<li>secondarynamenode结点通过在hdfs-site.xml中通过以下属性进行指定，默认就是本机</li>
</ul>



<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>0.0.0.0:50090<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>

<ul>
<li>resourcemanager所在的主机，在yarn-site.xml</li>
</ul>



<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>localhost<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>

<ul>
<li>MapReduce HistoryServer在mapred-site.xml中,默认是本机</li>
</ul>



<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.jobhistory.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>0.0.0.0:10020<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>0.0.0.0:19888<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
</code></pre>



<h2 id="问题">问题</h2>

<p>每次运行bin/hdfs dfs都会出现警告WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable。原因是hadoop的lib/native本地库和系统所使用的本地库不对应，要想去掉警告，需要下载hadoop的源码在本地进行编译，并替换native即可。 <br>
编译可以看源码包下的BUILDING.txt文件</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>