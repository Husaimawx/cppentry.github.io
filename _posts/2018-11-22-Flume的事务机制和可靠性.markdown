---
layout:     post
title:      Flume的事务机制和可靠性
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主女朋友允许不得转载。					https://blog.csdn.net/qq_26442553/article/details/79037298				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p> <span style="font-size:14px;">实际开发中，或者在面试中，总会碰到诸如Flume如何保证数据传输的完整性？</span></p>
<p><span style="font-size:14px;">     一：Flume的事务机制</span></p>
<p><span style="font-size:14px;">     所以这就不得不提<span style="color:#ff0000;">Flume的事务机制（类似数据库的事务机制）：Flume使用两个独立的事务分别负责从soucrce到channel，以及从channel到sink的事件传递。比如以上面一篇博客中的事例为例：spooling directory source 为文件的每一行创建一个事件，一旦事务中所有的事件全部传递到channel且提交成功，那么source就将该文件标记为完成。同理，事务以类似的方式处理从channel到sink的传递过程，如果因为某种
 原因使得事件无法记录，那么事务将会回滚。且所有的事件都会保持到channel中，等待重新传递。</span></span></p>
<p><span style="font-size:14px;">    二:Flume的At-least-once提交方式</span></p>
<p><span style="font-size:14px;">     Flume的事务机制，总的来说，保证了source产生的每个事件都会传送到sink中。但是值得一说的是，实际上Flume作为高容量并行采集系统采用的是At-least-once（传统的企业系统采用的是exactly-once机制）提交方式，这样就造成每个source产生的事件至少到达sink一次，换句话说就是同一事件有可能重复到达。这样虽然看上去是一个缺陷，但是相比为了保证Flume能够可靠地将事件从source,channel传递到sink,这也是一个可以接受的权衡。如上博客中spooldir的使用，Flume会对已经处理完的数据进行标记。</span></p>
<p><span style="font-size:14px;">    三：Flume的批处理机制</span></p>
<p><span style="font-size:14px;">     为了提高效率，Flume尽可能的以事务为单位来处理事件，而不是逐一基于事件进行处理。比如上篇博客提到的spooling directory source以100行文本作为一个批次来读取（BatchSize属性来配置，类似数据库的批处理模式）。批处理的设置尤其有利于提高file channle的效率，这样整个事务只需要写入一次本地磁盘，或者调用一次fsync，速度回快很多。</span></p>
            </div>
                </div>