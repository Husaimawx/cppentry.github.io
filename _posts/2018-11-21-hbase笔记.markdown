---
layout:     post
title:      hbase笔记
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>1.用户问题</p>
<p>最好不用root吧，如下新建一个用户，新建一个目录给这个用户，作为安装hbase吧</p>
<p>$ useradd hbase</p>
<p>$ mkdir /usr/local/hbase</p>
<p>$ chown hbase:hbase /usr/local/hbase/</p>
<p><br>
2.版本升级问题</p>
<p>可以使用快捷方式，链接到hbase_home目录，对以后升级版本时，就修改链接就行。</p>
<p>$ ln -s /usr/local/hbase/hbase-0.90.4 /usr/local/hbase/current</p>
<p>原文：</p>
<p>We installed HBase 0.92.1 on a single server. We have used a symbolic link named current<br>
for it, so that version upgrading in the future is easy to do.</p>
<p><br>
3. $ list</p>
<p> hbase command, list all the tables.</p>
<p><br>
4.关于多个系统同步</p>
<p><a href="mailto:hadoop@master1%24" rel="nofollow">hadoop@master1$</a> for i in 1 2 3<br>
do rsync -avz /usr/local/hadoop/ slave$i:/usr/local/hadoop/<br>
sleep 1<br>
done</p>
<p><br>
5. 关于hadoop启动，先要格式化</p>
<p>$ HADOOP_HOME/bin/hadoop namenode -format</p>
<p><br>
6.关于hadoop的查看</p>
<p>hdfs admin page:</p>
<p><a href="http://master1:50070" rel="nofollow">http://master1:50070</a></p>
<p>MapReduce admin page:</p>
<p><a href="http://master1:50030" rel="nofollow">http://master1:50030</a></p>
<p><br>
7.关于跑多个zookeeper</p>
<p>实际时，至少三个，总是要单数个。</p>
<p>but in production it is recommended that you run a<br>
ZooKeeper ensemble of at least three nodes. Also, make sure to run an odd number of nodes</p>
<p><br>
8. zookeeper 配置 zoo.cfg</p>
<p>可以复制zoo_sample.cfg的。</p>
<p><a href="mailto:hadoop@master1%24" rel="nofollow">hadoop@master1$</a> vi $ZK_HOME/conf/zoo.cfg<br>
dataDir=/usr/local/ZooKeeper/var/data<br>
dataLogDir=/usr/local/ZooKeeper/var/datalog</p>
<p><br>
9.zookeeper的同步时，不要同步datadir和datalog目录</p>
<p><br>
10.  配置多个zookeeper</p>
<p>server.1中的1是myid。</p>
<p><a href="mailto:hadoop@node%7B1,2,3%7D%24" rel="nofollow">hadoop@node{1,2,3}$</a> vi $ZK_HOME/conf/zoo.cfg<br>
server.1=node1:2888:3888<br>
server.2=node2:2888:3888<br>
server.3=node3:2888:3888<br>
Also, you need to put a myid file under ${dataDir}. The myid file consists of a single line<br>
containing only the node ID. So myid of node1 would contain the text 1 and nothing else.</p>
<p><br>
11. 连接到zookeeper集群</p>
<p>三个server时，只能一个挂掉。</p>
<p>$ zkCli.sh -server node1,node2,node3<br>
ZooKeeper will function as long as more than half of the nodes in the ZooKeeper cluster are<br>
alive. This means, in a three node cluster, only one server can die.</p>
<p><br>
12. 关于同时打开文件数限制</p>
<p>最大文件打开数，和一个进程最大文件打开数，都要设置为最大，使用nproc命令，否则有OutOfMemoryError。修改的必须对启动hadoop和hbase的用户。要注释才生效。</p>
<p>查看最大文件打开数：</p>
<p>hadoop$ ulimit -n<br>
1024</p>
<p>查看1个进程的最大打开数：</p>
<p>hadoop$ ulimit -u<br>
unlimited</p>
<p>或者直接修改</p>
<p>root# vi /etc/security/limits.conf<br>
hadoop soft nofile 65535<br>
hadoop hard nofile 65535<br>
hadoop soft nproc 32000<br>
hadoop hard nproc 32000</p>
<p><br>
 </p>
<p> </p>
            </div>
                </div>