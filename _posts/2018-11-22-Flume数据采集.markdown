---
layout:     post
title:      Flume数据采集
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p></p><p style="background-color:rgb(255,255,255);">flume自带很长多的source，如：exe、kafka...其中有一个非常简单的source——httpsource，使用httpSource，flume启动后会拉起一个web服务来监听指定的ip和port。常用的使用场景：对于有些应用环境中，不能部署Flume SDK及其依赖项，可以在代码中通过HTTP而不是Flume的PRC发送数据的情况，此时HTTP SOURCE可以用来将数据接收到Flume中。</p><p style="background-color:rgb(255,255,255);">1、httpsource 参数：</p><p style="background-color:rgb(255,255,255);"></p><table style="border-spacing:0px;width:852px;color:rgb(51,51,51);font-size:14px;background-color:rgb(255,255,255);"><tbody><tr><td style="margin:0px;">配置参数</td><td style="margin:0px;">默认值</td><td style="margin:0px;">描述</td></tr><tr><td style="margin:0px;">type</td><td style="margin:0px;"><br></td><td style="margin:0px;">http (org.apache.fluem.source.httpSource）</td></tr><tr><td style="margin:0px;">bind</td><td style="margin:0px;"><br></td><td style="margin:0px;">绑定的IP地址或主机名</td></tr><tr><td style="margin:0px;">port</td><td style="margin:0px;"><br></td><td style="margin:0px;">绑定的端口号</td></tr><tr><td style="margin:0px;">enableSSL</td><td style="margin:0px;">false</td><td style="margin:0px;"><br></td></tr><tr><td style="margin:0px;">keystore</td><td style="margin:0px;"><br></td><td style="margin:0px;">使用的keystore文件的路径</td></tr><tr><td style="margin:0px;">keystorePassword</td><td style="margin:0px;"><br></td><td style="margin:0px;">能够进入keystore的密码</td></tr><tr><td style="margin:0px;">handler</td><td style="margin:0px;">JSONHandler</td><td style="margin:0px;">HTTP SOURCE使用的处理程序类</td></tr><tr><td style="margin:0px;">handler.*</td><td style="margin:0px;"><br></td><td style="margin:0px;">传给处理程序类的任何参数 可以 通过使用此参数（*）配置传入</td></tr></tbody></table><p style="background-color:rgb(255,255,255);">1）handler：</p><p style="background-color:rgb(255,255,255);">Flume使用一个可插拔的“handler”程序来实现转换，如果不指定默认是：JSONHandler，它能处理JSON格式的事件，格式如下。此外用户可以自定义handler，必须实现HTTPSourceHandler接口。<br><br>json数据格式：</p><p style="background-color:rgb(255,255,255);"></p><div class="dp-highlighter bg_html" style="padding:1px 0px 0px;margin:0px 0px 24px;font-family:Consolas, 'Courier New', Courier, mono, serif;font-size:12px;background-color:rgb(231,229,220);width:843.469px;text-align:left;color:rgb(51,51,51);"><div class="bar" style="padding:0px 0px 0px 45px;margin:0px;"><div class="tools" style="padding:3px 8px 10px 10px;margin:0px;font-size:9px;line-height:normal;font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;color:#C0C0C0;background-color:rgb(248,248,248);border-left:3px solid rgb(108,226,108);border-right:1px solid rgb(231,229,220);"><span>[html]</span> <a href="https://blog.csdn.net/liuxiao723846/article/details/78131732#" rel="nofollow" class="ViewSource" title="view plain" style='background-image:url("https://csdnimg.cn/release/phoenix/images/ico_plain.gif");background-position:left top;background-repeat:no-repeat;background-color:inherit;border:none;padding:1px;margin:0px 10px 0px 0px;width:16px;height:16px;text-indent:-2000px;'>view plain</a><span> <a href="https://blog.csdn.net/liuxiao723846/article/details/78131732#" rel="nofollow" class="CopyToClipboard" title="copy" style='background-image:url("https://csdnimg.cn/release/phoenix/images/ico_copy.gif");background-position:left top;background-repeat:no-repeat;background-color:inherit;border:none;padding:1px;margin:0px 10px 0px 0px;width:16px;height:16px;text-indent:-2000px;'>copy</a></span><div style="padding:0px;margin:0px;width:16px;height:16px;"></div><div style="padding:0px;margin:0px;width:16px;height:16px;"></div><span></span></div></div><ol start="1" class="dp-xml" style="border-top:none;border-right:1px solid rgb(231,229,220);border-bottom:none;border-left:none;background-color:rgb(255,255,255);color:rgb(92,92,92);"><li class="alt" style="border-top:none;border-right:none;border-bottom:none;border-left:3px solid rgb(108,226,108);color:inherit;line-height:18px;padding:0px 3px 0px 10px;margin-right:0px;margin-bottom:0px;list-style-position:outside;"><span style="margin:0px;padding:0px;border:none;color:#000000;background-color:inherit;"><span style="margin:0px;padding:0px;border:none;background-color:inherit;">[ { "headers":{"":"","":""  </span></span></li><li style="border-top:none;border-right:none;border-bottom:none;border-left:3px solid rgb(108,226,108);background-color:rgb(248,248,248);line-height:18px;padding:0px 3px 0px 10px;margin-right:0px;margin-bottom:0px;list-style-position:outside;"><span style="margin:0px;padding:0px;border:none;color:#000000;background-color:inherit;">                 },  </span></li><li class="alt" style="border-top:none;border-right:none;border-bottom:none;border-left:3px solid rgb(108,226,108);color:inherit;line-height:18px;padding:0px 3px 0px 10px;margin-right:0px;margin-bottom:0px;list-style-position:outside;"><span style="margin:0px;padding:0px;border:none;color:#000000;background-color:inherit;">     "body":"the first event"  </span></li><li style="border-top:none;border-right:none;border-bottom:none;border-left:3px solid rgb(108,226,108);background-color:rgb(248,248,248);line-height:18px;padding:0px 3px 0px 10px;margin-right:0px;margin-bottom:0px;list-style-position:outside;"><span style="margin:0px;padding:0px;border:none;color:#000000;background-color:inherit;">   },  </span></li><li class="alt" style="border-top:none;border-right:none;border-bottom:none;border-left:3px solid rgb(108,226,108);color:inherit;line-height:18px;padding:0px 3px 0px 10px;margin-right:0px;margin-bottom:0px;list-style-position:outside;"><span style="margin:0px;padding:0px;border:none;color:#000000;background-color:inherit;">   { "headers":{"":"","":""  </span></li><li style="border-top:none;border-right:none;border-bottom:none;border-left:3px solid rgb(108,226,108);background-color:rgb(248,248,248);line-height:18px;padding:0px 3px 0px 10px;margin-right:0px;margin-bottom:0px;list-style-position:outside;"><span style="margin:0px;padding:0px;border:none;color:#000000;background-color:inherit;">                 },  </span></li><li class="alt" style="border-top:none;border-right:none;border-bottom:none;border-left:3px solid rgb(108,226,108);color:inherit;line-height:18px;padding:0px 3px 0px 10px;margin-right:0px;margin-bottom:0px;list-style-position:outside;"><span style="margin:0px;padding:0px;border:none;color:#000000;background-color:inherit;">     "body":"the second event"  </span></li><li style="border-top:none;border-right:none;border-bottom:none;border-left:3px solid rgb(108,226,108);background-color:rgb(248,248,248);line-height:18px;padding:0px 3px 0px 10px;margin-right:0px;margin-bottom:0px;list-style-position:outside;"><span style="margin:0px;padding:0px;border:none;color:#000000;background-color:inherit;">   }  </span></li><li class="alt" style="border-top:none;border-right:none;border-bottom:none;border-left:3px solid rgb(108,226,108);color:inherit;line-height:18px;padding:0px 3px 0px 10px;margin-right:0px;margin-bottom:0px;list-style-position:outside;"><span style="margin:0px;padding:0px;border:none;color:#000000;background-color:inherit;">     </span></li><li style="border-top:none;border-right:none;border-bottom:none;border-left:3px solid rgb(108,226,108);background-color:rgb(248,248,248);line-height:18px;padding:0px 3px 0px 10px;margin-right:0px;margin-bottom:0px;list-style-position:outside;"><span style="margin:0px;padding:0px;border:none;color:#000000;background-color:inherit;">]  </span></li></ol></div><br style="color:rgb(51,51,51);font-size:14px;background-color:rgb(255,255,255);"><span style="color:rgb(51,51,51);font-size:14px;background-color:rgb(255,255,255);">2、简单介绍一下flume的logger sink：</span><p style="background-color:rgb(255,255,255);">记录INFO级别的日志，一般用于调试。本文将使用这种类型的sink，配置的属性：<br></p><ul style="list-style:none;color:rgb(51,51,51);font-size:14px;background-color:rgb(255,255,255);"><li style="padding:0px;">type  logger</li><li style="padding:0px;">maxBytesToLog    16    Maximum number of bytes of the Event body to log</li></ul><span style="color:rgb(51,51,51);font-size:14px;background-color:rgb(255,255,255);">注意：要求必须在 --conf 参数指定的目录下有 log4j的配置文件，可以通过-Dflume.root.logger=INFO,console在命令启动时手动指定log4j参数。</span><p style="background-color:rgb(255,255,255);"></p><p>3、应用<span style="background-color:rgb(255,255,255);"></span></p><p>3.1 Flume配置如下：</p><p><img src="https://img-blog.csdn.net/20180612150941829?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x6c19mYW4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p>3.2 结构说明</p><p><span style="color:rgb(61,70,77);font-family:'-apple-system', 'Helvetica Neue', Helvetica, Arial, 'PingFang SC', 'Hiragino Sans GB', 'WenQuanYi Micro Hei', 'Microsoft Yahei', sans-serif;text-align:left;background-color:rgb(255,255,255);">在该场景中，使用三个Flume Agent分别部署在三台Web服务器上，用来采集终端的数据，然后其数据的下沉方式都为发送到另外两个Flume Agent上，然后这两个Flume agent 将数据发送到kafka或者hdfs中</span><br></p><p>3.3 配置</p><p>3.3.1 第一层Flume配置</p><p></p><pre style="line-height:1.45;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace;margin-bottom:10px;max-width:100%;white-space:pre-line;color:rgb(86,116,130);background:rgb(242,245,249);text-align:left;"><code class="language-properties" style="font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace;margin:0px;line-height:inherit;color:rgb(51,51,51);background:transparent;border:0px;">#########################################################
##
##主要作用是监听文件中的新增数据，采集到数据之后，输出到avro
##    注意：Flume agent的运行，主要就是配置source channel sink
##  下面的a1就是agent的代号，source叫r1 channel叫c1 sink叫k1
#########################################################</code></pre><p>a1.sources  = r1<br>a1.channels = c1<br>a1.sinks    = k1 k2<br></p><p>a1.sinkgroups= g1</p>a1.sources.r1.type     = http<br>a1.sources.r1.port     = 14703<br>a1.sources.r1.channels = c1<br>a1.sources.r1.charset = UTF-8<br><pre style="line-height:1.45;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace;margin-bottom:10px;max-width:100%;white-space:pre-line;color:rgb(86,116,130);background:rgb(242,245,249);text-align:left;"><code class="language-properties" style="font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace;margin:0px;line-height:inherit;color:rgb(51,51,51);background:transparent;border:0px;">#对于channel的配置描述 使用内存作为数据的临时缓存</code></pre>a1.channels.c1.type   = memory<br>a1.channels.c1.capacity = 1000000000<br>a1.channels.c1.byteCapacityBufferPercentage = 20<br>a1.channels.c1.byteCapacity = 10240000000<br><pre style="line-height:1.45;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace;margin-bottom:10px;max-width:100%;white-space:pre-line;color:rgb(86,116,130);background:rgb(242,245,249);text-align:left;"><code class="language-properties" style="font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace;margin:0px;line-height:inherit;color:rgb(51,51,51);background:transparent;border:0px;">#对于sink的配置描述 使用avro日志做数据的消费</code></pre>a1.sinks.k1.type=avro<br>a1.sinks.k1.channel=c1<br>a1.sinks.k1.hostname=lzs01<br><p>a1.sinks.k1.port=44444</p>a1.sinks.k2.type=avro<br>a1.sinks.k2.channel=c1<br>a1.sinks.k2.hostname=lzs02<br><p>a1.sinks.k2.port=44445</p>a1.sinkgroups.g1.sinks= k1 k2  <br>a1.sinkgroups.g1.processor.type= load_balance  <br>a1.sinkgroups.g1.processor.backoff = true<br>a1.sinkgroups.g1.processor.selector = round_robin <p></p><p><br></p><p>3.3.2第二层Flume配置</p><p>tier1.sources = r1 r2<br>tier1.sinks = k1 hdfs1<br>tier1.channels = c_k1 c_hdfs1<br><br><br>#对于source的配置描述 监听avro<br>tier1.sources.r1.type = avro<br>tier1.sources.r1.bind = 0.0.0.0<br>tier1.sources.r1.port = 44444<br>tier1.sources.r1.charset = UTF-8<br><br><br>#对于source的配置描述 监听avro<br>tier1.sources.r2.type = avro<br>tier1.sources.r2.bind = 0.0.0.0<br>tier1.sources.r2.port = 44445<br>tier1.sources.r2.charset = UTF-8<br><br><br>#对于sink的配置描述 使用kafka做数据的消费<br>tier1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink<br>tier1.sinks.k1.topic = f-k-s<br>tier1.sinks.k1.brokerList = lzs01:9092,lzs02:9092,lzs03:9092<br>tier1.sinks.k1.requiredAcks = 1<br>tier1.sinks.k1.batchSize = 20<br>tier1.sinks.k1.channel = k1<br><br><br>#对于sink的配置描述 使用日志做数据的消费<br>tier1.sinks.hdfs1.type = hdfs<br>tier1.sinks.hdfs1.hdfs.path = hdfs://nameservice1/user/flume/cloud/%Y%m%d/<br>tier1.sinks.hdfs1.hdfs.filePrefix = stb-%Y-%m-%d-%H<br>tier1.sinks.hdfs1.hdfs.useLocalTimeStamp = true <br>tier1.sinks.hdfs1.hdfs.fileSuffix = .log<br>tier1.sinks.hdfs1.hdfs.inUseSuffix = .tmp<br>tier1.sinks.hdfs1.hdfs.round = true<br>tier1.sinks.hdfs1.hdfs.rollInterval = 3600<br>tier1.sinks.hdfs1.hdfs.rollCount = 0<br>tier1.sinks.hdfs1.hdfs.rollSize = 134217728<br>tier1.sinks.hdfs1.hdfs.callTimeout = 60000<br>tier1.sinks.hdfs1.hdfs.batchSize = 600<br>tier1.sinks.hdfs1.hdfs.idleTimeout = 0<br># 如果希望上面配置的日志文件滚动策略生效，则必须要配置下面这一项<br>tier1.sinks.hdfs1.hdfs.minBlockReplicas = 1<br>#配置下面两项后，保存到HDFS中的数据才是文本<br>#否则通过hdfs dfs -text查看时，显示的是经过压缩的16进制<br>tier1.sinks.hdfs1.hdfs.serializer = TEXT<br>tier1.sinks.hdfs1.hdfs.fileType = DataStream<br><br><br>#对于channel的配置描述 使用内存缓冲区域做数据的临时缓存<br><br>tier1.channels.c_k1.type   = memory<br>tier1.channels.c_k1.capacity = 1000000000<br>tier1.channels.c_k1.byteCapacityBufferPercentage = 20<br>tier1.channels.c_k1.byteCapacity = 10240000000<br><br>#对于channel的配置描述 使用文件作为数据的临时缓存<br>tier1.channels.c_hdfs1.type= file<br>tier1.channels.c_hdfs1.checkpointDir = /data/flume/cloud/filechannel/checkpoint<br>tier1.channels.c_hdfs1.dataDirs = /data/flume/cloud/filechannel/data<br>tier1.channels.c_hdfs1.useDualCheckpoints = true<br>tier1.channels.c_hdfs1.backupCheckpointDir = /data/flume/cloud/filechannel/backupCheckpoint<br>tier1.channels.c_hdfs1.checkpointInterval = 300000<br>tier1.channels.c_hdfs1.transactionCapacity=600<br>tier1.channels.c_hdfs1.capacity = 200000000<br>tier1.channels.c_hdfs1.maxFileSize = 2146435071<br><br>#通过channel将source和sink 关联起来<br>tier1.sources.r1.channels = c_k1 c_hdfs1<br>tier1.sources.r2.channels=c_k1 c_hdfs1<br>tier1.sinks.k1.channel = c_k1<br>tier1.sinks.hdfs1.channel=c_hdfs1<br></p><p>3.4 测试</p><p>3.4.1 创建kafka对应的topic</p><p>a.查看topic列表</p><p>bin/kafka-topics --list --zookeeper lzs01:2181,lzs02:2181,lzs03:2181/kafka<br></p><p>b.创建topic</p><p> bin/kafka-topics --zookeeper lzs01:2181,lzs02:2181,lzs03:2181/kafka --create --topic f-k-s  --partitions 3 --replication-factor 3<br></p><p>c.启动消费</p><p>bin/kafka-console-consumer --topic f-k-s  --bootstrap-server lzs01:9092,lzs02:9092,lzs03:9092 <br></p><p>3.4.2 启动第二层的flume</p><p>3.4.3 启动第一层的flume</p><p> bin/flume-ng agent -c conf/ -f conf/flume-httparvo.conf -n a1  -Dflume.root.logger=INFO,console<br></p><p>3.4.4 发送数据</p><p><span style="background-color:rgb(255,255,255);"><span style="background-color:rgb(255,255,255);">curl -X POST -d'[{"headers":{"h1":"v1","h2":"v2"},"body":"hello body"}]'  http://192.168.1.102:14703</span></span><br></p><p><span style="background-color:rgb(255,255,255);"><span style="background-color:rgb(255,255,255);">3.4.5查看kafka和hdfs对应的目录是否有数据</span></span></p><p><span style="background-color:rgb(255,255,255);"><span style="background-color:rgb(255,255,255);"><br></span></span></p>            </div>
                </div>