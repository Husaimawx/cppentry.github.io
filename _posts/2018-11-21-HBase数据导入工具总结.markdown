---
layout:     post
title:      HBase数据导入工具总结
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
    <div class="rich_media_content" id="js_content">
                    

                    

                    
                    
                    <p><span style="font-size:15px;">本文对HBase常用的数据导入工具进行介绍，并结合云HBase常见的导入场景，给出建议的迁移工具和参考资料。</span></p><p><span style="font-size:15px;"><br></span></p><h2><strong>HBase之间数据导入常用工具</strong></h2><p><span style="font-size:15px;">HBase提供了几种数据迁移工具，其中基于API调用的有CopyTable,Export&amp;Import。基于写HDFS的有distcp，snapshot。</span></p><p><span style="font-size:15px;">这里要说明的是，本文作为一般性的介绍，不能忽略常用的工具distcp和snapshot，但是由于云HBase默认不开启HDFS端口，所以在云HBase上面基于HDFS的方法都是用不了的。我们推荐用户使用CopyTable进行迁移，根据我们的测试，CopyTable的性能足以支撑10T以下数据的迁移。如果您的数据量比较大（超过10T），可以联系云HBase工作人员单独为您处理。</span></p><p><span style="font-size:15px;"><br></span></p><h3><strong>CopyTable</strong></h3><p><span style="font-size:15px;">CopyTable是HBase提供的一个数据同步工具，可以用于同步表的部分或全部数据。CopyTable通过运行Map-Reduce任务从源表读出数据再写入到目标表。<br>CopyTable使用只需要运行一个命令即可，命令示例：</span></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);">./bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable -Dhbase.client.scanner.caching=<span style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">200</span> -Dmapreduce.local.map.tasks.maximum=<span style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">16</span> -Dmapred.map.tasks.speculative.execution=<span style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">false</span> --peer.adr=$ZK_IP1,$ZK_IP2,$ZK_IP3<span style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">:/hbase</span> $TABLE_NAME<br></code></pre><p><br></p><p><span style="font-size:15px;">本文介绍如何使用CopyTable同步HBase数据。针对没有Hadoop集群的用户，还介绍单机运行CopyTable的配置和参数。根据我们的测试，在表不压缩的情况下，单机版CopyTable可以达到1小时100G左右的导入速度。10T以下的数据都可以使用CopyTable导入数据。</span></p><h2><br></h2><h2><span style="font-size:16px;"><strong>准备工作</strong></span></h2><p><strong><span style="font-size:15px;">1.安装HBase<br></span></strong><span style="font-size:15px;">CopyTable依赖于hadoop mapreduce。如果源HBase集群中开启了mapreduce则可以直接在源集群上运行。否则可以在另一个hadoop集群上安装HBase客户端并将hbase-site.xml文件中的zk地址指向源集群。<br>也可以单机运行，单机运行时，不需要安装hadoop，只要安装了HBase就可以使用hadoop的本地模式运行CopyTable。<br>安装和配置HBase的过程参考https://help.aliyun.com/document_detail/52056.html?spm=a2c4e.11153940.blogcont176546.17.333c5579bR1Adg。</span></p><p><span style="font-size:15px;"><br></span></p><p><strong><span style="font-size:15px;">2.创建目标表<br></span></strong><span style="font-size:15px;">使用CopyTable同步数据前，需要确保目标表存在。如果不存在需要先创建目标表。<strong>强烈建议根据数据的分布情况对目标表进行预分裂，这样能够提高写入速度。</strong></span></p><p><span style="font-size:15px;"><br></span></p><p><strong><span style="font-size:15px;">3.其他准备工作</span><br></strong></p><p><span style="font-size:15px;">需要将运行CopyTable的机器ip加入HBase的ip白名单，确保可以访问到HBase。<br>需要修改hbase-site.xml文件中的zk地址指向源集群。</span></p><p><span style="font-size:15px;">准备工作完成后，就可以运行CopyTable进行数据同步了。</span></p><p><span style="font-size:15px;"><br></span></p><h2><span style="font-size:16px;"><strong>命令示例</strong></span></h2><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);">./bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable -Dhbase.client.scanner.caching=<span style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">200</span> -Dmapreduce.local.map.tasks.maximum=<span style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">16</span> -Dmapred.map.tasks.speculative.execution=<span style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">false</span> --peer.adr=$ZK_IP1,$ZK_IP2,$ZK_IP3<span style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">:/hbase</span> $TABLE_NAME<br></code></pre><h2><span style="font-size:15px;"><br></span></h2><h2><strong><span style="font-size:16px;">参数说明</span></strong></h2><p><span style="font-size:15px;">CopyTable常用选项说明如下：<br></span></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);"><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">startrow</span> 开始行。<br><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">stoprow</span> 停止行。<br><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">starttime</span> 时间戳（版本号）的最小值。<br><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">endtime</span> 时间戳的最大值。如果不指定<span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">starttime</span>，<span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">endtime</span>不起作用。<br><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">peer</span><span style="font-size:inherit;line-height:inherit;color:rgb(165,218,45);">.adr</span> 目标集群的地址。格式为：<span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">hbase</span><span style="font-size:inherit;line-height:inherit;color:rgb(165,218,45);">.zookeeer.quorum</span><span style="font-size:inherit;color:inherit;line-height:inherit;">:hbase.zookeeper.client.port:zookeeper.znode.parent</span><br><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">families</span> 要同步的列族。多个列族用逗号分隔。<br><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">all</span><span style="font-size:inherit;line-height:inherit;color:rgb(165,218,45);">.cells</span> 删除标记也进行同步。<br></code></pre><p><span style="font-size:15px;">更多参数参见</span><span style="font-size:15px;text-decoration:none;">官方文档:http://hbase.apache.org/book.html#copy.table</span><br></p><p><span style="font-size:15px;text-decoration:none;"><br></span></p><p><span style="font-size:15px;">除copytable的参数外， 以下选项也建议在命令中进行设置：<br>(1)对于单机运行的情况，需要指定mapreduce.local.map.tasks.maximum参数，表示并行执行的最大map个数。不指定的话默认是1，所有任务都是串行执行的。(2)hbase.client.scanner.caching建议设置为大于100的数。这个数越大，使用的内存越多，但是会减少scan与服务端的交互次数，对提升读性能有帮助。<br>(3)mapred.map.tasks.speculative.execution建议设置为false，避免因预测执行机制导致数据写两次。</span></p><p><span style="font-size:15px;"><br></span></p><p><span style="font-size:15px;">另外，如果是在E-mapreduce集群上执行CopyTable,需要注意E-mapreduce默认的hbase-site.xml文件中配置了phoenix，所以需要导入phoenix的jar包，否则运行时会报错:<br></span></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);">-libjars <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$HBASE_HOME</span>/lib/phoenix-<span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$PhoenixVersion</span>-HBase-<span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$HBaseVersion</span>-server.jar<br></code></pre><p><span style="font-size:15px;"></span><br></p><h2><strong><span style="font-size:16px;">性能数据</span></strong></h2><p><span style="font-size:15px;">我们使用两个云HBase集群来进行导入数据的测试。两个集群配置一致：3台region-server，机器配置为4CPU
 8GB，数据盘为SSD云盘。源数据使用hbase 
pe产生，共16亿条数据，表采用SNAPPY压缩，数据文件大小为71.9GB，共有32个region。数据为单行单列，rowkey长度26字节，列长度100字节。</span></p><p><span style="font-size:15px;"><br>使用一台4CPU 8GB的ECS执行CopyTable，测试结果如下表：</span></p><table><thead><tr style="border-top:1px solid rgb(198,203,209);"><th style="text-align:left;border-top-width:1px;border-color:rgb(223,226,229);" width="60"><span style="font-size:15px;">测试轮次</span></th><th style="text-align:left;border-top-width:1px;border-color:rgb(223,226,229);" width="221"><span style="font-size:15px;">测试条件</span></th><th style="text-align:left;border-top-width:1px;border-color:rgb(223,226,229);"><span style="font-size:15px;">导入时间</span></th><th style="text-align:left;border-top-width:1px;border-color:rgb(223,226,229);"><span style="font-size:15px;">导入速度(rec/s)</span></th><th style="text-align:left;border-top-width:1px;border-color:rgb(223,226,229);"><span style="font-size:15px;">导入速度(MB/s)</span></th></tr></thead><tbody><tr style="border-top:1px solid rgb(198,203,209);"><td style="border-color:rgb(223,226,229);" width="55"><span style="font-size:15px;">1</span></td><td style="border-color:rgb(223,226,229);" width="200"><span style="font-size:15px;">-Dhbase.client.scanner.caching=100 -Dmapreduce.local.map.tasks.maximum=16</span></td><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">1h21min</span></td><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">329218</span></td><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">15.15</span></td></tr><tr style="background-color:rgb(246,248,250);border-top:1px solid rgb(198,203,209);"><td style="border-color:rgb(223,226,229);" width="55"><span style="font-size:15px;">2</span></td><td style="border-color:rgb(223,226,229);" width="200"><span style="font-size:15px;">在测试1的基础上修改-Dhbase.client.scanner.caching=500</span></td><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">1h14min</span></td><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">360360</span></td><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">16.58</span></td></tr><tr style="border-top:1px solid rgb(198,203,209);"><td style="border-color:rgb(223,226,229);" width="55"><span style="font-size:15px;">3</span></td><td style="border-color:rgb(223,226,229);" width="200"><span style="font-size:15px;">在测试2的基础上按照源表数据分布对目标表进行预分裂再进行导入</span></td><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">1h5min</span></td><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">410256</span></td><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">18.88</span></td></tr></tbody></table><p><br></p><p><span style="font-size:15px;">测试过程中的相关监控如下：</span></p><h3><span style="font-size:15px;">测试1</span></h3><p style="text-align:center;"><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/Yicunacl1x3vb7K1rzuoLCic74bREt9LmGTpgvdiaVXrEkeC8wZ1xZTOB4pSyuekBEcDbyia93Ktsluib49fCLR1kYg/640?wx_fmt=png" alt="640?wx_fmt=png"></p><h3><span style="font-size:15px;">测试2</span></h3><p style="text-align:center;"><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/Yicunacl1x3vb7K1rzuoLCic74bREt9LmGJIyNPal1alYGrwc9Gg8ob4WdLShcDBjJfO5HWtUFH8te246fUBKvYA/640?wx_fmt=png" alt="640?wx_fmt=png"></p><h3><span style="font-size:15px;">测试3</span></h3><p style="text-align:center;"><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/Yicunacl1x3vb7K1rzuoLCic74bREt9LmGsMMaoibdfrXicPCGKibRoj9CA4DbpdCyTZwrbicxiaPAjGNJTLWEIvfh3zw/640?wx_fmt=png" alt="640?wx_fmt=png"></p><p><br></p><h3><strong>Export&amp;Import</strong></h3><p><span style="font-size:15px;">Export将HBase表内容dump到一个顺序文件(sequence)中。Import将Export得到的顺序文件内容写入HBase表。和CopyTable一样，Export和Import也是通过运行map-reduce任务来执行的。<br>Export和Import命令格式：</span></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);">bin/hbase org.apache.hadoop.hbase.mapreduce.Export <span style="font-size:inherit;color:inherit;line-height:inherit;">&lt;<span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">tablename</span>&gt;</span> <span style="font-size:inherit;color:inherit;line-height:inherit;">&lt;<span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">outputdir</span>&gt;</span> [<span style="font-size:inherit;color:inherit;line-height:inherit;">&lt;<span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">versions</span>&gt;</span> [<span style="font-size:inherit;color:inherit;line-height:inherit;">&lt;<span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">starttime</span>&gt;</span> [<span style="font-size:inherit;color:inherit;line-height:inherit;">&lt;<span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">endtime</span>&gt;</span>]]]<br>bin/hbase org.apache.hadoop.hbase.mapreduce.Import <span style="font-size:inherit;color:inherit;line-height:inherit;">&lt;<span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">tablename</span>&gt;</span> <span style="font-size:inherit;color:inherit;line-height:inherit;">&lt;<span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">inputdir</span>&gt;</span><br></code></pre><p><span style="font-size:15px;"></span><br></p><p><span style="font-size:16px;"><strong>distcp</strong></span></p><p><span style="font-size:15px;">distcp是Hadoop提供的用于复制HDFS文件的工具，经常也被用来同步HBase数据。<br>使用distcp进行数据同步的步骤如下：<br>(1)源集群停止写入。<br>(2)将数据文件复制到目标集群上。运行</span></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);"> <span style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">hadoop</span> distcp <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$SrcFilePath</span> <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$DstFilePath</span> </code></pre><p><span style="font-size:15px;">(3)然后在目标集群上执行</span><br></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);"><span style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">hbase</span> hbck -fixAssignments -fixMeta<br></code></pre><h3><br></h3><h3><strong>snapshot</strong></h3><p><span style="font-size:15px;">HBase snapshot可以在对region-server影响很小的情况下创建快照、将快照复制到另一个集群。<br>使用snapshot迁移数据的操作步骤如下：<br>(1)在源表上创建snapshot。<br></span></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);"><span style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">hbase</span> snapshot create -n <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$SnapshotName</span> -t <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$TableName</span> <br></code></pre><p><span style="font-size:15px;">(2)将snapshot拷贝到目标集群的HDFS上。</span></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);"><span style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">hbase</span> org.apache.hadoop.hbase.snapshot.ExportSnapshot -snapshot <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$SnapshotName</span> -copy-from <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$SrcSnapshotPath</span> -copy-to <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$DstSnapshotPath</span></code></pre><p><span style="font-size:15px;color:rgb(36,41,46);">(3)在目标集群恢复snapshot。在hbase shell中执行</span></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);"><span style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">restore_snapshot</span> <span style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">'<span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$SnapshotName</span>'</span><br></code></pre><h2><br></h2><h2><strong><span style="font-size:16px;">异构数据导入HBase常用工具</span></strong></h2><p><span style="font-size:15px;">其他类型数据向HBase导入常见的工具有：<br>(1)关系数据库可以使用Sqoop导入。<br>(2)其他类型数据可以使用DataX。<br>(3)如果是周期性数据导入需求，可以使用数据集成。</span></p><p><br></p><h3><strong>Sqoop</strong></h3><p><span style="font-size:15px;">Sqoop是一个用来将Hadoop和关系型数据库中的数据相互转移的工具。Sqoop的数据同步也是通过map-reduce实现的。<br>使用Sqoop同步数据只需要运行一个命令即可，命令示例：</span></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);"><span style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">sqoop</span> import -Dmapreduce.local.map.tasks.maximum=<span style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">8</span> --connect jdbc:mysql://<span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$mysqlURL</span>:3306/<span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$database</span> --table <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$table</span> --hbase-table <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$hbaseTable</span> --column-family <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$columnFamily</span> --hbase-row-key <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$mysqlColumn</span> --username <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$mysqlUser</span> -m <span style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">8</span> -P<br></code></pre><p><span style="color:rgb(36,41,46);"></span><br></p><p><span style="font-size:15px;">Sqoop是一个用来将Hadoop和关系型数据库中的数据相互转移的工具。本文介绍如何使用sqoop将数据从Mysql导入到HBase。从成本的角度考虑，针对没有hadoop集群的用户，重点介绍单机运行sqoop的配置和参数。</span></p><p><span style="font-size:15px;"><br></span></p><h2><span style="font-size:16px;"><strong>安装</strong></span></h2><p><span style="font-size:15px;">要完成从MyDW向HBase导入数据的任务，需要安装和配置的软件包括hadoop,sqoop,mysql-connector和HBase。我们针对单机运行sqoop的情况提供了四合一的安装包简化安装流程。如果是在hadoop集群上运行sqoop，可以参考Sqoop官方文档进行配置。<br>以下介绍单机版的安装流程。</span></p><p><span style="font-size:15px;">1.下载安装包。把文件放在~目录。</span></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);"><span style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">cd</span> <span style="font-size:inherit;color:inherit;line-height:inherit;">~ <br>wget</span> http://public-hbase.oss-cn-hangzhou.aliyuncs.com/installpackage/sqoop-all.tar.gz<br></code></pre><p><span style="font-size:15px;">2.解压文件：解压，进入解压后的目录sqoop-all。</span></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);"><span style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">tar</span> -xzvf sqoop-<span style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">all</span>.tar.gzcd scoop-<span style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">all</span><br></code></pre><p><span style="font-size:15px;">3.设置环境变量。</span></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);"><span style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">cp</span> sqoop-env.sh /etc/profile.d; <span style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">source</span> /etc/profile</code></pre><p><span style="font-size:15px;">4.修改hbase-1.1.9/conf/hbase-site.xml文件，添加集群的
 ZK 
地址。可参考云HBase帮助文档:https://help.aliyun.com/document_detail/52056.html?spm=a2c4e.11153940.blogcont176524.13.1c1ba954n0tDas</span><br><span style="font-size:15px;"></span></p><p><span style="font-size:15px;"><br></span></p><h2><strong><span style="font-size:16px;">准备工作</span></strong></h2><p><span style="font-size:15px;">1.设置ip白名单。需要把运行sqoop的机器ip添加到云HBase的ip白名单中。如果Mysql是云上的RDS，也需要修改RDS的ip白名单。总之就是保证这台机器能够访问mysql和HBase。<br>2.确保目标表存在。如果不存在需要先建表。</span></p><p><span style="font-size:15px;"><br></span></p><h2><strong><span style="font-size:16px;">运行</span></strong></h2><p><span style="font-size:15px;">安装完成并配置好ip白名单之后，就可以运行sqoop进行数据导入了。</span></p><h4><span style="font-size:16px;">命令示例</span></h4><p><span style="font-size:15px;"> 以下是单机运行sqoop的命令示例：</span></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);"><span style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">sqoop</span> import -Dmapreduce.local.map.tasks.maximum=<span style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">8</span> --connect jdbc:mysql://<span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$mysqlURL</span>:3306/<span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$database</span> --table <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$table</span> --hbase-table <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$hbaseTable</span> --column-family <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$columnFamily</span> --hbase-row-key <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$mysqlColumn</span> --username <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$mysqlUser</span> -m <span style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">8</span> -P<br></code></pre><p><span style="font-size:15px;"></span><br></p><p><strong><span style="font-size:16px;">常用参数说明</span></strong></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);"><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">--connect JDBC连接字符串</span><br><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">--table 要导入的mysql表名 </span><br><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">--columns 要导入的列</span><br><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">--where 过滤条件</span><br><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">--hbase-table hbase表名 </span><br><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">--column-family hbase列族</span><br><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">--hbase-row-key 用来做HBase rowkey的mysql列名 </span><br><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">--username mysql用户名</span><br><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">-m map个数，默认为4</span><br></code></pre><p><span style="font-size:15px;"><br></span></p><p><span style="font-size:15px;">此外，对于单机运行，还需要指定mapreduce.local.map.tasks.maximum参数，表示并行执行的最大map个数，否则默认为1，map就变成串行执行的了。也可以根据需要调整其他hadoop参数。 <br>sqoop import的其他参数可参考[sqoop-import文档](<br>http://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html#_literal_sqoop_import_literal)。</span><br></p><p><span style="font-size:15px;"><br></span></p><h2><strong><span style="font-size:16px;">公网运行</span></strong></h2><p><span style="font-size:15px;">一般来说，我们不建议在公网执行数据同步任务，因为可能会有潜在的安全隐患以及绕行公网带来的延时增大、性能问题等。但是考虑到开发测试阶段的便利，HBase也提供了公网访问的功能，我们可以通过配置HBase公网访问实现在公网运行数据同步任务。</span></p><p><span style="font-size:15px;"><br></span></p><h3><strong><span style="font-size:16px;">开通公网访问</span></strong></h3><p><span style="font-size:15px;">开通公网访问的方法参见公网访问方案。<br>公网访问需要使用阿里云定制的客户端，具体的下载和配置参见使用 Shell 访问。<br>完成后，如果能通过hbase shell访问，就说明这一步的配置已经成功了。</span></p><h3><span style="font-size:15px;">修改sqoop环境变量</span></h3><p><span style="font-size:15px;">sqoop环境变量中和HBase相关的环境变量主要是HBASE_HOME，需要把这个变量改成阿里云定制客户端所在的目录。运行vi sqoop-en.sh，修改如下内容：</span></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);"><span style="font-size:inherit;line-height:inherit;color:rgb(128,128,128);">#export HBASE_HOME=~/sqoop-all/hbase-1.1.9 注释这一行，替换成：</span><br><span style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">export</span> HBASE_HOME=~/sqoop-all/alihbase-1.1.4 <span style="font-size:inherit;line-height:inherit;color:rgb(128,128,128);">#改成阿里云客户端所在的目录</span><br></code></pre><p><span style="font-size:15px;">然后</span><br><span style="font-size:15px;"></span></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);"><span style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">cp</span> sqoop-env.sh /etc/profile.d; <span style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">source</span> /etc/profile<br></code></pre><p><span style="font-size:15px;">环境变量生效之后，就可以在公网执行导入操作了。</span><br><span style="font-size:15px;"></span></p><h3><br></h3><h3><strong>DataX</strong></h3><p><span style="font-size:15px;">DataX 是广泛使用的离线数据同步工具/平台，实现包括 MySQL、Oracle、SqlServer、Postgre、HDFS、Hive、ADS、HBase、OTS、ODPS 等各种异构数据源之间高效的数据同步功能。<br>DataX本身作为数据同步框架，将不同数据源的同步抽象为从源头数据源读取数据的Reader插件，以及向目标端写入数据的Writer插件，理论上DataX框架可以支持任意数据源类型的数据同步工作。同时DataX插件体系作为一套生态系统,
 每接入一套新数据源该新加入的数据源即可实现和现有的数据源互通。<br>使用DataX进行数据同步的步骤如下：<br>(1)编写作业的配置文件。配置文件为json格式，具体格式可参考这里：</span></p><p><span style="font-size:15px;">https://github.com/alibaba/DataX</span></p><p><span style="font-size:15px;">(2)运行DataX。执行命令</span></p><pre style="font-size:inherit;color:inherit;line-height:inherit;"><code style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);"><span style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">python</span> datax.py <span style="font-size:inherit;line-height:inherit;color:rgb(98,151,85);">$config</span>.json<br></code></pre><p><span style="font-size:15px;">DataX的使用参考官方文档:https://github.com/alibaba/DataX/wiki/Quick-Start?</span><span style="font-size:15px;">spm=a2c4e.11153940.blogcont178446.21.dacd1078SCL03L<br></span></p><h3><br></h3><h3><strong><span style="font-size:16px;">数据集成</span></strong></h3><p><span style="font-size:15px;">数据集成是阿里集团对外提供的的数据同步平台，其底层也基于DataX。由于数据集成提供了调度的功能，所以很适合用于周期性导入数据或是与其他任务有依赖关系的情况。<br>使用数据集成同步数据的步骤较复杂，具体请参考这里：</span></p><p><span style="font-size:15px;">https://yq.aliyun.com/articles/165981?spm=a2c4e.11153940.blogcont178446.22.dacd1078SCL03L</span></p><p><br></p><h2><strong>云HBase数据迁移指南</strong></h2><table><thead><tr style="border-top:1px solid rgb(198,203,209);"><th style="text-align:left;border-top-width:1px;border-color:rgb(223,226,229);"><span style="font-size:15px;">场景</span></th><th style="text-align:left;border-top-width:1px;border-color:rgb(223,226,229);"><span style="font-size:15px;">建议迁移工具</span></th><th style="text-align:left;border-top-width:1px;border-color:rgb(223,226,229);" width="295"><span style="font-size:15px;">参考资料</span></th></tr></thead><tbody><tr style="border-top:1px solid rgb(198,203,209);"><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">HBase-&gt;HBase，数据量&lt;10T</span></td><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">CopyTable</span></td><td style="border-color:rgb(223,226,229);" width="274"><p><span style="font-size:15px;">使用CopyTable同步HBase数据：</span></p><p><span style="font-size:14px;">https://yq.aliyun.com/articles/176546?spm=a2c4e.11153940.blogcont178446.23.dacd1078SCL03L</span></p></td></tr><tr style="background-color:rgb(246,248,250);border-top:1px solid rgb(198,203,209);"><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">HBase-&gt;HBase，数据量&gt;10T</span></td><td colspan="2" style="border-color:rgb(223,226,229);" width="412"><span style="font-size:15px;">联系云HBase工作人员处理</span></td></tr><tr style="border-top:1px solid rgb(198,203,209);"><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">HBase经典网络集群迁移到vpc网络</span></td><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">使用ClassicLink打通网络。迁移工具参考具体场景</span></td><td style="border-color:rgb(223,226,229);" width="274"><p><span style="font-size:15px;">HBase经典网络集群迁移到vpc网络</span><span style="font-size:15px;">：</span></p><p><span style="font-size:14px;">https://yq.aliyun.com/articles/328405?spm=a2c4e.11153940.blogcont178446.24.dacd1078SCL03L</span></p></td></tr><tr style="background-color:rgb(246,248,250);border-top:1px solid rgb(198,203,209);"><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">关系型数据库-&gt;HBase</span></td><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">Sqoop</span></td><td style="border-color:rgb(223,226,229);" width="274"><p><span style="font-size:15px;">使用Sqoop从MySQL向云HBase同步数据</span><span style="font-size:15px;">：</span></p><p><span style="font-size:14px;">https://yq.aliyun.com/articles/176524?spm=a2c4e.11153940.blogcont178446.25.dacd1078SCL03L</span></p></td></tr><tr style="border-top:1px solid rgb(198,203,209);"><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">其他类型数据源一次性导入HBase</span></td><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">DataX</span></td><td style="border-color:rgb(223,226,229);" width="274"><p><span style="font-size:15px;">DataX官方文档</span><span style="font-size:15px;">：</span></p><p><span style="font-size:14px;">https://github.com/alibaba/DataX/wiki/Quick-Start?spm=a2c4e.11153940.blogcont178446.26.dacd1078SCL03L</span></p></td></tr><tr style="background-color:rgb(246,248,250);border-top:1px solid rgb(198,203,209);"><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">导入Phoenix表</span></td><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">Datax</span></td><td style="border-color:rgb(223,226,229);" width="274"><p><span style="font-size:15px;">HBase11xsqlwriter插件文档</span><span style="font-size:15px;">：</span></p><p><span style="font-size:14px;">https://github.com/alibaba/DataX/blob/master/hbase11xsqlwriter/doc/hbase11xsqlwriter.md?spm=a2c4e.11153940.blogcont178446.27.dacd1078SCL03L&amp;file=hbase11xsqlwriter.md</span></p></td></tr><tr style="border-top:1px solid rgb(198,203,209);"><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">其他类型数据源周期性导入HBase</span></td><td style="border-color:rgb(223,226,229);"><span style="font-size:15px;">数据集成</span></td><td style="border-color:rgb(223,226,229);" width="274"><p><span style="font-size:15px;">step-by-step通过数据集成同步数据到HBase 数据集成概述</span><span style="font-size:15px;">：</span></p><p><span style="font-size:15px;">https://yq.aliyun.com/articles/165981?spm=a2c4e.11153940.blogcont178446.28.dacd1078SCL03L</span></p></td></tr></tbody></table><p><br></p><p style="min-height:1em;line-height:1.6em;border-color:rgb(18,149,39);color:inherit;">猜你喜欢</p><p style="min-height:1em;line-height:1.6em;color:inherit;border-color:rgb(18,149,39);"><br></p><p style="min-height:1em;line-height:1.6em;color:inherit;border-color:rgb(18,149,39);"><br></p><p style="min-height:1em;line-height:1.6em;color:inherit;border-color:rgb(18,149,39);"><br></p><p style="min-height:1em;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3ODUxMzQxMA==&amp;mid=2663994491&amp;idx=1&amp;sn=95fe95ff6f9451b25d789a96d126ae57&amp;chksm=847c6016b30be9001f03a2653897b4c1c6a1cf11ff285f4ffb72ed54be29cc2973bcb6cbc04f&amp;scene=21#wechat_redirect" rel="nofollow" style="color:rgb(255,169,0);">#大数据和云计算机技术社区#博客精选（2017）</a><br></p><p style="min-height:1em;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3ODUxMzQxMA==&amp;mid=2663994350&amp;idx=1&amp;sn=13c264dd596408df24acfb4acfd1cbfc&amp;chksm=847c6783b30bee959a9f5f58f1112de38cdb7ac6e5f097346911d6dd8ad6505e14b87f5e71a9&amp;scene=21#wechat_redirect" rel="nofollow" style="color:rgb(255,169,0);">NoSQL 还是 SQL ？这一篇讲清楚</a><br></p><p style="min-height:1em;"><span style="color:#FFA900;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3ODUxMzQxMA==&amp;mid=2663994245&amp;idx=1&amp;sn=18985825170e51b5665390b2dabda326&amp;chksm=847c67e8b30beefea82e331ba2c2a8bf077e7eef226356a74bc9b112736fe84527f1a6fa6830&amp;scene=21#wechat_redirect" rel="nofollow" style="color:rgb(255,169,0);">阿里的OceanBase解密</a></span></p><p style="min-height:1em;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3ODUxMzQxMA==&amp;mid=2663994424&amp;idx=1&amp;sn=5ce873e5b062c41d9d3feb169421de81&amp;chksm=847c6055b30be94356ff5f6a7752af218a04a96ab915ff1bfad6b8c8a60078d953d4a9e36292&amp;scene=21#wechat_redirect" rel="nofollow" style="color:rgb(255,169,0);">#大数据和云计算技术#: "四有"社区介绍</a></p><p style="min-height:1em;"><span style="color:#FFA900;">大数据和云计算技术周报（第56期）</span></p><p style="min-height:1em;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3ODUxMzQxMA==&amp;mid=2663994281&amp;idx=1&amp;sn=3bf17f41fd00d5ff1bd74044ab61c6fc&amp;chksm=847c67c4b30beed20a2b746511aeb029466ad7f40c5a92a8c39aba6812bdb46298a717bd7d25&amp;scene=21#wechat_redirect" rel="nofollow" style="color:rgb(255,169,0);">新数仓系列：Hbase周边生态梳理（1）</a></p><p style="min-height:1em;"><span style="color:#FFA900;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3ODUxMzQxMA==&amp;mid=2663994165&amp;idx=1&amp;sn=6fe5e33d5ab6ac7ca96e79f8d4e47b90&amp;chksm=847c6758b30bee4e6eb784516668e7487a206bb88ab50aca2996968b9a994ceafa26769de478&amp;scene=21#wechat_redirect" rel="nofollow" style="color:rgb(255,169,0);">《大数据架构详解》第2次修订说明</a></span></p><p style="min-height:1em;"><span style="color:#FFA900;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3ODUxMzQxMA==&amp;mid=2663994233&amp;idx=1&amp;sn=854040597998b707f7089bb303346a79&amp;chksm=847c6714b30bee029af0e0ae09fc02fa2b4fea30af0c6f8f2fc5fd513455c5b3da9e477b2184&amp;scene=21#wechat_redirect" rel="nofollow" style="color:rgb(255,169,0);">简单梳理跨数据中心数据库</a></span></p><p style="min-height:1em;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3ODUxMzQxMA==&amp;mid=2663994186&amp;idx=1&amp;sn=b056116636ee348c80d224a7efc7b0d9&amp;chksm=847c6727b30bee310889ad2bc72a09cb26635ff801d5e31bc0c49e13d8c9f04ae583cb7ca7b4&amp;scene=21#wechat_redirect" rel="nofollow" style="color:rgb(255,169,0);">云观察系列：漫谈运营商公有云发展史</a></p><p style="min-height:1em;"><span style="color:#FFA900;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3ODUxMzQxMA==&amp;mid=2663994181&amp;idx=1&amp;sn=12a19f42d855361f6850ea4a5f7c5bb5&amp;chksm=847c6728b30bee3e74830b458243b264ed8a4841e3c3e30fb89fc1f95d6bca3cc748ea1d5e12&amp;scene=21#wechat_redirect" rel="nofollow" style="color:rgb(255,169,0);">云观察系列：百度云的一波三折</a></span><br></p><p style="min-height:1em;"><span style="color:#FFA900;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3ODUxMzQxMA==&amp;mid=2663994176&amp;idx=1&amp;sn=22293c8dca2bd0d59c79bddcc689379a&amp;chksm=847c672db30bee3b83bfcff9d23e5e08c85b685f425d49bbcc3db02be80010f4f9848e95cb60&amp;scene=21#wechat_redirect" rel="nofollow" style="color:rgb(255,169,0);">云观察系列：阿里云战略观察</a></span></p><p style="min-height:1em;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3ODUxMzQxMA==&amp;mid=2663994152&amp;idx=1&amp;sn=b5ee27c116f0ad80a0aabf7d2a1922eb&amp;chksm=847c6745b30bee537f950387c63d1044ef413cb9795929ecb03bf56106c33da4cd363a659248&amp;scene=21#wechat_redirect" rel="nofollow" style="color:rgb(255,169,0);">超融合方案分析系列（7）思科超融合方案分析</a></p><p style="min-height:1em;line-height:1.6em;border-color:rgb(18,149,39);color:inherit;">加入技术讨论群</p><p style="min-height:1em;line-height:1.6em;color:inherit;border-color:rgb(18,149,39);"><br></p><p style="min-height:1em;line-height:1.6em;color:inherit;border-color:rgb(18,149,39);"><br></p><p style="min-height:1em;line-height:1.6em;color:inherit;border-color:rgb(18,149,39);"><br></p><p style="min-height:1em;"><span style="color:#3E3E3E;">《大数据和云计算技术》社区群</span><span style="color:#CC0000;">人数已经3000+</span><span style="color:#3E3E3E;">，欢迎大家加下面助手微信，拉大家进群，自由交流。</span><br></p><p style="min-height:1em;text-align:center;"><img width="276" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/EIMsXZPn4OXFtpI13ys0NOdj8PGgwPVJAfXQzbQfBMadrDMibL9w1yb7iaoxnATficcoSggSIRxp3ycbzoia2W9Orw/640?wx_fmt=jpeg" alt="640?wx_fmt=jpeg"></p><p style="min-height:1em;"><br></p><p style="min-height:1em;">喜欢QQ群的，可以扫描下面二维码：</p><p style="min-height:1em;text-align:center;"><img width="241" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/EIMsXZPn4OXFtpI13ys0NOdj8PGgwPVJg453YRribn1xzh6B2h6ibrYc71Y175J7VMCRAwBOXf0HpibAE71hUmqKA/640?wx_fmt=jpeg" alt="640?wx_fmt=jpeg"></p><p style="min-height:1em;">欢迎大家通过二维码打赏支持技术社区（<span style="color:#D92142;">英雄请留名，社区感谢您，打赏次数超过108+</span>）：</p><p style="min-height:1em;text-align:center;"><img width="253" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/EIMsXZPn4OXFtpI13ys0NOdj8PGgwPVJd9NSewrZzIiaRojCFiaWictPmLibQ7RM19ZQbnqLzhxkr2zicfA29thwvJg/640?wx_fmt=jpeg" alt="640?wx_fmt=jpeg"></p><p><br></p>
                </div>
              </div>
                </div>