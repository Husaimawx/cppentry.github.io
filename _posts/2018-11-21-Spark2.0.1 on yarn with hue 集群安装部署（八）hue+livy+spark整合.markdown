---
layout:     post
title:      Spark2.0.1 on yarn with hue 集群安装部署（八）hue+livy+spark整合
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h1 id="hue-livy-spark整合">hue livy spark整合</h1>



<h3 id="1配置hue">1、配置hue</h3>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">cd</span> /bigdata/hue/desktop/conf
vim /hue.ini</code></pre>

<p>找到[spark]选项进行修改：</p>



<pre class="prettyprint"><code class=" hljs vhdl">[spark]
  # Host address <span class="hljs-keyword">of</span> the Livy Server.
 livy_server_host=bigdata1

  # <span class="hljs-keyword">Port</span> <span class="hljs-keyword">of</span> the Livy Server.
 livy_server_port=<span class="hljs-number">8998</span>

  # Configure Livy <span class="hljs-keyword">to</span> start <span class="hljs-keyword">in</span> local <span class="hljs-attribute">'process</span>' mode, <span class="hljs-keyword">or</span> <span class="hljs-attribute">'yarn</span>' workers.
 livy_server_session_kind=yarn

  # Host <span class="hljs-keyword">of</span> the Sql Server
 sql_server_host=bigdata1

  # <span class="hljs-keyword">Port</span> <span class="hljs-keyword">of</span> the Sql Server
 sql_server_port=<span class="hljs-number">10008</span></code></pre>

<p>此处不配置也是可以的，将采用默认配置，以上显示内容就是默认配置。</p>



<h3 id="2启动hue">2、启动hue</h3>



<pre class="prettyprint"><code class=" hljs mel">/bigdata/hue/build/<span class="hljs-keyword">env</span>/bin/supervisor</code></pre>



<h3 id="3启动livy">3、启动livy</h3>



<pre class="prettyprint"><code class=" hljs axapta">/bigdata/livy/bin/livy-<span class="hljs-keyword">server</span></code></pre>

<p>启动livy用于编写scala、pyspark、R等语言。</p>



<h3 id="4spark测试">4、spark测试</h3>

<p>浏览器选择谷歌或者火狐较好，其他浏览器可能存在不兼容问题。打开页面： <br>
<a href="http://bigdata1:8888/" rel="nofollow">http://bigdata1:8888/</a> <br>
登入后进入quick start页面。该页面未提示spark未配置，表示livy和hue配置成功，启动thriftserver则表示hive已经配置成功了。 <br>
<img src="https://img-blog.csdn.net/20161128220230165" alt="这里写图片描述" title=""></p>



<h4 id="1测试scala">1）、测试scala</h4>

<p>打开netobooks <br>
点击+号，选择scala选项，执行以下代码，做一个简单wordcount测试。</p>



<pre class="prettyprint"><code class=" hljs avrasm">sc<span class="hljs-preprocessor">.textFile</span>(<span class="hljs-string">"/test"</span>)<span class="hljs-preprocessor">.faltMap</span>(_<span class="hljs-preprocessor">.split</span>(<span class="hljs-string">" "</span>))<span class="hljs-preprocessor">.map</span>((_,<span class="hljs-number">1</span>))<span class="hljs-preprocessor">.reduceByKey</span>(_+_)<span class="hljs-preprocessor">.collect</span><span class="hljs-comment">; </span></code></pre>

<p><img src="https://img-blog.csdn.net/20161128220356520" alt="这里写图片描述" title=""></p>



<h4 id="2pyspark测试">2)、pySpark测试</h4>

<p>点击+号，选择pySpark选项，执行以下代码，做一个简单的wordcount测试。</p>



<pre class="prettyprint"><code class=" hljs avrasm">sc<span class="hljs-preprocessor">.textFile</span>(<span class="hljs-string">"/test"</span>)<span class="hljs-preprocessor">.flatMap</span>(lambda <span class="hljs-built_in">x</span>:<span class="hljs-built_in">x</span><span class="hljs-preprocessor">.split</span>(<span class="hljs-string">" "</span>))<span class="hljs-preprocessor">.map</span>(lambda <span class="hljs-built_in">x</span>:(<span class="hljs-built_in">x</span>,<span class="hljs-number">1</span>))<span class="hljs-preprocessor">.reduceByKey</span>(lambda <span class="hljs-built_in">x</span>,<span class="hljs-built_in">y</span>:<span class="hljs-built_in">x</span>+<span class="hljs-built_in">y</span>)<span class="hljs-preprocessor">.collect</span>()<span class="hljs-comment">;</span></code></pre>

<p><img src="https://img-blog.csdn.net/20161128220451353" alt="这里写图片描述" title=""></p>



<h4 id="3r测试">3）、R测试</h4>

<p><img src="https://img-blog.csdn.net/20161128220531789" alt="这里写图片描述" title=""></p>

<p>由于sparkR使用yarn-cluster模式运行，所以每个Executor主机必须安装R已经rJava <br>
每个Executor主机安装完成R和rJava后，安装步骤参考前一个章节。 <br>
将该路径下的</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-variable">$SPARK_HOME</span>/examples/src/main/resources/people.json</code></pre>

<p>people.json文件上传至hdfs的根目录中。执行测试代码：</p>



<pre class="prettyprint"><code class=" hljs avrasm">sparkR<span class="hljs-preprocessor">.session</span>(master=<span class="hljs-string">"yarn"</span>)
people &lt;- read<span class="hljs-preprocessor">.df</span>(<span class="hljs-string">"/people.json"</span>, <span class="hljs-string">"json"</span>)
head(people)</code></pre>

<p>执行结果： <br>
<img src="https://img-blog.csdn.net/20161128220737292" alt="这里写图片描述" title=""></p>



<h4 id="4spark-submit-jar测试">4）、spark submit jar测试</h4>

<p>点击+号，选择spark submit jar选项，执行以下代码，做一个简单的pi测试。 <br>
<img src="https://img-blog.csdn.net/20161128220830512" alt="这里写图片描述" title=""> <br>
path指定的路径为hdfs中的路径，点击path右侧的按钮，弹出选择框，将jar包上传至hdfs中，并选中hdfs中的jar包，便会自动生成路径。输入calss，如果有入参可以点击添加arguments，点击右上角的齿轮可以设置执行的相关配置： <br>
<img src="https://img-blog.csdn.net/20161128220901716" alt="这里写图片描述" title=""> <br>
点击运行。 <br>
出现异常： <br>
<img src="https://img-blog.csdn.net/20161128220941058" alt="这里写图片描述" title=""></p>

<p>hue日志： <br>
<img src="https://img-blog.csdn.net/20161128221021390" alt="这里写图片描述" title=""></p>

<p>livy日志： <br>
<img src="https://img-blog.csdn.net/20161128221052637" alt="这里写图片描述" title=""></p>

<p>错误排查： <br>
1）、在测试livy-batch提交jar包的时候，livy到spark是可以正常联通。 <br>
2）、spark-submit的默认启动模式已经改成了yarn-cluster <br>
3）、且在任务浏览器中并没有该任务的提交记录，所以可以判断hue发送数据到livy，livy进行解析时就报错了。 <br>
导致的原因： <br>
hue发送数据到livy不符合restful api规范。通过查询github中的是否有该bug处于open状态，果然有： <br>
地址： <br>
<a href="https://github.com/cloudera/hue/pull/441/files" rel="nofollow">https://github.com/cloudera/hue/pull/441/files</a> <br>
修改该文件内容： <br>
 desktop/libs/notebook/src/notebook/connectors/spark_batch.py</p>



<pre class="prettyprint"><code class=" hljs cs">   def execute(self, notebook, snippet):


     api = get_spark_api(self.user)


-


-    properties = {


-        <span class="hljs-string">'file'</span>: snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-keyword">get</span>(<span class="hljs-string">'app_jar'</span>),


-        <span class="hljs-string">'className'</span>: snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-keyword">get</span>(<span class="hljs-string">'class'</span>),


-        <span class="hljs-string">'args'</span>: snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-keyword">get</span>(<span class="hljs-string">'arguments'</span>),


-        <span class="hljs-string">'pyFiles'</span>: snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-keyword">get</span>(<span class="hljs-string">'py_file'</span>),


-        <span class="hljs-string">'files'</span>: snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-keyword">get</span>(<span class="hljs-string">'files'</span>),


-        <span class="hljs-preprocessor"># driverMemory</span>


-        <span class="hljs-preprocessor"># driverCores</span>


-        <span class="hljs-preprocessor"># executorMemory</span>


-        <span class="hljs-preprocessor"># executorCores</span>


-        <span class="hljs-preprocessor"># archives</span>


-    }


+    <span class="hljs-keyword">if</span> snippet[<span class="hljs-string">'type'</span>] == <span class="hljs-string">'jar'</span>:


+        properties = {


+            <span class="hljs-string">'file'</span>: snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-keyword">get</span>(<span class="hljs-string">'app_jar'</span>),


+            <span class="hljs-string">'className'</span>: snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-keyword">get</span>(<span class="hljs-string">'class'</span>),


+            <span class="hljs-string">'args'</span>: snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-keyword">get</span>(<span class="hljs-string">'arguments'</span>),


+        }


+    elif snippet[<span class="hljs-string">'type'</span>] == <span class="hljs-string">'py'</span>:


+        properties = {


+            <span class="hljs-string">'file'</span>: snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-keyword">get</span>(<span class="hljs-string">'py_file'</span>),


+            <span class="hljs-string">'args'</span>: snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-keyword">get</span>(<span class="hljs-string">'arguments'</span>),


+        }


+    <span class="hljs-keyword">else</span>:


+        properties = {


+            <span class="hljs-string">'file'</span>: snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-keyword">get</span>(<span class="hljs-string">'app_jar'</span>),


+            <span class="hljs-string">'className'</span>: snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-keyword">get</span>(<span class="hljs-string">'class'</span>),


+            <span class="hljs-string">'args'</span>: snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-keyword">get</span>(<span class="hljs-string">'arguments'</span>),


+            <span class="hljs-string">'pyFiles'</span>: snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-keyword">get</span>(<span class="hljs-string">'py_file'</span>),


+            <span class="hljs-string">'files'</span>: snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-keyword">get</span>(<span class="hljs-string">'files'</span>),


+            <span class="hljs-preprocessor"># driverMemory</span>


+            <span class="hljs-preprocessor"># driverCores</span>


+            <span class="hljs-preprocessor"># executorMemory</span>


+            <span class="hljs-preprocessor"># executorCores</span>


+            <span class="hljs-preprocessor"># archives</span>


+        }





     response = api.submit_batch(properties)


     <span class="hljs-keyword">return</span> {

</code></pre>

<blockquote>
  <p>注：-号表示删除，+号表示添加，修改对应编译好的hue项目对应的文件夹下的文件，保存，重启hue即可。该段代码采用python编写，使用空格缩进，一定要保持一致，很重要，否则无法启动。</p>
</blockquote>

<p>然后重新执行任务。 <br>
<img src="https://img-blog.csdn.net/20161128221516701" alt="这里写图片描述" title=""> <br>
至此便执行成功了。 <br>
查看job browers也显示成功了： <br>
<img src="https://img-blog.csdn.net/20161128221544631" alt="这里写图片描述" title=""></p>

<p>但是输入dirvercores、executor等启动配置信息时，无效： <br>
<img src="https://img-blog.csdn.net/20161128221612976" alt="这里写图片描述" title=""></p>

<p>查看livy日志：</p>

<blockquote>
  <p>16/11/07 11:12:49 INFO SparkProcessBuilder: Running ‘/bigdata/spark/bin/spark-submit’ ‘–name’ ‘Livy’ ‘–class’ ‘com.jmmy.WordCount’ ‘hdfs://bigdata1:8020/original-com.jmmy-1.0-SNAPSHOT.jar’ ‘/wordcount’ ‘/testout’</p>
</blockquote>

<p>说明改配置的参数并没有传入到spark-submit中。 <br>
经过分析，修改内容如下：</p>



<pre class="prettyprint"><code class=" hljs bash">vim <span class="hljs-variable">$HUE_HOME</span>/desktop/libs/notebook/src/notebook/connectors/spark_batch.py</code></pre>

<p>在response = api.submit_batch(properties)之前添加如下代码：</p>



<pre class="prettyprint"><code class=" hljs livecodeserver">    driverCores=snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-built_in">get</span>(<span class="hljs-string">'driverCores'</span>)
    numExecutors=snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-built_in">get</span>(<span class="hljs-string">'numExecutors'</span>)
    executorCores=snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-built_in">get</span>(<span class="hljs-string">'executorCores'</span>)
    queue=snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-built_in">get</span>(<span class="hljs-string">'queue'</span>)
    archives=snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-built_in">get</span>(<span class="hljs-string">'archives'</span>)
    <span class="hljs-built_in">files</span>=snippet[<span class="hljs-string">'properties'</span>].<span class="hljs-built_in">get</span>(<span class="hljs-string">'files'</span>)
    <span class="hljs-keyword">if</span> driverCores!=<span class="hljs-string">''</span>:
        properties[<span class="hljs-string">'driverCores'</span>]=driverCores
    <span class="hljs-keyword">if</span> numExecutors!=<span class="hljs-string">''</span>:
        properties[<span class="hljs-string">'numExecutors'</span>]=numExecutors
    <span class="hljs-keyword">if</span> executorCores!=<span class="hljs-string">''</span>:
        properties[<span class="hljs-string">'executorCores'</span>]=executorCores
    <span class="hljs-keyword">if</span> queue!=<span class="hljs-string">''</span>:
        properties[<span class="hljs-string">'queue'</span>]=queue
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(archives)&gt;<span class="hljs-number">0</span>:
        properties[<span class="hljs-string">'archives'</span>]=archives
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(<span class="hljs-built_in">files</span>)&gt;<span class="hljs-number">0</span>:
        properties[<span class="hljs-string">'files'</span>]=<span class="hljs-built_in">files</span></code></pre>

<p>最终修改内容如下： <br>
<img src="https://img-blog.csdn.net/20161128221757540" alt="这里写图片描述" title=""></p>

<p>保存，重启hue。运行内容如下： <br>
<img src="https://img-blog.csdn.net/20161128221919843" alt="这里写图片描述" title=""> <br>
运行livy日志如下：</p>

<blockquote>
  <p>16/11/07 15:17:28 INFO SparkProcessBuilder: Running ‘/bigdata/spark/bin/spark-submit’ ‘–name’ ‘Livy’ ‘–class’ ‘com.jmmy.WordCount’ ‘–conf’ ‘spark.executor.instances=3’ ‘–conf’ ‘spark.driver.cores=1’ ‘–conf’ ‘spark.yarn.dist.archives=hdfs://bigdata1:8020/people.json’ ‘–conf’ ‘spark.executor.cores=2’ ‘–queue’ ‘default’ ‘hdfs://bigdata1:8020/original-com.jmmy-1.0-SNAPSHOT.jar’ ‘/wordcount’ ‘/testout’</p>
</blockquote>

<p>至此，说明参数已经提交到livy了。已经可以成功提交spark submit jar了。</p>



<h4 id="5spark-submit-py测试">5）、spark submit py测试</h4>

<p>点击+号，选择spark submit python选项，执行以下代码，做一个简单的pi测试。 <br>
<img src="https://img-blog.csdn.net/20161128222130563" alt="这里写图片描述" title=""></p>

<p>运行按钮不可用。通过spark submit jar可以正常使用进行分析，极有可能是前台代码bug导致，通过分析源码，具体修改内容如下：</p>



<pre class="prettyprint"><code class=" hljs bash"> <span class="hljs-built_in">cd</span> <span class="hljs-variable">$HUE_HOME</span>/build/static/notebook/js/notebook.ko.js</code></pre>

<p>修改内容如下： <br>
原始内容： <br>
<img src="https://img-blog.csdn.net/20161128222227955" alt="这里写图片描述" title=""> <br>
修改内容如下： <br>
<img src="https://img-blog.csdn.net/20161128222408454" alt="这里写图片描述" title=""> <br>
由于前台采用knockout.js以及python的django的web框架mako模版编写，本人甚是不熟，因此按该方法修改，点击提交python的按钮css样式失效，至此还未深入研究解决，但是已经可以正常提交python任务了。 <br>
运行结果： <br>
<img src="https://img-blog.csdn.net/20161128222650239" alt="这里写图片描述" title=""></p>

<hr>

<p><em>欢迎拍砖，能力有限，相互学习，相互进步</em></p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>