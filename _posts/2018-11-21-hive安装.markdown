---
layout:     post
title:      hive安装
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h1>hive的安装</h1>

<p><br>
    hive的最新版本3.1<br>
    hive2.3.2版本<br>
    下载包：<br>
    http://mirrors.hust.edu.cn/apache/hive/ </p>

<p>    http://mirrors.shu.edu.cn/apache/hive/ </p>

<p>    http://mirrors.tuna.tsinghua.edu.cn/apache/hive/ </p>

<p>如果懒得找，可以去我的百度盘下2.3.2版本的hive</p>

<p>百度云链接: https://pan.baidu.com/s/1MbRM8PyxubQ3wnjW_ZKiaw 密码: 0861<br>
    安装模式：<br>
        只需要任意选择一台hadoop的节点进行安装就可以了<br>
        准备：<br>
            hadoop正常的<br>
            jdk安装好的<br>
        按照元数据库分：<br>
        1）使用自带的元数据库--derby（关系型数据库）<br>
            步骤：<br>
            1）上传<br>
            2）解压<br>
            tar -xvzf apache-hive-2.3.2-bin.tar.gz<br>
            3）配置环境变量<br>
            export HIVE_HOME=/home/hadoop/apps/apache-hive-2.3.2-bin<br>
            export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$HIVE_HOME/bin<br>
            <br>
            source /etc/profile<br>
            4）初始化元数据库<br>
             schematool -dbType derby -initSchema<br>
             初始完成标志：<br>
                Initialization script completed<br>
                schemaTool completed<br>
                <br>
                初始化完成，在初始化目录下：<br>
                    derby.log  元数据库日志文件<br>
                    metastore_db：元数据信息<br>
            5)启动  <br>
            必须保证hadoop启动<br>
            hive<br>
            hive&gt; <br>
            验证：<br>
                show databases;<br>
                报错：hive的元数据报错  元数据库的实例化报错<br>
                FAILED: SemanticException <br>
                org.apache.hadoop.hive.ql.metadata.HiveException: <br>
                java.lang.RuntimeException: Unable to <br>
                instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient<br>
            <br>
            安装完成<br>
            <br>
            切换目录：<br>
            报错：<br>
            FAILED: SemanticException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: <br>
            Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient<br>
            原因：启动hive的时候如果使用的是默认的derby的话，默认加载启动目录下的元数据库<br>
            启动目录下没有元数据库  就会报错<br>
            <br>
            重新初始化：<br>
                启动的时候  发现可以正常启动的<br>
            不同目录启动的  加载的是不同目录下的元数据信息  访问的结果是不一样的<br>
            缺陷：<br>
                只适合单用户  不适合多用户</p>

<p> </p>

<p>2）元数据库使用自己安装的mysql<br>
            步骤：<br>
            1）上传<br>
            2）解压<br>
            tar -xvzf apache-hive-2.3.2-bin.tar.gz<br>
            3）配置环境变量<br>
            export HIVE_HOME=/home/hadoop/apps/apache-hive-2.3.2-bin<br>
            export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$HIVE_HOME/bin<br>
            让配置生效<br>
            source /etc/profile<br>
            4）安装mysql<br>
                参见文档<br>
            5）修改hive的配置文件<br>
                新建配置文件<br>
                touch hive-site.xml<br>
                修改：<br>
                &lt;configuration&gt;<br>
                &lt;property&gt;<br>
                &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;<br>
                &lt;value&gt;jdbc:mysql://localhost:3306/myhive?createDatabaseIfNotExist=true&lt;/value&gt;<br>
                &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;<br>
                &lt;!-- 如果 mysql 和 hive 在同一个服务器节点，那么为 localhost</p>

<p>             注意，该节点名字是你mysql安装所在的节点--&gt;<br>
                &lt;/property&gt;</p>

<p><br>
                &lt;property&gt;<br>
                &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;<br>
                &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;<br>
                &lt;description&gt;添加mysql的驱动&lt;/description&gt;<br>
                &lt;/property&gt;</p>

<p><br>
                &lt;property&gt;<br>
                &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;<br>
                &lt;value&gt;root&lt;/value&gt;<br>
                &lt;description&gt;hive的元数据库mysql的用户名&lt;/description&gt;<br>
                &lt;/property&gt;</p>

<p><br>
                &lt;property&gt;<br>
                &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;<br>
                &lt;value&gt;123456&lt;/value&gt;<br>
                &lt;description&gt;hive的元数据库mysql连接的密码&lt;/description&gt;<br>
                &lt;/property&gt;<br>
                &lt;/configuration&gt;<br>
            6）将mysql的驱动包加到hive的lib下<br>
            <br>
            7）初始化元数据库<br>
            schematool -dbType mysql -initSchema<br>
            8）启动hive   保证hadoop启动<br>
            hive<br>
            <br>
            9）测试<br>
            show databases;<br>
            create database test;<br>
            use test;<br>
            create table test01(id int,name string);<br>
            insert into table test01 values(1,'zs');<br>
            select * from test01;</p>            </div>
                </div>