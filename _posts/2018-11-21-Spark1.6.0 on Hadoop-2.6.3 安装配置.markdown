---
layout:     post
title:      Spark1.6.0 on Hadoop-2.6.3 安装配置
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<h1 align="center"><strong><span style="color:rgb(51,51,51);">Spark1.6.0 on Hadoop-2.6.3 安装配置<a name="OLE_LINK7"></a></span></strong></h1>
<h3 style="background:rgb(254,254,254);"><span style="color:rgb(51,51,51);">1. </span><strong><span style="color:rgb(51,51,51);">配置</span><span style="color:rgb(51,51,51);">hadoop</span></strong></h3>
<p><span style="color:rgb(51,51,51);">(1)、<strong>下载</strong></span><span style="color:rgb(51,51,51);"><strong>hadoop</strong></span></p>
<table><tbody><tr><td valign="top">
<p>mkdir<a name="OLE_LINK22"> /usr/local/</a>bigdata/hadoop</p>
<p>cd  /usr/local/bigdata/hadoop</p>
<p>wget <a href="http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.6.3/hadoop-2.6.3.tar.gz" rel="nofollow">
http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.6.3/hadoop-2.6.3.tar.gz</a></p>
<p>tar zxvf <u>hadoop-2.6.3.tar.gz</u></p>
</td>
</tr></tbody></table><p><span style="color:rgb(51,51,51);">(2)、<strong>配置hadoop环境变量</strong></span></p>
<table><tbody><tr><td valign="top">
<p>export HADOOP_HOME=/usr/local/bigdata/hadoop/hadoop-2.6.3</p>
<p>export PATH=${JAVA_HOME}/bin:${HADOOP_HOME}/bin</p>
</td>
</tr></tbody></table><p> </p>
<h3 style="background:rgb(254,254,254);"><span style="color:rgb(51,51,51);">2. </span><strong><span style="color:rgb(51,51,51);">安装配置Scala</span></strong></h3>
<p><a name="OLE_LINK21"></a>(1)、<strong><span style="color:rgb(51,51,51);">下载scala</span></strong></p>
<table><tbody><tr><td valign="top">
<p><a name="OLE_LINK4"></a>mkdir /usr/local/bigdata/scala</p>
<p>wget  <a href="http://www.scala-lang.org/files/archive/scala-2.10.4.tgz" rel="nofollow">http://www.scala-lang.org/files/archive/scala-2.10.4.tgz</a></p>
<p>tar zxvf scala-2.10.4.tgz </p>
</td>
</tr></tbody></table><p> </p>
<p><a name="OLE_LINK5"></a><span style="color:rgb(51,51,51);">(2)、<strong>配置scala环境变量</strong></span></p>
<table><tbody><tr><td valign="top">
<p><a name="OLE_LINK2"></a>export SCALA_HOME=/usr/local/bigdata/scala/scala-2.10.4</p>
<p><a name="OLE_LINK3"></a>export PATH=${JAVA_HOME}/bin:${HADOOP_HOME}/bin:${SCALA_HOME}/bin:$PATH</p>
</td>
</tr></tbody></table><p><a name="OLE_LINK9"></a>显示安装的<span style="font-family:Calibri;">scala</span><span style="font-family:'宋体';">版本</span></p>
<p> <img src="https://img-blog.csdn.net/20160726165404359?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><img src="" alt=""><img src="" alt=""></p>
<p><a name="OLE_LINK8"></a><span style="color:rgb(51,51,51);">(3)、<strong>测试scala运行环境</strong></span></p>
<table><tbody><tr><td valign="top">
<p><a name="OLE_LINK10"></a>输入<span style="font-family:Calibri;">scala</span><span style="font-family:'宋体';">进入</span><span style="font-family:Calibri;">scala</span><span style="font-family:'宋体';">环境：</span></p>
<p> </p>
<p>测试：<span style="font-family:Calibri;">12*12 </span><span style="font-family:'宋体';">回车</span></p>
</td>
</tr></tbody></table><p><strong><span style="color:rgb(51,51,51);"> <img src="https://img-blog.csdn.net/20160726165421484?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><img src="" alt=""></span></strong></p>
<h3 style="background:rgb(254,254,254);"><a name="OLE_LINK34"></a><span style="color:rgb(51,51,51);">3. </span><strong><span style="color:rgb(51,51,51);">安装配置Spark1.6.0</span></strong></h3>
<p><a name="OLE_LINK12"></a><span style="color:rgb(51,51,51);">(1)、 </span><strong><span style="color:rgb(51,51,51);">下载Spark1.6.0</span></strong></p>
<p><a name="OLE_LINK36"></a><a name="OLE_LINK19">根据<span style="font-family:Calibri;">Hadoop</span><span style="font-family:'宋体';">选择对应版本下载</span><span style="font-family:Calibri;">Spark</span></a>,<span style="font-family:'宋体';">下载网址：</span><span style="font-family:Calibri;">http://spark.apache.org/downloads.html</span></p>
<p> </p>
<table><tbody><tr><td valign="top">
<p>mkdir /usr/local/bigdata/spark</p>
<p>wget http://archive.apache.org/dist/spark/spark-1.6.0/spark-1.6.0-bin-hadoop2.6.tgz</p>
<p>tar zxvf <u>spark-1.6.0.tgz</u></p>
</td>
</tr></tbody></table><p> </p>
<p><a name="OLE_LINK18"></a><span style="color:rgb(51,51,51);">(2)、<strong>配置Spark环境变量</strong></span></p>
<table><tbody><tr><td valign="top">
<p><a name="OLE_LINK24"></a>export SPARK_HOME=/usr/local/bigdata/spark/spark-1.6.0-bin-hadoop2.6</p>
<p>export PATH=${JAVA_HOME}/bin:${HADOOP_HOME}/bin:${SCALA_HOME}/bin:<a name="OLE_LINK26">${SPARK_HOME}/bin:</a><a name="OLE_LINK25"></a>$PATH</p>
</td>
</tr></tbody></table><p><a name="OLE_LINK27"></a><span style="color:rgb(51,51,51);">(3)、<strong>配置Spark</strong></span></p>
<table><tbody><tr><td valign="top">
<p><a name="OLE_LINK29"></a>cd /usr/local/bigdata/spark/spark-1.6.0-bin-hadoop2.6/conf</p>
<p>cp spark-env.sh.template spark-env.sh</p>
<p><a name="OLE_LINK20"></a>vim spark-env.sh #添加<span style="font-family:Calibri;">SPARK</span><span style="font-family:'宋体';">配置信息</span></p>
<p>export JAVA_HOME=/usr/java/jdk1.8.0_71</p>
<p>export SCALA_HOME=/usr/local/bigdata/scala/scala-2.10.4</p>
<p>export SPARK_MASTER_IP=<a name="OLE_LINK30">XTYFB-CSJ06</a></p>
<p>export SPARK_WORKER_CORES=2</p>
<p>export SPARK_WORKER_MEMORY=1g</p>
<p>export HADOOP_CONF_DIR=/usr/local/bigdata/hadoop/hadoop-2.6.3/etc/hadoop</p>
</td>
</tr></tbody></table><p> </p>
<p> </p>
<p> </p>
<p> </p>
<table><tbody><tr><td valign="top">
<p>cp slaves.template slaves</p>
<p><a name="OLE_LINK32"></a>vim slaves  #添加节点</p>
<p>XTYFB-CSJ06 或者 <span style="font-family:Calibri;">127.0.1.1</span></p>
</td>
</tr></tbody></table><p><strong><span style="color:rgb(51,51,51);"> </span></strong></p>
<p><strong><span style="color:rgb(51,51,51);"> </span></strong></p>
<h3 style="background:rgb(254,254,254);"><span style="color:rgb(51,51,51);">4. </span><strong><span style="color:rgb(51,51,51);">启动Spark，查看集群状况</span></strong></h3>
<table><tbody><tr><td valign="top">
<p>cd /usr/local/bigdata/spark/spark-1.6.0-bin-hadoop2.6/sbin</p>
<p> </p>
<p>启动：</p>
<p>./start-all.sh</p>
</td>
</tr></tbody></table><p> </p>
<p>jps<span style="font-family:'宋体';">查看进程：多了一个</span><span style="font-family:Calibri;">Master</span><span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">Worker</span><span style="font-family:'宋体';">进程</span></p>
<p> </p>
<p>使用<span style="font-family:Calibri;">jps -mlv</span><span style="font-family:'宋体';">查看进程的详情</span></p>
<p> </p>
<p>可以看到<a name="OLE_LINK37"></a>Master<span style="font-family:'宋体';">前端的访问地址</span><span style="font-family:Calibri;">http://172.16.80.226:8080/</span></p>
<p> </p>
<p>Worker<span style="font-family:'宋体';">前端的访问地址</span><span style="font-family:Calibri;">http://172.16.80.226:8081/</span></p>
<p> </p>
<p>切换到cd /usr/local/bigdata/spark/spark-1.6.0-bin-hadoop2.6/bin</p>
<p>启动：<span style="font-family:Calibri;">spark-shell</span></p>
<p> </p>
<p>mkdir <a name="OLE_LINK38">/usr/local/bigdata/spark/testData</a></p>
<p>vim /usr/local/bigdata/spark/testData/wcDemo1.txt</p>
<table><tbody><tr><td valign="top">
<p>spark hive</p>
<p>spark hive</p>
<p>hive   redis</p>
<p>hdds    redis</p>
</td>
</tr></tbody></table><p> </p>
<p>执行<span style="font-family:Calibri;">scala</span><span style="font-family:'宋体';">的脚本命令获得单词计数的结果：</span></p>
<table><tbody><tr><td valign="top">
<p> val rdd=sc.textFile("/usr/local/bigdata/spark/testData/wcDemo1.txt").flatMap(_.split("\t")).map(x=&gt;(x,1)).reduceByKey(_+_).collect</p>
</td>
</tr></tbody></table><p> </p>
<p> </p>
<p> </p>
<p>打印统计出结果：<span style="font-family:Calibri;">rdd: Array[(String, Int)] = Array((hive,3), (spark,2), (hdds,1), (redis,2))</span></p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p><a name="OLE_LINK39"></a>其他例子：对结果升序排序</p>
<table><tbody><tr><td valign="top">
<p>val rdd=sc.textFile("/usr/local/bigdata/spark/testData/wcDemo1.txt").flatMap(_.split("\t")).map(x=&gt;(x,1)).reduceByKey(_+_).sortByKey().collect</p>
<p> </p>
<p> </p>
</td>
</tr></tbody></table><p>执行结果：<span style="font-family:Calibri;">rdd: Array[(String, Int)] = Array((hdds,1), (hive,3), (redis,2), (spark,2))</span></p>
<p> </p>
<p>对结果降序排序</p>
<table><tbody><tr><td valign="top">
<p>val rdd=sc.textFile("/usr/local/bigdata/spark/testData/wcDemo1.txt").flatMap(_.split("\t")).map(x=&gt;(x,1)).reduceByKey(_+_).sortByKey(false).collect</p>
<p> </p>
<p> </p>
</td>
</tr></tbody></table><p>执行结果：<span style="font-family:Calibri;">rdd: Array[(String, Int)] = Array((spark,2), (redis,2), (hive,3), (hdds,1))</span></p>
<p> </p>
<p>统计结果行数</p>
<table><tbody><tr><td valign="top">
<p><a name="OLE_LINK45">val rdd=sc.textFile("</a><a name="OLE_LINK42">/usr/local/bigdata/spark</a><a name="OLE_LINK41">/testData/</a>wcDemo1.txt").flatMap(_.split("\t")).map(x=&gt;(x,1)).reduceByKey(_+_).sortByKey(false).count</p>
<p> </p>
</td>
</tr></tbody></table><p>执行结果：<span style="font-family:Arial;">rdd: Long = 4</span></p>
<p>将结果进行保存</p>
<table><tbody><tr><td valign="top">
<p>val rdd=sc.textFile("/usr/local/bigdata/spark/testData/wcDemo1.txt").flatMap(_.split("\t")).map(x=&gt;(x,1)).reduceByKey(_+_).sortByKey(false).saveAsTextFile("/usr/local/bigdata/spark/testData/wcDemo_out")</p>
<p> </p>
</td>
</tr></tbody></table><p> </p>
<p>对于<span style="font-family:Calibri;">WC</span><span style="font-family:'宋体';">而言，需要从输入数据中每行字符串解析出单词，然后将相同的单词放到一个桶中，最后统计每个桶中每个单词出现的频率。</span></p>
<p>flatMap<span style="font-family:'宋体';">函数将一条记录转换成多条记录（一对多关系），</span><span style="font-family:Calibri;">map</span><span style="font-family:'宋体';">函数将一条记录转换成另一条记录（一对一关系），</span><span style="font-family:Calibri;">reduceByKey</span><span style="font-family:'宋体';">函数将</span><span style="font-family:Calibri;">Key</span><span style="font-family:'宋体';">相同的数据划分到一个桶中，并以</span><span style="font-family:Calibri;">Key</span><span style="font-family:'宋体';">为单位分组进行计算。</span></p>
<p>经过一系列的<span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">转换算子操作，之前都是</span><span style="font-family:Calibri;">Transformation</span><span style="font-family:'宋体';">算子，最后</span><span style="font-family:Calibri;">collect</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">saveAsTextFile</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">count</span><span style="font-family:'宋体';">都是</span><span style="font-family:Calibri;">Actions</span><span style="font-family:'宋体';">算子。</span></p>
<p>查看结果如下截图</p>
<p> </p>
            </div>
                </div>