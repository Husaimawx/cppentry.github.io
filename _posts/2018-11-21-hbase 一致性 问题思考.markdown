---
layout:     post
title:      hbase 一致性 问题思考
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/fei33423/article/details/78083807				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>搜索了下 hbase 和 paxos .说 hbase 本身的 hdfs 和 paxos 无关. <br></p>
<p>后来又发现一篇文章<a href="http://kabike.iteye.com/blog/2168852" rel="nofollow">浅谈Hbase 的强一致性</a><em class="actions"></em>:</p>
<p><em>    从一开始就知道hbase是CAP中的CP系统,即hbase是强一致性的.我原来一直以为hbase的强一致性是因为底层的HDFS写入时,必须所有副本都写入成功才能返回.最近才想明白,hbase之所以是CP系统,实际和底层HDFS无关,它是CP系统,是因为对每一个region同时只有一台region server为它服务,对一个region所有的操作请求,都由这一台region server来响应,自然是强一致性的.在这台region server fail的时候,它管理的region failover到其他region
 server时,需要根据WAL log来redo,这时候进行redo的region应该是unavailable的,所以hbase降低了可用性,提高了一致性.设想一下,如果redo的region能够响应请求,那么可用性提高了,则必然返回不一致的数据(因为redo可能还没完成),那么hbase就降低一致性来提高可用性了.</em></p>
<p>    <br></p>
<p>   这个和我的理解时一致的:</p>
<p>    hbase 的强一致性分为两部分来说. <br>
    数据分为两部分  <br></p>
<p>           1.文件存储 <br></p>
<p>            2.hbase region 本身有 lsm 的内存数据. <br><br>
       对于第一部分,hdfs 的数据有个特点不可变. 对于不可变的数据好处是不用考虑更新时的数据一致性. 而分布式的数据一致性本身的由来也是因为各个不同的人想改同一个值(paxos 是 大家都想对"决议"进行修改,使其变成某个值)<br>
 meta 数据的修改时通过 zk 的,所以一致性也得到了保证.<br><br>
      对于第二部分数据,由于只有一个 region,只有一个操作者.故也没啥一致性问题.</p>
<p><br></p>
<p>   另外split时 由于直接报错,故也保证了一致性</p>
<p><br></p>
<p><br></p>
<p>通过分布式系统框架+ 幂等重试 实现最终一致性 (支付宝和 ebay 架构 <br></p>
<p>保证分布式系统数据一致性的6种方案)<br></p>
<p><br></p>
<p>附录:</p>
<p></p>
<h1><span class="link_title"><a href="http://blog.csdn.net/fei33423/article/details/78083767" rel="nofollow">HBase Region分裂 原理,过程</a></span></h1>
<br><p></p>
            </div>
                </div>