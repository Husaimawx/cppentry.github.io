---
layout:     post
title:      HDFS 文件权限
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h2 id="hdfs文件权限">HDFS文件权限</h2>

<p>HDFS实现的文件权限模型与Linux文件权限非常类似  ，也有superuser ， 但是hdfs中superuser是不是root呢 ， 这个有点区别， 在hdfs中superuser是启动namenode的用户 ， 例如，如果你用root用户安装的并且启动hdfs，那么superuser就是root， 如果用hadoop用户安装并且启动的hdfs那么superuser就是haddop  ;</p>

<p>当我们用过命令 ，或者通过HDFS Client API访问Hdfs的时候 ，提示权限不足 ，我们可以考虑是不是你当前用户对你访问的路径权限不够 ，以及你当前superuser到底是什么用户， 然后使用superuser对你操作的路劲进行分配权限 。</p>

<p>我写了一个简单的程序使用java client api， 在hdfs中创建一个目录 ，然后抛出一下异常 ，</p>



<pre class="prettyprint"><code class="language-java hljs ">org.apache.hadoop.security.AccessControlException: Permission denied: user=hadoop, access=WRITE, inode=<span class="hljs-string">"/"</span>:root:supergroup:drwxr-xr-x</code></pre>

<p>经过分析，我的hdfs安装的时候 ，我是用root用户进行安装， 启动的， 那么根路径只有root用户才有权限操作 ，而我java程序默认使用hadoop用户进行去访问 ，自然是不会有权限  <br>
解决也比较简单 ， 我可以使用root用户在服务器上，创建一个/test目录 ，然后把该目录的owner赋值给hadoop , 可以通过一下命令完成。</p>

<pre class="prettyprint"><code class="language-java hljs "># cd /opt/hadoop-<span class="hljs-number">2.6</span><span class="hljs-number">.4</span>/
# bin/hadoop fs -mkdir /test
# bin/hadoop -chown -R hadoop:hadoop /test</code></pre>

<p>另一种解决办法，就是安装启动使用hadoop这个用户 ， 那么superuser就是hadoop</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>