---
layout:     post
title:      Kafka Manager实现原理与填坑
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<h3 style="font-weight:400;line-height:1.75;font-size:16px;">
Kafka Manager 简介</h3>
<ul style="line-height:1.75;font-size:16px;"><li style="margin-left:30px;"><span><a href="https://github.com/DavidLiuXh/kafka-manager" rel="nofollow" style="background-color:transparent;color:rgb(0,0,0);border-bottom:1px dashed rgb(0,0,0);">Kafka Manager</a> 可能是现在能找到的最好的可视化的Kafka管理工具, 感谢<a href="https://www.yahoo.com/" rel="nofollow" style="background-color:transparent;color:rgb(0,0,0);border-bottom:1px dashed rgb(0,0,0);">Yahoo</a>-我人生中打开的一个网站-的开源;</span></li><li style="margin-left:30px;"><span>使用Kafka Manager, 基本上之前需要运行Kafka相应命令行工具的工作现在都可以可视化的完成:</span>
<ol style="line-height:1.75;"><li style="margin-left:30px;"><span>创建Topic, 调整消息保存时长, Partition数量等等配置;</span></li><li style="margin-left:30px;"><span>管理Topic, 包括Reassign Partitions, Preferred Replica Election等等;</span></li><li style="margin-left:30px;"><span>消费情况查看, 支持offset保存到zk和broker两种方式, 列出所有消费的group, 消费每个partition的详情;</span></li><li style="margin-left:30px;"><span>集群的简单健康状态查看,包括partition分布是否均衡, leader分布是否均衡等;</span></li><li style="margin-left:30px;"><span>通过JMX查看各种指标, 比如各个broker的网络流量和消息进出数据, 每个Topic消息的读写速度等;</span></li></ol></li><li style="margin-left:30px;"><span>下面我们会先简单介绍下Kafka Manager的实现和在使用中遇到的几种坑;</span></li></ul><h3 style="font-weight:400;line-height:1.75;font-size:16px;">
Kafka Manager实现</h3>
<ul style="line-height:1.75;font-size:16px;"><li style="margin-left:30px;"><span>实现语言: Scala</span></li><li style="margin-left:30px;"><span>用到的框架和第三方库:</span>
<ol style="line-height:1.75;"><li style="margin-left:30px;"><span><a href="https://www.playframework.com/" rel="nofollow" style="background-color:transparent;color:rgb(0,0,0);border-bottom:1px dashed rgb(0,0,0);">Play framework</a>: Kafka-Mananger本质上是个Web应用, 因此使用play framework的MVC架构实现;</span></li><li style="margin-left:30px;"><span><a href="http://akka.io/" rel="nofollow" style="background-color:transparent;color:rgb(0,0,0);border-bottom:1px dashed rgb(0,0,0);">AKKA</a>: 用于构建高并发、分布式和容错的应用. Kafka Manager中的所有请求都使用akka来异步处理;</span></li><li style="margin-left:30px;"><span><a href="http://curator.apache.org/" rel="nofollow" style="background-color:transparent;color:rgb(0,0,0);border-bottom:1px dashed rgb(0,0,0);">Apache Curator Framework</a>: 用于访问zookeeper;</span></li><li style="margin-left:30px;"><span><a href="http://kafka.apache.org/" rel="nofollow" style="background-color:transparent;color:rgb(0,0,0);border-bottom:1px dashed rgb(0,0,0);">Kafka Sdk</a>: 用于获取各Topic的last offset, 使用Admin接口实现各种管理功能;</span></li></ol></li><li style="margin-left:30px;"><span>编译:<br>
整个工程使用 <a href="http://www.scala-sbt.org/" rel="nofollow" style="background-color:transparent;color:rgb(0,0,0);border-bottom:1px dashed rgb(0,0,0);">sbt</a> 构建, 具体编译流程可以在githut上找到. sbt在build过程中会加载很多第三方依赖, 这个在国内有时会很慢, 各种同学各显神通吧.</span></li><li style="margin-left:30px;"><span>实现:<br>
其实kafka manager的代码还是很清晰易阅读的, 如果熟悉scala和play的话应该没有难度. 不同本人也是现学现用, 好惭愧~~~. 咱们这里捡重点的说吧, 不分析具体代码实现,只讲下实现的方法:</span>
<ol style="line-height:1.75;"><li style="margin-left:30px;"><span><span>获取集群中所有Topic</span><br>
使用Curator访问zk获取,并监听zk相关节点 /brokers/topics 的变化;</span></li><li style="margin-left:30px;"><span><span>获取Topic的partiton, leader, replicas信息</span><br>
也是从zk获取, /brokers/topics/[topic]/partitions;</span></li><li style="margin-left:30px;"><span><span>获取Topic的各partition的last offset</span><br>
使用kafka sdk发送OffsetRequest到kafka集群来获得, 这个获取的动作会被封装成<a href="http://doc.akka.io/docs/akka/snapshot/scala/futures.html" rel="nofollow" style="background-color:transparent;color:rgb(0,0,0);border-bottom:1px dashed rgb(0,0,0);">Future[PartitionOffsetsCapture]</a>,
 每个topic一个Future, 使用Google的<a href="https://google.github.io/guava/releases/19.0/api/docs/com/google/common/cache/LoadingCache.html" rel="nofollow" style="background-color:transparent;color:rgb(0,0,0);border-bottom:1px dashed rgb(0,0,0);">LoadingCache</a>来存储这些future,
 利用LoadingCache的超时淘汰机制来周期性的创建新的Future来间隔地发送OffsetRequest获取当前最新的last offset;</span></li><li style="margin-left:30px;"><span><span>获取Kafka本身管理的group的消费情况</span><br>
使用kafka sdk不断地消费"<span>consumer_offsets"这个topic, 来获取所有group的消费情况,关于</span>consumer_offsets参考 <a href="https://cwiki.apache.org/confluence/display/KAFKA/Committing+and+fetching+consumer+offsets+in+Kafka" rel="nofollow" style="background-color:transparent;color:rgb(0,0,0);border-bottom:1px dashed rgb(0,0,0);">Committing
 and fetching consumer offsets in Kafka</a></span></li><li style="margin-left:30px;"><span><span>获取zookeeper管理的group的消费情况</span><br>
肯定是从zk上读取, /consumers</span></li></ol></li><li style="margin-left:30px;"><span>上面的这些实现都在 <span>KafkaStateActor.scala</span> 这个文件里.</span></li><li style="margin-left:30px;"><span>各种Acotr的关系简图,仅供参考</span></li></ul><img src="http://qiniuimg.qingmang.mobi/image/orion/e47373a310afe30a164629d9c208ca05_1864_676.png" width="1864" alt="" style="border:0px;vertical-align:middle;display:block;"><p style="line-height:1.75;font-size:16px;">
<span>kafka-manager.png</span></p>
<h3 style="font-weight:400;line-height:1.75;font-size:16px;">
Kafka Manager遇到的坑</h3>
<ul style="line-height:1.75;font-size:16px;"><li style="margin-left:30px;"><span>多个kafka manager来管理同一个kafka集群:<br>
你会发现在kafka manager里无法看到所有offset使用kafka本身管理的group.<br>
前面我们讲过使用kafka sdk不断地消费"__consumer_offsets", 看看这段代码(在KafkaStateActor.scala中):<br>
props.put("group.id", "KafkaManagerOffsetCache")<br>
props.put("bootstrap.servers", bootstrapBrokerList.list.map(bi =&gt; s"${bi.host}:${bi.port}").mkString(","))<br>
props.put("exclude.internal.topics", "false")<br>
props.put("enable.auto.commit", "false")<br>
props.put("key.deserializer", "org.apache.kafka.common.serialization.ByteArrayDeserializer")<br>
props.put("value.deserializer", "org.apache.kafka.common.serialization.ByteArrayDeserializer")<br>
props.put("auto.offset.reset", "latest")<br>
props.put("group.id", "KafkaManagerOffsetCache")<br>
这句说明不管启动了几个kafka manager, 消费"__consumer_offsets"都使用同一个group.<br><span>解决方案</span>: group.id从配置文件中读取,每个kafka manager使用不同的group id;</span></li><li style="margin-left:30px;">
<pre style="overflow:auto;font-family:Menlo, Monaco, Consolas, 'Courier New', monospace;font-size:15px;line-height:1.75;color:rgb(51,51,51);background-color:rgb(245,245,245);border:1px solid rgb(204,204,204);">客户端使用某些sdk(比如librdkafka)消费topic, 客户端crash后, 在kafka manager上查看其group的消费情况, 仍然一直能看到"Consumer Instance Owner"<br>原因在于处理从broker返回的GroupMetadata response时没有处理异常情况:<br>            case GroupMetadataKey(version, key) =&gt;<br>                  val value: GroupMetadata = readGroupMessageValue(key, ByteBuffer.wrap(record.value()))<br>                  value.allMemberMetadata.foreach {<br>                    mm =&gt;<br>                      mm.assignment.foreach {<br>                        case (topic, part) =&gt;<br>                          groupTopicPartitionMemberMap += (key, topic, part) -&gt; mm<br>                      }<br>                  }<br>              }<br>这里的record.value可能为空, 此时应作清理工作:<br>                if (null != record &amp;&amp;                                                                                                   <br>                    null != record.value()) {                                                                                           <br>                      val value: GroupMetadata = readGroupMessageValue(key, ByteBuffer.wrap(record.value()))                            <br>                      value.allMemberMetadata.foreach {                                                                                               <br>                        mm =&gt;<br>                          mm.assignment.foreach {                                                                                                     <br>                            case (topic, part) =&gt;                                                                                                     <br>                              groupTopicPartitionMemberMap += (key, topic, part) -&gt; mm                                                                <br>                          }<br>                      }                                                                                                                               <br>                      } else {                                                                                                                          <br>                        groupTopicPartitionMemberMap.foreach {                                                                                          <br>                          case ((group, topic, part), mmd) =&gt;                                                                                           <br>                            if (group == key) {                                                                                                         <br>                              var tmp = mmd                                                                                                             <br>                              tmp.memberId = ""                                                                                                         <br>                              tmp.clientHost = ""                                                                                                       <br>                              groupTopicPartitionMemberMap += (key, topic, part) -&gt; tmp                                                                 <br>                            }                                                                                                                           <br>                        }                                                                                                                               <br>                      }</pre>
</li></ul><ul style="line-height:1.75;font-size:16px;"><li style="margin-left:30px;"><span>Yikes! Ask timed out on [ActorSelection[Anchor(akka://kafka-manager-system/), Path(/user/kafka-manager)]] after [5000 ms]<br>
访问kafka manager时出现上面的超时提示, 遇到这个问题,好学不服输的你肯定会上网各种搜, 然后你会去改kafka manager的各种配置, 调大各种thread pool的容量, 增大queue size, 甚至开大jvm的使用内存, 然而问题并没有解决, 看来只剩下定时重启这一招儿了.<br><span>这里提供一种解决方案</span>: 这个超时是Actor在执行异步请求时一直等不到返回结果造成的, 主要是前面讲过的"获取Topic的各partition的last offset的Future"没有返回结果,这些Future是通过Await.ready来阻塞拿到result的, 然而在kafka manager中这个Await.ready没有给timeout, 是一直等待, 那咱们就给个timeout好了, 代码在ActorModel.scala中, 有好几处Await.ready的调用.</span></li></ul>            </div>
                </div>