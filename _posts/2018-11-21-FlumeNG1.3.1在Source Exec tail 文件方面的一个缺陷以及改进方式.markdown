---
layout:     post
title:      FlumeNG1.3.1在Source Exec tail 文件方面的一个缺陷以及改进方式
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/yangbutao/article/details/8648113				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>    在用FlumeNG1.3.1 Tail 一个文件收集日志到HDFS中时，发现原始日志文件最后几行数据总是不能写入到HDFS文件中，即使HDFS按照大小或者时间rollling成了一个新的文件。</p>
<p>   HDFS在回滚一个新的文件中时，保留在HDFSEventSink中的数据（即使未达到一个包的大小）会写入到HDFS中，在HDFS的.hadoop fs -cat命令可以看到该数据。</p>
<p>   经过分析Flume的源码，在TailExecSource的实现中对于数据量是批量发送的，当数据量未达到batch size时，暂存在Source端。</p>
<p>   改进方式，支持Source端对数据的发送超时设置，这样在批量操作时，如果未达到批量的大小的情况下，超过规定的时，也把数据发送出去。</p>
<p> </p>
<p> </p>
<p> </p>
            </div>
                </div>