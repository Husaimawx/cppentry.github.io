---
layout:     post
title:      spark 笔记1 （11-06-2017）
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>spark （一个用来实现快速而通用的集群计算平台） <br>
1.优点:  <br>
  a  好用，高级API剥离了对于集群本身的关注， 只需在本子上开发Spark应用； <br>
  b 很快，支持交互式计算 和复杂算法 （扩展了 MapReduce 模型 交互式查询和流计算    内存中计算） <br>
  c 通用引擎 完成各种运算（SQL查询，文本处理 机器学习） <br>
  d 接口丰富 提供基于python java scala SQL的简单易用的API 内建的丰富的程序库。还可以和其他大数据工具密切使用，（eg.spark可以运行在hadoop集群上 访问包括 Cassandra在内的任意hadoop数据源） </p>

<p>2 spark (一个大一统的软件栈) <br>
 组件图： <br>
 <img src="https://img-blog.csdn.net/20171106101332847?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGl1d2VpeGlhbnNoZW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
 (a) Spark core <br>
  实现spark基本功能，(任务调度 内存管理 错误恢复 与存储系统交互) 还包含了 对RDD（弹性分布式数据集，RDD 表示分布在多个计算节点上可以进行并行操作的元素集合 是Spark的主要编程抽象，spark core还提供了很多创建和操所这些集合的多个API ）的API定义。 <br>
(b) Saprk SQL</p>

<p>(c) Spark Streamoing</p>

<p>(d) MLib （spark中的提供的常见的机器学习的功能的程序库） <br>
       它提供了很多机器学习算法 包括分类，回归，聚类，协同过滤等，还提供了模型评估，数据导入等额外支持的功能。还提供了一些更底层的原语，包括一个通用的梯度下降优化算法。所有这些算法，都被设计为可以在集群上轻松伸缩的架构。 <br>
(e) GraphX <br>
它是用来操作图的程序（比如社交网络的朋友关系图），可以支持并行的图计算。它扩展了spark RDD的API，能用来创建一个顶点和边都包含任意属性的有向图。还支持对于图的各种操作（比如进行图分割的subgraph 和操作所有顶点的mapVertices）,以及一些常用的图算法（PageRank和三角技术） <br>
(f) 集群管理器 <br>
 就底层而言，spark设计为 可以高效在一个到数千个计算节点伸缩计算。因此spark支持在各种集群管理器上运行。（hadoop-YARN  Apache-Mesos,以及一个自带的独立调度器） </p>

<p>3  Spark 用户用途 <br>
&lt;数据科学任务&gt;  分析处理数据并建模 <br>
&lt;数据处理应用&gt;  针对工程师（软件开发者）。为开发用于集群并行执行的程序提供了一条捷径。</p>

<p>4 Spark 简史 <br>
  2009年诞生于 加州大学伯克利分校RAD实验室。hadoop-MapReduce在迭代计算和交互式任务上表现低下。 <br>
  一开始Spark就是为交互式查询，迭代计算而设计；同时支持内存式存储和高效的容错机制。2009年，相比于MapReduce spark在某些任务上已经有了10-20倍提升。</p>

<p>5 spark存储层次 <br>
 spark不仅可以将hadoop分布式文件系统（hdfs）上的文件读取为分布式数据集。也支持其他支持hadoop接口的系统（例如：本地文件，亚马逊S3，cassandra,Hive,HBase） <br>
 hadoop并非spark的必要组件，spark支持任何实现了hadoop接口的存储系统。saprk支持的hadoop的输入格式包括 文本文件，SequenceFile,Avro,Parquet等</p>

<p>参考：《Spark快速大数据分析》 <br>
作者：Holden Karau,Andy Konwinski,Patrick Wendell,Matei Zaharia. 王道远译。 英特尔大数据中心审校。</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>