---
layout:     post
title:      阿里大数据工程师教你怎样理解Flume
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/a318804626/article/details/79940524				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p><span style="font-weight:700;">lume是干什么的？</span></p>
<p>收集日志的</p>
<p><span style="font-weight:700;">flume如何搜集日志？</span></p>
<p>我们把flume比作情报人员</p>
<p>（1）搜集信息</p>
<p>（2）获取记忆信息</p>
<p>（3）传递报告间谍信息</p>
<p><span style="font-weight:700;">flume是怎么完成上面三件事情的，三个组件：</span></p>
<p>source： 搜集信息</p>
<p>channel：传递信息</p>
<p>sink：存储信息</p>
<p>flume OG（original generation初始版本）和NG（next generation，cdh4以及之后的版本）</p>
<p>Flume OG 代码工程臃肿、核心组件设计不合理、核心配置不标准等</p>
<p>Flume OG 有三种角色节点：agent、collector、master节点。</p>
<p>Flume NG 只有一种角色的节点：代理节点（agent）,去掉了 collector、master 节点，这是核心组件最核心的变化。</p>
<p>agent 节点的组成也发生了变化,由 source、sink、channel 组成。</p>
<p>NG要求jdk1.6以上，而且只有linux上的启动脚本</p>
<p>OG版本已经不更新了</p>
<p><span style="font-weight:700;">NG的核心组件：</span></p>
<p>source：完成对日志数据的收集，分成transition和event打入到channel中。</p>
<p>source有多种实现包括AvroSource（监控端口）、NetCat Source、Syslog Source、Syslog TCP Source、Syslog UDP Source、Http Source、HDFS Source、Spooling Directory Source（对目录下新增文件的监控，并读取文件数据）、Exec Source（以运行linux命令的方式，持续输出最新数据，如tail
 -F）等</p>
<p><span style="font-weight:700;">flume可以和log4j配合使用</span></p>
<p>sink：取出channel中的数据，输出到存储文件系统，数据库，或远程服务器</p>
<p>多种实现方式如Avro sink、HDFS Sink、HBase Sink、Logger Sink（测试用，后台打印）</p>
<p>小数据可以存储在文件或数据库中，海量数据（每天GB、TB级别的数据）存储到hadoop中</p>
<p>Channel：管道，提供一个队列的功能，对source提供的数据进行简单缓存</p>
<p>实现由Memory/File/jdbc channel,Memory无法保证数据完成性，官方建议使用File Channel，保证数据完整性和一致性</p>
<p><span style="font-weight:700;">Flow Pipeline</span></p>
<p>1、多个Agent顺序连接</p>
<p>2、多个Agent的数据汇聚到同一个Agent</p>
<p>3、多路（一个agent上有多个channel）（Multiplexing）Agent</p>
<p>这种模式，有两种方式，一种是用来复制（Replication），另一种是用来分流（Multiplexing）。Replication方式，可以将最前端的数据源复制多份，分别传递到多个channel中，每个channel接收到的数据都是相同的；Multiplexing方式，selector可以根据header的值来确定数据传递到哪一个channel</p>
<p>4、实现load balance功能</p>
<p>5、实现failover功能</p>
<p><span style="font-weight:700;">flume source</span></p>
<p>Avro Source：接收外部avro客户端的事件</p>
<p>Thrift Source：接收外部thrift客户端的事件</p>
<p>Exec Source：接收来自一个给定的Unix命令的标准输出上的数据</p>
<p>Jms Source：接收来自消息队列的事件</p>
<p>NetCat Source：netcat在一端侦听，每一行文字变成一个事件源</p>
<p>Spooling Directory Source：以目录中文件内容为事件源</p>
<p>SequenceGenerator Source:一个简单地序列生成器，主要用于测试</p>
<p>Syslog Source：读取syslog数据</p>
<p>SyslogUDP Source</p>
<p>SyslogTCP Source</p>
<p>Multiport Syslog TCP Source</p>
<p>Http Source：接收http post，get事件，get只用于试验</p>
<p>Custom Source：自定义source</p>
<p><span style="font-weight:700;">flume sink</span></p>
<p>HDFS Sink将事件写入到hadoop分布式文件系统HDFS</p>
<p>Logger sink 通常用于调试、测试</p>
<p>Avro sink 可以批量传送，可以配置批量大小</p>
<p><span style="font-weight:700;">Thrift sink</span></p>
<p>IRC sink 从通道中取得信息到irc server</p>
<p>File Roll sink存储文件到本地文件系统中</p>
<p>Null sink丢弃从通道接收的所有事件</p>
<p>HBase sink将数据写入到hbase中</p>
<p>AsyncHbase sink异步方式将数据写入到hbase中</p>
<p>Custom sink 自定义sink</p>
<p><span style="font-weight:700;">flume channel</span></p>
<p>Memory channel 时间存储在一个可配置的最大尺寸的内存中的队列；速度快，吞吐量大，但是代理出现故障时数据丢失</p>
<p>JDBC channel 时间存储在数据库中</p>
<p>File channel 不同的file channel应该写到不同的磁盘上，避免单磁盘io过大</p>
<p>Pseudo Thansaction channel 用于测试</p>
<p>Custom channel 自定义channel</p>
<p>flume channel selector</p>
<p>Replicating channel selector （default） 复制，相同的数据发送到多个channel</p>
<p>Multiplexing channel selector 复用，以header区分一个event发送到哪个channel</p>
<p>Custom channel selector 自定义channel selector</p>
<p>数据通信系统或计算机网络系统中，传输媒体的带宽或容量往往会大于传输单一信号的需求，为了有效地利用通信线路,希望一个信道同时传输多路信号，这就是所谓的多路复用技术(Multiplexing)。采用多路复用技术能把多个信号组合起来在一条物理信道上进行传输，在远距离传输时可大大节省电缆的安装和维护费用。</p>
<p>Flume sink processor</p>
<p>Default sink processor</p>
<p>Failover sink processor 故障转移（主备）</p>
<p>Load balancing sink processor 负载均衡：轮询round_robin或随机random</p>
<p>flume interceptor</p>
<p>拦截器主要是对事件的header信息信息操作，要么直接忽略他，要么修改他的数据</p>
<p><span style="font-weight:700;">一、Event Serializers</span></p>
<p>file_roll sink 和hdfs sink 都支持EventSerializer接口</p>
<p>Body TextSerializer，别名：text。这个拦截器将把事件的body部分写入到输出流中而不需要任何转换或者修改。事件的header将直接被忽略。</p>
<p>Avro Event Serializer别名：avro_event。这个拦截器将把事件序列化到一个Avro容器文件中。使用的模式和RPC Avro机制使用到的处理flume事件的机制一样。这个序列化器继承自AbstractAvroEventSerializer类。</p>
<p><span style="font-weight:700;">二、Timestamp Interceptor</span></p>
<p>Flume 可以在事件传输过程中对它进行修改与删除，而这个都是通过Interceptor进行实现的，实际都是往事件的header里插数据。而Timestamp Interceptor拦截器就是可以往event的header中插入关键词为timestamp的时间戳。</p>
<p><span style="font-weight:700;">三、Host Interceptor</span></p>
<p>该拦截器可以往event的header中插入关键词默认为host主机名或者ip地址（注意是agent运行的机器的主机名或者ip地址）</p>
<p><span style="font-weight:700;">四、Static Interceptor</span></p>
<p>Static Interceptor拦截器允许用户增加一个static的header并为所有的事件赋值。范围是所有事件。</p>
<p><span style="font-weight:700;">五、Regex FilteringInterceptor</span></p>
<p>Regex Filtering Interceptor拦截器用于过滤事件，筛选出与配置的正则表达式相匹配的事件。可以用于包含事件和排除事件(include 或者是exclude)。常用于数据清洗，通过正则表达式把数据过滤出来。</p>
<p>flume开发</p>
<p><span style="font-weight:700;">1、RPC</span></p>
<p>flume虽然包含一些内部机制来采集数据，但是有时候用户希望能将应用程序和flume直接相通。flume client是一个库，允许应用程序链接flume和通过rpc往flume发送数据。</p>
<p>avro是flume默认的rpc协议</p>
<p><span style="font-weight:700;">2、Transaction</span></p>
<p>Flume 的核心是把数据从数据源收集过来，再送到目的地。为了保证输送一定成功，在送到目的地之前，会先缓存数据，待数据真正到达目的地后，删除自己缓存的数据。</p>
<p>Flume 使用事务性的方式保证传送Event整个过程的可靠性。Sink 必须在 Event 被存入 Channel 后，或者，已经被传达到下一站agent里，又或者，已经被存入外部数据目的地之后，才能把 Event 从 Channel 中 remove 掉。这样数据流里的 event 无论是在一个 agent 里还是多个 agent 之间流转，都能保证可靠，因为以上的事务保证了
 event 会被成功存储起来。而 Channel 的多种实现在可恢复性上有不同的保证。也保证了 event 不同程度的可靠性。比如 Flume 支持在本地保存一份文件 channel 作为备份，而memory channel 将 event 存在内存 queue 里，速度快，但丢失的话无法恢复。</p>
<p><span style="font-weight:700;">3、Source</span></p>
<p><span style="font-weight:700;">4、Sink</span></p>
<p><span style="font-weight:700;">最佳实践</span></p>
<p>参考基于Flume的美团日志收集系统(一)架构和设计，列出一些最佳实践：</p>
<p>模块命名规则：所有的 Source 以 src 开头，所有的 Channel 以 ch 开头，所有的 Sink 以 sink 开头；</p>
<p>模块之间内部通信统一使用 Avro 接口；</p>
<p>将日志采集系统系统分为三层：Agent 层，Collector 层和 Store 层，其中 Agent 层每个机器部署一个进程，负责对单机的日志收集工作；Collector 层部署在中心服务器上，负责接收Agent层发送的日志，并且将日志根据路由规则写到相应的 Store 层中；Store 层负责提供永久或者临时的日志存储服务，或者将日志流导向其它服务器。</p>
<p>扩展 MemoryChannel 和 FileChannel ，提供 DualChannel 的实现，以提供高吞吐和大缓存</p>
<p>监控 collector HdfsSink写数据到 hdfs 的速度、FileChannel 中拥堵的 events 数量，以及写 hdfs 状态（查看是否有 .tmp 文件生成）</p>
<p>PS：</p>
<p>关注微信公众号“程序员OfHome”，发送“领取资料”可以免费领取视频资料。</p>
<p>对大数据感兴趣的朋友可以加入到我们的<span style="font-weight:700;">程序员OfHomeQQ群：610535338 </span>群里有都是从事或者在学习大数据的朋友，在此我也邀请你进群一起学习，群内没有广告，也是禁止打广告的，大家也可以关注一下我的微信公共号“程序员OfHome”下方扫扫可关注。</p>
<p><br><img src="https://upload-images.jianshu.io/upload_images/8771499-52ca61f4afe03f61.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/258" alt="" style="border:0px;vertical-align:middle;display:block;z-index:100;color:rgb(47,47,47);font-size:16px;text-align:center;"><br></p>
<p><br></p>
<div><img src="https://upload-images.jianshu.io/upload_images/8771499-52ca61f4afe03f61.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/258" alt="" style="border:0px;vertical-align:middle;display:block;z-index:100;color:rgb(47,47,47);font-size:16px;text-align:center;"></div>
            </div>
                </div>