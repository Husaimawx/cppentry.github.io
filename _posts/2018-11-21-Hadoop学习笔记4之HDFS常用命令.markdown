---
layout:     post
title:      Hadoop学习笔记4之HDFS常用命令
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/cskywit/article/details/80502397				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>1.查看${Hadoop_HOME}/bin/hadoop脚本的hadoop命令帮助信息打印可知：</p><p><img src="https://img-blog.csdn.net/20180529212442937" alt=""></p><p>hadoop  version   //查看版本</p><p>hadoop fs        //文件系统客户端</p><p>hadoop  jar    //运行jar包</p><p>hadoop classpath //查看类路径</p><p>hadoop checknative //检查本地库并压缩</p><p>hadoop distcp   // 远程递归拷贝文件</p><p>hadoop credential //认证</p><p>hadoop trace    //跟踪</p><p>不同的命令对应了不同的java类</p><p> </p><p>2.bin/hdfs可以执行的命令</p><p><span style="color:#FF0000;">dfs    </span>              //等价于 hadoop fs命令.</p><p> classpath            prints the classpath</p><p> namenode -format     format theDFS filesystem</p><p> secondarynamenode    run the DFSsecondary namenode</p><p> namenode             run the DFSnamenode</p><p> journalnode          run the DFSjournalnode</p><p> zkfc                 run the ZKFailover Controller daemon</p><p> datanode             run a DFSdatanode</p><p> dfsadmin             run a DFSadmin client</p><p> haadmin              run a DFS HAadmin client</p><p> fsck                 run a DFSfilesystem checking utility</p><p> balancer             run a clusterbalancing utility</p><p> jmxget               get JMXexported values from NameNode or DataNode.</p><p> mover                run a utilityto move block replicas across</p><p>                       storage types</p><p> oiv                  apply theoffline fsimage viewer to an fsimage</p><p> oiv_legacy           apply theoffline fsimage viewer to an legacy fsimage</p><p> oev                  apply theoffline edits viewer to an edits file</p><p> fetchdt              fetch adelegation token from the NameNode</p><p> getconf              get configvalues from configuration</p><p> groups               get thegroups which users belong to</p><p> snapshotDiff         diff twosnapshots of a directory or diff the</p><p>                       current directorycontents with a snapshot</p><p> lsSnapshottableDir   list allsnapshottable dirs owned by the current user</p><p>                                               Use -help to see options</p><p> portmap              run a portmapservice</p><p> nfs3                 run an NFSversion 3 gateway</p><p> cacheadmin           configure theHDFS cache</p><p> crypto               configureHDFS encryption zones</p><p> storagepolicies      list/get/setblock storage policies</p><p> version              print theversion</p><p> </p><p>3.hdfs fds命令：</p><p>Usage: hadoop fs [generic options]</p><p>       [-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]</p><p>       [-cat [-ignoreCrc] &lt;src&gt; ...]</p><p>       [-checksum &lt;src&gt; ...]</p><p>       [-chgrp [-R] GROUP PATH...]</p><p>       [-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]</p><p>       [-chown [-R] [OWNER][:[GROUP]] PATH...]</p><p>       [-copyFromLocal [-f] [-p] [-l] &lt;localsrc&gt; ... &lt;dst&gt;]</p><p>       [-copyToLocal [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</p><p>       [-count [-q] [-h] &lt;path&gt; ...]</p><p>       [-cp [-f] [-p | -p[topax]] &lt;src&gt; ... &lt;dst&gt;]</p><p>       [-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]]</p><p>       [-deleteSnapshot&lt;snapshotDir&gt; &lt;snapshotName&gt;]</p><p>       [-df [-h] [&lt;path&gt; ...]]</p><p>       [-du [-s] [-h] &lt;path&gt; ...]</p><p>       [-expunge]</p><p>       [-find &lt;path&gt; ... &lt;expression&gt; ...]</p><p>       [-get [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</p><p>       [-getfacl [-R] &lt;path&gt;]</p><p>       [-getfattr [-R] {-n name | -d} [-e en] &lt;path&gt;]</p><p>       [-getmerge [-nl] &lt;src&gt; &lt;localdst&gt;]</p><p>       [-help [cmd ...]]</p><p>       [-ls [-d] [-h] [-R] [&lt;path&gt; ...]]</p><p>       [-mkdir [-p] &lt;path&gt; ...]</p><p>       [-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]</p><p>       [-moveToLocal &lt;src&gt; &lt;localdst&gt;]</p><p>       [-mv &lt;src&gt; ... &lt;dst&gt;]</p><p>       [-put [-f] [-p] [-l] &lt;localsrc&gt; ... &lt;dst&gt;]</p><p>       [-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;]</p><p>       [-rm [-f] [-r|-R] [-skipTrash] &lt;src&gt; ...]</p><p>       [-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]</p><p>       [-setfacl [-R] [{-b|-k} {-m|-x &lt;acl_spec&gt;} &lt;path&gt;]|[--set&lt;acl_spec&gt; &lt;path&gt;]]</p><p>       [-setfattr {-n name [-v value] | -x name} &lt;path&gt;]</p><p>       [-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...]</p><p>       [-stat [format] &lt;path&gt; ...]</p><p>       [-tail [-f] &lt;file&gt;]</p><p>       [-test -[defsz] &lt;path&gt;]</p><p>       [-text [-ignoreCrc] &lt;src&gt; ...]</p><p>       [-touchz &lt;path&gt; ...]</p><p>       [-truncate [-w] &lt;length&gt; &lt;path&gt; ...]</p><p>       [-usage [cmd ...]]</p><p> </p><p>4.例：</p><p>$ hdfs dfs -mkdir-p /user/ubuntu/        //在hdfs上建立文件夹</p><p>$ hdfs dfs -puthdfs.cmd  /user/ubuntu/  //将本地文件上传到HDFS</p><p>$ hdfs dfs -get/user/ubuntu/hadoop.cmd  a.cmd   //将文件从HDFS取回本地</p><p>$  hdfs dfs -rm -r  -f  /user/ubuntu/    //删除</p><p>hdfs dfs -ls -R/                       //递归展示HDFS文件系统</p>            </div>
                </div>