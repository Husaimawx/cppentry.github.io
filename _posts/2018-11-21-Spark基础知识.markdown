---
layout:     post
title:      Spark基础知识
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p><span style="color:#f33b45;"><strong>Spark为什么比Hadoop快？</strong></span></p>

<p>1、Spark基于内存<br>
    Spark默认情况下将处理过程中的数据保存在内存中，而Hadoop的计算结果每次都保存到磁盘，增加了I/O读写的时间。这也导致在迭代计算时Spark速度愈发快于Hadoop。<br>
2、Spark基于DAG<br>
    Spark的执行任务事先已经通过DAG规划，任务管理更加精细化。<br>
3、移动计算而非移动数据<br>
    RDD的partitions就近读取节点上的数据进行计算。</p>

<p><strong><span style="color:#f33b45;">Spark的运行模式有哪几种？</span></strong></p>

<p>1、本地模式<br>
2、Standalone<br>
3、第三方资源调度框架（Yarn、Mesos）</p>

<p><span style="color:#f33b45;"><strong>生成DataFrame的方式有哪些？</strong></span></p>

<p>1、从RDD转换为DataFrame<br>
    （1）某一类的RDD转换为DataFrame<br>
           val df = class_rdd.toDF<br>
    （2）结构化的RDD转换为DataFrame<br>
              val df = sparkSession.createDataFrame(row_rdd,schema)<br>
2、从文件读取<br>
    （1）parquet文件<br>
          spark.read.load(path)<br>
    （2）json文件<br>
          spark.read.json(path)</p>

<p> </p>            </div>
                </div>