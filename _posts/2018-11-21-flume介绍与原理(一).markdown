---
layout:     post
title:      flume介绍与原理(一)
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
转自：http://www.cnblogs.com/gongxijun/p/5656778.html<br><br>
1 .背景<br>
  flume是由cloudera软件公司产出的可分布式日志收集系统，后与2009年被捐赠了apache软件基金会，为hadoop相关组件之一。尤其近几年随着flume的不断被完善以及升级版本的逐一推出，特别是flume-ng;同时flume内部的各种组件不断丰富，用户在开发的过程中使用的便利性得到很大的改善，现已成为apache top项目之一.<br>
 <br>
2 .概述<br>
   1.  什么是flume?<br>
   apache Flume 是一个从可以收集例如日志，事件等数据资源，并将这些数量庞大的数据从各项数据资源中集中起来存储的工具/服务，或者数集中机制。flume具有高可用，分布式，配置工具，其设计的原理也是基于将数据流，如日志数据从各种网站服务器上汇集起来存储到HDFS，HBase等集中存储器中。其结构如下图所示：<br><p><img src="http://images2015.cnblogs.com/blog/539316/201607/539316-20160710192339483-1093743457.jpg" alt="">       </p>
<p><br></p>
<p><br></p>
  2.应用场景<br>
    比如我们在做一个电子商务网站，然后我们想从消费用户中访问点特定的节点区域来分析消费者的行为或者购买意图. 这样我们就可以更加快速的将他想要的推送到界面上，实现这一点，我们需要将获取到的她访问的页面以及点击的产品数据等日志数据信息收集并移交给Hadoop平台上去分析.而Flume正是帮我们做到这一点。现在流行的内容推送，比如广告定点投放以及新闻私人定制也是基于次，不过不一定是使用FLume,毕竟优秀的产品很多，比如facebook的Scribe，还有Apache新出的另一个明星项目chukwa，还有淘宝Time
 Tunnel。<br>
3.Flume的优势<br>
      1.  Flume可以将应用产生的数据存储到任何集中存储器中，比如HDFS,HBase<br>
      2.  当收集数据的速度超过将写入数据的时候，也就是当收集信息遇到峰值时，这时候收集的信息非常大，甚至超过了系统的写入数据能力，这时候，Flume会在数据生产者和数据收容器间做出调整，保证其能够在两者之间提供一共平稳的数据.<br>
     3.   提供上下文路由特征<br>
     4.   Flume的管道是基于事务，保证了数据在传送和接收时的一致性.<br>
     5.   Flume是可靠的，容错性高的，可升级的，易管理的,并且可定制的。 <br>
4. Flume具有的特征：<br>
    1. Flume可以高效率的将多个网站服务器中收集的日志信息存入HDFS/HBase中<br>
    2. 使用Flume，我们可以将从多个服务器中获取的数据迅速的移交给Hadoop中<br>
    3. 除了日志信息，Flume同时也可以用来接入收集规模宏大的社交网络节点事件数据，比如facebook,twitter,电商网站如亚马逊，flipkart等<br>
    4. 支持各种接入资源数据的类型以及接出数据类型<br>
    5. 支持多路径流量，多管道接入流量，多管道接出流量，上下文路由等<br>
    6. 可以被水平扩展<br>
 <br>
 3. Flume的结构<br>
    1. flume的外部结构：<br>
 <img src="http://images2015.cnblogs.com/blog/539316/201607/539316-20160710192411655-1258050429.jpg" alt=""><br>
     <br>
     如上图所示，数据发生器（如：facebook,twitter）产生的数据被被单个的运行在数据发生器所在服务器上的agent所收集，之后数据收容器从各个agent上汇集数据并将采集到的数据存入到HDFS或者HBase中<br>
 2. Flume 事件<br>
  事件作为Flume内部数据传输的最基本单元.它是由一个转载数据的字节数组(该数据组是从数据源接入点传入，并传输给传输器，也就是HDFS/HBase)和一个可选头部构成.<br><p>典型的Flume 事件如下面结构所示：</p>
<p><img src="http://images2015.cnblogs.com/blog/539316/201607/539316-20160710200535405-525622527.jpg" alt=""><br></p>
 <br>
我们在将event在私人定制插件时比如：flume-hbase-sink插件是，获取的就是event然后对其解析，并依据情况做过滤等，然后在传输给HBase或者HDFS.<br>
3.Flume Agent<br>
  我们在了解了Flume的外部结构之后,知道了Flume内部有一个或者多个Agent,然而对于每一个Agent来说,它就是一共独立的守护进程(JVM),它从客户端哪儿接收收集,或者从其他的 Agent哪儿接收,然后迅速的将获取的数据传给下一个目的节点sink,或者agent. 如下图所示flume的基本模型<br>
 <img src="http://images2015.cnblogs.com/blog/539316/201607/539316-20160710201913405-993590950.jpg" alt=""><br>
Agent主要由:source,channel,sink三个组件组成.<br>
 <br>
Source:<br>
   从数据发生器接收数据,并将接收的数据以Flume的event格式传递给一个或者多个通道channal,Flume提供多种数据接收的方式,比如Avro,Thrift,twitter1%等<br>
Channel:<br>
 channal是一种短暂的存储容器,它将从source处接收到的event格式的数据缓存起来,直到它们被sinks消费掉,它在source和sink间起着一共桥梁的作用,channal是一个完整的事务,这一点保证了数据在收发的时候的一致性. 并且它可以和任意数量的source和sink链接. 支持的类型有: JDBC channel , File System channel , Memort channel等.<br>
sink:<br>
  sink将数据存储到集中存储器比如Hbase和HDFS,它从channals消费数据(events)并将其传递给目标地. 目标地可能是另一个sink,也可能HDFS,HBase.<br>
 <br><p>它的组合形式举例:</p>
<p><br></p>
<p><br></p>
<p> <img src="http://images2015.cnblogs.com/blog/539316/201607/539316-20160710212100811-1167384889.png" alt=""></p>
<p></p>
<p>转载人注：下图类似于消息中间件AMQP，消息生产方产生的消息按照一定的路由规则路由到不同的队列中去，即同一个生产者产生测消息有可能被路由到不同的队列中，</p>
<p><span></span>  而一个消费者只能消费一个队列中的消息？</p>
<p><img src="http://images2015.cnblogs.com/blog/539316/201607/539316-20160710212113749-1885343.png" alt=""><br></p>
 <br>
 <br>
以上介绍的flume的主要组件,下面介绍一下Flume插件:<br>
1. Interceptors拦截器<br>
   用于source和channel之间,用来更改或者检查Flume的events数据<br>
2. 管道选择器 channels Selectors<br>
   在多管道是被用来选择使用那一条管道来传递数据(events). 管道选择器又分为如下两种:<br>
   默认管道选择器:  每一个管道传递的都是相同的events<br>
  多路复用通道选择器:  依据每一个event的头部header的地址选择管道.<br>
3.sink线程<br>
   用于激活被选择的sinks群中特定的sink,用于负载均衡.
            </div>
                </div>