---
layout:     post
title:      Spark视频王家林大神 第7课： Spark机器学习内幕剖析
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：王家林大咖2018年新书《SPARK大数据商业实战三部曲》清华大学出版，清华大学出版社官方旗舰店（天猫）https://qhdx.tmall.com/?spm=a220o.1000855.1997427721.d4918089.4b2a2e5dT6bUsM					https://blog.csdn.net/duan_zhihua/article/details/79176742				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>Spark视频王家林大神 第7课： Spark机器学习内幕剖析</p><p></p><p>本节讲解Spark机器学习内幕，Spark机器学习的本质是什么，Spark机器学习的内部构成到底是什么？基于Spark 2.x版本，怎么学习机器学习？这是所有做机器学习的同学都非常关注的。Spark 2.x版本的发布，标志着以Spark为核心的大数据统一计算时代真正的到来。</p><p>Spark机器学习的本质是什么？机器学习是数据+算法（迭代），从老师的角度而言，Spark机器学习就是Spark平台之上的函数库，这是一个非常重要的观点。将Spark机器学习看作普通的函数，很多函数构成函数库，机器学习mllib库函数有自己的一套逻辑，以机器学习的方式，机器学习比较特殊，具有迭代性，或基于迭代进行改进等，函数有自己内部的逻辑。这些函数基于RDD/DataFrame/DataSet，以后将全面转向DataSet。</p><p>Spark机器学习数据来源，在Spark的最底层肯定是RDD封装的，这个和Spark具体是什么版本没有任何关系，版本的发展只不过提供了更多的更高层的API而已。例如DataFrame/DataSet，而之所以有DataFrame/DataSet等，一般情况下是为了使用统一的优化引擎。在统一的优化引擎基础上，只要优化引擎，引擎上面的所有的子框架都会受益。抽象程度越高，优化算法和空间就越大<a name="_Hlk504760081">。</a>（因此越底层越高效的观点，显然是不完善的。）</p><p>Spark机器学习的数据来源主要基于RDD。看一下Spark机器学习的官网<span style="color:#000000;">（</span><span style="color:#000000;"><a href="http://spark.apache.org/docs/latest/mllib-guide.html" rel="nofollow"><span style="color:#000000;">http://spark.apache.org/docs/latest/mllib-guide.html</span></a></span><span style="color:#000000;">），</span><span style="color:#000000;">Spark2.2.1</span><span style="color:#000000;">版本的官方文档说明</span><span style="color:#000000;">MLlib</span><span style="color:#000000;">库有基于</span><span style="color:#000000;">RDD</span><span style="color:#000000;">的</span><span style="color:#000000;">RDD-basedAPI</span><span style="color:#000000;">，也有基于</span><span style="color:#000000;">DataFrame</span><span style="color:#000000;">的</span><span style="color:#000000;">DataFrame-basedAPI</span><span style="color:#000000;">。</span><span style="color:#000000;">SparkRDD</span><span style="color:#000000;">有一个弱点，就是它的每一行的列的数据不是可知的，但是如果变成了</span><span style="color:#000000;">DataFrame</span><span style="color:#000000;">或者</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">，使用统一的</span><span style="color:#000000;">Catalyst</span><span style="color:#000000;">引擎，对列的数据带来更大的优化空间。</span><span style="color:#000000;">Spark2.x </span><span style="color:#000000;">版本的</span><span style="color:#000000;">DataFrame-based API</span><span style="color:#000000;">是</span><span style="color:#000000;">primary</span><span style="color:#000000;">级别的，</span><span style="color:#000000;">DataFrame-basedAPI </span><span style="color:#000000;">在</span><span style="color:#000000;">spark.ml</span><span style="color:#000000;">包里面。</span></p><p><span style="color:#000000;">MLlib</span><span style="color:#000000;">依旧支持</span><span style="color:#000000;">RDD-based API</span><span style="color:#000000;">的</span><span style="color:#000000;">BUG</span><span style="color:#000000;">的修复；</span><span style="color:#000000;">MLlib</span><span style="color:#000000;">不会再增加</span><span style="color:#000000;">RDD-basedAPI</span><span style="color:#000000;">新的算法和新的功能；</span><span style="color:#1D1F22;background:#FFFFFF;">在</span><span style="color:#1D1F22;background:#FFFFFF;">Spark 2.x</span><span style="color:#1D1F22;background:#FFFFFF;">发行版本中，</span><span style="color:#1D1F22;background:#FFFFFF;">Mllib</span><span style="color:#1D1F22;background:#FFFFFF;">将</span><span style="color:#1D1F22;background:#FFFFFF;">RDD-based API</span><span style="color:#1D1F22;background:#FFFFFF;">平滑过渡到</span><span style="color:#1D1F22;background:#FFFFFF;">DataFrames-based API</span><span style="color:#1D1F22;background:#FFFFFF;">，</span><span style="color:#1D1F22;background:#FFFFFF;">DataFrame</span><span style="color:#1D1F22;background:#FFFFFF;">的底层封装了</span><span style="color:#1D1F22;background:#FFFFFF;">RDD</span><span style="color:#1D1F22;background:#FFFFFF;">。</span><span style="color:#1D1F22;background:#FFFFFF;">RDD-based API </span><span style="color:#1D1F22;background:#FFFFFF;">可能在</span><span style="color:#1D1F22;background:#FFFFFF;">Spark 3.0</span><span style="color:#1D1F22;background:#FFFFFF;">的时候移除掉，将来将完全基于</span><span style="color:#1D1F22;background:#FFFFFF;">DataFrame</span><span style="color:#1D1F22;background:#FFFFFF;">或</span><span style="color:#1D1F22;background:#FFFFFF;">DataSet</span><span style="color:#1D1F22;background:#FFFFFF;">。</span>越上层引擎就越统一，Spark SQL、Spark Streaming也越来越倾向于基于DataFrame/DataSet统一的引擎，更高程度的抽象，更多优化的算法，更大优化的空间，性能会更好。</p><p>但是机器学习从算法的角度而言，最原始的其实都是基于向量Vector和矩阵Matrix进行计算的，也就是RDD/DataFrame/DataSet等里面的数据从机器学习的角度讲都是Vector和Matrix，而借助于RDD/DataFrame/DataSet天然的分布式并行计算就完成了机器学习的并行化和可扩展性等。</p><p>其实机器学习和图计算的思路非常相似，图计算中的数据也是存储在RDD中的，但是Spark的图计算提供了Vertices、Edges、Routing Tables等对象来解析RDD中的数据，从而变成图计算可用的数据。机器学习的方式是Vector和Matrix的方式，底层都基于RDD。</p><p>Spark机器学习一方面基于RDD/DataFrame/DataSet，另一方面由Vector和Matrix通过JNI的方式调用已有的数学库的实现，中间由很多算法（函数）<span style="color:#000000;">。如图所示。</span></p><p><img src="https://img-blog.csdn.net/20180126210855301?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZHVhbl96aGlodWE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br>                                              </p><p><strong><span style="color:#FF0000;"> </span></strong></p><p><span style="color:#000000;">如何基于</span><span style="color:#000000;">Spark2.x</span><span style="color:#000000;">进行</span><span style="color:#000000;">Spark</span><span style="color:#000000;">机器学习？</span></p><p><span style="color:#000000;">1)      </span><span style="color:#000000;">巩固学习</span><span style="color:#000000;">Spark Core</span><span style="color:#000000;">的内容。</span></p><p><span style="color:#000000;">2)      </span><span style="color:#000000;">Vector</span><span style="color:#000000;">和</span><span style="color:#000000;">Matrix</span><span style="color:#000000;">的学习需要花一点精力，矩阵非常复杂，需要学习一年以上的时间。从阅读机器学习源码的角度，用了哪些</span><span style="color:#000000;">Vector</span><span style="color:#000000;">和</span><span style="color:#000000;">Matrix</span><span style="color:#000000;">的信息。</span></p><p><span style="color:#000000;">3)      </span><span style="color:#000000;">对于</span><span style="color:#000000;">Spark</span><span style="color:#000000;">机器学习的每个算法，学习的步骤：</span></p><p><span style="color:#000000;">第一步：算法是如何推演过来的，也就是算法的原理（应用场景）。</span></p><p><span style="color:#000000;">第二步：</span><span style="color:#000000;">Spark</span><span style="color:#000000;">如何用代码实现的；</span></p><p><span style="color:#000000;">第三步：案例实战；</span></p><p><span style="color:#000000;">第四步：基于上面的三步进行深入的思考。</span></p><p> 致谢DT大数据梦工厂和王家林大神！</p><br>            </div>
                </div>