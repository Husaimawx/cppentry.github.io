---
layout:     post
title:      03.分布式文件系统HDFS
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/ZJ__ZFH/article/details/79600973				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h2 id="分布式文件系统hdfs">分布式文件系统HDFS</h2>



<h3 id="hdfs概述及设计目标">HDFS概述及设计目标</h3>



<h4 id="什么是hdfs">什么是HDFS</h4>

<p>Hadoop实现了一个分布式文件系统(Hadoop Distributed File System),简称HDFS <br>
源自Google的GFS论文 <br>
发表于2003年，HDFS是GFS的克隆版</p>



<h4 id="hdfs的设计目标">HDFS的设计目标</h4>

<ol>
<li>非常巨大的分布式文件系统</li>
<li>运行在普通廉价的硬件上</li>
<li>以扩展，为用户提供性能不错的文件存储服务</li>
</ol>



<h3 id="hdfs架构">HDFS架构</h3>

<p><img src="//img-blog.csdn.net/20180318093134142?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L1pKX19aRkg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
1个Master(NameNode/NN) 带 N个Slaves(DataNode/DN) <br>
1个文件会被拆分成多个blocks <br>
NN负责： <br>
1. 负责客户端请求的数据 <br>
2. 负责元数据(文件的名称、副本系数、block存放的DN)的管理 <br>
DN的职责： <br>
1. 存储用户的文件对应的数据块(Block) <br>
2. 要定期向NN发送心跳信息，汇报本身及其所有的block信息及健康状况 <br>
A typical deployment has a dedicated machine that runs only the NameNode software. Each of the other machines in the cluster runs one instance of the DataNode software. The architecture does not preclude running multiple DataNodes on the same machine but in a real deployment that is rarely the case. <br>
NameNode + N个DataNode <br>
建议:NN和DN是部署在不同的节点上   </p>



<h3 id="hdfs副本机制">HDFS副本机制</h3>

<p><img src="//img-blog.csdn.net/20180318093152862?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L1pKX19aRkg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>



<h3 id="hdfs环境搭建">HDFS环境搭建</h3>

<p>hadoop伪分布式安装步骤 <br>
1. jdk安装 <br>
2. 安装ssh <br>
yum install ssh <br>
ssh-keygen -t rsa <br>
cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys <br>
3. 下载并解压hadoop <br>
<a href="http://archive.cloudera.com/cdh5/cdh/5/" rel="nofollow">地址</a> <br>
解压:tar -zxvf hadoop-2.6.0-xxxx <br>
4. hadoop配置文件的修改(hadoop_home/etc/hadoop) <br>
修改hadoop-env.sh <br>
<img src="//img-blog.csdn.net/20180318104114637?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L1pKX19aRkg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
修改core-site.xml  <br>
<img src="//img-blog.csdn.net/20180318105239276?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L1pKX19aRkg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
修改hdfs-site.xml <br>
<img src="//img-blog.csdn.net/20180318105447820?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L1pKX19aRkg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
修改slaves <br>
<img src="//img-blog.csdn.net/20180318105603544?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L1pKX19aRkg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
5.  启动hdfs <br>
格式化系统(仅第一次执行即可，不要重复执行): hdfs namenode -format <br>
<img src="//img-blog.csdn.net/2018031810595765?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L1pKX19aRkg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
启动:hdfs:sbin/start-dfs.sh <br>
验证是否启动成功: <br>
方式1:jps <br>
<img src="//img-blog.csdn.net/20180318110508693?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L1pKX19aRkg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
方式2 <br>
浏览器访问方式:<a href="http://localhost:50070" rel="nofollow">http://localhost:50070</a> <br>
6.  停止hdfs <br>
sbin/stop-dfs.sh</p>

<h3 id="hdfs-shell">HDFS shell</h3>

<p>hdfs shell常用命令的使用，包括ls,mkdir,put,get,rm</p>



<h4 id="ls">ls</h4>

<p>hdfs dfs -ls /  <br>
hdfs dfs -ls -R /</p>

<h4 id="mkdir">mkdir</h4>

<p>hdfs dfs -mkdir /test1 <br>
hdfs dfs -mkdir -p /test/a/b</p>

<h4 id="put-copyfromlocal">put copyFromLocal</h4>

<p>hdfs dfs -put ./hadoop.txt / <br>
hdfs dfs -copyFromLocal hadoop.txt /test/a/b/h.txt</p>

<h4 id="get">get</h4>

<p>hdfs dfs -get /test/a/b/h.txt hello.txt</p>

<h4 id="rm">rm</h4>

<p>hdfs dfs -rm /hadoop.txt <br>
hdfs dfs -rm -R /test</p>

<h4 id="cat">cat</h4>

<p>hdfs dfs -cat /hadoop.txt</p>

<h4 id="text">text</h4>

<p>hdfs dfs -text /hadoop.txt</p>

<h3 id="java-api操作hdfs">Java API操作HDFS</h3>



<h4 id="idea-maven构建java工程">IDEA Maven构建Java工程</h4>



<h4 id="title"> </h4>

<h3 id="hdfs文件读写流程">HDFS文件读写流程</h3>



<h3 id="hdfs优缺点">HDFS优缺点</h3>

<hr>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>