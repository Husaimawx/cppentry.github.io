---
layout:     post
title:      flume篇
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h1 id="flume介绍">flume介绍</h1>

<blockquote>
  <p>日志数据收集器</p>
</blockquote>



<h1 id="flume使用步骤">flume使用步骤</h1>

<blockquote>
  <ol>
  <li>定义source，channel(通道),sink(转存的位置)</li>
  <li>启动agent</li>
  <li>如果有数据，就已经开始接受转存了</li>
  </ol>
</blockquote>



<h1 id="flume运行机理">flume运行机理</h1>

<p><img title="" alt="这里写图片描述" src="https://img-blog.csdn.net/20180127155212326?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnJlZTk3emw=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>



<h1 id="flume-type介绍">flume type介绍</h1>

<blockquote>
  <ul>
  <li>source type <br>
  <ul><li>Avro,  Exec, Jms, Spooling directory, Netcat, Http,  <br>
  Syslog, Thrift, twitter等 <br>
  高级编写自己的source type</li></ul></li>
  <li>channel <br>
  <ul><li>可以存放在memory、jdbc、file中</li></ul></li>
  <li>sink type <br>
  <ul><li>HDFS, Hbase 或SPARK STREAM也可能是另一个sink</li></ul></li>
  </ul>
</blockquote>



<h1 id="flume-demo"> flume demo</h1>



<pre class="prettyprint"><code class=" hljs avrasm">安装解压flume：
/home/hadoop/opt/apache-flume-<span class="hljs-number">1.8</span><span class="hljs-number">.0</span>-bin/conf
vi spooldir<span class="hljs-preprocessor">.conf</span>

========================================================
spooldir<span class="hljs-preprocessor">.sources</span>=sa
spooldir<span class="hljs-preprocessor">.channels</span>=ma
spooldir<span class="hljs-preprocessor">.sinks</span>=ha

spooldir<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.sa</span><span class="hljs-preprocessor">.type</span>=spooldir
spooldir<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.sa</span><span class="hljs-preprocessor">.spoolDir</span>=/home/hadoop/firstdemo/flume_spider
spooldir<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.sa</span><span class="hljs-preprocessor">.fileHeader</span> = true

spooldir<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.ma</span><span class="hljs-preprocessor">.type</span>=memory
spooldir<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.ma</span><span class="hljs-preprocessor">.capacity</span>=<span class="hljs-number">10000</span>
spooldir<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.ma</span><span class="hljs-preprocessor">.transactioncapacity</span>=<span class="hljs-number">1000000</span>

<span class="hljs-preprocessor">#spooldir.sinks.ha.type=logger</span>
spooldir<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.ha</span><span class="hljs-preprocessor">.type</span>=hdfs
spooldir<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.ha</span><span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.fileType</span>=DataStream
spooldir<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.ha</span><span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.path</span>=/user/hadoop/spider
spooldir<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.ha</span><span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.writeFormat</span>=Text
spooldir<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.ha</span><span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.batchSize</span>=<span class="hljs-number">10000</span>
spooldir<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.ha</span><span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.rollCount</span>=<span class="hljs-number">1000</span>
spooldir<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.ha</span><span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.fileSuffix</span>=<span class="hljs-preprocessor">.csv</span>
spooldir<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.ha</span><span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.filePrefix</span>=test
spooldir<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.ha</span><span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.rollSize</span>=<span class="hljs-number">0</span>
spooldir<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.ha</span><span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.rollInterval</span>=<span class="hljs-number">0</span>


spooldir<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.sa</span><span class="hljs-preprocessor">.channels</span>=ma
spooldir<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.ha</span><span class="hljs-preprocessor">.channel</span>=ma 
me
==
</code></pre>

<p>启动flume <br>
./bin/flume-ng agent -n spooldir -c conf -f conf/spooldir.conf  <br>
重新加载flume <br>
./bin/flume-ng agent -n spooldir -c conf -f conf/spooldir.conf -Dflume.root.logger=INFO,console <br>
“`</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>