---
layout:     post
title:      hbase常见错误
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：转载请注明出处					https://blog.csdn.net/seashouwang/article/details/81699221				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p style="margin-left:0cm;"> </p>

<ol><li>
	<ol><li>hbase启动错误
		<ol><li>org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper: The identifier of this process is 4818@localhost85</li>
		</ol></li>
	</ol></li>
</ol><p style="margin-left:0cm;">[root@localhost86 local]#<span style="color:#FF0000;"> hbase shell</span></p>

<p style="margin-left:0cm;">HBase Shell; enter 'help&lt;RETURN&gt;' for list of supported commands.</p>

<p style="margin-left:0cm;">Type "exit&lt;RETURN&gt;" to leave the HBase Shell</p>

<p style="margin-left:0cm;">Version 0.94.7, r1471806, Wed Apr 24 18:44:36 PDT 2013</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">hbase(main):001:0&gt; <span style="color:#FF0000;">list</span></p>

<p style="margin-left:0cm;">TABLE                                                                                          </p>

<p style="margin-left:0cm;">17/04/01 19:15:06 ERROR zookeeper.RecoverableZooKeeper: ZooKeeper exists failed after 3 retries</p>

<p style="margin-left:0cm;">17/04/01 19:15:06 WARN zookeeper.ZKUtil: hconnection Unable to set watcher on znode (/hbase/hbaseid)</p>

<p style="margin-left:0cm;">org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid</p>

<p style="margin-left:0cm;">    at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)</p>

<p style="margin-left:0cm;">    at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)</p>

<p style="margin-left:0cm;">    at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1041)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:172)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:450)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.zookeeper.ClusterId.readClusterIdZNode(ClusterId.java:61)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.zookeeper.ClusterId.getId(ClusterId.java:50)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.zookeeper.ClusterId.hasId(ClusterId.java:44)</p>

<p style="margin-left:0cm;">    at</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><strong>根据日志文件记录分析：</strong></p>

<p style="margin-left:0cm;"> <span style="color:#FF0000;">vim hbase-root-master-localhost85.log</span></p>

<p style="margin-left:0cm;">INFO <span style="color:#FF0000;">org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper: The identifier of this process is 4818@localhost85</span></p>

<p style="margin-left:0cm;">原因：主要是hbase-site.xml中hbase.zookeeper.quorum的值配置错误</p>

<p style="margin-left:0cm;">&lt;property&gt;</p>

<p style="margin-left:0cm;">&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</p>

<p style="margin-left:0cm;"><span style="color:#FF0000;">&lt;!--&lt;value&gt;localhost85,localhost86&lt;/value&gt;--&gt;</span></p>

<p style="margin-left:0cm;"><span style="color:#FF0000;">修改为以下内容</span></p>

<p style="margin-left:0cm;">   <span style="color:#FF0000;"> &lt;value&gt;192.168.1.85,192.168.1.86&lt;/value&gt;</span></p>

<p style="margin-left:0cm;">  &lt;/property&gt;</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<ol><li>
	<ol><li>
		<ol><li>org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server is not running yet</li>
		</ol></li>
	</ol></li>
</ol><p style="margin-left:0cm;">hbase(main):003:0* list</p>

<p style="margin-left:0cm;">TABLE                                                                                                </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><span style="color:#FF0000;">ERROR: org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server is not running yet</span></p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.master.HMaster.checkServiceStarted(HMaster.java:2445)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.master.MasterRpcServices.isMasterRunning(MasterRpcServices.java:946)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:58521)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2339)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:123)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:188)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:168)</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">Here is some help for this command:</p>

<p style="margin-left:0cm;">List all tables in hbase. Optional regular expression parameter could</p>

<p style="margin-left:0cm;">be used to filter the output. Examples:</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">  hbase&gt; list</p>

<p style="margin-left:0cm;">  hbase&gt; list 'abc.*'</p>

<p style="margin-left:0cm;">  hbase&gt; list 'ns:abc.*'</p>

<p style="margin-left:0cm;">  hbase&gt; list 'ns:.*'</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><strong>原因：</strong></p>

<p style="margin-left:0cm;"><strong>    Hadoop</strong><strong>目录hdfs在访问时是受包含模式，取消hdfs目录访问安全模式。</strong></p>

<p style="margin-left:0cm;"><strong>解决办法：</strong></p>

<p style="margin-left:0cm;"><strong>进入hadoop安装目录中执行命令： <span style="color:#FF0000;">bin/hdfs dfsadmin –safemode leave</span></strong></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<ol><li>
	<ol><li>
		<ol><li>localhosti65: ssh: Could not resolve hostname localhosti65: Name or service not known</li>
		</ol></li>
	</ol></li>
</ol><p style="margin-left:0cm;">[root@localhost65 hbase-1.3.1]# bin/start-hbase.sh</p>

<p style="margin-left:0cm;">localhost65: starting zookeeper, logging to /usr/local/hbase-1.3.1/bin/../logs/hbase-root-zookeeper-localhost65.out</p>

<p style="margin-left:0cm;">starting master, logging to /usr/local/hbase-1.3.1/logs/hbase-root-master-localhost65.out</p>

<p style="margin-left:0cm;">Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128m; support was removed in 8.0</p>

<p style="margin-left:0cm;">Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=128m; support was removed in 8.0</p>

<p style="margin-left:0cm;"><span style="color:#FF0000;">localhosti65: ssh: Could not resolve hostname localhosti65: Name or service not known</span></p>

<p style="margin-left:0cm;">[root@localhost65 hbase-1.3.1]#</p>

<p style="margin-left:0cm;">问题原因：</p>

<p style="margin-left:0cm;">    Hbase中链接Zookeeper配置写错。</p>

<p style="margin-left:0cm;">解决办法：</p>

<p style="margin-left:0cm;">    1.检查hbase-site.xml中的zookeeper链接ip,端口配置是否正确。如下：</p>

<p style="margin-left:0cm;">&lt;property&gt;</p>

<p style="margin-left:0cm;">                &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</p>

<p style="margin-left:0cm;">                &lt;value&gt;localhost65&lt;/value&gt;</p>

<p style="margin-left:0cm;">        &lt;/property&gt;</p>

<p style="margin-left:0cm;">&lt;!--表示客户端连接 ZooKeeper 的端口 --&gt;</p>

<p style="margin-left:0cm;">        &lt;property&gt;</p>

<p style="margin-left:0cm;">                &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;</p>

<p style="margin-left:0cm;">                &lt;value&gt;2181&lt;/value&gt;</p>

<p style="margin-left:0cm;">        &lt;/property&gt;</p>

<p style="margin-left:0cm;">    2.检查regionservers 文件配置地址是否正确。如下：</p>

<p style="margin-left:0cm;">    [root@localhost65 hbase-1.3.1]# <span style="color:#FF0000;">vim conf/regionservers </span></p>

<p style="margin-left:0cm;"><span style="color:#FF0000;">localhost65 #</span><span style="color:#FF0000;">域名</span></p>

<p style="margin-left:0cm;">[root@localhost65 hbase-1.3.1]#</p>

<p style="margin-left:0cm;"> </p>

<ol><li>
	<ol><li>
		<ol><li>org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.fs.PathIsNotEmptyDirectoryException):`/hbase/WALs/localhost65,16201,1503546750714-splitting is non empty': Directory is not empty</li>
		</ol></li>
	</ol></li>
</ol><p style="margin-left:0cm;">2017-08-29 09:57:42,398 WARN  [ProcedureExecutor-0] master.SplitLogManager: Returning success without actually splitting and deleting all the log files in path hdfs://192.168.3.65:9000/hbase/WALs/localhost65,16201,1503546750714-splitting: [FileStatus{path=hdfs://192.168.3.65:9000/hbase/WALs/localhost65,16201,1503546750714-splitting/localhost65%2C16201%2C1503546750714.meta.1503568364024.meta; isDirectory=false; length=83; replication=1; blocksize=134217728; modification_time=1503568364030; access_time=1503568364030; owner=root; group=supergroup; permission=rw-r--r--; isSymlink=false}]</p>

<p style="margin-left:0cm;"><span style="color:#FF0000;">org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.fs.PathIsNotEmptyDirectoryException): `/hbase/WALs/localhost65,16201,1503546750714-splitting is non empty': Directory is not empty</span></p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:4012)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInt(FSNamesystem.java:3968)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3952)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:825)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:589)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)</p>

<p style="margin-left:0cm;">    at java.security.AccessController.doPrivileged(Native Method)</p>

<p style="margin-left:0cm;">    at javax.security.auth.Subject.doAs(Subject.java:422)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><strong>该问题原因较多，从以下几个方面检查： </strong></p>

<p style="margin-left:0cm;"><strong>1</strong><strong>、系统或hdfs是否有空间</strong><br><strong>2</strong><strong>、datanode数是否正常</strong> <br><strong>3</strong><strong>、是否在safemode</strong> <br><strong>4</strong><strong>、防火墙关闭</strong><br><strong>5</strong><strong>、配置方面</strong><br><strong>6</strong><strong>、把NameNode的tmp文件清空，然后重新格式化NameNode</strong></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<ol><li>
	<ol><li>
		<ol><li>ERROR:org.apache.hadoop.hbase.PleaseHoldException: Master is initializing</li>
		</ol></li>
	</ol></li>
</ol><p style="margin-left:0cm;">ERROR:org.apache.hadoop.hbase.PleaseHoldException: Master is initializing</p>

<p style="margin-left:0cm;">at org.apache.hadoop.hbase.master.HMaster.checkInitialized(HMaster.java:2452)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.master.MasterRpcServices.getClusterStatus(MasterRpcServices.java:792)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:58519)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2339)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:123)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:188)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:168)</p>

<p style="margin-left:0cm;"><span style="color:#000000;">can't get master address from ZooKeeper</span></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><strong><span style="color:#000000;">解决办法：</span></strong></p>

<p style="margin-left:0cm;"><span style="color:#000000;">通过查看日志信息来分析，可以看出hbase数据库 shell运行失败的原因大概就是时钟不同步了。安装ntpdate, sudo apt-get install ntpdate后，运行shell命令：ntpdate  0.cn.pool.ntp.org    这个命令很简单，参数可以选择任意一个时间服务器的地址，然后重启hbase数据库：bin/stop-hbase.sh     bin/start-hbase.sh  即可。可能会出现 can't get master address from ZooKeeper错误，这可能是由于ZooKeeper不稳定造成的，我试着又重启了一下，就可以了。</span></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<ol><li>
	<ol><li>
		<ol><li>Can't get master address from ZooKeeper; znode data == null</li>
		</ol></li>
	</ol></li>
</ol><p style="margin-left:0cm;">hbase(main):001:0&gt; status</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><span style="color:#FF0000;">ERROR: Can't get master address from ZooKeeper; znode data == null</span></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">Here is some help for this command:</p>

<p style="margin-left:0cm;">Show cluster status. Can be 'summary', 'simple', 'detailed', or 'replication'. The</p>

<p style="margin-left:0cm;">default is 'summary'. Examples:</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<ol><li>
	<ol><li>
		<ol><li>java.net.SocketTimeoutException: callTimeout=60000, callDuration=68489</li>
		</ol></li>
	</ol></li>
</ol><p style="margin-left:0cm;">hbase(main):029:0&gt;</p>

<p style="margin-left:0cm;">hbase(main):029:0&gt; [root@node3 ~]# hive</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">Logging initialized using configuration in jar:file:/opt/cloudera/parcels/CDH-5.10.0-1.cdh5.10.0.p0.41/jars/hive-common-1.1.0-cdh5.10.0.jar!/hive-log4j.properties</p>

<p style="margin-left:0cm;">WARNING: Hive CLI is deprecated and migration to Beeline is recommended.</p>

<p style="margin-left:0cm;">hive&gt; select *  FROM TempLogTerminal WHERE RESOURCETYPE=32 AND  AreaCode='610103' AND KEY LIKE 'T%';</p>

<p style="margin-left:0cm;">Query ID = root_20180227182020_72cd9a43-95b7-4e89-82d1-15feea3af10e</p>

<p style="margin-left:0cm;">Total jobs = 1</p>

<p style="margin-left:0cm;">Launching Job 1 out of 1</p>

<p style="margin-left:0cm;">Number of reduce tasks is set to 0 since there's no reduce operator</p>

<p style="margin-left:0cm;">Starting Job = job_1519724327083_0007, Tracking URL = http://node1:8088/proxy/application_1519724327083_0007/</p>

<p style="margin-left:0cm;">Kill Command = /opt/cloudera/parcels/CDH-5.10.0-1.cdh5.10.0.p0.41/lib/hadoop/bin/hadoop job  -kill job_1519724327083_0007</p>

<p style="margin-left:0cm;">Hadoop job information for Stage-1: number of mappers: 22; number of reducers: 0</p>

<p style="margin-left:0cm;">2018-02-27 18:21:08,970 Stage-1 map = 0%,  reduce = 0%</p>

<p style="margin-left:0cm;">2018-02-27 18:21:31,265 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 8.69 sec</p>

<p style="margin-left:0cm;">2018-02-27 18:21:32,334 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 17.66 sec</p>

<p style="margin-left:0cm;">2018-02-27 18:21:34,470 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 21.59 sec</p>

<p style="margin-left:0cm;">2018-02-27 18:21:36,574 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 25.94 sec</p>

<p style="margin-left:0cm;">2018-02-27 18:21:38,662 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 33.28 sec</p>

<p style="margin-left:0cm;">2018-02-27 18:21:39,704 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 33.44 sec</p>

<p style="margin-left:0cm;">2018-02-27 18:21:40,730 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 37.89 sec</p>

<p style="margin-left:0cm;">2018-02-27 18:21:48,923 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 39.94 sec</p>

<p style="margin-left:0cm;">2018-02-27 18:21:50,987 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 43.99 sec</p>

<p style="margin-left:0cm;">2018-02-27 18:21:52,008 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 55.82 sec</p>

<p style="margin-left:0cm;">2018-02-27 18:21:53,032 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 60.51 sec</p>

<p style="margin-left:0cm;">2018-02-27 18:21:54,067 Stage-1 map = 86%,  reduce = 0%, Cumulative CPU 69.67 sec</p>

<p style="margin-left:0cm;">2018-02-27 18:21:56,109 Stage-1 map = 91%,  reduce = 0%, Cumulative CPU 73.65 sec</p>

<p style="margin-left:0cm;">2018-02-27 18:22:56,560 Stage-1 map = 91%,  reduce = 0%, Cumulative CPU 73.65 sec</p>

<p style="margin-left:0cm;">2018-02-27 18:23:57,063 Stage-1 map = 91%,  reduce = 0%, Cumulative CPU 73.65 sec</p>

<p style="margin-left:0cm;">2018-02-27 18:24:55,426 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 73.65 sec</p>

<p style="margin-left:0cm;">MapReduce Total cumulative CPU time: 1 minutes 13 seconds 650 msec</p>

<p style="margin-left:0cm;">Ended Job = job_1519724327083_0007 with errors</p>

<p style="margin-left:0cm;">Error during job, obtaining debugging information...</p>

<p style="margin-left:0cm;">Examining task ID: task_1519724327083_0007_m_000002 (and more) from job job_1519724327083_0007</p>

<p style="margin-left:0cm;">Examining task ID: task_1519724327083_0007_m_000016 (and more) from job job_1519724327083_0007</p>

<p style="margin-left:0cm;">Examining task ID: task_1519724327083_0007_m_000020 (and more) from job job_1519724327083_0007</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">Task with the most failures(4):</p>

<p style="margin-left:0cm;">-----</p>

<p style="margin-left:0cm;">Task ID:</p>

<p style="margin-left:0cm;">  task_1519724327083_0007_m_000020</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">URL:</p>

<p style="margin-left:0cm;">  http://0.0.0.0:8088/taskdetails.jsp?jobid=job_1519724327083_0007&amp;tipid=task_1519724327083_0007_m_000020</p>

<p style="margin-left:0cm;">-----</p>

<p style="margin-left:0cm;">Diagnostic Messages for this Task:</p>

<p style="margin-left:0cm;">Error: java.io.IOException: org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=36, exceptions:</p>

<p style="margin-left:0cm;">Tue Feb 27 18:24:45 CST 2018, null, java.net.SocketTimeoutException: callTimeout=60000, callDuration=68489: row 'TC09F0534B145' on table 'LOG20180108' at region=LOG20180108,TC09F0534B145,1515254515969.dbd4f4e281c3c7d6d765352f6f990af7., hostname=node2,60020,1519721631359, seqNum=4326</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderCreationException(HiveIOExceptionHandlerChain.java:97)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderCreationException(HiveIOExceptionHandlerUtil.java:57)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:252)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getRecordReader(CombineHiveInputFormat.java:703)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.&lt;init&gt;(MapTask.java:169)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:432)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)</p>

<p style="margin-left:0cm;">    at java.security.AccessController.doPrivileged(Native Method)</p>

<p style="margin-left:0cm;">    at javax.security.auth.Subject.doAs(Subject.java:415)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1796)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)</p>

<p style="margin-left:0cm;">Caused by: org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=36, exceptions:</p>

<p style="margin-left:0cm;"><span style="color:#FF0000;">Tue Feb 27 18:24:45 CST 2018, null, java.net.SocketTimeoutException: callTimeout=60000, callDuration=68489: row 'TC09F0534B145' on table 'LOG20180108' at region=LOG20180108,TC09F0534B145,1515254515969.dbd4f4e281c3c7d6d765352f6f990af7., hostname=node2,60020,1519721631359, seqNum=4326</span></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.throwEnrichedException(RpcRetryingCallerWithReadReplicas.java:286)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:231)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:61)</p>

<p style="margin-left:0cm;">   at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:320)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:295)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:160)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.ClientScanner.&lt;init&gt;(ClientScanner.java:155)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:867)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.restart(TableRecordReaderImpl.java:91)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.initialize(TableRecordReaderImpl.java:169)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.mapreduce.TableRecordReader.initialize(TableRecordReader.java:134)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.mapreduce.TableInputFormatBase$1.initialize(TableInputFormatBase.java:211)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat.getRecordReader(HiveHBaseTableInputFormat.java:118)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:250)</p>

<p style="margin-left:0cm;">    ... 9 more</p>

<p style="margin-left:0cm;">Caused by: java.net.SocketTimeoutException: callTimeout=60000, callDuration=68489: row 'TC09F0534B145' on table 'LOG20180108' at region=LOG20180108,TC09F0534B145,1515254515969.dbd4f4e281c3c7d6d765352f6f990af7., hostname=node2,60020,1519721631359, seqNum=4326</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:159)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:80)</p>

<p style="margin-left:0cm;">    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)</p>

<p style="margin-left:0cm;">    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)</p>

<p style="margin-left:0cm;">    at java.lang.Thread.run(Thread.java:745)</p>

<p style="margin-left:0cm;">Caused by: org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region LOG20180108,TC09F0534B145,1515254515969.dbd4f4e281c3c7d6d765352f6f990af7. is not online on node2,60020,1519721631359</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2921)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:1053)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.regionserver.RSRpcServices.scan(RSRpcServices.java:2384)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:33648)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2170)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:109)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:185)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:165)</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</p>

<p style="margin-left:0cm;">    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)</p>

<p style="margin-left:0cm;">    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)</p>

<p style="margin-left:0cm;">    at java.lang.reflect.Constructor.newInstance(Constructor.java:526)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:95)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRemoteException(ProtobufUtil.java:327)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.ScannerCallable.openScanner(ScannerCallable.java:402)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:203)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:64)</p>

<p style="margin-left:0cm;">   at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:381)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:355)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:126)</p>

<p style="margin-left:0cm;">    ... 4 more</p>

<p style="margin-left:0cm;">Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.NotServingRegionException): org.apache.hadoop.hbase.NotServingRegionException: Region LOG20180108,TC09F0534B145,1515254515969.dbd4f4e281c3c7d6d765352f6f990af7. is not online on node2,60020,1519721631359</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2921)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:1053)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.regionserver.RSRpcServices.scan(RSRpcServices.java:2384)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:33648)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2170)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:109)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:185)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:165)</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1269)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:227)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:336)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:34094)</p>

<p style="margin-left:0cm;">    at org.apache.hadoop.hbase.client.ScannerCallable.openScanner(ScannerCallable.java:394)</p>

<p style="margin-left:0cm;">    ... 10 more</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask</p>

<p style="margin-left:0cm;">MapReduce Jobs Launched:</p>

<p style="margin-left:0cm;">Stage-Stage-1: Map: 22   Cumulative CPU: 73.65 sec   HDFS Read: 445399 HDFS Write: 2667943 FAIL</p>

<p style="margin-left:0cm;">Total MapReduce CPU Time Spent: 1 minutes 13 seconds 650 msec</p>

<p style="margin-left:0cm;">hive&gt;</p>

<p style="margin-left:0cm;">解决 办法：</p>

<p style="margin-left:0cm;">设置连接超时时间：</p>

<p style="margin-left:0cm;">hbase.rpc.timeout",20000</p>

<p style="margin-left:0cm;">hbase.client.operation.timeout",30000</p>

<p style="margin-left:0cm;">hbase.client.scanner.timeout.period",200000</p>

<p style="margin-left:0cm;"> </p>            </div>
                </div>