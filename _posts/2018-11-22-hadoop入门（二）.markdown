---
layout:     post
title:      hadoop入门（二）
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/a15020059230/article/details/72960214				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
1.HDFS shell<br>
    1.0查看帮助<br>
        hadoop fs -help &lt;cmd&gt;<br>
    1.1上传<br>
        hadoop fs -put &lt;linux上文件&gt; &lt;hdfs上的路径&gt;<br>
    1.2查看文件内容<br>
        hadoop fs -cat &lt;hdfs上的路径&gt;<br>
    1.3查看文件列表<br>
        hadoop fs -ls /<br>
    1.4下载文件<br>
        hadoop fs -get &lt;hdfs上的路径&gt; &lt;linux上文件&gt;<br><br>
2.使用java接口操作HDFS<br>
    见eclipse工程下的demo <br><br>
3.hadoop通信机制<br>
    不同进程之间的方法进行调用<br><br>
4.HDFS源码分析<br>
    FileSystem.get --&gt; 通过反射实例化了一个DistributedFileSystem --&gt; new DFSCilent()把他作为自己的成员变量<br>
    在DFSClient构造方法里面，调用了createNamenode，使用了RPC机制，得到了一个NameNode的代理对象，就可以和NameNode进行通信了<br>
    <br>
    FileSystem --&gt; DistributedFileSystem --&gt; DFSClient --&gt; NameNode的代理
            </div>
                </div>