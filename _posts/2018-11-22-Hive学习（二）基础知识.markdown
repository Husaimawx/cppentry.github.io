---
layout:     post
title:      Hive学习（二）基础知识
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/qq_41851454/article/details/79808392				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>目录</p><p>1、Hive 基本概念</p><p>1.1、Hive 简介 </p><p>1.1.1、什么是 Hive</p><p>1.1.2、为什么使用 Hive</p><p>1.1.3、Hive 特点</p><p>1.2、Hive 和 RDBMS 的对比</p><p>1.3、Hive 架构</p><p>1.4、Hive 的数据存储 </p><p><br></p><h1>1、Hive 基本概念</h1><h2>1.1、Hive 简介</h2><h3>1.1.1、什么是 Hive</h3><p>Hive 由 Facebook 实现并开源，是基于 Hadoop 的一个<span style="color:#ff0000;">数据仓库</span>工具，可以将<span style="color:#ff0000;">结构化</span>的数据<span style="color:#ff0000;">映射</span>为一张数据库表，并提供 <span style="color:#ff0000;">HQL(Hive SQL)</span>查询功能，底层数据是存储在 HDFS 上。Hive的本质是将 SQL 语句转换为 MapReduce 任务运行，使不熟悉 MapReduce 的用户很方便地利用 HQL 处理和计算 HDFS 上的结构化的数据，适用于离线的批量数据计算。<br></p><p></p><p><span style="color:#cc0000;">1、Hive 由 Facebook 实现并开源</span></p><p><span style="color:#cc0000;">2、是基于 Hadoop 的一个数据仓库工具，</span></p><p><span>	</span>1、hive是数据仓库， 用来存储数据</p><p><span>	</span>2、真实存储在Hive中的数据，底层时候存储在HDFS上的。</p><p><span>	</span>3、Hive是一个使用SQL语句计算存储在HDFS上的数据的，底层的执行引擎：MapReduce</p><p><span>	</span>hbase：  数据库</p><p><span>	</span>hive : 数据仓库</p><p><span>	</span>区别：</p><p><span>		</span>1、数据库，对于数据会做精细化的管理，具有事务的概念</p><p><span>		</span>     数据仓库，存储数据的格式就类似打包，没有事务的概念</p><span>		</span>2、操作方式的区别：<br><span>		</span>     数据库：NoSQL语法  put get scan delele<br><p><span>		</span>     数据仓库: SQL方言 Hive的SQL ===  HQL     hibernate:HQL</p><p>                3、用途的区别：</p><p><span>		</span>   数据库：OLTP  联机事务处理   增删改</p><p><span>		</span>   数据仓库： OLAP   联机分析处理   查询</p><p><span>		</span>   hive是数据仓库，它根本就不支持 update和delete   但是支持insert</p><p><span>		</span>4、模式上的区别</p><p><span>		</span>    数据库： 写模式    hbase无严格模式 ： 仅有的模式校验只有 表名和列簇的名称</p><p><span>		</span>    数据仓库：  读模式</p><p><span style="color:#cc0000;">3、可以将结构化的数据映射为一张数据库表，</span></p><p><span>	</span>你就把存储在HDFS上的数据，看做是一张二维表格</p><span>	</span>ORM ：对象映射模型<br><span>		</span>mysql<span>		</span>class<br><span>		</span>student<span>		</span>Student<br><span>		</span>id<span>		</span>id<br><span>		</span>name<span>		</span>name<br><p><span>		</span>sex<span>		</span>sex</p><p><span>		</span>一条记录<span>	</span>一个实例对象</p><p><span>	</span>mybatis : 半orm    hibernate： 全orm</p><span>	</span>HDFS<span>			</span>mysql<br><p><span>	</span>student.txt<span>		</span>student</p><p><span>	</span>一行记录<span>		</span>一条记录</p><span>	</span>第一个属性<span>		</span>第一个字段<br><span>	</span>第二个属性<span>		</span>第二个字段<br><p><span>	</span>.....<span>			</span>....</p><p><span>	</span>咱们完全可以把存储在HDFS上的结构化的数据看做是一张二维表格</p><p><span style="color:#cc0000;">4、并提供 HQL(Hive SQL)查询功能，</span></p><p><span>	</span>使用SQL语句进行操作</p><p><span style="color:#cc0000;">5、底层数据是存储在 HDFS 上。</span></p><p><span>	</span>Hive是数据仓库，但是本身不存储数据， 仅仅只是用来存储描述存储在HDFS上的数据</p><p><span>	</span>为了SQL语法能够顺利执行，肯定需要把存储在HDFS上的数据，进行一番抽象</p><p><span>	</span>并且把抽象出来数据进行存储。 Hive就存储这份数据   就叫做 元数据</p><p><span>	</span>Hive的元数据到底是什么？</p><p><span>	</span>Hive的元数据，就是描述存储在HDFS上的数据的 数据，  Hive数据仓库的元数据，是一定不能丢失的。</p><p><span>	</span>Hive的元数据，是借用RDBMS进行存储。 最常用的就是 MySQL</p><p><span>	</span>任何地方提到元数据，，都是同一个概念，， 都是指  描述  数据的  数据</p><p><span>	</span>HDFS 集群中会存储非常多的大文件的很多数据块，</p><p><span>	</span>namenode中就存储了 “描述了存储在HDFS上的数据被切分成多少个数据块的数据”</p><p><span style="color:#cc0000;">6、Hive的本质是将 SQL 语句转换为 MapReduce 任务运行，</span></p><p><span>	</span>Hive的本质作用就是  把 用户编写 SQL语句 转换成hadoop能够执行的 maprdcue分布式计算程序去执行</p><p><span>	</span>Hive的SQL语句，你就应该把它看做是一个MapReduce程序</p><p><span>	</span>但是事实上，一个SQL有可能没法使用一个MapReduce去实现。</p><p><span>	</span>Hive的作用：就是把SQL转换成MapReduce</p><p><span>	</span>数据仓库  +  工具</p><p><span style="color:#cc0000;">7、使不熟悉 MapReduce 的用户很方便地利用 HQL 处理和计算 HDFS 上的结构化的数据，适用于离线的批量数据计算。</span></p><p><br></p><p>数据仓库之父比尔·恩门（Bill Inmon）在 1991 年出版的“Building the Data Warehouse”（《建立数据仓库》）一书中所提出的定义被广泛接受——数据仓库（Data Warehouse）是一个面向主题的（Subject Oriented）、集成的（Integrated）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策(Decision Making Support)。<br></p><p>Hive 依赖于 HDFS 存储数据，Hive 将 HQL 转换成 MapReduce 执行</p><p>所以说 Hive 是基于 Hadoop 的一个数据仓库工具，实质就是一款基于 HDFS 的 MapReduce计算框架，对存储在 HDFS 中的数据进行分析和管理<br></p><p><img src="https://img-blog.csdn.net/20180403201110402?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxODUxNDU0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><h3>1.1.2、为什么使用 Hive</h3><p>直接使用 MapReduce 所面临的问题：</p><p>    人员学习成本太高</p><p>    项目周期要求太短</p><p>    MapReduce 实现复杂查询逻辑开发难度太大</p><p>为什么要使用 Hive：</p><p>    更友好的接口：操作接口采用类 SQL 的语法，提供快速开发的能力</p><p>    更低的学习成本：避免了写 MapReduce，减少开发人员的学习成本</p><p>    更好的扩展性：可自由扩展集群规模而无需重启服务，还支持用户自定义函数<br></p><h3>1.1.3、Hive 特点</h3><p><span style="color:#ff0000;">优点：</span></p><p>1、<span style="color:#ff0000;">可扩展性,横向扩展</span>，Hive 可以自由的扩展集群的规模，一般情况下不需要重启服务</p><p>    横向扩展：通过分担压力的方式扩展集群的规模</p><p>    纵向扩展：一台服务器cpu i7-6700k 4核心8线程，8核心16线程，内存64G =&gt; 128G</p><p>2、<span style="color:#ff0000;">延展性</span>，Hive 支持自定义函数，用户可以根据自己的需求来实现自己的函数</p><p>3、<span style="color:#ff0000;">良好的容错性</span>，可以保障即使有节点出现问题，SQL 语句仍可完成执行<br></p><p><span style="color:#ff0000;">缺点：</span></p><p>1、<span style="color:#ff0000;">Hive 不支持记录级别的增删改操作</span>，但是用户可以通过查询生成新表或者将查询结果导入到文件中（当前选择的 hive-2.3.2 的版本支持记录级别的插入操作）</p><p>2、<span style="color:#ff0000;">Hive 的查询延时很严重</span>，因为 MapReduce Job 的启动过程消耗很长时间，所以不能用在交互查询系统中。</p><p>3、<span style="color:#ff0000;">Hive 不支持事务</span>（因为不没有增删改，所以主要用来做 OLAP（联机分析处理），而不是 OLTP（联机事务处理），这就是数据处理的两大级别）。<br></p><h2>1.2、Hive 和 RDBMS 的对比</h2><p><img src="https://img-blog.csdn.net/20180403201442462?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxODUxNDU0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p>总结：Hive 具有 SQL 数据库的外表，但应用场景完全不同，<span style="color:#ff0000;">Hive 只适合用来做海量离线数据统计分析，也就是数据仓库。</span><br></p><h2>1.3、Hive 架构</h2><p><img src="https://img-blog.csdn.net/20180403201758322?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxODUxNDU0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><h4>基本组成</h4><h5>一、用户接口</h5><p>    CLI，Shell 终端命令行（Command Line Interface），采用交互形式使用 Hive 命令行与 Hive进行交互，最常用（学习，调试，生产）    </p><p>    JDBC/ODBC，是 Hive 的基于 JDBC 操作提供的客户端，用户（开发员，运维人员）通过这连接至 Hive server 服务</p><p>    Web UI，通过浏览器访问 Hive<br></p><h5>二、Thrift Server</h5><p>Thrift 是 Facebook 开发的一个软件框架，可以用来进行可扩展且跨语言的服务的开发，Hive 集成了该服务，能让不同的编程语言调用 Hive 的接口</p><h5>三、元数据存储</h5><p>元数据，通俗的讲，就是存储在 Hive 中的数据的描述信息。</p><p>Hive 中的元数据通常包括：表的名字，表的列和分区及其属性，表的属性（内部表和外部表），表的数据所在目录</p><p>Metastore 默认存在自带的 Derby 数据库中。缺点就是不适合多用户操作，并且数据存储目录不固定。数据库跟着 Hive 走，极度不方便管理</p><p>解决方案：通常存我们自己创建的 MySQL 库（本地 或 远程）</p><p>Hive 和 MySQL 之间通过 MetaStore 服务交互<br></p><h5>四、Driver：编译器（Compiler），优化器（Optimizer），执行器（Executor）</h5><p>Driver 组件完成 HQL 查询语句从词法分析，语法分析，编译，优化，以及生成逻辑执行计划的生成。生成的逻辑执行计划存储在 HDFS 中，并随后由 MapReduce 调用执行</p><p>Hive 的核心是驱动引擎， 驱动引擎由四部分组成：</p><p>(1) 解释器：解释器的作用是将 HiveSQL 语句转换为抽象语法树（AST）</p><p>(2) 编译器：编译器是将语法树编译为逻辑执行计划</p><p>(3) 优化器：优化器是对逻辑执行计划进行优化</p><p>(4) 执行器：执行器是调用底层的运行框架执行逻辑执行计划<br></p><h5>五、执行流程</h5><p>HiveQL 通过命令行或者客户端提交，经过 Compiler 编译器，运用 MetaStore 中的元数据进行类型检测和语法分析，生成一个逻辑方案(Logical Plan)，然后通过的优化处理，产生一个 MapReduce 任务。<br></p><h2>1.4、Hive 的数据存储</h2><p>1、Hive 的存储结构包括<span style="color:#ff0000;">数据库、表、视图、分区和表数据</span>等。数据库，表，分区等等都对应 HDFS 上的一个目录。表数据对应 HDFS 对应目录下的文件。</p><p>2、Hive 中所有的数据都存储在 HDFS 中，没有专门的数据存储格式，因为 Hive 是<span style="color:#ff0000;">读模式</span>（Schema On Read），可支持 TextFile，SequenceFile，RCFile 或者自定义格式等</p><p>3、 只需要在创建表的时候告诉 Hive 数据中的<span style="color:#ff0000;">列分隔符</span>和<span style="color:#ff0000;">行分隔符</span>，Hive 就可以解析数据</p><p>Hive 的默认列分隔符：控制符 Ctrl + A，\x01</p><p>Hive 的默认行分隔符：换行符 \n</p><p>4、Hive 中包含以下数据模型：</p><p><span style="color:#ff0000;">database</span>：在 HDFS 中表现为${hive.metastore.warehouse.dir}目录下一个文件夹</p><p><span style="color:#ff0000;">table</span>：在 HDFS 中表现所属 database 目录下一个文件夹<br></p><p><span style="color:#ff0000;">external table</span>：与 table 类似，不过其数据存放位置可以指定任意 HDFS 目录路径</p><p><span style="color:#ff0000;">partition</span>：在 HDFS 中表现为 table 目录下的子目录</p><p><span style="color:#ff0000;">bucket</span>：在 HDFS 中表现为同一个表目录或者分区目录下根据某个字段的值进行 hash 散列之后的多个文件</p><p><span style="color:#ff0000;">view</span>：与传统数据库类似，只读，基于基本表创建<br></p><p>5、Hive 的元数据存储在 RDBMS 中，除元数据外的其它所有数据都基于 HDFS 存储。默认情况下，Hive 元数据保存在内嵌的 Derby 数据库中，只能允许一个会话连接，只适合简单的测试。实际生产环境中不适用，为了支持多用户会话，则需要一个独立的元数据库，使用MySQL 作为元数据库，Hive 内部对 MySQL 提供了很好的支持。<br></p><p>6、Hive 中的表分为<span style="color:#ff0000;">内部表、外部表、分区表和 Bucket 表</span><br></p><p><span style="color:#6633ff;">内部表和外部表的区别：</span></p><p>    删除内部表，删除表元数据和数据</p><p>    删除外部表，删除元数据，不删除数据</p><p><span style="color:#6633ff;">内部表和外部表的使用选择：</span></p><p>    大多数情况，他们的区别不明显，如果数据的所有处理都在 Hive 中进行，那么倾向于选择内部表，但是如果 Hive 和其他工具要针对相同的数据集进行处理，外部表更合适。</p><p>    使用外部表访问存储在 HDFS 上的初始数据，然后通过 Hive 转换数据并存到内部表中</p><p>    使用外部表的场景是针对一个数据集有多个不同的 Schema<br></p><p>通过外部表和内部表的区别和使用选择的对比可以看出来，hive 其实仅仅只是对存储在HDFS 上的数据提供了一种新的抽象。而不是管理存储在 HDFS 上的数据。所以不管创建内部表还是外部表，都可以对 hive 表的数据存储目录中的数据进行增删操作。<br></p><p><span style="color:#6633ff;">分区表和分桶表的区别：</span></p><p>Hive 数据表可以根据某些字段进行分区操作，细化数据管理，可以让部分查询更快。同时表和分区也可以进一步被划分为 Buckets，分桶表的原理和 MapReduce 编程中的HashPartitioner 的原理类似</p><p>分区和分桶都是细化数据管理，但是分区表是手动添加区分，由于 Hive 是读模式，所以对添加进分区的数据不做模式校验，分桶表中的数据是按照某些分桶字段进行 hash 散列形成的多个文件，所以数据的准确性也高很多<br></p><p><br></p><p><br></p>            </div>
                </div>