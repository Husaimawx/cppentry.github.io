---
layout:     post
title:      Flume的基本使用介绍
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<h1><span style="font-size:18px;">一、Flume概述</span></h1>
<p><span style="font-size:18px;">Flume是一个分布式的、高可靠的、可用的一个服务，用于收集、聚合、移动大量数据。它有简单、灵活的结构基于数据流，具有健壮性和容错性，它能够使用简单的、可扩展的数据模型用于在线实时分析应用。结构图如下：</span></p>
<p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20171113100348627?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvV2luZ185Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p>
<p><span style="font-size:18px;"><br></span></p>
<p><span style="font-size:18px;">webserver(源端)  ===&gt;  flume   ===&gt; hdfs(目的地)，一个Flume对应一个agent，agent里包含Source、channel、sink，所以只需要配置agent，就可以完成各项配置，也增强了Flume的管理性。<br></span></p>
<p><span style="font-size:18px;">设计目标为：可靠性、扩展性、管理性。</span></p>
<h1><span style="font-size:18px;">二、Flume的架构和核心组件</span></h1>
<h2><span style="font-size:18px;">2.1 三个核心组件</span></h2>
<p><span style="font-size:18px;">1.source（输入）</span></p>
<p><span style="font-size:18px;">source相当于数据的输入，source的种类很多中，像Avro source、exec source、JMS source等，你也可以自定义source，这根据你不同的需要去官网查看对应的配置。</span></p>
<p><span style="font-size:18px;">2.channel（收集）</span></p>
<p><span style="font-size:18px;">主要用于数据的收集，相当于一个缓存池一样，可以指定大小，先把数据积攒起来，再一起处理。种类有memory channel、File channel、 kafka channel、 file channel等，也可以自定义。</span></p>
<p><span style="font-size:18px;">3.sink（输出）</span></p>
<p><span style="font-size:18px;">主要用于将收集好的数据对目的地进行输出，主要有HDFS sink，HIVE sink，Logger sink，Avro sink， Hbase sink等，也可以自定义sink。</span></p>
<h2><span style="font-size:18px;">2.2 Flume的设置方式</span></h2>
<p><span style="font-size:18px;">Flume可以进行串联和并联，很高的扩展性，下面来介绍几种Flume的设置方式。</span></p>
<p><span style="font-size:18px;">1.串联：</span></p>
<p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20171113110133554?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvV2luZ185Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p>
<p><span style="font-size:18px;">2.整合使用（Consolidation），多个agent合并输出到某个agent：</span></p>
<p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20171113110242222?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvV2luZ185Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p>
<p><span style="font-size:18px;">3.多路复用流（multiplexing the flow），一个agent多个sink输出：</span></p>
<p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20171113110248943?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvV2luZ185Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p>
<h1><span style="font-size:18px;">三、Flume安装与部署</span></h1>
<h2><span style="font-size:18px;">3.1 Flume安装前置条件</span></h2>
<p><span style="font-size:18px;">1. Java内存环境1.7 及 以上</span></p>
<p><span style="font-size:18px;">2.要有足够内存</span></p>
<p><span style="font-size:18px;">3. 足够的磁盘空间</span></p>
<p><span style="font-size:18px;">4. 有目录的权限</span></p>
<h2><span style="font-size:18px;">3.2 安装JDK</span></h2>
<p><span style="font-size:18px;">下载，解压到~/app，再将java配置系统环境变量中: ~/.bash_profile，设置如下：<br><span></span>export JAVA_HOME=/home/hadoop/app/jdk1.8.0_144<br><span></span>export PATH=$JAVA_HOME/bin:$PATH<br>
配置好后，source下让其配置生效，最后检测: java  -version。<br></span></p>
<h2><span style="font-size:18px;">3.3 安装FLUME</span></h2>
<p><span style="font-size:18px;">下载，解压到~/app，再将java配置系统环境变量中: ~/.bash_profile<span></span><br><span></span>export FLUME_HOME=/home/hadoop/app/apache-flume-1.6.0-cdh5.7.0-bin<br><span></span>export PATH=$FLUME_HOME/bin:$PATH<br>
配置好后，source下让其配置生效，其中主要的是flume-env.sh的配置：</span></p>
<p><span style="font-size:18px;"><span></span>export JAVA_HOME=/home/hadoop/app/jdk1.8.0_144<br>
最后检测: flume-ng version。<br></span></p>
<h2><span style="font-size:18px;">3.4 使用</span></h2>
<p><span style="font-size:18px;">使用Flume的关键就是写配置文件<br>
A） 配置Source<br>
B） 配置Channel<br>
C） 配置Sink<br>
D） 把以上三个组件串起来<br></span></p>
<p><span style="font-size:18px;">接下来我就用三个Demo来进行展示。</span></p>
<h1><span style="font-size:18px;">四、Flume实战Demo</span></h1>
<h2><span style="font-size:18px;">4-1 从指定网络端口采集数据输出到控制台</span></h2>
<p><span style="font-size:18px;">在Flume的conf目录下生成一个配置文件，内容如下</span></p>
<p><span style="font-size:18px;"></span></p>
<pre><code class="language-html"><span style="font-size:18px;">a1: agent名称 
r1: source的名称
k1: sink的名称
c1: channel的名称

# Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
a1.sources.r1.type = netcat
a1.sources.r1.bind = hadoop000
a1.sources.r1.port = 44444

# Describe the sink
a1.sinks.k1.type = logger

# Use a channel which buffers events in memory
a1.channels.c1.type = memory

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1</span></code></pre><span style="font-size:18px;"> 采用到source的netcat类型，意思就是监听hadoop000 的44444端口，把文本的每行内容转成一个event，就相当于一个日志输出单元。channel试着为memory，采用内存进行缓存，sink的type设置为logger，意思是sink的形式为日志形式，并且是Info的等级。后面两句配置语句，就是将source、channel、sink配置起来，注意的是一个source可以设置多个channel，而一个channel只能对应一个sink，和然后启动agent，命令如下：</span>
<p></p>
<p><span style="font-size:18px;"></span></p>
<pre><code class="language-html"><span style="font-size:18px;">flume-ng agent \
--name a1  \
--conf $FLUME_HOME/conf  \
--conf-file $FLUME_HOME/conf/example.conf \
-Dflume.root.logger=INFO,console</span></code></pre><span style="font-size:18px;">使用telnet进行测试： telnet hadoop000 44444。</span>
<p></p>
<p><span style="font-size:18px;">测试结果如下：</span></p>
<p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20171113110139422?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvV2luZ185Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p>
<p><span style="font-size:18px;">其中要注意的是：<br>
Event: { headers:{} body: 68 65 6C 6C 6F 0D hello. }<br>
Event是FLume数据传输的基本单元<br>
Event =  可选的header + byte array<br></span></p>
<h2><span style="font-size:18px;">4.2 监控一个文件实时采集新增的数据<span style="font-size:18px;">输出</span>到控制台</span></h2>
<p><span style="font-size:18px;">Agent选型：exec source + memory channel + logger sink，选择exec source就是运行unix指定的命令行来处理不断的数据，以此来生产数据。本demo就是实时监控data.log日志内的内容。<br></span></p>
<p><span style="font-size:18px;">配置文件如下：</span></p>
<p></p>
<pre><code class="language-html"><span style="font-size:18px;"># Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /home/hadoop/data/data.log
a1.sources.r1.shell = /bin/sh -c

# Describe the sink
a1.sinks.k1.type = logger

# Use a channel which buffers events in memory
a1.channels.c1.type = memory

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1</span></code></pre><span style="font-size:18px;">此处用到的source command也就是执行对data.log进行数据的读取命令，启动agent命令如下：</span>
<p></p>
<p><span style="font-size:18px;"></span></p>
<pre><code class="language-html"><span style="font-size:18px;">flume-ng agent \
--name a1  \
--conf $FLUME_HOME/conf  \
--conf-file $FLUME_HOME/conf/exec-memory-logger.conf \
-Dflume.root.logger=INFO,console
</span></code></pre>
<p></p>
<h2><span style="font-size:18px;">4.3 将A服务器上的日志实时采集到B服务器上</span></h2>
<p><span style="font-size:18px;">技术选型：<br><span></span>exec source + memory channel + avro sink<br><span></span>avro source + memory channel + logger sink</span><br></p>
<p><span style="font-size:18px;">流程图：</span></p>
<p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20171113115511375?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvV2luZ185Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p>
<p><span style="font-size:18px;">注意跨节点的数据一般都采用到的是avro 类型。</span></p>
<p><span style="font-size:18px;">配置文件exec-memory-avro.conf：</span></p>
<p></p>
<pre><code class="language-html"><span style="font-size:18px;">exec-memory-avro.sources = exec-source
exec-memory-avro.sinks = avro-sink
exec-memory-avro.channels = memory-channel

exec-memory-avro.sources.exec-source.type = exec
exec-memory-avro.sources.exec-source.command = tail -F /home/hadoop/data/data.log
exec-memory-avro.sources.exec-source.shell = /bin/sh -c

exec-memory-avro.sinks.avro-sink.type = avro
exec-memory-avro.sinks.avro-sink.hostname = hadoop000
exec-memory-avro.sinks.avro-sink.port = 44444

exec-memory-avro.channels.memory-channel.type = memory

exec-memory-avro.sources.exec-source.channels = memory-channel
exec-memory-avro.sinks.avro-sink.channel = memory-channel
</span></code></pre><span style="font-size:18px;">配置文件avro-memory-logger.conf：</span>
<p></p>
<pre><code class="language-html"><span style="font-size:18px;">avro-memory-logger.sources = avro-source
avro-memory-logger.sinks = logger-sink
avro-memory-logger.channels = memory-channel

avro-memory-logger.sources.avro-source.type = avro
avro-memory-logger.sources.avro-source.bind = hadoop000
avro-memory-logger.sources.avro-source.port = 44444

avro-memory-logger.sinks.logger-sink.type = logger

avro-memory-logger.channels.memory-channel.type = memory

avro-memory-logger.sources.avro-source.channels = memory-channel
avro-memory-logger.sinks.logger-sink.channel = memory-channel

</span></code></pre>
<p><span style="font-size:18px;">先启动avro-memory-logger，命令如下：</span></p>
<p><span style="font-size:18px;"></span></p>
<pre><code class="language-html"><span style="font-size:18px;">flume-ng agent \
--name avro-memory-logger  \
--conf $FLUME_HOME/conf  \
--conf-file $FLUME_HOME/conf/avro-memory-logger.conf \
-Dflume.root.logger=INFO,console</span></code></pre><span style="font-size:18px;">再启动exec-memory-avro，命令如下：</span>
<p></p>
<p><span style="font-size:18px;"></span></p>
<pre><code class="language-html"><span style="font-size:18px;">flume-ng agent \
--name exec-memory-avro  \
--conf $FLUME_HOME/conf  \
--conf-file $FLUME_HOME/conf/exec-memory-avro.conf \
-Dflume.root.logger=INFO,console</span></code></pre><span style="font-size:18px;">效果基本就是在data.log进行输入，然后会在avro-memory-logger这个配置文件的agent里进行控制台的输出。</span>
<p></p>
<br><br><p></p>
<p><br></p>
<br><p><span style="font-size:18px;"><br></span></p>
<p><br></p>
            </div>
                </div>