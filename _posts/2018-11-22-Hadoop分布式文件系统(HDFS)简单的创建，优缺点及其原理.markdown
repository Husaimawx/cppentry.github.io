---
layout:     post
title:      Hadoop分布式文件系统(HDFS)简单的创建，优缺点及其原理
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h1>一：HDFS简单的创建</h1><p>在HDFS中创建一下目录：</p><span>	</span><span style="background-color:rgb(255,255,255);"><span style="color:#6600cc;">hdfs dfs -mkdir /user<br><span>	</span>hdfs dfs -mkdir /user/wjw</span></span><br><span>	</span>可以通过hdfs|hadoop fs -ls / 可以查看目录是否创建成功<br><br><br>在当前用户桌面创建文件wjw.txt。<span>	</span><br><span>	</span><span style="color:#6600cc;">touch wjw.txt</span><br><span>	</span>在wjw.txt中随便添加一下内容,保证有东西就可以了<br><br><br>将wjw.txt这个文件上传到hdfs中<br><span>	</span><span style="color:#6600cc;">hdfs dfs -put ./wjw.txt /user/wjw/</span><br><br><br>查看文件是否上传成功<br><span>	</span><span style="color:#6600cc;">hdfs dfs -ls /user/wjw/</span><br><br><br>查看文件中的内容<br><span>	</span><span style="color:#6600cc;">hdfs dfs -cat /user/wjw/wjw.txt</span><br><br><br>删除hdfs中的文件<br><span>	</span><span style="color:#6600cc;">hdfs dfs -rm /user/wjw/wjw.txt</span><br><br><h1>二：HDFS的优缺点</h1><p><strong>HDFS的优点：</strong></p><p></p><h3 style="line-height:1.5;color:rgb(0,0,0);text-align:left;background-color:rgb(255,255,255);"><span style="font-weight:normal;"><span style="font-family:SimSun;font-size:16px;">1.支持超大文件</span></span></h3><p style="color:rgb(0,0,0);text-align:left;background-color:rgb(255,255,255);"><span style="font-family:SimSun;font-size:16px;">    支持超大文件。超大文件在这里指的是几百<span>M</span><span>，几百</span><span>GB</span><span>，甚至几</span><span>TB</span><span>大小的文件。一般来说</span><span>hadoop</span><span>的文件系统会存储</span><span>TB</span><span>级别或者</span><span>PB</span><span>级别的数据。所以在企业的应用中，数据节点有可能有上千个。</span></span></p><p style="text-align:left;background-color:rgb(255,255,255);"><span style="font-family:SimSun;font-size:16px;"><span></span></span></p><p style="background-color:rgb(255,255,255);"><span style="font-size:16px;"><span style="font-family:SimSun;"><span style="color:#333333;">2、流式的访问数据</span></span></span></p><p style="background-color:rgb(255,255,255);"><span style="font-size:16px;"><span style="font-family:SimSun;"><span style="color:#333333;">    HDFS的设计建立在“一次写入、多次读写”任务的基础上。这意味着一个数据集一旦由数据源生成，就会被复制分发到不同的存储节点中，然后响应各种各样的数据分析任务请求。在多数情况下，分析任务都会涉及数据集中的大部分数据，也就是说，对HDFS来说，请求读取整个数据集要比读取一条记录更加高效。</span></span></span></p><p style="background-color:rgb(255,255,255);"><span style="font-size:16px;"><span style="font-family:SimSun;"><span style="color:#333333;"> 3、运行于廉价的商用机器集群上</span></span></span></p><p style="background-color:rgb(255,255,255);"><span style="font-size:16px;"><span style="font-family:SimSun;"><span style="color:#333333;">     Hadoop设计对应急需求比较低，只须运行在低廉的商用硬件集群上，而无需在昂贵的高可用性机器上。廉价的商用机也就意味着大型集群中出现节点故障情况的概率非常高。HDFS遇到了上述故障时，被设计成能够继续运行且不让用户察觉到明显的中断。</span></span></span></p><h3 style="line-height:1.5;text-align:left;background-color:rgb(255,255,255);"><span style="font-weight:normal;"><span style="font-size:16px;"><span style="font-family:SimSun;"><span style="color:#333333;">4.检测和快速应对硬件故障（高容错性）</span></span></span></span></h3><p style="text-align:left;background-color:rgb(255,255,255);"><span style="font-size:16px;"><span style="font-family:SimSun;"><span style="color:#333333;">    在集群的环境中，硬件故障是常见的问题。因为有上千台服务器连接在一起，这样会导致高故障率。因此故障检测和自动恢复是hdfs文件系统的一个设计目标。</span></span></span></p><br><p><strong><span style="font-size:16px;">HDFS的缺点：</span></strong></p><p></p><p style="background-color:rgb(255,255,255);"><span style="font-family:SimSun;font-size:16px;color:#333333;">1、不适合低延迟数据访问</span></p><p style="background-color:rgb(255,255,255);"><span style="font-family:SimSun;font-size:16px;color:#333333;">    如果要处理一些用户要求时间比较短的低延迟应用请求，则HDFS不适合。HDFS是为了处理大型数据集分析任务的，主要是为达到高的数据吞吐量而设计的，这就可能要求以高延迟作为代价。</span></p><p style="background-color:rgb(255,255,255);"><span style="font-family:SimSun;font-size:16px;color:#333333;">     <span>改进策略</span>：</span></p><p style="background-color:rgb(255,255,255);"><span style="font-family:SimSun;font-size:16px;color:#333333;">     对于那些有低延时要求的应用程序，HBase是一个更好的选择，通过上层数据管理项目尽可能地弥补这个不足。在性能上有了很大的提升，它的口号是goes real time。使用缓存或多个master设计可以降低Clinet的数据请求压力，以减少延时。</span></p><p style="background-color:rgb(255,255,255);"><span style="font-family:SimSun;font-size:16px;color:#333333;">2、无法高效存储大量的小文件</span></p><p style="background-color:rgb(255,255,255);"><span style="font-family:SimSun;font-size:16px;color:#333333;">      因为NameNode把文件系统的元数据放置在内存中，所有文件系统所能容纳的文件数目是由NameNode的内存大小来决定。还有一个问题就是，因为MapTask的数量是由Splits来决定的，所以用MR处理大量的小文件时，就会产生过多的MapTask，线程管理开销将会增加作业时间。当Hadoop处理很多小文件(文件大小小于HDFS中Block大小)的时候，由于FileInputFormat不会对小文件进行划分，所以每一个小文件都会被当做一个Split并分配一个Map任务，导致效率底下。</span></p><p style="background-color:rgb(255,255,255);"><span style="font-family:SimSun;font-size:16px;color:#333333;">     例如：一个1G的文件，会被划分成16个64MB的Split，并分配16个Map任务处理，而10000个100Kb的文件会被10000个Map任务处理。</span></p><p style="background-color:rgb(255,255,255);"><span style="font-family:SimSun;font-size:16px;color:#333333;">      <span>改进策略</span>：</span></p><p style="background-color:rgb(255,255,255);"><span style="font-family:SimSun;font-size:16px;color:#333333;">      要想让HDFS能处理好小文件，有不少方法。利用SequenceFile、MapFile、Har等方式归档小文件，这个方法的原理就是把小文件归档起来管理，HBase就是基于此的。</span></p><p style="background-color:rgb(255,255,255);"><span style="font-family:SimSun;font-size:16px;color:#333333;">3、不支持多用户写入及任意修改文件</span></p><p style="background-color:rgb(255,255,255);"><span style="font-family:SimSun;font-size:16px;color:#333333;">      在HDFS的一个文件中只有一个写入者，而且写操作只能在文件末尾完成，即只能执行追加操作（append），目前HDFS还不支持多个用户对同一文件的写操作，以及在文件任意位置进行修改。</span></p><h1><span style="font-family:SimSun;font-size:32px;color:#333333;"></span></h1><h1>三：HDFS的原理</h1><p><span style="font-size:16px;"><span style="font-family:SimSun;color:#333333;">HDFS上的文件被划分为块大小的多个分块，默认块大小为64MB。当用户通过hdfs命令要求存储文件时，系统会将文件切割成多个块（block）,每个块的大小为64MB。</span></span></p><span style="font-size:16px;"><br><br><span style="font-family:SimSun;">块的副本策略<br><span>	</span>一个文件块默认会有3个副本，可以在Hadoop配置文件中修改块的副本数，文本块损坏时，NameNode会自动寻找其它位置上DataNode上的副本来恢复数据，总之，要求维持3份副本。<br></span></span><span style="font-family:SimSun;"><br><br><span style="font-size:16px;">机架感应：<br><span>	</span>hdfs具备机架感应功能，第一份副本放在Rack（支架）机架的节点上，第二个副本放在同机架Rack的不同节点上，第三个副本放在不同机架的不同节点上。这样设计的好处是尽可能的防止数据丢失。<br><br><br>HDFS的块大小比磁盘块（512字节）大，其目的是为了节省寻址时间。比如寻址时间为10ms,而传输速率为100MB/s, 为了让寻址时间只占我们的传输时间1%，那么我们的块大小应该设置为100MB,实际默认是64MB。很多情况下，HDFS使用128MB为块大小。随着速率的提升，并不是块大小越大越好，因为块过大，MapReduce中，map的时候通常一次只能处理一个块中的数据。如果任务数量大小，反而会影响作业的速度。<br><br><br>NameNode：是HDFS的守护进程，用来管理文件系统的命名空间，负责记录文件是如何分割成数据块，以及这些数据块分别被存储到那些数据节点上，但它并不永久保存块的位置信息，因为这些信息在系统启动时由数据节点重建。它的主要功能是对内存及IO进行集中管理。<br><br><br>DataNode: 文件系统的工作节点，根据需要存储和检索数据块， 并且定期向namenode发送他们所存储的块的列表。<br><br><br>Secondary NomeNode: 辅助后台程序，与NameNode进行通信，以便定期保存HDFS元数据的快照。<br><br><br>NameNode和DataNode是HDFS的两个主要组件。其中，元数据存储在NameNode上，而数据存储在DataNode的集群上。 NameNode不仅要管理存储在HDFS上内容的元数据，而且要记录一些事情，比如哪些节点是集群的一部分，某个文件有几份副本等。它还要决定当集群的节点宕机或者数据副本丢失的时候系统需要做什么。<br>存储在HDFS上的每份数据片有多份副本(replica)保存在不同的服务器上。在本质上，NameNode是HDFS的Master(主服务器)，DataNode是Slave(从服务器)。</span></span>            </div>
                </div>