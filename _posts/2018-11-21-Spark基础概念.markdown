---
layout:     post
title:      Spark基础概念
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h2>此文章打算梳理之前项目所用过的Spark的一些基础概念。</h2>

<p>Spark是一个计算框架</p>

<p>Hadoop是包含计算框架MapReducehe分布式文件系统HDFS。</p>

<p>Spark是基于内存的</p>

<h1><strong>Spark：</strong></h1>

<p style="margin-left:0pt;">Spark有四大组件包括Spark Streaming、Spark SQL、Spark MLlib和Spark GraphX。</p>

<p style="margin-left:0pt;">四大组件的应用场景可以参考这篇文章：<a href="http://f.dataguru.cn/thread-593630-1-1.html" rel="nofollow">http://f.dataguru.cn/thread-593630-1-1.html</a></p>

<p style="margin-left:0pt;">使用的Spark的部署模式为<strong>独立模式</strong>，即不依赖其它的资源管理系统。</p>

<p style="margin-left:0pt;">Spark的三种部署模式可以参考这篇文章：<a href="https://wenku.baidu.com/view/284ba2ec227916888586d78d.html" rel="nofollow">https://wenku.baidu.com/view/284ba2ec227916888586d78d.html</a></p>

<h3 style="margin-left:0pt;">Spark的Application、Driver节点、Worker节点、Executor</h3>

<p>（1）Application就是你写的代码。</p>

<p>（2）Driver节点上的Driver程序运行的是main函数</p>

<p>（3）Worker节点就是工作节点，上面运行Executor进程。</p>

<p>（4）Executor进程负责运行Task。</p>

<h3 style="margin-left:0pt;">Spark的<strong><strong>job、state、task</strong></strong></h3>

<p><img alt="" class="has" height="403" src="https://img-blog.csdn.net/20180728190627307?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NTRE5yaG1t/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="645"></p>

<p><img alt="" class="has" height="114" src="https://img-blog.csdn.net/20180728190150939?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NTRE5yaG1t/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="770"></p>

<p>如这里的collect()算子就是一个action。</p>

<h3><strong>如何划分stage？</strong></h3>

<p><img alt="" class="has" height="479" src="https://img-blog.csdn.net/20180728191008856?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NTRE5yaG1t/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="649"></p>

<p style="margin-left:0pt;"><strong>我的理解是</strong>：<strong><span style="color:#ff0000;"><strong>如果有n个shuffle过程，那就有n+1个stage</strong></span></strong>。</p>

<p style="margin-left:0pt;"><strong>参考文章</strong>：<a href="http://litaotao.github.io/spark-questions-concepts" rel="nofollow">http://litaotao.github.io/spark-questions-concepts</a></p>

<h3 style="margin-left:0pt;">闭包：</h3>

<p style="margin-left:0pt;"><img alt="" class="has" height="280" src="https://img-blog.csdn.net/2018072819123246?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NTRE5yaG1t/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="528"></p>

<p style="margin-left:0pt;">由上述图片介绍可知，闭包会导致全局变量不能被所有Worker共享，即一个Worker修改了全局变量后，对其它的Worker是透明的。</p>

<p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;"><strong>闭包带来的问题的参考文章：</strong><a href="https://blog.csdn.net/liangyihuai/article/details/56840473" rel="nofollow">https://blog.csdn.net/liangyihuai/article/details/56840473</a></p>

<p style="margin-left:0pt;">由上述图片可知，每个task都会接受的一个闭包，有时候会太浪费资源了。因此出现了<strong>Broadcast variables</strong>，该变量发送给每一个executor，executor将广播变量缓存。广播变量是单向传播的，从驱动到任务，没有办法更新广播变量或者将更新传播回驱动程序。这种情况下，可以通过Accumulator来实现。</p>

<h3 id="accumulators">Accumulators</h3>

<p>当一个作业运行完毕后，累积器的最终值可以从驱动程序中获取</p>

<p><strong>介绍Broadcast variables和Accumulators的参考文章：</strong><a href="https://www.zybuluo.com/BrandonLin/note/446869" rel="nofollow">https://www.zybuluo.com/BrandonLin/note/446869</a></p>

<p style="margin-left:0pt;"> </p>            </div>
                </div>