---
layout:     post
title:      Spark相关总结
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/guaniu_zsx/article/details/79499050				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                开源的、数据分析、开发快、运行快<br><br>spark core批量处理、spark streaming流式处理、spark mllib机器学习、spark GraphX图计算<br><br>spark基于内存的计算<br><br>MapReduce处理海量数据，无法取代<br><br>Storm实时流失处理，无法取代<br><br>Hive无法取代<br><br>Spark为什么快？基于内存、DAG优化<br><br>Spark四种运行模式：Local、Standalone(Master、Zookeeper(配置HA))、Yarn(粗粒度的资源调用)、Mesos(可以细粒度的资源调用)<br><br>RDD五大特性<br><br>Cluster --&gt; Worker Node --&gt; Executors(进程、端口) --&gt; Thread<br>Application(main Driver(new SparkContext (DagScheduler TaskScheduler))) --&gt; Job --&gt; Stage --&gt; Task <br><br>Transformation 是延迟执行 --&gt; RDD RDD<br>Action 是立即执行 --&gt; RDD 结果<br><br>缓存RDD <br>可以对反复调用的RDD进行缓存、为了多次使用的时候速度快<br>默认的缓存策略是 StorageLevel.MEMORY_ONLY <br>MEMORY_AND_DISK<br>_2（两个父本）<br>_ser（序列化）<br><br>容错<br>Lineage （血统）重新计算 、如果lineage很长，是不是可以做缓存RDD来提高效率<br>doCheckpoint("hdfs://") 之前需要setCheckpointDir()<br><br>宽窄依赖概念的：<br>宽依赖目的是为了切分Stage<br>窄依赖目的是做DAG优化，一个partition会对应一个Task，会对应一个pipeline，1+1+1+1=4<br>什么宽依赖？Shuffle 父RDD里面的partition会去向子RDD里面的多个partition<br><br>spark程序代码会被转化为DAG、有向无环图 SparkContext.runJob(rdd)<br>DAGScheduler会根据DAG切分Stage，被封装每个Stage为TaskSet，发送给下游的TaskScheduler submitTasks(TaskSet)<br>TaskScheduler会跟Yarn进行沟通，把TaskSet打散为Task发配到真正的某一个Executor里面去计算<br><br>碰到Struggling的Task，可以配置一个speculation的选项，会去发送一个同样的Task和之前的挣扎的Task竞争<br><br>Spark-shell去执行WordCount ，PV、UV distinct() ， sortBy() sortByKey()<span style="width:0px;"></span>            </div>
                </div>