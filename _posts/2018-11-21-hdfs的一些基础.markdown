---
layout:     post
title:      hdfs的一些基础
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h1>hdfs</h1><p>Created Friday 16 March 2018</p><p><a title="hdfs:通过统一的命名空间目录树来定位文件." class="page">hdfs:通过统一的命名空间目录树来定位文件.</a></p><p>hdfs采用的是master/slave架构,一般一个hdfs集群是有一个namenode和一定数目的<br>datanode组成,Namenode是hdfs集群主节点,datanode是hdfs集群的从节点,两种角色各司其职,共同协调完成分布式的文件存储服务.</p><br><p>hdfs中的文件在物理上是分块存储(block)的,块的大小可以通过配置参数来规定,默认<br>大小在hadoop2.x版本中是128M</p><p>名字空间:  <br></p><div>namenode负责维护文件系统的名字空间,任何对文件系统名字空间或属性修改都将会被namenode记录下来. </div><p>NameNode元数据管理:<br></p><div>我们把目录结构及文件分块位置信息叫做<strong>元数据</strong>,namenode负责维护整个hdfs文件系统的目录结构,以及每一个文件所对应的block块消息(block的id,及所在的datanode服务器).</div><p>datanode数据存储:<br></p><div>文件的各个block的具体存储管理有datanode节点来承担,每一个block都可以在多个datanode上,datanode需要定时向namenode汇报自己特有的block信息.</div><p>副本机制:<br></p><div>为了容错,文件的所有block都会有副本,每个文件的block大小和副本系数都是可以配置的.</div><p>一次写入,多次读出:<br>hdfs是设计为适应一次写入,多次读出的场景,且不支持文件的修改.</p><p>hdfs基本的操作:<br>hadoop fs &lt;args&gt;<br>完整的写法是:hadoop fs -ls <a title="hdfs://node01:9000/" class="hdfs">hdfs://node01:9000/</a><br>在配置文件种配置了fs.defaultFS为hdfs,所有可以省略上面写法.<br>还有一种写法:hdfs dfs -ls / </p><p>-put:上传文件,是从本地linux上传到hdfs上<br><a href="" rel="nofollow" title="-get:从hdfs下载到本地linux上" class="page">-get:从hdfs下载到本地linux上</a><br><a href="" rel="nofollow" title="-appendtofile:把文件追加到另一个文件." class="page">-appendtofile:把文件追加到另一个文件.</a><br><a href="" rel="nofollow" title="-getmerge:把所有的文件合并到一个文件" class="page">-getmerge:把所有的文件合并到一个文件</a><br><a href="" rel="nofollow" title="-setrep:改变一个文件的副本系数." class="page">-setrep:改变一个文件的副本系数.</a></p><br><br><br><br><br><br><br><br>            </div>
                </div>