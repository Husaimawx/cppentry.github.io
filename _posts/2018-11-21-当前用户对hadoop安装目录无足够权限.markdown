---
layout:     post
title:      当前用户对hadoop安装目录无足够权限
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<div class="markdown_views">
<p><strong>1、首先将hadoop解压到 /opt</strong> </p>
<p><strong>$sudo tar -zxvf hadoop.xx.xx.tar.gz</strong> <br>
到达/opt下，然后建立hadoop文件夹，里面建立name和data两个文件夹 <br><strong>$sudo mkdir hadoop</strong> <br>
到达/hadoop <br><strong>$sudo mkdir name <br>
$sudo mkdir data</strong></p>
<p><strong>2、配置hadoop</strong></p>
<pre class="prettyprint"><code class="hljs xml has-numbering">**core-size.xml**
<span class="hljs-pi">&lt;?xml version="1.0"?&gt;</span>
<span class="hljs-pi">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>
<span class="hljs-comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>/opt/hadoop<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.name.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>/opt/hadoop/name<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>fs.default.name<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>hdfs://localhost:9000<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>
<p><strong>hdfs-size.xml</strong></p>
<pre class="prettyprint"><code class="hljs xml has-numbering"><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.data.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>/opt/hadoop/data<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>

<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>

<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span>
</code></pre>
<p><strong>mapred-size.xml</strong></p>
<pre class="prettyprint"><code class="hljs xml has-numbering"><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>maperd.job.tracker<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>localhost:9001<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span>
</code></pre>
<p><strong>hadoop-env.sh</strong></p>
<pre class="prettyprint"><code class="hljs ruby has-numbering"><span class="hljs-comment"># The java implementation to use.  Required.</span>
 **export <span class="hljs-constant">JAVA_HOME</span>=<span class="hljs-regexp">/usr/local</span><span class="hljs-regexp">/java/jdk</span>1.<span class="hljs-number">7.0_67</span>**
<span class="hljs-comment"># Extra Java CLASSPATH elements.  Optional.</span></code></pre>
<p>打开/etc/profile</p>
<pre class="prettyprint"><code class="hljs bash has-numbering"><span class="hljs-keyword">export</span> JAVA_HOME=/usr/local/java/jdk1.<span class="hljs-number">7.0</span>_67
<span class="hljs-keyword">export</span> HADOOP_HOME=/opt/hadoop-<span class="hljs-number">1.2</span>.<span class="hljs-number">1</span>
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">$JAVA_HOME</span>/bin:<span class="hljs-variable">$HADOOP_HOME</span>/bin:<span class="hljs-variable">$PATH</span>
<span class="hljs-keyword">export</span> CLASSPATH=.:<span class="hljs-variable">$JAVA_HOME</span>/lib/dt.jar:<span class="hljs-variable">$JAVA_HOME</span>/lib/tools.jar
</code></pre>
<p>到这里配置Hadoop配置差不多没问题了。 <br>
$ hadoop （可以看到是否成功） <br><strong>1、格式化HDFS 到达hadoop的bin目录下 执行 <br>
$hadoop namenode -format</strong> <br>
这里我直接报了这个错 （<strong>namenode 无法启动</strong>） <br>
ERROR namenode.NameNode: <a href="http://lib.csdn.net/base/javase" rel="nofollow" class="replace_word" title="Java SE知识库" style="color:#df3434;font-weight:bold;">
Java</a>.io.IOException: Cannot create directory /export/home/dfs/name/current</p>
<p>解决：原因是 没有设置 /opt/hadoop 的权限没有设置， 将之改为： <br><strong>$ chown –R hadoop:hadoop /opt/hadoop <br>
$ sudo chmod -R a+w /opt/hadoop</strong></p>
<p><strong>2、启动Hadoop</strong></p>
<p>执行 <strong>start-all.sh <br>
当前用户对hadoop安装目录无足够权限</strong> <br>
hm@hm-ubuntu:/usr/hadoop-1.1.2/bin$ start-all.sh <br>
mkdir: cannot create directory <code>/usr/hadoop-1.1.2/libexec/../logs': Permission denied
<br>
chown: cannot access</code>/usr/hadoop-1.1.2/libexec/../logs’: No such file or directory</p>
<p>starting namenode, logging to /usr/hadoop-1.1.2/libexec/../logs/hadoop-hm-namenode-hm-ubuntu.out
<br>
/usr/hadoop-1.1.2/bin/hadoop-daemon.sh: line 136: /usr/hadoop-1.1.2/libexec/../logs/hadoop-hm-namenode-hm-ubuntu.out: No such file or directory
<br>
head: cannot open `/usr/hadoop-1.1.2/libexec/../logs/hadoop-hm-namenode-hm-ubuntu.out’ for reading: No such file or directory
<br>
hm@localhost’s password: <br>
… … <br>
解决： <br>
执行 chown 命令为当前用户赋予对目录可写的权限 <br><strong>sudo chown -hR Eddie（当前用户名） hadoop-xxx(当前版本)</strong></p>
</div>
            </div>
                </div>