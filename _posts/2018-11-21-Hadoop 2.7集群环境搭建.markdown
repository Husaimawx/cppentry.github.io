---
layout:     post
title:      Hadoop 2.7集群环境搭建
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/chenhaifeng2016/article/details/63688535				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<h1>系统拓扑</h1>
<table border="1" cellspacing="0" cellpadding="0"><tbody><tr><td valign="top">
<p>角色</p>
</td>
<td valign="top">
<p> ip地址</p>
</td>
<td valign="top">
<p>hdfs</p>
</td>
<td valign="top">
<p>yarn</p>
</td>
</tr><tr><td valign="top">
<p>Master</p>
</td>
<td valign="top">
<p>10.0.0.201</p>
</td>
<td valign="top">
<p>NameNode</p>
</td>
<td valign="top">
<p>ResourceManager</p>
</td>
</tr><tr><td valign="top">
<p>slave</p>
</td>
<td valign="top">
<p>10.0.0.202</p>
</td>
<td valign="top">
<p>DataNode</p>
</td>
<td valign="top">
<p>NodeManager</p>
</td>
</tr><tr><td valign="top">
<p>slave</p>
</td>
<td valign="top">
<p>10.0.0.203</p>
</td>
<td valign="top">
<p>DataNode</p>
</td>
<td valign="top">
<p>NodeManager</p>
</td>
</tr></tbody></table><p> <img src="https://img-blog.csdn.net/20170715154255279" alt=""></p>
<h1>前提条件</h1>
<p>安装jdk</p>
<p>关闭selinux</p>
<p>关闭防火墙或者配置端口</p>
<h2>设置ssh免密登录</h2>
<p>在所有节点生RSA密钥对, 不要设置私钥密码。</p>
<p>ssh-keygen</p>
<p>把所有节点的公钥加入authorized_keys文件。</p>
<p>cat id_rsa.pub &gt;&gt; authorized_keys</p>
<p>cat id_rsa.pub.202 &gt;&gt; authorized_keys</p>
<p>cat id_rsa.pub.203 &gt;&gt; authorized_keys</p>
<p></p>
<p> <img src="https://img-blog.csdn.net/20170319201600104" alt=""></p>
<p>scp authorized_keys root@10.0.0.202:/root/.ssh/authorized_keys</p>
<p>scp authorized_keys root@10.0.0.203:/root/.ssh/authorized_keys</p>
<p> </p>
<p>ssh node1</p>
<p>ssh node2</p>
<p>ssh node3</p>
<h2>设置/etc/hosts</h2>
<p><img src="https://img-blog.csdn.net/20170319201605854" alt=""></p>
<p>scp /etc/hosts root@10.0.0.202:/etc/hosts</p>
<p>scp /etc/hosts <a href="mailto:root@10.0.0.203:/etc/hosts" rel="nofollow">
root@10.0.0.203:/etc/hosts</a></p>
<h2>设置环境变量</h2>
<p>/etc/profile</p>
<p></p>
<p> <img src="https://img-blog.csdn.net/20170319201617723" alt=""></p>
<h1>配置Hadoop</h1>
<p>解压hadoop</p>
<p>并创建目录</p>
<p>mkdir –p dfs/name</p>
<p>mkdir –p dfs/data</p>
<p>vim /etc/profile</p>
<p>exportHADOOP_HOME=/usr/local/src/Hadoop-2.7.0</p>
<p> </p>
<p>vim ./etc/Hadoop/hadoop-env.sh</p>
<p>export JAVA_HOME=/usr/local/src/jdk1.7.0_60</p>
<h2>core-site.xml</h2>
<p></p>
<p> <img src="https://img-blog.csdn.net/20170319201622964" alt=""></p>
<h2>hdfs-site.xml</h2>
<p></p>
<p> <img src="https://img-blog.csdn.net/20170319201628620" alt=""></p>
<h2>mapred-site.xml</h2>
<p><img src="https://img-blog.csdn.net/20170319201636214" alt=""></p>
<h2>yarn-site.xml</h2>
<p><img src="https://img-blog.csdn.net/20170319201646552" alt=""></p>
<p><span style="color:#FF0000;">yarn.nodemanager.resource.memory-mb</span><span style="color:#FF0000;">必须大于等于</span><span style="color:#FF0000;">2048</span></p>
<p><span style="color:#FF0000;">图中有误，改为yarn.nodemanager.aux-services.mapreduce_shuffle.class</span></p>
<h2>修改slaves</h2>
<p><img src="https://img-blog.csdn.net/20170319201652136" alt=""></p>
<p> </p>
<h2>分发hadoop</h2>
<p>scp -r ./hadoop-2.7.0 <a href="mailto:root@10.0.0.202:/usr/local/src" rel="nofollow">
root@10.0.0.202:/usr/local/src</a></p>
<p>scp -r ./hadoop-2.7.0 <a href="mailto:root@10.0.0.203:/usr/local/src" rel="nofollow">
root@10.0.0.203:/usr/local/src</a></p>
<p> </p>
<h1>运行hadoop</h1>
<h2>运行HDFS</h2>
<p>bin/hdfs namenode –format (运行一次)</p>
<p> </p>
<p>sbin/start-dfs.sh</p>
<p><img src="https://img-blog.csdn.net/20170319201658896" alt=""></p>
<h2>运行yarn</h2>
<p>sbin/yarn-daemon.sh  --config ./etc/hadoop start proxyserver</p>
<p>sbin/start-yarn.sh</p>
<p><img src="https://img-blog.csdn.net/20170319201709261" alt=""><br></p>
<p></p>
<h2>运行mapreduce JobHistory Server</h2>
<p>sbin/mr-jobhistory-daemon.sh –config ./etc/hadoopstart historyserver</p>
<p><img src="https://img-blog.csdn.net/20170319201714808" alt=""><br></p>
<p></p>
<h2>查看进程</h2>
<p>201</p>
<p></p>
<p> <img src="https://img-blog.csdn.net/20170319201720745" alt=""></p>
<p>202</p>
<p></p>
<p> <img src="https://img-blog.csdn.net/20170319201727839" alt=""></p>
<p>203</p>
<p><img src="https://img-blog.csdn.net/20170319201735839" alt=""><br></p>
<p></p>
<h1>测试hadoop</h1>
<h2>hdfs namenode</h2>
<p><a href="http://10.0.0.201:50070/" rel="nofollow">http://10.0.0.201:50070</a></p>
<p><img src="https://img-blog.csdn.net/20170319201741507" alt=""><br></p>
<p></p>
<h2>secondary namenode</h2>
<div><img src="https://img-blog.csdn.net/20170319201748542" alt=""><br></div>
<p></p>
<h2>yarn ResourceManager</h2>
<p><a href="http://10.0.0.201:8088/" rel="nofollow">http://10.0.0.201:8088</a></p>
<p><img src="https://img-blog.csdn.net/20170319201802054" alt=""><br></p>
<p></p>
<h2>MapReduce JobHistory Server</h2>
<p><a href="http://10.0.0.201:19888/" rel="nofollow">http://10.0.0.201:19888</a></p>
<p> </p>
<p><img src="https://img-blog.csdn.net/20170319201808038" alt=""></p>
<p> </p>
<h2>运行mapreduce worldcount</h2>
<p><img src="https://img-blog.csdn.net/20170319201815371" alt=""></p>
<p><img src="https://img-blog.csdn.net/20170319201820918" alt=""><br></p>
<p></p>
<p>bin/hadoop jar./share/hadoop/mapreduce/hadoop-mapred                                                                                                             uce-examples-2.7.0.jarwordcount /example/input /example/output</p>
<p></p>
<p></p>
<p></p>
<p><img src="https://img-blog.csdn.net/20170319201828633" alt=""></p>
<p><img src="https://img-blog.csdn.net/20170319201834867" alt=""><img src="https://img-blog.csdn.net/20170319201840336" alt=""><img src="https://img-blog.csdn.net/20170319201845649" alt=""><br></p>
<h1>停止hadoop</h1>
<h2>停止hdfs</h2>
<p>sbin/stop-dfs.sh</p>
<h2>停止yarn</h2>
<p>sbin/stop-yarn.sh</p>
<p> </p>
<h2>停止WebAppProxy</h2>
<p>sbin/yarn-daemon.sh –config ./etc/hadoopstop proxyserver</p>
<p> </p>
<h2>停止MapReduce JobHistory Server</h2>
<p>sbin/mr-jobhistory-daemon.sh –config ./etc/hadoopstop historyserver</p>
            </div>
                </div>