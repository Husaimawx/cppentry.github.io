---
layout:     post
title:      大数据笔记16：Hadoop入门
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>第16天——Hadoop入门</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><hr style="clear:both;"><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">一、Hadoop概述</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">1、Hadoop创始人Doug Cutting</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">2、Hadoop简介</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">3、Hadoop发展简史</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">4、Hadoop特性</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">5、Hadoop应用现状</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">6、Hadoop在企业中的应用架构</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">7、Apache Hadoop版本演变</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">8、Hadoop各种版本</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">二、Hadoop项目结构</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">三、Hadoop安装方式</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">四、伪分布式安装Hadoop</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">五、小结</span></div><hr style="clear:both;"><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>一、Hadoop概述</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>1、Hadoop创始人Doug Cutting</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">1985年毕业于美国斯坦福大学，他是Lucene、Nutch和Hadoop三个项目的创立者，先是参与了Lucene的开发，然后是Nutch，然后是Hadoop。最近几年，一直在专注于Hadoop生态系统的建设。比如Hbase，Hbase越来越稳定，也越来越高效。逐渐在升温。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>2、Hadoop简介</strong></span></div><ul><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">Hadoop是Apache软件基金会旗下的一个开源分布式计算平台，为用户提供了系统底层细节透明的分布式基础架构</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">Hadoop是基于Java语言开发的，具有很好的跨平台特性，并且可以部署在廉价的计算机集群中</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">Hadoop的核心是分布式文件系统<span style="color:rgb(153,72,0);">HDFS</span>（Hadoop Distributed File System）和<span style="color:rgb(153,72,0);">MapReduce</span></li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">Hadoop被公认为行业大数据标准开源软件，在分布式环境下提供了海量数据的处理能力</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">几乎所有主流厂商都围绕Hadoop提供开发工具、开源软件、商业化工具和技术服务，如谷歌、雅虎、微软、思科、淘宝等，都支持Hadoop</li></ul><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>3、Hadoop发展简史</strong></span></div><ul><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">Hadoop最初是由Apache Lucene项目的创始人Doug Cutting开发的文本搜索库。Hadoop源自始于2002年的Apache Nutch项目——一个开源的网络搜索引擎并且也是Lucene项目的一部分</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">在2004年，Nutch项目也模仿GFS开发了自己的分布式文件系统NDFS（Nutch Distributed File System），也就是HDFS的前身</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">2004年，谷歌公司又发表了另一篇具有深远影响的论文，阐述了MapReduce分布式编程思想</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">2005年，Nutch开源实现了谷歌的MapReduce</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">到了2006年2月，Nutch中的NDFS和MapReduce开始独立出来，成为Lucene项目的一个子项目，称为Hadoop，同时，Doug Cutting加盟雅虎</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">2008年1月，Hadoop正式成为Apache顶级项目，Hadoop也逐渐开始被雅虎之外的其他公司使用</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">2008年4月，Hadoop打破世界纪录，成为最快排序1TB数据的系统，它采用一个由910个节点构成的集群进行运算，排序时间只用了209秒</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">在2009年5月，Hadoop更是把1TB数据排序时间缩短到62秒。Hadoop从此名声大震，迅速发展成为大数据时代最具影响力的开源分布式开发平台，并成为事实上的大数据处理标准</li></ul><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>4、Hadoop特性</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">Hadoop是一个能够对大量数据进行分布式处理的软件框架，并且是以一种可靠、高效、可伸缩的方式进行处理的，它具有以下几个方面的特性：</span></div><ul><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">高可靠性</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">高效性</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">高可扩展性</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">高容错性</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">成本低</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">运行在Linux平台上</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">支持多种编程语言</li></ul><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>5、Hadoop应用现状</strong></span></div><ul><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">Hadoop凭借其突出的优势，已经在各个领域得到了广泛的应用，而互联网领域是其应用的主阵地</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">2007年，雅虎在Sunnyvale总部建立了M45——一个包含了4000个处理器和1.5PB容量的Hadoop集群系统</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">Facebook作为全球知名的社交网站，Hadoop是非常理想的选择，Facebook主要将Hadoop平台用于日志处理、推荐系统和数据仓库等方面</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">国内采用Hadoop的公司主要有百度、淘宝、网易、华为、中国移动等，其中，淘宝的Hadoop集群比较大</li></ul><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>6、Hadoop在企业中的应用架构</strong></span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070043929" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>7、Apache Hadoop版本演变</strong></span></div><ul><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">Apache Hadoop版本分为两代，我们将第一代Hadoop称为Hadoop 1.0，第二代Hadoop称为Hadoop 2.0</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">第一代Hadoop包含三个大版本，分别是0.20.x，0.21.x和0.22.x，其中，0.20.x最后演化成1.0.x，变成了稳定版，而0.21.x和0.22.x则增加了NameNode HA等新的重大特性</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">第二代Hadoop包含两个版本，分别是0.23.x和2.x，它们完全不同于Hadoop 1.0，是一套全新的架构，均包含HDFS Federation和YARN两个系统，相比于0.23.x，2.x增加了NameNode HA和Wire-compatibility两个重大特性</li></ul><div style="text-align:left;line-height:1.75;font-size:14px;"><img src="https://img-blog.csdn.net/20180304070105308" alt=""><br></div><div style="text-align:left;"></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">Hadoop1.0：HDFS + MapReduce</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">Hadoop2.0：引入Yarn，可以在集群中同时运行多种计算框架，比如Spark、Tez。（Yarn：Yet Another Resource Negotiator）</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">Hadoop3.0：Hadoop 2.0是基于JDK 1.7开发的，而JDK 1.7在2015年4月已停止更新，这直接迫使Hadoop社区基于JDK 1.8重新发布一个新的Hadoop版本，而这正是hadoop 3.0。Hadoop 3.0的alpha版预计2016年夏天发布，GA版本11月或12月发布。Hadoop 3.0中引入了一些重要的功能和优化，包括HDFS 可擦除编码、多Namenode支持、MR Native Task优化、YARN基于cgroup的内存和磁盘IO隔离、YARN container resizing等。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>8、Hadoop各种版本</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>（1）开源版和发行版</strong></span></div><ul><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">Apache Hadoop</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">Hortonworks</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">Cloudera（CDH：Cloudera Distribution Hadoop）</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">MapR</li></ul><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>（2）选择Hadoop版本的考虑因素</strong></span></div><ul><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">是否开源（即是否免费）</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">是否有稳定版</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">是否经实践检验</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">是否有强大的社区支持</li></ul><div style="text-align:left;line-height:1.75;font-size:14px;"><img src="https://img-blog.csdn.net/20180304070121192" alt=""><br></div><div style="text-align:left;"></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;font-weight:bold;">二、Hadoop项目结构</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">Hadoop项目结构不断丰富发展，已经形成一个丰富的Hadoop生态系统。</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/2018030407013784" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><img src="https://img-blog.csdn.net/20180304070155437" alt=""><br></div><div style="text-align:left;"><span style="font-size:18px;font-weight:bold;">三、Hadoop安装方式</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">1、单机模式：不能使用HDFS，只能使用MapReduce，所以单机模式最主要的目的是在本机调试MapReduce代码。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">2、伪分布式模式：用多个线程模拟多台真实机器，即模拟真实的分布式环境。Hadoop在单节点上以伪分布式方式运行，Hadoop进程以分离的Java进程来运行，节点既作为NameNode也作为DataNode，同时，读取的是HDFS中的文件。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">3、完全分布式模式：使用多个节点构成集群环境来运行Hadoop。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>四、伪分布式安装Hadoop</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>1、创建虚拟机hadoop</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>（1）克隆虚拟机hadoop</strong></span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070214585" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>（2）启动虚拟机hadoop，设置网络连接</strong></span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070226827" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><img src="https://img-blog.csdn.net/20180304070242562" alt=""><br></div><div style="text-align:left;"></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>（3）关闭防火墙</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">执行：</span><span style="font-size:18px;"><strong>service iptables stop</strong></span><span style="font-size:18px;"> 这个指令关闭完防火墙后，如果重启，防火墙会重新建立，所以，如果想重启后防火墙还关闭，需额外执行：</span><span style="font-size:18px;"><strong>chkconfig iptables off。</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><img src="https://img-blog.csdn.net/20180304070257979" alt=""><br></div><div style="text-align:left;"></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">注意：CentOS 7上，关闭防火墙命令变了。</span></div><ul><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">停止防火墙服务：systemctl stop firewalld</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">禁用防火墙服务：systemctl disable firewalld</li></ul><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">（4）用SecureCRT登录虚拟机hadoop</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070312841" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>2、配置主机名</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">执行：vim /etc/sysconfig/network</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">编辑主机名：HOSTNAME=</span><span style="font-size:18px;color:rgb(153,72,0);">hadoop</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070329190" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">注意：主机名里不能有下滑线，或者特殊字符#或$，不然会找不到主机导致无法启动。这种方式更改主机名需要重启才能永久生效，因为主机名属于内核参数。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;color:rgb(123,91,161);">如果不想重启，可以执行：hostname hadoop。但是这种更改是临时的，重启后会恢复原主机名。可结合使用。先修改配置文件，然后执行：hostname hadoop 。可以达到不重启或重启都是主机名都是同一个的目的。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;color:rgb(123,91,161);">重启虚拟机：reboot。</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070353104" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><img src="https://img-blog.csdn.net/20180304070400868" alt=""><br></div><div style="text-align:left;"></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>3、配置hosts文件，做域名映射</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">执行：vim /etc/hosts</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/2018030407041725" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">这样访问“192.168.225.100”，就可用主机名“hadoop”替代。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>4、配置免秘钥登录</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>（1）执行：ssh-keygen  生成密钥对</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">一直敲回车，生成节点的公钥和私钥，生成的文件会自动放在/root/.ssh目录下，然后把公钥发往远程机器或本机。</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070430645" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>5、配置免密登录自己</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">执行：ssh-copy-id </span><span style="font-size:18px;color:rgb(57,57,57);">root@hadoop</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/2018030407044375" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">验证一下，hadoop是否可以免密登录自己：</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/2018030407045574" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>6、安装和配置JDK</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">（1）创建/home/software目录</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070507816" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">当前目录已经切换到/home/software。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">（2）利用rz上传JDK安装包</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070522972" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><img src="https://img-blog.csdn.net/20180304070533448" alt=""><br></div><div style="text-align:left;"></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">（3）利用rpm命令安装JDK</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">[root@hadoop software]# rpm -ivh jdk-8u111-linux-x64.rpm</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070548464" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">查看JDK安装在何处：rpm -qc jdk1.8.0_111</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/2018030407060176" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">（3）配置JDK环境变量</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">执行： vim /etc/profile</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">在尾行添加：</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">JAVA_HOME=/usr/java/jdk1.8.0_111</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">PATH=$JAVA_HOME/bin:$PATH</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">export JAVA_HOME CLASSPATH PATH</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070614202" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">末行模式下：wq，保存退出。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">发布</span><span style="font-size:18px;color:rgb(153,72,0);">source /etc/profile</span><span style="font-size:18px;"> 使更改的配置立即生效。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">发布java -version 查看JDK版本信息。</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070636120" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>7、下载、上传和解压Hadoop安装包</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>（1）下载Hadoop</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">下载地址：</span><a href="http://hadoop.apache.org/releases.html" rel="nofollow"><span style="font-size:18px;color:rgb(0,56,132);"><u>http://hadoop.apache.org/releases.html</u></span></a></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070649499" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">注意：source表示源码；binary表示二进制包（安装包）</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070718925" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><img src="https://img-blog.csdn.net/20180304070733136" alt=""><br></div><div style="text-align:left;"></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">（2）利用rz上传hadoop-2.7.4.tar.gz</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070752387" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><img src="https://img-blog.csdn.net/20180304070757336" alt=""><br></div><div style="text-align:left;"></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">（3）解压缩hadoop-2.7.4.tar.gz</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">执行：tar -zxvf hadoop-2.7.4.tar.gz，生成目录hadoop-2.7.4。</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070811533" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">（4）进入目录hadoop-2.7.4，查看其子目录</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070827436" alt=""></div><ul><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">bin目录：命令脚本</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">etc/hadoop：存放hadoop的配置文件</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">lib目录：hadoop运行的依赖jar包</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">sbin目录：存放启动和关闭hadoop等命令</li><li style="text-align:left;line-height:1.75;font-size:18px;list-style-position:inside;font-family:'Microsoft YaHei', STXihei;color:rgb(0,0,0);">libexec目录：存放的也是hadoop命令，但一般不常用，最常用的就是bin和etc目录。</li></ul><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">查看etc/hadoop目录：</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070842776" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">查看sbin目录：</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070855530" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>8、修改hadoop环境配置文件hadoop-env.sh</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">进入hadoop配置目录，执行vim hadoop-env.sh</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070911317" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">export JAVA_HOME=/usr/java/jdk1.8.0_111</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">export HADOOP_HOME=/home/software/hadoop-2.7.4</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">export HADOOP_OPTS="-Djava.library.path=${HADOOP_HOME}/lib/native"</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070923318" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">然后执行：source hadoop-env.sh 让配置立即生效。</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070937328" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>9、修改hadoop核心配置文件core-site.xml</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">在etc/hadoop目录下执行：vim core-site.xml</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304070956426" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;configuration&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;!--用来指定hdfs的老大，namenode的地址--&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;property&gt;</span></div><div style="margin-left:56px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;name&gt;fs.defaultFS&lt;/name&gt;</span></div><div style="margin-left:56px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;value&gt;hdfs://hadoop:9000&lt;/value&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;/property&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;!--用来指定hadoop运行时产生文件的存放目录--&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;property&gt;</span></div><div style="margin-left:56px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span></div><div style="margin-left:56px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;value&gt;/home/software/hadoop-2.7.4/tmp&lt;/value&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;/property&gt;</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;/configuration&gt;</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304071010625" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>10、修改分布式文件系统配置文件hdfs-site .xml</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">[root@hadoop hadoop]# vim hdfs-site.xml</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;configuration&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;!--指定hdfs保存数据副本数量，默认值是3--&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;!--如果是伪分布模式，此值是1--&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;property&gt;</span></div><div style="margin-left:56px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;name&gt;dfs.replication&lt;/name&gt;</span></div><div style="margin-left:56px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;value&gt;1&lt;/value&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;/property&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;!--设置hdfs的操作权限，false表示任何用户都可以在hdfs上操作文件--&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;property&gt;</span></div><div style="margin-left:56px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;name&gt;dfs.permissions&lt;/name&gt;</span></div><div style="margin-left:56px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;value&gt;false&lt;/value&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;/property&gt;</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;/configuration&gt;</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304071044657" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>11、修改MapReduce配置文件mapred-site.xml</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">将模板文件mapred-site.xml.template拷贝一份，并重命名为mapred-site.xml</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">[root@hadoop hadoop]# cp mapred-site.xml.template mapred-site.xml</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">执行：vim mapred-site.xml</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;configuration&gt;</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">     &lt;!--指定mapreduce运行在yarn上--&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;property&gt;</span></div><div style="margin-left:56px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span></div><div style="margin-left:56px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;value&gt;yarn&lt;/value&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;/property&gt;</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;/configuration&gt;</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304071059996" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">yarn是资源协调工具。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>12、修改yarn配置文件yarn-site.xml</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">[root@hadoop hadoop]# vim yarn-site.xml </span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;configuration&gt;</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">      &lt;!--指定yarn的老大resoucemanager的地址--&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;property&gt;</span></div><div style="margin-left:56px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span></div><div style="margin-left:56px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;value&gt;hadoop&lt;/value&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;/property&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;!--NodeManager获取数据的方式--&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;property&gt;</span></div><div style="margin-left:56px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span></div><div style="margin-left:56px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span></div><div style="margin-left:28px;text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;/property&gt;</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">&lt;/configuration&gt;</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304071119724" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>13、配置hadoop的环境变量</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">[root@hadoop hadoop]# vim /etc/profile</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">JAVA_HOME=/usr/java/jdk1.8.0_111</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">HADOOP_HOME=/home/software/hadoop-2.7.4</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">export JAVA_HOME HADOOP_HOME CLASSPATH PATH</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304071150558" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">执行source /etc/profile，让配置生效。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">[root@hadoop hadoop]# source /etc/profile</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>14、创建hadoop存放生成文件的临时目录tmp</strong></span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304071208256" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>15、格式化名称节点namenode</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">格式化namenode，形成可用的分布式文件系统HDFS。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">执行：hadoop namenode -format</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">如果不好使，可以重启Linux。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">当出现：successfully，证明格式化成功。</span></div><div style="text-align:left;"><img src="https://img-blog.csdn.net/20180304071241562" alt=""></div><div style="text-align:left;line-height:1.75;font-size:14px;"><img src="https://img-blog.csdn.net/20180304071247155" alt=""><br></div><div style="text-align:left;"></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">建议使用命令：</span><span style="font-size:18px;color:rgb(223,64,42);"><strong>hdfs namenode -format</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;"><strong>五、小结</strong></span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">1、Hadoop被视为事实上的大数据处理标准，讲述了Hadoop的发展历程，并阐述了Hadoop的高可靠性、高效性、高可扩展性、高容错性、成本低、运行在Linux平台上、支持多种编程语言等特性。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">2、Hadoop目前已经在各个领域得到了广泛的应用，雅虎、Facebook、百度、淘宝、网易等公司都建立了自己的Hadoop集群。</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="font-size:18px;">3、经过多年发展，Hadoop项目已经变得非常成熟和完善，包括Common、Avro、Zookeeper、HDFS、MapReduce、HBase、Hive、Chukwa、Pig等子项目，其中，HDFS和MapReduce是Hadoop的两大核心组件。</span></div>            </div>
                </div>