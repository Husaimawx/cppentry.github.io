---
layout:     post
title:      Spark RDD 分析总结(一)
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/WYpersist/article/details/79783021				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p><span style="font-size:28px;"><strong>Spark RDD是Spark 核心基石</strong></span></p><h1><strong>RDD为什么是Spark的核心概念</strong></h1><p>Spark<span style="font-family:'宋体';">建立在统一抽象的</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">之上，使得</span><span style="font-family:Calibri;">Spark</span><span style="font-family:'宋体';">可以很容易扩展，比如 </span><span style="font-family:Calibri;">Spark Streaming</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Spark SQL</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Machine Learning</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Graph</span><span style="font-family:'宋体';">都是在</span><span style="font-family:Calibri;">spark RDD</span><span style="font-family:'宋体';">上面进行的扩展</span>。</p><h1><strong>RDD的概念</strong></h1><p> <img src="https://img-blog.csdn.net/20180401224622896" alt=""></p><p>RDD<span style="font-family:'宋体';">是</span><span style="font-family:Calibri;">spark</span><span style="font-family:'宋体';">的核心，也是整个</span><span style="font-family:Calibri;">spark</span><span style="font-family:'宋体';">的架构基础，</span></p><p>RDD<span style="font-family:'宋体';">是弹性分布式集合（</span><span style="font-family:Calibri;">Resilient Distributed  Datasets</span><span style="font-family:'宋体';">）的简称，</span></p><p><span style="font-family:'宋体';">是分布式</span><span style="color:rgb(255,0,0);"><span style="font-family:'宋体';">只读</span></span><span style="font-family:'宋体';">且已分区</span>（<span style="font-family:'宋体';">多个</span>partition<span style="font-family:'宋体';">组成</span>）<span style="font-family:'宋体';">集合对象</span>，Partition<span style="font-family:'宋体';">分区，</span></p><p><span style="font-family:'宋体';">和</span>Block<span style="font-family:'宋体';">数据块是一一对应的</span><span style="font-family:Calibri;"> </span><span style="font-family:'宋体';">。</span></p><p><span style="font-family:'宋体';">这些集合是弹性的，如果数据集一部分丢失，则可以对它们进行重建。</span></p><p><span style="color:rgb(0,86,109);"> </span>优点：</p><p><span style="color:rgb(0,86,109);"> </span>RDD<span style="font-family:'宋体';">只能从持久存储或通过</span><span style="font-family:Calibri;">Transformations</span><span style="font-family:'宋体';">操作产生，相比于分布式共享内存</span><span style="font-family:Calibri;">(DSM)</span><span style="font-family:'宋体';">可以更高效实现容错，对于丢失部分数据分区只需根据它的</span><span style="font-family:Calibri;">lineage</span><span style="font-family:'宋体';">就可重新计算出来，而</span>不<span style="font-family:'宋体';">需要做特定的</span>Checkpoint</p><p>• 1<span style="font-family:'宋体';">、</span>RDD<span style="font-family:'宋体';">的</span>不<span style="font-family:'宋体';">变性，可以实现类</span>Hadoop MapReduce<span style="font-family:'宋体';">的推测式执行。</span></p><p>• 2<span style="font-family:'宋体';">、</span>RDD<span style="font-family:'宋体';">的数据分区特性，可以通过数据的本地性来提高性能，这</span>和Hadoop MapReduce<span style="font-family:'宋体';">是一样的。</span></p><p>• 3<span style="font-family:'宋体';">、</span>RDD<span style="font-family:'宋体';">都是可序列化的，在内存</span>不<span style="font-family:'宋体';">足时可自劢降级为磁盘存储，把</span>RDD<span style="font-family:'宋体';">存储于磁盘上，这时性能会有大的下降但</span>不<span style="font-family:'宋体';">会差于现在的</span>MapReduce<span style="font-family:'宋体';">。</span></p><p>• 4<span style="font-family:'宋体';">、</span><span style="font-family:'宋体';">批量操作：任务能够根据数据本地性</span> (data locality) <span style="font-family:'宋体';">被分配，从而提高性能。</span></p><h1><strong>RDD五个特性</strong></h1><p align="justify"><span style="font-family:'宋体';">每个</span> RDD <span style="font-family:'宋体';">都包含五部分信息，即数据分区的集合，能根据本地性快速访问到数据的偏好位置，依赖关系，计算方法，是否是哈希 </span><span style="font-family:Calibri;">/ </span><span style="font-family:'宋体';">范围分区的元数据</span></p><p> <img src="https://img-blog.csdn.net/20180401224636985" alt=""></p><p><span style="font-family:'宋体';">分区、最佳位置、依赖、</span> <span style="font-family:'宋体';">函数、分区策略</span></p><h1><strong>RDD的例子</strong></h1><p>val file = sc.textFile("hdfs://data/test.txt")</p><p> val data = file.flatMap(_.split(" ")).map((_,1)).reduceByKey(_ + _)</p><h2><strong>Spark <span style="font-family:'黑体';">程序具体的流程图</span></strong></h2><p> <img src="https://img-blog.csdn.net/2018040122464814" alt=""></p><p>1.<span style="font-family:'宋体';">客户端提交任务，初始化</span>sparkContext<span style="font-family:'宋体';">之后，</span><span style="font-family:Calibri;">sc.textFile(“hdfs://“)</span><span style="font-family:'宋体';">，去</span><span style="font-family:Calibri;">hdfs</span><span style="font-family:'宋体';">加载文件</span> <br>2.<span style="font-family:'宋体';">加载的文件比如有</span><span style="font-family:Calibri;">300MB</span><span style="font-family:'宋体';">，在</span><span style="font-family:Calibri;">hdfs</span><span style="font-family:'宋体';">中就有</span><span style="font-family:Calibri;">3</span><span style="font-family:'宋体';">个</span><span style="font-family:Calibri;">block</span><span style="font-family:'宋体';">块，对应 </span><span style="font-family:Calibri;">RDD </span><span style="font-family:'宋体';">里面的三个</span><span style="font-family:Calibri;">partition </span><br>3.<span style="font-family:'宋体';">加载的这个过程其实就是</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">的创建（</span><span style="font-family:Calibri;">MapPartitionsRDD</span><span style="font-family:'宋体';">）</span><span style="font-family:Calibri;"> </span><br>4.<span style="font-family:'宋体';">数据被加载到不同的</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">中，通过构建的</span><span style="font-family:Calibri;">stage</span><span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">task set</span><span style="font-family:'宋体';">）然后提交到</span><span style="font-family:Calibri;">executor</span><span style="font-family:'宋体';">中去并行计算</span><span style="font-family:Calibri;"> </span><br>5<span style="font-family:'宋体';">计算完成后输出结果</span></p><h2><strong>Spark<span style="font-family:'黑体';">计算流程</span>之RDD的<span style="font-family:'黑体';">作用</span></strong></h2><p><span style="font-family:'宋体';">可以看出整个计算流程都是基于</span>RDD<span style="font-family:'宋体';">在做计算</span><span style="font-family:Calibri;">,</span><span style="font-family:'宋体';">从数据加载，即</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">的创建</span><span style="font-family:Calibri;">,</span><span style="font-family:'宋体';">中途的计算（</span><span style="font-family:Calibri;">stage</span><span style="font-family:'宋体';">的划分，</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">的操作，</span><span style="font-family:Calibri;">shuffle</span><span style="font-family:'宋体';">）。到最后结果的输出，整个计算流程都是由</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">在贯穿</span></p><h1>RDD<span style="font-family:'宋体';">操作</span> <strong></strong></h1><p>RDD<span style="font-family:'宋体';">还提供了一组丰富的操作来操作这些数据，这种操作叫做算子。比如</span><span style="font-family:Calibri;">map</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">flatMap</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">filter</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">join</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">groupBy</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">reduceByKey</span><span style="font-family:'宋体';">等</span><span style="font-family:Calibri;"> </span><br>RDD<span style="font-family:'宋体';">分类，分为创建算子、转换、缓存、执行</span><span style="font-family:Calibri;"> </span><br>Transformation<span style="font-family:'宋体';">：转换算子，这类转换并不触发提交作业，完成作业中间过程处理。</span><span style="font-family:Calibri;"> </span><br>Action<span style="font-family:'宋体';">：行动算子，这类算子会触发</span><span style="font-family:Calibri;">SparkContext</span><span style="font-family:'宋体';">提交</span><span style="font-family:Calibri;">Job</span><span style="font-family:'宋体';">作业</span>。</p><p> <img src="https://img-blog.csdn.net/20180401224734753" alt=""></p><h1><strong>RDD接口</strong></h1><p> </p><p> <img src="https://img-blog.csdn.net/20180401224715282" alt=""></p><h1><strong>RDD的本质特征</strong></h1><p> <img src="https://img-blog.csdn.net/20180401224748932" alt=""></p><p> </p><h1><strong>RDD之间依赖关系（DAG）</strong></h1><h2><strong>窄依赖</strong></h2><p><span style="font-family:'宋体';">每个父</span>RDD<span style="font-family:'宋体';">的分区都至多被一个子</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">的分区使用，即为</span><span style="font-family:Calibri;">OneToOneDependecies</span><span style="font-family:'宋体';">；</span></p><p><span style="font-family:'宋体';">窄依赖是指父</span>RDD<span style="font-family:'宋体';">的每个分区都只被子</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">的一个分区所使用，如</span><span style="font-family:Calibri;">map</span><span style="font-family:'宋体';">就是一种窄依赖</span></p><h2><strong><span style="font-family:'黑体';">宽依赖</span></strong></h2><p><span style="font-family:'宋体';">宽依赖就是指父</span>RDD<span style="font-family:'宋体';">的分区被多个子</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">的分区所依赖，如</span><span style="font-family:Calibri;">join</span><span style="font-family:'宋体';">则会导致宽依赖</span></p><p> </p><p><span style="font-family:'宋体';">多个子</span>RDD<span style="font-family:'宋体';">的分区依赖一个父</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">的分区，即为</span><span style="font-family:Calibri;">ShuffleDependency  </span><span style="font-family:'宋体';">。例如，</span><span style="font-family:Calibri;">map</span><span style="font-family:'宋体';">操作是一种窄依赖，而</span><span style="font-family:Calibri;">join</span><span style="font-family:'宋体';">操作是一种宽依赖（除非父</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">已经基于</span><span style="font-family:Calibri;">Hash</span><span style="font-family:'宋体';">策略被划分过了，</span><span style="font-family:Calibri;">co- partitioned</span><span style="font-family:'宋体';">）</span></p><p> <img src="https://img-blog.csdn.net/20180401224810870" alt=""></p><p>stage<span style="font-family:'宋体';">的划分是</span><span style="font-family:Calibri;">Spark</span><span style="font-family:'宋体';">作业调度的关键一步，它基于</span><span style="font-family:Calibri;">DAG</span><span style="font-family:'宋体';">确定依赖关系，借此来划分</span><span style="font-family:Calibri;">stage</span><span style="font-family:'宋体';">，将依赖链断开，每个</span><span style="font-family:Calibri;">stage</span><span style="font-family:'宋体';">内部可以并行运行（划分关键点），整个作业按照</span><span style="font-family:Calibri;">stage</span><span style="font-family:'宋体';">顺序依次执行，最终完成整个</span><span style="font-family:Calibri;">Job</span><span style="font-family:'宋体';">。</span></p><p> <img src="https://img-blog.csdn.net/20180401224821788" alt=""></p><h2><strong><span style="font-family:'黑体';">窄依赖具体实现</span></strong></h2><p><span style="font-family:'宋体';">所有的依赖都要实现</span>trait Dependency[T]</p><p><span style="font-family:'宋体';">窄依赖是有两种具体实现</span> OneToOneDependency <span style="font-family:'宋体';">和 </span><span style="font-family:Calibri;">RangeDependency</span></p><p> <img src="https://img-blog.csdn.net/20180401224837153" alt=""></p><h2><strong><span style="font-family:'黑体';">宽依赖的实现</span></strong></h2><p><span style="font-family:'宋体';">宽依赖的实现只有一种：</span>ShuffleDependency</p><p><span style="color:rgb(0,0,136);">class</span><span style="color:rgb(0,0,0);"> </span>ShuffleDependency<span style="color:rgb(0,0,0);">[</span>K<span style="color:rgb(0,0,0);">, </span>V<span style="color:rgb(0,0,0);">, </span>C<span style="color:rgb(0,0,0);">] </span><span style="color:rgb(0,0,136);">extends</span><span style="color:rgb(0,0,0);"> </span>Dependency<span style="color:rgb(0,0,0);">[</span>Product2<span style="color:rgb(0,0,0);">[</span>K<span style="color:rgb(0,0,0);">, </span>V<span style="color:rgb(0,0,0);">]] {</span><span style="color:rgb(0,0,0);background:rgb(246,248,250);"> … }</span></p><p> <img src="https://img-blog.csdn.net/20180401224849616" alt=""></p><p> </p><h2><strong>依赖划分好处</strong></h2><p><span style="font-family:'宋体';">窄依赖相比宽依赖更高效资源消耗更少</span></p><p><span style="font-family:'宋体';">允许在单个集群节点上流水线式执行，这个节点可以计算所有父级分区。例如，可以逐个元</span>   <span style="font-family:'宋体';">素地依次执行</span>filter<span style="font-family:'宋体';">操作和</span><span style="font-family:Calibri;">map</span><span style="font-family:'宋体';">操作。</span></p><p><span style="font-family:'宋体';">例如基于一对一的关系，可以在</span>filter<span style="font-family:'宋体';">之后执行</span><span style="font-family:Calibri;">map</span><span style="font-family:'宋体';">。</span></p><p> </p><p><span style="font-family:'宋体';">相反，宽依赖需要所有的父</span>RDD<span style="font-family:'宋体';">数据可用并且数据已经通过类</span><span style="font-family:Calibri;">MapReduce</span><span style="font-family:'宋体';">的操作</span><span style="font-family:Calibri;">shuffle</span><span style="font-family:'宋体';">完   成。</span></p><p><span style="font-family:'宋体';">在窄依赖中，节点失败后的恢复更加高效</span>（<span style="font-family:'宋体';">窄依赖支持更高效的故障还原</span>）<span style="font-family:'宋体';">。</span></p><p><span style="font-family:'宋体';">因为只有丢失的父级分区需要重新计算，并且这些丢失的父级分区可以并行地在不同节点上</span>   <span style="font-family:'宋体';">重新计算。</span></p><p> </p><p><span style="font-family:'宋体';">与此相反，在宽依赖的继承关系中，单个失败的节点可能导致一个</span>RDD<span style="font-family:'宋体';">的所有先祖</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">中的   一些分区丢失，导致计算的重新执行。</span></p><p> </p><p><span style="font-family:'宋体';">对于宽依赖，一个结点的故障可能导致来自所有父</span>RDD<span style="font-family:'宋体';">的分区丢失，因此就需要完全重新执行。因此对于宽依赖，</span><span style="font-family:Calibri;">Spark</span><span style="font-family:'宋体';">会在持有各个父分区的结点上，将中间数据持久化来简化故障还原</span></p><h2><strong>RDD-compute </strong></h2><p>分区计算</p><p>Spark对RDD的计算是以partition<span style="font-family:'微软雅黑';">为最小单位的，并且都是对迭代器进行复合，不需要保存</span>   每次的计算结果</p><h2><strong>RDD- partitioner</strong></h2><p><span style="font-family:'微软雅黑';">分区函数：目前</span>spark中提供两种分区函数</p><p>HashPatitioner（哈希分区）</p><p>RangePatitioner（区域分区）</p><p><span style="font-family:'微软雅黑';">且</span>partitioner只存在于（K，V）类型的RDD中，rdd本身决定了分区的数量</p><h2><strong>RDD- lineage</strong></h2><p>val lines = sc.textFile("hdfs://...")</p><p>// transformed RDDs</p><p>val errors = lines.filter(_.startsWith("ERROR"))</p><p>val messages = errors.map(_.split("\t")).map(r =&gt; r(1)) messages.cache()</p><p>// action 1 messages.filter(_.contains("mysql")).count()</p><p>// action 2 messages.filter(_.contains("php")).count()</p><p> <img src="https://img-blog.csdn.net/20180401224907837" alt=""></p><p> </p><p>RDD经过trans或action后产生一个新的RDD，RDD之间的通过lineage来表达依赖关系，</p><p>lineage是rdd容错的重要机制，rdd转换后的分区可能在转换前分区的节点内存中</p><p> <img src="https://img-blog.csdn.net/20180401224920141" alt=""></p><h1><strong>RDD依赖关系的划分（stage）</strong></h1><h1><strong><span style="background:rgb(255,255,255);">RDD依赖关系的划分，RDD怎么被划分到一个stage里面？</span> </strong></h1><p>1. <span style="font-family:'宋体';">就是通过窄依赖和宽依赖来划分</span>stage<span style="font-family:'宋体';">的</span> <br>2.<span style="font-family:'宋体';">如果是窄依赖就他们放在一个</span><span style="font-family:Calibri;">Stage</span><span style="font-family:'宋体';">里面，遇到宽依赖就断开划分为另外一个</span><span style="font-family:Calibri;">stage </span><br>3.<span style="font-family:'宋体';">如</span><span style="font-family:Calibri;">workCount</span><span style="font-family:'宋体';">例子，就划分为了两个</span><span style="font-family:Calibri;">stage</span><span style="font-family:'宋体';">，在</span><span style="font-family:Calibri;">reduceByKey</span><span style="font-family:'宋体';">的时候断开了</span><span style="font-family:Calibri;"> </span><br>4.<span style="font-family:'宋体';">如下图，遇到</span><span style="font-family:Calibri;">groupByKey</span><span style="font-family:'宋体';">断开，为一个</span><span style="font-family:Calibri;">stage1</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">map</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">union</span><span style="font-family:'宋体';">为窄依赖遇到</span><span style="font-family:Calibri;">join</span><span style="font-family:'宋体';">断开划分为</span><span style="font-family:Calibri;">stage2</span><span style="font-family:'宋体';">，其余划分为</span><span style="font-family:Calibri;">stage3</span></p><p> <img src="https://img-blog.csdn.net/20180401224940213" alt=""></p><p><span style="color:rgb(153,153,153);background:rgb(238,240,244);"> </span></p><h1><strong><span style="font-family:'宋体';">典型</span>RDD特征</strong></h1><p>Spark <span style="font-family:'宋体';">中内建的几个 </span><span style="font-family:Calibri;">RDD </span><span style="font-family:'宋体';">举例来说</span></p><p> <img src="https://img-blog.csdn.net/20180401224957207" alt=""></p><p> </p><h1><strong><span style="font-family:'宋体';">不同角度看</span>RDD</strong></h1><p> <img src="https://img-blog.csdn.net/20180401225008595" alt=""></p><h1><strong>Scheduler Optimizations（调度优化）</strong></h1><p> <img src="https://img-blog.csdn.net/20180401225016817" alt=""></p><p><span style="font-family:'宋体';">调度优化，在同样的</span>Stage<span style="font-family:'宋体';">阶段内，基于内存进行迭代</span></p><h1><strong>Schedule </strong></h1><p> <img src="https://img-blog.csdn.net/20180401225033273" alt=""></p><p><span style="font-family:'宋体';">基于</span>RDD<span style="font-family:'宋体';">编程（通过</span><span style="font-family:Calibri;">DataFrame</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">DateSet</span><span style="font-family:'宋体';">来编程）</span> <br>1<span style="font-family:'宋体';">）</span><span style="font-family:Calibri;">RDD Objects</span><span style="font-family:'宋体';">生成</span><span style="font-family:Calibri;">DAG</span><span style="font-family:'宋体';">（有向无环图的依赖），图中示例的</span><span style="font-family:Calibri;">rdd1</span><span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">rdd2</span><span style="font-family:'宋体';">之间经过</span><span style="font-family:Calibri;">join</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">groupBy</span><span style="font-family:'宋体';">等若干</span><span style="font-family:Calibri;">lazy</span><span style="font-family:'宋体';">级别的</span><span style="font-family:Calibri;">transform</span><span style="font-family:'宋体';">操作</span><span style="font-family:Calibri;">,</span><span style="font-family:'宋体';">生成</span><span style="font-family:Calibri;">DAG</span><span style="font-family:'宋体';">有向无环图，</span><span style="font-family:Calibri;">DAG</span><span style="font-family:'宋体';">用来描述任务之间的先后关系。</span><span style="font-family:Calibri;"> </span><br>2<span style="font-family:'宋体';">）</span><span style="font-family:Calibri;">DAG</span><span style="font-family:'宋体';">作为输入递交给</span><span style="font-family:Calibri;">DAGScheduler</span><span style="font-family:'宋体';">。</span><span style="font-family:Calibri;">DAGScheduler</span><span style="font-family:'宋体';">根据</span><span style="font-family:Calibri;">DAG</span><span style="font-family:'宋体';">描述的任务内部的先后顺序和转换关系，进而被划分出不同的</span><span style="font-family:Calibri;">stage</span><span style="font-family:'宋体';">，得到了</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">内部的依赖关系，形成</span><span style="font-family:Calibri;">TaskSet</span><span style="font-family:'宋体';">。</span><span style="font-family:Calibri;"> </span><br>3<span style="font-family:'宋体';">）</span><span style="font-family:Calibri;">TaskSet</span><span style="font-family:'宋体';">再由底层调度器</span><span style="font-family:Calibri;">TaskScheduler</span><span style="font-family:'宋体';">通过</span><span style="font-family:Calibri;">cluster Manager</span><span style="font-family:'宋体';">来分配任务，把任务交给</span><span style="font-family:Calibri;">Worker</span><span style="font-family:'宋体';">执行。如果出错了或者慢任务，</span><span style="font-family:Calibri;">TaskScheduler</span><span style="font-family:'宋体';">需要不断重试。</span></p><h1><span style="font-family:'宋体';">总结</span></h1><p>RDD<span style="font-family:'宋体';">是</span><span style="font-family:Calibri;">Spark</span><span style="font-family:'宋体';">架构的基石。</span><span style="background:rgb(255,255,255);"> </span></p><h1><strong><span style="background:rgb(255,255,255);"><br></span> </strong></h1><p> </p>            </div>
                </div>