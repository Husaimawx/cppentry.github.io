---
layout:     post
title:      6.配置spark环境
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/chuan442616909/article/details/71915720				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p><span style="font-family:'宋体';"><span style="font-size:12px;">spark1:<span style="font-family:Arial;">Master、<span style="font-family:Arial;">Worker </span></span></span></span></p>
<p><span style="font-family:'宋体';"><span style="font-size:12px;"><span style="font-family:'宋体';">spark2:<span style="font-family:Arial;">Worker </span></span><br></span></span></p>
<p><span style="font-family:'宋体';"><span style="font-size:12px;"><span style="font-family:'宋体';"><span style="font-family:'宋体';">spark3:<span style="font-family:Arial;">Worker </span></span><br></span></span></span></p>
<p><span style="font-family:'宋体';"><span style="font-size:12px;">1.基本<span style="font-family:'宋体';">spark1</span>环境配置</span></span></p>
<p><span style="font-family:'宋体';"><span style="font-size:12px;">解压缩spark包：tarzxvf spark-1.3.0-bin-hadoop2.4.tgz</span></span></p>
<p><span style="font-family:'宋体';"></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:'宋体';"><span style="font-size:12px;">更改spark目录名：mvspark-1.3.0-bin-hadoop2.4 spark</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:'宋体';"><span style="font-size:12px;">设置spark环境变量</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;">vi .bashrc</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;">export SPARK_HOME=/usr/local/spark</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;">export PATH=$SPARK_HOME/bin</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;">exportCLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;">source .bashrc</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;"><br></span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;">2.修改spark-env.sh</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;">1、cd /usr/local/spark/conf</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;">2、cp spark-env.sh.templatespark-env.sh</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;">3、vi spark-env.sh</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;">export JAVA_HOME=/usr/java/latest</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;">export SCALA_HOME=/usr/local/scala</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;">exportSPARK_MASTER_IP=192.168.1.191</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;">export SPARK_WORKER_MEMORY=1g</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;">exportHADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;"><br></span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;">3.修改slaves文件</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;">vim slaves</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;"></span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;">spark1</span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;">spark2</span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;">spark3</span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><br></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;">4.安装集群</span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-family:'宋体';">另外两个节点进行一模一样的配置，使用scp将spark和.bashrc拷贝到spark2和spark3即可。</span><br></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-family:'宋体';"><br></span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-family:'宋体';">5.启动</span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-family:'宋体';"></span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;">1、在spark目录下的sbin目录</span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;">2、执行./start-all.sh</span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;">3、使用jps和8080端口可以检查集群是否启动成功</span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;">[root@spark1 sbin]# jps<br>
2200 QuorumPeerMain<span style="font-family:Arial;">(kafka -集群)</span><br>
1624 SecondaryNameNode(hdfs-集群)<br>
2599 Jps<br>
1780 ResourceManager<span style="font-family:Arial;">(yarn -集群）</span><br>
2342 Master*********************（spark-集群）<br>
2226 Kafka<br>
1367 NameNode<span style="font-family:Arial;">(hdfs-集群)</span><br>
1486 DataNode<span style="font-family:Arial;">(hdfs-集群)</span><br>
2483 Worker **************<span style="font-family:Arial;">（spark-集群）</span><br>
1877 NodeManager<span style="font-family:Arial;">(hdfs-集群)</span><br></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><br></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;">[root@spark2 spark1.3]# jps<br>
1151 NodeManager<span style="font-family:Arial;">(yarn -集群）</span><br>
1389 Worker<br>
1310 Kafka<br>
1280 QuorumPeerMain<br>
1485 Jps<br>
1044 DataNode<br></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><br></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;">[root@spark3 spark1.3]# jps<br>
1151 NodeManager<span style="font-family:Arial;">(yarn -集群）</span><br>
1304 Kafka<br>
1493 Jps<br>
1280 QuorumPeerMain<br>
1382 Worker<br>
1044 DataNode<br></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><br></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<br></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;">4、进入spark-shell查看是否正常</span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;">会进入到一个scala的shell命令行界面</span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;">[root@spark1 sbin]# spark-shell <br>
Spark assembly has been built with Hive, including Datanucleus jars on classpath<br>
17/05/13 23:20:57 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable<br>
17/05/13 23:20:57 INFO spark.SecurityManager: Changing view acls to: root<br>
17/05/13 23:20:57 INFO spark.SecurityManager: Changing modify acls to: root<br>
17/05/13 23:20:57 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)<br>
17/05/13 23:20:57 INFO spark.HttpServer: Starting HTTP Server<br>
17/05/13 23:20:57 INFO server.Server: jetty-8.y.z-SNAPSHOT<br>
17/05/13 23:20:57 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:39913<br>
17/05/13 23:20:57 INFO util.Utils: Successfully started service 'HTTP class server' on port 39913.<br>
Welcome to<br>
      ____              __<br>
     / __/__  ___ _____/ /__<br>
    _\ \/ _ \/ _ `/ __/  '_/<br>
   /___/ .__/\_,_/_/ /_/\_\   version 1.3.0<br>
      /_/<br><br><br>
Using Scala version 2.10.4 (Java HotSpot(TM) Client VM, Java 1.7.0_65)<br>
Type in expressions to have them evaluated.<br>
Type :help for more information.<br>
17/05/13 23:21:03 INFO spark.SparkContext: Running Spark version 1.3.0<br>
17/05/13 23:21:04 INFO spark.SecurityManager: Changing view acls to: root<br>
17/05/13 23:21:04 INFO spark.SecurityManager: Changing modify acls to: root<br>
17/05/13 23:21:04 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)<br>
17/05/13 23:21:04 INFO slf4j.Slf4jLogger: Slf4jLogger started<br>
17/05/13 23:21:04 INFO Remoting: Starting remoting<br>
17/05/13 23:21:05 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@spark1:51907]<br>
17/05/13 23:21:05 INFO util.Utils: Successfully started service 'sparkDriver' on port 51907.<br>
17/05/13 23:21:05 INFO spark.SparkEnv: Registering MapOutputTracker<br>
17/05/13 23:21:05 INFO spark.SparkEnv: Registering BlockManagerMaster<br>
17/05/13 23:21:05 INFO storage.DiskBlockManager: Created local directory at /tmp/spark-94d129a9-6648-4991-815c-379356745670/blockmgr-e56d32a4-58bb-46fd-a52b-47aa47f1933f<br>
17/05/13 23:21:05 INFO storage.MemoryStore: MemoryStore started with capacity 267.3 MB<br>
17/05/13 23:21:06 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-e4b6b925-8a8f-40dc-83e7-239a5576d55c/httpd-dedba235-059b-453a-9ec3-a5f83d9e9e29<br>
17/05/13 23:21:06 INFO spark.HttpServer: Starting HTTP Server<br>
17/05/13 23:21:06 INFO server.Server: jetty-8.y.z-SNAPSHOT<br>
17/05/13 23:21:06 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:44783<br>
17/05/13 23:21:06 INFO util.Utils: Successfully started service 'HTTP file server' on port 44783.<br>
17/05/13 23:21:06 INFO spark.SparkEnv: Registering OutputCommitCoordinator<br>
17/05/13 23:21:06 INFO server.Server: jetty-8.y.z-SNAPSHOT<br>
17/05/13 23:21:06 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040<br>
17/05/13 23:21:06 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.<br>
17/05/13 23:21:06 INFO ui.SparkUI: Started SparkUI at http://spark1:4040<br>
17/05/13 23:21:06 INFO executor.Executor: Starting executor ID &lt;driver&gt; on host localhost<br>
17/05/13 23:21:06 INFO executor.Executor: Using REPL class URI: http://192.168.1.191:39913<br>
17/05/13 23:21:06 INFO util.AkkaUtils: Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@spark1:51907/user/HeartbeatReceiver<br>
17/05/13 23:21:07 INFO netty.NettyBlockTransferService: Server created on 55860<br>
17/05/13 23:21:07 INFO storage.BlockManagerMaster: Trying to register BlockManager<br>
17/05/13 23:21:07 INFO storage.BlockManagerMasterActor: Registering block manager localhost:55860 with 267.3 MB RAM, BlockManagerId(&lt;driver&gt;, localhost, 55860)<br>
17/05/13 23:21:07 INFO storage.BlockManagerMaster: Registered BlockManager<br>
17/05/13 23:21:07 INFO repl.SparkILoop: Created spark context..<br>
Spark context available as sc.<br>
17/05/13 23:21:08 INFO repl.SparkILoop: Created sql context (with Hive support)..<br>
SQL context available as sqlContext.<br><br>
scala&gt; <br></span></p>
<br><p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-family:'宋体';"><br></span></span></p>
总结：到此为止 spark集群安装全部完成。更多细节请参考环境配置 1~6分部讲解<br><p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;"><br></span></span></p>
<p style="line-height:150%;vertical-align:baseline;">
<span style="font-family:Arial;"><span style="font-size:12px;"><br></span></span></p>
<br>            </div>
                </div>