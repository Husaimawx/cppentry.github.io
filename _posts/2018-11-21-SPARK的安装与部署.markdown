---
layout:     post
title:      SPARK的安装与部署
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>Spark 1.6.0 单机安装配置</p><h1>一、       约束条件如下</h1><p>Spark runs on Java7+, Python 2.6+ and R 3.1+. For the Scala API, Spark 1.6.0 uses Scala 2.10. Youwill need to use a compatible Scala version (2.10.x).</p><p>Spark 1.6  + Scala 2.10 </p><h1>二、   依赖安装</h1><p>1、JDK 1.8+  （前置安装）</p><p> </p><p>2、HADOOP 2.6.0+（前置安装）</p><p> </p><p>3、SCALA 2.10.+</p><p><a href="http://downloads.lightbend.com/scala/2.10.6/scala-2.10.6.tgz" rel="nofollow">http://downloads.lightbend.com/scala/2.10.6/scala-2.10.6.tgz</a></p><p>4、Spark -1.6.0 –bin-Hadoop</p><p>http://d3kbcqa49mib13.cloudfront.net/spark-1.6.3-bin-hadoop2.6.tgz</p><p> </p><h1>三、依赖安装</h1><p>n  <strong>配置ssh localhost</strong></p><p>确保已经安装openssh-server</p><p>yum –y install openssh-server</p><p>n  <strong>无密码登陆配置</strong></p><p>ssh-keygen -t rsa </p><p>cat~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys </p><p>如果已经生成过密钥，只需执行后两行命令。测试ssh localhost </p><p> </p><h1>四、安装scala</h1><p>n  <strong>解压scala安装包到任意目录：</strong></p><p>cd /opt/scala</p><p>tar -xzvfscala-2.10.6.tgz </p><p>n  <strong>编辑环境变量</strong></p><p>vim /etc/profile</p><p>exportSCALA_HOME=/home/tom/scala-2.10.6</p><p>exportPATH=$SCALA_HOME/bin:$PATH</p><p>n  <strong>使环境变量生效</strong></p><p>source/etc/profile</p><p>n  <strong>查看是否成功：</strong></p><p>scala -version</p><p> </p><h1>五、安装SPARK</h1><p>n  <strong>解压spark安装包到任意目录：</strong></p><p>cd /opt/spark</p><p>tar -xzvfspark-1.6.0-bin-hadoop2.6.tgz</p><p>mvspark-1.6.0-bin-hadoop2.6 spark-1.6.0</p><p>vim /etc/profile</p><p>n  <strong>在 /etc/profile 文件的末尾添加环境变量： </strong></p><p>exportSPARK_HOME=/opt/spark</p><p>exportPATH=$SPARK_HOME/bin:$PATH</p><p>n  <strong>保存并更新 /etc/profile ： </strong></p><p>source/etc/profile</p><p> </p><h1>六、配置SPARK</h1><p>n  <strong>在conf目录下复制并重命名 spark-env.sh.template 为 spark-env.sh ：</strong></p><p>cpspark-env.sh.template spark-env.sh</p><p>vim spark-env.sh</p><p>n  <strong>在 spark-env.sh 中添加： </strong></p><p>export JAVA_HOME=/opt/jdk1.8/</p><p>exportSPARK_MASTER_IP=localhost</p><p>exportSPARK_WORKER_MEMORY=1G</p><p> </p><h1>七、启动与测试SPARK</h1><p>n  <strong>启动</strong></p><p>$SPARK_HOME/sbin/start-all.sh</p><p>n  <strong>测试Spark是否安装成功：</strong></p><p>$SPARK_HOME/bin/run-exampleSparkPi</p><p>n  <strong>得到结果：</strong></p><p>Pi is roughly 3.14716</p><p>n  <strong>检查页面： 是否安装成功</strong></p><p><a href="http://localhost/" rel="nofollow">http://localhost</a> :8080 </p><p>感谢科多大数据的同学们做的这个总结，分享给大家</p><p>Spark 1.6.0分布式安装配置</p><p> </p><h1>一、             *配置解释：</h1><p>JAVA_HOME 指定 Java 安装目录； </p><p>SCALA_HOME 指定 Scala 安装目录； </p><p>SPARK_MASTER_IP 指定 Spark 集群 Master 节点的 IP 地址； </p><p>SPARK_WORKER_MEMORY 指定的是 Worker 节点能够分配给Executors 的最大内存大小； </p><p>#HADOOP_CONF_DIR 指定 Hadoop 集群配置文件目录。 </p><p> </p><h1>二、             基于单机集群：</h1><p>一、主节点配置：</p><p>1，  添加配置到 spark-env.sh文件</p><p>export HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop</p><p>2，  <span style="color:#000000;">将</span><span style="color:#000000;"> slaves.template </span><span style="color:#000000;">拷贝到</span><span style="color:#000000;"> slaves</span><span style="color:#000000;">，</span><span style="color:#000000;">编辑其内容为：</span></p><p><code><span style="color:#000000;">hadoop1</span></code></p><p><code><span style="color:#000000;">hadoop2</span></code></p><p><code><span style="color:#000000;">hadoop3</span></code></p><p><span style="color:#000000;">(</span><span style="color:#000000;">不同机器名的，记得更改)</span></p><p><span style="color:#000000;"> </span></p><p><span style="color:#000000;">二、从节点配置</span></p><p><span style="color:#000000;"> </span></p><p><span style="color:#000000;">拷贝主节点配置到其他节点，并且修改环境变量</span></p><p><span style="color:#000000;"> </span></p><h1>三、             启动集群</h1><p>1) 启动  Master 节点</p><p>运行 start-master.sh</p><p>2) 启动  Slave 节点</p><p>运行 start-slaves.sh</p><p> </p><p> </p><h1>四、             验证集群</h1><p>通过 8080端口能够看到  worker数量为 3</p><p><br></p><p><br></p>            </div>
                </div>