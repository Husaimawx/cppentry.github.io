---
layout:     post
title:      Hadoop命令手册使用指南
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>在学习Hadoop的过程中，你可能经常遇到Hadoop命令方面的问题，本节就向大家介绍一些常用的Hadoop命令，欢迎大家一起来学习。</p>
<p>Hadoop命令手册</p>
<p>所有的hadoop命令均由bin/hadoop脚本引发。不指定参数运行hadoop脚本会打印所有命令的描述。<br>
用法：hadoop[--configconfdir][COMMAND][GENERIC_OPTIONS][COMMAND_OPTIONS]<br>
Hadoop有一个选项解析框架用于解析一般的选项和运行类。</p>
<p>命令选项描述<br>
--configconfdir覆盖缺省配置目录。缺省是${HADOOP_HOME}/conf。<br>
GENERIC_OPTIONS多个命令都支持的通用选项。<br>
COMMAND<br>
命令选项S各种各样的命令和它们的选项会在下面提到。这些命令被分为用户命令管理命令两组。</p>
<p><strong>Hadoop命令常规选项</strong></p>
<p>下面的选项被dfsadmin,fs,fsck和job支持。应用程序要实现Tool来支持常规选项。<br>
GENERIC_OPTION描述<br>
-conf&lt;configurationfile&gt;指定应用程序的配置文件。<br>
-D&lt;property=value&gt;为指定property指定值value。<br>
-fs&lt;local|namenode:port&gt;指定namenode。<br>
-jt&lt;local|jobtracker:port&gt;指定jobtracker。只适用于job。<br>
-files&lt;逗号分隔的文件列表&gt;指定要拷贝到mapreduce集群的文件的逗号分隔的列表。只适用于job。<br>
-libjars&lt;逗号分隔的jar列表&gt;指定要包含到classpath中的jar文件的逗号分隔的列表。只适用于job。<br>
-archives&lt;逗号分隔的archive列表&gt;指定要被解压到计算节点上的档案文件的逗号分割的列表。只适用于job。</p>
<p><strong>用户命令</strong></p>
<p>hadoop集群用户的常用命令。<br>
archive<br>
创建一个hadoop档案文件。参考HadoopArchives.<br>
用法：hadooparchive-archiveNameNAME&lt;src&gt;*&lt;dest&gt;</p>
<p>命令选项描述<br>
-archiveNameNAME要创建的档案的名字。<br>
src文件系统的路径名，和通常含正则表达的一样。<br>
dest保存档案文件的目标目录。</p>
<p>distcp<br>
Hadoop命令distcp用于递归地拷贝文件或目录。参考DistCp指南以获取等多信息。<br>
用法：hadoopdistcp&lt;srcurl&gt;&lt;desturl&gt;</p>
<p>命令选项描述<br>
srcurl源Url<br>
desturl目标Url</p>
<p>fs</p>
<p>用法：hadoopfs[GENERIC_OPTIONS][COMMAND_OPTIONS]<br>
运行一个常规的文件系统客户端。<br>
各种命令选项可以参考HDFSShell指南。</p>
<p>fsck<br>
Hadoop命令主要用来运行HDFS文件系统检查工具。参考Fsck了解更多。<br>
用法：hadoopfsck[GENERIC_OPTIONS]&lt;path&gt;[-move|-delete|-openforwrite][-files[-blocks[-locations|-racks]]]</p>
<p>命令选项描述<br>
&lt;path&gt;检查的起始目录。<br>
-move移动受损文件到/lost+found<br>
-delete删除受损文件。<br>
-openforwrite打印出写打开的文件。<br>
-files打印出正被检查的文件。<br>
-blocks打印出块信息报告。<br>
-locations打印出每个块的位置信息。<br>
-racks打印出data-node的网络拓扑结构。</p>
<p>jar</p>
<p>Hadoop命令主要用来运行jar文件。用户可以把他们的MapReduce代码捆绑到jar文件中，使用这个命令执行。<br>
用法：hadoopjar&lt;jar&gt;[mainClass]args...<br>
streaming作业是通过这个命令执行的。参考Streamingexamples中的例子。<br>
Wordcount例子也是通过jar命令运行的。参考Wordcountexample。</p>
<p>job</p>
<p>用于和MapReduce作业交互和命令。<br>
用法：hadoopjob[GENERIC_OPTIONS][-submit&lt;job-file&gt;]|[-status&lt;job-id&gt;]|[-counter&lt;job-id&gt;&lt;group-name&gt;&lt;counter-name&gt;]|[-kill&lt;job-id&gt;]|[-events&lt;job-id&gt;&lt;from-event-#&gt;&lt;#-of-events&gt;]|[-history[all]&lt;jobOutputDir&gt;]|[-list[all]]|[-kill-task&lt;task-id&gt;]|[-fail-task&lt;task-id&gt;]</p>
<p>命令选项描述<br>
-submit&lt;job-file&gt;提交作业<br>
-status&lt;job-id&gt;打印map和reduce完成百分比和所有计数器。<br>
-counter&lt;job-id&gt;&lt;group-name&gt;&lt;counter-name&gt;打印计数器的值。<br>
-kill&lt;job-id&gt;杀死指定作业。<br>
-events&lt;job-id&gt;&lt;from-event-#&gt;&lt;#-of-events&gt;打印给定范围内jobtracker接收到的事件细节。<br>
-history[all]&lt;jobOutputDir&gt;-history&lt;jobOutputDir&gt;打印作业的细节、失败及被杀死原因的细节。更多的关于一个作业的细节比如成功的任务，做过的任务尝试等信息可以通过指定[all]选项查看。<br>
-list[all]-listall显示所有作业。-list只显示将要完成的作业。<br>
-kill-task&lt;task-id&gt;杀死任务。被杀死的任务不会不利于失败尝试。<br>
-fail-task&lt;task-id&gt;使任务失败。被失败的任务会对失败尝试不利。本节有关Hadoop命令简单介绍到这里。</p>
<p>【编辑推荐】</p>
<ol><li><a href="http://developer.51cto.com/art/201006/203761.htm" rel="nofollow">常见Hadoop Shell命令用法详解</a></li><li><a href="http://developer.51cto.com/art/201006/203746.htm" rel="nofollow">Hadoop MapReduce的简单应用Cascading详解</a></li><li><a href="http://developer.51cto.com/art/201005/201623.htm" rel="nofollow">Hadoop集群与Hadoop性能优化</a></li><li><a href="http://developer.51cto.com/art/201006/203663.htm" rel="nofollow">HadoopHBase实现配置简单的单机环境</a></li><li><a href="http://developer.51cto.com/art/201006/203744.htm" rel="nofollow">如何实现Cassandra与Hadoop MapReduce的整合？</a></li></ol>            </div>
                </div>