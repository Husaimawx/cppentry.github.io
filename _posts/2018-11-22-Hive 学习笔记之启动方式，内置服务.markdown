---
layout:     post
title:      Hive 学习笔记之启动方式，内置服务
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p><strong>一、Hive介绍</strong></p>

<p>　　Hive是基于Hadoop的一个数据仓库，Hive能够将SQL语句转化为MapReduce任务进行运行。</p>

<p>　　Hive架构图分为以下四部分。</p>

<p>　　<img alt="" class="has" height="231" src="https://images2017.cnblogs.com/blog/93998/201711/93998-20171116205206937-1496676969.png" width="331"> </p>

<p>　　<em><strong>1、用户接口</strong></em></p>

<p>　　　 Hive有三个用户接口：</p>

<ul><li>
	<ul><li>命令行接口（CLI）:以命令行的形式输入SQL语句进行数据数据操作</li>
		<li>Web界面：通过Web方式进行访问。　　　　　</li>
		<li>Hive的远程服务方式：通过JDBC等方式进行访问。　　　　　　　　　　　　　　</li>
	</ul></li>
</ul><p>　　<em><strong>2、元数据存储</strong></em></p>

<p>　　　 将元数据存储在关系数据库中（MySql、Derby），元数据包括表的属性、表的名称、表的列、分区及其属性以及表数据所在的目录等。</p>

<p>　　<em><strong>3、解释器、编译器、优化器</strong></em></p>

<p>　　　 分别完成SQL查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在HDFS中，并在随后由MapReduce调用执行。</p>

<p>　　<em><strong>4、数据存储</strong></em></p>

<p>　　　 Hive没有专门的数据存储格式，也没有为数据建立索引，Hive中所有数据都存储在HDFS中。</p>

<p>　　　 Hive包含以下数据模型：表、外部表、分区和桶</p>

<p><strong>二、Metadata，Metastore 的作用</strong></p>

<p>　　<strong><em>Metadata即元数据:</em></strong>   元数据包含用Hive创建的database、tabel等的元信息。元数据存储在关系型数据库中。如Derby、MySQL等。</p>

<p>　　<em><strong>Metastore的作用是:</strong></em>  客户端连接metastore服务，metastore再去连接MySQL数据库来存取元数据。</p>

<p>　　有了metastore服务，就可以有多个客户端同时连接，而且这些客户端不需要知道MySQL数据库的用户名和密码，只需要连接metastore 服务即可。</p>

<p><strong>三、Hive的元数据存储(Metastore三种配置方式)</strong></p>

<p><strong>　　</strong>由于元数据不断地修改、更新，所以Hive元数据不适合存储在HDFS中，一般存在RDBMS中。</p>

<p>　　 <em><strong>1、内嵌模式（Embedded）</strong></em></p>

<p>　　　  hive服务和metastore服务运行在同一个进程中，derby服务也运行在该进程中.</p>

<p>　　　  内嵌模式使用的是内嵌的Derby数据库来存储元数据，也不需要额外起Metastore服务。</p>

<p>　　　  这个是默认的，配置简单，但是一次只能一个客户端连接，适用于用来实验，不适用于生产环境。</p>

<p> 　　<em><strong>2、本地模式（Local）:本地安装mysql 替代derby存储元数据</strong></em></p>

<p>　　　　这种安装方式和嵌入式的区别在于，不再使用内嵌的Derby作为元数据的存储介质，而是使用其他数据库比如MySQL来存储元数据。</p>

<p>　　　　hive服务和metastore服务运行在同一个进程中，mysql是单独的进程，可以同一台机器，也可以在远程机器上。</p>

<p>　　　　这种方式是一个多用户的模式，运行多个用户client连接到一个数据库中。这种方式一般作为公司内部同时使用Hive。</p>

<p>　　　　每一个用户必须要有对MySQL的访问权利，即每一个客户端使用者需要知道MySQL的用户名和密码才行。</p>

<pre>
　　<strong>&lt;</strong><strong>property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
        &lt;value&gt;jdbc:mysql://127.0.0.1:3306/hive? createDatabaseIfNotExit=true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
        &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
        &lt;value&gt;root&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
        &lt;value&gt;root&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
    　　&lt;name&gt;hive.metastore.uris&lt;/name&gt;
    　　&lt;value&gt;&lt;/value&gt;
    　　&lt;description&gt;指向的是运行metastore服务的主机,这是hive客户端配置，metastore服务不需要配置&lt;/description&gt;
  　&lt;/property&gt;
    &lt;property&gt;
    　　&lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;
    　　&lt;value&gt;/user/hive/warehouse&lt;/value&gt;
    　　&lt;description&gt;hive表的默认存储路径,为HDFS的路径location of default database for the warehouse&lt;/description&gt;
    &lt;/property&gt;</strong>
</pre>

<p>　　<em><strong>3、远程模式（Remote）: 远程安装mysql 替代derby存储元数据</strong></em></p>

<p>　　　　Hive服务和metastore在不同的进程内，可能是不同的机器，该模式需要将hive.metastore.local设置为false，将hive.metastore.uris设置为metastore服务器URL，</p>

<p>　　　　如果有多个metastore服务器，将URL之间用逗号分隔，metastore服务器URL的格式为thrift://127.0.0.1:9083。</p>

<p>　　　　远程元存储需要单独起metastore服务，然后每个客户端都在配置文件里配置连接到该metastore服务。</p>

<p>　　　　将metadata作为一个单独的服务进行启动。各种客户端通过beeline来连接，连接之前无需知道数据库的密码。</p>

<p>　　　　仅连接远程的mysql并不能称之为“远程模式”，是否远程指的是metastore和hive服务是否在同一进程内.</p>

<p>　　　　hive metastore 服务端启动命令：<br><code>　　　　<strong>hive --service metastore -p &lt;port_num&gt;</strong></code><br>
　　　　如果不加端口默认启动：<code>hive --service metastore</code>，则默认监听端口是：9083 。</p>

<p>　　　　注意客户端中的端口配置需要和启动监听的端口一致。服务端启动正常后，客户端就可以执行hive操作了。</p>

<p>　　 　  <em>客户端连接metastore服务配置如下</em>：</p>

<pre>
　<strong>&lt;</strong><strong>property&gt;
    &lt;name&gt;hive.metastore.uris&lt;/name&gt;
    &lt;value&gt;thrift://127.0.0.1:9083，thrift://127.0.0.1:9084&lt;/value&gt;
    &lt;description&gt;指向的是运行metastore服务的主机&lt;/description&gt;
  &lt;/property&gt;</strong></pre>

<p><strong>　　</strong>在服务器端启动一个MetaStoreServer，客户端利用Thrift协议通过MetaStoreServer访问元数据库。如下图：<strong>　　　　</strong></p>

<p><strong>　　<img alt="" class="has" height="112" src="https://images2017.cnblogs.com/blog/93998/201711/93998-20171117212235718-2061466074.png" width="327"></strong></p>

<p><strong>四、Thrift 服务 </strong></p>

<p>　　通过hiveServer/hiveServer2启动Thrift服务，客户端连接Thrift服务访问Hive数据库（JDBC，JAVA等连接Thrift服务访问Hive）。</p>

<pre>
　<strong>&lt;</strong><strong>property&gt;
    &lt;name&gt;hive.server2.thrift.port&lt;/name&gt;
    &lt;value&gt;&lt;/value&gt;
    &lt;description&gt;Port number of HiveServer2 Thrift interface when hive.server2.transport.mode is 'binary'.&lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hive.server2.thrift.bind.host&lt;/name&gt;
    &lt;value&gt;127.0.0.1&lt;/value&gt;
    &lt;description&gt;Bind host on which to run the HiveServer2 Thrift service.&lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hive.server2.enable.doAs&lt;/name&gt;
    &lt;value&gt;false&lt;/value&gt;
    &lt;description&gt;
      Setting this property to true will have HiveServer2 execute
      Hive operations as the user making the calls to it.
　　　 如果为True：Hive Server会以提交用户的身份去执行语句
　　　 如果为False：会以hive server daemon的admin user来执行语句

    &lt;/description&gt;
  &lt;/property&gt;</strong></pre>

<p><strong>　　启动Thrift服务：</strong><strong>hive --service hiveserver2</strong></p>

<p>　　 测试Thrift服务：</p>

<p>　　 新开一个命令行窗口，执行beeline命令：</p>

<pre>
shuwendeMBP:~ shuwen$ beeline
Beeline version 1.2.1.spark2 by Apache Hive
beeline&gt; !<strong>connect jdbc:hive2://127.0.0.1:10000</strong>
Connecting to jdbc:hive2://127.0.0.1:10000
Enter username for jdbc:hive2://127.0.0.1:10000: shuwen
Enter password for jdbc:hive2://127.0.0.1:10000: ******
log4j:WARN No appenders could be found for logger (org.apache.hive.jdbc.Utils).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
Connected to: Apache Hive (version 1.2.2)
Driver: Hive JDBC (version 1.2.1.spark2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
0: jdbc:hive2://127.0.0.1:10000&gt; show databases;
+----------------+--+
| database_name  |
+----------------+--+
| db_2_1         |
| default        |
| netuml         |
+----------------+--+
3 rows selected (1.941 seconds)</pre>

<p> </p>

<p><strong>五、Hive的三种启动方式</strong></p>

<p> 　　<strong>1、hive 命令行模式</strong></p>

<p>　　　　进入hive安装目录，输入bin/hive的执行程序，或者输入 hive –service cli，用于linux平台命令行查询，查询语句基本跟mysql查询语句类似</p>

<p>　　 <strong>2、hive web界面的启动方式</strong></p>

<p><strong>　　　　</strong>Hive 2.0 以后才支持Web UI的</p>

<p>　　　　bin/hive –service hwi （&amp; 表示后台运行）</p>

<p>　　　　用于通过浏览器来访问hive，感觉没多大用途，浏览器访问地址是：127.0.0.1:9999/hwi</p>

<p>　　 <strong>3、hive 远程服务 (端口号10000) 启动方式 （Thrift服务）</strong></p>

<p>　　　  bin/hive –service hiveserver2 &amp;（&amp;表示后台运行）</p>

<p>　　　  用java，python等程序实现通过jdbc等驱动的访问hive就用这种起动方式了，这个是程序员最需要的方式了</p>

<p> </p>

<p><strong>六、Hive几种内置服务 </strong></p>

<p>　　执行bin/hive --service help 如下：</p>

<pre>
shuwendeMBP:~ shuwen$ hive --service help
Usage ./hive &lt;parameters&gt; --service serviceName &lt;service parameters&gt;
Service List: beeline cli help hiveburninclient hiveserver hiveserver2 hwi jar lineage metastore metatool orcfiledump rcfilecat schemaTool version 
Parameters parsed:
  --auxpath : Auxillary jars 
  --config : Hive configuration directory
  --service : Starts specific service/component. cli is default
Parameters used:
  HADOOP_HOME or HADOOP_PREFIX : Hadoop install directory
  HIVE_OPT : Hive options
For help on a particular service:
  ./hive --service serviceName --help
Debug help:  ./hive --debug --help</pre>

<p>　　我们可以看到上边输出项Server List，里边显示出Hive支持的服务列表，beeline cli help hiveserver2 hiveserver hwi jar lineage metastore metatool orcfiledump rcfilecat。</p>

<p>　　下面介绍最有用的一些服务</p>

<p>　　1、cli：是Command Line Interface 的缩写，是Hive的命令行界面，用的比较多，是默认服务，直接可以在命令行里使用。</p>

<p>　　3、hwi：其实就是hive web interface的缩写它是hive的web借口，是hive cli的一个web替代方案。</p>

<p>　　2、hiveserver：这个可以让Hive以提供Thrift服务的服务器形式来运行，可以允许许多个不同语言编写的客户端进行通信，使用需要启动HiveServer服务以和客户端联系，</p>

<p>　　　 我们可以通过设置HIVE_PORT环境变量来设置服务器所监听的端口，在默认情况下，端口号为10000，这个可以通过以下方式来启动Hiverserver：</p>

<p>　　　 bin/hive --service hiveserver -p 10002</p>

<p>　　　 其中-p参数也是用来指定监听端口的<br>
　　<br>
　　4、jar：与hadoop jar等价的Hive接口，这是运行类路径中同时包含Hadoop 和Hive类的Java应用程序的简便方式</p>

<p>　　5、metastore：在默认的情况下，metastore和hive服务运行在同一个进程中，使用这个服务，可以让metastore作为一个单独的进程运行。</p>

<p>　　　 我们可以通过METASTOE——PORT来指定监听的端口号</p>

<p> </p>

<p><strong> 七、问题总结</strong></p>

<blockquote>
<p><strong>Could not create ServerSocket on address 0.0.0.0/0.0.0.0:9083</strong></p>

<p>遇到这种情况大家都找不到头绪，是因为你开始运行了hive的metastore，可以输入jps<br>
查看有没有RunJar<br>
然后再输入<br>
hive --service metastore启动</p>
</blockquote>

<p> </p>

<blockquote>
<p><strong>Hive在spark2.0.0启动时无法访问spark-assembly-*.jar的解决办法</strong></p>

<p>ls: /usr/local/share/spark-2.0.0-bin-hadoop2.7/lib/spark-assembly-*.jar: No such file or directory<br>
发现主要原因是：在/&lt;PathToHive&gt;/bin/hive文件中，有这样的命令：加载spark中相关的JAR包</p>

<pre>
if [[ -n "$SPARK_HOME" ]]
then
sparkAssemblyPath=`ls ${SPARK_HOME}/lib/spark-assembly-*.jar`
CLASSPATH="${CLASSPATH}:${sparkAssemblyPath}"
fi</pre>

<p>但是spark升级到spark2以后，原有lib目录下的大JAR包被分散成多个小JAR包，原来的spark-assembly-*.jar已经不存在，所以hive没有办法找到这个JAR包。</p>

<p>解决方法:修改/&lt;PathToHive&gt;/bin/hive文件，将加载原来的lib/spark-assembly-*.jar`替换成jars/*.jar，就不会出现这样的问题。</p>
</blockquote>

<p> </p>

<p> </p>

<blockquote>
<p>1.hive.metastore.uris指向的是运行metastore服务的主机，并不是指向运行hiveserver的主机，那台主机不用启动hiveserver也ok；</p>

<p>2.直接使用hive命令启动shell环境时，其实已经顺带启动了hiveserver，所以远程模式下其实只需要单独启动metastore，然后就可以进入shell环境正常使用</p>

<p>3.hiveserver和metastore进程名都叫RunJar。</p>
</blockquote>

<p> 转自：<a href="https://www.cnblogs.com/netuml/p/7841387.html" rel="nofollow">https://www.cnblogs.com/netuml/p/7841387.html</a></p>            </div>
                </div>