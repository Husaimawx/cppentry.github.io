---
layout:     post
title:      大数据学习七
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>SPARK</p>
<p>1、Spark的生态系统</p>
<p>    Spark Core:engine</p>
<p>    Spark SQL :交互式查询</p>
<p>    Spark Streaming：流式计算</p>
<p>    MLLib:机器学习和数据挖掘</p>
<p>    GraphX:图计算</p>
<p>2、基本概念</p>
<p>   RDD：分布式内存的一个抽象</p>
<p>   DAG:有向无环图，反映RDD之间的依赖关系</p>
<p>   Executor：运行在工作节点上的一个进程，负责运行具体的Task；</p>
<p>   Application：用户编写的程序</p>
<p>   Task：运行在Executor上的工作单元</p>
<p>   Job：一个Job包含多个RDD以及作用于相应RDD上的操作</p>
<p>   Stage：是Job调度的基本单元，一个Job会分为多组Task，每一组Task称为Stage。</p>
<p>  3、Spark运行架构包括：</p>
<p>     集群资源管理器cluster Manager，可以自带的Mesos，也可以基于YARN</p>
<p>    工作节点Worker Node</p>
<p>    每个应用的控制节点Driver</p>
<p>   每个节点上负责具体任务的执行进程Executor</p>
<p>4、Executor的两个优点：</p>
<p>     一是可以多线程，减少任务的启动开销；</p>
<p>     二是Executor中有一个BlockManager存储模块，会将内存和磁盘共同作为存储设备，有效减少IO开销。</p>
<p>5、一个Application由一个Driver和若干个Job构成，一个Job有若干个Stage，一个Stage由若干个没有shuffle关系的Task组成。</p>
<p>    当执行一个Application时，Driver向cluster manager申请资源，启动Executor，并向Executor发送应用程序代码和文件，在后在Executor上执行Task，运行结束后，结果返回给Driver，或者写到HDFS中。</p>
<p>6、Spark运行的基本流程</p>
<p>    1）首先由Driver创建一个Spark context, 进行资源申请、任务的分配和监控；</p>
<p>    2）资源管理器为Executor分配资源，并启动Executor；</p>
<p>    3）SparkContext根据RDD的依赖关系构建DAG图，DAG图交给DAGScheduler解析成Stage，然后交给底层的TaskScheduler处理，Task Scheduler将Task发放给Executor运行，并提供相关代码；</p>
<p>   4）Task在Executor上执行，并把结果反馈给TaskScheduler，然后TaskScheduler反馈给DAGScheduler，运行完后写入数据并释放所有资源。</p>
<p>7、Spark运行架构的特点：</p>
<p>    1）每一个Application都有自己的Executor进程，并且Executor在Application运行期间一直驻留。Executor以多线程方式运行Task。</p>
<p>    2）Spark运行过程与资源管理器无关，只要能够获取Executor进程，并保持通信就成。</p>
<p>    3）Task采用了数据本地性和推测执行等优化机制。</p>
<p>8、RDD概念</p>
<p>    RDD本质上是一个只读的分区记录集合，不能直接修改，每个分区就是一个数据集片段，并且一个RDD的不同分区可以来自不同的节点。</p>
<p>9、RDD的运行原理</p>
<p>    RDD提供了一组丰富的操作支持常见的数据运算，分为“Action”和“Transformation”两种类型，并且RDD的转换接口的都死Map、Filter、groupby，join等粗粒度的数据转换操作。</p>
<p>    Scala语言实现了RDD的API，可以通过Scala可以实现对RDD的操作。</p>
<p>RDD典型当执行过程：</p>
<p>   RDD读入外部数据源进行创建；</p>
<p>   RDD经过一些列的转换操作，每一次操作都产生不同的RDD，供下一个转换使用；</p>
<p>   最后一个RDD经过Action操作转换，输出到外部数据源。</p>
<p>  这一系列的处理称为学院关系，即DAG拓扑排序的结果。优点：惰性调用，管道化，避免同步等待，不需要保存中间结果，每次操作变得简单。</p>
<p>10、RDD设计的特性</p>
<p>   1）高效的容错性</p>
<p>      血缘关系只需要找到父亲节点，不需要重新计算丢失分区，无需回滚操作。</p>
<p>   2）中间结果保存到内存中，数据在多个RDD之间进行传递，避免了不必要的磁盘读写开销；</p>
<p>   3）存放的对象可以是Java对象，无需对象的序列化和反序列化。</p>
<p>11、RDD的依赖关系</p>
<p>    窄依赖关系：一个父RDD的分区对应于一个子RDD的分区或者多个父RDD对应于一个子RDD分区</p>
<p>    宽依赖：一个父RDD的分区对应于一个子RDD的多个分区。</p>
<p>12、Stage的划分</p>
<p>   Spark通过分析各个RDD的依赖关系生产了DAG，在通过分析各个RDD中的分区之间的依赖关系决定如何划分Stage，具体的划分是：</p>
<p>   在DAG反解析过程中，遇到宽依赖就断开；</p>
<p>   遇到窄依赖就把当前的RDD加入到Stage；</p>
<p>    将窄依赖尽量划分到同一个Stage中，可以实现流水线计算。</p>
<p>  Stage的类型包含两种：ShuffleMapStage和ResultStage，</p>
<p>    ShuffleMapStage：不是最终的Stage，在他之后还有别的Stage，所以她的输出需要经过Shuffle处理，并作为后续Stage的输入；这种Stage以Shuffle为输出边界，输入可以是外部数据源，也可以是别的ShuffleMapStage的输出；在一个Job里，可能有这种Stage存在；</p>
<p>    ResultStage是最终的Stage，没有输出，直接将结果存储。一个Job里必须有这种Stage。</p>
<p>   因此，一个Job可能包含一个或者多个Stage，但至少有一个ResultStage。</p>
<p><br></p>
<p>   </p>
            </div>
                </div>