---
layout:     post
title:      Hadoop - 03 - HDFS分布式文件系统
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，可以转载，但请注明出处。					https://blog.csdn.net/Simba_cheng/article/details/82765471				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p id="main-toc"><strong>目录</strong></p>

<p id="HDFS%E7%9A%84%E6%A6%82%E5%BF%B5-toc" style="margin-left:0px;"><a href="#HDFS%E7%9A%84%E6%A6%82%E5%BF%B5" rel="nofollow">HDFS的概念</a></p>

<p id="%E6%95%B0%E6%8D%AE%E5%9D%97-toc" style="margin-left:40px;"><a href="#%E6%95%B0%E6%8D%AE%E5%9D%97" rel="nofollow">数据块</a></p>

<p id="NameNode%E5%92%8CDataNode-toc" style="margin-left:40px;"><a href="#NameNode%E5%92%8CDataNode" rel="nofollow">NameNode和DataNode</a></p>

<p id="NameNode(Master)-toc" style="margin-left:80px;"><a href="#NameNode(Master)" rel="nofollow">NameNode(Master)</a></p>

<p id="Client%E5%AE%A2%E6%88%B7%E7%AB%AF-toc" style="margin-left:80px;"><a href="#Client%E5%AE%A2%E6%88%B7%E7%AB%AF" rel="nofollow">Client客户端</a></p>

<p id="DataNode(Slave)-toc" style="margin-left:80px;"><a href="#DataNode(Slave)" rel="nofollow">DataNode(Slave)</a></p>

<p id="HA%EF%BC%9AHDFS%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7-toc" style="margin-left:40px;"><a href="#HA%EF%BC%9AHDFS%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7" rel="nofollow">HA：HDFS的可靠性</a></p>

<p id="HDFS%20HA%E5%8E%9F%E5%9B%A0%E5%88%86%E6%9E%90-toc" style="margin-left:80px;"><a href="#HDFS%20HA%E5%8E%9F%E5%9B%A0%E5%88%86%E6%9E%90" rel="nofollow">HDFS HA原因分析</a></p>

<p id="%E7%8E%B0%E6%9C%89HDFS%20HA%20%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-toc" style="margin-left:80px;"><a href="#%E7%8E%B0%E6%9C%89HDFS%20HA%20%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88" rel="nofollow">现有HDFS HA 解决方案</a></p>

<p id="%E6%96%87%E4%BB%B6%E6%95%B0%E6%8D%AE%E5%92%8C%E5%85%83%E6%95%B0%E6%8D%AE-toc" style="margin-left:40px;"><a href="#%E6%96%87%E4%BB%B6%E6%95%B0%E6%8D%AE%E5%92%8C%E5%85%83%E6%95%B0%E6%8D%AE" rel="nofollow">文件数据和元数据</a></p>

<p id="%E5%85%83%E6%95%B0%E6%8D%AE-toc" style="margin-left:80px;"><a href="#%E5%85%83%E6%95%B0%E6%8D%AE" rel="nofollow">元数据</a></p>

<p id="%E6%96%87%E4%BB%B6%E6%95%B0%E6%8D%AE-toc" style="margin-left:80px;"><a href="#%E6%96%87%E4%BB%B6%E6%95%B0%E6%8D%AE" rel="nofollow">文件数据</a></p>

<p id="HDFS%20Java%20API-toc" style="margin-left:40px;"><a href="#HDFS%20Java%20API" rel="nofollow">HDFS Java API</a></p>

<p id="%E6%95%B0%E6%8D%AE%E6%B5%81-toc" style="margin-left:40px;"><a href="#%E6%95%B0%E6%8D%AE%E6%B5%81" rel="nofollow">数据流</a></p>

<p id="%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96-toc" style="margin-left:80px;"><a href="#%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96" rel="nofollow">文件读取</a></p>

<p id="%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5-toc" style="margin-left:80px;"><a href="#%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5" rel="nofollow">文件写入</a></p>

<hr id="hr-toc"><p> HDFS是Hadoop生态中的一个产品、组件，亦可作为单独使用。</p>

<p>这里暂不会对HDFS深入研究，而是从应用的角度去学习。</p>

<p>脚踏实地慢慢啃。</p>

<p>相关代码已经上传GitHub：<a href="https://github.com/Simba-cheng/HadoopCode" rel="nofollow">Hadoop相关完整示例代码</a>，如果觉得还不错，请点Star。</p>

<p> </p>

<p>在官方文档的引言中简略的介绍了HDFS：</p>

<blockquote>
<p>Hadoop<span style="color:#f33b45;">分布式文件系统</span>(HDFS)被设计成适合运行在通用硬件(commodity hardware)上的分布式文件系统。</p>

<p>HDFS是一个<span style="color:#f33b45;">高度容错性的系统</span>，适合部署在廉价的机器上。</p>

<p>HDFS能<span style="color:#f33b45;">提供高吞吐量的数据访问</span>，非常适合大规模数据集上的应用。</p>
</blockquote>

<p> </p>

<h1 id="HDFS%E7%9A%84%E6%A6%82%E5%BF%B5"><span style="color:#7c79e5;">HDFS的概念</span></h1>

<h2 id="%E6%95%B0%E6%8D%AE%E5%9D%97"><span style="color:#86ca5e;">数据块</span></h2>

<p>每个磁盘都有默认的数据块大小，这是磁盘进行数据读/写的最小单位。</p>

<p>构建于单个磁盘之上的文件系统(HDFS)通过磁盘块来管理该文件系统中的块，该文件系统块的大小可以是磁盘块的整数倍，磁盘块一般为512字节。</p>

<p>HDFS中同样有块(Block)的概念，但是大的多，默认为64MB。</p>

<blockquote>
<p><span style="color:#f33b45;">注：从2.7.3版本开始，官方关于Data Blocks 的说明中，block size由64 MB变成了128 MB。</span></p>
</blockquote>

<p>为何HDFS中的块(block)如此之大？</p>

<blockquote>
<p><span style="color:#f33b45;">HDFS的块比磁盘的块大，其目的是为了最小化寻址开销。</span></p>
</blockquote>

<p> </p>

<p> </p>

<h2 id="NameNode%E5%92%8CDataNode"><span style="color:#86ca5e;">NameNode和DataNode</span></h2>

<p>HDFS架构是主/从架构(Master/Slave)，即一个NameNode和多个DataNode。</p>

<p>HDFS暴露了文件系统的命名空间，用户能够以文件的形式在上面存储数据。</p>

<p>文件系统命名空间的层次结构和大多数现有的文件系统(Linux)类似：用户可以创建、删除、移动、重命名文件。</p>

<p><img alt="" class="has" height="513" src="https://img-blog.csdn.net/20180918224606280?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NpbWJhX2NoZW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="1045"></p>

<p><img alt="" class="has" height="317" src="https://img-blog.csdn.net/2018091822462310?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NpbWJhX2NoZW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="453"></p>

<p>[图片来自：《Hadoop实战》]</p>

<p> </p>

<h3 id="NameNode(Master)"><span style="color:#ffbb66;">NameNode(Master)</span></h3>

<p><span style="color:#f33b45;">NameNode存储文件的元数据</span>。</p>

<p>NameNode是整个文件系统的管理节点，它负责文件系统'命名空间(NameSpace)'的管理与维护；</p>

<p>比如：打开、关闭、重命名文件或目录，任何对文件系统命名空间或属性的修改都将被NameNode记录下来；</p>

<p>它也负责确定数据块(Block)到具体DataNode节点的映射，同时负责客户端文件操作的控制以及具体存储任务的管理与分配。<br>
 <br>
NameNode维护着文件系统树及整棵树内所有的文件和目录。</p>

<p>这些信息以两个文件形式永久保存在本地磁盘上：命名空间镜像文件 和 编辑日志文件。</p>

<p><span style="color:#e579b6;">NameNode也记录着每个文件中各个块所在的数据节点信息</span>，但它并不永久保存块的位置信息，因为这些信息会在系统启动时由数据节点重建。</p>

<p> </p>

<h3 id="Client%E5%AE%A2%E6%88%B7%E7%AB%AF"><span style="color:#ffbb66;">Client客户端</span></h3>

<p>它代表用户通过与NameNode与DataNode交互来访问整个文件系统。</p>

<p>Client提供了一个文件系统接口，因此用户在编程时无需知道NameNode和DataNode，也可实现其功能。</p>

<p> </p>

<h3 id="DataNode(Slave)"><span style="color:#ffbb66;">DataNode(Slave)</span></h3>

<p><span style="color:#f33b45;">DataNode存储了实际的数据(文件数据)</span>。</p>

<p>DataNode提供真实文件数据的存储服务。</p>

<p>负责处理文件系统客户端的读写请求。在NameNode的统一调度下进行数据块的创建、删除和复制。</p>

<p>DataNode是文件系统的工作节点。</p>

<p>它们根据需要存储并检索数据块(受客户端或NameNode调度)，并定期向NameNode发送它们所存储的块列表。</p>

<p>从 图9-1 可以看出，客户端Client联系NameNode，以获取文件的元数据或修饰属性，而真正的文件I/O操作是直接和DataNode进行交互的。</p>

<p> </p>

<p> </p>

<h2 id="HA%EF%BC%9AHDFS%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7"><span style="color:#86ca5e;">HA：HDFS的可靠性</span></h2>

<p>从上面对NameNode 和 DataNode的了解之后，可以想到：没有NameNode或NameNode故障后，文件系统将无法使用。</p>

<p>事实上，如果运行NameNode服务的机器损坏，文件系统上所有的文件将会丢失。</p>

<p>因此对NameNode实现容错非常重要，Hadoop为此提供了两种机制：</p>

<p>    • 备份数据持久状态元文件</p>

<p>    • 运行一个辅助的NameNode。</p>

<p><em>(此小节内容直接摘选复制，详细请查阅原书《HDFS—Hadoop分布式文件系统深度实践》)</em></p>

<p>HA的英文全称是 High Availability ，中文翻译为高可用性。</p>

<p>HA的定义为系统对外正常提供服务时间的百分比。</p>

<p>HA更多地是从系统对外的角度来说的，除了包含系统正常工作的能力，它还强调系统中止服务后迅速恢复的能力：一个可靠性很高的系统，如果其中止服务后，修复时间很长，那么它的可用性也不会很高，而一个可靠性不是特别高的系统，如果发生中止服务后，可迅速恢复，那么其可用性也可能会很高。</p>

<p>因此只有HA才能准确度量系统对外正常服务的能力。</p>

<p> </p>

<h3 id="HDFS%20HA%E5%8E%9F%E5%9B%A0%E5%88%86%E6%9E%90"><span style="color:#ffbb66;">HDFS HA原因分析</span></h3>

<p><u><strong><span style="color:#3399ea;">可靠性</span></strong></u></p>

<p>我们知道，HDFS由NameNode和DataNode两类节点组成，由于NameNode只有１个，且负责整个HDFS文件系统的管理和控制，因此当NameNode不能提供正常服务时，会直接导致HDFS不能对外正常服务，因此NameNode的可靠性是影响HDFS可靠性的重要因素。</p>

<p>由于NameNode只有一个，它的正常运行与否直接决定了HDFS能否正常服务，因此它也就成为了HDFS 系统的一个单一故障点（single point of failure——SPOF）</p>

<p>DataNode负责存储真实文件数据，每个文件可以指定副本个数，因此同一个文件可在多个DataNode上进行存储，当DataNode发生故障时，客户端可以访问其他DataNode上的副本，因此DataNode发生故障并不会影响HDFS对外正常服务。</p>

<p><strong><u><span style="color:#3399ea;">可维护性</span></u></strong></p>

<p>当NameNode不能正常服务时，通常需要重新启动NameNode来恢复服务，NameNode启动时需要加载磁盘上的元数据文件：</p>

<p>如果此时元数据没有损坏，那么直接启动NameNode就可以恢复HDFS对外正常服务；</p>

<p>如果元数据损坏，将导致NameNode无法启动，无法再对外正常服务，也就是说平均维护时间是无限大。</p>

<p>因此元数据的可靠性决定了HDFS的可维护时间。</p>

<p>当DataNode无法正常工作时，HDFS会自动启动该DataNode上所有数据的复制任务，将丢失的数据重新分布到其他DataNode上，因此DataNode并不影响HDFS的可维护性。</p>

<p>综上所述，HDFS的HA主要由NameNode的HA决定，NameNode的可靠性主要取决于自身计算机硬件系统的可靠性、系统软件以及HDFS 软件的可靠性；</p>

<p>NameNode的可维护性则取决于元数据的可靠性以及NameNode服务恢复时间。</p>

<p> </p>

<h3 id="%E7%8E%B0%E6%9C%89HDFS%20HA%20%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span style="color:#ffbb66;">现有HDFS HA 解决方案</span></h3>

<p>    1. Hadoop元数据备份</p>

<p>    2. Secondary NameNode方法</p>

<p>    3. Hadoop的Backup Node方案</p>

<p>    4. DRDB机制进行元数据备份</p>

<p>详情可以查阅原书。</p>

<p> </p>

<p> </p>

<h2 id="%E6%96%87%E4%BB%B6%E6%95%B0%E6%8D%AE%E5%92%8C%E5%85%83%E6%95%B0%E6%8D%AE"><span style="color:#86ca5e;">文件数据和元数据</span></h2>

<p>HDFS中有两种数据：文件数据和元数据</p>

<h3 id="%E5%85%83%E6%95%B0%E6%8D%AE"><span style="color:#ffbb66;">元数据</span></h3>

<p>元数据是指'数据'的数据，简单的说就是 'DataNode文件数据'的相关信息。</p>

<p>HDFS的元数据就是指维护HDFS文件系统中的文件和目录所需要的信息。</p>

<p>注意：</p>

<p>DataNode中具体的文件内容并不是元数据，元数据的可用性直接决定了HDFS的可用性。</p>

<p>从形式上讲，元数据可分为 内存元数据 和 元数据文件 两种。</p>

<p>内存元数据：NameNode在内存中维护整个文件系统的元数据镜像，用于HDFS的管理；</p>

<p>元数据文件：用于持久化存储。<br>
 <br>
从类型上讲，元数据有三类重要的信息：</p>

<p>一、第1类是 文件和目录自身的属性信息，例如：文件名、目录名、父目录信息、文件大小、创建时间等。</p>

<p>二、第2类是记录文件内容(Block)存储的相关信息，例如：文件分块情况、副本个数、每个副本所在的DataNode信息等。</p>

<p>三、第三类用来记录HDFS中所有DataNode的信息，用于DataNode管理。</p>

<p>元数据的主要来源于NameNode磁盘上的元数据文件，以及各个DataNode的上报信息。</p>

<p> </p>

<h3 id="%E6%96%87%E4%BB%B6%E6%95%B0%E6%8D%AE"><span style="color:#ffbb66;">文件数据</span></h3>

<p>文件数据指用户保存在HDFS上文件的具体内容。</p>

<p>HDFS将用户保存的文件按照大小进行分块(一块简称为一个Block)，并保存在各个DataNode上，每一个块(Block)可能会有多个副本，具体数量可以设置；</p>

<p>相同块对应的副本通常保存在不同的DataNode上，这样可以有效保证文件数据块的可靠性。</p>

<blockquote>
<p><span style="color:#f33b45;">注意：从2.7.3版本开始，官方关于Data Blocks 的说明中，block size由64 MB变成了128 MB。</span></p>
</blockquote>

<p> </p>

<p> </p>

<h2 id="HDFS%20Java%20API"><span style="color:#86ca5e;">HDFS Java API</span></h2>

<p>Hadoop文件系统中通过Hadoop Path对象来代表文件。</p>

<p>可以将路径视为一个Hadoop文件系统URL，例如：/HDFS-JAVA-API-Demo-01/input/hdfs-test02.txt</p>

<p><img alt="" class="has" height="330" src="https://img-blog.csdn.net/20180918225808303?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NpbWJhX2NoZW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="741"></p>

<p><em>(图片来自网络)</em></p>

<p>相关API 挺简单的，下面直接贴代码：</p>

<pre class="has">
<code class="language-java">package com.server;

import com.server.conf.LoadConfig;
import org.apache.commons.io.IOUtils;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.BlockLocation;
import org.apache.hadoop.fs.FSDataInputStream;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.PathFilter;
import org.apache.hadoop.hdfs.DistributedFileSystem;
import org.apache.hadoop.hdfs.protocol.DatanodeInfo;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.IOException;
import java.net.URI;
import java.text.SimpleDateFormat;
import java.util.Date;

/**
 * Java API 操作HDFS
 *
 * @author CYX
 */
public class HDFSApp {

    private static final Logger LOGGER = LoggerFactory.getLogger(HDFSApp.class);

    private static final String HDFS_PATH = "hdfs://192.168.137.160:9000";

    public static void main(String[] args) {

        try {
            LoadConfig.getInstance();
        } catch (Exception e) {
            System.exit(1);
        }

        try {

            //createFile();

            //copyFromLocalFile();

            //moveFromLocalFileAndDelete();

            //deleteDirectory();

            //isDirectory();

            //exist();

            //findAllDirectory();

            //createDirectory();

            //createMultiDirectory();

            //readerFile();

            //createMultiDirectory();

            //appendDataToHDFSFile();

            //globStatus();

            //renameHDFSFile();
            
            //getModificationTime();
            
            //getFileBlockLocation();
            
            //getHostName();
            
        } catch (Exception e) {
            LOGGER.error(e.getMessage(), e);
        }

    }

    /**
     * 创建一个文件，并写入数据
     */
    private static void createFile() {
        FSDataOutputStream fsDataOutputStream = null;
        try {
            Configuration configuration = new Configuration();
            FileSystem fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration);
            fsDataOutputStream = fileSystem.create(new Path("/HDFS-JAVA-API-Demo-01/input/test01.txt"));
            fsDataOutputStream.writeUTF("HelloWorld");
            fsDataOutputStream.flush();
            LOGGER.info("创建文件并写入数据成功");
        } catch (Exception e) {
            LOGGER.error("创建文件失败");
            LOGGER.error(e.getMessage(), e);
        } finally {
            try {
                fsDataOutputStream.close();
            } catch (IOException e) {
                LOGGER.error(e.getMessage(), e);
            }
        }
    }

    /**
     * 从本地拷贝文件到HDFS
     */
    private static void copyFromLocalFile() {

        try {
            Configuration configuration = new Configuration();
            FileSystem fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration);
            Path src = new Path("./file/test02.txt");
            Path dst = new Path("/HDFS-JAVA-API-Demo-01/input/");
            fileSystem.copyFromLocalFile(src, dst);
            LOGGER.info("本地文件拷贝至HDFS成功");
        } catch (Exception e) {
            LOGGER.error("拷贝失败");
            LOGGER.error(e.getMessage(), e);
        }
    }

    /**
     * 移动本地文件到HDFS,同时删除本地文件
     */
    private static void moveFromLocalFileAndDelete() {

        try {
            Configuration configuration = new Configuration();
            FileSystem fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration);

            Path src = new Path("./file/test02.txt");
            Path dst = new Path("/HDFS-JAVA-API-Demo-01/input/hdfs-test02.txt");

            fileSystem.moveFromLocalFile(src, dst);
            LOGGER.info("移动文件成功");

        } catch (Exception e) {
            LOGGER.error("移动文件失败");
            LOGGER.error(e.getMessage(), e);
        }
    }

    /**
     * 递归删除某个文件或某个文件夹
     */
    private static void deleteDirectory() {

        boolean result;
        try {
            Configuration configuration = new Configuration();
            FileSystem fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration);
            result = fileSystem.delete(new Path("/HDFS-JAVA-API-Demo-01"), true);
            LOGGER.info("result : {}", new Object[]{result});
        } catch (Exception e) {
            LOGGER.error("删除失败");
            LOGGER.error(e.getMessage(), e);
        }
    }

    /**
     * 查看某个路径是目录还是文件
     */
    private static void isDirectory() {

        boolean result = false;
        try {
            Configuration configuration = new Configuration();
            FileSystem fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration);

            Path path = new Path("/HDFS-JAVA-API-Demo-01/");
            result = fileSystem.isDirectory(path);

        } catch (Exception e) {
            LOGGER.error("检查异常");
            LOGGER.error(e.getMessage(), e);
        }
        LOGGER.info("该路径是否是目录:{}", new Object[]{result});
    }

    /**
     * 查看某个路径是否存在
     */
    private static void exist() {

        boolean result = false;
        try {
            Configuration configuration = new Configuration();
            FileSystem fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration);
            Path path = new Path("/HDFS-JAVA-API-Demo-01/output");
            result = fileSystem.exists(path);
        } catch (Exception e) {
            LOGGER.error("检查异常");
            LOGGER.error(e.getMessage(), e);
        }
        LOGGER.info("路径是否存在:{}", new Object[]{result});
    }


    /**
     * 查找指定目录下的子目录
     *
     * @throws Exception
     */
    private static void findAllDirectory() throws Exception {
        Configuration configuration = new Configuration();
        FileSystem fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration);
        FileStatus[] listFiles = fileSystem.listStatus(new Path("/"));

        FileStatus fileStatus;
        if (null != listFiles &amp;&amp; listFiles.length &gt; 0) {
            for (int i = 0; i &lt; listFiles.length; i++) {
                fileStatus = listFiles[i];
                LOGGER.info("path : {} ", new Object[]{fileStatus.toString()});
            }
        }
    }

    /**
     * 创建单级目录
     *
     * @throws Exception
     */
    private static void createDirectory() {
        try {
            Configuration configuration = new Configuration();
            FileSystem fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration);
            fileSystem.mkdirs(new Path("/HDFS-JAVA-API-Demo-01"));
            LOGGER.info("创建目录成功");
        } catch (Exception e) {
            LOGGER.error("创建目录失败");
            LOGGER.error(e.getMessage(), e);
        }
    }

    /**
     * 创建多级目录
     *
     * @throws Exception
     */
    private static void createMultiDirectory() {
        boolean result;
        try {
            Configuration configuration = new Configuration();
            FileSystem fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration);
            result = fileSystem.mkdirs(new Path("/HDFS-JAVA-API-Demo-01/input"));
            LOGGER.info("result : {}", new Object[]{result});
        } catch (Exception e) {
            LOGGER.error("创建目录失败");
            LOGGER.error(e.getMessage(), e);
        }
    }


    /**
     * 读取指定文件的数据
     *
     * @throws Exception
     */
    private static void readerFile() throws Exception {
        FSDataInputStream fsDataInputStream = null;
        try {
            Configuration configuration = new Configuration();
            FileSystem fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration);
            fsDataInputStream = fileSystem.open(new Path("/HDFS-JAVA-API-Demo-01/input/test02.txt"));
            String fileResult = IOUtils.toString(fsDataInputStream, "UTF-8");
            LOGGER.info("fileResult : {}", new Object[]{fileResult});
        } catch (Exception e) {
            LOGGER.error(e.getMessage(), e);
        } finally {
            fsDataInputStream.close();
        }
    }

    /**
     * 向HDFS文件上重写内容
     * &lt;p&gt;
     * 向HDFS文件上追加内容，需要修改配置文件内容，这里不测试了
     * https://www.iteblog.com/archives/881.html
     */
    private static void appendDataToHDFSFile() {

        FSDataOutputStream fsDataOutputStream = null;

        try {
            Configuration configuration = new Configuration();
            FileSystem fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration);
            Path path = new Path("/HDFS-JAVA-API-Demo-01/input/hdfs-test02.txt");
            fsDataOutputStream = fileSystem.append(path);
            fsDataOutputStream.writeUTF("9998885557744");
        } catch (Exception e) {
            LOGGER.error(e.getMessage(), e);
        } finally {
            try {
                fsDataOutputStream.close();
            } catch (IOException e) {
                LOGGER.error(e.getMessage(), e);
            }
        }
    }

    /**
     * 根据某些规则，列出指定路径下的文件
     */
    private static void globStatus() {

        try {
            Configuration configuration = new Configuration();
            FileSystem fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration);
            Path allPath = new Path("/*/*/");

            FileStatus[] fileStatuses = fileSystem.globStatus(allPath, new PathFilter() {
                @Override
                public boolean accept(Path path) {
                    String contidion = "01";
                    return path.toString().contains(contidion);
                }
            });

            for (int i = 0; i &lt; fileStatuses.length; i++) {
                FileStatus statuses = fileStatuses[i];
                LOGGER.info("statuses : {}", new Object[]{statuses});
            }
        } catch (Exception e) {
            LOGGER.error(e.getMessage(), e);
        }

    }

    /**
     * 重命名HDFS上的文件、目录
     */
    private static void renameHDFSFile() {
        try {
            Configuration configuration = new Configuration();
            FileSystem fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration);

            Path src = new Path("/HDFS-JAVA-API-Demo-01/input");
            Path dst = new Path("/HDFS-JAVA-API-Demo-01/inputxx");
            boolean result = fileSystem.rename(src, dst);
            LOGGER.info("result : " + result);
        } catch (Exception e) {
            LOGGER.error(e.getMessage(), e);
        }
    }
    
   /**
     * 查看HDFS文件的最后修改时间
     */
    private static void getModificationTime() {

        try {
            Configuration configuration = new Configuration();
            FileSystem fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration);

            Path src = new Path("/HDFS-JAVA-API-Demo-01/inputxx");

            FileStatus fileStatus = fileSystem.getFileStatus(src);
            long time = fileStatus.getModificationTime();
            SimpleDateFormat dateFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
            String timeStr = dateFormat.format(new Date(time));
            LOGGER.info("modificationTime : {}", new Object[]{timeStr});
        } catch (Exception e) {
            LOGGER.error(e.getMessage(), e);
        }
    }
    
    /**
     * 查找某个文件在HDFS集群的位置
     */
    private static void getFileBlockLocation() {

        try {
            Configuration configuration = new Configuration();
            FileSystem fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration);

            Path path = new Path("/HDFS-JAVA-API-Demo-01/inputxx/testxx.txt");
            FileStatus fileStatus = fileSystem.getFileStatus(path);
            
            BlockLocation[] blockLocations = fileSystem.getFileBlockLocations(fileStatus, 0L, fileStatus.getLen());

            String[] hosts;
            for (int i = 0; i &lt; blockLocations.length; i++) {
                hosts = blockLocations[i].getHosts();
                LOGGER.info("block_" + i + "_location:" + hosts[0]);
            }
        } catch (Exception e) {
            LOGGER.error(e.getMessage(), e);
        }
    }
    
    /**
     * 获取HDFS集群上所有节点名称信息
     */
    private static void getHostName() {

        try {
            Configuration configuration = new Configuration();
            FileSystem fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration);

            DistributedFileSystem hdfs = (DistributedFileSystem) fileSystem;
            DatanodeInfo[] datanodeInfos = hdfs.getDataNodeStats();

            for (int i = 0; i &lt; datanodeInfos.length; i++) {
                LOGGER.info("DataNode_" + i + "_Name:" + datanodeInfos[i].getHostName());
            }

        } catch (Exception e) {
            LOGGER.error(e.getMessage(), e);
        }
    }
    
}
</code></pre>

<p> </p>

<p> </p>

<h2 id="%E6%95%B0%E6%8D%AE%E6%B5%81"><span style="color:#86ca5e;">数据流</span></h2>

<h3 id="%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96"><span style="color:#ffbb66;">文件读取</span></h3>

<p><img alt="" class="has" height="364" src="https://img-blog.csdn.net/20180918230020741?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NpbWJhX2NoZW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="918"></p>

<p>了解客户端及与之交互的HDFS、NameNode和DataNode之间的数据流是什么样的。</p>

<p>客户端通过调用FileSystem对象的open()方法打开希望读取的文件。</p>

<p>(步骤1、2)</p>

<p>DistributedFileSystem通过RPC调用NameNode，获得起始块的位置。</p>

<p>DistributedFileSystem会返回一个FSDataInputStream对象。</p>

<p>FSDataInputStream对象封装着DFSInputStream对象，该对象管理着DataNode和NameNode的I/O。</p>

<p>(步骤3/4)</p>

<p>接着客户端调用DFSIputStream对象的read()方法。</p>

<p>存储着文件起始几个块的DataNode地址的DFSInputStream随机连接距离最近的DataNode。</p>

<p>通过对数据流反复调用read()方法，可以将数据从DataNode传输到客户端。</p>

<p>(步骤5)</p>

<p>到达块的末端时，DFSIputStream关闭与该DataNode的连接，然后寻找下一个块的最佳DataNode。</p>

<p>客户端只需要读取连续的流，对于客户端都是透明的。</p>

<p>(步骤6)</p>

<p>客户端从流中读取数据时，块是按照打开DSFInputStream与DataNode新建连接的顺序读取的。</p>

<p>它也会根据需要询问NameNode来检索下一批数据块的DataNode的位置。</p>

<p>一旦客户端完成读取，就对FSDataInputStream调用Close()方法。</p>

<p>简单的来说：</p>

<p>    Client向NameNode发送读取请求。</p>

<p>    NameNode返回数据块(Block)在DataNode上的位置。</p>

<p>    block位置有顺序的，按照顺序，依次读取(优先读取本机架的数据)。</p>

<p> </p>

<h3 id="%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5"><span style="color:#ffbb66;">文件写入</span></h3>

<p><em>(网上看到一篇不错的博文，http://www.daniubiji.cn/archives/596 精简一下)</em></p>

<p><img alt="" class="has" height="553" src="https://img-blog.csdn.net/20180918230438512?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NpbWJhX2NoZW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="827"></p>

<p>有一个文件FileA，100MB，Client将FileA写到HDFS上。</p>

<p>HDFS按照默认进行配置。同时 HDFS分布在三个机架上。</p>

<p>    1. Client 将FileA按64M分成两块：block1(64MB) 和 block2(36MB)    </p>

<p>    2. Client 向NameNode发送请求，然后NameNode返回可用的DataNode信息。</p>

<p>                    block1 : <span style="color:#ffbb66;">host2 -----&gt; host1 -----&gt; host3</span></p>

<p>                    block2 : <span style="color:#e579b6;">host7 -----&gt; host8 -----&gt; host4</span></p>

<p>    3. Client向DataNode发送block；发送过程是流式写入。</p>

<p>    具体过程：</p>

<p>        a. Client将block1(64MB)<span style="color:#86ca5e;">按64K块划分</span>，然后<span style="color:#ffbb66;">将第一个64K块</span>发送给host2。</p>

<p>        b. host2接收Client完成之后，host2的DataNode将<span style="color:#ffbb66;">第一个64K块</span>同步发送给host1，同时，Client继续向host2发送<span style="color:#3399ea;">第二个64K块</span>。</p>

<p>        c. host1接收完<span style="color:#ffbb66;">第一个64K块</span>后，接着同步给host3，同时同步接收来自host2的<span style="color:#3399ea;">第二个64K块</span>。</p>

<p>        d. 依次类推，直到将block1发送完毕。</p>

<p>        e. <span style="color:#7c79e5;">host2、host1、host3向NameNode发送通知</span>，<span style="color:#f33b45;">host2向Client发送通知，说"发送完毕"</span>。(疑问？为啥是host2向Client报告？)</p>

<p>        f. <span style="color:#3399ea;">Client接收到host2的消息后，向NameNode发送消息，说写完了。这样，block1就彻底发送结束了</span>。</p>

<p>        g. 接着继续发送block2，host7、host8、host4向NameNode发送通知，host7向Client发送通知，然后Client向NameNode发送消息，block2也彻底结束了。</p>

<p>这样就完毕了。</p>

<p> </p>

<p>（最近工作太忙，没有时间往下扣，暂时将这个问题记录下来）</p>

<p>问题：</p>

<p>    1. 为什么block1全部写完之后，host2要向Client发送通知，而不是host1 或 host3？</p>

<p>    2. block1写完之后，host2、host1、host3向NameNode发送了什么？</p>

<p> </p>

<p>参考资料：</p>

<p>http://hadoop.apache.org/docs/</p>

<p>http://www.daniubiji.cn/archives/596</p>

<p>《HDFS—Hadoop分布式文件系统深度实践》</p>            </div>
                </div>