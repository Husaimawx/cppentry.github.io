---
layout:     post
title:      hadoop HA 下 Hbase无法连接外部zookeeper问题
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>hadoop HA 下 Hbase无法连接外部zookeeper问题</p><p>1.搭建好hadoop集群并启动后，安装Hbase,配置好文件，启动HBase,进入hbase shell 后，</p><p>输入list 提示如下信息：</p><p>hbase(main):001:0&gt; list<br></p><p>TABLE                                                                                                                 </p><p>ERROR: Can't get master address from ZooKeeper; znode data == null</p>Here is some help for this command:<br>List all tables in hbase. Optional regular expression parameter could<br><p>be used to filter the output. Examples:</p>  hbase&gt; list<br>  hbase&gt; list 'abc.*'<br>  hbase&gt; list 'ns:abc.*'<br><p>  hbase&gt; list 'ns:.*'</p><p>错误提示，HMaster 无法从zookeeper集群中获取znode信息，找不到master地址</p><p>网上百度一番：说修改配置文件</p><p>打开配置文件，发现配置没有问题：</p><p>1.  hbase-env.sh ：</p><p>配置pid文件的目录在有访问权限的home 目录下：</p><p>  export HBASE_PID_DIR=/home/zookeeper-hbase/pids </p><p>启用外部zookeeper:</p><p>export HBASE_MANAGES_ZK=false<br></p><p> 2. hbase-site.xml:</p><p>&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;<br>&lt;value&gt;master,slave1,slave2&lt;/value&gt; #指定zookeeper集群节点名,因为是由zookeeper表决算法决定的<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;zookeeper.znode.parent&lt;/name&gt;<br>&lt;value&gt;/hbase-unsecure&lt;/value&gt; #配置zookeeper集群数据节点<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; #指zookeeper集群data目录<br>&lt;value&gt;/home/zookeeper-hbase&lt;/value&gt;<br></p><p>&lt;/property&gt;</p><p>查看zookeeper 节点</p><p>1.进入zookeeper shell :      bin/zkCli.sh</p><p> 输入 ls / 查看zookeeper根目录下的所有znode节点：</p><p><img src="https://img-blog.csdn.net/20180323112851113?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NvZGVlZWU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p>发现有 hbase-unsecure 这个在配置文件中配置的节点：</p><p>获取节点信息： get /hbase-unsecure:</p><p><img src="https://img-blog.csdn.net/20180323113012773?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NvZGVlZWU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p>发现该节点下是空的：</p><p>网上百度的方法没有解决问题，于是开始分析报错信息：Can't get master address from ZooKeeper ；znode data == null</p><p>hbase自身的zookeeper服务被关闭，使用外部的zookeeper服务时，需要在hdfs上存储自己的数据库信息等，也就是要获得hadoop集群的namenode的地址，即集群的id,通过集群向datanode上存储数据,于是找到hadoop集群的名称，由于之前配置的hadoop HA集群，打开hadoop配置文件hdfs-site.xml文件:</p><p>&lt;property&gt;<br>    &lt;!-- 为namenode集群定义一个services name --&gt;<br>    &lt;name&gt;dfs.nameservices&lt;/name&gt;<br>    &lt;value&gt;HAcluster&lt;/value&gt;<br>  &lt;/property&gt;<br>  &lt;property&gt;<br>    &lt;!-- nameservice 包含哪些namenode，为各个namenode起名 --&gt;<br>    &lt;name&gt;dfs.ha.namenodes.HAcluster&lt;/name&gt;<br>    &lt;value&gt;namenode1,namenode2&lt;/value&gt;<br>  &lt;/property&gt;<br></p><p>发现配置了两个namenode分别为namenode1,namenode2,在zookeeper中可以看到namenode1为active状态，试试将hbase-site.xml文件中数据集群群节点，所有分布式和集群统一修改。</p><p>先关闭hbase:bin/stop-hbase.sh</p><p>修改成如下：</p><p><br></p><p><br></p><p>发现执行出错：</p><p><img src="https://img-blog.csdn.net/20180323115136998?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NvZGVlZWU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p><p>查看jps,发现HMaster已经关闭，但其他节点的HRegionServer依然存活，</p><p><img src="https://img-blog.csdn.net/20180323115648261?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NvZGVlZWU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p>说明habse无法通过zookeeper集群去关闭其他节点的HRegionServer，只能手动杀死HRegionServer进程。。。</p><p>修改后重启hbase:</p><p>还是报错，打开日志文件，logs下的启动日志可以看到。总是提示ClustId read in Zookeeper in null. hbase无法读取zookeeper中的clustid节点，也就是datanode节点，于是查看datanode节点是否正常，发现，hadoop集群中有两个namenode节点的datanode节点没有启动，分析可能是由于之前按网上教程提示格式化过namenode,导致版本不匹配，于是停掉所有服务，删除所有节点hadoopHA/tmp/dfs 内容，重新格式化namenode</p><p>注意在HA模式下格式化namenode有所不同，</p><p>格式化步骤：</p><p>1.各节点分别启动Journalnode<br>    sbin/hadoop-daemon.sh start journalnode<br>2.启动zookeeper<br>    bin/zkServer.sh start<br>3.格式化namenode<br>  第一台：bin/hdfs namenode -format <br>          启动namenode, sbin/hadoop-daemon.sh start namenode<br>  第二台：bin/hdfs namenode -bootstrapStandby <br>4.启动namenode<br>  sbin/hadoop-daemon.sh start namenode<br>5.查看HDFS页面 两个namenode都是standby状态<br>  http://192.168.0.128:50070/<br>  切换第一台为active状态：bin/hdfs haadmin -transitionToActive namenode1<br>                          可添加强制转换：bin/hdfs haadmin -transitionToActive -forcemanual namenode1<br></p><p>至此，格式化完毕，namenode也已启动成功，于是停掉服务：sbin/stop-all.sh</p><p>重新启动hadoop:</p><p>启动顺序：</p><p>1.启动zookeeper: bin/zkServer.sh start<br>2.启动zkfc:  sbin/hadoop-daemon.sh start  zkfc <br>3.启动hdfs: sbin/start-dfs.sh<br>4.启动yarn: sbin/start-yarn.sh<br></p><p>5.切换namenode 为active: bin/hdfs haadmin -transitionToActive -forcemanual namenode1</p><p>1.在namenode状态为active的节点上启动hbase:</p><p>bin/start-hbase.sh</p><p>2.启用备用HMaster节点:<br></p><p>bin/hbase-daemon.sh start master</p><p>3.进入hbase shell:</p><p>bin/hbase shell</p><p>打开启动日志提示报错：</p><p><span style="color:rgb(69,69,69);background-color:rgb(255,255,255);"> java.net.UnknownHostException: unknown host: HAcluster</span><br style="color:rgb(69,69,69);background-color:rgb(255,255,255);"><span style="color:rgb(69,69,69);background-color:rgb(255,255,255);">        at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.&lt;init&gt;(HBaseClient.java:302)</span><br style="color:rgb(69,69,69);background-color:rgb(255,255,255);"><span style="color:rgb(69,69,69);background-color:rgb(255,255,255);">        at org.apache.hadoop.hbase.ipc.HBaseClient.createConnection(HBaseClient.java:281)</span><br style="color:rgb(69,69,69);background-color:rgb(255,255,255);"><span style="color:rgb(69,69,69);background-color:rgb(255,255,255);">        at org.apache.hadoop.hbase.ipc.HBaseClient.getConnection(HBaseClient.java:1137)</span><br style="color:rgb(69,69,69);background-color:rgb(255,255,255);"><span style="color:rgb(69,69,69);background-color:rgb(255,255,255);">        at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:1000)</span></p><p>这个错应该是hbase的hadoop版本与hadoop集群的hadoop版本不匹配造成的，于是，替换hbase的hadoop版本为hadoop 集群版本：</p><p></p><p>1）、cp /opt/hadoopHA/share/hadoop/common/hadoop-common-2.7.4.jar  /opt/hbase-1.3.1/lib/</p><p>2）、scp /opt/hadoopHA/share/hadoop/common/hadoop-common-2.7.4.jar   slave1:/opt/hbase-1.3.1/lib/</p><p>3）、scp /opt/hadoopHA/share/hadoop/common/hadoop-common-2.7.4.jar   slave1:/opt/hbase-1.3.1/lib/</p><p>同时还要将hdfs-site.xml和core-site.xml文件拷贝到/opt/hbase-1.3.1/conf/下，或者建立一个到这个文件的软连接。</p>重启hbase、进入hbase shell,<p>输入list:没有报错，问题解决。结果如下：</p><p><img src="https://img-blog.csdn.net/20180329112740371?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NvZGVlZWU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p><br></p><p>总结：</p><p>1、HA 模式下，hbase 的配置文件hbase-site.xml 中的 hbase.rootdir 值要与hadoop 配置文件core-site.xml 的dfs.Deafult 配置一样，我的配置是：</p><p><img src="https://img-blog.csdn.net/20180329113147647?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NvZGVlZWU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p><p>故hbase-site.xml应配置为：</p><p><img src="https://img-blog.csdn.net/20180329113345288?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NvZGVlZWU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p>2.由于HA模式下 namenode节点状态由zookeeper指定，故hbase应给出个端口6000即可</p><p><img src="https://img-blog.csdn.net/20180329113530621?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NvZGVlZWU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p>3.hbase.zookeeper.quorum 访问端口默认为locallhost,在分布式环境下需要设成统一的端口：</p><p><img src="https://img-blog.csdn.net/20180329113719424?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NvZGVlZWU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p>4.hbase 自带的hadoop版本需要与集群的hadoop版本一致，将hadoop的版本替换掉hbase的版本：</p><p>5、尽量多从日志以及zookeeper及hbase还有Hadoop的关系，架构上去分析问题。</p><p><br></p><p><br></p><p><br></p><p><br></p>            </div>
                </div>