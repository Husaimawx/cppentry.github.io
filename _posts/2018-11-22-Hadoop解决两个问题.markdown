---
layout:     post
title:      Hadoop解决两个问题
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<div>
<div><span style="color:#2DA2BF;">Hadoop解决两个问题</span></div>
<div>海量数据的存储 -- HDFS</div>
<div><br></div>
<div>海量数据的分析 -- MapReduce</div>
</div>
<div><br></div>
<div>
<div>
<div>Hadoop  = The Hadoop projects</div>
<div><br></div>
<div>和Hadoop相关的一些项目</div>
<div></div>
<div><em>Common, Avro, MapReduce, HDFS, Pig, Hive, Hbase, ZooKeeper, Sqoop, Oozie</em></div>
</div>
<br></div>
<div>HDFS设计目标</div>
<div>
<div>
<div><span style="color:#2DA2BF;">1、</span>Very large files</div>
<div><br></div>
<div><span style="color:#2DA2BF;">2、</span>Streaming data access</div>
<div>write-once, read-many-times</div>
<div><span style="color:rgb(45,162,191);"><br></span></div>
<div><span style="color:rgb(45,162,191);">3、</span>Commodity hardware</div>
</div>
<div><br></div>
<div>HDFS不适合的情况</div>
<div>
<div>
<div><span style="color:#2da2bf;">1、</span>Low-latency data access</div>
<div><br></div>
<div><span style="color:#2da2bf;">2、</span>Lots of small files</div>
<div><br></div>
<div><span style="color:#2da2bf;">3、</span>Multiple writers, arbitrary file modifications</div>
</div>
<div>
<div>在Hadoop中，一个文件被划分成大小固定的多个文件块，分布的存储在集群中的节点中</div>
</div>
<div><br></div>
<div>HDFS架构</div>
<div>
<div>
<div><br></div>
<div>Block：一个文件分块，默认64M</div>
<div></div>
<div>NameNode：保存整个文件系统的目录信息，文件信息以及文件相应的分块信息。</div>
<div></div>
<div>DataNode：用于存储Blocks</div>
<div></div>
<div>HDFS的HA策略：NameNode一旦宕机，整个文件系统将无法工作。</div>
<div>如果NameNode中的数据丢失，整个文件系统也就丢失了。</div>
<div>2.x开始，HDFS支持NameNode的active-standy模式</div>
</div>
<br></div>
<br></div>
<br></div>
            </div>
                </div>