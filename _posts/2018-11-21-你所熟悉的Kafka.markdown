---
layout:     post
title:      你所熟悉的Kafka
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/qq_36290794/article/details/78368553				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p><strong><em>Kafka是什么??</em></strong> <br>
   在流式计算中,Kafka一般用来缓存数据,Storm通过消费Kafka的数据进行计算</p>

<p>Kafka是一个分布式消息队列:生产者,消费者的功能;它提供了类似于JMS的特性,但是在设计实现上完全不同         <a href="http://blog.csdn.net/qq_36290794/article/details/78368674" rel="nofollow">我只是小小的知识点–JMS</a></p>

<p>Kafka对消息保存时根据Topic进行归类,发送消息者称为Producer,消息接受者称为Consumer; <br>
kafka集群有多个kafka实例组成,每个实例(server)称为broker</p>

<p>无论是kafka集群,还是producer和consumer都依赖于zookeeper集群保存一些meta信息,来保证系统可用性</p>

<p><strong><em>Kafka核心组件:</em></strong> <br>
  Topic: 消息根据Topic进行归类 <br>
  Producer:发送消息者 <br>
  Consumer:消息接受者 <br>
  broker:每个kafka实例(server) <br>
  zookeeper:依赖集群保存meta信息</p>

<p>Kafka整体架构图: <br>
<img src="https://img-blog.csdn.net/20171029203621909?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzYyOTA3OTQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="架构图" title=""> <br>
Producer   Cluster: <br>
1.1  生产者负责获取数据,比如flume,logstash会监控一个目录把数据传输到Kafka <br>
1.2  生产者集群由多个进程组成,一个生产者作为一个进程 <br>
1.3  多个生产者生产的数据可以放到同一个Topic的同一个分区里 <br>
1.4  一个生产者生产的数据可以放到多个Topic里 <br>
1.5  单个生产者具有数据分发的能力</p>

<p>Kafka  Cluster: <br>
1. Kafka可以保存多种数据类型的数据,一种数据可以保存到一个Topic里,一个Kafka集群可以保存多个Topic <br>
2.每个Topic里可以创建一个或多个分区,分区的数量在创建Topic时指定 <br>
3.每个分区的数据由多个segment组成,一个segment里由index和data组成 <br>
4.一个Topic的分区数据可以有多个备份,备份数在创建Topic时指定,原始数据和备份数据不可以在同一个节点上 </p>

<p>Consumer Cluster: <br>
2.1 消费者负责拉取数据进行消费;比如SparkStreaming获取kafka的数据进行计算,此时SparkStreaming就是消费者 <br>
2.2 一个CondumerGroup称为Consumer Cluster <br>
2.3 新增或减少Consumer成员时会触发Consumer Cluster的负载均衡 <br>
2.4 CondumerGroup(组)可以消费一个或多个分区的数据;反之,一个分区只可以同时被一个Consumer消费 <br>
2.5 Consumer和Consumer消费的数据各不相同,而且数据不可以重复消费</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>