---
layout:     post
title:      Spark开发环境的配置
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<div class="entry-content" style="color:rgb(51,51,51);font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:15px;line-height:20px;">
<p><strong>软件版本</strong>：Spark 0.9</p>
<p>配置Spark开发环境，其实分为三个层次，一种是针对运维人员，把Spark安装部署到集群；一种是针对普通开发者，引入Spark的jar包，调用Spark提供的接口，编写分布式程序，写好后编译成jar，就可以提交到Spark集群去运行了；第三种是针对Spark开发者，为了给Spark贡献代码，需要git clone Spark的代码，然后导入IDE，为Spark开发代码。</p>
<h2 id="spark" style="font-family:inherit;line-height:40px;color:inherit;font-size:22.5px;">
1 部署Spark集群</h2>
<p>这种是运维人员在生产环境下，搭建起一个Spark集群。</p>
<h3 id="spark-1" style="font-family:inherit;line-height:40px;color:inherit;font-size:18.75px;">
（可选）创建新用户 Spark</h3>
<p>一般我倾向于把需要启动daemon进程，对外提供服务的程序，即服务器类的程序，安装在单独的用户下面。这样可以做到隔离，运维方面，安全性也提高了。</p>
<p>创建一个新的group,</p>
<pre><code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;color:inherit;border:0px;background-color:transparent;">$ sudo groupadd spark
</code></pre>
<p>创建一个新的用户，并加入group,</p>
<pre><code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;color:inherit;border:0px;background-color:transparent;">$ sudo useradd -g spark spark
</code></pre>
<p>给新用户设置密码，</p>
<pre><code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;color:inherit;border:0px;background-color:transparent;">$ sudo passwd spark
</code></pre>
<p>在每台机器上创建 spark 新用户，并配置好SSH无密码，参考我的另一篇博客，<a href="http://www.yanjiuyanjiu.com/blog/20120102/" rel="nofollow" style="color:rgb(0,136,204);text-decoration:none;">SSH无密码登录的配置</a></p>
<p>假设有三台机器，hostname分别是 master, worker01, worker02。</p>
<h3 id="spark-" style="font-family:inherit;line-height:40px;color:inherit;font-size:18.75px;">
1.1 下载 Spark 预编译好的二进制包</h3>
<p>如果你需要用到HDFS，则要针对Hadoop 1.x 和Hadoop 2.x 选择不同的版本。这里我选择 Hadoop 2.x 版。</p>
<pre><code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;color:inherit;border:0px;background-color:transparent;">spark@master $ wget http://d3kbcqa49mib13.cloudfront.net/spark-0.9.0-incubating-bin-hadoop1.tgz
spark@master $ tar zxf spark-0.9.0-incubating-bin-hadoop1.tgz -C ~/local/opt
</code></pre>
<h3 id="tgzscp" style="font-family:inherit;line-height:40px;color:inherit;font-size:18.75px;">
1.2 将tgz压缩包scp到所有机器，解压到相同的路径</h3>
<pre><code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;color:inherit;border:0px;background-color:transparent;">spark@master $ scp spark-0.9.0-incubating-bin-hadoop1.tgz spark@worker01:~
spark@master $ ssh worker01
spark@worker01 $ tar zxf spark-0.9.0-incubating-bin-hadoop1.tgz -C ~/local/opt
spark@worker01 $ exit
spark@master $ scp spark-0.9.0-incubating-bin-hadoop1.tgz spark@worker02:~
spark@master $ ssh worker02
spark@worker02 $ tar zxf spark-0.9.0-incubating-bin-hadoop1.tgz -C ~/local/opt
spark@worker02 $ exit
</code></pre>
<h3 id="section" style="font-family:inherit;line-height:40px;color:inherit;font-size:18.75px;">
1.3 修改配置文件</h3>
<p>Spark 0.9 以后，配置文件简单多了，只有一个必须要配置，就是 <code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;font-size:.8em;color:rgb(85,85,85);border:1px solid rgb(221,221,221);display:inline-block;line-height:1.5em;">conf/slaves</code> 这个文件。在这个文件里添加slave的hostname。</p>
<h3 id="slave" style="font-family:inherit;line-height:40px;color:inherit;font-size:18.75px;">
1.4 拷贝配置文件到所有slave</h3>
<pre><code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;color:inherit;border:0px;background-color:transparent;">spark@master $ spark@master $ scp ./conf/slaves spark@worker01:~/local/opt/spark-0.9.0-incubating-bin-hadoop1/conf
spark@master $ spark@master $ scp ./conf/slaves spark@worker02:~/local/opt/spark-0.9.0-incubating-bin-hadoop1/conf
</code></pre>
<h3 id="spark-2" style="font-family:inherit;line-height:40px;color:inherit;font-size:18.75px;">
1.5 启动Spark集群</h3>
<pre><code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;color:inherit;border:0px;background-color:transparent;">spark@master $ ./sbin/start-all.sh
</code></pre>
<p>也可以一台一台启动，先启动 master</p>
<pre><code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;color:inherit;border:0px;background-color:transparent;">spark@master $ ./sbin/start-master.sh
</code></pre>
<p>启动两台 slave，</p>
<pre><code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;color:inherit;border:0px;background-color:transparent;">spark@worker01 $ ./sbin/start-slave.sh 1 spark://master:7077
spark@worker02 $ ./sbin/start-slave.sh 2 spark://master:7077
</code></pre>
<p>其中，<code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;font-size:.8em;color:rgb(85,85,85);border:1px solid rgb(221,221,221);display:inline-block;line-height:1.5em;">1</code>, <code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;font-size:.8em;color:rgb(85,85,85);border:1px solid rgb(221,221,221);display:inline-block;line-height:1.5em;">2</code> 是
 worker的编号，可以是任意数字，只要不重复即可，<code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;font-size:.8em;color:rgb(85,85,85);border:1px solid rgb(221,221,221);display:inline-block;line-height:1.5em;">spark://master:7077</code> 是
 master 的地址。以后向集群提交作业的时候，也需要这个地址。</p>
<h3 id="section-1" style="font-family:inherit;line-height:40px;color:inherit;font-size:18.75px;">
1.6 测试一下，向集群提交一个作业</h3>
<pre><code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;color:inherit;border:0px;background-color:transparent;">spark@master $ ./bin/run-example org.apache.spark.examples.SparkPi spark://master:7077
</code></pre>
<h2 id="section-2" style="font-family:inherit;line-height:40px;color:inherit;font-size:22.5px;">
2 配置普通开发环境</h2>
<p>TODO</p>
<h2 id="spark-3" style="font-family:inherit;line-height:40px;color:inherit;font-size:22.5px;">
3 配置Spark开发环境</h2>
<p>当你需要修改Spark的代码，或给Spark添加代码，就需要阅读本节了。</p>
<h3 id="git-clone-" style="font-family:inherit;line-height:40px;color:inherit;font-size:18.75px;">
3.1 git clone 代码</h3>
<pre><code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;color:inherit;border:0px;background-color:transparent;">git clone git@github.com:apache/incubator-spark.git
</code></pre>
<h3 id="section-3" style="font-family:inherit;line-height:40px;color:inherit;font-size:18.75px;">
3.2 编译</h3>
<p>Spark脚本会自动下载对应版本的sbt和scala编译器，因此机器事先不需要安装sbt和scala</p>
<p>按照 github 官方repo首页的文档，输入如下一行命令即可开始编译，</p>
<pre><code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;color:inherit;border:0px;background-color:transparent;">./sbt/sbt assembly
</code></pre>
<h3 id="section-4" style="font-family:inherit;line-height:40px;color:inherit;font-size:18.75px;">
3.3 运行一个例子</h3>
<pre><code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;color:inherit;border:0px;background-color:transparent;">./run-example org.apache.spark.examples.SparkPi local
</code></pre>
<p>说明安装成功了。</p>
<h3 id="spark-shell" style="font-family:inherit;line-height:40px;color:inherit;font-size:18.75px;">
3.4 试用 spark shell</h3>
<p>./spark-shell</p>
<p>会出现<code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;font-size:.8em;color:rgb(85,85,85);border:1px solid rgb(221,221,221);display:inline-block;line-height:1.5em;">scala&gt;</code>提示符号，可见spark脚本自动下载了scala编译器，其实就是一个jar，例如<code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;font-size:.8em;color:rgb(85,85,85);border:1px solid rgb(221,221,221);display:inline-block;line-height:1.5em;">scala-compiler-2.10.3.jar</code>。</p>
<h3 id="scala" style="font-family:inherit;line-height:40px;color:inherit;font-size:18.75px;">
3.5 安装scala</h3>
<p>开发Spark的时候，由于Intellij Idea 需要调用外部的sbt和scala，因此机器上还是需要安装scala和sbt。</p>
<p>打开 <code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;font-size:.8em;color:rgb(85,85,85);border:1px solid rgb(221,221,221);display:inline-block;line-height:1.5em;">projects/SparkBuild.scala</code>，搜索<code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;font-size:.8em;color:rgb(85,85,85);border:1px solid rgb(221,221,221);display:inline-block;line-height:1.5em;">scalaVersion</code>，获得spark所使用的scala编译器版本，然后去scala官网<a href="http://www.scala-lang.org/" rel="nofollow" style="color:rgb(0,136,204);text-decoration:none;">http://www.scala-lang.org/</a>，下载该版本的scala编译器，并设置<code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;font-size:.8em;color:rgb(85,85,85);border:1px solid rgb(221,221,221);display:inline-block;line-height:1.5em;">SCALA_HOME</code>环境变量，将bin目录加入PATH。例如下载scala-2.10.3.tgz，解压到/opt，设置环境变量如下：</p>
<pre><code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;color:inherit;border:0px;background-color:transparent;">sudo vim /etc/profile
export SCALA_HOME=/opt/scala-2.10.3
export PATH=$PATH:$SCALA_HOME/bin
</code></pre>
<h3 id="sbt" style="font-family:inherit;line-height:40px;color:inherit;font-size:18.75px;">
3.6 安装sbt</h3>
<p>打开<code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;font-size:.8em;color:rgb(85,85,85);border:1px solid rgb(221,221,221);display:inline-block;line-height:1.5em;">projects/build.properties</code>，可以看到spark所使用的sbt版本号，去
 官网<a href="http://www.scala-sbt.org/" rel="nofollow" style="color:rgb(0,136,204);text-decoration:none;">http://www.scala-sbt.org/</a>下载该版本的sbt，双击安装。并设置<code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;font-size:.8em;color:rgb(85,85,85);border:1px solid rgb(221,221,221);display:inline-block;line-height:1.5em;">SBT_HOME</code>环境变量，将bin目录加入PATH。</p>
<h3 id="idea" style="font-family:inherit;line-height:40px;color:inherit;font-size:18.75px;">
3.7 下载并安装idea</h3>
<p>Spark核心团队的hashjoin曾在我博客上留言，说他们都使用idea在开发spark，我用过<a href="http://cn.soulmachine.me/blog/20140130/www.scala-ide.org" rel="nofollow" style="color:rgb(0,136,204);text-decoration:none;">Scala IDE</a>和idea，两者各有优劣，总的来说，idea要好用一些，虽然我是老牌eclipse用户，但我还是转向了idea。</p>
<p>去idea官网下载idea的tar.gz包，解压就行。运行idea，安装scala插件。</p>
<h3 id="idea-1" style="font-family:inherit;line-height:40px;color:inherit;font-size:18.75px;">
3.8 生成idea项目文件</h3>
<p>在源码根目录，使用如下命令</p>
<pre><code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;color:inherit;border:0px;background-color:transparent;">./sbt/sbt gen-idea
</code></pre>
<p>就生成了idea项目文件。</p>
<h3 id="open-project" style="font-family:inherit;line-height:40px;color:inherit;font-size:18.75px;">
3.9 Open Project</h3>
<p>使用 idea，点击<code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;font-size:.8em;color:rgb(85,85,85);border:1px solid rgb(221,221,221);display:inline-block;line-height:1.5em;">File-&gt;Open
 project</code>，浏览到 <code style="font-family:Monaco, Menlo, Consolas, 'Courier New', monospace;font-size:.8em;color:rgb(85,85,85);border:1px solid rgb(221,221,221);display:inline-block;line-height:1.5em;">incubator-spark</code>文件夹，打开项目，就可以修改Spark代码了。</p>
</div>
<p class="meta"><span class="byline author vcard">Posted by <span class="fn">soulmachine</span></span> Jan 30th, 2014 <span class="categories"><a class="category" href="http://cn.soulmachine.me/blog/categories/spark/" rel="nofollow" style="color:rgb(0,136,204);text-decoration:none;">Spark</a></span></p>
<p class="meta">http://cn.soulmachine.me/blog/20140130/<br></p>
            </div>
                </div>