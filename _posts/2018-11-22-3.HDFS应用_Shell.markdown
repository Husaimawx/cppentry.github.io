---
layout:     post
title:      3.HDFS应用_Shell
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/qq_15014327/article/details/83033266				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h2>一. 概述</h2>

<ul><li>所有HDFS命令都由hadoop安装目录下的bin/hdfs脚本调用。运行不带任何参数的hdfs脚本会打印所有命令的描述。</li>
	<li>用法：hdfs [SHELL_OPTIONS]命令 [GENERIC_OPTIONS] [COMMAND_OPTIONS]</li>
	<li>HDFS命令主要分为两类：用户命令和管理命令。</li>
</ul><h2>二. 用户命令</h2>

<p><strong>1. 用法：hadoop fs -appendToFile &lt;localsrc&gt; ... &lt;dst&gt;</strong></p>

<p>将单个src或多个srcs从本地文件系统附加到目标文件系统。还从stdin读取输入并附加到目标文件系统。</p>

<ul><li>hadoop fs -appendToFile localfile /user/hadoop/hadoopfile</li>
	<li>hadoop fs -appendToFile localfile1 localfile2 /user/hadoop/hadoopfile</li>
	<li>hadoop fs -appendToFile localfile hdfs://nn.example.com/hadoop/hadoopfile</li>
	<li>hadoop fs -appendToFile - hdfs://nn.example.com/hadoop/hadoopfile                       //从stdin读取输入</li>
</ul><p><strong>2. 用法：hadoop fs -cat URI [URI ...]</strong></p>

<p>将源路径复制到stdout。</p>

<p>例：</p>

<ul><li>hadoop fs -cat hdfs://nn1.example.com/file1 hdfs://nn2.example.com/file2</li>
</ul><p><strong>3. 用法：hadoop fs -checksum URI</strong></p>

<p>返回文件的校验和信息。</p>

<p>例：</p>

<ul><li>hadoop fs -checksum hdfs://nn1.example.com/file1</li>
</ul><p><strong>4. 用法：hadoop fs -chgrp [-R] GROUP URI [URI ...]</strong></p>

<p>更改文件的组关联。用户必须是文件的所有者，否则必须是超级用户。</p>

<p>选项</p>

<ul><li>-R选项将通过目录结构递归地进行更改。</li>
</ul><p><strong>5. 用法：hadoop fs -chmod [-R] &lt;MODE [，MODE] ... | OCTALMODE&gt; URI [URI ...]</strong></p>

<p>更改文件的权限。使用-R，通过目录结构递归更改。用户必须是文件的所有者，否则必须是超级用户。</p>

<p>选项</p>

<ul><li>-R选项将通过目录结构递归地进行更改。</li>
</ul><p><strong>6. 用法：hadoop fs -chown [-R] [OWNER] [：[GROUP]] URI [URI]</strong></p>

<p>更改文件的所有者。用户必须是超级用户。</p>

<p>选项</p>

<ul><li>-R选项将通过目录结构递归地进行更改。</li>
</ul><p><strong>7. 用法：hadoop fs -chown [-R] [OWNER] [：[GROUP]] URI [URI]</strong></p>

<p>更改文件的所有者。用户必须是超级用户。</p>

<p>选项</p>

<ul><li>-R选项将通过目录结构递归地进行更改。</li>
</ul><p><strong>8. 用法：hadoop fs -copyFromLocal &lt;localsrc&gt; URI</strong></p>

<p>与put命令类似，但源仅限于本地文件引用。</p>

<p>选项：</p>

<ul><li>如果目标已存在，则-f选项将覆盖目标。</li>
</ul><p><strong>9. 用法：hadoop fs -copyToLocal [-ignorecrc] [-crc] URI &lt;localdst&gt;</strong></p>

<p>与get命令类似，但目标仅限于本地文件引用。</p>

<p><strong>10. 用法：hadoop fs -cp [-f] [-p | -p [topax]] URI [URI ...] &lt;dest&gt;</strong></p>

<p>将文件从源复制到目标。此命令也允许多个源，在这种情况下，目标必须是目录。</p>

<p>选项：</p>

<ul><li>如果目标已存在，则-f选项将覆盖目标。</li>
</ul><p>例：</p>

<ul><li>hadoop fs -cp /user/hadoop/file1/user/hadoop/file2</li>
</ul><p><strong>11. 用法：hadoop fs -df [-h] URI [URI ...]</strong></p>

<p>显示可用空间。</p>

<p>选项：</p>

<ul><li>-h选项将以“人类可读”的方式格式化文件大小（例如64.0m而不是67108864）</li>
</ul><p>例：</p>

<ul><li>hadoop dfs -df /user/ hadoop/dir1</li>
</ul><p><strong>12. 用法：hadoop fs -du [-s] [-h] URI [URI ...]</strong></p>

<p>显示给定目录中包含的文件和目录的大小或文件的长度。</p>

<p>选项：</p>

<ul><li>-s选项将导致显示文件长度的汇总摘要，而不是单个文件。</li>
	<li>-h选项将以“人类可读”的方式格式化文件大小（例如64.0m而不是67108864）</li>
</ul><p>例：</p>

<ul><li>hadoop fs -du /user/hadoop/dir1 /user/hadoop/file1 hdfs://nn.example.com/user/hadoop/dir1</li>
</ul><p><strong>13. 用法：hadoop fs -get</strong></p>

<p>&lt;src&gt; &lt;localdst&gt;</p>

<p>将文件复制到本地文件系统。</p>

<p>例：</p>

<ul><li>hadoop fs -get /user/hadoop/file localfile</li>
	<li>hadoop fs -get hdfs://nn.example.com/user/hadoop/file localfile</li>
</ul><p><strong>14. 用法：hadoop fs -ls [-d] [-h] [-R] [-t] [-S] [-r] [-u] &lt;args&gt;</strong></p>

<p>选项：</p>

<ul><li>-d：目录列为纯文件。</li>
	<li>-h：以人类可读的方式格式化文件大小（例如64.0m而不是67108864）。</li>
	<li>-R：递归列出遇到的子目录。</li>
	<li>-t：按修改时间排序输出（最近的第一个）。</li>
	<li>-S：按文件大小排序输出。</li>
	<li>-r：反转排序顺序。</li>
	<li>-u：使用访问时间而不是修改时间进行显示和排序。</li>
</ul><p><strong>15. 用法：hadoop fs -lsr &lt;args&gt;</strong></p>

<p>ls的递归版本。</p>

<p>注意：不推荐使用此命令。而是使用hadoop fs -ls -R</p>

<p><strong>16. 用法：hadoop fs -mkdir [-p] &lt;paths&gt;</strong></p>

<p>将路径uri作为参数并创建目录。</p>

<p>选项：</p>

<ul><li>-p选项行为与Unix mkdir -p非常相似，沿路径创建父目录。</li>
</ul><p><strong>17. 用法：hadoop fs -moveFromLocal &lt;localsrc&gt; &lt;dst&gt;</strong></p>

<p>与put命令类似，只是在复制后删除了源localsrc。</p>

<p><strong>18. 用法：hadoop fs -mv URI [URI ...] &lt;dest&gt;</strong></p>

<p>将文件从源移动到目标。此命令也允许多个源，在这种情况下，目标需要是目录。不允许跨文件系统移动文件。</p>

<p>例：</p>

<ul><li>hadoop fs -mv /user/hadoop/file1 /user/hadoop/file2</li>
</ul><p><strong>19. 用法：hadoop fs -put &lt;localsrc&gt; ... &lt;dst&gt;</strong></p>

<p>将单个src或多个srcs从本地文件系统复制到目标文件系统。还从stdin读取输入并写入目标文件系统。</p>

<ul><li>hadoop fs -put localfile /user/hadoop/hadoopfile</li>
	<li>hadoop fs -put localfile1 localfile2/user/hadoop/hadoopdir</li>
	<li>hadoop fs -put localfile hdfs://nn.example.com/hadoop/hadoopfile</li>
	<li>hadoop fs -put - hdfs://nn.example.com/hadoop/hadoopfile从stdin读取输入。</li>
</ul><p><strong>20. 用法：hadoop fs -rm [-f] [-r | -R] [-skipTrash] URI [URI ...]</strong></p>

<p>删除指定为args的文件。</p>

<p>选项：</p>

<ul><li>如果文件不存在，-f选项将不显示诊断消息或修改退出状态以反映错误。</li>
	<li>-R选项以递归方式删除目录及其下的任何内容。</li>
	<li>-r选项等效于-R。</li>
</ul><p>例：</p>

<ul><li>hadoop fs -rm hdfs：//nn.example.com/file / user / hadoop / emptydir</li>
</ul><p><strong>21. 用法：hadoop fs -rmdir [--ignore-fail-on-non-empty] URI [URI ...]</strong></p>

<p>删除目录。</p>

<p>选项：</p>

<ul><li>--ignore-fail-on-non-empty：使用通配符时，如果目录仍包含文件，请不要失败。</li>
</ul><p>例：</p>

<ul><li>hadoop fs -rmdir /user/hadoop/emptydir</li>
</ul><p><strong>22. 用法：hadoop fs -touchz URI [URI ...]</strong></p>

<p>创建一个零长度的文件。</p>

<p><strong>23. 用法：hadoop fs -usage 命令</strong></p>

<p>返回单个命令的帮助。</p>

<p><strong>24. 用法：hadoop jar &lt;jar&gt; [mainClass] args ...</strong></p>

<p>运行一个jar文件。</p>

<p>使用yarn jar来代替启动YARN应用程序。</p>

<p><strong>25. 用法：hdfs classpath</strong></p>

<p>打印获取Hadoop jar和所需库所需的类路径</p>

<p><strong>26. 用法：</strong></p>

<p>hdfs getconf -namenodes</p>

<p>hdfs getconf -secondaryNameNodes</p>

<p>hdfs getconf -backupNodes</p>

<p>hdfs getconf -includeFile</p>

<p>hdfs getconf -excludeFile</p>

<p>hdfs getconf -nnRpcAddresses</p>

<p>hdfs getconf -confKey [key]</p>

<table border="1" cellpadding="0" cellspacing="0"><tbody><tr><td>命令选项</td>
			<td>描述</td>
		</tr><tr><td>-namenodes</td>
			<td>获取集群中的名称节点列表。</td>
		</tr><tr><td>-secondaryNameNodes</td>
			<td>获取群集中的辅助名称节点列表。</td>
		</tr><tr><td>-backupNodes</td>
			<td>获取群集中的备份节点列表。</td>
		</tr><tr><td>-includeFile</td>
			<td>获取包含文件路径，该路径定义可以加入群集的数据节点。</td>
		</tr><tr><td>-excludeFile</td>
			<td>获取排除文件路径，该路径定义需要停用的数据节点。</td>
		</tr><tr><td>-nnRpcAddresses</td>
			<td>获取namenode rpc地址</td>
		</tr><tr><td>-confKey [key]</td>
			<td>从配置中获取特定密钥</td>
		</tr></tbody></table><p><strong>27. 用法：hdfs groups [username ...]</strong></p>

<p>返回给定一个或多个用户名的组信息。</p>

<p><strong>28. 用法：hdfs version</strong></p>

<p>打印版本。</p>

<h2>三. 管理命令</h2>

<p><strong>1. 用法：</strong></p>

<p>hdfs balancer [-threshold &lt;threshold&gt;]</p>

<p>                      [-policy &lt;policy&gt;]</p>

<p>                     [-exclude [-f &lt;hosts-file&gt; | &lt;以逗号分隔的主机列表&gt;]]</p>

<p>                     [-include [-f &lt;hosts-file&gt; | &lt;以逗号分隔的主机列表&gt;]]</p>

<p>                     [-idleiterations &lt;idleiterations&gt;]</p>

<table border="1" cellpadding="0" cellspacing="0"><tbody><tr><td>-policy &lt;policy&gt;</td>
			<td>datanode（默认值）：如果每个datanode均衡，则群集是平衡的。<br>
			blockpool：如果每个datanode中的每个块池都是平衡的，则群集是平衡的。</td>
		</tr><tr><td>-threshold &lt;threshold&gt;</td>
			<td>磁盘容量的百分比。这会覆盖默认阈值。</td>
		</tr><tr><td>-exclude -f &lt;hosts-file&gt; | &lt;以逗号分隔的主机列表&gt;</td>
			<td>排除指定的数据节点不被平衡器平衡。</td>
		</tr><tr><td>-include -f &lt;hosts-file&gt; | &lt;以逗号分隔的主机列表&gt;</td>
			<td>仅包括由平衡器平衡的指定数据节点。</td>
		</tr><tr><td>-idleiterations &lt;iterations&gt;</td>
			<td>退出前的最大空闲迭代次数。这会覆盖默认的空闲状态（5）。</td>
		</tr></tbody></table><p>运行集群平衡实用程序。管理员只需按Ctrl-C即可停止重新平衡过程。</p>

<p><strong>2. 用法：</strong></p>

<p>hdfs dfsadmin [-report [-live] [-dead] [-decommissioning]]</p>

<p>[-safemode enter | leave| get| wait]</p>

<p>[-saveNamespace]</p>

<p>[-rollEdits]</p>

<p>[-restoreFailedStorage true | false | check]</p>

<p>[-refreshNodes] [-setQuota &lt;quota&gt; &lt;dirname&gt; ... &lt;dirname&gt;]</p>

<p>[-clrQuota &lt;dirname&gt; ... &lt;dirname &gt;]</p>

<p>[-setSpaceQuota &lt;quota&gt; &lt;dirname&gt; ... &lt;dirname&gt;]</p>

<p>[-clspSpaceQuota &lt;dirname&gt; ... &lt;dirname&gt;]</p>

<p>[-setStoragePolicy &lt;path&gt; &lt;policyName&gt;]</p>

<p>[-getStoragePolicy &lt;path&gt;</p>

<p>[-metasave filename]</p>

<p>[-refreshServiceAcl]</p>

<p>[-refreshUserToGroupsMappings]</p>

<p>[-refreshSuperUserGroupsConfiguration]</p>

<p>[-refreshCallQueue]</p>

<p>[-refresh &lt;host：ipc_port&gt; &lt;key&gt; [arg1..argn]]</p>

<p>[-reconfig &lt;datanode | ...&gt; &lt; host：ipc_port&gt; &lt;start | status&gt;]</p>

<p>[-printTopology]</p>

<p>[-refreshNamenodes datanodehost:port]</p>

<p>[-deleteBlockPool datanode-host:port blockpoolId [force]]</p>

<p>[-setBalancerBandwidth &lt;带宽，以每秒字节数为单位&gt;] </p>

<p>[-shutdownDatanode &lt;datanode_host:ipc_port&gt; [upgrade]]</p>

<p>[-getDatanodeInfo &lt;datanode_host：ipc_port&gt;]</p>

<p>[-triggerBlockReport [-incremental] &lt;datanode_host：ipc_port&gt;]</p>

<p>[-help [cmd]]</p>

<table border="1" cellpadding="0" cellspacing="0"><tbody><tr><td style="width:414px;">命令选项</td>
			<td style="width:434px;">描述</td>
		</tr><tr><td style="width:414px;">-report [-live] [-dead] [-decommissioning]</td>
			<td style="width:434px;">报告基本文件系统信息和统计信息。可选标志可用于过滤显示的DataNode列表。</td>
		</tr><tr><td style="width:414px;">-safemode enter| leave | get | wait</td>
			<td style="width:434px;">安全模式维护命令。安全模式是一种Namenode状态，其中：1.不接受对名称空间的更改（只读）2.不复制或删除块。<br>
			在Namenode启动时自动进入安全模式，并在配置的最小块百分比满足最小复制条件时自动离开安全模式。也可以手动输入安全模式，但也只能手动关闭。</td>
		</tr><tr><td style="width:414px;">-saveNamespace</td>
			<td style="width:434px;">将当前名称空间保存到存储目录并重置编辑日志。需要安全模式。</td>
		</tr><tr><td style="width:414px;">-rollEdits</td>
			<td style="width:434px;">在活动NameNode上滚动编辑日志。</td>
		</tr><tr><td style="width:414px;">-restoreFailedStorage true | false | check</td>
			<td style="width:434px;">此选项将打开/关闭自动尝试以还原失败的存储副本。如果故障存储再次可用，系统将尝试在检查点期间恢复编辑和/或fsimage。'check'选项将返回当前设置。</td>
		</tr><tr><td style="width:414px;">-refreshNodes</td>
			<td style="width:434px;">重新读取主机并排除文件以更新允许连接到Namenode的数据节点集以及应该停用或重新调试的数据节点集。</td>
		</tr><tr><td style="width:414px;">-setQuota &lt;quota&gt; &lt;dirname&gt; ... &lt;dirname&gt;</td>
			<td style="width:434px;"><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/HdfsQuotaAdminGuide.html#Administrative_Commands" rel="nofollow">有关详细信息，请参阅HDFS配额指南。</a></td>
		</tr><tr><td style="width:414px;">-clrQuota &lt;dirname&gt; ... &lt;dirname&gt;</td>
			<td style="width:434px;"><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/HdfsQuotaAdminGuide.html#Administrative_Commands" rel="nofollow">有关详细信息，请参阅HDFS配额指南。</a></td>
		</tr><tr><td style="width:414px;">-setSpaceQuota &lt;quota&gt; &lt;dirname&gt; ... &lt;dirname&gt;</td>
			<td style="width:434px;"><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/HdfsQuotaAdminGuide.html#Administrative_Commands" rel="nofollow">有关详细信息，请参阅HDFS配额指南。</a></td>
		</tr><tr><td style="width:414px;">-clrSpaceQuota &lt;dirname&gt; ... &lt;dirname&gt;</td>
			<td style="width:434px;"><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/HdfsQuotaAdminGuide.html#Administrative_Commands" rel="nofollow">有关详细信息，请参阅HDFS配额指南。</a></td>
		</tr><tr><td style="width:414px;">-setStoragePolicy &lt;path&gt; &lt;policyName&gt;</td>
			<td style="width:434px;">将存储策略设置为文件或目录。</td>
		</tr><tr><td style="width:414px;">-getStoragePolicy &lt;path&gt;</td>
			<td style="width:434px;">获取文件或目录的存储策略。</td>
		</tr><tr><td style="width:414px;">-finalizeUpgrade</td>
			<td style="width:434px;">完成HDFS的升级。Datanodes删除其先前版本的工作目录，然后Namenode执行相同操作。这样就完成了升级过程。</td>
		</tr><tr><td style="width:414px;">-rollingUpgrade [&lt;query&gt; | &lt;prepare&gt; | &lt;finalize&gt;]</td>
			<td style="width:434px;"><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html#dfsadmin_-rollingUpgrade" rel="nofollow">有关详细信息，请参见滚动升级文档</a></td>
		</tr><tr><td style="width:414px;">-metasave 文件名</td>
			<td style="width:434px;">保存的Namenode的主要数据结构，文件名由hadoop.log.dir属性指定的目录。如果存在，则覆盖filename。filename将包含以下每一行的一行<br>
			1.使用Namenode心跳的数据节点<br>
			2.等待复制的<br>
			块3.当前正在复制的<br>
			块4.等待删除的块</td>
		</tr><tr><td style="width:414px;">-refreshServiceAcl</td>
			<td style="width:434px;">重新加载服务级别授权策略文件。</td>
		</tr><tr><td style="width:414px;">-refreshUserToGroupsMappings</td>
			<td style="width:434px;">刷新用户到组的映射。</td>
		</tr><tr><td style="width:414px;">-refreshSuperUserGroupsConfiguration</td>
			<td style="width:434px;">刷新超级用户代理组映射</td>
		</tr><tr><td style="width:414px;">-refreshCallQueue</td>
			<td style="width:434px;">从config重新加载呼叫队列。</td>
		</tr><tr><td style="width:414px;">-refresh &lt;host:ipc_port&gt; &lt;key&gt; [arg1..argn]</td>
			<td style="width:434px;">触发&lt;host：ipc_port&gt;上&lt;key&gt;指定的资源的运行时刷新。之后的所有其他args被发送到主机。</td>
		</tr><tr><td style="width:414px;">-reconfig &lt;datanode | ...&gt; &lt;host：ipc_port&gt; &lt;start | status&gt;</td>
			<td style="width:434px;">开始重新配置或获取正在进行的重新配置的状态。第二个参数指定节点类型。目前，仅支持重新加载DataNode的配置。</td>
		</tr><tr><td style="width:414px;">-printTopology</td>
			<td style="width:434px;">打印Namenode报告的机架树及其节点</td>
		</tr><tr><td style="width:414px;">-refreshNamenodes datanodehost：port</td>
			<td style="width:434px;">对于给定的datanode，重新加载配置文件，停止服务已删除的块池并开始提供新的块池。</td>
		</tr><tr><td style="width:414px;">-deleteBlockPool datanode-host：port blockpoolId [force]</td>
			<td style="width:434px;">如果传递force，则删除给定datanode上给定blockpool id的块池目录及其内容，否则仅当目录为空时才删除该目录。如果datanode仍在为块池提供服务，该命令将失败。请参阅refreshNamenodes以关闭datanode上的块池服务。</td>
		</tr><tr><td style="width:414px;">-setBalancerBandwidth &lt;带宽，以每秒字节数为单位&gt;</td>
			<td style="width:434px;">在HDFS块平衡期间更改每个datanode使用的网络带宽。&lt;bandwidth&gt;是每个datanode将使用的每秒最大字节数。此值将覆盖dfs.balance.bandwidthPerSec参数。注意：新值在DataNode上不是持久的。</td>
		</tr><tr><td style="width:414px;">-fetchImage &lt;本地目录&gt;</td>
			<td style="width:434px;">从NameNode下载最新的fsimage并将其保存在指定的本地目录中。</td>
		</tr><tr><td style="width:414px;">-shutdownDatanode &lt;datanode_host：ipc_port&gt; [upgrade]</td>
			<td style="width:434px;"><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html#dfsadmin_-shutdownDatanode" rel="nofollow">提交给定datanode的关闭请求。</a></td>
		</tr><tr><td style="width:414px;">-getDatanodeInfo &lt;datanode_host：ipc_port&gt;</td>
			<td style="width:434px;"><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html#dfsadmin_-getDatanodeInfo" rel="nofollow">获取有关给定datanode的信息。</a></td>
		</tr><tr><td style="width:414px;">-triggerBlockReport [-incremental] &lt;datanode_host：ipc_port&gt;</td>
			<td style="width:434px;">触发给定datanode的块报告。如果指定'incremental'，则是一个完整的块报告。</td>
		</tr><tr><td style="width:414px;">-help [cmd]</td>
			<td style="width:434px;">显示给定命令或所有命令的帮助（如果未指定）。</td>
		</tr></tbody></table><p><strong>3. 用法：</strong></p>

<p>hdfs haadmin -checkHealth &lt;serviceId&gt;</p>

<p>hdfs haadmin -failover [--forcefence] [--forceactive] &lt;serviceId&gt; &lt;serviceId&gt;</p>

<p>hdfs haadmin -getServiceState &lt;serviceId&gt;</p>

<p>hdfs haadmin -help &lt;command&gt;</p>

<p>hdfs haadmin -transitionToActive &lt;serviceId&gt; [ - -forceactive]</p>

<p>hdfs haadmin -transitionToStandby &lt;serviceId&gt;</p>

<table border="1" cellpadding="0" cellspacing="0"><tbody><tr><td>命令选项</td>
			<td>描述</td>
		</tr><tr><td>-checkHealth</td>
			<td>检查给定NameNode的运行状况</td>
		</tr><tr><td>-failover</td>
			<td>在两个NameNode之间启动故障转移</td>
		</tr><tr><td>-getServiceState</td>
			<td>确定给定的NameNode是活动还是待机</td>
		</tr><tr><td>-transitionToActive</td>
			<td>将给定NameNode的状态转换为Active（警告：不执行防护）</td>
		</tr><tr><td>-transitionToStandby</td>
			<td>将给定NameNode的状态转换为Standby（警告：没有完成防护）</td>
		</tr></tbody></table><p><strong>4. 用法：hdfs journalnode</strong></p>

<p>此comamnd启动一个日志节点，用于<a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#Administrative_commands" rel="nofollow">与QJM一起</a>使用<a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#Administrative_commands" rel="nofollow">HDFS HA</a>。</p>

<p><strong>5. 用法：hdfs mover [-p &lt;files / dirs&gt; | -f &lt;本地文件名&gt;]</strong></p>

<table border="1" cellpadding="0" cellspacing="0"><tbody><tr><td>命令选项</td>
			<td>描述</td>
		</tr><tr><td>-f &lt;本地文件&gt;</td>
			<td>指定包含要迁移的HDFS文件/目录列表的本地文件。</td>
		</tr><tr><td>-p &lt;files / dirs&gt;</td>
			<td>指定要迁移的HDFS文件/目录的空格分隔列表。</td>
		</tr></tbody></table><p>运行数据迁移实用程序。</p>

<p>请注意，当省略-p和-f选项时，默认路径是根目录。</p>

<p><strong>6. hdfs namenode [-backup]</strong></p>

<p>                              [-checkpoint]</p>

<p>                              [-format [-clusterid cid] [-force] [-nonInteractive]]</p>

<p>                              [-upgrade [-clusterid cid] [-renameReserved &lt;kv pairs&gt;]]</p>

<p>                              [-upgradeOnly [-clusterid cid] [-renameReserved &lt;kv pairs&gt;]]</p>

<p>                              [-rollback] | [-rollingUpgrade &lt;downgrade | rollback&gt;] | [-finalize]</p>

<p>                              [-importCheckpoint] | [-initializeSharedEdits] | [-bootstrapStandby]</p>

<p>                              [-recover [-force]] | [-metadataVersion]</p>

<table border="1" cellpadding="0" cellspacing="0"><tbody><tr><td style="width:402px;">命令选项</td>
			<td style="width:446px;">描述</td>
		</tr><tr><td style="width:402px;">-backup</td>
			<td style="width:446px;">启动备份节点。</td>
		</tr><tr><td style="width:402px;">-checkpoint</td>
			<td style="width:446px;">启动检查点节点。</td>
		</tr><tr><td style="width:402px;">-format [-clusterid cid] [-force] [-nonInteractive]</td>
			<td style="width:446px;">格式化指定的NameNode。它启动NameNode，对其进行格式化然后将其关闭。如果名称目录存在，则为-force选项格式。如果名称目录存在，则-nonInteractive选项将中止，除非指定了-force选项。</td>
		</tr><tr><td style="width:402px;">-upgrade [-clusterid cid] [ -renameReserved &lt;kv pairs&gt;]</td>
			<td style="width:446px;">在分发新的Hadoop版本后，应该使用升级选项启动Namenode。</td>
		</tr><tr><td style="width:402px;">-upgradeOnly [-clusterid cid] [ -renameReserved &lt;kv pairs&gt;]</td>
			<td style="width:446px;">升级指定的NameNode然后关闭它。</td>
		</tr><tr><td style="width:402px;">-rollback</td>
			<td style="width:446px;">将NameNode回滚到以前的版本。这应该在停止集群并分发旧的Hadoop版本后使用。</td>
		</tr><tr><td style="width:402px;">-rollingUpgrade &lt;downgrade | rollback | started&gt;</td>
			<td style="width:446px;"><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html#NameNode_Startup_Options" rel="nofollow">有关详细信息，请参见滚动升级文档</a></td>
		</tr><tr><td style="width:402px;">-finalize</td>
			<td style="width:446px;">Finalize将删除文件系统的先前状态。最近的升级将成为永久性。回滚选项将不再可用。完成后，它会关闭NameNode。</td>
		</tr><tr><td style="width:402px;">-importCheckpoint</td>
			<td style="width:446px;">从检查点目录加载图像并将其保存到当前目录中。从属性fs.checkpoint.dir读取检查点目录</td>
		</tr><tr><td style="width:402px;">-initializeSharedEdits</td>
			<td style="width:446px;">格式化新的共享编辑目录并复制足够的编辑日志段，以便备用NameNode可以启动。</td>
		</tr><tr><td style="width:402px;">-bootstrapStandby</td>
			<td style="width:446px;">允许通过从活动NameNode复制最新的命名空间快照来引导备用NameNode的存储目录。首次配置HA群集时使用此选项。</td>
		</tr><tr><td style="width:402px;">-recover [-force]</td>
			<td style="width:446px;"><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html#Recovery_Mode" rel="nofollow">在损坏的文件系统上恢复丢失的元数据。有关详细信息，请参阅HDFS用户指南。</a></td>
		</tr><tr><td style="width:402px;">-metadataVersion</td>
			<td style="width:446px;">验证配置的目录是否存在，然后打印软件和映像的元数据版本。</td>
		</tr></tbody></table><p><strong>7. 用法：hdfs storagepolicies</strong></p>

<p>列出所有存储策略。</p>

<p><strong>8. 用法：hdfs zkfc [-formatZK [-force] [-nonInteractive]]</strong></p>

<table border="1" cellpadding="0" cellspacing="0"><tbody><tr><td>命令选项</td>
			<td>描述</td>
		</tr><tr><td>-formatZK</td>
			<td>格式化Zookeeper实例</td>
		</tr><tr><td>-H</td>
			<td>显示帮助</td>
		</tr></tbody></table><p>此comamnd启动Zookeeper故障转移控制器进程，以便与<a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#Administrative_commands" rel="nofollow">HDJ HA和QJM一起使用</a>。</p>

<p><strong>9. 用法：hdfs debug verify [-meta &lt;metadata-file&gt;] [-block &lt;block-file&gt;]</strong></p>

<table border="1" cellpadding="0" cellspacing="0"><tbody><tr><td>命令选项</td>
			<td>描述</td>
		</tr><tr><td>-block 块的文件</td>
			<td>可选参数，用于指定数据节点的本地文件系统上的块文件的绝对路径。</td>
		</tr><tr><td>-meta 元数据文件</td>
			<td>数据节点的本地文件系统上的元数据文件的绝对路径。</td>
		</tr></tbody></table><p>验证HDFS元数据和块文件。如果指定了块文件，我们将验证元数据文件中的校验和是否与块文件匹配。</p>            </div>
                </div>