---
layout:     post
title:      Spark四种运行模式
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<div id="article_content" class="article_content tracking-ad">

<p>转载：http://blog.cheyo.net/29.html</p>
<p><br>
</p>
<p></p>
<h3 id="介绍"><a target="_blank"></a>
介绍</h3>
<ul>
<li>
本地模式</li></ul>
<p></p>
<p>
Spark单机运行，一般用于开发测试。</p>
<ul>
<li>
Standalone模式</li></ul>
<p>
构建一个由Master+Slave构成的Spark集群，Spark运行在集群中。</p>
<ul>
<li>
Spark on Yarn模式</li></ul>
<p>
Spark客户端直接连接Yarn。不需要额外构建Spark集群。</p>
<ul>
<li>
Spark on Mesos模式</li></ul>
<p>
Spark客户端直接连接Mesos。不需要额外构建Spark集群。</p>
<h4 id="启动方式-spark-shellshscala"><a target="_blank"></a>
启动方式: spark-shell.sh(Scala)</h4>
<p>
spark-shell通过不同的参数控制采用何种模式进行。 涉及两个参数：</p>
<div class="highlight">
<br><br><br><br><table class="highlighttable ">
<tbody>
<tr>
<td class="linenos">
<div class="linenodiv">
<pre>1
2
3
4</pre>
</div>

<p></p></td> 
<td class="code">

<div class="highlight">
<pre>--master MASTER_URL         spark://host:port, mesos://host:port, yarn, or local.
--deploy-mode DEPLOY_MODE   Whether to launch the driver program locally <span class="o">(</span><span class="s2">"client"</span><span class="o">)</span> or
                            on one of the worker machines inside the cluster <span class="o">(</span><span class="s2">"cluster"</span><span class="o">)</span>
                            <span class="o">(</span>Default: client<span class="o">)</span>.
</pre>
</div>

<p></p></td> 
</tr> 
</tbody> 
</table> <br>
</div>

<p>
–master参数用于指定采用哪种运行模式。<br>
对于Spark on Yarn模式和Spark on Mesos模式还可以通过 –deploy-mode参数控制Drivers程序的启动位置。</p>

<ul>
<li>
进入本地模式：</li></ul>

<pre><code>./spark-shell --master local
./spark-shell --master local[2]  # 本地运行,两个worker线程,理想状态下为本地CPU core数</code></pre>
<ul>
<li>
进入Standalone模式：</li></ul>
<pre><code>./spark-shell --master spark://192.168.1.10:7077</code></pre>
<p>
备注：测试发现MASTER_URL中使用主机名替代IP地址无法正常连接(hosts中有相关解析记录)，即以下命令连接不成功：</p>
<pre><code>./spark-shell --master spark://ctrl:7077  # 连接失败</code></pre>
<ul>
<li>
Spark on Yarn模式</li></ul>
<div class="highlight">
<br><br><br><table class="highlighttable ">
<tbody>
<tr>
<td class="linenos">
<div class="linenodiv">
<pre>1
2
3
4
5
6
7</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre>./spark-shell --master yarn
./spark-shell --master yarn-client
<span class="c">#不支持这种模式</span>
<span class="c">#./spark-shell --master yarn-cluster</span>
./spark-shell --master yarn --deploy-mode client
<span class="c">#不支持这种模式</span>
<span class="c">#./spark-shell --master yarn --deploy-mode cluster</span>
</pre>

<p></p></div> <br>
</td> 
</tr> 
</tbody> 
</table> <br>
</div>

<p>
备注：Yarn的连接信息在Hadoop客户端的配置文件中指定。通过spark-env.sh中的环境变量HADOOP<span>CONF</span>DIR指定Hadoop配置文件路径。</p>

<ul>
<li>
Spark on Mesos模式：</li></ul>

<pre><code>./spark-shell --master mesos://host:port
./spark-shell --master mesos://host:port --deploy-mode client
./spark-shell --master mesos://host:port --deploy-mode cluster</code></pre>

<h4 id="启动方式-pysparkpython"><a target="_blank"></a>
启动方式: pyspark(Python)</h4>

<p>
参数及用法与Scala语言的spark-shell相同，比如：</p>

<pre><code>pyspark --master local[2]</code></pre>

<p><br></p>

<p></p></div>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>