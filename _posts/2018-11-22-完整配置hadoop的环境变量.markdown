---
layout:     post
title:      完整配置hadoop的环境变量
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>修改hadoop解压文件名称 ：</p>
<p> mv hadoop-2.4.1 hadoop</p>
<p>将hadoop安装目录的权限赋值为hadoop用户：</p>
<p>chown -R hadoop:hadoop hadoop<br></p>
<p>创建Hadoop数据目录，并赋予权限：</p>
<p>[root@djt java]# mkdir -p /data/dfs/name<br>
[root@djt java]# mkdir -p /data/dfs/data<br>
[root@djt java]# mkdir -p /data/tmp<br>
[root@djt java]# chown -R hadoop:hadoop hadoop /data/<br>
[root@djt java]# ls -l /d<br>
data/ dev/  <br>
[root@djt java]# ls -l /data/<br>
total 8<br>
drwxr-xr-x 4 hadoop hadoop 4096 May 21 17:26 dfs<br>
drwxr-xr-x 2 hadoop hadoop 4096 May 21 17:26 tmp<br></p>
<p>1.1修改主机名<br><span></span>vim /etc/sysconfig/network<br><span></span><br><span></span>NETWORKING=yes<br><span></span>HOSTNAME=itcast    ###<br><br><br><span></span>1.2修改IP<br><span></span>两种方式：<br><span></span>第一种：通过Linux图形界面进行修改（强烈推荐）<br><span></span>进入Linux图形界面 -&gt; 右键点击右上方的两个小电脑 -&gt; 点击Edit connections -&gt; 选中当前网络System eth0 -&gt; 点击edit按钮 -&gt; 选择IPv4 -&gt; method选择为manual -&gt; 点击add按钮 -&gt; 添加IP：192.168.1.101 子网掩码：255.255.255.0 网关：192.168.1.1 -&gt; apply<br><span></span><br><span></span>第二种：修改配置文件方式（屌丝程序猿专用）<br><span></span>vim /etc/sysconfig/network-scripts/ifcfg-eth0<br><span></span><br><span></span>DEVICE="eth0"<br><span></span>BOOTPROTO="static"               ###<br><span></span>HWADDR="00:0C:29:3C:BF:E7"<br><span></span>IPV6INIT="yes"<br><span></span>NM_CONTROLLED="yes"<br><span></span>ONBOOT="yes"<br><span></span>TYPE="Ethernet"<br><span></span>UUID="ce22eeca-ecde-4536-8cc2-ef0dc36d4a8c"<br><span></span>IPADDR="192.168.1.101"           ###<br><span></span>NETMASK="255.255.255.0"          ###<br><span></span>GATEWAY="192.168.1.1"            ###<br><span></span><br><span></span>1.3修改主机名和IP的映射关系<br><span></span>vim /etc/hosts<br><span></span><br><span></span>192.168.1.101<span> </span>
localhost<br><span></span><br><span></span>1.4关闭防火墙<br><span></span>#查看防火墙状态<br><span></span>service iptables status<br><span></span>#关闭防火墙<br><span></span>service iptables stop<br><span></span>#查看防火墙开机启动状态<br><span></span>chkconfig iptables --list<br><span></span>#关闭防火墙开机启动<br><span></span>chkconfig iptables off<br><span></span><br><span></span>1.5重启Linux<br><span></span>reboot<br><br><br>
2.安装JDK<br><span></span>2.1上传alt+p 后出现sftp窗口，然后put d:\xxx\yy\ll\jdk-7u_65-i585.tar.gz<br><span></span><br><span></span>2.2解压jdk<br><span></span>#创建文件夹<br><span></span>mkdir /home/hadoop/app<br><span></span>#解压<br><span></span>tar -zxvf jdk-7u55-linux-i586.tar.gz -C /home/hadoop/app<br><span></span><br><span></span>2.3将java添加到环境变量中<br><span></span>vim /etc/profile<br><span></span>#在文件最后添加<br><span></span>export JAVA_HOME=/root/hadoop/app/jdk1.7.0_65<br><span></span>export PATH=$PATH:$JAVA_HOME/bin<br><span></span><br><span></span>#刷新配置<br><span></span>source /etc/profile<br><span></span><br>
3.安装hadoop2.4.1<br><span></span>先上传hadoop的安装包到服务器上去/home/hadoop/<br><span></span>注意：hadoop2.x的配置文件$HADOOP_HOME/etc/hadoop<br><span></span>伪分布式需要修改5个配置文件<br>
        第一个配置hadoop环境变量<br><span></span>HADOOP_HOME=/usr/java/hadoop<br><span></span>PATH=$HADOOP_HOME/bin:$PATH<br><span></span>export HADOOP_HOME PATH<span>
</span><br><span></span>第二个：core-site.xml<br><br><br>
&lt;!-- 指定HADOOP所使用的文件系统schema（URI），HDFS的老大（NameNode）的地址 --&gt;<br>
&lt;property&gt;<br><span></span>&lt;name&gt;fs.defaultFS&lt;/name&gt;<br><span></span>&lt;value&gt;hdfs://djt:9000&lt;/value&gt;<br>
&lt;/property&gt;<br>
&lt;property&gt;<br><span></span>&lt;name&gt;io.file.buffer.size&lt;/name&gt;<br><span></span>&lt;value&gt;131072&lt;/value&gt;<br>
&lt;/property&gt;<br>
&lt;property&gt;<br><span></span>&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;<br><span></span>&lt;value&gt;file:/data/tmp&lt;/value&gt;<br><span></span>&lt;description&gt;Abase for other temporary directories.&lt;/description&gt;<br>
&lt;/property&gt;<br>
&lt;property&gt;<br><span></span>&lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt;<br><span></span>&lt;value&gt;*&lt;/value&gt;<br>
&lt;/property&gt;<br>
&lt;property&gt;<br><span></span>&lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt;<br><span></span>&lt;value&gt;*&lt;/value&gt;<br>
&lt;/property&gt;<br><span></span><br><span></span>第三个：hdfs-site.xml   <br><span></span>&lt;!-- 指定HDFS副本的数量 --&gt;<br>
&lt;configuration&gt;<br>
&lt;property&gt;<br><span></span>&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;<br><span></span>&lt;value&gt;/data/dfs/name&lt;/value&gt;<br><span></span>&lt;final&gt;ture&lt;/final&gt;<br>
&lt;/property&gt;<br>
&lt;property&gt;<br><span></span>&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;<br><span></span>&lt;value&gt;/data/dfs/data&lt;/value&gt;<br><span></span>&lt;final&gt;ture&lt;/final&gt;<br>
&lt;/property&gt;<br>
&lt;property&gt;<br><span></span>&lt;name&gt;dfs.replication&lt;/name&gt;<br><span></span>&lt;value&gt;1&lt;/value&gt;<br>
&lt;/property&gt;<br>
&lt;property&gt;<br>
&lt;name&gt;dfs.permissions&lt;/name&gt;<br>
&lt;value&gt;false&lt;/value&gt;<br>
&lt;/property&gt;<br>
&lt;/configuration&gt;<br><span></span><br><span></span>第四个：mapred-site.xml (mv mapred-site.xml.template mapred-site.xml)<br><span></span>mv mapred-site.xml.template mapred-site.xml<br><span></span>vim mapred-site.xml<br><span></span>&lt;!-- 指定mr运行在yarn上 --&gt;<br>
&lt;property&gt;<br><span></span>&lt;name&gt;mapreduce.framework.name&lt;/name&gt;<br><span></span>&lt;value&gt;yarn&lt;/value&gt;<br>
&lt;/property&gt;<br>
  五个 yarn-site.xml<br>
&lt;property&gt;<br><span></span>&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;<br><span></span>&lt;value&gt;mapreduce_shuffle&lt;/value&gt;<br>
&lt;/property&gt;<br><span></span><br>
五：vi slaves<br>
        <br><br><br>
   <br><span></span>source /etc/profile<br><span></span><br><span></span>3.3格式化namenode（是对namenode进行初始化）<br><span></span>hdfs namenode -format (hadoop namenode -format)<br><span></span><br><span></span>3.4启动hadoop<br><span></span>先启动HDFS<br><span></span>sbin/start-dfs.sh<br><span></span><br><span></span>再启动YARN<br><span></span>sbin/start-yarn.sh<br><span></span><br><span></span>3.5验证是否启动成功<br><span></span>使用jps命令验证<br><span></span>27408 NameNode<br><span></span>28218 Jps<br><span></span>27643 SecondaryNameNode<br><span></span>28066 NodeManager<br><span></span>27803 ResourceManager<br><span></span>27512 DataNode<br><span></span><br><span></span>http://192.168.1.101:50070 （HDFS管理界面）<br><span></span>http://192.168.1.101:8088 （MR管理界面）<br><span></span><br>
4.配置ssh免登陆<br><span></span>#生成ssh免登陆密钥<br><span></span>#进入到我的home目录<br><span></span>cd ~/.ssh<br><br><br><span></span>ssh-keygen -t rsa （四个回车）<br><span></span>执行完这个命令后，会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）<br><span></span>将公钥拷贝到要免登陆的机器上<br><span></span>ssh-copy-id localhost<br><span></span><br></p>
<p><br></p>
<p><br></p>
<p><br></p>
<p><br></p>
<p><br></p>
            </div>
                </div>