---
layout:     post
title:      HDFS编程实践
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h1>HDFS常用命令</h1>

<p>cd /usr/local/hadoop</p>

<p>./sbin/start-dfs.sh #启动hadoop</p>

<h2>利用Shell命令与HDFS进行交互</h2>

<p>查看fs支持了哪些命令</p>

<pre class="has">
<code class="language-bash">hadoop@ubuntu:/usr/local/hadoop$ ./bin/hadoop fs
Usage: hadoop fs [generic options]
	[-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]
	[-cat [-ignoreCrc] &lt;src&gt; ...]
	[-checksum &lt;src&gt; ...]
	[-chgrp [-R] GROUP PATH...]
	[-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]
	[-chown [-R] [OWNER][:[GROUP]] PATH...]
	[-copyFromLocal [-f] [-p] [-l] [-d] &lt;localsrc&gt; ... &lt;dst&gt;]
	[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]
	[-count [-q] [-h] [-v] [-t [&lt;storage type&gt;]] [-u] [-x] &lt;path&gt; ...]
	[-cp [-f] [-p | -p[topax]] [-d] &lt;src&gt; ... &lt;dst&gt;]
	[-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]]
	[-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;]
	[-df [-h] [&lt;path&gt; ...]]
	[-du [-s] [-h] [-x] &lt;path&gt; ...]
	[-expunge]
	[-find &lt;path&gt; ... &lt;expression&gt; ...]
	[-get [-f] [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]
	[-getfacl [-R] &lt;path&gt;]
	[-getfattr [-R] {-n name | -d} [-e en] &lt;path&gt;]
	[-getmerge [-nl] [-skip-empty-file] &lt;src&gt; &lt;localdst&gt;]
	[-help [cmd ...]]
	[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [&lt;path&gt; ...]]
	[-mkdir [-p] &lt;path&gt; ...]
	[-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]
	[-moveToLocal &lt;src&gt; &lt;localdst&gt;]
	[-mv &lt;src&gt; ... &lt;dst&gt;]
	[-put [-f] [-p] [-l] [-d] &lt;localsrc&gt; ... &lt;dst&gt;]
	[-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;]
	[-rm [-f] [-r|-R] [-skipTrash] [-safely] &lt;src&gt; ...]
	[-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]
	[-setfacl [-R] [{-b|-k} {-m|-x &lt;acl_spec&gt;} &lt;path&gt;]|[--set &lt;acl_spec&gt; &lt;path&gt;]]
	[-setfattr {-n name [-v value] | -x name} &lt;path&gt;]
	[-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...]
	[-stat [format] &lt;path&gt; ...]
	[-tail [-f] &lt;file&gt;]
	[-test -[defsz] &lt;path&gt;]
	[-text [-ignoreCrc] &lt;src&gt; ...]
	[-touchz &lt;path&gt; ...]
	[-truncate [-w] &lt;length&gt; &lt;path&gt; ...]
	[-usage [cmd ...]]
</code></pre>

<p>查看具体某个命令的作用,如查看put命令如何使用：</p>

<pre class="has">
<code class="language-bash">./bin/hadoop fs -help put</code></pre>

<h3>1、目录操作</h3>

<p>Hadoop系统安装好以后，第一次使用HDFS时，需要首先在HDFS中创建用户目录。在HDFS中为hadoop用户创建一个用户目录，命令如下：</p>

<pre class="has">
<code class="language-bash">cd /usr/local/hadoop
./bin/hdfs dfs –mkdir –p /user/hadoop</code></pre>

<pre class="has">
<code class="language-bash">cd /usr/local/hadoop
./bin/hdfs dfs –mkdir –p /user/hadoop</code></pre>

<p>该命令中表示在HDFS中创建一个“/user/hadoop”目录，“–mkdir”是创建目录的操作，“-p”表示如果是多级目录，则父目录和子目录一起创建，这里“/user/hadoop”就是一个多级目录，因此必须使用参数“-p”，否则会出错。<br>
“/user/hadoop”目录就成为hadoop用户对应的用户目录，可以使用如下命令显示HDFS中与当前用户hadoop对应的用户目录下的内容：</p>

<pre class="has">
<code class="language-bash">./bin/hdfs dfs –ls . #等价于./bin/hdfs dfs –ls /user/hadoop</code></pre>

<p>该命令中，“-ls”表示列出HDFS某个目录下的所有内容，“.”表示HDFS中的当前用户目录，也就是“/user/hadoop”目录。</p>

<p> </p>

<p>列出HDFS上的所有目录：</p>

<pre class="has">
<code class="language-bash">./bin/hdfs dfs –ls</code></pre>

<p>创建一个input目录：</p>

<pre class="has">
<code class="language-bash">./bin/hdfs dfs –mkdir input</code></pre>

<p>在创建个input目录时，采用了相对路径形式，实际上，这个input目录创建成功以后，它在HDFS中的完整路径是“/user/hadoop/input”。</p>

<p>在HDFS的根目录下创建一个名称为input的目录：</p>

<pre class="has">
<code class="language-bash">./bin/hdfs dfs –mkdir /input</code></pre>

<p>使用rm命令删除一个目录，如，可以使用如下命令删除刚才在HDFS中创建的“/input”目录（不是“/user/hadoop/input”目录）：</p>

<pre class="has">
<code class="language-bash">./bin/hdfs dfs –rm –r /input</code></pre>

<p>“-r”参数表示如果删除“/input”目录及其子目录下的所有内容，如果要删除的一个目录包含了子目录，则必须使用“-r”参数，否则会执行失败。</p>

<h3>2、文件操作</h3>

<p>使用vim编辑器，在本地Linux文件系统的“/home/hadoop/”目录下创建一个文件me.txt，里面输入如下三行：</p>

<pre class="has">
<code class="language-bash">vim me.txt</code></pre>

<pre class="has">
<code class="language-bash">you
me
friends
</code></pre>

<p>把本地文件系统的“/home/hadoop/me.txt”上传到HDFS中的当前用户目录的input目录下，也就是上传到HDFS的“/user/hadoop/input/”目录下：</p>

<pre class="has">
<code class="language-bash">./bin/hdfs dfs -put /home/hadoop/me.txt input</code></pre>

<p>使用ls命令查看文件是否成功上传到HDFS中：</p>

<pre class="has">
<code class="language-bash">./bin/hdfs dfs –ls input</code></pre>

<p>查看文件内容：</p>

<pre class="has">
<code class="language-bash">./bin/hdfs dfs –cat input/myLocalFile.txt</code></pre>

<p>如何把文件从HDFS中的一个目录拷贝到HDFS中的另外一个目录。比如，如果要把HDFS的“/user/hadoop/input/me.txt”文件，拷贝到HDFS的另外一个目录“/input”中（注意，这个input目录位于HDFS根目录下），可以使用如下命令：</p>

<pre class="has">
<code class="language-bash">./bin/hdfs dfs -cp input/myLocalFile.txt /input</code></pre>            </div>
                </div>