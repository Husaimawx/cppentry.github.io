---
layout:     post
title:      分布式发布订阅消息系统Kafka单实例测试
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/fjssharpsword/article/details/60758304				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
1、Kafka简介<br>
Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。<br>
kafka对消息保存时根据Topic进行归类，发送消息者成为Producer,消息接受者成为Consumer,此外kafka集群有多个kafka实例组成，每个实例(server)成为broker。<br>
无论是kafka集群，还是producer和consumer都依赖于zookeeper来保证系统可用性集群保存一些meta信息。<br><br><img src="https://img-blog.csdn.net/20170307115914028?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmpzc2hhcnBzd29yZA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br>
2、Kafka安装和启动<br><br><br>
1)下载并解压kafka_2.10-0.10.1.1.tgz<br>
  #tar -xzvf kafka_2.10-0.10.1.1.tgz<br><br><br>
2)下载并解压zookeeper-3.4.6.tar.gz<br>
  #tar -xzvf zookeeper-3.4.6.tar.gz<br><br><br>
3)启动单实例Zookkeeper服务<br>
  #cd zookeeper-3.4.6<br>
  conf文件夹中新建名zoo.cfg文件，可复制zoo_sample.cfg文件进行相应修改。<br>
  启动服务：<br>
  #bin/zkServer.sh &amp;<br>
  <br>
4)启动Kafka服务<br>
   #cd kafka_2.10<br>
   配置config/server.properties相应信息，如zookeeper.connect；<br>
   启动服务：<br>
   #bin/kafka-server-start.sh config/server.properties &amp;<br><br><br>
3、测试：<br>
   1)创建topic<br>
   #bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test0307<br>
   通过list命令查看创建的topic:<br>
   #bin/kafka-topics.sh --list --zookeeper localhost:2181<br>
   2)生产消息<br>
    Kafka 使用一个简单的命令行producer，从文件中或者从标准输入中读取消息并发送到服务端。<br>
    默认的每条命令将发送一条消息。运行producer并在控制台中输一些消息，这些消息将被发送到服务端：<br>
    #bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test0307<br>
     I am testing kafka for inputing message into HDFS.<br>
     不发送就ctrl+c退出。<br>
   3)消费消息<br>
     Kafka命令行consumer可以读取消息并输出到标准输出：<br>
     #bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test0307 --from-beginning<br><br><br>
4、后续待研究： <br>
1）这是单实例测试，可以在一台机子上配置多个broker，也可以建立kafka集群。<br>
2）kafka的producer可以来自flume的sink，其consumer可以输出到hdfs中。<br>
参考：http://www.cnblogs.com/cssdongl/p/6077311.html
            </div>
                </div>