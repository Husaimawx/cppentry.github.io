---
layout:     post
title:      hive学习笔记1
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <span style="font-size:16px;">Hive是构建在Hadoop的数据仓库平台，最初Hive被Facebook用来处理海量的用户和日志数据。利用Hive处理分析的数据一般满足结构化的特征，Hive基于MapReduce之上增加了优化和更可用性的特性，Hive把用户从复杂的MapReduce编程中解脱出来，Hive定义了类似于SQL的查询语言：HQL，Hive能够将HQL转换为相应的MapReduce程序，并在Hadoop平台上执行。</span>
<p><span style="font-size:16px;"></span></p>
<p><span style="font-size:16px;">一、Hive的安装与启动</span></p>
<p><span style="font-size:16px;"> Hive的运行环境需要Jdk1.6、Hadoop0.17及以上版本，在这里我下载了hive-0.6.0.tar.gz。解压到/usr/local/hive，在环境变量中</span></p>
<div class="dp-highlighter">
<div class="bar">
<div class="tools">Shell代码 <a title="收藏这段代码"><img class="star" src="http://xm-king.iteye.com/images/icon_star.png" alt="收藏代码"></a>
</div>
</div>
<ol class="dp-default" start="1"><li><span><span>&lt;spanstyle=</span><span class="string">"font-size:medium;"</span><span>&gt;HIVE_HOME=/usr/local/hive</span></span></li>
<li><span>PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HIVE_HOME/bin&lt;/span&gt;</span></li>
<li><span>&lt;spanstyle=<span class="string">"font-size:medium;"</span><span>&gt;</span></span></li>
<li><span>&lt;/span&gt;</span></li>
</ol></div>
<p><span style="font-size:16px;"> 首先，启动Hadoop，到HADOOP_HOME/bin下，执行start-all.sh，然后在命令行中输入hive，回车，就进入了Hive的执行界面：</span></p>
<p><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92258/4b8d4092-1cb9-398e-b7ae-e51873bfc4da.jpg" alt="" height="45" width="580"></span></p>
<p><span style="font-size:16px;">二、HQL</span></p>
<p><span style="font-size:16px;">create table 语句</span></p>
<p><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92260/c2df43c9-f8f1-364f-9c90-be7bffc6bf02.jpg" alt="" height="69" width="350"></span></p>
<p><span style="font-size:16px;"> 第一行声明了一个名为user的一张表，该表包括两个字段id和name，分别为int和string类型。剩下的两行表示在存储user的数据的文件中每一行应该有三个字段，字段用tab键隔开，每行用回车隔开。</span></p>
<p><span style="font-size:16px;">Load Data语句</span></p>
<p><span style="font-size:16px;"> 将数据加载到user表中</span></p>
<p><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92262/683e7fad-f2cb-3fd4-9816-3f4db135786c.jpg" alt="" height="97" width="347"></span></p>
<p><span style="font-size:16px;">通过上面的命令告诉Hive将sample.txt移动到hive的仓库目录(默认为/user/hive/warehouse)下面，在这个过程中不涉及到文件的解析，hive也不会按照特殊的格式来存储sample.txt。我们可以通过命令来浏览HDFS目录</span></p>
<p><span style="font-size:16px;"><img class="magplus" title="点击查看原始大小图片" src="http://dl.iteye.com/upload/picture/pic/92264/6e5c5f70-8882-3c52-a29f-5d060a25c5fc.jpg" alt="" height="65" width="700"></span></p>
<p><span style="font-size:16px;">select 语句</span></p>
<p><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92266/1136c25c-0e34-3b27-bab4-f05f834785b6.jpg" alt="" height="123" width="205"></span></p>
<p><span style="font-size:16px;"> HQL的select操作和SQL非常相似，但是也有一些细微差别，这在以后会慢慢地讲到的</span></p>
<p><span style="font-size:16px;">三、partitions and buckets</span></p>
<p><span style="font-size:16px;"> hive可以通过partitions将表粗粒度划分为不同的目录来提高查询的效率，例如包含时间戳的日志文件，如果我们按照时间来把日志文件分在不同的目录下，那么相同日期的记录就会存储在同一个分区目录下面，那我们就可以更高效率地查询特定某个时间的记录了。例如：</span></p>
<p><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92268/b04dedde-521d-340a-b3b7-95aeabe1c96a.jpg" alt="" height="81" width="375"></span></p>
<p><span style="font-size:16px;">通过partitioned by声明的字段表面上和在普通的column没什么不一样的。如下所示：</span></p>
<p><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92270/4222b0f4-ef5d-355d-b53b-c313d9465b15.jpg" alt="" height="95" width="200"></span></p>
<p><span style="font-size:16px;"> 不同之处在于，表并不存储通过partitioned by声明的字段，而是将不同字段的数据放在partitioned字段目录下面，通过路径来获得partitioned字段的值。所以在我们想partitioned 表中加载数据时，需要指明partitioned 字段的值，例如：</span></p>
<p><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92274/b1c78c6b-c0a9-3d40-b0e4-2224b0abf2b8.jpg" alt="" height="94" width="504"></span></p>
<p><span style="font-size:16px;"> 我们可以查看一个table的partitioned 情况：</span></p>
<p><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92272/86c1157e-1738-3acc-bf42-60bb3d699690.jpg" alt="" height="92" width="215"></span></p>
<p><span style="font-size:16px;"></span></p>
<p><span style="font-size:16px;"> 为了是查询效率更高以及采样数据更方便，在Hive中引入了bucket的概念，首先来看一下如何产生一个bucketed的table。</span></p>
<p><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92276/94e58507-8d71-35a7-8e2c-dd0321cab81b.jpg" alt="" height="57" width="420"></span></p>
<p><span style="font-size:16px;"> 首先需要将Hive的hive.enforce.bucketing属性设置为ture，然后加载数据：</span></p>
<p><span style="font-size:16px;"><img class="magplus" title="点击查看原始大小图片" src="http://dl.iteye.com/upload/picture/pic/92278/a68b8629-15f3-3466-a994-a9759697e45b.jpg" alt="" height="258" width="700"></span></p>
<p><span style="font-size:16px;"> 下面我们来看一下bucketed_user 下的数据文件结构,包含了四个部分。</span></p>
<p><span style="font-size:16px;"><img class="magplus" title="点击查看原始大小图片" src="http://dl.iteye.com/upload/picture/pic/92282/853249d7-280a-3247-a92c-cd593555da83.jpg" alt="" height="92" width="700"></span></p>
<p><span style="font-size:16px;"> 我们随便查看一个文件</span></p>
<p><span style="font-size:16px;"><img class="magplus" title="点击查看原始大小图片" src="http://dl.iteye.com/upload/picture/pic/92284/5d613212-1368-37d3-96f3-aa127df96cc2.jpg" alt="" height="41" width="700"></span></p>
<p><span style="font-size:16px;"> 可以看到id为1和5的记录被放进了同一个文件中，主要是应为我们设置了bucketed的参数为4，hive会按照id的hash值对4取模来确定存储的bucketed。</span></p>
<br>            </div>
                </div>