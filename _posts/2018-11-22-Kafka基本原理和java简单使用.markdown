---
layout:     post
title:      Kafka基本原理和java简单使用
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，转载请注明出处。					https://blog.csdn.net/LeiXiaoTao_Java/article/details/80019456				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h1><strong>Apache Kafka<span style="font-family:'宋体';">学习（一）：</span><span style="font-family:Calibri;">Kafka</span><span style="font-family:'宋体';">基本原理</span></strong></h1><h2><strong>1<span style="font-family:'黑体';">、什么是</span><span style="font-family:Arial;">Kafka</span><span style="font-family:'黑体';">？</span></strong></h2><p>Kafka<span style="font-family:'宋体';">是一个使用</span><span style="font-family:Calibri;">Scala</span><span style="font-family:'宋体';">编写的消息系统，原本开发自</span><span style="font-family:Calibri;">LinkedIn</span><span style="font-family:'宋体';">，用作</span><span style="font-family:Calibri;">LinkedIn</span><span style="font-family:'宋体';">的活动流（</span><span style="font-family:Calibri;">Activity Stream</span><span style="font-family:'宋体';">）和运营数据处理管道（</span><span style="font-family:Calibri;">Pipeline</span><span style="font-family:'宋体';">）的基础。现在它已被多家不同类型的公司作为多种类型的数据管道和消息系统使用。</span></p><p>Kafka<span style="font-family:'宋体';">是一种分布式的，基于发布</span><span style="font-family:Calibri;">/</span><span style="font-family:'宋体';">订阅的消息系统。</span></p><p>Kafka<span style="font-family:'宋体';">使用</span><span style="font-family:Calibri;">zookeeper</span><span style="font-family:'宋体';">作为其分布式协调框架，很好的将消息生产、消息存储、消息消费的过程结合在一起。同时借助</span><span style="font-family:Calibri;">zookeeper</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">kafka</span><span style="font-family:'宋体';">能够生产者、消费者和</span><span style="font-family:Calibri;">broker</span><span style="font-family:'宋体';">在内的所以组件在无状态的情况下，建立起生产者和消费者的订阅关系，并实现生产者与消费者的负载均衡。</span></p><h2><strong>2<span style="font-family:'黑体';">、</span><span style="font-family:Arial;">kafka</span><span style="font-family:'黑体';">的特性</span></strong></h2><p><span style="font-family:'宋体';">（</span>1<span style="font-family:'宋体';">）以时间复杂度为</span><span style="font-family:Calibri;">O(1)</span><span style="font-family:'宋体';">的方式提供消息持久化能力，即使对</span><span style="font-family:Calibri;">TB</span><span style="font-family:'宋体';">级以上数据也能保证常数时间复杂度的访问性能。</span></p><p><span style="font-family:'宋体';">（</span>2<span style="font-family:'宋体';">）高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒</span><span style="font-family:Calibri;">100K</span><span style="font-family:'宋体';">条以上消息的传输。</span></p><p><span style="font-family:'宋体';">（</span>3<span style="font-family:'宋体';">）支持</span><span style="font-family:Calibri;">Kafka Server</span><span style="font-family:'宋体';">间的消息分区，及分布式消费，同时保证每个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">内的消息顺序存储和传输。</span></p><p><span style="font-family:'宋体';">（</span>4<span style="font-family:'宋体';">）同时支持离线数据处理（</span><span style="font-family:Calibri;">Offline</span><span style="font-family:'宋体';">）和实时数据处理（</span><span style="font-family:Calibri;">Online</span><span style="font-family:'宋体';">）。</span></p><p><span style="font-family:'宋体';">（</span>5<span style="font-family:'宋体';">）</span><span style="font-family:Calibri;">Scale out</span><span style="font-family:'宋体';">：支持在线水平扩展。无需停机即可扩展机器。</span></p><p><span style="font-family:'宋体';">（</span>6<span style="font-family:'宋体';">）支持定期删除数据机制。可以按照时间段来删除，也可以按照文档大小来删除。</span></p><p><span style="font-family:'宋体';">（</span>7<span style="font-family:'宋体';">）</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">采用</span><span style="font-family:Calibri;">pull</span><span style="font-family:'宋体';">的方式消费数据，消费状态由</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">控制，减轻</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">负担。</span></p><h2><strong>3<span style="font-family:'黑体';">、</span><span style="font-family:Arial;">Kafka</span><span style="font-family:'黑体';">架构</span></strong></h2><p align="justify">（1）Broker<span style="font-family:'宋体';">：和</span><span style="font-family:Calibri;">RabbitMQ</span><span style="font-family:'宋体';">中的</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">概念类似。一个</span><span style="font-family:Calibri;">kafka</span><span style="font-family:'宋体';">服务器就是一个</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">，而一个</span><span style="font-family:Calibri;">kafka</span><span style="font-family:'宋体';">集群包含一个或多个</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">。</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">会持久化数据到相应的</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">中，不会有</span><span style="font-family:Calibri;">cache</span><span style="font-family:'宋体';">压力。</span></p><p align="justify"> </p><p align="justify">（2）Topic<span style="font-family:'宋体';">：主题。每条消息都有一个类别，这个类别就叫做</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">。</span><span style="font-family:Calibri;">Kafka</span><span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">可以理解为</span><span style="font-family:Calibri;">RabbitMQ</span><span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">Queue</span><span style="font-family:'宋体';">消息队列，相同类别的消息被发送到同一个</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">中，然后再被此</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">消费。</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">是逻辑上的概念，而物理上的实现就是</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">。</span></p><p align="justify"> </p><p align="justify">（3）Partition<span style="font-family:'宋体';">：分区。分区是物理上的概念，每个</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">包含一个或者多个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">，每个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">都是一个</span><strong>有序队列</strong><span style="font-family:'宋体';">。发送给</span>Topic<span style="font-family:'宋体';">的消息经过分区算法（可以自定义），决定消息存储在哪一个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">当中。每一条数据都会被分配一个有序</span><span style="font-family:Calibri;">id</span><span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">Offset</span><span style="font-family:'宋体';">。</span><strong><span style="font-family:'宋体';">注意：</span>kafka<span style="font-family:'宋体';">只保证按一个</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">中的顺序将消息发给</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">，不保证一个</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">的整体（多个</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">间）的顺序。</span></strong></p><p align="justify"> </p><p align="justify">（4）Replication<span style="font-family:'宋体';">：备份。</span><span style="font-family:Calibri;">Replication</span><span style="font-family:'宋体';">是基于</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">而不是</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">的。每个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">都有自己的备份，且分布在不同的</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">上。</span><strong></strong></p><p align="justify"><strong> </strong></p><p align="justify"><span style="color:rgb(51,51,51);background:rgb(255,255,255);">（5）</span><span style="color:rgb(51,51,51);background:rgb(255,255,255);">Offset<span style="font-family:'宋体';">：</span></span><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:'宋体';">偏移量。</span>kafka<span style="font-family:'宋体';">的存储文件都是用</span><span style="font-family:Arial;">offset</span><span style="font-family:'宋体';">来命名，用</span><span style="font-family:Arial;">offset</span><span style="font-family:'宋体';">做名字的好处是方便查找。例如你想找位于</span><span style="font-family:Arial;">2049</span><span style="font-family:'宋体';">的位置，只要找到</span><span style="font-family:Arial;">2048.log</span><span style="font-family:'宋体';">的文件即可。当然</span><span style="font-family:Arial;">the first offset</span><span style="font-family:'宋体';">就是</span><span style="font-family:Arial;">00000000000.log</span><span style="font-family:'宋体';">。</span></span><strong><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:'宋体';">注意：每个</span>Partition<span style="font-family:'宋体';">中的</span><span style="font-family:Arial;">Offset</span><span style="font-family:'宋体';">都是各不影响的从</span><span style="font-family:Arial;">0</span><span style="font-family:'宋体';">开始的有序数列。</span></span></strong></p><p align="justify"><strong> </strong></p><p align="justify">（6）Producer<span style="font-family:'宋体';">：消息生产者。</span></p><p align="justify"> </p><p align="justify">（7）Consumer<span style="font-family:'宋体';">：消息消费者。</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">采用</span><span style="font-family:Calibri;">pull</span><span style="font-family:'宋体';">的方式从</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">获取消息，并且</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">要维护消费状态，因此</span><span style="font-family:Calibri;">Kafaka</span><span style="font-family:'宋体';">系统中，业务重心一般都在</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">身上，而不像</span><span style="font-family:Calibri;">RabbitMQ</span><span style="font-family:'宋体';">那样</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">做了大部分的事情。</span></p><p align="justify"> </p><p align="justify">（8）Consumer Group<span style="font-family:'宋体';">：消费组。每个</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">属于一个特定的</span><span style="font-family:Calibri;">Consumer Group</span><span style="font-family:'宋体';">（可为每个</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">指定</span><span style="font-family:Calibri;">group name</span><span style="font-family:'宋体';">，若不指定</span><span style="font-family:Calibri;">group name</span><span style="font-family:'宋体';">则属于默认的</span><span style="font-family:Calibri;">group</span><span style="font-family:'宋体';">）。每个</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">可以被多个</span><span style="font-family:Calibri;">Group</span><span style="font-family:'宋体';">订阅，每个</span><span style="font-family:Calibri;">Group</span><span style="font-family:'宋体';">中可以有多个</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">。发送到</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">的一条消息会被每个</span><span style="font-family:Calibri;">Group</span><span style="font-family:'宋体';">中的一个</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">消费，多个</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">之间将交错消费整个</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">的消息，实现负载均衡。</span></p><p align="justify"> </p><p align="justify">（9）Record<span style="font-family:'宋体';">：消息。每一个消息由一个</span><span style="font-family:Calibri;">Key</span><span style="font-family:'宋体';">、一个</span><span style="font-family:Calibri;">Value</span><span style="font-family:'宋体';">和一个时间戳构成。</span></p><p align="justify"> </p><p align="justify"><strong><span style="color:rgb(255,0,0);">注意</span></strong><span style="font-family:'宋体';">：同一个</span>partition<span style="font-family:'宋体';">内的消息只能被同一个组中的一个</span><span style="font-family:Calibri;">consumer</span><span style="font-family:'宋体';">消费，不过一个</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">可以同时消费多个</span><span style="font-family:Calibri;">partitions</span><span style="font-family:'宋体';">中的消息</span><span style="font-family:Calibri;">.</span><span style="font-family:'宋体';">。当消费者数量多于</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">的数量时，多余的消费者将会空闲。也就是说如果只有一个</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">你在同一组启动多少个</span><span style="font-family:Calibri;">consumer</span><span style="font-family:'宋体';">都没用，</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">的数量决定了此</span><span style="font-family:Calibri;">topic</span><span style="font-family:'宋体';">在同一组中被可被均衡的程度，例如</span><span style="font-family:Calibri;">partition=4</span><span style="font-family:'宋体';">，则可在同一组中被最多</span><span style="font-family:Calibri;">4</span><span style="font-family:'宋体';">个</span><span style="font-family:Calibri;">consumer</span><span style="font-family:'宋体';">均衡消费。</span></p><p align="justify"> </p><p align="justify"> <img src="https://img-blog.csdn.net/20180420153208582" alt=""></p><p align="center">Kafka<span style="font-family:'宋体';">内部结构图（图片源于网络）</span></p><p align="justify"> <img src="https://img-blog.csdn.net/20180420153231825" alt=""></p><p align="center">Kafka<span style="font-family:'宋体';">拓扑结构图（图片源于网络）</span></p><h2><strong>4<span style="font-family:'黑体';">、</span><span style="font-family:Arial;">Topic</span><span style="font-family:'黑体';">、</span><span style="font-family:Arial;">Partition</span><span style="font-family:'黑体';">文件存储</span></strong></h2><h3><strong>4.1<span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">与</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">的关系</span></strong></h3><p>Topic<span style="font-family:'宋体';">在逻辑上可以被认为是一个</span><span style="font-family:Calibri;">queue</span><span style="font-family:'宋体';">，每条消费都必须指定它的</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">，可以简单理解为必须指明把这条消息放进哪个</span><span style="font-family:Calibri;">queue</span><span style="font-family:'宋体';">里。为了使得</span><span style="font-family:Calibri;">Kafka</span><span style="font-family:'宋体';">的吞吐率可以线性提高，物理上把</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">分成一个或多个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">，每个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">在物理上对应一个文件夹，该文件夹下存储这个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">的所有消息和索引文件。若创建</span><span style="font-family:Calibri;">topic1</span><span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">topic2</span><span style="font-family:'宋体';">两个</span><span style="font-family:Calibri;">topic</span><span style="font-family:'宋体';">，且分别有</span><span style="font-family:Calibri;">13</span><span style="font-family:'宋体';">个和</span><span style="font-family:Calibri;">19</span><span style="font-family:'宋体';">个分区，则整个集群上会相应会生成共</span><span style="font-family:Calibri;">32</span><span style="font-family:'宋体';">个文件夹。</span><span style="font-family:Calibri;">partiton</span><span style="font-family:'宋体';">命名规则为</span><span style="font-family:Calibri;">topic</span><span style="font-family:'宋体';">名称</span><span style="font-family:Calibri;">+</span><span style="font-family:'宋体';">有序序号，第一个</span><span style="font-family:Calibri;">partiton</span><span style="font-family:'宋体';">序号从</span><span style="font-family:Calibri;">0</span><span style="font-family:'宋体';">开始，序号最大值为</span><span style="font-family:Calibri;">partitions</span><span style="font-family:'宋体';">数量减</span><span style="font-family:Calibri;">1</span><span style="font-family:'宋体';">。</span></p><p> </p><h3><strong>4.2<span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">文件存储的特点</span></strong></h3><p>（1）<span style="font-family:'宋体';">每个</span>partition<span style="font-family:'宋体';">目录相当于一个巨型文件被平均分配到多个大小相等</span><span style="font-family:Calibri;">segment</span><span style="font-family:'宋体';">数据文件中。但每个</span><span style="font-family:Calibri;">segment file</span><span style="font-family:'宋体';">消息数量不一定相等，这种特性方便</span><span style="font-family:Calibri;">old segment file</span><span style="font-family:'宋体';">快速被删除。</span></p><p>（2）<span style="font-family:'宋体';">每个</span>partiton<span style="font-family:'宋体';">只需要支持顺序读写就行了，</span><span style="font-family:Calibri;">segment</span><span style="font-family:'宋体';">文件生命周期由服务端配置参数决定。</span></p><p>（3）segment file<span style="font-family:'宋体';">组成：由</span><span style="font-family:Calibri;">2</span><span style="font-family:'宋体';">大部分组成，分别为</span><span style="font-family:Calibri;">index file</span><span style="font-family:'宋体';">（后缀“</span><span style="font-family:Calibri;">.index</span><span style="font-family:'宋体';">”）和</span><span style="font-family:Calibri;">data file</span><span style="font-family:'宋体';">（后缀“</span><span style="font-family:Calibri;">.log</span><span style="font-family:'宋体';">”），此</span><span style="font-family:Calibri;">2</span><span style="font-family:'宋体';">个文件一一对应，成对出现。</span></p><p>（4）segment<span style="font-family:'宋体';">文件命名规则：</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">全局的第一个</span><span style="font-family:Calibri;">segment</span><span style="font-family:'宋体';">从</span><span style="font-family:Calibri;">0</span><span style="font-family:'宋体';">开始，后续每个</span><span style="font-family:Calibri;">segment</span><span style="font-family:'宋体';">文件名为上一个</span><span style="font-family:Calibri;">segment</span><span style="font-family:'宋体';">文件</span><strong><span style="font-family:'宋体';">最后一条消息的</span>offset<span style="font-family:'宋体';">值</span></strong><span style="font-family:'宋体';">。数值最大为</span>64<span style="font-family:'宋体';">位</span><span style="font-family:Calibri;">long</span><span style="font-family:'宋体';">大小，</span><span style="font-family:Calibri;">19</span><span style="font-family:'宋体';">位数字字符长度，没有数字用</span><span style="font-family:Calibri;">0</span><span style="font-family:'宋体';">填充。</span></p><p align="center"><img src="https://img-blog.csdn.net/20180420153258464" alt=""> </p><p align="center">Segment file<span style="font-family:'宋体';">结构图（图片来源于网络）</span></p><p><span style="font-family:'宋体';">以上述图</span>2<span style="font-family:'宋体';">中一对</span><span style="font-family:Calibri;">segment file</span><span style="font-family:'宋体';">文件为例，说明</span><span style="font-family:Calibri;">segment</span><span style="font-family:'宋体';">中</span><span style="font-family:Calibri;">index</span><span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">log</span><span style="font-family:'宋体';">文件对应关系物理结构如下：</span></p><p> <img src="https://img-blog.csdn.net/2018042015332069" alt=""></p><p align="center">Index<span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">log</span><span style="font-family:'宋体';">文件对应图（图片来源于网络）</span></p><p><span style="font-family:'宋体';">其中以索引文件中元数据</span>3,497<span style="font-family:'宋体';">为例，依次在数据文件中表示第</span><span style="font-family:Calibri;">3</span><span style="font-family:'宋体';">个</span><span style="font-family:Calibri;">message</span><span style="font-family:'宋体';">（在全局</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">表示第</span><span style="font-family:Calibri;">368772</span><span style="font-family:'宋体';">个</span><span style="font-family:Calibri;">message</span><span style="font-family:'宋体';">）、以及该消息的物理偏移地址为</span><span style="font-family:Calibri;">497</span><span style="font-family:'宋体';">。</span></p><h3><strong>4.3<span style="font-family:'宋体';">、在</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">中如何通过</span><span style="font-family:Calibri;">offset</span><span style="font-family:'宋体';">查找</span><span style="font-family:Calibri;">message</span></strong></h3><p><span style="font-family:'宋体';">例如读取</span>offset=368776<span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">message</span><span style="font-family:'宋体';">，需要通过下面</span><span style="font-family:Calibri;">2</span><span style="font-family:'宋体';">个步骤查找。</span></p><p><span style="font-family:'宋体';">（</span>1<span style="font-family:'宋体';">）第一步查找</span><span style="font-family:Calibri;">segment file</span></p><p><span style="font-family:'宋体';">上图为例，其中</span>00000000000000000000.index<span style="font-family:'宋体';">表示最开始的文件，起始偏移量</span><span style="font-family:Calibri;">(offset)</span><span style="font-family:'宋体';">为</span><span style="font-family:Calibri;">0.</span><span style="font-family:'宋体';">第二个文件</span><span style="font-family:Calibri;">00000000000000368769.index</span><span style="font-family:'宋体';">的消息量起始消息为</span><span style="font-family:Calibri;">368770 = 368769 + 1.</span><span style="font-family:'宋体';">同样，第三个文件</span><span style="font-family:Calibri;">00000000000000737337.index</span><span style="font-family:'宋体';">的起始消息为</span><span style="font-family:Calibri;">737338=737337 + 1</span><span style="font-family:'宋体';">，只要根据</span><span style="font-family:Calibri;">offset </span><span style="font-family:'宋体';">进行二分查找文件列表，就可以快速定位到具体文件。当</span><span style="font-family:Calibri;">offset=368776</span><span style="font-family:'宋体';">时定位到</span><span style="font-family:Calibri;">00000000000000368769.index|log</span><span style="font-family:'宋体';">。</span></p><p><span style="font-family:'宋体';">（</span>2<span style="font-family:'宋体';">）第二步通过</span><span style="font-family:Calibri;">segment file</span><span style="font-family:'宋体';">查找</span><span style="font-family:Calibri;">message</span></p><p><span style="font-family:'宋体';">通过第一步定位到</span>segment file<span style="font-family:'宋体';">，当</span><span style="font-family:Calibri;">offset=368776</span><span style="font-family:'宋体';">时，依次定位到</span><span style="font-family:Calibri;">00000000000000368769.index</span><span style="font-family:'宋体';">的元数据物理位置和</span><span style="font-family:Calibri;">00000000000000368769.log</span><span style="font-family:'宋体';">的物理偏移地址，然后再通过</span><span style="font-family:Calibri;">00000000000000368769.log</span><span style="font-family:'宋体';">顺序查找直到</span><span style="font-family:Calibri;">offset=368776</span><span style="font-family:'宋体';">为止。</span></p><h3><strong>4.4<span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Kafka</span><span style="font-family:'宋体';">集群中</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">分布规则</span></strong></h3><p><span style="font-family:'宋体';">首先来看一条在</span>Linux<span style="font-family:'宋体';">下创建</span><span style="font-family:Calibri;">topic</span><span style="font-family:'宋体';">的命令：</span></p><p>bin/kafka-topics.sh --create --zookeeper ip1:2181,ip2:2181,ip3:2181,ip4:2181  --replication-factor 2 --partitions 4 --topic test</p><p><span style="font-family:'宋体';">此命令的意思是在四个</span>Broker<span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">kafka</span><span style="font-family:'宋体';">集群上创建一个名为</span><span style="font-family:Calibri;">test</span><span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">，并且有</span><span style="font-family:Calibri;">4</span><span style="font-family:'宋体';">个分区</span><span style="font-family:Calibri;">2</span><span style="font-family:'宋体';">个备份（此处比较容易搞混，</span><span style="font-family:Calibri;">2</span><span style="font-family:'宋体';">个</span><span style="font-family:Calibri;">Replication</span><span style="font-family:'宋体';">表示</span><span style="font-family:Calibri;">Leader</span><span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">Follower</span><span style="font-family:'宋体';">一共加起来有</span><span style="font-family:Calibri;">2</span><span style="font-family:'宋体';">个）。此时在四台机器上面就有</span><span style="font-family:Calibri;">8</span><span style="font-family:'宋体';">个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">，如图所示。</span></p><p> <img src="https://img-blog.csdn.net/20180420153344759" alt=""></p><p align="center">Kafka<span style="font-family:'宋体';">集群</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">分布图</span><span style="font-family:Calibri;">1</span><span style="font-family:'宋体';">（图片来源于网络）</span></p><p><span style="font-family:'宋体';">当集群中新增</span>2<span style="font-family:'宋体';">节点，</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">增加到</span><span style="font-family:Calibri;">6</span><span style="font-family:'宋体';">个时分布情况如下：</span></p><p> <img src="https://img-blog.csdn.net/201804201534001" alt=""></p><p align="center">Kafka<span style="font-family:'宋体';">集群</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">分布图</span><span style="font-family:Calibri;">2</span><span style="font-family:'宋体';">（图片来源于网络）</span></p><p><span style="font-family:'宋体';">在</span>Kafka<span style="font-family:'宋体';">集群中，每个</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">都有均等分配</span><span style="font-family:Calibri;">Leader Partition</span><span style="font-family:'宋体';">机会。</span></p><p><span style="font-family:'宋体';">上述图</span>Broker Partition<span style="font-family:'宋体';">中，箭头指向为副本，以</span><span style="font-family:Calibri;">Partition-0</span><span style="font-family:'宋体';">为例：</span><span style="font-family:Calibri;">broker1</span><span style="font-family:'宋体';">中</span><span style="font-family:Calibri;">parition-0</span><span style="font-family:'宋体';">为</span><span style="font-family:Calibri;">Leader</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">Broker2</span><span style="font-family:'宋体';">中</span><span style="font-family:Calibri;">Partition-0</span><span style="font-family:'宋体';">为副本。每个</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">（按照</span><span style="font-family:Calibri;">BrokerId</span><span style="font-family:'宋体';">有序）依次分配主</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">，下一个</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">为副本，如此循环迭代分配，多副本都遵循此规则。</span></p><p> </p><p><strong><span style="color:rgb(255,0,0);">副本分配算法</span></strong>：</p><p>（1）<span style="font-family:'宋体';">将所有</span>n<span style="font-family:'宋体';">个</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">和待分配的</span><span style="font-family:Calibri;">i</span><span style="font-family:'宋体';">个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">排序。</span></p><p>（2）<span style="font-family:'宋体';">将第</span>i<span style="font-family:'宋体';">个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">分配到第</span><strong><span style="color:rgb(255,0,0);">(i mod n)</span></strong><span style="font-family:'宋体';">个</span>Broker<span style="font-family:'宋体';">上。</span></p><p>（3）<span style="font-family:'宋体';">将第</span>i<span style="font-family:'宋体';">个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">的第</span><span style="font-family:Calibri;">j</span><span style="font-family:'宋体';">个副本分配到第</span><strong><span style="color:rgb(255,0,0);">((i + j) mod n)</span></strong><span style="font-family:'宋体';">个</span>Broker<span style="font-family:'宋体';">上</span></p><p> </p><p><span style="font-family:'宋体';">例如图</span>2<span style="font-family:'宋体';">中的第三个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">partition-2</span><span style="font-family:'宋体';">，将被分配到</span><span style="font-family:Calibri;">Broker3</span><span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">(3 mod 6)=3</span><span style="font-family:'宋体';">）上，</span><span style="font-family:Calibri;">partition-2</span><span style="font-family:'宋体';">的副本将被分配到</span><span style="font-family:Calibri;">Broker4</span><span style="font-family:'宋体';">上（</span><span style="font-family:Calibri;">(3+1) mod 6=4</span><span style="font-family:'宋体';">）。</span></p><p align="justify"> </p><h3><strong>4.5<span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">kafka</span><span style="font-family:'宋体';">文件存储特点</span></strong></h3><p>（1）Kafka<span style="font-family:'宋体';">把</span><span style="font-family:Calibri;">topic</span><span style="font-family:'宋体';">中一个</span><span style="font-family:Calibri;">parition</span><span style="font-family:'宋体';">大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。可以设置</span><span style="font-family:Calibri;">segment</span><strong>文件大小定期删除</strong>和<strong>消息过期时间定期删除</strong></p><p>（2）<span style="font-family:'宋体';">通过索引信息可以快速定位</span>message<span style="font-family:'宋体';">。</span></p><p>（3）<span style="font-family:'宋体';">通过</span>index<span style="font-family:'宋体';">元数据全部映射到</span><span style="font-family:Calibri;">memory</span><span style="font-family:'宋体';">，可以避免</span><span style="font-family:Calibri;">segment file</span><span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">IO</span><span style="font-family:'宋体';">磁盘操作。</span></p><p>（4）<span style="font-family:'宋体';">通过索引文件稀疏存储，可以大幅降低</span>index<span style="font-family:'宋体';">文件元数据占用空间大小。</span></p><h3><strong>4.6<span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">的关系</span></strong></h3><p><span style="font-family:'宋体';">对于多个</span>Partition<span style="font-family:'宋体';">，多个</span><span style="font-family:Calibri;">Consumer</span></p><p><span style="font-family:'宋体';">（</span>1<span style="font-family:'宋体';">）如果</span><span style="font-family:Calibri;">consumer</span><span style="font-family:'宋体';">比</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">多，是浪费，因为</span><span style="font-family:Calibri;">kafka</span><span style="font-family:'宋体';">的设计是在一个</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">上是不允许并发的，所以</span><span style="font-family:Calibri;">consumer</span><span style="font-family:'宋体';">数不要大于</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">数。</span></p><p><span style="font-family:'宋体';">（</span>2<span style="font-family:'宋体';">）如果</span><span style="font-family:Calibri;">consumer</span><span style="font-family:'宋体';">比</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">少，一个</span><span style="font-family:Calibri;">consumer</span><span style="font-family:'宋体';">会对应于多个</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">，这里要合理分配</span><span style="font-family:Calibri;">consumer</span><span style="font-family:'宋体';">数和</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">数，否则会导致</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">里面的数据被取的不均匀。</span><strong><span style="font-family:'宋体';">最好</span>partiton<span style="font-family:'宋体';">数目是</span><span style="font-family:Calibri;">consumer</span><span style="font-family:'宋体';">数目的整数倍，所以</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">数目很重要，比如取</span><span style="font-family:Calibri;">24</span><span style="font-family:'宋体';">，就很容易设定</span><span style="font-family:Calibri;">consumer</span><span style="font-family:'宋体';">数目。</span></strong></p><p><span style="font-family:'宋体';">（</span>3<span style="font-family:'宋体';">）如果</span><span style="font-family:Calibri;">consumer</span><span style="font-family:'宋体';">从多个</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">读到数据，不保证数据间的顺序性，</span><span style="font-family:Calibri;">kafka</span><span style="font-family:'宋体';">只保证在一个</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">上数据是有序的，但多个</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">，根据你读的顺序会有不同</span></p><p><span style="font-family:'宋体';">（</span>4<span style="font-family:'宋体';">）增减</span><span style="font-family:Calibri;">consumer</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">broker</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">会导致</span><span style="font-family:Calibri;">rebalance</span><span style="font-family:'宋体';">，所以</span><span style="font-family:Calibri;">rebalance</span><span style="font-family:'宋体';">后</span><span style="font-family:Calibri;">consumer</span><span style="font-family:'宋体';">对应的</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">会发生变化</span></p><p><span style="font-family:'宋体';">（</span>5<span style="font-family:'宋体';">）</span><span style="font-family:Calibri;">High-level</span><span style="font-family:'宋体';">接口中获取不到数据的时候是会</span><span style="font-family:Calibri;">block</span><span style="font-family:'宋体';">的。</span></p><p> </p><p><span style="font-family:'宋体';">关于</span>zookeeper<span style="font-family:'宋体';">中</span><span style="font-family:Calibri;">Offset</span><span style="font-family:'宋体';">初始值的问题：</span></p><p>Zookeeper<span style="font-family:'宋体';">中</span><span style="font-family:Calibri;">Offset</span><span style="font-family:'宋体';">的初始值默认是</span><strong><span style="color:rgb(255,0,0);">非法的</span></strong><span style="font-family:'宋体';">，因此通过设置</span>Consumer<span style="font-family:'宋体';">的参数</span><strong><span style="color:rgb(255,0,0);">auto.offset.reset</span></strong><span style="font-family:'宋体';">来告诉</span>Consumer<span style="font-family:'宋体';">读取到</span><span style="font-family:Calibri;">Offset</span><span style="font-family:'宋体';">非法时该怎么做。</span></p><p>auto.offset.reset<span style="font-family:'宋体';">有三个值：</span></p><p><span style="font-family:'宋体';">（</span>1<span style="font-family:'宋体';">）</span><span style="font-family:Calibri;">smallest : </span><span style="font-family:'宋体';">自动把</span><span style="font-family:Calibri;">zookeeper</span><span style="font-family:'宋体';">中的</span><span style="font-family:Calibri;">offset</span><span style="font-family:'宋体';">设为</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">中最小的</span><span style="font-family:Calibri;">offset</span><span style="font-family:'宋体';">；</span></p><p><span style="font-family:'宋体';">（</span>2<span style="font-family:'宋体';">）</span><span style="font-family:Calibri;">largest : </span><span style="font-family:'宋体';">自动把</span><span style="font-family:Calibri;">zookeeper</span><span style="font-family:'宋体';">中</span><span style="font-family:Calibri;">offset</span><span style="font-family:'宋体';">设为</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">中最大的</span><span style="font-family:Calibri;">offset</span><span style="font-family:'宋体';">；</span></p><p><span style="font-family:'宋体';">（</span>3<span style="font-family:'宋体';">）</span><span style="font-family:Calibri;">anything else: </span><span style="font-family:'宋体';">抛出异常；</span></p><p> </p><p>auto.offset.reset<span style="font-family:'宋体';">默认值是</span><span style="font-family:Calibri;">largest</span><span style="font-family:'宋体';">，此种情况下如果</span><span style="font-family:Calibri;">producer</span><span style="font-family:'宋体';">先发送了</span><span style="font-family:Calibri;">10</span><span style="font-family:'宋体';">条数据到某个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">，然后</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">启功后修改</span><span style="font-family:Calibri;">zookeeper</span><span style="font-family:'宋体';">中</span><strong><span style="font-family:'宋体';">非法</span>Offset</strong><span style="font-family:'宋体';">值为</span>Partition<span style="font-family:'宋体';">中的最大值</span><span style="font-family:Calibri;">9</span><span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">Offset</span><span style="font-family:'宋体';">从</span><span style="font-family:Calibri;">0</span><span style="font-family:'宋体';">开始），这样</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">就忽略了这</span><span style="font-family:Calibri;">10</span><span style="font-family:'宋体';">条消息。就算现在再次设置成</span><span style="font-family:Calibri;">smallest</span><span style="font-family:'宋体';">也读取不到之前的</span><span style="font-family:Calibri;">10</span><span style="font-family:'宋体';">条数据了，因为此时</span><span style="font-family:Calibri;">Offset</span><span style="font-family:'宋体';">是合法的了。</span></p><p><span style="font-family:'宋体';">所以，想要读取之前的数据，就需要在一开始指定</span>auto.offset.reset=smallest<span style="font-family:'宋体';">。</span></p><h2><strong>5<span style="font-family:'黑体';">、</span><span style="font-family:Arial;">Replication</span><span style="font-family:'黑体';">副本同步机制</span></strong></h2><p>Replication<span style="font-family:'宋体';">是基于</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">而不是</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">的。每个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">都有自己的备份，且分布在不同的</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">上。这些</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">当中有一个是</span><span style="font-family:Calibri;">Leader</span><span style="font-family:'宋体';">，其他都是</span><span style="font-family:Calibri;">Follower</span><span style="font-family:'宋体';">。</span><span style="font-family:Calibri;">Leader Partition</span><span style="font-family:'宋体';">负责</span><strong>读写</strong><span style="font-family:'宋体';">操作，</span>Follower Partition<span style="font-family:'宋体';">只负责从</span><span style="font-family:Calibri;">Leader</span><span style="font-family:'宋体';">处复制数据，使自己与</span><span style="font-family:Calibri;">Leader</span><span style="font-family:'宋体';">保持一致。</span><span style="font-family:Calibri;">Zookeeper</span><span style="font-family:'宋体';">负责两者间的故障切换（</span><span style="color:rgb(51,51,51);background:rgb(255,255,255);">fail over</span><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:'宋体';">，可以理解为</span></span><span style="color:rgb(51,51,51);background:rgb(255,255,255);">Leader<span style="font-family:'宋体';">选举</span></span><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:'宋体';">）。</span></span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:'宋体';">消息复制延迟受最慢的</span></span><span style="color:rgb(51,51,51);background:rgb(255,255,255);">F</span>ollower<span style="font-family:'宋体';">限制，</span><span style="font-family:Calibri;">Leader</span><span style="font-family:'宋体';">负责跟踪所有</span><span style="font-family:Calibri;">Follower</span><span style="font-family:'宋体';">的状态，如果</span><span style="font-family:Calibri;">Follower</span><span style="font-family:'宋体';">“落后”太多或者失效，</span><span style="font-family:Calibri;">Leader</span><span style="font-family:'宋体';">就将此</span><span style="font-family:Calibri;">Follower</span><span style="font-family:'宋体';">从</span><span style="font-family:Calibri;">R</span><span style="color:rgb(51,51,51);background:rgb(255,255,255);">eplication<span style="font-family:'宋体';">同步列表中移除，但此时</span><span style="font-family:Arial;">Follower</span><span style="font-family:'宋体';">是活着的，并且一直从</span><span style="font-family:Arial;">Leader</span><span style="font-family:'宋体';">拉取数据，直到差距小于</span></span><strong><span style="color:rgb(51,51,51);background:rgb(255,255,255);">replica.lag.max.messages</span></strong><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:'宋体';">值，然后重新加入同步列表</span></span><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:'宋体';">。当一条消息被所有的</span>Follower<span style="font-family:'宋体';">保存成功，此消息才被认为是“</span><span style="font-family:Arial;">committed</span><span style="font-family:'宋体';">”，</span><span style="font-family:Arial;">Consumer</span><span style="font-family:'宋体';">才能消费这条消息。这种同步方式就要求</span><span style="font-family:Arial;">Leader</span><span style="font-family:'宋体';">和</span><span style="font-family:Arial;">Follower</span><span style="font-family:'宋体';">之间要有良好的网络环境。</span></span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:'宋体';">一个</span>partition<span style="font-family:'宋体';">的</span><span style="font-family:Arial;">follower</span><span style="font-family:'宋体';">落后于</span><span style="font-family:Arial;">leader</span><span style="font-family:'宋体';">足够多时，会被认为不在同步副本列表或处于滞后状态。在</span><span style="font-family:Arial;">Kafka-0.8.2.x</span><span style="font-family:'宋体';">中，副本滞后判断依据是副本落后于</span><span style="font-family:Arial;">leader</span></span><strong><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:'宋体';">最大消息数量</span></span></strong><span style="color:rgb(51,51,51);background:rgb(255,255,255);">(</span><strong><span style="color:rgb(51,51,51);background:rgb(255,255,255);">replica.lag.max.messages</span></strong><span style="color:rgb(51,51,51);background:rgb(255,255,255);">)<span style="font-family:'宋体';">或</span><span style="font-family:Arial;">replication</span><span style="font-family:'宋体';">响应</span><span style="font-family:Arial;">Leader partition</span><span style="font-family:'宋体';">的</span></span><strong><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:'宋体';">最长等待时间</span></span></strong><span style="color:rgb(51,51,51);background:rgb(255,255,255);">(</span><strong><span style="color:rgb(51,51,51);background:rgb(255,255,255);">replica.lag.time.max.ms</span></strong><span style="color:rgb(51,51,51);background:rgb(255,255,255);">)<span style="font-family:'宋体';">。前者是用来检测缓慢的副本，而后者是用来检测失效或死亡的副本。假设</span></span><span style="color:rgb(51,51,51);background:rgb(255,255,255);">replica.lag.max.messages</span><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:'宋体';">设置为</span>4<span style="font-family:'宋体';">，表明只要</span><span style="font-family:Arial;">follower</span><span style="font-family:'宋体';">落后</span><span style="font-family:Arial;">leader</span><span style="font-family:'宋体';">的消息数小于</span><span style="font-family:Arial;">4</span><span style="font-family:'宋体';">，就不会从同步副本列表中移除。</span></span><strong><span style="color:rgb(51,51,51);background:rgb(255,255,255);">replica.lag.time.max</span></strong><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:'宋体';">设置为</span>500 ms<span style="font-family:'宋体';">，表明只要</span><span style="font-family:Arial;">follower</span><span style="font-family:'宋体';">向</span><span style="font-family:Arial;">leader</span><span style="font-family:'宋体';">发送拉取数据请求时间间隔超过</span><span style="font-family:Arial;">500 ms</span><span style="font-family:'宋体';">，就会被标记为死亡，并且会从同步副本列表中移除。</span></span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:'宋体';">当</span>Leader<span style="font-family:'宋体';">处于流量高峰时，比如一瞬间就收到了</span><span style="font-family:Arial;">4</span><span style="font-family:'宋体';">条数据，此时所有</span><span style="font-family:Arial;">Follower</span><span style="font-family:'宋体';">将被认为是“</span><span style="font-family:Arial;">out-of-sync</span><span style="font-family:'宋体';">”并且从同步副本列表中移除，然后</span><span style="font-family:Arial;">Follower</span><span style="font-family:'宋体';">拉取数据赶上</span><span style="font-family:Arial;">Leader</span><span style="font-family:'宋体';">过后又重新加入同步列表，就这样</span><span style="font-family:Arial;">Follower</span><span style="font-family:'宋体';">频繁在副本同步列表移除和重新加入之间来回切换。</span></span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:'宋体';">即使只有一个</span>replicas<span style="font-family:'宋体';">实例存活，仍然可以保证消息的正常发送和接收，只要</span><span style="font-family:Arial;">zookeeper</span><span style="font-family:'宋体';">集群存活即可</span><span style="font-family:Arial;">(</span><span style="font-family:'宋体';">注意：不同于其他分布式存储，比如</span><span style="font-family:Arial;">hbase</span><span style="font-family:'宋体';">需要</span><span style="font-family:Arial;">"</span><span style="font-family:'宋体';">多数派</span><span style="font-family:Arial;">"</span><span style="font-family:'宋体';">存活才行</span><span style="font-family:Arial;">)</span><span style="font-family:'宋体';">。</span></span></p><p><span style="color:rgb(51,51,51);background:rgb(255,255,255);"><span style="font-family:'宋体';">当</span>leader<span style="font-family:'宋体';">失效时，需在</span><span style="font-family:Arial;">followers</span><span style="font-family:'宋体';">中选取出新的</span><span style="font-family:Arial;">leader</span><span style="font-family:'宋体';">，可能此时</span><span style="font-family:Arial;">follower</span><span style="font-family:'宋体';">落后于</span><span style="font-family:Arial;">leader</span><span style="font-family:'宋体';">，因此需要选择一个</span><span style="font-family:Arial;">"up-to-date"</span><span style="font-family:'宋体';">的</span><span style="font-family:Arial;">follower</span><span style="font-family:'宋体';">。</span><span style="font-family:Arial;">kafka</span><span style="font-family:'宋体';">中</span><span style="font-family:Arial;">leader</span><span style="font-family:'宋体';">选举并没有采用</span><span style="font-family:Arial;">"</span><span style="font-family:'宋体';">投票多数派</span><span style="font-family:Arial;">"</span><span style="font-family:'宋体';">的算法，因为这种算法对于</span><span style="font-family:Arial;">"</span><span style="font-family:'宋体';">网络稳定性</span><span style="font-family:Arial;">"/"</span><span style="font-family:'宋体';">投票参与者数量</span><span style="font-family:Arial;">"</span><span style="font-family:'宋体';">等条件有较高的要求，而且</span><span style="font-family:Arial;">kafka</span><span style="font-family:'宋体';">集群的设计，还需要容忍</span><span style="font-family:Arial;">N-1</span><span style="font-family:'宋体';">个</span><span style="font-family:Arial;">replicas</span><span style="font-family:'宋体';">失效。对于</span><span style="font-family:Arial;">kafka</span><span style="font-family:'宋体';">而言，每个</span><span style="font-family:Arial;">partition</span><span style="font-family:'宋体';">中所有的</span><span style="font-family:Arial;">replicas</span><span style="font-family:'宋体';">信息都可以在</span><span style="font-family:Arial;">zookeeper</span><span style="font-family:'宋体';">中获得，那么选举</span><span style="font-family:Arial;">leader</span><span style="font-family:'宋体';">将是一件非常简单的事情。选择</span><span style="font-family:Arial;">follower</span><span style="font-family:'宋体';">时需要兼顾一个问题，就是新</span><span style="font-family:Arial;">leader </span><span style="font-family:'宋体';">所在的</span><span style="font-family:Arial;">server</span><span style="font-family:'宋体';">服务器上已经承载的</span><span style="font-family:Arial;">partition leader</span><span style="font-family:'宋体';">的个数，如果一个</span><span style="font-family:Arial;">server</span><span style="font-family:'宋体';">上有过多的</span><span style="font-family:Arial;">partition leader</span><span style="font-family:'宋体';">，意味着此</span><span style="font-family:Arial;">server</span><span style="font-family:'宋体';">将承受着更多的</span><span style="font-family:Arial;">IO</span><span style="font-family:'宋体';">压力。在选举新</span><span style="font-family:Arial;">leader</span><span style="font-family:'宋体';">，需要考虑到</span><span style="font-family:Arial;">"</span><span style="font-family:'宋体';">负载均衡</span><span style="font-family:Arial;">"</span><span style="font-family:'宋体';">，</span><span style="font-family:Arial;">partition leader</span><span style="font-family:'宋体';">较少的</span><span style="font-family:Arial;">broker</span><span style="font-family:'宋体';">将会更有可能成为新的</span><span style="font-family:Arial;">leader</span><span style="font-family:'宋体';">。在整个集群中，只要有一个</span><span style="font-family:Arial;">replicas</span><span style="font-family:'宋体';">存活，那么此</span><span style="font-family:Arial;">partition</span><span style="font-family:'宋体';">都可以继续接受读写操作。</span></span></p><h2><strong>6<span style="font-family:'黑体';">、</span><span style="font-family:Arial;">Consumer</span><span style="font-family:'黑体';">均衡算法</span></strong></h2><p><span style="font-family:'宋体';">当一个</span>Group<span style="font-family:'宋体';">中，有</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">加入或者离开时，会触发</span><span style="font-family:Calibri;">Partitions</span><span style="font-family:'宋体';">均衡。均衡的最终目的，是提升</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">的并发消费能力。</span></p><p><span style="font-family:'宋体';">（</span>1<span style="font-family:'宋体';">）假如</span><span style="font-family:Calibri;">topic1</span><span style="font-family:'宋体';">，具有如下</span><span style="font-family:Calibri;">partitions: P0</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">P1</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">P2</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">P3</span></p><p><span style="font-family:'宋体';">（</span>2<span style="font-family:'宋体';">）加入</span><span style="font-family:Calibri;">group</span><span style="font-family:'宋体';">中，有如下</span><span style="font-family:Calibri;">consumer: C0</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">C1</span></p><p><span style="font-family:'宋体';">（</span>3<span style="font-family:'宋体';">）首先根据</span><span style="font-family:Calibri;">partition</span><span style="font-family:'宋体';">索引号对</span><span style="font-family:Calibri;">partitions</span><span style="font-family:'宋体';">排序</span><span style="font-family:Calibri;">: P0</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">P1</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">P2</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">P3</span></p><p><span style="font-family:'宋体';">（</span>4<span style="font-family:'宋体';">）根据</span><span style="font-family:Calibri;">consumer.id</span><span style="font-family:'宋体';">排序</span><span style="font-family:Calibri;">: C0</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">C1</span></p><p><span style="font-family:'宋体';">（</span>5<span style="font-family:'宋体';">）计算倍数</span><span style="font-family:Calibri;">: M = [P0</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">P1</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">P2</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">P3].size / [C0</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">C1].size</span><span style="font-family:'宋体';">，本例值</span><span style="font-family:Calibri;">M=2(</span><span style="font-family:'宋体';">向上取整</span><span style="font-family:Calibri;">)</span></p><p><span style="font-family:'宋体';">（</span>6<span style="font-family:'宋体';">）然后依次分配</span><span style="font-family:Calibri;">partitions: C0 = [P0</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">P1]</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">C1=[P2</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">P3]</span><span style="font-family:'宋体';">，即</span><strong><span style="color:rgb(255,0,0);">Ci = [P(i * M)<span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">P((i + 1) * M -1)]</span></span></strong></p><p><span style="color:rgb(0,0,0);"><span style="font-family:'宋体';">通过此算法，就能知道具体</span>Consumer<span style="font-family:'宋体';">消费的是哪个分区中的数据。</span></span></p><h2><strong>7<span style="font-family:'黑体';">、</span><span style="font-family:Arial;">Producer</span><span style="font-family:'黑体';">消息路由机制</span></strong></h2><p><span style="font-family:'宋体';">在</span>kafka-Client-0.11.0.0.jar<span style="font-family:'宋体';">中，提供的有默认的</span><span style="font-family:Calibri;">KafkaProducer</span><span style="font-family:'宋体';">和</span><span style="color:rgb(0,0,0);background:rgb(255,255,255);">DefaultPartitioner</span><span style="color:rgb(0,0,0);background:rgb(255,255,255);"><span style="font-family:'宋体';">实现。其中</span></span><span style="color:rgb(0,0,0);background:rgb(255,255,255);">DefaultPartitioner</span><span style="color:rgb(0,0,0);background:rgb(255,255,255);"><span style="font-family:'宋体';">主要提供了</span></span><span style="color:rgb(0,0,0);background:rgb(255,255,255);">Producer<span style="font-family:'宋体';">发送消息到分区的路由算法，如果给定</span><span style="font-family:Consolas;">Key</span><span style="font-family:'宋体';">值，就通过</span><span style="font-family:Consolas;">Key</span><span style="font-family:'宋体';">的哈希值和分区个数取余来计算；如果没有给定</span><span style="font-family:Consolas;">Key</span><span style="font-family:'宋体';">，就通过</span></span><span style="color:rgb(0,0,0);background:rgb(255,255,255);">ThreadLocalRandom.</span><em><span style="color:rgb(0,0,0);background:rgb(255,255,255);">current</span></em><span style="color:rgb(0,0,0);background:rgb(255,255,255);">().nextInt()</span><span style="color:rgb(0,0,0);background:rgb(255,255,255);"><span style="font-family:'宋体';">产生的随机数与分区数取余（其中涉及复杂步奏参考如下代码）</span></span><span style="color:rgb(0,0,0);background:rgb(255,255,255);"><span style="font-family:'宋体';">。具体代码如下：</span></span></p><p><span style="color:rgb(0,0,0);background:rgb(255,255,255);"> </span></p><pre><code class="language-java">public class DefaultPartitioner implements Partitioner {

    private final ConcurrentMap&lt;String, AtomicInteger&gt; topicCounterMap = new ConcurrentHashMap&lt;&gt;();

    public void configure(Map&lt;String, ?&gt; configs) {}

    /**
     * 计算给定记录的分区
     *
     * @param topic The topic name
     * @param key The key to partition on (or null if no key)
     * @param keyBytes serialized key to partition on (or null if no key)
     * @param value The value to partition on or null
     * @param valueBytes serialized value to partition on or null
     * @param cluster The current cluster metadata
     */
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
        List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);
        int numPartitions = partitions.size();
        if (keyBytes == null) {
            int nextValue = nextValue(topic);
            List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);
            if (availablePartitions.size() &gt; 0) {
                int part = Utils.toPositive(nextValue) % availablePartitions.size();
                return availablePartitions.get(part).partition();
            } else {
                // no partitions are available, give a non-available partition
                return Utils.toPositive(nextValue) % numPartitions;
            }
        } else {
            // hash the keyBytes to choose a partition
            return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
        }
    }

    private int nextValue(String topic) {
        AtomicInteger counter = topicCounterMap.get(topic);
        if (null == counter) {
            counter = new AtomicInteger(ThreadLocalRandom.current().nextInt());
            AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter);
            if (currentCounter != null) {
                counter = currentCounter;
            }
        }
        return counter.getAndIncrement();
    }

    public void close() {}

}</code></pre><p><span style="color:rgb(0,0,0);">我们也可以设置自己的</span><span style="color:rgb(0,0,0);">Partition<span style="font-family:'宋体';">路由规则，需要继承</span></span><strong><span style="color:rgb(255,0,0);background:rgb(255,255,255);">Partitioner</span></strong><span style="color:rgb(0,0,0);background:rgb(255,255,255);"><span style="font-family:'宋体';">类实现</span></span></p><pre><code class="language-java">public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);。</code></pre><p><span style="color:rgb(0,0,0);background:rgb(255,255,255);"><span style="font-family:'宋体';">方法。</span></span></p><h2>8、<strong>kafka<span style="font-family:'黑体';">消息投递保证（</span><span style="font-family:Arial;">delivery</span><span style="font-family:'黑体';">保证）</span></strong></h2><p>Kafka<span style="font-family:'宋体';">的消息</span><span style="font-family:Calibri;">delivery</span><span style="font-family:'宋体';">保证主要有三种：</span></p><p>（1）At most once <span style="font-family:'宋体';">最多一次。消息可能会丢失，但绝不会重复传输。</span></p><p>（2）At least once <span style="font-family:'宋体';">最少一次。消息绝不会丢失，但可能会重复传输。</span></p><p>（3）Exactly once <span style="font-family:'宋体';">正好一次。每条消息正好被传输一次和消费一次。</span></p><h3><strong>8.1<span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Producer delivery</span><span style="font-family:'宋体';">保证</span></strong></h3><p>Producer<span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">delivery</span><span style="font-family:'宋体';">保证可以通过参数</span><span style="font-family:Calibri;">request.required.acks</span><span style="font-family:'宋体';">设置来保证：</span></p><p>（1）request.required.acks=0<span style="font-family:'宋体';">。</span></p><p align="justify"><span style="font-family:'宋体';">相当于消息异步发送。消息一发送完毕马上发送下一条。由于不需要</span>ack<span style="font-family:'宋体';">，可能会造成数据丢失，相当于实现了</span><span style="font-family:Calibri;">At most once</span><span style="font-family:'宋体';">。</span></p><p>（2）request.required.acks=1<span style="font-family:'宋体';">。</span></p><p align="justify"><span style="font-family:'宋体';">消息发送给</span>Leader Partition<span style="font-family:'宋体';">，在</span><span style="font-family:Calibri;">Leader Partition</span><span style="font-family:'宋体';">确认消息并</span><span style="font-family:Calibri;">ack </span><span style="font-family:'宋体';">生产者过后才发下一条。</span></p><p>（3）request.required.acks=-1<span style="font-family:'宋体';">。</span></p><p><span style="font-family:'宋体';">消息发送给</span>Leader<span style="font-family:'宋体';">，在</span><span style="font-family:Calibri;">Leader</span><span style="font-family:'宋体';">收到所有</span><span style="font-family:Calibri;">Follower</span><span style="font-family:'宋体';">确认保存消息的</span><span style="font-family:Calibri;">ack</span><span style="font-family:'宋体';">后对</span><span style="font-family:Calibri;">producer</span><span style="font-family:'宋体';">进行</span><span style="font-family:Calibri;">ack</span><span style="font-family:'宋体';">才发送下一条。</span></p><p><span style="font-family:'宋体';">所以一条消息从</span>Producer<span style="font-family:'宋体';">到</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">至少是确保了</span><span style="font-family:Calibri;">At least once</span><span style="font-family:'宋体';">的，因为有</span><span style="font-family:Calibri;">Replication</span><span style="font-family:'宋体';">的存在，只要消息到达</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">就不会丢失。如果</span><span style="font-family:Calibri;">ack</span><span style="font-family:'宋体';">出现问题，比如网络中断，有可能会导致</span><span style="font-family:Calibri;">producer</span><span style="font-family:'宋体';">收不到</span><span style="font-family:Calibri;">ack</span><span style="font-family:'宋体';">而重复发送消息。</span><span style="font-family:Calibri;">Exactly once</span><span style="font-family:'宋体';">这种方式，没有查到相关的实现。</span></p><p> </p><p><span style="font-family:'宋体';">第（</span>3<span style="font-family:'宋体';">）种方式的具体步奏如下：</span></p><p>a. producer <span style="font-family:'宋体';">先从 </span><span style="font-family:Calibri;">zookeeper </span><span style="font-family:'宋体';">的 </span><span style="font-family:Calibri;">"/brokers/.../state" </span><span style="font-family:'宋体';">节点找到该 </span><span style="font-family:Calibri;">partition </span><span style="font-family:'宋体';">的 </span><span style="font-family:Calibri;">leader</span></p><p>b. producer <span style="font-family:'宋体';">将消息发送给该 </span><span style="font-family:Calibri;">leader</span></p><p>c. leader <span style="font-family:'宋体';">将消息写入本地 </span><span style="font-family:Calibri;">log</span></p><p>d. followers <span style="font-family:'宋体';">从 </span><span style="font-family:Calibri;">leader pull </span><span style="font-family:'宋体';">消息，写入本地 </span><span style="font-family:Calibri;">log </span><span style="font-family:'宋体';">后向 </span><span style="font-family:Calibri;">leader </span><span style="font-family:'宋体';">发送 </span><span style="font-family:Calibri;">ACK</span></p><p>e. leader <span style="font-family:'宋体';">收到所有 </span><span style="font-family:Calibri;">ISR </span><span style="font-family:'宋体';">中的 </span><span style="font-family:Calibri;">replica </span><span style="font-family:'宋体';">的 </span><span style="font-family:Calibri;">ACK </span><span style="font-family:'宋体';">后，增加 </span><span style="font-family:Calibri;">HW</span><span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">high watermark</span><span style="font-family:'宋体';">，最后 </span><span style="font-family:Calibri;">commit </span><span style="font-family:'宋体';">的 </span><span style="font-family:Calibri;">offset</span><span style="font-family:'宋体';">） 并向 </span><span style="font-family:Calibri;">producer </span><span style="font-family:'宋体';">发送 </span><span style="font-family:Calibri;">ACK</span></p><h3><strong>8.2<span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Consumer delivery</span><span style="font-family:'宋体';">保证</span></strong></h3><p><span style="color:rgb(0,0,0);background:rgb(255,255,255);">Consumer<span style="font-family:'宋体';">从</span><span style="font-family:Consolas;">Broker</span><span style="font-family:'宋体';">拉取数据过后，可以选择</span><span style="font-family:Consolas;">commit</span><span style="font-family:'宋体';">，此操作会在</span><span style="font-family:Consolas;">zookeeper</span><span style="font-family:'宋体';">中存下此</span><span style="font-family:Consolas;">Consumer</span><span style="font-family:'宋体';">读取对应</span><span style="font-family:Consolas;">Partition</span><span style="font-family:'宋体';">消息的</span><span style="font-family:Consolas;">Offset</span><span style="font-family:'宋体';">，以便下一次拉取数据时会从</span><span style="font-family:Consolas;">Partition</span><span style="font-family:'宋体';">的下一个</span><span style="font-family:Consolas;">Offset</span><span style="font-family:'宋体';">消费，避免重复消费。</span></span></p><p><span style="color:rgb(0,0,0);background:rgb(255,255,255);"><span style="font-family:'宋体';">同样，</span>Consumer<span style="font-family:'宋体';">可以通过设置参数</span></span><span style="color:rgb(42,0,255);background:rgb(255,255,255);">enable.auto.commit</span><span style="color:rgb(42,0,255);background:rgb(255,255,255);">=true</span><span style="color:rgb(0,0,0);background:rgb(255,255,255);"><span style="font-family:'宋体';">来自动确认消息，即</span>Consumer<span style="font-family:'宋体';">一收到消息立刻自动</span><span style="font-family:Consolas;">commit</span><span style="font-family:'宋体';">。如果只看消息的读取过程，</span><span style="font-family:Consolas;">kafka</span><span style="font-family:'宋体';">是确保了</span></span>Exactly once<span style="font-family:'宋体';">的，但是实际情况中</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">不可能读取到数据就结束了，往往还需要处理读取到的数据。因此</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">处理消息和</span><span style="font-family:Calibri;">commit</span><span style="font-family:'宋体';">消息的顺序就决定了</span><span style="font-family:Calibri;">delivery</span><span style="font-family:'宋体';">保证的类别。</span></p><p> </p><p>（1）<span style="font-family:'宋体';">先处理后</span>commit</p><p align="justify"><span style="font-family:'宋体';">这种方式实现了</span>At least once<span style="font-family:'宋体';">。</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">收到消息先处理后提交，如果在处理完成后机器崩溃了，导致</span><span style="font-family:Calibri;">Offset</span><span style="font-family:'宋体';">没有更新，</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">下次启动时又会重新读取上一次消费的数据，实际上此消息已经处理过了。</span></p><p align="justify"> </p><p>（2）<span style="font-family:'宋体';">先</span>commit<span style="font-family:'宋体';">后处理</span></p><p align="justify"><span style="font-family:'宋体';">这种方式实现了</span>At most once<span style="font-family:'宋体';">。</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">收到消息过后立刻</span><span style="font-family:Calibri;">commit</span><span style="font-family:'宋体';">，更新</span><span style="font-family:Calibri;">zookeeper</span><span style="font-family:'宋体';">上的</span><span style="font-family:Calibri;">Offset</span><span style="font-family:'宋体';">，然后再处理消息。如果处理还未结束</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">崩溃了，等</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">再次启动的时候会读取</span><span style="font-family:Calibri;">Offset</span><span style="font-family:'宋体';">更新过后的下一条数据，这就导致了数据丢失。</span></p><h2>9、<strong>High Level API<span style="font-family:'黑体';">和</span><span style="font-family:Arial;">Low Level API</span></strong></h2><p>Kafka<span style="font-family:'宋体';">提供了两种</span><span style="font-family:Calibri;">Consumer API</span><span style="font-family:'宋体';">，选用哪种</span><span style="font-family:Calibri;">API</span><span style="font-family:'宋体';">需要视具体情况而定。</span></p><h3><strong>9.1<span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">High Level Consumer API</span></strong></h3><p>High Level Consumer API<span style="font-family:'宋体';">围绕着</span><span style="font-family:Calibri;">Consumer Group</span><span style="font-family:'宋体';">这个逻辑概念展开，它屏蔽了每个</span><span style="font-family:Calibri;">Topic</span><span style="font-family:'宋体';">的每个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">Offset</span><span style="font-family:'宋体';">管理（自动读取</span><span style="font-family:Calibri;">zookeeper</span><span style="font-family:'宋体';">中该</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">last offset </span><span style="font-family:'宋体';">）、</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">失败转移以及增减</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">时的负载均衡</span><span style="font-family:Calibri;">(</span><span style="font-family:'宋体';">当</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">增减时，</span><span style="font-family:Calibri;">Kafka</span><span style="font-family:'宋体';">自动进行</span><span style="font-family:Calibri;">Rebalance</span><span style="font-family:'宋体';">）。</span></p><h3><strong>9.2<span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Low Level Consumer API</span></strong></h3><p>Low Level Consumer API<span style="font-family:'宋体';">，作为底层的</span><span style="font-family:Calibri;">Consumer API</span><span style="font-family:'宋体';">，提供了消费</span><span style="font-family:Calibri;">Kafka Message</span><span style="font-family:'宋体';">更大的控制，用户可以实现重复读取、跳读等功能。</span></p><p><span style="font-family:'宋体';">使用</span>Low Level Consumer API<span style="font-family:'宋体';">，是没有对</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">增减进行处理，如果出现这些的增减时，需要自己处理负载均衡。</span></p><p> </p><p>Low Level Consumer API<span style="font-family:'宋体';">提供更大灵活控制是以增加复杂性为代价的：</span></p><p><span style="font-family:'宋体';">（</span>1<span style="font-family:'宋体';">）</span><span style="font-family:Calibri;">Offset</span><span style="font-family:'宋体';">不再透明</span></p><p><span style="font-family:'宋体';">（</span>2<span style="font-family:'宋体';">）</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">自动失败转移需要处理</span></p><p><span style="font-family:'宋体';">（</span>3<span style="font-family:'宋体';">）增加</span><span style="font-family:Calibri;">Consumer</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">需要自己做负载均衡</span></p><p align="justify"> </p><p><span style="color:rgb(0,0,0);background:rgb(255,255,255);"><br clear="all"></span></p><h1><strong>Apache Kafka<span style="font-family:'宋体';">学习（二）：</span><span style="font-family:Calibri;">java</span><span style="font-family:'宋体';">使用</span><span style="font-family:Calibri;">Kafka</span></strong></h1><h2>1、<strong>maven<span style="font-family:'黑体';">依赖</span></strong></h2><pre><code class="language-java">&lt;dependency&gt;

&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;

&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;

&lt;version&gt;0.11.0.0&lt;/version&gt;

&lt;/dependency&gt;</code></pre><h2>2、<strong>Producer</strong></h2><h3><strong>2.1<span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">producer</span><span style="font-family:'宋体';">发送消息</span></strong></h3><pre><code class="language-java">import java.util.Properties;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;
/**
 * 最简单的kafka producer
 */
public class ProducerDemo {

	public static void main(String[] args) {
		Properties properties =new Properties();
		//zookeeper服务器集群地址，用逗号隔开
		properties.put("bootstrap.servers", "172.16.0.218:9092,172.16.0.219:9092,172.16.0.217:9092");
        properties.put("acks", "all");
        properties.put("retries", 0);
        properties.put("batch.size", 16384);
        properties.put("linger.ms", 1);
        properties.put("buffer.memory", 33554432);
        properties.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        properties.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        //自定义producer拦截器
        properties.put("interceptor.classes", "com.lt.kafka.producer.MyProducerInterceptor");
        //自定义消息路由规则（消息发送到哪一个Partition中）
        //properties.put("partitioner.class", "com.lt.kafka.producer.MyPartition");
        
        Producer&lt;String, String&gt; producer = null;
        try {
            producer = new KafkaProducer&lt;String, String&gt;(properties);
            for (int i = 20; i &lt; 40; i++) {
                String msg = "This is Message:" + i;
                
				/**
				 * kafkaproducer中会同时调用自己的callback的onCompletion方法和producerIntercepter的onAcknowledgement方法。
				 * 关键源码：Callback interceptCallback = this.interceptors == null ?
				 * callback : new InterceptorCallback&lt;&gt;(callback,
				 * this.interceptors, tp);
				 */
                producer.send(new ProducerRecord&lt;String, String&gt;("leixiang", msg),new MyCallback());
            }
        } catch (Exception e) {
            e.printStackTrace();

        } finally {
        	if(producer!=null)
            producer.close();
        }
	}

}</code></pre><br><h3><strong>2.2<span style="font-family:'宋体';">、自定义</span><span style="font-family:Calibri;">producer</span><span style="font-family:'宋体';">拦截器</span></strong></h3><pre><code class="language-java">import java.util.Map;

import org.apache.kafka.clients.producer.ProducerInterceptor;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
/**
 * 自定义producer拦截器
 */
public class MyProducerInterceptor implements ProducerInterceptor&lt;String,String&gt; {

	/**
	 * 打印配置相关信息
	 */
	public void configure(Map&lt;String, ?&gt; configs) {
		// TODO Auto-generated method stub
		System.out.println(configs.toString());
	}

	/**
	 * producer发送信息拦截方法
	 */
	public ProducerRecord&lt;String,String&gt; onSend(ProducerRecord&lt;String, String&gt; record) {
		System.out.println("拦截处理前》》》");
		String topic=record.topic();
		String value=record.value();
		System.out.println("拦截处理前的消息："+value);
		ProducerRecord&lt;String,String&gt; record2=new ProducerRecord&lt;String, String&gt;(topic, value+" (intercepted)");
		System.out.println("拦截处理后的消息："+record2.value());
		System.out.println("拦截处理后《《《");
		return record2;
	}

	/**
	 * 消息确认回调函数，和callback的onCompletion方法相似。
	 * 在kafkaProducer中，如果都设置，两者都会调用。
	 */
	public void onAcknowledgement(RecordMetadata metadata, Exception exception) {
		if (metadata != null)
			System.out.println("MyProducerInterceptor onAcknowledgement:RecordMetadata=" + metadata.toString());
		if (exception != null)
			exception.printStackTrace();
	}

	/**
	 * interceptor关闭回调
	 */
	public void close() {
		System.out.println("MyProducerInterceptor is closed!");
	}

}</code></pre><br><p><span style="color:rgb(0,0,0);"> </span><span style="font-weight:bold;font-size:22px;">2.3</span><span style="font-size:22px;font-family:'宋体';"><strong>、自定义消息路由规则</strong></span></p><p>自定义路由规则，可以根据自己的需要定义消息发送到哪个分区。自定义路由规则需要实现<span style="color:rgb(0,0,0);">Partitioner</span><span style="color:rgb(0,0,0);">。</span></p><p> </p><pre><code class="language-java">import java.util.Map;

import org.apache.kafka.clients.producer.Partitioner;
import org.apache.kafka.common.Cluster;

public class MyPartition implements Partitioner{

	public void configure(Map&lt;String, ?&gt; arg0) {
		// TODO Auto-generated method stub
		
	}

	public void close() {
		// TODO Auto-generated method stub
		
	}

	public int partition(String arg0, Object arg1, byte[] arg2, Object arg3, byte[] arg4, Cluster arg5) {
		// TODO Auto-generated method stub
		return 0;
	}

}</code></pre><br><p><br></p><h2>3、<strong>Consumer</strong></h2><h3><strong>3.1<span style="font-family:'宋体';">、自动提交</span></strong></h3><pre><code class="language-java">import java.util.Arrays;
import java.util.Properties;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;

public class AutoCommitConsumerDemo {
	public static void main(String[] args) {
		Properties props = new Properties();
		props.put("bootstrap.servers", "172.16.0.218:9092,172.16.0.219:9092,172.16.0.217:9092");
		props.put("group.id", "leixiang");
		props.put("enable.auto.commit", "true");
		//想要读取之前的数据，必须加上
		//props.put("auto.offset.reset", "earliest");
		/* 自动确认offset的时间间隔 */
		props.put("auto.commit.interval.ms", "1000");
		/*
		 * 一旦consumer和kakfa集群建立连接，
		 * consumer会以心跳的方式来高速集群自己还活着，
		 * 如果session.timeout.ms 内心跳未到达服务器，服务器认为心跳丢失，会做rebalence
		 */
		props.put("session.timeout.ms", "30000");
		props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
		props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
		//配置自定义的拦截器，可以在拦截器中引入第三方插件实现日志记录等功能。
		//props.put("interceptor.classes", "com.lt.kafka.consumer.MyConsumerInterceptor");
		
		@SuppressWarnings("resource")
		KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props);
		try {
			/* 消费者订阅的topic, 可同时订阅多个 ，用逗号隔开*/
			consumer.subscribe(Arrays.asList("leixiang"));
			while (true) {
				//轮询数据。如果缓冲区中没有数据，轮询等待的时间为毫秒。如果0，立即返回缓冲区中可用的任何记录，则返回空
				ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);
				for (ConsumerRecord&lt;String, String&gt; record : records)
					System.out.printf("offset = %d, key = %s, value = %s%n", record.offset(), record.key(),
							record.value());
			}
		} catch (Exception e) {
			// TODO: handle exception
			e.printStackTrace();
		}
	}
}</code></pre><p><span style="font-weight:bold;font-size:22px;">3.2</span><span style="font-size:22px;font-family:'宋体';"><strong>、手动提交</strong></span></p><pre><code class="language-java">import java.util.Arrays;
import java.util.Properties;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;

public class ManualCommitConsumerDemo {
	public static void main(String[] args) {
		Properties props = new Properties();
		props.put("bootstrap.servers", "172.16.0.218:9092,172.16.0.219:9092,172.16.0.217:9092");
		props.put("group.id", "leixiang");
		props.put("enable.auto.commit", "false");//手动确认
		/* 自动确认offset的时间间隔 */
		props.put("auto.commit.interval.ms", "1000");
		props.put("auto.offset.reset", "earliest");//想要读取之前的数据，必须加上
		/*
		 * 一旦consumer和kakfa集群建立连接，
		 * consumer会以心跳的方式来高速集群自己还活着，
		 * 如果session.timeout.ms 内心跳未到达服务器，服务器认为心跳丢失，会做rebalence
		 */
		props.put("session.timeout.ms", "30000");
		props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
		props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
		//配置自定义的拦截器，可以在拦截器中引入第三方插件实现日志记录等功能。
		props.put("interceptor.classes", "com.lt.kafka.consumer.MyConsumerInterceptor");
		
		KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props);
		/* 消费者订阅的topic, 可同时订阅多个 ，用逗号隔开*/
		consumer.subscribe(Arrays.asList("leixiang"));
		while (true) {
		    ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);
		    for (ConsumerRecord&lt;String, String&gt; record : records) {
		    	//处理消息
		    	saveMessage(record);
		    	//手动提交，并且设置Offset提交回调方法
		    	//consumer.commitAsync(new MyOffsetCommitCallback());
		    	consumer.commitAsync();
		    }
		}
	}
	
	public static void saveMessage(ConsumerRecord&lt;String, String&gt; record){
		System.out.printf("处理消息：offset = %d, key = %s, value = %s%n", record.offset(), record.key(),
							record.value());
	}
}</code></pre><p><span style="color:rgb(0,0,0);font-family:'宋体';">自定义</span><span style="color:rgb(0,0,0);">Consumer</span><span style="color:rgb(0,0,0);font-family:'宋体';">拦截器</span></p><pre><code class="language-java">import java.util.Map;

import org.apache.kafka.clients.consumer.ConsumerInterceptor;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.OffsetAndMetadata;
import org.apache.kafka.common.TopicPartition;

public class MyConsumerInterceptor implements ConsumerInterceptor&lt;String, String&gt; {

	public void configure(Map&lt;String, ?&gt; configs) {
		System.out.println("MyConsumerInterceptor configs&gt;&gt;&gt;"+configs.toString());
	}

	public ConsumerRecords&lt;String, String&gt; onConsume(ConsumerRecords&lt;String, String&gt; records) {
		System.out.println("onConsume");
		return records;
	}

	public void onCommit(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets) {
		System.out.println("onCommit");
	}

	public void close() {
		System.out.println("MyConsumerInterceptor is closed!");
	}

}</code></pre><p><span style="color:rgb(0,0,0);font-family:'宋体';">自定义</span><span style="color:rgb(0,0,0);">Offset</span><span style="color:rgb(0,0,0);font-family:'宋体';">提交回调方法</span></p><pre><code class="language-java">import java.util.Map;

import org.apache.kafka.clients.consumer.OffsetAndMetadata;
import org.apache.kafka.clients.consumer.OffsetCommitCallback;
import org.apache.kafka.common.TopicPartition;

public class MyOffsetCommitCallback implements OffsetCommitCallback {

	public void onComplete(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception) {
		if (offsets != null)
			System.out.println("offsets&gt;&gt;&gt;" + offsets.toString());
		if (exception != null)
			exception.printStackTrace();
	}

}</code></pre><br><p><span style="color:rgb(0,0,0);"> </span><span style="font-weight:bold;font-size:28px;">Apache Kafka</span><span style="font-size:28px;font-family:'宋体';"><strong>学习（三）：</strong></span><span style="font-size:28px;font-family:Calibri;"><strong>Kafka</strong></span><span style="font-size:28px;font-family:'宋体';"><strong>常用命令</strong></span></p><p> </p><p><span style="color:rgb(0,0,0);background:rgb(255,255,255);"> </span></p><h2><strong>1<span style="font-family:'黑体';">、开启</span><span style="font-family:Arial;">zookeeper</span><span style="font-family:'黑体';">（在安装目录下使用命令）</span></strong></h2><p>Linux<span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">bin/zkServer.sh start</span></p><p>windows:bin\zkServer.cmd</p><p> </p><h2><strong>2<span style="font-family:'黑体';">、启动</span><span style="font-family:Arial;">kafka</span><span style="font-family:'黑体';">（安装目录下使用命令）</span></strong></h2><p>Linux<span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">bin/kafka-server-start.sh start config/server.properties</span></p><p>windows:bin\windows\kafka-server-start.bat config\server.properties</p><p> </p><h2><strong>3<span style="font-family:'黑体';">、查看</span><span style="font-family:Arial;">topic</span><span style="font-family:'黑体';">名称列表</span></strong></h2><p>Linux<span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">bin/kafka-topics.sh -list --zookeeper 172.16.0.99:2181,172.16.0.218:2181</span></p><p>windows:bin\windows\kafka-topics.bat -list --zookeeper 172.16.0.99:2181,172.16.0.218:2181</p><p> </p><h2><strong>4<span style="font-family:'黑体';">、查看</span><span style="font-family:Arial;">topic</span><span style="font-family:'黑体';">详情</span></strong></h2><p>Linux<span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">bin/kafka-topics.sh -zookeeper localhost:2181 --topic test --describe</span></p><p>windows<span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">bin\windows\kafka-topics.bat --zookeeper localhost:2181 --topic test --describe</span></p><p> </p><p> </p><h2><strong>5<span style="font-family:'黑体';">、删除</span><span style="font-family:Arial;">topic</span></strong></h2><p>Linux<span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic "test"</span></p><p>windows:bin\windows\kafka-topics.bat --zookeeper localhost:2181 --delete --topic "test"</p><p><span style="font-family:'宋体';">注意：集群中一台机器删除了</span>topic<span style="font-family:'宋体';">，其他机器同步删除相同</span><span style="font-family:Calibri;">topic</span></p><p> </p><h2><strong>6<span style="font-family:'黑体';">、创建</span><span style="font-family:Arial;">topic</span></strong></h2><p>Linux<span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</span></p><p>windows:bin\windows\kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</p><p>注意：</p><p>replication-factor:<span style="font-family:'宋体';">副本个数，一般为小于等于</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">个数。</span></p><p>partitions<span style="font-family:'宋体';">：分区个数。如果副本个数为</span><span style="font-family:Calibri;">1</span><span style="font-family:'宋体';">，分区为</span><span style="font-family:Calibri;">4</span><span style="font-family:'宋体';">，则</span><span style="font-family:Calibri;">4</span><span style="font-family:'宋体';">个分区会均匀的分布在各个</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">上。如果</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">为</span><span style="font-family:Calibri;">2</span><span style="font-family:'宋体';">，副本为</span><span style="font-family:Calibri;">2</span><span style="font-family:'宋体';">，分区为</span><span style="font-family:Calibri;">4</span><span style="font-family:'宋体';">，则每个</span><span style="font-family:Calibri;">Broker</span><span style="font-family:'宋体';">上面都有</span><span style="font-family:Calibri;">4</span><span style="font-family:'宋体';">个分区。</span></p><p> </p><h2><strong>7<span style="font-family:'黑体';">、创建</span><span style="font-family:Arial;">Consumer</span></strong></h2><p>Linux<span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning</span></p><p>windows<span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">bin\windows\kafka-console-consumer.bat --zookeeper localhost:2181 --topic test --form-beginning</span></p><p><span style="font-family:'宋体';">注意：</span>form beginning<span style="font-family:'宋体';">表示从头拉取。</span></p><p> </p><h2><strong>8<span style="font-family:'黑体';">、创建</span><span style="font-family:Arial;">Producer</span></strong></h2><p>Linux<span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">bin/kafka-console-producer.sh --broker-list 172.16.0.99:9020,172.16.0.218:9020 --topic test</span></p><p>windows<span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">bin\windows\kafka-console-producer.bat --broker-list 172.16.0.99:9092,172.16.0.218:9080 --topic test</span></p><p><span style="font-family:'宋体';">注意：此处是</span>kafka<span style="font-family:'宋体';">的端口，而且在集群里如果此处填</span><span style="font-family:Calibri;">localhost</span><span style="font-family:'宋体';">，会报一个连接错误，猜想应该是消息没有到达集群，因此此处将集群的</span><span style="font-family:Calibri;">ip</span><span style="font-family:'宋体';">都填上。</span></p><p> </p><h2><strong>9<span style="font-family:'黑体';">、查询</span><span style="font-family:Arial;">topic</span><span style="font-family:'黑体';">所有分区的</span><span style="font-family:Arial;">offset</span><span style="font-family:'黑体';">值</span></strong></h2><p>Linux<span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list 10.162.160.115:9092 --topic s1mmetest --time -1</span></p><p> </p><h2><strong>10<span style="font-family:'黑体';">、查询</span><span style="font-family:Arial;">kafka</span><span style="font-family:'黑体';">集群当前</span><span style="font-family:Arial;">topic</span><span style="font-family:'黑体';">所有分区中的消息数目</span></strong></h2><p>Linux<span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list 10.162.160.115:9092 --topic s1mmetest --time -2</span></p><p> </p><p><span style="color:#ff0000;"> <span style="font-family:'Microsoft YaHei';font-size:14px;line-height:21px;background-color:rgb(255,255,255);">【四川乐山程序员联盟，欢迎大家加群相互交流学习5 7 1 8 1 4 7 4 3】</span></span></p><p> </p><p> </p>            </div>
                </div>