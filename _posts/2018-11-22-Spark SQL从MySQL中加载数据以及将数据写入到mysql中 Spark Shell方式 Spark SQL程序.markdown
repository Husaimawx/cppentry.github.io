---
layout:     post
title:      Spark SQL从MySQL中加载数据以及将数据写入到mysql中 Spark Shell方式 Spark SQL程序
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p><strong>分享一下我老师大神的人工智能教程！零基础，通俗易懂！<a href="https://blog.csdn.net/jiangjunshow/article/details/77338485" rel="nofollow">http://blog.csdn.net/jiangjunshow</a></strong></p><p></p><p><strong>也欢迎大家转载本篇文章。分享知识，造福人民，实现我们中华民族伟大复兴！</strong></p><p></p><div class="markdown_views">       <!-- flowchart &#31661;&#22836;&#22270;&#26631; &#21247;&#21024; -->       <svg xmlns="http://www.w3.org/2000/svg"><path id="raphael-marker-block" stroke-linecap="round" d="M 5 0 L 0 2.5 L 5 5 Z"></path></svg>       <h1 id="1-jdbc"><a></a>1． JDBC</h1><p>Spark SQL可以通过JDBC从关系型数据库中读取数据的方式创建DataFrame，通过对DataFrame一系列的计算后，还可以将数据再写回关系型数据库中。</p><h2 id="11-从mysql中加载数据spark-shell方式"><a></a>1.1． 从MySQL中加载数据（Spark Shell方式）</h2><p><strong>1.启动Spark Shell，必须指定mysql连接驱动jar包</strong></p><pre class="prettyprint"><code class="hljs brainfuck has-numbering"><span class="hljs-title">[</span><span class="hljs-comment">root@hadoop1</span> <span class="hljs-comment">spark</span><span class="hljs-literal">-</span><span class="hljs-comment">2</span><span class="hljs-string">.</span><span class="hljs-comment">1</span><span class="hljs-string">.</span><span class="hljs-comment">1</span><span class="hljs-literal">-</span><span class="hljs-comment">bin</span><span class="hljs-literal">-</span><span class="hljs-comment">hadoop2</span><span class="hljs-string">.</span><span class="hljs-comment">7</span><span class="hljs-title">]</span><span class="hljs-comment">#</span> <span class="hljs-comment">bin/spark</span><span class="hljs-literal">-</span><span class="hljs-comment">shell</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">master</span> <span class="hljs-comment">spark://hadoop1:7077</span><span class="hljs-string">,</span><span class="hljs-comment">hadoop2:7077</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">jars</span> <span class="hljs-comment">/home/tuzq/software/spark</span><span class="hljs-literal">-</span><span class="hljs-comment">2</span><span class="hljs-string">.</span><span class="hljs-comment">1</span><span class="hljs-string">.</span><span class="hljs-comment">1</span><span class="hljs-literal">-</span><span class="hljs-comment">bin</span><span class="hljs-literal">-</span><span class="hljs-comment">hadoop2</span><span class="hljs-string">.</span><span class="hljs-comment">7/jars/mysql</span><span class="hljs-literal">-</span><span class="hljs-comment">connector</span><span class="hljs-literal">-</span><span class="hljs-comment">java</span><span class="hljs-literal">-</span><span class="hljs-comment">5</span><span class="hljs-string">.</span><span class="hljs-comment">1</span><span class="hljs-string">.</span><span class="hljs-comment">38</span><span class="hljs-string">.</span><span class="hljs-comment">jar</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">driver</span><span class="hljs-literal">-</span><span class="hljs-comment">class</span><span class="hljs-literal">-</span><span class="hljs-comment">path</span> <span class="hljs-comment">/home/tuzq/software/spark</span><span class="hljs-literal">-</span><span class="hljs-comment">2</span><span class="hljs-string">.</span><span class="hljs-comment">1</span><span class="hljs-string">.</span><span class="hljs-comment">1</span><span class="hljs-literal">-</span><span class="hljs-comment">bin</span><span class="hljs-literal">-</span><span class="hljs-comment">hadoop2</span><span class="hljs-string">.</span><span class="hljs-comment">7/jars/mysql</span><span class="hljs-literal">-</span><span class="hljs-comment">connector</span><span class="hljs-literal">-</span><span class="hljs-comment">java</span><span class="hljs-literal">-</span><span class="hljs-comment">5</span><span class="hljs-string">.</span><span class="hljs-comment">1</span><span class="hljs-string">.</span><span class="hljs-comment">38</span><span class="hljs-string">.</span><span class="hljs-comment">jar</span></code></pre><ul class="pre-numbering"><li>1</li></ul><p><img title="" alt="这里写图片描述" src="https://img-blog.csdn.net/20170711161019218?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdG90b3R1enVvcXVhbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p><p><strong>2.从mysql中加载数据</strong> <br>进入bigdata中创建person表：</p><pre class="prettyprint"><code class="hljs sql has-numbering"><span class="hljs-operator"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">DATABASE</span> bigdata <span class="hljs-keyword">CHARACTER</span> <span class="hljs-keyword">SET</span> utf8;</span>USE bigdata;<span class="hljs-operator"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> person (    id <span class="hljs-keyword">INT</span>(<span class="hljs-number">10</span>) AUTO_INCREMENT <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span>,    name <span class="hljs-keyword">varchar</span>(<span class="hljs-number">100</span>),    age <span class="hljs-keyword">INT</span>(<span class="hljs-number">3</span>)) ENGINE=INNODB <span class="hljs-keyword">DEFAULT</span> CHARSET=utf8;</span></code></pre><ul class="pre-numbering"><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li></ul><p>并初始化数据： <br><img title="" alt="这里写图片描述" src="https://img-blog.csdn.net/20170711163051212?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdG90b3R1enVvcXVhbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p><pre class="prettyprint"><code class="hljs avrasm has-numbering">scala&gt; val sqlContext = new org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.spark</span><span class="hljs-preprocessor">.sql</span><span class="hljs-preprocessor">.SQLContext</span>(sc)</code></pre><ul class="pre-numbering"><li>1</li></ul><pre class="prettyprint"><code class="hljs lasso has-numbering">scala<span class="hljs-subst">&gt;</span> val jdbcDF <span class="hljs-subst">=</span> sqlContext<span class="hljs-built_in">.</span>read<span class="hljs-built_in">.</span>format(<span class="hljs-string">"jdbc"</span>)<span class="hljs-built_in">.</span>options(<span class="hljs-built_in">Map</span>(<span class="hljs-string">"url"</span> <span class="hljs-subst">-&gt; </span><span class="hljs-string">"jdbc:mysql://hadoop10:3306/bigdata"</span>, <span class="hljs-string">"driver"</span> <span class="hljs-subst">-&gt; </span><span class="hljs-string">"com.mysql.jdbc.Driver"</span>, <span class="hljs-string">"dbtable"</span> <span class="hljs-subst">-&gt; </span><span class="hljs-string">"person"</span>, <span class="hljs-string">"user"</span> <span class="hljs-subst">-&gt; </span><span class="hljs-string">"root"</span>, <span class="hljs-string">"password"</span> <span class="hljs-subst">-&gt; </span><span class="hljs-string">"123456"</span>))<span class="hljs-built_in">.</span>load()</code></pre><ul class="pre-numbering"><li>1</li></ul><p><strong>3.执行查询</strong></p><pre class="prettyprint"><code class="hljs asciidoc has-numbering"><span class="hljs-header">scala&gt; jdbcDF.show+---+--------+---+</span><span class="hljs-header">| id|    name|age|+---+--------+---+</span>|  1|zhangsan| 19||  2|    lisi| 20||  3|  wangwu| 28||  4| zhaoliu| 26|<span class="hljs-header">|  5|  tianqi| 55|+---+--------+---+</span></code></pre><ul class="pre-numbering"><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li></ul><h2 id="12-将数据写入到mysql中打jar包方式"><a></a>1.2． 将数据写入到MySQL中（打jar包方式）</h2><h3 id="121编写spark-sql程序"><a></a>1.2.1编写Spark SQL程序</h3><pre class="prettyprint"><code class="hljs scala has-numbering"><span class="hljs-keyword">package</span> cn.toto.spark<span class="hljs-keyword">import</span> java.sql.DriverManager<span class="hljs-keyword">import</span> org.apache.spark.rdd.JdbcRDD<span class="hljs-keyword">import</span> org.apache.spark.{SparkConf, SparkContext}<span class="hljs-javadoc">/**  * Created by toto on 2017/7/11.  */</span><span class="hljs-class"><span class="hljs-keyword">object</span> <span class="hljs-title">JdbcRDDDemo</span> {</span>  <span class="hljs-keyword">def</span> main(args: Array[String]): Unit = {    <span class="hljs-keyword">val</span> conf = <span class="hljs-keyword">new</span> SparkConf().setAppName(<span class="hljs-string">"JdbcRDDDemo"</span>).setMaster(<span class="hljs-string">"local[2]"</span>)    <span class="hljs-keyword">val</span> sc = <span class="hljs-keyword">new</span> SparkContext(conf)    <span class="hljs-keyword">val</span> connection = () =&gt; {      Class.forName(<span class="hljs-string">"com.mysql.jdbc.Driver"</span>).newInstance()      DriverManager.getConnection(<span class="hljs-string">"jdbc:mysql://hadoop10:3306/bigdata"</span>,<span class="hljs-string">"root"</span>,<span class="hljs-string">"123456"</span>)    }    <span class="hljs-comment">//这个地方没有读取数据(数据库表也用的是person)</span>    <span class="hljs-keyword">val</span> jdbcRDD = <span class="hljs-keyword">new</span> JdbcRDD(      sc,      connection,      <span class="hljs-string">"SELECT * FROM person where id &gt;= ? AND id &lt;= ?"</span>,      <span class="hljs-comment">//这里表示从取数据库中的第1、2、3、4条数据，然后分两个区</span>      <span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">2</span>,      r =&gt; {        <span class="hljs-keyword">val</span> id = r.getInt(<span class="hljs-number">1</span>)        <span class="hljs-keyword">val</span> code = r.getString(<span class="hljs-number">2</span>)        (id, code)      }    )    <span class="hljs-comment">//这里相当于是action获取到数据</span>    <span class="hljs-keyword">val</span> jrdd = jdbcRDD.collect()    println(jrdd.toBuffer)    sc.stop()  }}</code></pre><ul class="pre-numbering"><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li><li>12</li><li>13</li><li>14</li><li>15</li><li>16</li><li>17</li><li>18</li><li>19</li><li>20</li><li>21</li><li>22</li><li>23</li><li>24</li><li>25</li><li>26</li><li>27</li><li>28</li><li>29</li><li>30</li><li>31</li><li>32</li><li>33</li><li>34</li><li>35</li><li>36</li><li>37</li></ul><p>注意在运行的时候使用的还是person这个表，表中的数据如下： <br><img title="" alt="这里写图片描述" src="https://img-blog.csdn.net/20170711175927544?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdG90b3R1enVvcXVhbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p><p>如果是在IDEA中运行程序，程序结果如下： <br><img title="" alt="这里写图片描述" src="https://img-blog.csdn.net/20170711175836942?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdG90b3R1enVvcXVhbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p><h3 id="122用maven将程序打包"><a></a>1.2.2用maven将程序打包</h3><p><img title="" alt="这里写图片描述" src="https://img-blog.csdn.net/20170711183857789?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdG90b3R1enVvcXVhbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p><h3 id="123将jar包提交到spark集群"><a></a>1.2.3.将Jar包提交到spark集群</h3><p>将bigdata-1.0-SNAPSHOT.jar放到：/home/tuzq/software/sparkdata，如下： <br><img title="" alt="这里写图片描述" src="https://img-blog.csdn.net/20170711184051057?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdG90b3R1enVvcXVhbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">    </p><p>注意在运行执行，要将mysql-connector-java-5.1.38.jar 放到：/home/tuzq/software/spark-2.1.1-bin-hadoop2.7/jars/下</p><pre class="prettyprint"><code class="hljs avrasm has-numbering">bin/spark-submit --class cn<span class="hljs-preprocessor">.toto</span><span class="hljs-preprocessor">.spark</span><span class="hljs-preprocessor">.JdbcRDDDemo</span> --master spark://hadoop1:<span class="hljs-number">7077</span> --jars /home/tuzq/software/spark-<span class="hljs-number">2.1</span><span class="hljs-number">.1</span>-bin-hadoop2<span class="hljs-number">.7</span>/jars/mysql-connector-java-<span class="hljs-number">5.1</span><span class="hljs-number">.38</span><span class="hljs-preprocessor">.jar</span> --driver-class-path /home/tuzq/software/spark-<span class="hljs-number">2.1</span><span class="hljs-number">.1</span>-bin-hadoop2<span class="hljs-number">.7</span>/jars/mysql-connector-java-<span class="hljs-number">5.1</span><span class="hljs-number">.38</span><span class="hljs-preprocessor">.jar</span> /home/tuzq/software/sparkdata/bigdata-<span class="hljs-number">1.0</span>-SNAPSHOT<span class="hljs-preprocessor">.jar</span></code></pre><ul class="pre-numbering"><li>1</li></ul><p>运行结果： <br><img title="" alt="这里写图片描述" src="https://img-blog.csdn.net/20170711184452517?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdG90b3R1enVvcXVhbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"> <br><img title="" alt="这里写图片描述" src="https://img-blog.csdn.net/20170711184633963?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdG90b3R1enVvcXVhbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p><h1 id="2通过spark-sql将数据存储到数据库中"><a></a>2、通过Spark-sql将数据存储到数据库中</h1><h3 id="221代码如下"><a></a>2.2.1.代码如下：</h3><pre class="prettyprint"><code class="hljs scala has-numbering"><span class="hljs-keyword">package</span> cn.toto.spark<span class="hljs-keyword">import</span> java.util.Properties<span class="hljs-keyword">import</span> org.apache.spark.sql.{Row, SQLContext}<span class="hljs-keyword">import</span> org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}<span class="hljs-keyword">import</span> org.apache.spark.{SparkConf, SparkContext}<span class="hljs-javadoc">/**  * Created by toto on 2017/7/11.  */</span><span class="hljs-class"><span class="hljs-keyword">object</span> <span class="hljs-title">JdbcRDD</span> {</span>  <span class="hljs-keyword">def</span> main(args: Array[String]): Unit = {    <span class="hljs-keyword">val</span> conf = <span class="hljs-keyword">new</span> SparkConf().setAppName(<span class="hljs-string">"MySQL-Demo"</span>).setMaster(<span class="hljs-string">"local"</span>)    <span class="hljs-keyword">val</span> sc = <span class="hljs-keyword">new</span> SparkContext(conf)    <span class="hljs-keyword">val</span> sqlContext = <span class="hljs-keyword">new</span> SQLContext(sc)    <span class="hljs-comment">//通过并行化创建RDD</span>    <span class="hljs-keyword">val</span> personRDD = sc.parallelize(Array(<span class="hljs-string">"14 tom 5"</span>, <span class="hljs-string">"15 jerry 3"</span>, <span class="hljs-string">"16 kitty 6"</span>)).map(_.split(<span class="hljs-string">" "</span>))    <span class="hljs-comment">//通过StrutType直接指定每个字段的schema</span>    <span class="hljs-keyword">val</span> schema = StructType(      List(        StructField(<span class="hljs-string">"id"</span>,IntegerType,<span class="hljs-keyword">true</span>),        StructField(<span class="hljs-string">"name"</span>,StringType,<span class="hljs-keyword">true</span>),        StructField(<span class="hljs-string">"age"</span>,IntegerType,<span class="hljs-keyword">true</span>)      )    )    <span class="hljs-comment">//将RDD映射到rowRDD</span>    <span class="hljs-keyword">val</span> rowRDD = personRDD.map(p =&gt; Row(p(<span class="hljs-number">0</span>).toInt, p(<span class="hljs-number">1</span>).trim, p(<span class="hljs-number">2</span>).toInt))    <span class="hljs-comment">//将schema信息应用到rowRDD上</span>    <span class="hljs-keyword">val</span> personDataFrame = sqlContext.createDataFrame(rowRDD,schema)    <span class="hljs-comment">//创建Properties存储数据库相关属性</span>    <span class="hljs-keyword">val</span> prop = <span class="hljs-keyword">new</span> Properties()    prop.put(<span class="hljs-string">"user"</span>, <span class="hljs-string">"root"</span>)    prop.put(<span class="hljs-string">"password"</span>, <span class="hljs-string">"123456"</span>)    <span class="hljs-comment">//将数据追加到数据库</span>    personDataFrame.write.mode(<span class="hljs-string">"append"</span>).jdbc(<span class="hljs-string">"jdbc:mysql://hadoop10:3306/bigdata"</span>,      <span class="hljs-string">"bigdata.person"</span>,prop)    <span class="hljs-comment">//停止SparkContext</span>    sc.stop()  }}</code></pre><ul class="pre-numbering"><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li><li>12</li><li>13</li><li>14</li><li>15</li><li>16</li><li>17</li><li>18</li><li>19</li><li>20</li><li>21</li><li>22</li><li>23</li><li>24</li><li>25</li><li>26</li><li>27</li><li>28</li><li>29</li><li>30</li><li>31</li><li>32</li><li>33</li><li>34</li><li>35</li><li>36</li><li>37</li><li>38</li><li>39</li><li>40</li><li>41</li></ul><p>运行结果： <br><img title="" alt="这里写图片描述" src="https://img-blog.csdn.net/20170711192655428?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdG90b3R1enVvcXVhbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p><h3 id="222用maven将程序打包"><a></a>2.2.2、用maven将程序打包</h3><p><img title="" alt="这里写图片描述" src="https://img-blog.csdn.net/20170711194523095?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdG90b3R1enVvcXVhbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p><h2 id="223将jar包提交到spark集群"><a></a>2.2.3、将Jar包提交到spark集群</h2><pre class="prettyprint"><code class="hljs avrasm has-numbering">bin/spark-submit --class cn<span class="hljs-preprocessor">.toto</span><span class="hljs-preprocessor">.spark</span><span class="hljs-preprocessor">.JdbcRDD</span> --master spark://hadoop1:<span class="hljs-number">7077</span> --jars /home/tuzq/software/spark-<span class="hljs-number">2.1</span><span class="hljs-number">.1</span>-bin-hadoop2<span class="hljs-number">.7</span>/jars/mysql-connector-java-<span class="hljs-number">5.1</span><span class="hljs-number">.38</span><span class="hljs-preprocessor">.jar</span> --driver-class-path /home/tuzq/software/spark-<span class="hljs-number">2.1</span><span class="hljs-number">.1</span>-bin-hadoop2<span class="hljs-number">.7</span>/jars/mysql-connector-java-<span class="hljs-number">5.1</span><span class="hljs-number">.38</span><span class="hljs-preprocessor">.jar</span> /home/tuzq/software/sparkdata/bigdata-<span class="hljs-number">1.0</span>-SNAPSHOT<span class="hljs-preprocessor">.jar</span></code></pre><ul class="pre-numbering"><li>1</li></ul>            </div><p></p><strong></strong><h4>给我老师的人工智能教程打call！<a href="https://blog.csdn.net/jiangjunshow/article/details/77338485" rel="nofollow">http://blog.csdn.net/jiangjunshow</a></h4><div align="center"><img title="" alt="这里写图片描述" src="https://img-blog.csdn.net/20161220210733446?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc3VuaHVhcWlhbmcx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></div>

            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>