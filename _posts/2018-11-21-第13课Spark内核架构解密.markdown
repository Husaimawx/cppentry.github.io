---
layout:     post
title:      第13课Spark内核架构解密
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p><strong></strong></p>
<p><span style="font-size:12px;">第一阶段：<span style="font-family:Calibri;">Spark streaming</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">spark sql</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">kafka</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">spark</span><span style="font-family:'宋体';">内核原理（必须有一个大型项目经验）；</span></span></p>
<p><span style="font-size:12px;">第二阶段：<span style="font-family:Calibri;">spark</span><span style="font-family:'宋体';">运行的各种环境，各种故障的解决，性能优化（精通</span><span style="font-family:Calibri;">spark</span><span style="font-family:'宋体';">内核、运行原理）；</span></span></p>
<p><span style="font-size:12px;">第三阶段：流处理、机器学习为鳌头，需要首先掌握前两个阶段的内容；<strong><span></span></strong></span></p>
<p><span style="font-size:12px;"><span></span></span></p>
<p style="font-weight:bold;"><span style="font-size:12px;"><span></span>跟随王家林老师的零基础讲解，注重动手实战，成为<span style="font-family:Calibri;">spark</span><span style="font-family:'宋体';">高数，笑傲大数据之林！</span></span></p>
<p><strong>本期内容：</strong></p>
<p><strong>1 <span style="font-family:'宋体';">通过手动绘图的方式解密</span><span style="font-family:Calibri;">Spark</span><span style="font-family:'宋体';">内核架构</span></strong></p>
<p><strong>2 <span style="font-family:'宋体';">通过案例来验证</span><span style="font-family:Calibri;">Spark</span><span style="font-family:'宋体';">内核架构</span></strong></p>
<p><strong>3 Spark<span style="font-family:'宋体';">架构思考</span></strong></p>
<p><span style="font-family:'宋体';"></span></p>
<p style="font-weight:bold;">一、详细剖析<span style="font-family:Calibri;">Spark</span><span style="font-family:'宋体';">运行机制</span></p>
<p style="font-weight:bold;">（<span style="font-family:Calibri;">1</span><span style="font-family:'宋体';">）</span><span style="font-family:Calibri;">Driver</span><span style="font-family:'宋体';">端架构</span></p>
<p><span></span>Driver<span style="font-family:'宋体';">部分代码包含了</span><span style="font-family:Calibri;">SparkConf+SparkContext</span><span style="font-family:'宋体';">，基本一切应用程序代码由</span><span style="font-family:Calibri;">Driver</span><span style="font-family:'宋体';">端的代码和分布在集群其他机器上的</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">代码组成（</span><span style="font-family:Calibri;">textFile flatMap map</span><span style="font-family:'宋体';">），</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">executor</span><span style="font-family:'宋体';">是运行在</span><span style="font-family:Calibri;">worker</span><span style="font-family:'宋体';">上的进程里的对象）是由线程池并发执行和线程的覆用，线程处理</span><span style="font-family:Calibri;">task</span><span style="font-family:'宋体';">任务，</span><span style="font-family:Calibri;">task</span><span style="font-family:'宋体';">从</span><span style="font-family:Calibri;">disk</span><span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">mem</span><span style="font-family:'宋体';">上读取数据。</span></p>
<p><span></span>SparkApplication<span style="font-family:'宋体';">的运行不依赖于C</span><span style="font-family:Calibri;">lusterManager,</span><span style="font-family:'宋体';">也就是说运行时不需要</span><span style="font-family:Calibri;">ClusterManager</span><span style="font-family:'宋体';">的参与（粗粒度分配资源即一次性分配完成）。</span></p>
<p><span></span>Driver<span style="font-family:'宋体';">运行程序的时候创建了</span><span style="font-family:Calibri;">SparkContext</span><span style="font-family:'宋体';">并且有</span><span style="font-family:Calibri;">main</span><span style="font-family:'宋体';">方法，</span><span style="font-family:Calibri;">SparkContext</span><span style="font-family:'宋体';">本身是程序调度器（分高低度调度器</span><span style="font-family:Calibri;">DAGScheduler</span><span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">TaskScheduler</span><span style="font-family:'宋体';">）。</span><span style="font-family:Calibri;">Driver</span><span style="font-family:'宋体';">端是用来提交</span><span style="font-family:Calibri;">Spark</span><span style="font-family:'宋体';">程序的机器，这台机器一般和</span><span style="font-family:Calibri;">Spark cluster</span><span style="font-family:'宋体';">集群在相同的网络环境下，因为要保证</span><span style="font-family:Calibri;">Driver</span><span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">进行频繁的通信，并且</span><span style="font-family:Calibri;">Driver</span><span style="font-family:'宋体';">的机器配置基本和</span><span style="font-family:Calibri;">Worker</span><span style="font-family:'宋体';">相同，</span><span style="font-family:Calibri;">Driver</span><span style="font-family:'宋体';">的机器安装了</span><span style="font-family:Calibri;">Spark</span><span style="font-family:'宋体';">，但不属于</span><span style="font-family:Calibri;">Spark</span><span style="font-family:'宋体';">集群的范围。</span><span style="font-family:Calibri;">Application</span><span style="font-family:'宋体';">提交的时候使用</span><span style="font-family:Calibri;">spark-submit</span><span style="font-family:'宋体';">（可配置运行时的参数</span><span style="font-family:Calibri;">MEM</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">CPU</span><span style="font-family:'宋体';">等），而生产环境下使用自动化</span><span style="font-family:Calibri;">shell</span><span style="font-family:'宋体';">脚本提交。</span></p>
<div style="text-align:center;"><img alt="" src="https://img-blog.csdn.net/20160117092928199?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center"></div>
<p><span style="font-family:'宋体';"></span></p>
<p><span></span>首先<span style="font-family:Calibri;">Driver</span><span style="font-family:'宋体';">端的应用程序包含了</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">Driver</span><span style="font-family:'宋体';">代码部分。应用程序本身</span><span style="font-family:Calibri;">Driver</span><span style="font-family:'宋体';">代码（</span><span style="font-family:Calibri;">SparkConf</span><span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">SparkContext</span><span style="font-family:'宋体';">），</span><span style="font-family:Calibri;">SparkConf</span><span style="font-family:'宋体';">中包含了设置程序名称</span><span style="font-family:Calibri;">setAppName</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">setMaster</span><span style="font-family:'宋体';">等，</span><span style="font-family:Calibri;">SparkContext</span><span style="font-family:'宋体';">包含了</span><span style="font-family:Calibri;">DAGScheduler</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">TaskScheduler</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">SchedulerBackend</span><span style="font-family:'宋体';">以及</span><span style="font-family:Calibri;">SparkEnv</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">代码包含了对业务逻辑的具体实现的代码（</span><span style="font-family:Calibri;">map</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">flatmap</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">ReduceByKey</span><span style="font-family:'宋体';">等）。</span></p>
<p><span></span>可以看出<span style="font-family:Calibri;">Driver</span><span style="font-family:'宋体';">端由</span><span style="font-family:Calibri;">SparkConf</span><span style="font-family:'宋体';">中将程序运行的配置信息传给</span><span style="font-family:Calibri;">SparkContext</span><span style="font-family:'宋体';">的上下文，由</span><span style="font-family:Calibri;">SparkContext</span><span style="font-family:'宋体';">创建</span><span style="font-family:Calibri;">DAGScheduler</span><span style="font-family:'宋体';">（高层调度器）、</span><span style="font-family:Calibri;">TaskScheduler</span><span style="font-family:'宋体';">（底层调度器：负责一个作业内部运行）、</span><span style="font-family:Calibri;">SchedulerBackend</span><span style="font-family:'宋体';">（负责握住计算资源），实例化的过程中注册当前程序给</span><span style="font-family:Calibri;">Master</span><span style="font-family:'宋体';">。然后</span><span style="font-family:Calibri;">DAGScheduler</span><span style="font-family:'宋体';">根据</span><span style="font-family:Calibri;">Actor</span><span style="font-family:'宋体';">触发</span><span style="font-family:Calibri;">job</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">SparkContext</span><span style="font-family:'宋体';">通过</span><span style="font-family:Calibri;">DAGScheduler</span><span style="font-family:'宋体';">将</span><span style="font-family:Calibri;">job</span><span style="font-family:'宋体';">中</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">形成的</span><span style="font-family:Calibri;">DAG</span><span style="font-family:'宋体';">有向无环图划分为不同的</span><span style="font-family:Calibri;">Stage</span><span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">Task</span><span style="font-family:'宋体';">具体运行于哪台机器上？就是在划分</span><span style="font-family:Calibri;">Stage</span><span style="font-family:'宋体';">的时候确定，这里就是根据数据本地行定位发送的</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">位</span></p>
<p><span style="font-family:'宋体';">置），</span><span style="font-family:Calibri;">TaskScheduler</span><span style="font-family:'宋体';">会将不同</span><span style="font-family:Calibri;">Stage</span><span style="font-family:'宋体';">中的一系列的</span><span style="font-family:Calibri;">Task</span><span style="font-family:'宋体';">发送到对应的</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">去执行，具体划分的的过程在前面</span><span style="font-family:Calibri;">WordCount</span><span style="font-family:'宋体';">背后的数据流中详细进行了分析描述，即不同的</span><span style="font-family:Calibri;">(map</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">flatmap</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">ReduceByKey</span><span style="font-family:'宋体';">）函数</span><span style="font-family:Calibri;">RDD api</span><span style="font-family:'宋体';">产生的</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">形成的</span><span style="font-family:Calibri;">DAG</span><span style="font-family:'宋体';">进行划分，得到不同的</span><span style="font-family:Calibri;">Stage</span><span style="font-family:'宋体';">，而每个</span><span style="font-family:Calibri;">Stage</span><span style="font-family:'宋体';">都由相同业务逻辑，不同处理数据的</span><span style="font-family:Calibri;">Task</span><span style="font-family:'宋体';">组成，</span><span style="font-family:Calibri;">Task</span><span style="font-family:'宋体';">又一一对应</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">中的每个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">。将划分</span><span style="font-family:Calibri;">Stages</span><span style="font-family:'宋体';">得到的</span><span style="font-family:Calibri;">TaskSet</span><span style="font-family:'宋体';">提交到</span><span style="font-family:Calibri;">TaskScheduler</span><span style="font-family:'宋体';">，进而提交给</span><span style="font-family:Calibri;">executor</span><span style="font-family:'宋体';">执行。</span></p>
<p><span></span>Driver<span style="font-family:'宋体';">端划分好</span><span style="font-family:Calibri;">Stage</span><span style="font-family:'宋体';">后，提交到</span><span style="font-family:Calibri;">Spark</span><span style="font-family:'宋体';">集群，即提交到</span><span style="font-family:Calibri;">Master</span><span style="font-family:'宋体';">由</span><span style="font-family:Calibri;">Master</span><span style="font-family:'宋体';">接收后分配资源的</span><span style="font-family:Calibri;">AppId</span><span style="font-family:'宋体';">并发送指令给</span><span style="font-family:Calibri;">Worker</span><span style="font-family:'宋体';">，然后</span><span style="font-family:Calibri;">Worker</span><span style="font-family:'宋体';">分配</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">，最后由</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">（并发处理数据分片）中的线程池中的线程并发执行。</span></p>
<p><strong>（2）Spark<span style="font-family:'宋体';">集群运行架构</span></strong></p>
<div style="text-align:center;"><img alt="" src="https://img-blog.csdn.net/20160117093037847?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center"></div>
<p><span style="font-family:'宋体';"></span></p>
<p><span></span>Driver<span style="font-family:'宋体';">端提交程序</span><span style="font-family:Calibri;">Tasks</span><span style="font-family:'宋体';">后，由</span><span style="font-family:Calibri;">Master</span><span style="font-family:'宋体';">检测没有问题便进行资源的分配和</span><span style="font-family:Calibri;">AppId</span><span style="font-family:'宋体';">的分配，然后发送指令给</span><span style="font-family:Calibri;">Worker</span><span style="font-family:'宋体';">节点，</span><span style="font-family:Calibri;">Worker</span><span style="font-family:'宋体';">节点默认会分配一个</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">，然后在</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">的线程池中进行并发执行。</span></p>
<p>Master<span style="font-family:'宋体';">收到提交的程序，</span><span style="font-family:Calibri;">Master</span><span style="font-family:'宋体';">根据以下三点为程序分配资源：</span></p>
<p><span></span>1，spark-env.sh和spark-defaults.sh</p>
<p><span></span>2，spark-submit提供的参数</p>
<p><span></span>3，程序中SparkConf配置的参数</p>
<p><span></span>Worker<span style="font-family:'宋体';">管理当前</span><span style="font-family:Calibri;">Node</span><span style="font-family:'宋体';">的资源，并接受</span><span style="font-family:Calibri;">Master</span><span style="font-family:'宋体';">的指令来分配具体的计算资源（</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">）。</span><span style="font-family:Calibri;">Worker</span><span style="font-family:'宋体';">进程通过一个</span><span style="font-family:Calibri;">Proxy</span><span style="font-family:'宋体';">（代理句柄）为</span><span style="font-family:Calibri;">ExecutorRunner</span><span style="font-family:'宋体';">的对象实例远程启动</span><span style="font-family:Calibri;">ExecutorBackend</span><span style="font-family:'宋体';">进程，实际工作的时候会通过</span><span style="font-family:Calibri;">TaskRunner</span><span style="font-family:'宋体';">（一个</span><span style="font-family:Calibri;">Runner</span><span style="font-family:'宋体';">的接口，线程一般会用</span><span style="font-family:Calibri;">Runner</span><span style="font-family:'宋体';">的接口封装业务逻辑，有</span><span style="font-family:Calibri;">run</span><span style="font-family:'宋体';">方法所以可以回调）来封装</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">接收到的</span><span style="font-family:Calibri;">Task</span><span style="font-family:'宋体';">，然后从</span><span style="font-family:Calibri;">ThreadPool</span><span style="font-family:'宋体';">中获取一个线程执行，执行完成后释放并覆用。</span></p>
<p><span></span>在最后一个<span style="font-family:Calibri;">Stage</span><span style="font-family:'宋体';">前的其他</span><span style="font-family:Calibri;">Stage</span><span style="font-family:'宋体';">都进行</span><span style="font-family:Calibri;">shuffleMapTask</span><span style="font-family:'宋体';">，此时是对数据进行</span><span style="font-family:Calibri;">shuffle</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">shuffle</span><span style="font-family:'宋体';">的结果保存在</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">所在节点的本地文件系统中，最后一个</span><span style="font-family:Calibri;">Stage</span><span style="font-family:'宋体';">中的</span><span style="font-family:Calibri;">Task</span><span style="font-family:'宋体';">就是</span><span style="font-family:Calibri;">ResultTask</span><span style="font-family:'宋体';">，负责结果数据生成。</span><span style="font-family:Calibri;">Driver</span><span style="font-family:'宋体';">会不断发送</span><span style="font-family:Calibri;">Task</span><span style="font-family:'宋体';">给</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">进行执行，所以</span><span style="font-family:Calibri;">Task</span><span style="font-family:'宋体';">都正确执行，到程序运行结束；若超过执行次数的限制，或者没有执行时会停止，待正确执行后会进入下一个</span><span style="font-family:Calibri;">stage</span><span style="font-family:'宋体';">，若没有正确执行成功，高层调度器</span><span style="font-family:Calibri;">DAGSchedular</span><span style="font-family:'宋体';">会进行一定次数的重试，若还是执行不成功就意味着整个作业的失败。</span></p>
<p><span></span>每个<span style="font-family:Calibri;">Task</span><span style="font-family:'宋体';">具体执行</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">中的一个</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">，（默认情况下为</span><span style="font-family:Calibri;">128M</span><span style="font-family:'宋体';">，但最后一个记录跨两个</span><span style="font-family:Calibri;">Block</span><span style="font-family:'宋体';">）基于该</span><span style="font-family:Calibri;">Partition</span><span style="font-family:'宋体';">具体执行我们定义的一系列内部函数，直到程序执行完成。</span></p>
<p><strong>二、Spark<span style="font-family:'宋体';">运行架构概要</span></strong></p>
<p><span></span>首先用户创建<span style="font-family:Calibri;">SparkContext</span><span style="font-family:'宋体';">，新创建的</span><span style="font-family:Calibri;">SparkContext</span><span style="font-family:'宋体';">会根据编程时设置的参数或系统默认的配置连接到</span>ClusterManager上，<span style="font-family:Calibri;">ClusterManager</span>会根据用户提交时的设置（如：占用<span style="font-family:Calibri;">CPU</span>、<span style="font-family:Calibri;">MEN</span>等资源情况），来为用户程序分配计算资源，启动相应的<span style="font-family:Calibri;">Executor</span>；而<span style="font-family:Calibri;">Driver</span>根据用户程序调度的<span style="font-family:Calibri;">Stage</span>的划分，即高层调度器（<span style="font-family:Calibri;">RDD</span>的依赖关系），若有宽依赖，会划分成不同的<span style="font-family:Calibri;">Stage</span>，每个<span style="font-family:Calibri;">Stage</span>由一组完全相同的任务组成（业务逻辑相同，处理数据不同的<span style="font-family:Calibri;">Tasks</span>组成），该<span style="font-family:Calibri;">Stage</span>分别作用于待处理的分区，待<span style="font-family:Calibri;">Stage</span>划分完成和<span style="font-family:Calibri;">TaskSet</span>创建完成后，<span style="font-family:Calibri;">Driver</span>端会向<span style="font-family:Calibri;">Executor</span>发送具体的<span style="font-family:Calibri;">task</span>，当<span style="font-family:Calibri;">Executor</span>收到<span style="font-family:Calibri;">task</span>后，会自动下载运行需要的库、包等，准备好运行环境后由线程池中的线程开始执行，因此<span style="font-family:Calibri;">Spark</span>执行是线程级别的。</p>
<p><span></span>Hadoop<span style="font-family:'宋体';">运行比</span><span style="font-family:Calibri;">Spark</span><span style="font-family:'宋体';">代价大很多，因</span><span style="font-family:Calibri;">Hadoop</span><span style="font-family:'宋体';">中的</span><span style="font-family:Calibri;">MapReduce</span><span style="font-family:'宋体';">运行的</span><span style="font-family:Calibri;">JVM</span><span style="font-family:'宋体';">虚拟机不可以复用，而</span><span style="font-family:Calibri;">Spark</span><span style="font-family:'宋体';">运行的线</span>程池中的线程可以进行复用。</p>
<p><span></span>执行<span style="font-family:Calibri;">Task</span><span style="font-family:'宋体';">的过程中，</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">会将执行的</span><span style="font-family:Calibri;">Task</span><span style="font-family:'宋体';">汇报给</span><span style="font-family:Calibri;">Driver</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">Driver</span><span style="font-family:'宋体';">收到</span><span style="font-family:Calibri;">Task</span><span style="font-family:'宋体';">的运行状态情况后，会根据具体状况进行更新等。</span></p>
<div style="text-align:center;"><img alt="" src="https://img-blog.csdn.net/20160117093200274?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center"></div>
<div style="text-align:left;"><br></div>
<p><span style="font-family:'宋体';"></span></p>
<p><strong>三、<span style="font-family:Calibri;">Spark</span><span style="font-family:'宋体';">内部组件简介</span></strong></p>
<p><strong>1<span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Task</span><span style="font-family:'宋体';">划分：</span></strong>Task<span style="font-family:'宋体';">根据不同的</span><span style="font-family:Calibri;">Stage</span><span style="font-family:'宋体';">的划分，会被划分为两种类型</span></p>
<p>（<span style="font-family:Calibri;">1</span><span style="font-family:'宋体';">）</span><span style="font-family:Calibri;">shuffleMapTask</span><span style="font-family:'宋体';">，在最后一个</span><span style="font-family:Calibri;">Stage</span><span style="font-family:'宋体';">前的其他</span><span style="font-family:Calibri;">Stage</span><span style="font-family:'宋体';">都进行</span><span style="font-family:Calibri;">shuffleMapTask</span><span style="font-family:'宋体';">，此时是对数据进行</span><span style="font-family:Calibri;">shuffle</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">shuffle</span><span style="font-family:'宋体';">的结果保存在</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">所在节点的本地文件系统中；</span></p>
<p>（<span style="font-family:Calibri;">2</span><span style="font-family:'宋体';">）第二种</span><span style="font-family:Calibri;">Task</span><span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">ResultTask</span><span style="font-family:'宋体';">，负责生成结果数据</span><span style="font-family:Calibri;">;</span></p>
<p><span></span>Driver<span style="font-family:'宋体';">会不断发送</span><span style="font-family:Calibri;">Task</span><span style="font-family:'宋体';">给</span><span style="font-family:Calibri;">Executor</span><span style="font-family:'宋体';">进行执行，所以</span><span style="font-family:Calibri;">Task</span><span style="font-family:'宋体';">都正确执行或者超过执行次数的限制，或者没有执行时会停止，待正确执行后会进入下一个</span><span style="font-family:Calibri;">stage</span><span style="font-family:'宋体';">，若没有正确执行成功，高层调度器</span><span style="font-family:Calibri;">DAGSchedular</span><span style="font-family:'宋体';">会进行一定次数的重试，若还是执行不成功就意味着整个作业的失败。</span></p>
<div style="text-align:center;"><img alt="" src="https://img-blog.csdn.net/20160117093345067?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center"></div>
<p><span style="font-family:'宋体';"><br></span></p>
<p><span style="font-family:'宋体';"></span></p>
<p><strong>2<span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">DAGScheduler:</span></strong>负责将<span style="font-family:Calibri;">job</span><span style="font-family:'宋体';">中</span><span style="font-family:Calibri;">rdd</span><span style="font-family:'宋体';">构成的</span><span style="font-family:Calibri;">DAG</span><span style="font-family:'宋体';">划分为不同的</span><span style="font-family:Calibri;">Stage</span></p>
<p>3<strong><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Worker</span><span style="font-family:'宋体';">：</span></strong>集群运行节点，<span style="font-family:Calibri;">Worker</span><span style="font-family:'宋体';">上不会运行</span><span style="font-family:Calibri;">Application</span><span style="font-family:'宋体';">的程序，因为</span>Worker管理当前Node的资源资源，并接受Master的指令来分配具体的计算资源Executor（在新的进程中分配），Worker不会向Master发送Worker的资源占用情况（MEN、CPU），Worker向Master发送心跳，只有Worker ID，因为Master在程序注册的时候已经分配好了资源，同时只有故障的时候才会发送资源的情况。</p>
<p><strong>4、Job：</strong>包含了一系列Task的并行计算。Job由action（如SaveAsTextFile）触发的，其前面是若干RDD，而RDD是Transformation级别的，transformation是Lazy的，因为是Lazy的所以不计算往前推（如：WordCount中collect触发了job，执行的时候由mapPartitionRDD往前推到hadoopRDD,之后开始一步步执行），若两个RDD之间回数的时候是窄依赖的话就在内存中进行迭代，也是Spark之所以快的原因，不是因为基于内存，因为其调度和容错及其他内容。</p>
<p><strong>5、宽依赖和窄依赖</strong></p>
<p>在RDD中将依赖划分成了两种类型：窄依赖(narrow dependencies)和宽依赖(wide dependencies)。</p>
<p><span></span>窄依赖是指父RDD的每个分区都只被子RDD的一个分区所使用（一对一）；</p>
<p><span></span>宽依赖就是指父RDD的分区被多个子RDD的分区所依赖（一对多）。</p>
<p>例如，map就是一种窄依赖，而join则会导致宽依赖(除非父RDD是hash-partitioned</p>
<div style="text-align:center;"><img alt="" src="https://img-blog.csdn.net/20160117093445705?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center"></div>
<p><span style="font-family:'宋体';"><br></span></p>
<p><span style="font-family:'宋体';"></span></p>
<p><span></span>这种划分有两个用处。首先，窄依赖支持在一个结点上管道化执行。例如基于一对一的关系，可以在<span style="font-family:Calibri;">filter</span><span style="font-family:'宋体';">之后执行</span><span style="font-family:Calibri;">map</span><span style="font-family:'宋体';">。其次，窄依赖支持更高效的故障还原。因为对于窄依赖，只有丢失的父</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">的分区需要重新计算。而对于宽依赖，一个结点的故障可能导致来自所有父</span><span style="font-family:Calibri;">RDD</span><span style="font-family:'宋体';">的分区丢失，因此就需要完全重新执行。因此对于宽依赖，</span><span style="font-family:Calibri;">Spark</span><span style="font-family:'宋体';">会在持有各个父分区的结点上，将中间数据持久化来简化故障还原，就像</span><span style="font-family:Calibri;">MapReduce</span><span style="font-family:'宋体';">会持久化</span><span style="font-family:Calibri;">map</span><span style="font-family:'宋体';">的输出一样。</span></p>
<p><span style="color:rgb(255,0,0);">注：一个Application里面可以有多个Jobs  一般一个action对应一个job。；</span><span style="color:rgb(255,0,0);">Stage内部是RDD构成的，RDD内部是并行Task的集合 </span></p>
<img alt="" src="https://img-blog.csdn.net/20160117093552372?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center"><img alt="" src="https://img-blog.csdn.net/20160117093552372?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center"><br><p><span style="font-family:'宋体';"><strong>（注：有任何有误的地方请不吝指出，方便大家学习）</strong></span></p>
            </div>
                </div>