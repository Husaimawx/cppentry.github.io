---
layout:     post
title:      Spark集群资源调度
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<br>
在学习和使用Spark过程中，简单了解下Spark如何在不同计算间分配资源，总的来说可以分为如下两个角度去分析（请路过高手指正）：<br><br><span style="font-size:18px;"><strong>1&gt;</strong></span> 每个Spark应用被分配到独立的进程(Executor)集上，Cluster Manager负责在不同的Spark应用间调度资源。<br><span style="font-size:18px;"><strong>2&gt;</strong> </span>对于每个Spark应用的进程集内（一个SparkContext实例内），Spark通过 Fair Scheduler来调度资源。<br><br><p><strong><span style="font-size:18px;">针对1&gt;，</span></strong></p>
<p><strong><span style="font-size:18px;">        最简单的是静态分配资源；基于集群模式的不同，分配策略稍有区别：</span></strong></p>
        <br><blockquote>
<blockquote><strong><span style="font-size:14px;">Standalone： </span></strong><br>
---  提交的应用遵循FIFO顺序执行（每个应用默认试图使用所有可能的结点--slave nodes）<br>
---  应用程序中可以限制可使用的Slave node数目（通过spark.cores.max或 spark.deploy.defaultCores）<br>
---  应用程序也可以限制每个executor的内存使用（spark.executor.memory）<br><br><strong><span style="font-size:14px;">YARN:</span></strong><br>
---  可限制Spark应用的executor数目（--num-executor）<br>
---  可限制每个executor可使用的CPU及内存资源 （--executor-cores 和 --executor-memory)<br><br><strong><span style="font-size:14px;">Mesos:</span></strong><br>
---  指定使用粗粒度模型 (spark.mesos.coarse设为true,表示资源静态分配)<br>
           -- 限制每个应用可使用的最大CPU资源 （spare.cores.max）<br>
           -- 限制每个executor的memory使用  (spark.executor.memory)<br>
---  也可指定细粒度模型,但仅针对CPU Cores（动态分配CPU资源，当应用不忙时可暂时释放CPU给其他应用。Memory仍然静态分配）<br></blockquote>
</blockquote>
<br><span style="font-size:18px;"><strong>        </strong></span><strong><span style="font-size:18px;">动态调度资源目前在YARN上支持，默认是disable的；未来版本会在standalone上支持。（暂时不详细介绍该部分）</span><br><br><span style="font-size:18px;">针对2&gt;--Spark应用内的资源调度：</span></strong><br><br><blockquote>
<blockquote>---  默认模式是FIFO，先被执行的Job可使用所有资源，如果先执行的Job通过资源限制并不使用所有资源，则后续的Job也可以开始运行；<br>
---  Spark应用中可以通过代码设置采用Fair Scheduler, 简单讲这就是一种round robin模式，Job不论提交顺序，都会被轮询执行。</blockquote>
</blockquote>
            </div>
                </div>