---
layout:     post
title:      Spark-胡乱小记
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主“等木鱼的猫”原创文章，转载请注明出处 http://blog.csdn.net/u012761191  					https://blog.csdn.net/u012761191/article/details/81222247				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>1.从hdfs文件中获取数据</p>

<pre class="has">
<code class="language-java">    val hdfs=org.apache.hadoop.fs.FileSystem.get(new java.net.URI("hdfs://hacluster"),
        new org.apache.hadoop.conf.Configuration())
    val fSDataInputStream1=hdfs.open(new Path(hdfs://hacluster/A/B/test.txt))
    val bufferedReader1=new BufferedReader(new InputStream(fSDataInputStream1))
    val line=bufferedReader1.readLine()</code></pre>

<p>2.定义创建ssc函数</p>

<pre class="has">
<code class="language-java">     val sc = SparkContext.getOrCreate()
     def funCreateStreamingContext():StreamingContext={
          val newSsc= new StreamingContext(sc,Seconds(60))
          println("Creating new StreamingContext")
          newSsc.chekpoint(vCheckPoint)
          newSsc
     }</code></pre>

<p>3.创建ssc</p>

<pre class="has">
<code class="language-java">    val checkPointPath ="hdfs://hacluster/A/B/checkPointPath"
    val ssc=StreamingContext.getActiveOrCreate(checkPointPath ,funCreateStreamingContext)</code></pre>

<p> </p>            </div>
                </div>