---
layout:     post
title:      HDFS上传流程以及操作命令
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/qq_43147136/article/details/83018782				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p><strong><a href="https://blog.csdn.net/gscsd_t/article/details/79949688" rel="nofollow">HDFS文件上传流程</a></strong></p>
<p><img src="https://user-gold-cdn.xitu.io/2018/8/14/1653820297235489?w=1908&amp;h=850&amp;f=png&amp;s=90568" alt=""></p>
<h2><a id="HDFS_3"></a>操作HDFS的基本命令</h2>
<pre><code>
1) 打印文件列表

标准写法：

hadoop fs -ls hdfs:/#hdfs: 明确说明是HDFS系统路径

简写：

hadoop fs -ls /#默认是HDFS系统下的根目录

打印指定子目录：

hadoop fs -ls /package/test/#HDFS系统下某个目录

2) 上传文件、目录（put、copyFromLocal）

put用法：

上传新文件：

hdfs fs -put file:/root/test.txt hdfs:/  #上传本地test.txt文件到HDFS根目录，HDFS根目录须无同名文件，否则“File exists”

hdfs fs -put test.txt /test2.txt  #上传并重命名文件。

hdfs fs -put test1.txt test2.txt hdfs:/  #一次上传多个文件到HDFS路径。


上传文件夹：

hdfs fs -put mypkg /newpkg  #上传并重命名了文件夹。
 

覆盖上传：

hdfs fs -put -f /root/test.txt /  #如果HDFS目录中有同名文件会被覆盖


copyFromLocal用法：

上传文件并重命名：

hadoop fs -copyFromLocal file:/test.txt hdfs:/test2.txt

3) 下载文件、目录（get、copyToLocal）

get用法：

拷贝文件到本地目录：

hadoop fs -get hdfs:/test.txt file:/root/

拷贝文件并重命名，可以简写：

hadoop fs -get /test.txt /root/test.txt

copyToLocal用法

拷贝文件到本地目录：

hadoop fs -copyToLocal hdfs:/test.txt file:/root/

拷贝文件并重命名，可以简写：

hadoop fs -copyToLocal /test.txt /root/test.txt

4) 拷贝文件、目录（cp）

从本地到HDFS，同put

hadoop fs -cp file:/test.txt hdfs:/test2.txt

从HDFS到HDFS

hadoop fs -cp hdfs:/test.txt hdfs:/test2.txt

hadoop fs -cp /test.txt /test2.txt

5) 移动文件（mv）

hadoop fs -mv hdfs:/test.txt hdfs:/dir/test.txt

hadoop fs -mv /test.txt /dir/test.txt

6) 删除文件、目录（rm）

删除指定文件

hadoop fs -rm /a.txt

删除全部txt文件

hadoop fs -rm /*.txt

递归删除全部文件和目录

hadoop fs -rm -R /dir/

7) 读取文件（cat、tail）

hadoop fs -cat /test.txt  #以字节码的形式读取

hadoop fs -tail /test.txt

8) 创建空文件（touchz）

hadoop fs - touchz /newfile.txt

9) 创建文件夹（mkdir）

hadoop fs -mkdir /newdir /newdir2#可以同时创建多个

hadoop fs -mkdir -p /newpkg/newpkg2/newpkg3 #同时创建父级目录

10) 获取逻辑空间文件、目录大小（du）

hadoop fs - du /  #显示HDFS根目录中各文件和文件夹大小

hadoop fs -du -h /  #以最大单位显示HDFS根目录中各文件和文件夹大小

hadoop fs -du -s /  #仅显示HDFS根目录大小。即各文件和文件夹大小之和

</code></pre>

            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>