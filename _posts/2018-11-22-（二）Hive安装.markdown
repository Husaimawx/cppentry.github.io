---
layout:     post
title:      （二）Hive安装
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h1><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html" rel="nofollow" id="cb_post_title_url">（二）Hive安装</a></h1>

<p><a name="_labelTop"></a></p>

<p><strong>目录</strong></p>

<ul><li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label0" rel="nofollow">Hive的下载</a></li>
	<li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label1" rel="nofollow">Hive的安装</a>
	<ul><li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label1_0" rel="nofollow">1、本人使用MySQL做为Hive的元数据库，所以先安装MySQL。</a></li>
		<li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label1_1" rel="nofollow">2、上传Hive安装包</a></li>
		<li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label1_2" rel="nofollow">3、解压安装包</a></li>
		<li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label1_3" rel="nofollow">4、修改配置文件</a></li>
		<li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label1_4" rel="nofollow">5、 一定要记得加入 MySQL 驱动包（mysql-connector-java-5.1.40-bin.jar）该 jar 包放置在 hive 的根路径下的 lib 目录</a></li>
		<li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label1_5" rel="nofollow">6、 安装完成，配置环境变量</a></li>
		<li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label1_6" rel="nofollow">7、 验证 Hive 安装</a></li>
		<li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label1_7" rel="nofollow">8、 初始化元数据库</a></li>
		<li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label1_8" rel="nofollow">9、 启动 Hive 客户端</a></li>
	</ul></li>
	<li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label2" rel="nofollow">基本使用</a>
	<ul><li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label2_0" rel="nofollow">1、创建一个数据库myhive</a></li>
		<li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label2_1" rel="nofollow">2、使用新的数据库myhive</a></li>
		<li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label2_2" rel="nofollow">3、查看当前正在使用的数据库</a></li>
		<li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label2_3" rel="nofollow">4、在数据库myhive创建一张student表</a></li>
		<li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label2_4" rel="nofollow">5、往表中加载数据</a></li>
		<li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label2_5" rel="nofollow">6、查询数据</a></li>
		<li><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_label2_6" rel="nofollow">7、查看表结构</a></li>
	</ul></li>
</ul><p> </p>

<p><strong>正文</strong></p>

<p><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label0"></a></p>

<h2>Hive的下载</h2>

<p>下载地址<a href="http://mirrors.hust.edu.cn/apache/" rel="nofollow">http://mirrors.hust.edu.cn/apache/</a></p>

<p>选择合适的Hive版本进行下载，进到stable-2文件夹可以看到稳定的2.x的版本是2.3.3</p>

<p><img alt="" class="has" height="347" src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180403130724778-219253901.png" width="693"></p>

<p><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label1"></a></p>

<h2>Hive的安装</h2>

<p><a name="_label1_0"></a></p>

<h3>1、本人使用MySQL做为Hive的元数据库，所以先安装MySQL。</h3>

<p>MySql安装过程<a href="http://www.cnblogs.com/qingyunzong/p/8294876.html" rel="nofollow">http://www.cnblogs.com/qingyunzong/p/8294876.html</a></p>

<pre class="has">
<code>　ubuntu上安装mysql非常简单只需要几条命令就可以完成。

　　1. sudo apt-get install mysql-server
 
　　2. apt-get isntall mysql-client
 
　　3.  sudo apt-get install libmysqlclient-dev
 
　　安装过程中会提示设置密码什么的，注意设置了不要忘了，安装完成之后可以使用如下命令来检查是否安装成功：
 
　　sudo netstat -tap | grep mysql
 
　　通过上述命令检查之后，如果看到有mysql 的socket处于 listen 状态则表示安装成功。</code></pre>

<p>修改mysql的远程访问配置，主要是将bind-address = 127.0.0.1 改成0.0.0.0，特别注意这种安装条件下,mysql的配置文件在如下位置. </p>

<p><img alt="" class="has" height="124" src="https://img-blog.csdnimg.cn/20181028101416743.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NTcxNTU0,size_27,color_FFFFFF,t_70" width="600"> </p>

<p><a name="_label1_1"></a></p>

<h3>2、上传Hive安装包</h3>

<p><img alt="" class="has" src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180403132436680-660336254.png"></p>

<p><a name="_label1_2"></a></p>

<h3>3、解压安装包</h3>

<pre class="has">
<code>[hadoop@hadoop3 ~]$ tar -zxvf apache-hive-2.3.3-bin.tar.gz -C apps/</code></pre>

<p><a name="_label1_3"></a></p>

<h3>4、修改配置文件</h3>

<p>配置文件所在目录apache-hive-2.3.3-bin/conf</p>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<pre class="has">
<code>[hadoop@hadoop3 apps]$ cd apache-hive-2.3.3-bin/
[hadoop@hadoop3 apache-hive-2.3.3-bin]$ ls
bin  binary-package-licenses  conf  examples  hcatalog  jdbc  lib  LICENSE  NOTICE  RELEASE_NOTES.txt  scripts
[hadoop@hadoop3 apache-hive-2.3.3-bin]$ cd conf/
[hadoop@hadoop3 conf]$ ls
beeline-log4j2.properties.template    ivysettings.xml
hive-default.xml.template             llap-cli-log4j2.properties.template
hive-env.sh.template                  llap-daemon-log4j2.properties.template
hive-exec-log4j2.properties.template  parquet-logging.properties
hive-log4j2.properties.template
[hadoop@hadoop3 conf]$ pwd
/home/hadoop/apps/apache-hive-2.3.3-bin/conf
[hadoop@hadoop3 conf]$ </code></pre>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<p>新建hive-site.xml并添加以下内容</p>

<pre class="has">
<code>[hadoop@hadoop3 conf]$ touch hive-site.xml
[hadoop@hadoop3 conf]$ vi hive-site.xml </code></pre>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<pre class="has">
<code>&lt;configuration&gt;
        &lt;property&gt;
                &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
                &lt;value&gt;jdbc:mysql://hadoop1:3306/hivedb?createDatabaseIfNotExist=true&lt;/value&gt;
                &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;
                &lt;!-- 如果 mysql 和 hive 在同一个服务器节点，那么请更改 hadoop02 为 localhost --&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
                &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
                &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
                &lt;value&gt;root&lt;/value&gt;
                &lt;description&gt;username to use against metastore database&lt;/description&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
                &lt;value&gt;root&lt;/value&gt;
        &lt;description&gt;password to use against metastore database&lt;/description&gt;
        &lt;/property&gt;
&lt;/configuration&gt;</code></pre>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<p>以下可选配置，该配置信息用来指定 Hive 数据仓库的数据存储在 HDFS 上的目录</p>

<pre class="has">
<code>      &lt;property&gt;
                &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;
                &lt;value&gt;/hive/warehouse&lt;/value&gt;
                &lt;description&gt;hive default warehouse, if nessecory, change it&lt;/description&gt;
        &lt;/property&gt;    </code></pre>

<p><a name="_label1_4"></a></p>

<h3>5、 一定要记得加入 MySQL 驱动包（mysql-connector-java-5.1.40-bin.jar）该 jar 包放置在 hive 的根路径下的 lib 目录</h3>

<p> <img alt="" class="has" height="369" src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180403133935984-1544488446.png" width="775"></p>

<p><a name="_label1_5"></a></p>

<h3>6、 安装完成，配置环境变量</h3>

<pre class="has">
<code>[hadoop@hadoop3 lib]$ vi ~/.bashrc 
#Hive
export HIVE_HOME=/home/hadoop/apps/apache-hive-2.3.3-bin
export PATH=$PATH:$HIVE_HOME/bin</code></pre>

<p>使修改的配置文件立即生效</p>

<pre class="has">
<code>[hadoop@hadoop3 lib]$ source ~/.bashrc </code></pre>

<p><a name="_label1_6"></a></p>

<h3>7、 验证 Hive 安装</h3>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<pre class="has">
<code>[hadoop@hadoop3 ~]$ hive --help
Usage ./hive &lt;parameters&gt; --service serviceName &lt;service parameters&gt;
Service List: beeline cleardanglingscratchdir cli hbaseimport hbaseschematool help hiveburninclient hiveserver2 hplsql jar lineage llapdump llap llapstatus metastore metatool orcfiledump rcfilecat schemaTool version 
Parameters parsed:
  --auxpath : Auxiliary jars 
  --config : Hive configuration directory
  --service : Starts specific service/component. cli is default
Parameters used:
  HADOOP_HOME or HADOOP_PREFIX : Hadoop install directory
  HIVE_OPT : Hive options
For help on a particular service:
  ./hive --service serviceName --help
Debug help:  ./hive --debug --help
[hadoop@hadoop3 ~]$ </code></pre>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<p><img alt="" class="has" height="227" src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180403134314992-1941171163.png" width="726"></p>

<p><a name="_label1_7"></a></p>

<h3>8、 初始化元数据库</h3>

<p>　　注意：当使用的 hive 是 2.x 之前的版本，不做初始化也是 OK 的，当 hive 第一次启动的 时候会自动进行初始化，只不过会不会生成足够多的元数据库中的表。在使用过程中会 慢慢生成。但最后进行初始化。如果使用的 2.x 版本的 Hive，那么就必须手动初始化元 数据库。使用命令：</p>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<pre class="has">
<code>[hadoop@hadoop3 ~]$ schematool -dbType mysql -initSchema
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/hadoop/apps/apache-hive-2.3.3-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/hadoop/apps/hadoop-2.7.5/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Metastore connection URL:     jdbc:mysql://hadoop1:3306/hivedb?createDatabaseIfNotExist=true
Metastore Connection Driver :     com.mysql.jdbc.Driver
Metastore connection User:     root
Starting metastore schema initialization to 2.3.0
Initialization script hive-schema-2.3.0.mysql.sql
Initialization script completed
schemaTool completed
[hadoop@hadoop3 ~]$ </code></pre>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<p><img alt="" class="has" height="243" src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180403134541826-654934912.png" width="779"></p>

<p><a name="_label1_8"></a></p>

<h3>9、 启动 Hive 客户端</h3>

<p><strong>hive --service cli和hive效果一样</strong><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<pre class="has">
<code>
[hadoop@hadoop3 ~]$ hive --service cli
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/hadoop/apps/apache-hive-2.3.3-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/hadoop/apps/hadoop-2.7.5/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/home/hadoop/apps/apache-hive-2.3.3-bin/lib/hive-common-2.3.3.jar!/hive-log4j2.properties Async: true
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
hive&gt; </code></pre>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<p><img alt="" class="has" height="224" src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180403163639692-1199542716.png" width="711"></p>

<p><a href="https://www.cnblogs.com/qingyunzong/p/8708057.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label2"></a></p>

<h2>基本使用</h2>

<p>现有一个文件student.txt，将其存入hive中，student.txt数据格式如下：</p>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<pre class="has">
<code>95002,刘晨,女,19,IS
95017,王风娟,女,18,IS
95018,王一,女,19,IS
95013,冯伟,男,21,CS
95014,王小丽,女,19,CS
95019,邢小丽,女,19,IS
95020,赵钱,男,21,IS
95003,王敏,女,22,MA
95004,张立,男,19,IS
95012,孙花,女,20,CS
95010,孔小涛,男,19,CS
95005,刘刚,男,18,MA
95006,孙庆,男,23,CS
95007,易思玲,女,19,MA
95008,李娜,女,18,CS
95021,周二,男,17,MA
95022,郑明,男,20,MA
95001,李勇,男,20,CS
95011,包小柏,男,18,MA
95009,梦圆圆,女,18,MA
95015,王君,男,18,MA</code></pre>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<p> </p>

<p><a name="_label2_0"></a></p>

<h3>1、创建一个数据库myhive</h3>

<pre class="has">
<code>hive&gt; create database myhive;
OK
Time taken: 7.847 seconds
hive&gt; </code></pre>

<p><img alt="" class="has" src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180403173156107-1549458905.png"></p>

<p><a name="_label2_1"></a></p>

<h3>2、使用新的数据库myhive</h3>

<pre class="has">
<code>hive&gt; use myhive;
OK
Time taken: 0.047 seconds
hive&gt; </code></pre>

<p><img alt="" class="has" src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180403173305344-1780862637.png"></p>

<p><a name="_label2_2"></a></p>

<h3>3、查看当前正在使用的数据库</h3>

<pre class="has">
<code>hive&gt; select current_database();
OK
myhive
Time taken: 0.728 seconds, Fetched: 1 row(s)
hive&gt; </code></pre>

<p><img alt="" class="has" src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180403173425413-1583852832.png"></p>

<p><a name="_label2_3"></a></p>

<h3>4、在数据库myhive创建一张student表</h3>

<pre class="has">
<code>hive&gt; create table student(id int, name string, sex string, age int, department string) row format delimited fields terminated by ",";
OK
Time taken: 0.718 seconds
hive&gt; </code></pre>

<p><img alt="" class="has" height="97" src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180403181521923-461375650.png" width="903"></p>

<p><a name="_label2_4"></a></p>

<h3>5、往表中加载数据</h3>

<pre class="has">
<code>hive&gt; load data local inpath "/home/hadoop/student.txt" into table student;
Loading data to table myhive.student
OK
Time taken: 1.854 seconds
hive&gt; </code></pre>

<p><img alt="" class="has" src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180403181841534-1261507478.png"></p>

<p><a name="_label2_5"></a></p>

<h3>6、查询数据</h3>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<pre class="has">
<code>hive&gt; select * from student;
OK
95002    刘晨    女    19    IS
95017    王风娟    女    18    IS
95018    王一    女    19    IS
95013    冯伟    男    21    CS
95014    王小丽    女    19    CS
95019    邢小丽    女    19    IS
95020    赵钱    男    21    IS
95003    王敏    女    22    MA
95004    张立    男    19    IS
95012    孙花    女    20    CS
95010    孔小涛    男    19    CS
95005    刘刚    男    18    MA
95006    孙庆    男    23    CS
95007    易思玲    女    19    MA
95008    李娜    女    18    CS
95021    周二    男    17    MA
95022    郑明    男    20    MA
95001    李勇    男    20    CS
95011    包小柏    男    18    MA
95009    梦圆圆    女    18    MA
95015    王君    男    18    MA
Time taken: 2.455 seconds, Fetched: 21 row(s)
hive&gt; </code></pre>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<p><img alt="" class="has" src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180403182000435-2086698927.png"></p>

<p><a name="_label2_6"></a></p>

<h3>7、查看表结构</h3>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<pre class="has">
<code>hive&gt; desc student;
OK
id                      int                                         
name                    string                                      
sex                     string                                      
age                     int                                         
department              string                                      
Time taken: 0.102 seconds, Fetched: 5 row(s)
hive&gt; </code></pre>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<p> </p>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<pre class="has">
<code>hive&gt; desc extended student;
OK
id                      int                                         
name                    string                                      
sex                     string                                      
age                     int                                         
department              string                                      
          
Detailed Table Information    Table(tableName:student, dbName:myhive, owner:hadoop, createTime:1522750487, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:sex, type:string, comment:null), FieldSchema(name:age, type:int, comment:null), FieldSchema(name:department, type:string, comment:null)], location:hdfs://myha01/user/hive/warehouse/myhive.db/student, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=,, field.delim=,}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{transient_lastDdlTime=1522750695, totalSize=523, numRows=0, rawDataSize=0, numFiles=1}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)    
Time taken: 0.127 seconds, Fetched: 7 row(s)
hive&gt; </code></pre>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<p> </p>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>

<pre class="has">
<code>hive&gt; desc formatted student;
OK
# col_name                data_type               comment             
          
id                      int                                         
name                    string                                      
sex                     string                                      
age                     int                                         
department              string                                      
          
# Detailed Table Information          
Database:               myhive                   
Owner:                  hadoop                   
CreateTime:             Tue Apr 03 18:14:47 CST 2018     
LastAccessTime:         UNKNOWN                  
Retention:              0                        
Location:               hdfs://myha01/user/hive/warehouse/myhive.db/student     
Table Type:             MANAGED_TABLE            
Table Parameters:          
    numFiles                1                   
    numRows                 0                   
    rawDataSize             0                   
    totalSize               523                 
    transient_lastDdlTime    1522750695          
          
# Storage Information          
SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe     
InputFormat:            org.apache.hadoop.mapred.TextInputFormat     
OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat     
Compressed:             No                       
Num Buckets:            -1                       
Bucket Columns:         []                       
Sort Columns:           []                       
Storage Desc Params:          
    field.delim             ,                   
    serialization.format    ,                   
Time taken: 0.13 seconds, Fetched: 34 row(s)
hive&gt; </code></pre>

<p><a><img alt="复制代码" class="has" src="https://common.cnblogs.com/images/copycode.gif"></a></p>            </div>
                </div>