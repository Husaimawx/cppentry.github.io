---
layout:     post
title:      Hadoop集群搭建常用命令、目录及注意
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>目录：（1）/usr/local/hadoop/（2）hadoop配置目录：/usr/local/hadoop/etc/hadoop（3）/usr/local/hadoop/sbin（4）share目录在/usr/local/hadoop下（5）将HDFS所有文件副本数调整为2，数据块大小为512MB：在/usr/local/hadoop/etc/hadoop/hdfs-site.xml文件中修改（6）将指定HDFS上某个文件（比如/home/hadoop/test.txt）的副本数调整成2：hadoop dfs -setrep -w 2 -R /home/hadoop/test.txt</p>

<p>命令：（1）①重新编译环境变量使配置生效，source /etc/profile</p>

<p>②开启namenode：hadoop-daemon.sh start namenode 关闭namenode：hadoop-daemon.sh stop namenode</p>

<p>③开启datanode：hadoop-daemon.sh start datanode 关闭datanode：hadoop-daemon.sh stop datanode</p>

<p>④开启hdfs：start-dfs.sh 关闭hdfs：stop-dfs.sh</p>

<p>⑤开启yarn：start-yarn.sh 关闭yarn：stop-yarn.sh</p>

<p>（2）hadoop完全分布式 HA高可用搭建过程：</p>

<p>1、使用hadoop用户解压并安装到apps路径下<br>
1.1使用hadoop用户进入到在/home/hadoop/apps目录下<br>
cd /home/hadoop/apps</p>

<p>注意：如果没有/home/hadoop/apps路径，自行在/home/hadoop路径下创建apps文件夹：mkdir /home/Hadoop/apps<br>
1.2使用rz将本机的hadoop安装包上传到/home/hadoop/apps目录下<br>
1.3解压安装文件<br>
tar -zxvf hadoop-2.7.4.tar.gz<br>
1.4使用root用户创建软链接<br>
ln -s /home/hadoop/apps/hadoop-2.7.4 /usr/local/hadoop<br>
1.5使用root用户修改软链接属主<br>
chown -R hadoop:hadoop /usr/local/hadoop</p>

<p><br>
1.6使用root用户将hadoop相关内容添加到环境变量中<br>
注意：Hadoop配置文件路径是/usr/local/hadoop/etc/hadoop<br>
vim /etc/profile<br>
添加内容如下：<br>
export HADOOP_HOME=/usr/local/hadoop<br>
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop<br>
export YARN_HOME=$HADOOP_HOME<br>
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop<br>
export PATH=$PATH:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin<br>
1.7使用root用户重新编译环境变量使配置生效<br>
source /etc/profile</p>

<p>2. 配置HDFS<br>
2.1使用hadoop用户进入到Hadoop配置文件路径<br>
     cd /usr/local/hadoop/etc/hadoop<br>
2.2修改hadoop-env.sh<br>
修改JDK路径export JAVA_HOME=/usr/local/jdk<br>
2.3 配置core-site.xml（<span style="color:#f33b45;">具体配置文件在最下面</span>）<br>
2.4 配置hdfs-site.xml</p>

<p>3. 配置YARN<br>
3.1 修改yarn-site.xml<br>
3.2 修改mapred-site.xml<strong>（在配置mapred-site.xml时，千万注意文件名字一定是mapred-site.xml，不是mapred-site.xml.template，要用命令：cp mapred-site.xml.template mapred-site.xml复制一份然后在配置）</strong><br>
3.3 在/usr/local/hadoop路径下创建hdpdata文件夹<br>
cd /usr/local/hadoop<br>
mkdir hdpdata</p>

<p>4. 修改slaves文件，设置datanode和nodemanager启动节点主机名称<br>
在slaves文件中添加节点的主机名称<br>
node03<br>
node04<br>
node05</p>

<p>注意：node03，node04，node05是我的虚拟机主机名称，在这三台机器上启动datanode和nodemanager，同学根据自己集群主机名称情况自行修改。</p>

<p>5. 配置hadoop用户免密码登陆<br>
配置node01到node01、node02、node03、node04、node05的免密码登陆<br>
在node01上生产一对钥匙<br>
ssh-keygen -t rsa<br>
将公钥拷贝到其他节点，包括自己本机<br>
ssh-copy-id -i node01<br>
ssh-copy-id -i node02<br>
ssh-copy-id -i node03<br>
ssh-copy-id -i node04<br>
ssh-copy-id -i node05</p>

<p>配置node02到node01、node02、node03、node04、node05的免密码登陆<br>
在node02上生产一对钥匙<br>
ssh-keygen -t rsa<br>
将公钥拷贝到其他节点，包括自己本机<br>
ssh-copy-id -i node01<br>
ssh-copy-id -i node02<br>
ssh-copy-id -i node03<br>
ssh-copy-id -i node04<br>
ssh-copy-id -i node05<br>
注意：两个namenode之间要配置ssh免密码登陆</p>

<p>6. 将配置好的hadoop拷贝到其他节点<br>
scp -r hadoop-2.7.4 hadoop@node02:/home/hadoop/apps<br>
scp -r hadoop-2.7.4 hadoop@node03:/home/hadoop/apps<br>
scp -r hadoop-2.7.4 hadoop@node04:/home/hadoop/apps<br>
scp -r hadoop-2.7.4 hadoop@node05:/home/hadoop/apps</p>

<p>在每个节点分别执行如下四步操作<br>
第一步：使用root用户创建软链接<br>
ln -s /home/hadoop/apps/hadoop-2.7.4 /usr/local/hadoop<br>
第二步：使用root用户修改软链接属主<br>
chown -R hadoop:hadoop /usr/local/hadoop<br>
第三步：使用root用户添加环境变量<br>
vim /etc/profile<br>
添加内容：<br>
export HADOOP_HOME=/usr/local/hadoop<br>
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop<br>
export YARN_HOME=$HADOOP_HOME<br>
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop</p>

<p>export PATH=$PATH:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin<br>
第四步：使用root用户重新编译环境变量使配置生效<br>
source /etc/profile</p>

<p>（3）集群规划</p>

<p><img alt="" class="has" height="318" src="https://img-blog.csdn.net/20180718110731473?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3MzkyNTg5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="439"><img alt="" class="has" height="321" src="https://img-blog.csdn.net/20180718110850443?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3MzkyNTg5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="463"></p>

<p>（4）启动hadoop集群命令(<strong>注意使用hadoop用户启动，严格按照顺序启动</strong>)：</p>

<p>①启动journalnode，在node03，node04，node05机器上，输入/usr/local/hadoop/sbin/hadoop-daemon.sh start journalnode 然后输入jps命令检验多了journalnode进程</p>

<p>②格式化HDFS，在node01上执行命令：hdfs namenode -format，格式化成功之后会在core-site.xml中的hadoop.tmp.dir制定的路径下生成dfs文件夹，将该文件夹拷贝到node02的相同路径下，scp -r hdpdata hadoop@node02:/usr/local/hadoop</p>

<p>③在node01上执行格式化ZKFC操作：hdfs zkfc -formatZK，执行成功后，日志输出如下信息：INFO ha.ActiveStandbyElector: Successfully created /hadoop-ha/ns in ZK</p>

<p>④在node01上启动HDFS：sbin/start-dfs.sh</p>

<p>⑤在node02上启动YARN:sbin/start-yarn.sh，在node01单独启动一个ResourceManager作为备份节点ResourceManager（Standby）：sbin/yarn-daemon.sh start resourcemanager</p>

<p>⑥在node02上启动JobHistoryServer：sbin/mr-jobhistory-daemon.sh start historyserver，启动完成node02会增加一个JobHistoryServer进程</p>

<p>⑦hadoop安装启动完成</p>

<p>HDFS HTTP访问地址：</p>

<p>NameNode (active)：http://192.168.183.100:50070<br>
NameNode (standby)：http://192.168.183.101:50070</p>

<p>ResourceManager HTTP访问地址：</p>

<p>ResourceManager ：http://192.168.183.101:8088</p>

<p>历史日志HTTP访问地址：</p>

<p>JobHistoryServer：http://192.168.183.101:19888</p>

<p>（5）集群验证</p>

<p>①验证HDFS是否正常工作及HA高可用</p>

<p>首先向hdfs上传一个文件：hadoop fs -put /usr/local/hadoop/README.txt /</p>

<p>在active节点手动关闭active的namenode：sbin/hadoop-daemon.sh stop namenode</p>

<p>通过HTTP 50070端口查看standby namenode的状态是否转换为active，手动启动上一步关闭的namenode：sbin/hadoop-daemon.sh start namenode</p>

<p>②验证YARN是否正常工作及ResourceManager HA高可用</p>

<p>运行测试hadoop提供的demo中的WordCount程序：</p>

<p>hadoop fs -mkdir /wordcount</p>

<p>hadoop fs -mkdir /wordcount/input</p>

<p>hadoop fs -mv /README.txt /wordcount/input</p>

<p>hadoop jar share/hadoop/mapreduce/hadoop-mapreduce/hadoop-mapreduce-examples-2.7.4.jar wordcount /wordcount/input /wordcount/output。share目录在/usr/local/hadoop下</p>

<p>验证ResourceManager HA</p>

<p>手动关闭node02的ResourceManager：sbin/hadoop-daemon.sh stop resourcemanager</p>

<p>通过HTTP 8088端口访问node01的ResourceManager查看状态</p>

<p>手动启动node02的ResourceManager:sbin/yarn-daemon.sh start resourcemanager</p>

<p> </p>

<p>配置文件（1）core-site.xml</p>

<p>&lt;?xml version="1.0" encoding="UTF-8"?&gt;<br>
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;<br>
&lt;!--<br>
  Licensed under the Apache License, Version 2.0 (the "License");<br>
  you may not use this file except in compliance with the License.<br>
  You may obtain a copy of the License at</p>

<p>    http://www.apache.org/licenses/LICENSE-2.0</p>

<p>  Unless required by applicable law or agreed to in writing, software<br>
  distributed under the License is distributed on an "AS IS" BASIS,<br>
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br>
  See the License for the specific language governing permissions and<br>
  limitations under the License. See accompanying LICENSE file.<br>
--&gt;</p>

<p>&lt;!-- Put site-specific property overrides in this file. --&gt;</p>

<p>&lt;configuration&gt;<br>
    &lt;!-- 指定hdfs的nameservice名称空间为ns --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;fs.defaultFS&lt;/name&gt;<br>
        &lt;value&gt;hdfs://ns&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 指定hadoop临时目录,默认在/tmp/{$user}目录下，不安全，每次开机都会被清空--&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;<br>
        &lt;value&gt;/usr/local/hadoop/hdpdata/&lt;/value&gt;<br>
        &lt;description&gt;需要手动创建hdpdata目录&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 指定zookeeper地址 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;<br>
        &lt;value&gt;node01:2181,node02:2181,node03:2181&lt;/value&gt;<br>
        &lt;description&gt;zookeeper地址，多个用逗号隔开&lt;/description&gt;<br>
    &lt;/property&gt;<br>
&lt;/configuration&gt;</p>

<p> </p>

<p>（2）hdfs-site.xml</p>

<p>&lt;?xml version="1.0" encoding="UTF-8"?&gt;<br>
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;<br>
&lt;!--<br>
  Licensed under the Apache License, Version 2.0 (the "License");<br>
  you may not use this file except in compliance with the License.<br>
  You may obtain a copy of the License at</p>

<p>    http://www.apache.org/licenses/LICENSE-2.0</p>

<p>  Unless required by applicable law or agreed to in writing, software<br>
  distributed under the License is distributed on an "AS IS" BASIS,<br>
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br>
  See the License for the specific language governing permissions and<br>
  limitations under the License. See accompanying LICENSE file.<br>
--&gt;</p>

<p>&lt;!-- Put site-specific property overrides in this file. --&gt;</p>

<p>&lt;configuration&gt;<br>
    &lt;!-- NameNode HA配置 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.nameservices&lt;/name&gt;<br>
        &lt;value&gt;ns&lt;/value&gt;<br>
        &lt;description&gt;指定hdfs的nameservice为ns，需要和core-site.xml中的保持一致&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.ha.namenodes.ns&lt;/name&gt;<br>
        &lt;value&gt;nn1,nn2&lt;/value&gt;<br>
        &lt;description&gt;ns命名空间下有两个NameNode，逻辑代号，随便起名字，分别是nn1，nn2&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.namenode.rpc-address.ns.nn1&lt;/name&gt;<br>
        &lt;value&gt;node01:9000&lt;/value&gt;<br>
        &lt;description&gt;nn1的RPC通信地址&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.namenode.http-address.ns.nn1&lt;/name&gt;<br>
        &lt;value&gt;node01:50070&lt;/value&gt;<br>
        &lt;description&gt;nn1的http通信地址&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.namenode.rpc-address.ns.nn2&lt;/name&gt;<br>
        &lt;value&gt;node02:9000&lt;/value&gt;<br>
        &lt;description&gt;nn2的RPC通信地址&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.namenode.http-address.ns.nn2&lt;/name&gt;<br>
        &lt;value&gt;node02:50070&lt;/value&gt;<br>
        &lt;description&gt;nn2的http通信地址&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;!--JournalNode配置 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;<br>
        &lt;value&gt;qjournal://node03:8485;node04:8485;node05:8485/ns&lt;/value&gt;<br>
        &lt;description&gt;指定NameNode的edits元数据在JournalNode上的存放位置&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;<br>
        &lt;value&gt;/usr/local/hadoop/journaldata&lt;/value&gt;<br>
        &lt;description&gt;指定JournalNode在本地磁盘存放数据的位置&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;!--namenode高可用主备切换配置 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;<br>
        &lt;value&gt;true&lt;/value&gt;<br>
        &lt;description&gt;开启NameNode失败自动切换&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.client.failover.proxy.provider.ns&lt;/name&gt;<br>
        &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;<br>
        &lt;description&gt;配置失败自动切换实现方式,使用内置的zkfc&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;<br>
        &lt;value&gt;<br>
            sshfence<br>
            shell(/bin/true)<br>
        &lt;/value&gt;<br>
        &lt;description&gt;配置隔离机制，多个机制用换行分割，先执行sshfence，执行失败后执行shell(/bin/true)，/bin/true会直接返回0表示成功&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;<br>
        &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;<br>
        &lt;description&gt;使用sshfence隔离机制时需要ssh免登陆&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;<br>
        &lt;value&gt;30000&lt;/value&gt;<br>
        &lt;description&gt;配置sshfence隔离机制超时时间&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;!--dfs文件属性设置--&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.replication&lt;/name&gt;<br>
        &lt;value&gt;3&lt;/value&gt;<br>
        &lt;description&gt;设置block副本数为3&lt;/description&gt;<br>
    &lt;/property&gt;</p>

<p>    &lt;property&gt;<br>
        &lt;name&gt;dfs.block.size&lt;/name&gt;<br>
        &lt;value&gt;134217728&lt;/value&gt;<br>
        &lt;description&gt;设置block大小是128M&lt;/description&gt;<br>
    &lt;/property&gt;<br>
&lt;/configuration&gt;</p>

<p> </p>

<p>（3）mapred-site.xml</p>

<p>&lt;?xml version="1.0"?&gt;<br>
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;<br>
&lt;!--<br>
  Licensed under the Apache License, Version 2.0 (the "License");<br>
  you may not use this file except in compliance with the License.<br>
  You may obtain a copy of the License at</p>

<p>    http://www.apache.org/licenses/LICENSE-2.0</p>

<p>  Unless required by applicable law or agreed to in writing, software<br>
  distributed under the License is distributed on an "AS IS" BASIS,<br>
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br>
  See the License for the specific language governing permissions and<br>
  limitations under the License. See accompanying LICENSE file.<br>
--&gt;</p>

<p>&lt;!-- Put site-specific property overrides in this file. --&gt;</p>

<p>&lt;configuration&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;<br>
        &lt;value&gt;yarn&lt;/value&gt;<br>
        &lt;description&gt;指定mr框架为yarn方式 &lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 历史日志服务jobhistory相关配置 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;<br>
        &lt;value&gt;node02:10020&lt;/value&gt;<br>
        &lt;description&gt;历史服务器端口号&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;<br>
        &lt;value&gt;node02:19888&lt;/value&gt;<br>
        &lt;description&gt;历史服务器的WEB UI端口号&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;mapreduce.jobhistory.joblist.cache.size&lt;/name&gt;<br>
        &lt;value&gt;2000&lt;/value&gt;<br>
        &lt;description&gt;内存中缓存的historyfile文件信息(主要是job对应的文件目录)&lt;/description&gt;<br>
    &lt;/property&gt;<br>
&lt;/configuration&gt;</p>

<p><br>
（4）yarn-site.xml</p>

<p>&lt;?xml version="1.0"?&gt;<br>
&lt;!--<br>
  Licensed under the Apache License, Version 2.0 (the "License");<br>
  you may not use this file except in compliance with the License.<br>
  You may obtain a copy of the License at</p>

<p>    http://www.apache.org/licenses/LICENSE-2.0</p>

<p>  Unless required by applicable law or agreed to in writing, software<br>
  distributed under the License is distributed on an "AS IS" BASIS,<br>
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br>
  See the License for the specific language governing permissions and<br>
  limitations under the License. See accompanying LICENSE file.<br>
--&gt;<br>
&lt;configuration&gt;<br>
    &lt;!-- 开启RM高可用 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;<br>
        &lt;value&gt;true&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 指定RM的cluster id，一组高可用的rm共同的逻辑id --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;<br>
        &lt;value&gt;yarn-ha&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 指定RM的名字，可以随便自定义 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;<br>
        &lt;value&gt;rm1,rm2&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 分别指定RM的地址 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;<br>
        &lt;value&gt;node01&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.resourcemanager.webapp.address.rm1&lt;/name&gt;<br>
        &lt;value&gt;${yarn.resourcemanager.hostname.rm1}:8088&lt;/value&gt;<br>
        &lt;description&gt;HTTP访问的端口号&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;<br>
        &lt;value&gt;node02&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.resourcemanager.webapp.address.rm2&lt;/name&gt;<br>
        &lt;value&gt;${yarn.resourcemanager.hostname.rm2}:8088&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 指定zookeeper集群地址 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;<br>
        &lt;value&gt;node01:2181,node02:2181,node03:2181&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!--NodeManager上运行的附属服务，需配置成mapreduce_shuffle，才可运行MapReduce程序--&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;<br>
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 开启日志聚合 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;<br>
        &lt;value&gt;true&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 日志聚合HDFS目录 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;<br>
        &lt;value&gt;/data/hadoop/yarn-logs&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 日志保存时间3days,单位秒 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;<br>
        &lt;value&gt;259200&lt;/value&gt;<br>
    &lt;/property&gt;<br>
&lt;/configuration&gt;</p>            </div>
                </div>