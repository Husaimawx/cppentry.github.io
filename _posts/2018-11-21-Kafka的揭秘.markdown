---
layout:     post
title:      Kafka的揭秘
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/qq_27232757/article/details/78951495				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h1 style="text-align:left;"><span style="font-size:32px;">目录</span></h1><h2></h2><div style="text-align:left;"><span style="font-size:18px;">01  Kafka的创建背景及其定义</span></div><div style="text-align:left;"><span style="font-size:18px;">02  Kafka的架构</span></div><div style="text-align:left;"><span style="font-size:18px;">03  Kafka数据的可靠性</span></div><div style="text-align:left;"><span style="font-size:18px;">04  Kafka消息传输保障</span></div><div style="text-align:left;"><span style="font-size:18px;">05  Kafka的并发性</span></div><div style="text-align:left;"><span style="font-size:18px;">06  Kafka在Zookeeper中的存储结构</span></div><div style="text-align:left;"><span style="font-size:18px;">07  Kafka的高可用性和高效性</span></div><div><h2><span style="color:#009900;">01  Kafka的创建背景及其定义</span></h2><div><span style="font-size:18px;">一、Kafka的创建背景<br>Kafka是一个消息系统，原本开发自LinkedIn，用作LinkedIn的活动流（Activity Stream）和运营数据处理管道（Pipeline）的基础。现在它已被多家不同类型的公司 作为多种类型的数据管道和消息系统使用。Kafka作为时下最流行的开源消息系统，被广泛地应用在数据缓冲、异步通信、汇集日志、系统解耦等方面.<br><br>二、Kafka的定义<br>Kafka是由Scala编写，运行在JVM上面。<br>以前官网上面给Kafka的定义是：A distributed publish-subscribe messaging system(一个分布式发布-订阅消息传递系统)，现在官网上面给出的Kafka的定义是：Apache Kafka is a distributed streaming platform(ApacheKafka是一个分布式流媒体平台)。</span><br></div><div><span style="font-size:18px;"><br></span></div><div><span style="font-size:18px;">三、现阶段主流的消息队列的对比</span></div><div><span style="font-size:18px;"></span><table border="0" cellpadding="0" cellspacing="0" width="748"><tbody><tr><td class="kso0" style="width:101pt;" width="135"><p><span style="font-size:12pt;"><strong>消息队列的类型</strong></span></p></td><td class="kso1" style="width:460pt;" width="613"><p><span style="font-size:12pt;"><strong>优缺点</strong></span></p></td></tr><tr><td class="kso2" style="width:101pt;" width="135"><p><span style="font-size:12pt;">RabbitMQ</span></p></td><td class="kso3" style="width:460pt;" width="613"><p><span style="font-size:12pt;color:#ff0000;">Erlang</span><span style="font-size:12pt;">编写的一个开源的消息队列，本身支持多种协议，使的它变的非常</span><span style="font-size:12pt;color:#ff0000;">重量级</span><span style="font-size:12pt;">，更适合于企业级的开发。对</span><span style="font-size:12pt;color:#ff0000;">路由</span><span style="font-size:12pt;">(Routing)，</span><span style="font-size:12pt;color:#ff0000;">负载均衡</span><span style="font-size:12pt;">(Load balance)或者</span><span style="font-size:12pt;color:#ff0000;">数据持久化</span><span style="font-size:12pt;">都有很好的支持</span></p></td></tr><tr><td class="kso4" style="width:101pt;" width="135"><p><span style="font-size:12pt;">ZeroMQ</span></p></td><td class="kso5" style="width:460pt;" width="613"><p><span style="font-size:12pt;">号称</span><span style="font-size:12pt;color:#ff0000;">最快</span><span style="font-size:12pt;">的消息队列系统，尤其针对大吞吐量的需求场景。ZeroMQ具有一个独特的非中间件的模式，你</span><span style="font-size:12pt;color:#ff0000;">不需要安装和运行一个消息服务器或中间件</span><span style="font-size:12pt;">，因为你的应用程序将扮演了这个服务角色。没有</span><span style="font-size:12pt;color:#ff0000;">持久化</span><span style="font-size:12pt;">功能。</span></p></td></tr><tr><td class="kso6" style="width:101pt;" width="135"><p><span style="font-size:12pt;">ActiveMQ</span></p></td><td class="kso7" style="width:460pt;" width="613"><p><span style="font-size:12pt;">对于</span><span style="font-size:12pt;">Spring</span><span style="font-size:12pt;">和</span><span style="font-size:12pt;">Ajax</span><span style="font-size:12pt;">的支持，支持通过</span><span style="font-size:12pt;">JDBC</span><span style="font-size:12pt;">提供高速的消息持久化</span></p></td></tr><tr><td class="kso8" style="width:101pt;" width="135"><p><span style="font-size:12pt;">Kafka</span></p></td><td class="kso9" style="width:460pt;" width="613"><p><span style="font-size:12pt;">以时间复杂度为</span><span style="font-size:12pt;color:#ff0000;">O(1)</span><span style="font-size:12pt;">的方式提供消息持久化能力，并保证即使对TB级以上数据也能保证常数时间的访问性能；即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输；支持Kafka Server间的消息分区，及分布式消息消费，同时保证每个partition内的</span><span style="font-size:12pt;color:#ff0000;">消息顺序传输</span><span style="font-size:12pt;">；支持</span><span style="font-size:12pt;color:#ff0000;">离线</span><span style="font-size:12pt;">数据处理和</span><span style="font-size:12pt;color:#ff0000;">实时</span><span style="font-size:12pt;">数据处理</span></p></td></tr><tr><td class="kso10" style="width:101pt;" width="135"><p><span style="font-size:12pt;">Redis</span></p></td><td class="kso11" style="width:460pt;" width="613"><p><span style="font-size:12pt;">数据小于</span><span style="font-size:12pt;">10K</span><span style="font-size:12pt;">时，</span><span style="font-size:12pt;">Redis</span><span style="font-size:12pt;">的</span><span style="font-size:12pt;color:#ff0000;">入队</span><span style="font-size:12pt;">的性能要高于</span><span style="font-size:12pt;">RabbitMQ，</span><span style="font-size:12pt;">Redis</span><span style="font-size:12pt;">在</span><span style="font-size:12pt;color:#ff0000;">出队</span><span style="font-size:12pt;">时表现出非常好的性能，无关数据的大小。</span></p></td></tr></tbody></table><br></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="color:#009900;">02  Kafka的架构</span></strong></span><br></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><br></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong>首先看一下比较常见的名词是什么意思</strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><br></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong></strong></span></span><table border="0" cellpadding="0" cellspacing="0" style="width:503pt;" width="671"><tbody><tr><td class="kso0" style="width:86pt;" width="115"><p><span style="font-size:18pt;"><strong>名称</strong></span></p></td><td class="kso1" style="width:417pt;" width="556"><p><span style="font-size:18pt;"><strong>解释</strong></span></p></td></tr><tr><td class="kso2" style="width:86pt;" width="115"><p><span style="font-size:14pt;">Broker</span></p></td><td class="kso3" style="width:417pt;" width="556"><p><span style="font-size:14pt;">消息中间件处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个Kafka集群</span></p></td></tr><tr><td class="kso4" style="width:86pt;" width="115"><p><span style="font-size:14pt;">Topic</span></p></td><td class="kso5" style="width:417pt;" width="556"><p><span style="font-size:14pt;">Kafka根据topic对消息进行归类，发布到Kafka集群的每条消息都需要指定一个topic</span></p></td></tr><tr><td class="kso6" style="width:86pt;" width="115"><p><span style="font-size:14pt;">Producer</span></p></td><td class="kso7" style="width:417pt;" width="556"><p><span style="font-size:14pt;">消息生产者，向Broker发送消息的客户端</span></p></td></tr><tr><td class="kso8" style="width:86pt;" width="115"><p><span style="font-size:14pt;">Consumer</span></p></td><td class="kso9" style="width:417pt;" width="556"><p><span style="font-size:14pt;">消息消费者，从Broker读取消息的客户端</span></p></td></tr><tr><td class="kso10" style="width:86pt;" width="115"><p><span style="font-size:14pt;">ConsumerGroup</span></p></td><td class="kso11" style="width:417pt;" width="556"><p><span style="font-size:14pt;">每个Consumer属于一个特定的Consumer Group，一条消息可以发送到多个不同的Consumer Group，但是一个Consumer Group中只能有一个Consumer能够消费该消息</span></p></td></tr><tr><td class="kso12" style="width:86pt;" width="115"><p><span style="font-size:14pt;">Partition</span></p></td><td class="kso13" style="width:417pt;" width="556"><p><span style="font-size:14pt;">物理上的概念，一个topic可以分为多个partition，每个partition内部是有序的</span></p></td></tr></tbody></table><br><img src="https://img-blog.csdn.net/20180102143359268" alt=""><br></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><span style="color:#009900;"><br></span></strong></span></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><span style="color:#009900;">03  Kafka数据的可靠性</span></strong></span><br></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><br></strong></span></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong>一、数据的存储结构</strong></span></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><br></strong></span></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong>数据存储结构的图片（手绘，不好看见谅）</strong></span></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><br></strong></span></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><br></strong></span></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><br></strong></span></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong>上图显示的是整个Kafka集群中数据的存储格式，下面介绍一下每条Message在文件中存储的结构</strong></span></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><br></strong></span></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong></strong></span></strong></span></span><table border="0" cellpadding="0" cellspacing="0" style="width:399pt;" width="532"><tbody><tr><td class="kso0" style="width:117pt;" width="156"><p><span style="font-size:14pt;"><strong>关键字</strong></span></p></td><td class="kso1" style="width:282pt;" width="376"><p><span style="font-size:14pt;"><strong>解释说明</strong></span></p></td></tr><tr><td class="kso2" style="width:117pt;" width="156"><p><span style="font-size:12pt;">offset</span></p></td><td class="kso3" style="width:282pt;" width="376"><p><span style="font-size:12pt;">在parition(分区)内的每条消息都有一个有序的id号，这个id号被称为偏移(offset),它可以唯一确定每条消息在parition(分区)内的位置。即offset表示partiion的第多少message</span></p></td></tr><tr><td class="kso4" style="width:117pt;" width="156"><p><span style="font-size:12pt;">message size</span></p></td><td class="kso5" style="width:282pt;" width="376"><p><span style="font-size:12pt;">message大小</span></p></td></tr><tr><td class="kso6" style="width:117pt;" width="156"><p><span style="font-size:12pt;">CRC32</span></p></td><td class="kso7" style="width:282pt;" width="376"><p><span style="font-size:12pt;">用crc32校验message</span></p></td></tr><tr><td class="kso8" style="width:117pt;" width="156"><p><span style="font-size:12pt;">magic</span></p></td><td class="kso9" style="width:282pt;" width="376"><p><span style="font-size:12pt;">表示本次发布Kafka服务程序协议版本号</span></p></td></tr><tr><td class="kso10" style="width:117pt;" width="156"><p><span style="font-size:12pt;">attributes</span></p></td><td class="kso11" style="width:282pt;" width="376"><p><span style="font-size:12pt;">表示为独立版本、或标识压缩类型、或编码类型。</span></p></td></tr><tr><td class="kso12" style="width:117pt;" width="156"><p><span style="font-size:12pt;">key length</span></p></td><td class="kso13" style="width:282pt;" width="376"><p><span style="font-size:12pt;">表示key的长度,当key为-1时，K byte key字段不填</span></p></td></tr><tr><td class="kso14" style="width:117pt;" width="156"><p><span style="font-size:12pt;">key</span></p></td><td class="kso15" style="width:282pt;" width="376"><p><span style="font-size:12pt;">可选</span></p></td></tr><tr><td class="kso16" style="width:117pt;" width="156"><p><span style="font-size:12pt;">payload<br></span></p><p><span style="font-size:12pt;"><br></span></p></td><td class="kso17" style="width:282pt;" width="376"><p><span style="font-size:12pt;">表示实际消息数据。</span></p></td></tr></tbody></table><br></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong>下面举个例子看一看Kafka是如何根据对应的offset找到对应的消息的：<br>假如我们要找offset是170418的消息（在数据存储结构图片的基础上面看更清晰一点），首先找到170410.index的文件发现offset比他大但是小于下一个index文件的文件名，所以该offset就在此index文件对应的log文件中，紧接着在index文件中查找第8（170418-170410）条信息对应的指针位置，根据该位置到对应的log文件中就可以查询到Message170418。</strong></span></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><br></strong></span></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong>二、Kafka副本的数据同步和复制</strong></span></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><br></strong></span></strong></span></span></div><div><span style="font-size:18px;"><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong>Kafka为了提高消息的可靠性，Kafka每个topic的partition有N个副本（replicas），其中N(大于等于1)是topic的复制因子（replica fator）的个数。Kafka通过多副本机制实现故障自动转移，当Kafka集群中一个broker失效情况下仍然保证服务可用。在Kafka中发生复制时确保partition的日志能有序地写到其他节点上，N个replicas中，其中一个replica为leader，其他都为follower, leader处理partition的所有读写请求，与此同时，follower会被动定期地去复制leader上的数据。<br></strong></span></strong></span></span></div><div><br></div><div><span style="font-size:18px;"><strong>Kafka确保从同步副本列表中选举一个副本为leader，或者说follower追赶leader数据。leader负责维护和跟踪ISR(In-Sync Replicas的缩写，表示副本同步队列，具体可参考下节)中所有follower滞后的状态。当producer发送一条消息到broker后，leader写入消息并复制到所有follower。消息提交之后才被成功复制到所有的同步副本。消息复制延迟受最慢的follower限制，重要的是快速检测慢副本，如果follower“落后”太多或者失效，leader将会把它从ISR中删除。<br><br><span style="color:#ff0000;">AR</span>(Assigned Replicas) : 所有的副本。 AR=ISR+OSR。<br><span style="color:#ff0000;">ISR</span>(In-Sync Replicas) : 副本同步队列。<br><span style="color:#ff0000;">OSR</span>(Outof-Sync Replicas) : 不同步的副本队列。<br>阈值 ：延迟时间replica.lag.time.max.ms<br>            延迟条数replica.lag.max.messages (0.10.x开始废弃这个参数)<br></strong></span></div><div><span style="font-size:18px;"><strong><br></strong></span></div><div><span style="font-size:18px;"><strong>下面介绍两个名词，以后会用得到：</strong></span></div><div><span style="font-size:18px;"><strong>HW  : 取一个partition对应的ISR中最小的LEO作为HW，consumer能够看到的此partition的位置。<br>LEO : LogEndOffset的缩写，表示每个partition的log最后一条Message的位置。<br></strong></span></div><div><span style="font-size:18px;"><strong><br></strong></span></div><div><span style="font-size:18px;"><strong>注意：</strong></span></div><div><span style="font-size:18px;"><strong>Leader节点的选举：</strong></span></div><div><span style="font-size:18px;"><strong> 1.少数服从多数</strong></span></div><div><span style="font-size:18px;"><strong> 2.ISR（从ISR列表中选一个）<br><br>在ISR中至少有一个follower时，Kafka可以确保已经commit的数据不丢失，但如果某一个partition的所有replica都挂了，就无法保证数据不丢失了。这种情况下有两种可行的方案：<br>（1）、等待ISR中任意一个replica“活”过来，并且选它作为leader<br>（2）、选择第一个“活”过来的replica（并不一定是在ISR中）作为leader<br></strong></span></div><div><span style="font-size:18px;"><strong><br></strong></span></div><div><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><span style="color:#009900;">04  Kafka消息传输保障</span></strong></span><br></strong></span></div><div><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><br></strong></span></strong></span></div><div><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong>（一）、Producer和Leader的通信可以通过request.required.acks参数来设置数据可靠性的级别。<br>1(默认)：这意味着producer在ISR中的leader已成功收到数据并得到确认。如果leader宕机了，则会丢失数据。<br>0：这意味着producer无需等待来自broker的确认而继续发送下一批消息。这种情况下数据传输效率最高，但是数据可靠性确是最低的。<br>-1：producer需要等待ISR中的所有follower都确认接收到数据后才算一次发送完成，可靠性最高。但是这样也不能保证数据不丢失，比如当ISR中只有leader时(前面ISR那一节讲到，ISR中的成员由于某些情况会增加也会减少，最少就只剩一个leader)，这样就变成了acks=1的情况。<br></strong></span></strong></span></div><div><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><br></strong></span></strong></span></div><div><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong>（二）、Kafka的发送模式<br>Kafka的发送模式由producer端的配置参数producer.type来设置，这个参数指定了在后台线程中消息的发送方式是同步的还是异步的，默认是同步的方式。<br>1.sync : 逐条发送(新版本已经取缔)。<br>2.async : 以batch的形式push数据，这样会极大的提高broker的性能，但是这样会增加丢失数据的风险。<br><br>---------------------------------------------------------------<br>Kafka的三种传输保障（delivery guarantee）:<br>At most once: 消息可能会丢，但绝不会重复传输；<br>At least once：消息绝不会丢，但可能会重复传输；<br>Exactly once：每条消息肯定会被传输一次且仅传输一次。<br>注释：Kafka的消息传输保障机制非常直观。当producer向broker发送消息时，一旦这条消息被commit，由于副本机制（replication）的存在，它就不会丢失。但是如果producer发送数据给broker后，遇到的网络问题而造成通信中断，那producer就无法判断该条消息是否已经提交（commit）。虽然Kafka无法确定网络故障期间发生了什么，但是producer可以retry多次，确保消息已经正确传输到broker中，所以目前Kafka实现的是at least once。<br></strong></span></strong></span></div><div><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong>---------------------------------------------------------------</strong></span></strong></span></div><div><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><br></strong></span></strong></span></div><div><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong>（三）、Consumer拉取消息的两种机制<br>consumer从broker中读取消息后，可以选择commit，该操作会在Zookeeper中存下该consumer在该partition下读取的消息的offset。该consumer下一次再读该partition时会从下一条开始读取。如未commit，下一次读取的开始位置会跟上一次commit之后的开始位置相同。<br>当然也可以将consumer设置为autocommit，即consumer一旦读取到数据立即自动commit。如果只讨论这一读取消息的过程，那Kafka是确保了exactly once, 但是如果由于前面producer与broker之间的某种原因导致消息的重复，那么这里就是at least once。<br></strong></span></strong></span></div><div><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><br></strong></span></strong></span></div><div><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><span style="color:#009900;">05  Kafka的并发性</span></strong></span><br></strong></span></strong></span></div><div><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><br></strong></span></strong></span></div><div><span style="font-family:'KaiTi_GB2312';font-size:18px;"><strong>一、Producer的并发<br>    Producer端，需要自己创造多线程并发环境才能提高客户端的出口吞吐量。<br>二、Consumer的并发<br>    任意Partition在某一个时刻只能被一个Consumer Group内的一个Consumer消费(反过来一个Consumer则可以同时消费多个Partition)，Kafka非常简洁的Offset机制最小化了Broker和Consumer之间的交互，这使Kafka并不会像同类其他消息队列一样，随着下游Consumer数目的增加而成比例的降低性能。此外，如果多个Consumer恰巧都是消费时间序上很相近的数据，可以达到很高的PageCache命中率，因而Kafka可以非常高效的支持高并发读操作，实践中基本可以达到单机网卡上限。</strong></span><br></div><div><span style="font-family:'KaiTi_GB2312';font-size:18px;"><strong><br></strong></span></div><div><span style="font-family:'KaiTi_GB2312';font-size:18px;"><span style="font-size:18px;"><span style="color:#009900;"><strong>06 Kafka在Zookeeper中的存储结构</strong></span></span><br></span></div><div><span style="font-family:'KaiTi_GB2312';font-size:18px;"><strong><span style="font-size:18px;"><strong><br></strong></span></strong></span></div><div><span style="font-family:'KaiTi_GB2312';font-size:18px;"><strong><span style="font-size:18px;"><strong></strong></span></strong></span><table border="0" cellpadding="0" cellspacing="0" width="884"><tbody><tr><td class="kso0" height="134" rowspan="3" style="width:105pt;" width="140"><p><span style="font-family:'MS Gothic';font-size:12pt;">consumers</span></p></td><td class="kso1" height="134" rowspan="3" style="width:86pt;" width="115"><p><span style="font-size:12pt;">[consumer-group]</span></p></td><td class="kso2" style="width:92pt;" width="123"><p><span style="font-size:12pt;">ids</span></p></td><td class="kso3" style="width:114pt;" width="152"><p><span style="font-size:12pt;">[consumer_id]</span></p></td><td class="kso4" style="width:265pt;" width="353"><p><span style="font-size:12pt;">consumer ID</span></p></td></tr><tr><td class="kso7" style="width:92pt;" width="123"><p><span style="font-size:12pt;">offsets</span></p></td><td class="kso8" style="width:114pt;" width="152"><p><span style="font-size:12pt;">topic/partition_id</span></p></td><td class="kso9" style="width:265pt;" width="353"><p><span style="font-size:12pt;">用来跟踪每个consumer group目前所消费的partition中最大的offset</span></p></td></tr><tr><td class="kso12" style="width:92pt;" width="123"><p><span style="font-size:12pt;">owners</span></p></td><td class="kso13" style="width:114pt;" width="152"><p><span style="font-size:12pt;">topic/[partition_id]</span></p></td><td class="kso14" style="width:265pt;" width="353"><p><span style="font-size:12pt;">用来标记partition被哪个consumer消费，为临时节点</span></p></td></tr><tr><td class="kso15" style="width:105pt;" width="140"><p><span style="font-size:12pt;">admin</span></p></td><td class="kso16" colspan="4" width="743"><p><span style="font-size:12pt;">重新分配分区，副本的选举，删除的主题</span></p></td></tr><tr><td class="kso20" style="width:105pt;" width="140"><p><span style="font-size:12pt;">config</span></p></td><td class="kso21" colspan="4" width="743"><p><span style="font-size:12pt;">topics</span><span style="font-size:12pt;">的配置</span></p></td></tr><tr><td class="kso25" style="width:105pt;" width="140"><p><span style="font-size:12pt;">controller</span></p></td><td class="kso26" colspan="4" width="743"><p><span style="font-size:12pt;">存储center controller（中央控制器）所在kafka broker的信息。</span></p></td></tr><tr><td class="kso30" height="192" rowspan="2" style="width:105pt;" width="140"><p><span style="font-size:12pt;">brokers</span></p></td><td class="kso31" style="width:86pt;" width="115"><p><span style="font-size:12pt;">ids</span></p></td><td class="kso32" style="width:92pt;" width="123"><p><span style="font-size:12pt;">[0...N]</span></p></td><td class="kso33" colspan="2" style="width:379pt;" width="505"><p><span style="font-size:12pt;">{   "jmx_port": -1, //JMX的端口号<br></span></p><p><span style="font-size:12pt;">    "timestamp": "1460082147315",//broker启动的时间戳<br></span></p><p><span style="font-size:12pt;">    "host": "xx.xxx.xxx.xxx",//host<br></span></p><p><span style="font-size:12pt;">    "version": 1,//默认的版本<br></span></p><p><span style="font-size:12pt;">    "port": 9092  //broker进程的对外监听的端口号}</span></p></td></tr><tr><td class="kso36" style="width:86pt;" width="115"><p><span style="font-size:12pt;">topics</span></p></td><td class="kso37" style="width:92pt;" width="123"><p><span style="font-size:12pt;">[topic]/partitions/[0...N] </span></p></td><td class="kso38" colspan="2" style="width:379pt;" width="505"><p><span style="font-size:12pt;">{"controller_epoch": 17,//中央控制器的总的选举次数  "leader": 0,  //此partition的broker leader的id   "version": 1, //默认版本号<br></span></p><p><span style="font-size:12pt;">    "leader_epoch": 1,//此partition的leader选举的次数  "isr": [0]    //同步副本组brokerId顺序列表}</span></p></td></tr><tr><td class="kso40" style="width:105pt;" width="140"><p><span style="font-size:12pt;">controller_epoch</span></p></td><td class="kso41" colspan="4" width="743"><p><span style="font-size:12pt;">此值为一个数字,kafka集群中第一个broker第一次启动时为1，以后只要集群中center controller（中央控制器）所在broker变更或挂掉，就会重新选举新的center controller，每次center controller变更controller_epoch值就会 + 1;</span></p></td></tr></tbody></table><br></div><div><span style="font-family:'KaiTi_GB2312';font-size:18px;"><strong><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><span style="color:#009900;">07 Kafka的高可用性和高效性</span></strong></span><br></strong></span></strong></span></div><div><span style="font-family:'KaiTi_GB2312';font-size:18px;"><strong><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><br></strong></span></strong></span></strong></span></div><div><span style="font-family:'KaiTi_GB2312';font-size:18px;"><strong><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong>1、消息的持久化<br>    只做Sequence I/O，规避了磁盘访问速度低下对性能可能造成的影响。Kafka重度依赖底层操作系统提供的PageCache功能，避免在JVM内部缓存数据。<br><br>2.消息的获取<br>    一个持久化的队列可以构建在对一个文件的读和追加上，所有的操作都是常数时间，并且读写之间不会相互阻塞。这种设计具有极大的性能优势：最终系统性能和数据大小完全无关，服务器可以充分利用廉价的硬盘来提供高效的消息服务。 事实上还有一点，磁盘空间的无限增大而不影响性能这点，意味着我们可以提供一般消息系统无法提供的特性。比如说，消息被消费后不是立马被删除，我们可以将这些消息保留一段相对比较长的时间（比如一个星期）。<br></strong></span></strong></span></strong></span></div><div><span style="font-family:'KaiTi_GB2312';font-size:18px;"><strong><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong><br></strong></span></strong></span></strong></span></div><div><span style="font-family:'KaiTi_GB2312';font-size:18px;"><strong><span style="font-size:18px;"><strong><span style="font-size:18px;"><strong>3、进一步提高效率<br>    为了减少大量小I/O操作的问题，kafka的协议是围绕消息集合构建的。Producer一次网络请求可以发送一个消息集合，而不是每一次只发一条消息。在server端是以消息块的形式追加消息到log中的，consumer在查询的时候也是一次查询大量的线性数据块。<br>    持久化log 块的网络传输。流行的unix操作系统提供了一种非常高效的途径来实现页面缓存和socket之间的数据传递。在Linux操作系统中，这种方式被称作：sendfile system call<br></strong></span></strong></span></strong></span></div></div>            </div>
                </div>