---
layout:     post
title:      HDFS海量存储
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/zmycoco2/article/details/10094669				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p><strong>HDFS海量存储</strong></p>
<p>HDFS允许用户链接多个集群中包含的节点(普通个人计算机)，那些集群是那个分布着一些数据文件。然后用户可以将那些数据文件作为一个无缝文件系统来进行访问和存储。对数据文件的访问通过一种流线型(streaming)方式进行处理，这意味着应用程序或命令通过mapreduce处理模型直接执行。</p>
<p>一次写入，多次读取(write-once-read-many)模型的显著优点是可以降低并发控制要求，化简数据的聚合，能支持高吞吐量的访问。Hadoop的优势表现在它已经在２０个节点上实际应用过（nutch项目）。</p>
<p>Hdfs另一个独特的特点是能处理逻辑并把它放置到数据附近，这种特性比将数据移到应用程序空间更好。Hdfs数据写入的特点是，将数据写入严格限制为一次只能写入一个程序。字节总是被附加到一个字节流的末尾，字节流总是以写入顺序先后来存储。</p>
<p>HDFS集群一般运行在多个机架上，不同机架上机器的通信需要通过交换机。通常情况下，副本的存放策略很关键，机架内节点之间的带宽比跨机架节点之间的带宽要大，它能影响HDFS的可靠性和性能。HDFS采用机架感知(reck-aware)策略来改进数据的可靠性，可用性和网络带宽的利用率。通过机架感知，namenode可以确定每个datanode所属的机架id。一般情况下，当复制因子是３的时候，HDFS的部署策略是将一个副本放在同一机架上的节点，一个副本存放在本地机架上的节点，最后一个副本放在不同机架上的节点。机架的错误远比节点的错误少，这个策略可以放置整个机架失效时数据丢失，不会影响到数据的可靠性和可用性，同时又能保证性能。</p>
<p>HDFS下的文件操作，命令格式为hadoop fs –cmd &lt;args&gt;　cmd的命令名通常与unix对应的命令名相同。例如，文件列表命令hadoop fs –ls。</p>
<p>$ bin/hadoop fs -ls/</p>
<p>Found 4 items</p>
<p>drwxr-xr-x   - yj70978 supergroup          0 2013-08-19 20:25 /home</p>
<p>drwxr-xr-x   - yj70978 supergroup          0 2013-08-19 20:27 /temp</p>
<p>drwxr-xr-x   - yj70978 supergroup          0 2013-08-19 05:42 /tmp</p>
<p>drwxr-xr-x   - yj70978 supergroup          0 2013-08-19 20:25 /user</p>
<p>$ bin/hadoop fs-mkdir /test</p>
<p>$ bin/hadoop fs -ls/</p>
<p>Found 5 items</p>
<p>drwxr-xr-x   - yj70978 supergroup          0 2013-08-19 20:25 /home</p>
<p>drwxr-xr-x   - yj70978 supergroup          0 2013-08-19 20:27 /temp</p>
<p>drwxr-xr-x   - yj70978 supergroup          0 2013-08-19 21:00 /test</p>
<p>drwxr-xr-x   - yj70978 supergroup          0 2013-08-19 05:42 /tmp</p>
<p>drwxr-xr-x   - yj70978 supergroup          0 2013-08-19 20:25 /user</p>
<p>hadoop的mkdir命令会自动创建父目录，类似于带-p的unix命令。</p>
<p>添加节点</p>
<p>HDFS的一个重要特性就是可扩展性，向HDFS集群中添加数据节点是很容易实现的。首先在新节点上安装号hadoop，配置hadoop时要与namenode节点采用相同的配置，在这里可以从namenode节点直接复制过来，然后再修改$hadoop_home/conf/master文件，加入namenode主机名，最后在namenode节点上修改$hadop_home/conf_slaves文件，加入新加节点主机名，在建立新节点的无密码ssh连接，这样添加节点就成功了。接下来运行启动命令。</p>
<p>$bin/start-all.sh</p>
            </div>
                </div>