---
layout:     post
title:      Kafka的简介与安装配置以及简单使用
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：版权所有,转载请注明出处.谢谢					https://blog.csdn.net/weixin_35353187/article/details/82991626				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h1>1、Kafka简介</h1>

<h3 style="margin-left:0pt;">1.1、什么是Kafka</h3>

<p style="margin-left:0pt;">Apache Kafka是分布式发布-订阅消息系统（消息中间件）。它最初由LinkedIn公司开发，之后成为Apache项目的一部分。Kafka是一种快速、可扩展的、设计内在就是分布式的，分区的和可复制的提交日志服务。</p>

<h3 style="margin-left:0pt;">1.2 、Apache Kafka与传统消息系统相比，有以下不同：</h3>

<p>1.它是分布式系统，易于向外扩展；</p>

<p>2.它同时为发布和订阅提供高吞吐量；</p>

<p>3.它支持多订阅者，当失败时能自动平衡消费者；</p>

<p>4.它将消息持久化到磁盘，因此可用于批量消费，例如ETL，以及实时应用程序。</p>

<h3>1.3、Kafka术语</h3>

<table border="1" cellspacing="0"><tbody><tr><td style="background-color:#c0504d;width:155px;">
			<p style="margin-left:0pt;"><strong><span style="color:#ffffff;"><strong>术语</strong></span></strong></p>
			</td>
			<td style="background-color:#c0504d;width:693px;">
			<p style="margin-left:0pt;"><strong><span style="color:#ffffff;"><strong>解释</strong></span></strong></p>
			</td>
		</tr><tr><td style="background-color:#b4c6e7;width:155px;">
			<p style="margin-left:0pt;"><strong><strong>Broker</strong></strong></p>
			</td>
			<td style="vertical-align:top;width:693px;">
			<p style="margin-left:0pt;">Kafka集群包含一个或多个服务器，这种服务器被称为broker</p>
			</td>
		</tr><tr><td style="background-color:#b4c6e7;width:155px;">
			<p style="margin-left:0pt;"><strong><strong>Topic</strong></strong></p>

			<p style="margin-left:0pt;"> </p>
			</td>
			<td style="vertical-align:top;width:693px;">
			<p style="margin-left:0pt;">每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</p>
			</td>
		</tr><tr><td style="background-color:#b4c6e7;width:155px;">
			<p style="margin-left:0pt;"><strong><strong>Partition</strong></strong></p>
			</td>
			<td style="vertical-align:top;width:693px;">
			<p style="margin-left:0pt;">Partition是物理上的概念，每个Topic包含一个或多个Partition.</p>
			</td>
		</tr><tr><td style="background-color:#b4c6e7;width:155px;">
			<p style="margin-left:0pt;"><strong><strong>Producer</strong></strong></p>
			</td>
			<td style="vertical-align:top;width:693px;">
			<p style="margin-left:0pt;">负责发布消息到Kafka broker</p>
			</td>
		</tr><tr><td style="background-color:#b4c6e7;width:155px;">
			<p style="margin-left:0pt;"><strong><strong>Consumer</strong></strong></p>
			</td>
			<td style="vertical-align:top;width:693px;">
			<p style="margin-left:0pt;">消息消费者，向Kafka broker读取消息的客户端</p>
			</td>
		</tr><tr><td style="background-color:#b4c6e7;width:155px;">
			<p style="margin-left:0pt;"><strong><strong>Consumer Group</strong></strong></p>
			</td>
			<td style="vertical-align:top;width:693px;">
			<p style="margin-left:0pt;">每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）</p>
			</td>
		</tr><tr><td style="background-color:#b4c6e7;width:155px;">
			<p style="margin-left:0pt;"><strong><strong>replica</strong></strong></p>
			</td>
			<td style="vertical-align:top;width:693px;">
			<p style="margin-left:0pt;">partition 的副本，保障 partition 的高可用</p>
			</td>
		</tr><tr><td style="background-color:#b4c6e7;width:155px;">
			<p style="margin-left:0pt;"><strong><strong>leader</strong></strong></p>
			</td>
			<td style="vertical-align:top;width:693px;">
			<p style="margin-left:0pt;">replica 中的一个角色， producer 和 consumer 只跟 leader 交互</p>
			</td>
		</tr><tr><td style="background-color:#b4c6e7;width:155px;">
			<p style="margin-left:0pt;"><strong><strong>follower</strong></strong></p>
			</td>
			<td style="vertical-align:top;width:693px;">
			<p style="margin-left:0pt;">replica 中的一个角色，从 leader 中复制数据</p>
			</td>
		</tr><tr><td style="background-color:#b4c6e7;width:155px;">
			<p style="margin-left:0pt;"><strong><strong>controller</strong></strong></p>
			</td>
			<td style="vertical-align:top;width:693px;">
			<p style="margin-left:0pt;">Kafka 集群中的其中一个服务器，用来进行 leader election 以及各种 failover</p>
			</td>
		</tr></tbody></table><hr><h1>2、Kafka的安装</h1>

<h3>2.1 下载</h3>

<p>下载官网 ：<a href="http://kafka.apache.org/downloads.html" rel="nofollow">http://kafka.apache.org/downloads.html</a></p>

<p><img alt="" class="has" height="266" src="https://img-blog.csdn.net/2018101008584769?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<p>以0.10.2.1为例。Kafka是用Scala开发的，所以下载时下载自己电脑上安装的Scala的对应的版本。</p>

<p><img alt="" class="has" height="264" src="https://img-blog.csdn.net/20181010090048676?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<h3>2.2 上传到Linux并解压</h3>

<p><span style="color:#f33b45;"><strong>scp -r /usr/local/kafka_2.11-0.10.2.1/ hadoop02:/usr/local/</strong></span></p>

<p><img alt="" class="has" height="220" src="https://img-blog.csdn.net/20181010094951156?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<h3>2.3 修改配置文件</h3>

<p><img alt="" class="has" height="255" src="https://img-blog.csdn.net/20181010095057492?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<pre class="has">
<code>broker.id=0
listeners=PLAINTEXT://hadoop01:9092
log.dirs=/usr/local/kafka_2.11-0.10.2.1/data
num.partitions=3
zookeeper.connect=hadoop01:2181,hadoop02:2181,hadoop03:2181,hadoop04:2181
</code></pre>

<h3>2.4 分发</h3>

<p><span style="color:#f33b45;"><strong>scp -r kafka_2.11-0.10.2.1/ hadoop02:/usr/local/</strong></span></p>

<p><span style="color:#f33b45;"><strong>scp -r kafka_2.11-0.10.2.1/ hadoop03:/opt/local/</strong></span></p>

<p><span style="color:#f33b45;"><strong>scp -r kafka_2.11-0.10.2.1/ hadoop04:/opt/local/</strong></span></p>

<h3><strong>2.5 修改配置文件</strong></h3>

<p><strong>详细配置文件说明参见文章（<a href="https://blog.csdn.net/weixin_35353187/article/details/82993955" rel="nofollow">https://blog.csdn.net/weixin_35353187/article/details/82993955</a>）</strong></p>

<p><strong>修改hadoop02：<br>
       broker.id=1<br>
       listeners=PLAINTEXT://hadoop02:9092</strong></p>

<p><strong>修改hadoop03：<br>
       broker.id=2<br>
       listeners=PLAINTEXT://hadoop03:9092</strong></p>

<p><strong>修改hadoop04：<br>
       broker.id=3<br>
       listeners=PLAINTEXT://hadoop04:9092</strong></p>

<h3><strong>2.6 启动Kafka</strong></h3>

<p><strong>启动Kafka之前，必须保证zookeeper是启动的</strong></p>

<p><span style="color:#f33b45;"><strong>kafka-server-start.sh -daemon /usr/local/kafka_2.11-0.10.2.1/config/server.properties</strong></span></p>

<p><img alt="" class="has" height="112" src="https://img-blog.csdn.net/20181010101532675?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<hr><h1>3、测试集群</h1>

<h3 style="margin-left:0pt;"><strong><strong>3.1、进入kafka根目录，创建Topic名称为： test的主题</strong></strong></h3>

<p style="margin-left:0pt;"><span style="color:#f33b45;"><strong>kafka-topics.sh --create --zookeeper hadoop01:2181,hadoop02:2181,hadoop03:2181 --replication-factor 3 --partitions 3 --topic test</strong></span></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="40" src="https://img-blog.csdn.net/20181010102234207?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<h3 style="margin-left:0pt;"><strong><strong>3.2、列出已创建的topic列表</strong></strong></h3>

<p style="margin-left:0pt;"><span style="color:#f33b45;"><strong>kafka-topics.sh --list --zookeeper hadoop01:2181</strong></span></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="42" src="https://img-blog.csdn.net/20181010102324591?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<h3 style="margin-left:0pt;"><strong><strong>3.3、查看Topic的详细信息</strong></strong></h3>

<p style="margin-left:0pt;"><span style="color:#f33b45;"><strong>kafka-topics.sh --describe --zookeeper hadoop01:2181 --topic test</strong></span></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="93" src="https://img-blog.csdn.net/20181010102542123?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<p style="margin-left:0pt;"><span style="color:#3399ea;">第一行是对所有分区的一个描述，然后每个分区对应一行。</span></p>

<p style="margin-left:0pt;"><span style="color:#3399ea;">leader：负责处理消息的读和写，leader是从所有节点中随机选择的.</span></p>

<p style="margin-left:0pt;"><span style="color:#3399ea;">replicas：列出了所有的副本节点，不管节点是否在服务中.</span></p>

<p style="margin-left:0pt;"><span style="color:#3399ea;">isr：是正在服务中的节点.  </span></p>

<p style="margin-left:0pt;"><span style="color:#3399ea;">isr: In-Sync Replicas   可以提供服务的副本</span></p>

<h3 style="margin-left:0pt;"><strong><strong>3.4、模拟客户端去发送消息（生产者）</strong></strong></h3>

<p style="margin-left:0pt;"><span style="color:#f33b45;"><strong>kafka-console-producer.sh --broker-list hadoop01:9092,hadoop02:9092 --topic hellotopic</strong></span></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="40" src="https://img-blog.csdn.net/20181010103114205?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="1084"></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="46" src="https://img-blog.csdn.net/20181010103245164?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<h3 style="margin-left:0pt;"><strong><strong>3.5、模拟客户端去接受消息  （消费者）</strong></strong></h3>

<p style="margin-left:0pt;"><strong><strong>连接broker的地址 ：</strong></strong><span style="color:#f33b45;"><strong><strong>kafka-console-consumer.sh --bootstrap-server hadoop03:9092 --from-beginning --topic hellotopic</strong></strong></span></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="75" src="https://img-blog.csdn.net/20181010103308687?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<h3 style="margin-left:0pt;"><strong><strong>3.6、测试一下容错能力. </strong></strong></h3>

<p style="margin-left:0pt;"><span style="color:#3399ea;">首先查看Topic的详细信息，发现Partition0的Leader为2</span></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="134" src="https://img-blog.csdn.net/20181010103945457?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<p style="margin-left:0pt;"><span style="color:#3399ea;">这里的Leader为2代表的是hadoop03这台机器</span></p>

<p style="margin-left:0pt;"><span style="color:#3399ea;">在hadoop03机器上关掉kafka进程</span></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="269" src="https://img-blog.csdn.net/20181010104113652?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<p style="margin-left:0pt;"><span style="color:#3399ea;">再次查看Topic详细信息，发现Partition0的Leader由2变为3,3为hadoop04机器</span></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="196" src="https://img-blog.csdn.net/20181010104618489?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<p style="margin-left:0pt;">Kill -9 pid[leader节点]</p>

<p style="margin-left:0pt;">另外一个节点被选做了leader,node 1 不再出现在 in-sync 副本列表中：</p>

<p style="margin-left:0pt;"><span style="color:#f33b45;"><strong>kafka-topics.sh --describe --zookeeper localhost:2181 --topic test</strong></span></p>

<hr><p style="margin-left:0pt;">        Topic: test     Partition: 0    Leader: 2       Replicas: 2,3,0 Isr: 2,3,0<br>
        Topic: test     Partition: 1    Leader: 3       Replicas: 3,0,1 Isr: 3,0,1<br>
        Topic: test     Partition: 2    Leader: 0       Replicas: 0,1,2 Isr: 0,2,1</p>

<hr><p style="margin-left:0pt;">        Topic: test     Partition: 0    Leader: 3       Replicas: 2,3,0 Isr: 3,0<br>
        Topic: test     Partition: 1    Leader: 3       Replicas: 3,0,1 Isr: 3,0,1<br>
        Topic: test     Partition: 2    Leader: 0       Replicas: 0,1,2 Isr: 0,1</p>

<hr><p style="margin-left:0pt;">虽然最初负责续写消息的leader down掉了，但之前的消息还是可以消费的：</p>

<p style="margin-left:0pt;"><span style="color:#f33b45;"><strong>kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic test</strong></span></p>

<h3 style="margin-left:0pt;"><span style="color:#f33b45;"><strong>3.7、注：如果再次启动hadoop03（即Leader2所在的机器）上的kafka服务，Leader还会变回去，不过需要一定的时间</strong></span></h3>

<p>重新启动hadoop03上的kafka服务</p>

<p style="margin-left:0pt;"><img alt="" class="has" height="336" src="https://img-blog.csdn.net/20181010105009472?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<p style="margin-left:0pt;">再次查看Topic的详细信息，会发现Leader变回了2，自动进行了均衡。Isr（正在服务中的节点）也增加了2</p>

<p style="margin-left:0pt;"><img alt="" class="has" height="235" src="https://img-blog.csdn.net/20181010105321885?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<h3 style="margin-left:0pt;">3.8、扩展：从头消费，指定分区消费</h3>

<p><span style="color:#3399ea;"><strong>生产者在生产数据的时候，默认会平均写到不同的分区中去。</strong></span></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="141" src="https://img-blog.csdn.net/20181010151752903?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<p style="margin-left:0pt;"><span style="color:#f33b45;"><strong><strong>--from-beginning参数意为从头开始消费</strong></strong></span></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="158" src="https://img-blog.csdn.net/20181010152031217?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="473" src="https://img-blog.csdn.net/20181010152200794?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>

<p style="margin-left:0pt;"><span style="color:#3399ea;"><strong>生产数据的时候，是有序的，但是消费数据的时候，会发现是无需的，这是因为在生产数据的时候，默认会平均写到不同的分区中去的。消费数据的时候，分区内的数据是有序的，但是分区间的数据，是无序的。</strong></span></p>

<p style="margin-left:0pt;"><span style="color:#3399ea;"><strong>可以通过-partition来指定消费某一个分区的数据。</strong></span></p>

<p style="margin-left:0pt;"><span style="color:#f33b45;"><strong>kafka-console-consumer.sh --bootstrap-server hadoop03:9092 --from-beginning --topic hellotopic --partition 0</strong></span></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="406" src="https://img-blog.csdn.net/2018101015284887?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTM1MzE4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="950"></p>            </div>
                </div>