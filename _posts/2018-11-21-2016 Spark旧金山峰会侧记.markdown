---
layout:     post
title:      2016 Spark旧金山峰会侧记
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<blockquote>
  <p><strong>作者简介：</strong>邵赛赛，Hortonworks技术专家，Spark活跃贡献者，主要聚焦Spark领域，包括Spark core、Spark on Yarn，以及Spark Streaming。此外，邵赛赛还是Apache Chukwa committer。</p>
</blockquote><p>Spark峰会是Spark领域内规模最大、最具影响力的工业会议，迄今为止已经成功举办了6届，规模和地域不断地扩大，从旧金山到纽约再到欧洲，从一个小型的工业会议发展到如今备受关注、极具影响力的业界顶级峰会。</p><p>本次Spark 旧金山峰会是迄今为止规模最大的一次峰会，吸引了众多业界顶级的演讲嘉宾和参展商，笔者也有幸参加本次峰会，为大家带来笔者的见闻和感想。</p><p><img src="http://img.blog.csdn.net/20160621092530790" alt="图片描述" title=""><br><strong>Spark 2.0</strong></p><p>本次峰会恰逢Spark 2.0的发布，因此Spark 2.0的特性和架构成为备受关注的焦点。在第一天的主题演讲中Databricks CTO Matei Zaharia详细介绍了Spark 2.0以及Spark社区在这上面所做的贡献。同时在后续的演讲中Databricks的Michael Armbrust和TD对其实现做了具体的介绍。</p><p>Spark 2.0是迄今为止Spark社区所发布的最大的版本，超过280个的贡献者贡献了2000+个patch。其中最主要的改进有Structured API 的改进，Structured Streaming模块的加入，MLlib模型导出，SQL2003支持等等。对于Structured API和Structured Streaming Matei做了详细地介绍。</p><p><img src="http://img.blog.csdn.net/20160621092617666" alt="图片描述" title=""></p><p><strong>Structured API</strong></p><p>在Spark的设计中，RDD (Resilient Distributed Dataset，弹性分布式数据集)是一个非常重要的概念，它是Spark数据处理的模型基础和编程接口，但其过于底层的设计，使得Spark系统本身对于使用RDD API所实现的代码优化空间有限，只能依赖于有经验的用户编写出高效的代码。因此为了兼顾灵活性和性能，Spark在1.6之后引入了Dataset API，这是一套类似与RDD的数据集操作API，但与RDD的最大不同是由于其实现层次的不同，系统能够对用户的代码逻辑有更多的优化。在Spark 2.0中Dataset API的地位得到了进一步的提高，并将其与DataFrame融合，Structured API将会成为新一代的Spark编程API。</p><p><strong>Structured Streaming</strong></p><p>流式处理是大数据应用中的非常重要的一环，在Spark中Spark Streaming利用Spark的高效框架提供了基于micro-batch的流式处理框架，并在RDD之上抽象了流式操作API DStream供用户使用。</p><p>随着流式处理需求的复杂化，用户希望在流式数据中引入较为复杂的查询和分析，传统的DStream API想要实现相应的功能就变得较为复杂，同时随着Spark的迭代，社区希望使用同一套Structured API来进行流式操作。因此在Spark 2.0中引入了structured Streaming模块，它使得用户可以使用与批处理同样的Structured API对结构化的流式数据进行处理：</p><pre class="prettyprint"><code class="hljs avrasm">logs = ctx<span class="hljs-preprocessor">.read</span><span class="hljs-preprocessor">.format</span>(“text”)<span class="hljs-preprocessor">.stream</span>(“s3://logs”)
logs<span class="hljs-preprocessor">.groupBy</span>(“userid”, “hour”)<span class="hljs-preprocessor">.avg</span>(“latency”)
   <span class="hljs-preprocessor">.write</span><span class="hljs-preprocessor">.format</span>(“jdbc”)
   <span class="hljs-preprocessor">.streamStream</span>(“jdbc:mysql//…”)</code></pre><p>Spark 2.0实现了基本的structured streaming功能，并会在后续的版本中逐步完善其功能。</p><p><strong>机器学习与数据科学</strong></p><p>在本届Spark峰会中机器学习和数据科学相关的议题占了主要的比例，涵盖了机器学习，深度学习，数据分析的方方面面。而Spark峰会更是邀请到了Google的Jeff Dean和Baidu的Andrew Ng分享关于深度学习、人工智能的主题演讲。</p><p>Jeff Dean为大家介绍了深度学习在Google的应用以及相应的开源项目TensorFlow。包括TensorFlow的设计初衷，基本原理，API设计和使用场景。TensorFlow是当前最为火热的深度学习框架之一，深度学习和与大数据的结合将擦出更精彩的火花。</p><p>接着Jeff Dean的主题演讲，Andrew Ng也为大家带来了人工智能和深度学习的探索，他将深度学习比作火箭，深度学习框架是火箭的引擎，而数据则是火箭的燃料，更强大的火箭所需要的是使用更强劲的引擎和更多的燃料，同样在深度学习中更大的训练网络和更多的数据会带来更精确的结果。同时Andrew Ng也为大家介绍了深度学习和人工智能的发展趋势，使用场景。最后他将人工智能比作电力资源，未来将会渗透和改变各行各业。</p><p><img src="http://img.blog.csdn.net/20160621092748871" alt="图片描述" title=""></p><p><strong>Spark&amp;深度学习</strong></p><p>Spark和深度学习是当前作为火热的两个概念，在这次Spark峰会中也有许多关于Spark和深度学习结合的议题。</p><p>百度为我们带来了在Spark上构建分布式深度学习框架的分享。他们公开了称为”Paddle”的分布式异步深度学习库，并且将其与其他主流的深度学习框架进行了比较。同时他们也详细介绍了基于Spark，Paddle，Parameter server和Yarn的一整套深度学习解决方案。</p><p>而雅虎则是分享了他们将Spark和Caffe相结合的项目Caffe On Spark。Caffe On Spark充分利用到了Spark自身分布式调度，将Caffe深度学习模块集成到了Spark中，由Spark进行任务管理和调度，同时Caffe On Spark扩展了 Spark本身的资源管理使其能够支持GPU，并且修改了Spark的通信模型使得Caffe On Spark可以支持节点之间的互相直接通信。最后Caffe On Spark提供了一套类似DataFrame的API使得用户能够轻易地在分布式数据集上进行深度学习。</p><p>EMC则是对现今的基于Spark之上的主流深度学习框架进行了一个比较，包括Deepdist，Sparknet，DL4j等等，从它们的实现原理，性能和应用场景上做了一个全面的比较。</p><p><strong>机器学习</strong></p><p>随着数据科学的蓬勃发展，如今的大数据应用已经不仅仅限于简单的数据处理，基于学习的数据分析预测变得越来越重要，这也可以从本次峰会的议题中看出，在本次峰会中有非常多的议题涵盖了机器学习和数据科学，从MLlib未来的发展到各种基于Spark的机器学习算法库，从机器学习前沿研究到工业应用。笔者简要地概述我所参加的几个议题。</p><p>在第一天的议题中，Databricks的Xiangrui Meng首先回顾了近期在SparkR和MLlib上的工作，包括扩展SparkR使其支持可扩展的预测分析，将更多地MLlib算法移植到SparkR中。同时他也对SparkR未来的方向进行了展望。</p><p>Intel则为我们带来了对于MLlib在大规模、高维数据下的优化。在MLlib中现今算法的实现都是基于一定量级的数据规模，在实际使用中如果数据量级变大这些实现往往会引起许多问题，因此Intel的工程师扩展和改进了原有的算法实现，使得这些算法能够对更大规模、更高维度下的数据进行处理。</p><p>当然还有许多与机器学习相关的议题，比如华为开源的构建在Spark Streaming之上的进行实时分析的算法库StreamDM，IBM开源的机器学习算法库SystemML, Netflix公开的机器学习工作流框架Meson等等。许多公司都在Spark 之上构建或扩展了机器学习的算法来满足自身业务的需求。</p><p>随着业界对于基于大数据的分析和预测的需求越来越强烈，越来越多的公司投入资源到机器学习领域，在大数据领域数据科学和机器学习呈现出井喷的趋势。 <br>
Spark生态圈和业界应用</p><p>随着Spark生态圈的日渐扩大，业界也在围绕着Spark发生着变化，这里有新兴的互联网公司，也有传统的软硬件公司，他们逐步地将Spark整合到自己产品 、架构和服务中去。</p><p>在第二天的主题演讲中，业界的公司纷纷介绍了Spark与其自身产品的整合。微软介绍了他们在Azure云上整合和提供的一整套基于Spark和HDInsight的分析工具。Cloudera则展示了他们基于One Spark的整个大数据软件栈。Capital One介绍了他们基于Spark的图分析工具链进行信用卡诈骗的预防。Intel则从硬件的角度分析了硬件的革新对于Spark大数据分析的推进。最后IBM介绍了他们围绕Spark的一系列工作从SQL到机器学习，再到对象存储。</p><p>在两天的会议中，许多的公司介绍了他们自身产品与Spark的结合：</p><ul><li>Elastic公司介绍了他们的Elasticsearch与Spark的结合使得Spark能够更好地应用在数据搜索和查询中。</li>
<li>Confluent介绍了他们基于Kafka的项目”Kafka Connect”，能够使数据从Kafka中导入导出变得更为简单，将其与Spark Streaming的结合能够使得streaming作业能够支持构建、监控和维护更为复杂的数据流。</li>
<li>Cloudera介绍了他们的开源项目Livy，他是一个基于REST API的网络服务，用户能够通过REST API来提交Spark作业或是应用。</li>
</ul><p>同时还有许多其他公司介绍了他们对Spark的支持，比如将Solr作为Spark SQL的Data Source；Spark和Couchbase的整合；HP Vertica对于Spark的支持等等。业界越来越多地将自身的产品与Spark进行结合，更进一步壮大了整个Spark生态圈。</p><p><strong>未来展望</strong></p><p>纵观本次Spark旧金山峰会，整个大数据Spark社区和生态都在蓬勃地发展中。</p><p>Spark正在高速地演化。相比于Spark1，Spark2有了更多的变化和革新，传统的基于RDD和DStream的编程范式被弱化，新一代的基于Dataset/DataFrame的API被提到了重要的位置。从之前的通用数据处理框架慢慢演化为针对结构化数据优化和改良的处理框架。</p><p>数据科学和机器学习蓬勃发展。Spark在其设计之初就与数据科学、机器学习紧密结合，而其提供的python和R接口更是构建起了传统数据科学与大数据之间的桥梁。随着Spark DataFrame API的产生和MLlib的演化，更多传统数据科学领域的概念和体系被移植到了Spark上，使得Spark在机器学习和数据科学领域产生了前所未有的火花。</p><p>越来越多的公司投入资源到Spark中去，他们或是将Spark整合到自身产品中去，或是提供Spark操作接口，又或是提供基于Spark的解决方案。同时也有许多使用Spark创业的商业智能公司，围绕着Spark的整个行业规模日渐凸显，大有当年Hadoop开疆拓土之势。</p><p>最后，国内的Spark力量不容小觑，在Spark峰会中来自国内的声音也占据了一席之地，尤其是华为在Spark上的工作令人刮目相看。</p><p>本届Spark峰会向我们展示了未来的Spark，未来的大数据，我们正处在一个数据革命的时代，未来必将更加精彩。</p><hr><p><strong>OpenStack Days China将于7月14-15日在北京国家会议中心举办，届时包括OpenStack基金会的Jonathan Bryce、Mark Collier、Alan Clark等大牛都将来到大会现场和2000名参会者一起坐而论道，共话OpenStack大势，现在<a href="http://openstackdaychina.csdn.net/m/zone/openstackdaychina/index" rel="nofollow">报名</a>票价优惠，欲报从速。</strong></p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>