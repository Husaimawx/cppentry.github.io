---
layout:     post
title:      19、大数据之Flume和Flume的安装部署
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h1><strong><span style="font-size:16px;">一. <span style="font-family:'宋体';">日志采集框架</span><span style="font-family:Calibri;">Flume</span></span></strong></h1><h2><strong><span style="font-size:16px;">1. Flume<span style="font-family:'宋体';">介绍</span></span></strong></h2><h3><strong><span style="font-size:16px;">1.1. <span style="font-family:'宋体';">概述</span></span></strong></h3><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p><span style="font-size:16px;"> Flume<span style="font-family:'宋体';">是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。</span></span></p><p><span style="font-size:16px;"> Flume<span style="font-family:'宋体';">可以采集文件，</span><span style="font-family:Calibri;">socket</span><span style="font-family:'宋体';">数据包等各种形式源数据，又可以将采集到的数据输出到</span><span style="font-family:Calibri;">HDFS</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">hbase</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">hive</span>、kafka等众多外部存储系统中</span></p><p><span style="font-size:16px;"> <span style="font-family:'宋体';">一般的采集需求，通过对</span>flume<span style="font-family:'宋体';">的简单配置即可实现</span></span></p><p><span style="font-size:16px;"> Flume<span style="font-family:'宋体';">针对特殊场景也具备良好的自定义扩展能力，因此，</span><span style="font-family:Calibri;">flume</span><span style="font-family:'宋体';">可以适用于大部分的日常数据采集场景</span></span></p></blockquote><p><span style="font-size:16px;"> </span></p><h3><strong><span style="font-size:16px;">1.2 <span style="font-family:'宋体';">运行机制</span></span></strong></h3><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p><span style="font-size:16px;">1、 Flume<span style="font-family:'宋体';">分布式系统中最</span><strong><span style="font-family:'宋体';">核心的角色是</span>agent</strong><span style="font-family:'宋体';">，</span>flume<span style="font-family:'宋体';">采集系统就是由一个个</span><span style="font-family:Calibri;">agent</span><span style="font-family:'宋体';">所连接起来形成</span></span></p><p><span style="font-size:16px;">2、 <strong><span style="font-family:'宋体';">每一个</span>agent<span style="font-family:'宋体';">相当于一个数据传递员</span>，内部有三个组件：</strong></span></p><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p><span style="font-size:16px;">a) Source<span style="font-family:'宋体';">：采集源，用于跟数据源对接，以获取数据</span></span></p></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p><span style="font-size:16px;">b) Sink<span style="font-family:'宋体';">：下沉地，采集数据的传送目的，用于往下一级</span><span style="font-family:Calibri;">agent</span><span style="font-family:'宋体';">传递数据或者往最终存储系统传递数据</span></span></p></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p><span style="font-size:16px;">c) Channel<span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">angent</span><span style="font-family:'宋体';">内部的数据传输通道，用于从</span><span style="font-family:Calibri;">source</span><span style="font-family:'宋体';">将数据传递到</span><span style="font-family:Calibri;">sink</span></span></p></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p><span style="font-size:16px;"> <img src="https://img-blog.csdn.net/20180610185734651?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIxNzgxOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></span></p></blockquote><p><span style="font-size:16px;"><br></span></p><p></p><h2><strong><span style="font-family:'微软雅黑';"><span style="font-size:16px;">组件：</span></span></strong></h2><h3><span style="font-size:16px;">1.Source</span></h3><p><span style="font-size:16px;">flume有许多类型的Source<span style="font-family:'宋体';">，见官网用户手册：</span></span></p><p><span style="font-size:16px;">http://flume.apache.org/FlumeUserGuide.html#flume-sources</span></p><p><span style="font-size:16px;"><br></span></p><p><span style="font-size:16px;">简单的归纳如下：</span></p><p></p><table border="1" cellspacing="0"><tbody><tr><td><p align="center"><span style="font-size:14px;">Source<span style="font-family:'宋体';">类型</span></span></p></td><td><p align="center"><span style="font-size:14px;">说明</span></p></td></tr><tr><td><p><span style="font-size:14px;">Avro Source</span></p></td><td><p><span style="font-size:14px;">支持<span style="font-family:Calibri;">Avro</span><span style="font-family:'宋体';">协议（实际上是</span><span style="font-family:Calibri;">Avro RPC</span><span style="font-family:'宋体';">），提供一个</span><span style="font-family:Calibri;">Avro</span><span style="font-family:'宋体';">的接口，需要往设置的地址和端口发送</span><span style="font-family:Calibri;">Avro</span><span style="font-family:'宋体';">消息，</span><span style="font-family:Calibri;">Source</span><span style="font-family:'宋体';">就能接收到</span><span style="font-family:Calibri;">,</span><span style="font-family:'宋体';">如：</span><span style="font-family:Calibri;">Log4j</span> Appender<span style="font-family:'宋体';">通过</span><span style="font-family:Calibri;">Avro Source</span><span style="font-family:'宋体';">将消息发送到</span><span style="font-family:Calibri;">Agent</span></span></p></td></tr><tr><td><p><span style="background:rgb(255,0,0);"><span style="font-size:14px;">Thrift Source</span></span></p></td><td><p><span style="font-size:14px;">支持<span style="font-family:Calibri;">Thrift</span><span style="font-family:'宋体';">协议，提供一个</span><span style="font-family:Calibri;">Thrift</span><span style="font-family:'宋体';">接口，类似</span><span style="font-family:Calibri;">Avro</span></span></p></td></tr><tr><td><p><span style="background:rgb(255,0,0);"><span style="font-size:14px;">Exec Source</span></span></p></td><td><p><span style="font-size:14px;">Source<span style="font-family:'宋体';">启动的时候会运行一个设置的</span><span style="font-family:Calibri;">UNIX</span><span style="font-family:'宋体';">命令（比如 </span><span style="font-family:Calibri;">cat file</span><span style="font-family:'宋体';">），该命令会不断地往标准输出（</span><span style="font-family:Calibri;">stdout</span><span style="font-family:'宋体';">）输出数据，这些数据就会被打包成</span><span style="font-family:Calibri;">Event</span><span style="font-family:'宋体';">，进行处理</span></span></p></td></tr><tr><td><p><span style="font-size:14px;">JMS Source</span></p></td><td><p><span style="font-size:14px;">从<span style="font-family:Calibri;">JMS</span><span style="font-family:'宋体';">系统（消息、主题）中读取数据，</span>类似ActiveMQ</span></p></td></tr><tr><td><p><span style="font-size:14px;">Spooling Directory Source</span></p></td><td><p><span style="font-size:14px;">监听某个目录，该目录有新文件出现时，把文件的内容打包成<span style="font-family:Calibri;">Event</span><span style="font-family:'宋体';">，进行处理</span></span></p></td></tr><tr><td><p><span style="background:rgb(255,0,0);"><span style="font-size:14px;">Netcat Source</span></span></p></td><td><p><span style="font-size:14px;">监控某个端口，将流经端口的每一个文本行数据作为<span style="font-family:Calibri;">Event</span><span style="font-family:'宋体';">输入</span></span></p></td></tr><tr><td><p><span style="font-size:14px;">Sequence Generator Source</span></p></td><td><p><span style="font-size:14px;">序列生成器数据源，生产序列数据</span></p></td></tr><tr><td><p><span style="font-size:14px;">Syslog Sources</span></p></td><td><p><span style="font-size:14px;">读取<span style="font-family:Calibri;">syslog</span><span style="font-family:'宋体';">数据，产生</span><span style="font-family:Calibri;">Event</span><span style="font-family:'宋体';">，支持</span><span style="font-family:Calibri;">UDP</span><span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">TCP</span><span style="font-family:'宋体';">两种协议</span></span></p></td></tr><tr><td><p><span style="font-size:14px;">HTTP Source</span></p></td><td><p><span style="font-size:14px;">基于<span style="font-family:Calibri;">HTTP POST</span><span style="font-family:'宋体';">或</span><span style="font-family:Calibri;">GET</span><span style="font-family:'宋体';">方式的数据源，支持</span><span style="font-family:Calibri;">JSON</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">BLOB</span><span style="font-family:'宋体';">表示形式</span></span></p></td></tr><tr><td><p><span style="font-size:14px;">Legacy Sources</span></p></td><td><p><span style="font-size:14px;">兼容老的<span style="font-family:Calibri;">Flume OG</span><span style="font-family:'宋体';">中</span><span style="font-family:Calibri;">Source</span><span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">0.9.x</span><span style="font-family:'宋体';">版本）</span></span></p></td></tr><tr><td><p><span style="font-size:14px;">自定义<span style="font-family:Calibri;">Source</span></span></p></td><td><p><span style="font-size:14px;">使用者通过实现Flume<span style="font-family:'宋体';">提供的接口来定制满足需求的</span><span style="font-family:Calibri;">Source</span>。</span></p></td></tr></tbody></table><div style="text-align:left;"><span style="font-size:14px;"><br></span></div><p><span style="font-size:16px;"><span style="font-family:'宋体';">对于直接读取文件</span>Source, <span style="font-family:'宋体';">主要有两种方式：</span><span style="font-family:Calibri;"> </span></span></p><p><span style="font-size:16px;">（1） Exec source</span></p></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><span style="font-size:16px;"><span style="font-family:'宋体';">可通过写</span>Unix command<span style="font-family:'宋体';">的方式组织数据，最常用的就是</span><span style="font-family:Calibri;">tail -F [file]</span><span style="font-family:'宋体';">。</span></span></p></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><span style="font-size:16px;">可以实现<span style="color:rgb(0,112,192);">实时传输</span><span style="font-family:'宋体';">，但在</span>flume<span style="font-family:'宋体';">不运行和脚本错误时，会丢数据，也不支持断点续传功能。因为没有记录上次文件读到的位置，从而没办法知道，下次再读时，从什么地方开始读。特别是在日志文件一直在增加的时候。</span><span style="font-family:Calibri;">flume</span><span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">source</span><span style="font-family:'宋体';">挂了。等</span><span style="font-family:Calibri;">flume</span><span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">source</span><span style="font-family:'宋体';">再次开启的这段时间内，增加的日志内容，就没办法被</span><span style="font-family:Calibri;">source</span><span style="font-family:'宋体';">读取到了。不过</span><span style="font-family:Calibri;">flume</span><span style="font-family:'宋体';">有一个</span><span style="font-family:Calibri;">execStream</span><span style="font-family:'宋体';">的扩展，可以自己写一个监控日志增加情况，把增加的日志，通过自己写的工具把增加的内容，传送给</span><span style="font-family:Calibri;">flume</span><span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">node</span><span style="font-family:'宋体';">。再传送给</span><span style="font-family:Calibri;">sink</span><span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">node</span><span style="font-family:'宋体';">。要是能在</span><span style="font-family:Calibri;">tail</span><span style="font-family:'宋体';">类的</span><span style="font-family:Calibri;">source</span><span style="font-family:'宋体';">中能支持，在</span><span style="font-family:Calibri;">node</span><span style="font-family:'宋体';">挂掉这段时间的内容，等下次</span><span style="font-family:Calibri;">node</span><span style="font-family:'宋体';">开启后在继续传送，那就更完美了。</span></span></p></blockquote></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><span style="font-size:16px;">（2） Spooling Directory Source</span></p></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><span style="font-size:16px;">SpoolSource:<span style="font-family:'宋体';">是监测配置的目录下新增的文件，并将文件中的数据读取出来，可实现准实时。需要注意两点：</span></span></p></blockquote></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><span style="font-size:16px;">1、<span style="font-family:'宋体';">拷贝到</span>spool<span style="font-family:'宋体';">目录下的文件不可以再打开编辑。</span></span></p></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><span style="font-size:16px;">2、spool<span style="font-family:'宋体';">目录下不可包含相应的子目录。在实际使用的过程中，可以结合</span><span style="font-family:Calibri;">log4j</span><span style="font-family:'宋体';">使用，使用</span><span style="font-family:Calibri;">log4j</span><span style="font-family:'宋体';">的时候，将</span><span style="font-family:Calibri;">log4j</span><span style="font-family:'宋体';">的文件分割机制设为</span><span style="font-family:Calibri;">1</span><span style="font-family:'宋体';">分钟一次，将文件拷贝到</span><span style="font-family:Calibri;">spool</span><span style="font-family:'宋体';">的监控目录。</span><span style="font-family:Calibri;">log4j</span><span style="font-family:'宋体';">有一个</span><span style="font-family:Calibri;">TimeRolling</span><span style="font-family:'宋体';">的插件，可以把</span><span style="font-family:Calibri;">log4j</span><span style="font-family:'宋体';">分割的文件到</span><span style="font-family:Calibri;">spool</span><span style="font-family:'宋体';">目录。基本实现了实时的监控。</span><span style="font-family:Calibri;">Flume</span><span style="font-family:'宋体';">在传完文件之后，将会修改文件的后缀，变为</span><span style="font-family:Calibri;">.COMPLETED</span><span style="font-family:'宋体';">（后缀也可以在配置文件中灵活指定）</span></span></p></blockquote></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><strong><span style="color:rgb(255,0,0);"><span style="font-size:16px;"><span style="font-family:'宋体';">注：</span>ExecSource<span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">SpoolSource</span><span style="font-family:'宋体';">对比</span></span></span></strong></p></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><span style="font-size:16px;">ExecSource<span style="font-family:'宋体';">可以实现对日志的实时收集，但是存在</span><span style="font-family:Calibri;">Flume</span><span style="font-family:'宋体';">不运行或者指令执行出错时，将无法收集到日志数据，无法何证日志数据的完整性。</span><span style="font-family:Calibri;">SpoolSource</span><span style="font-family:'宋体';">虽然无法实现实时的收集数据，但是可以使用以分钟的方式分割文件，趋近于实时。如果应用无法实现以分钟切割日志文件的话，可以两种收集方式结合使用。</span></span></p><p><span style="font-size:16px;"><span style="font-family:'宋体';"><br></span></span></p></blockquote></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><span style="font-size:16px;"><strong> 2.Channel</strong></span></p><p><span style="font-size:16px;"><span style="font-family:'宋体';">当前有几个</span> Channel <span style="font-family:'宋体';">可供选择，分别是</span> Memory Channel, JDBC Channel , File Channel<span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">Psuedo Transaction Channel</span><span style="font-family:'宋体';">。比较常见的是前三种 </span>Channel<span style="font-family:'宋体';">。</span></span></p></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><span style="font-size:16px;">（1）Memory Channel <span style="font-family:'宋体';">可以实现高速的吞吐，但是无法保证数据的完整性。</span></span></p></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><span style="font-size:16px;">（2）Memory Recover Channel <span style="font-family:'宋体';">在官方文档的建议上已经建义使用</span><span style="font-family:Calibri;">File</span> Channel<span style="font-family:'宋体';">来替换。</span></span></p></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><span style="font-size:16px;">（3）File Channel<span style="font-family:'宋体';">保证数据的完整性与一致性。在具体配置</span><span style="font-family:Calibri;">File</span> Channel<span style="font-family:'宋体';">时，建议</span><span style="font-family:Calibri;">File</span> Channel<span style="font-family:'宋体';">设置的目录和程序日志文件保存的目录设成不同的磁盘，以便提高效率。</span></span></p></blockquote></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><span style="font-size:16px;">        File Channel <span style="font-family:'宋体';">是一个持久化的隧道（</span>Channel<span style="font-family:'宋体';">），它持久化所有的事件，并将其存储到磁盘中。因此，即使</span> Java <span style="font-family:'宋体';">虚拟机当掉，或者操作系统崩溃或重启，再或者事件没有在管道中成功地传递到下一个代理（</span><span style="font-family:Calibri;">agent</span><span style="font-family:'宋体';">），这一切都不会造成数据丢失。</span><span style="font-family:Calibri;">Memory </span>Channel <span style="font-family:'宋体';">是一个不稳定的隧道，其原因是由于它在内存中存储所有事件。如果</span> Java <span style="font-family:'宋体';">进程死掉，任何存储在内存的事件将会丢失。另外，内存的空间收到 </span><span style="font-family:Calibri;">RAM</span><span style="font-family:'宋体';">大小的限制</span><span style="font-family:Calibri;">,</span><span style="font-family:'宋体';">而 </span><span style="font-family:Calibri;">File </span>Channel <span style="font-family:'宋体';">这方面是它的优势，只要磁盘空间足够，它就可以将所有事件数据存储到磁盘上。</span></span></p><p><span style="font-size:16px;"><span style="font-family:'宋体';"><br></span></span></p></blockquote></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><span style="font-size:16px;">Flume Channel <span style="font-family:'宋体';">支持的类型：</span></span></p><table border="1" cellspacing="0"><tbody><tr><td><p align="center"><span style="font-size:16px;">Channel类型</span></p></td><td><p align="center"><span style="font-size:16px;">说明</span></p></td></tr><tr><td><p><span style="font-size:16px;">Memory Channel</span></p></td><td><p><span style="font-size:16px;">Event<span style="font-family:'宋体';">数据存储在内存中</span></span></p></td></tr><tr><td><p><span style="font-size:16px;"><span style="background:rgb(255,0,0);">JDBC </span><span style="background:rgb(255,0,0);">Channel</span></span></p></td><td><p><span style="font-size:16px;">Event<span style="font-family:'宋体';">数据存储在持久化存储中，当前</span><span style="font-family:Calibri;">Flume </span>Channel内置支持<span style="font-family:Calibri;">Derby</span></span></p></td></tr><tr><td><p><span style="font-size:16px;"><span style="background:rgb(255,0,0);">File </span><span style="background:rgb(255,0,0);">Channel</span></span></p></td><td><p><span style="font-size:16px;">Event<span style="font-family:'宋体';">数据存储在磁盘文件中</span></span></p></td></tr><tr><td><p><span style="font-size:16px;">Spillable Memory Channel</span></p></td><td><p><span style="font-size:16px;">Event<span style="font-family:'宋体';">数据存储在内存中和磁盘上，当内存队列满了，会持久化到磁盘文件（当前试验性的，不建议生产环境使用）</span></span></p></td></tr><tr><td><p><span style="font-size:16px;">Pseudo Transaction Channel</span></p></td><td><p><span style="font-size:16px;">测试用途</span></p></td></tr><tr><td><p><span style="font-size:16px;">Custom Channel</span></p></td><td><p><span style="font-size:16px;">自定义Channel实现  </span></p></td></tr></tbody></table><p><span style="font-size:16px;"><br></span></p><p><span style="font-size:16px;"><strong>3. Sink</strong></span></p><p><span style="font-size:16px;">       Sink<span style="font-family:'宋体';">在设置存储数据时，可以向文件系统中，数据库中，</span><span style="font-family:Calibri;">Hadoop</span><span style="font-family:'宋体';">中储数据，在日志数据较少时，可以将数据存储在文件系中，并且设定一定的时间间隔保存数据。在日志数据较多时，可以将相应的日志数据存储到</span><span style="font-family:Calibri;">Hadoop</span><span style="font-family:'宋体';">中，便于日后进行相应的数据分析。</span><span style="font-family:Calibri;"> </span></span></p><p><span style="font-size:16px;"><span style="font-family:Calibri;"><br></span></span></p><p><span style="font-size:16px;">Flume Sink<span style="font-family:'宋体';">支持的类型</span></span></p><div align="center"><table border="1" cellspacing="0"><tbody><tr><td><p align="center"><strong><span style="font-size:16px;">Sink类型</span></strong></p></td><td><p align="center"><strong><span style="font-size:16px;">说明</span></strong></p></td></tr><tr><td><p><span style="background:rgb(255,0,0);"><span style="font-size:16px;">HDFS Sink</span></span></p></td><td><p><span style="font-size:16px;">数据写入HDFS</span></p></td></tr><tr><td><p><span style="background:rgb(255,0,0);"><span style="font-size:16px;">Logger Sink</span></span></p></td><td><p><span style="font-size:16px;">数据写入日志文件</span></p></td></tr><tr><td><p><span style="background:rgb(255,0,0);"><span style="font-size:16px;">Avro Sink</span></span></p></td><td><p><span style="font-size:16px;">数据被转换成Avro Event，然后发送到配置的RPC端口上</span></p></td></tr><tr><td><p><span style="font-size:16px;">Thrift Sink</span></p></td><td><p><span style="font-size:16px;">数据被转换成Thrift Event，然后发送到配置的RPC端口上</span></p></td></tr><tr><td><p><span style="font-size:16px;">IRC Sink</span></p></td><td><p><span style="font-size:16px;">数据在IRC上进行回放</span></p></td></tr><tr><td><p><span style="font-size:16px;">File Roll Sink</span></p></td><td><p><span style="font-size:16px;">存储数据到本地文件系统</span></p></td></tr><tr><td><p><span style="font-size:16px;">Null Sink</span></p></td><td><p><span style="font-size:16px;">丢弃到所有数据</span></p></td></tr><tr><td><p><span style="font-size:16px;">HBase Sink</span></p></td><td><p><span style="font-size:16px;">数据写入HBase数据库 </span></p></td></tr><tr><td><p><span style="font-size:16px;">Morphline Solr Sink</span></p></td><td><p><span style="font-size:16px;">数据发送到Solr搜索服务器（集群）</span></p></td></tr><tr><td><p><span style="font-size:16px;">ElasticSearch Sink</span></p></td><td><p><span style="font-size:16px;">数据发送到Elastic Search搜索服务器（集群）</span></p></td></tr><tr><td><p><span style="font-size:16px;">Kite Dataset Sink</span></p></td><td><p><span style="font-size:16px;">写数据到Kite Dataset，试验性质的</span></p></td></tr><tr><td><p><span style="font-size:16px;">Custom Sink</span></p></td><td><p><span style="font-size:16px;">自定义Sink实现</span></p></td></tr></tbody></table></div><p><span style="font-size:16px;">      Flume<span style="font-family:'宋体';">提供了大量内置的</span><span style="font-family:Calibri;">Source</span><span style="font-family:'宋体';">、</span>Channel<span style="font-family:'宋体';">和</span>Sink<span style="font-family:'宋体';">类型。不同类型的</span><span style="font-family:Calibri;">Source,</span>Channel<span style="font-family:'宋体';">和</span>Sink<span style="font-family:'宋体';">可以自由组合。</span><span style="color:rgb(0,112,192);"><span style="font-family:'宋体';">组合方式基于用户设置的配置文件，非常灵活。</span></span><span style="font-family:'宋体';">比如：</span>Channel<span style="font-family:'宋体';">可以把事件暂存在内存里，也可以持久化到本地硬盘上。</span>Sink<span style="font-family:'宋体';">可以把日志写入</span>HDFS, HBase<span style="font-family:'宋体';">，甚至是另外一个</span><span style="font-family:Calibri;">Source</span><span style="font-family:'宋体';">等等。</span><span style="font-family:Calibri;">Flume</span><span style="font-family:'宋体';">支持用户建立多级流，也就是说，多个</span>Agent<span style="font-family:'宋体';">可以协同工作，并且支持</span>Fan-in<span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Fan-out</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Contextual Routing</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">Backup Routes</span>。<span style="font-family:'宋体';">如下图所示</span>:</span></p><p align="center"><span style="font-size:16px;"><img src="https://img-blog.csdn.net/20180610191144640?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIxNzgxOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""> </span></p><p><strong><span style="font-size:16px;">小结：</span></strong></p><p><span style="font-size:16px;">       Flume<span style="font-family:'宋体';">是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。支持在日志系统中定制各类数据发送方，用于收集数据</span><span style="font-family:Calibri;">;</span><span style="font-family:'宋体';">同时，</span><span style="font-family:Calibri;">Flume</span><span style="font-family:'宋体';">提供对数据进行简单处理，并写到各种数据接受方</span><span style="font-family:Calibri;">(</span><span style="font-family:'宋体';">比如文本、</span>HDFS<span style="font-family:'宋体';">、</span>Hbase<span style="font-family:'宋体';">等</span><span style="font-family:Calibri;">)</span><span style="font-family:'宋体';">的能力。</span></span></p><p><span style="font-size:16px;">      Flume<span style="font-family:'宋体';">的数据流由事件</span><span style="font-family:Calibri;">(Event)</span><span style="font-family:'宋体';">贯穿始终。事件是</span><span style="font-family:Calibri;">Flume</span><span style="font-family:'宋体';">的基本数据单位，它携带日志数据</span>（<span style="font-family:'宋体';">字节数组形式</span>）<span style="font-family:'宋体';">并且携带有头信息，这些</span>Event<span style="font-family:'宋体';">由</span><span style="font-family:Calibri;">Agent</span><span style="font-family:'宋体';">外部的</span><span style="font-family:Calibri;">Source</span><span style="font-family:'宋体';">生成，当</span><span style="font-family:Calibri;">Source</span><span style="font-family:'宋体';">捕获事件后会进行特定的格式化，然后</span><span style="font-family:Calibri;">Source</span><span style="font-family:'宋体';">会把事件推入</span><span style="font-family:Calibri;">(</span><span style="font-family:'宋体';">单个或多个</span><span style="font-family:Calibri;">)</span>Channel<span style="font-family:'宋体';">中。你可以把</span>Channel<span style="font-family:'宋体';">看作是一个缓冲区，它将保存事件直到</span>Sink<span style="font-family:'宋体';">处理完该事件。</span><span style="font-family:Calibri;">Sink</span><span style="font-family:'宋体';">负责持久化日志或者把事件推向另一个</span><span style="font-family:Calibri;">Source</span><span style="font-family:'宋体';">。</span></span></p><p><span style="font-size:16px;"><span style="font-family:'宋体';">  当节点出现故障时，日志能够被传送到其他节点上而不会丢失。</span>Flume<span style="font-family:'宋体';">提供了三种级别的可靠性保障，从强到弱依次分别为：</span></span></p></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><span style="font-size:16px;">Ø end-to-end：<span style="font-family:'宋体';">收到数据</span>agent<span style="font-family:'宋体';">首先将</span><span style="font-family:Calibri;">event</span><span style="font-family:'宋体';">写到磁盘上，当数据传送成功后，再删除；如果数据发送失败，可以重新发送</span></span></p></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><span style="font-size:16px;">Ø Store on failure：<span style="font-family:'宋体';">这也是</span>scribe<span style="font-family:'宋体';">采用的策略，当数据接收方</span><span style="font-family:Calibri;">crash</span><span style="font-family:'宋体';">时，将数据写到本地，待恢复后，继续发送</span></span></p></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p></p><p><span style="font-size:16px;">Ø Best effort：<span style="font-family:'宋体';">数据发送到接收方后，不会进行确认</span>。</span></p></blockquote></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p><br></p></blockquote></blockquote><h3><strong><span style="font-size:16px;">1.3 Flume<span style="font-family:'宋体';">采集系统结构图</span></span></strong></h3><h4><strong><span style="font-size:16px;">1. <span style="font-family:'宋体';">简单结构</span></span></strong></h4><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p><span style="font-size:16px;"><span style="font-family:'宋体';">单个</span>agent<span style="font-family:'宋体';">采集数据</span></span></p><p><span style="font-size:16px;"> <img src="https://img-blog.csdn.net/20180610185905771?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIxNzgxOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></span></p><p><span style="font-size:16px;"><br></span></p></blockquote><h4><strong><span style="font-size:16px;">2. <span style="font-family:'宋体';">复杂结构</span></span></strong></h4><p><span style="font-size:16px;"><span style="font-family:'宋体';">多级</span>agent<span style="font-family:'宋体';">之间串联</span></span></p><p><span style="font-size:16px;"> <img src="https://img-blog.csdn.net/20180610185934517?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIxNzgxOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></span></p><p><br></p><h4><strong><span style="font-size:16px;">二、 Flume<span style="font-family:'宋体';">的安装部署</span></span></strong></h4><p><span style="font-size:16px;">1、Flume<span style="font-family:'宋体';">的安装非常简单，只需要解压即可，当然，前提是已有</span><span style="font-family:Calibri;">hadoop</span><span style="font-family:'宋体';">环境</span></span></p><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p><span style="font-size:16px;">上传安装包到数据源所在节点上</span></p><p><span style="font-size:16px;">然后解压  tar -zxvf apache-flume-1.6.0-bin.tar.gz</span></p><p><span style="font-size:16px;"><span style="font-family:'宋体';">然后进入</span>flume<span style="font-family:'宋体';">的目录，修改</span><span style="font-family:Calibri;">conf</span><span style="font-family:'宋体';">下的</span><span style="font-family:Calibri;">flume-env.sh</span><span style="font-family:'宋体';">，在里面配置</span><span style="font-family:Calibri;">JAVA_HOME</span></span></p></blockquote><p><span style="font-size:16px;">2<span style="font-family:'宋体';">、根据数据采集的</span>需求<strong>配置采集方案</strong>，描述在配置文件中(<span style="font-family:'宋体';">文件名可任意自定义</span><span style="font-family:Calibri;">)</span></span></p><p><span style="font-size:16px;">3<span style="font-family:'宋体';">、</span><strong>指定采集方案配置文件</strong><span style="font-family:'宋体';">，在相应的节点上启动</span>flume agent</span></p><p><span style="font-size:16px;"> </span></p><p><span style="font-size:16px;">先用一个最简单的例子来测试一下程序环境是否正常</span></p><p><span style="font-size:16px;">1、<span style="font-family:'宋体';">先在</span>flume<span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">conf</span><span style="font-family:'宋体';">目录下新建一个文件</span></span></p><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p><span style="font-size:16px;">vi   netcat-logger.conf</span></p></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><table border="1" cellspacing="0"><tbody><tr><td valign="top"><p><span style="font-size:16px;"># <span style="font-family:'宋体';">定义这个</span><span style="font-family:Calibri;">agent</span><span style="font-family:'宋体';">中各组件的名字</span></span></p><p><span style="font-size:16px;">a1.sources = r1</span></p><p><span style="font-size:16px;">a1.sinks = k1</span></p><p><span style="font-size:16px;">a1.channels = c1</span></p><p><span style="font-size:16px;"> </span></p><p><span style="font-size:16px;"># <span style="font-family:'宋体';">描述和配置</span><span style="font-family:Calibri;">source</span><span style="font-family:'宋体';">组件：</span><span style="font-family:Calibri;">r1</span></span></p><p><span style="font-size:16px;">a1.sources.r1.type = netcat</span></p><p><span style="font-size:16px;">a1.sources.r1.bind = localhost</span></p><p><span style="font-size:16px;">a1.sources.r1.port = 44444</span></p><p><span style="font-size:16px;"> </span></p><p><span style="font-size:16px;"># <span style="font-family:'宋体';">描述和配置</span><span style="font-family:Calibri;">sink</span><span style="font-family:'宋体';">组件：</span><span style="font-family:Calibri;">k1</span></span></p><p><span style="font-size:16px;">a1.sinks.k1.type = logger</span></p><p><span style="font-size:16px;"> </span></p><p><span style="font-size:16px;"># <span style="font-family:'宋体';">描述和配置</span><span style="font-family:Calibri;">channel</span><span style="font-family:'宋体';">组件，此处使用是内存缓存的方式</span></span></p><p><span style="font-size:16px;">a1.channels.c1.type = memory</span></p><p><span style="font-size:16px;">a1.channels.c1.capacity = 1000</span></p><p><span style="font-size:16px;">a1.channels.c1.transactionCapacity = 100</span></p><p><span style="font-size:16px;"> </span></p><p><span style="font-size:16px;"># <span style="font-family:'宋体';">描述和配置</span><span style="font-family:Calibri;">source  channel   sink</span><span style="font-family:'宋体';">之间的连接关系</span></span></p><p><span style="font-size:16px;">a1.sources.r1.channels = c1</span></p><p><span style="font-size:16px;">a1.sinks.k1.channel = c1</span></p></td></tr></tbody></table></blockquote><p><span style="font-size:16px;"> </span></p><p><span style="font-size:16px;">2、<span style="font-family:'宋体';">启动</span>agent<span style="font-family:'宋体';">去采集数据</span></span></p><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><table border="1" cellspacing="0"><tbody><tr><td valign="top"><p><span style="font-size:16px;">bin/flume-ng agent -c conf -f conf/netcat-logger.conf -n a1  -Dflume.root.logger=INFO,console</span></p></td></tr></tbody></table></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p><span style="font-size:16px;">-c conf   <span style="font-family:'宋体';">指定</span><span style="font-family:Calibri;">flume</span><span style="font-family:'宋体';">自身的配置文件所在目录</span></span></p><p><span style="font-size:16px;">-f conf/netcat-logger.con  <span style="font-family:'宋体';">指定我们所描述的采集方案</span></span></p><p><span style="font-size:16px;">-n a1  <span style="font-family:'宋体';">指定我们这个</span><span style="font-family:Calibri;">agent</span><span style="font-family:'宋体';">的名字</span></span></p><p><span style="font-family:'宋体';"><span style="font-size:16px;"><br></span></span></p></blockquote><p><span style="font-size:16px;">3、测试</span></p><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p><span style="font-size:16px;"><span style="font-family:'宋体';">先要往</span>agent<span style="font-family:'宋体';">采集监听的端口上发送数据，让</span><span style="font-family:Calibri;">agent</span><span style="font-family:'宋体';">有数据可采</span></span></p><p><span style="font-size:16px;"><span style="font-family:'宋体';">随便在一个能跟</span>agent<span style="font-family:'宋体';">节点联网的机器上</span></span></p><p><span style="font-size:16px;">telnet anget-hostname  port   <span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">telnet localhost 44444</span><span style="font-family:'宋体';">） </span></span></p><p><span style="font-size:16px;"> </span></p></blockquote><p><span style="font-size:16px;"> </span></p>            </div>
                </div>