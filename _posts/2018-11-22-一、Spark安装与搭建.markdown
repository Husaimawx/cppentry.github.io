---
layout:     post
title:      一、Spark安装与搭建
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>本文介绍安装mac单机版的spark，和spark 集群安装 分以下步骤</p>

<ul><li>安装scala </li>
	<li>下载spark 压缩包并解压</li>
	<li>修改spark的配置文件</li>
	<li>配置环境变量</li>
	<li>验证安装情况 
	<hr></li>
</ul><h1 id="安装scala"><a name="t0"></a>安装Scala</h1>

<p><a href="http://blog.csdn.net/u012373815/article/details/53231292" rel="nofollow">mac安装scala教程</a></p>

<hr><h1 id="下载spark压缩包并解压"><a name="t1"></a>下载spark压缩包并解压</h1>

<p>到官网下载spark的安装包（我用的是spark-2.0.1-bin-hadoop2.7.tgz）</p>

<p><a href="http://mirror.bit.edu.cn/apache/spark/" rel="nofollow">http://mirror.bit.edu.cn/apache/spark/</a></p>

<p>进入安装包存放目录，解压安装包 </p>

<pre class="has">
<code>tar -zxvf  spark-2.0.1-bin-hadoop2.7.tgz</code></pre>

<ul><li>1</li>
</ul><p>解压后进入conf 文件夹下将 spark-env.sh.template 改名为 spark-env.sh</p>

<pre class="has">
<code>mv spark-env.sh.template spark-env.sh</code></pre>

<ul><li>1</li>
</ul><p>操作如下图</p>

<p><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20161118100339825"></p>

<hr><h1 id="单机版安装"><a name="t2"></a>单机版安装</h1>

<h2 id="修改spark的配置文件"><a name="t3"></a>修改spark的配置文件</h2>

<p>修改 spark-env.sh 文件添加信息</p>

<pre class="has">
<code>vi spark-env.sh
//添加如下信息

export SCALA_HOME=/Users/yangyibo/Software/scala
export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home
export SPARK_MASTER_IP=192.168.100.176
export SPARK_WORKER_MEMORY=512m 
export master=spark://192.168.100.176:7070
</code></pre>

<ul><li>1</li>
	<li>2</li>
	<li>3</li>
	<li>4</li>
	<li>5</li>
	<li>6</li>
	<li>7</li>
	<li>8</li>
	<li>9</li>
</ul><p>如下图 <br><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20161118101226217"></p>

<p><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20161118101241454"></p>

<hr><p>修改 slaves.template 添加信息</p>

<pre class="has">
<code>vi slaves.template
//添加如下信息
master</code></pre>

<ul><li>1</li>
	<li>2</li>
	<li>3</li>
</ul><p>如下图 <br><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20161118101411422"></p>

<p><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20161118101423017"></p>

<hr><h2 id="配置环境变量"><a name="t4"></a>配置环境变量</h2>

<p>Mac修改 .bash_profile 文件，此文件是mac 当前用户的环境配置文件。</p>

<p>/etc/profile 是当前系统的环境配置文件（Linux，系统可修改这个）</p>

<p>.bash_profile 文件的路径是在当前用户下。</p>

<p>操作如下：</p>

<p>新打开终端输入命令</p>

<pre class="has">
<code>vi .bash_profile
//添加如下信息
#SPARK VARIABLES START
export SPARK_HOME=/Users/yangyibo/Software/spark-2.0.1-bin-hadoop2.7
export PATH=$PATH:$SPARK_HOME/bin</code></pre>

<ul><li>1</li>
	<li>2</li>
	<li>3</li>
	<li>4</li>
	<li>5</li>
</ul><p>如下图，mac 注意路径哦，</p>

<p><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20161118102430530"></p>

<p><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20161118102639141"></p>

<hr><h1 id="集群安装"><a name="t5"></a>集群安装</h1>

<h2 id="修改slaves"><a name="t6"></a>修改slaves</h2>

<p>集群安装与单机版安装相同 只是在修改 slaves.template 添加信息</p>

<pre class="has">
<code>vi slaves.template
//添加work 节点ip如下信息
192.168.100.23
192.168.100.24
192.168.100.25</code></pre>

<ul><li>1</li>
	<li>2</li>
	<li>3</li>
	<li>4</li>
	<li>5</li>
</ul><h2 id="将配置好的单机版spark复制到work节点上"><a name="t7"></a>将配置好的单机版spark复制到work节点上</h2>

<pre class="has">
<code>// 当然节点机器的 scala 和 jdk 的安装配置要和 master 相同
scp -rp /opt/apps/scala-2.11.7 root@work1IP:/opt/apps
scp -rp /opt/apps/jdk/current root@work1IP:/opt/apps
scp -rp /opt/apps/spark-2.2.1 root@work1IP:/opt/apps</code></pre>

<ul><li>1</li>
	<li>2</li>
	<li>3</li>
	<li>4</li>
</ul><h1 id="验证安装情况"><a name="t8"></a>验证安装情况</h1>

<p>此时就可以检验成果喽</p>

<p>进入安装包的sbin 目录执行 start-all.sh 脚本</p>

<pre class="has">
<code>./start-all.sh</code></pre>

<ul><li>1</li>
</ul><p><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20161118103228604"></p>

<p>此时可能会出现这个情况，我们可以直接忽略</p>

<p><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20161118103039619"></p>

<p>此时我们可以通过jps 命令 检验运行情况</p>

<p><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20161118103538232"></p>

<p>打开Spark Master 页面查看集群情况，我相信你会直接点击。</p>

<p><a href="http://localhost:8080/" rel="nofollow">http://localhost:8080/</a></p>

<p>如图</p>

<p><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20161118103749875"></p>

<hr><p>停止spark  <br>
进入spark的sbin目录，执行命令</p>

<pre class="has">
<code>$ ./stop-all.sh</code></pre>

<ul><li>1</li>
</ul><hr><p>如果要给已经启动的spark 集群附加 worker 节点的话 按照集群配置以后 进入sbin 目录以后： <br>
通过start-slave.sh 脚本 启动一个 slave</p>

<pre class="has">
<code> sh start-slave.sh spark://192.168.100.xx:7077</code></pre>

<ul><li>1</li>
</ul><p>接下来就是spark 的小程序了 <br><a href="http://blog.csdn.net/u012373815/article/details/53231580" rel="nofollow">Spark进阶体验</a></p>            </div>
                </div>