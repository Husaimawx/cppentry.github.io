---
layout:     post
title:      hadoop入门和简易分布式搭建
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/hu948162999/article/details/39059755				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<h3 style="color:#FFFFFF;font-family:verdana, geneva, arial, helvetica, sans-serif;font-size:15pt;font-weight:bolder;background-color:rgb(128,128,128);">
<strong><span style="font-family:Cambria;">&lt;1&gt;. Hadoop简介 </span></strong></h3>
<div><span style="font-family:Cambria;"><span style="font-size:14px;">     <a href="http://hadoop.apache.org/" rel="nofollow">hadoop</a>是apache的开源项目，山寨版的google</span></span></div>
<div><span style="font-family:Cambria;"><span style="font-size:14px;"></span></span>
<p>其中包含：</p>
<p>1. HDFS：分布式的文件系统  --  山寨版GFS（google文件系统）</p>
<p>2. Map-reduce 思想：计算PR （PageRank）：就是山寨版计算PageRank算法</p>
<p>3. Hbase ：就是山寨版的BigTable</p>
<p><br></p>
<p>过程：   数据存储：HDFS<br><span></span>数据处理：MapReduse</p>
<p></p>
<h3 style="color:#FFFFFF;font-family:verdana, geneva, arial, helvetica, sans-serif;font-size:15pt;font-weight:bolder;background-color:rgb(128,128,128);">
<strong><span style="font-family:Cambria;">&lt;2&gt;. Hadoop环境建立 </span></strong></h3>
<p></p>
<p>Linux和Windows所需软件包括:</p>
<ol><li>JDK，必须安装，建议选择Sun公司发行的Java版本。 </li><li><strong>ssh</strong> 必须安装并且保证 <strong>sshd</strong>一直运行，以便用Hadoop 脚本管理远端Hadoop守护进程。</li></ol><p>Windows下的附加软件需求<span style="font-size:12px;">    window安装hadoop的情况：</span></p>
<span></span>用cygwin 模拟nuix 环境  vi等命令<br><span></span>最重要的是 win不支持ssh通讯，微软巨坑，吐槽。。
<p><br></p>
<p>鄙人电脑4G发烧机。内存不足，推荐装两个虚拟机。给每个512内存。简单的分布式（非伪分布式）<span style="font-size:12px;">部署节点 ：一个主机master（768M），一个副机slave（256M）。</span></p>
<p>虚拟机软件下载地址：https://download3.vmware.com/software/wkst/file/VMware-workstation-full-10.0.0-1295980.exe <br>
64位操作系统下载地址：http://mirror.nsc.liu.se/centos-store/6.4/isos/x86_64/CentOS-6.4-x86_64-bin-DVD1.iso<br>
32位操作系统下载地址：http://mirror.nsc.liu.se/centos-store/6.4/isos/i386/CentOS-6.4-i386-bin-DVD1.iso<br></p>
<p><br></p>
<p>装好虚拟机之后</p>
<p>1：设置虚拟机网络</p>
<p>保证两台虚拟能连上互联网、能互相通讯、ping互相IP----不懂发邮件</p>
<p>2：禁用Selinux</p>
<p><strong>3：关闭防火墙</strong><br>
–service iptablesstop<br>
–chkconfigiptablesoff restart   ----永久性关闭防火墙</p>
<p>4：配置时钟同步</p>
<p>不安装Hbase的童鞋就不用了。</p>
<p>5：修改主机hostname</p>
<p>–vi /etc/sysconfig/network<br></p>
<p><strong>6：修改hosts映射</strong><br>
–vi /etc/hosts</p>
<p><strong>7：安装JDK：注意虚拟机版本是64为还是32位</strong><br></p>
<p><br></p>
<strong>8：配置主从节点SSH互信</strong></div>
<div>这一步很关键：分布式安装是 追加式的</div>
<div><br></div>
<div>理解：用pub 公钥加载的 只有私钥才能解密<br>
用私钥加密的 只有公钥才能解密<br><br>
----整理了一份很详细的ssh无密码配置。<br></div>
<div><br><h2><strong>一：<span> </span>安装和启动SSH</strong></h2>
步骤1<span> </span>以root用户登录到host1服务器。<br>
步骤2<span> </span>执行如下命令，查看是否安装ssh。<br>
$ rpm -qa | grep ssh<br>
屏幕显示如下：<br>
openssh-5.3p1-70.el6.x86_64<br>
libssh2-1.2.2-7.el6_1.1.x86_64<br>
openssh-server-5.3p1-70.el6.x86_64<br>
openssh-clients-5.3p1-70.el6.x86_64<br><br>
$ rpm -qa | grep rsync<br>
屏幕显示如下：<br>
rsync-3.0.6-5.el6_0.1.x86_64<br>
步骤3<span> </span>如果没有安装ssh和rsync，可以通过如下命令进行安装。（需要配置yum源）<br>
$ yum install ssh<br>
$ yum install rsync<br>
步骤4<span> </span>执行如下命令，查看ssh是否已经启动。<br>
$ service sshd status<br>
屏幕显示如下：<br>
openssh-daemon is stopped<br>
步骤5<span> </span>执行如下命令，启动ssh。<br>
$ service sshd start<br>
屏幕显示如下：<br>
Starting sshd:    [  OK  ]<br>
步骤6<span> </span>重复以上步骤，在192、193和195服务器上安装和启动SSH。<br><br><br><h2><strong>二：<span> </span>配置SSH无密码验证</strong></h2>
</div>
<div> 每一个节点在hadoop体系中就是一个java进程，如果在一个节点上回车start all 启动所有集群命令。之所以能全部启动，就是因为能远程登录到其他节点启动</div>
<div><br></div>
<div><strong>------简单来说 就是把自己的authorized_keys 追加到对方的authorized_keys上面，对方的都追加到自己的authorized_keys下面</strong></div>
<div><br>
步骤1<span> </span>以root用户登录到host1服务器。<br>
步骤2<span> </span>执行如下命令，生成密钥。<br>
$ ssh-keygen -t rsa<br><br>
以上命令用于生成无密码密钥对，询问其保存路径时直接回车采用默认路径。生成的密钥对：id_rsa和id_rsa.pub，默认存储在/root/.ssh目录下。<br>
步骤3<span> </span>执行如下命令，将id_rsa.pub文件内容追加到authorized_keys文件中。</div>
<div>$ cat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys</div>
<div><br>
步骤4<span> </span>执行如下命令，将/root/.ssh/authorized_keys文件权限设置为600。</div>
<div>$ chmod 600 /root/.ssh/authorized_keys</div>
<div><br>
步骤5<span> </span>执行如下命令，验证ssh无密码验证设置是否成功。<br>
$ ssh root@host1</div>
<div><br>
步骤6<span> </span>重复以上步骤，在host2 ,host3服务器上生成密钥对并进行配置。</div>
<div><br>
步骤7<span> </span>执行如下命令，将host1服务器上/root/.ssh/authorized_keys文件拷贝到其他服务器<br>
上的/root/.ssh/目录下。<br>
$ scp /root/.ssh/authorized_keys root@host2:/root/.ssh/authorized_keys_host2<br>
$ scp /root/.ssh/authorized_keys root@host3:/root/.ssh/authorized_keys_host3<br>
为了不覆盖原来服务器上的authorized_keys文件，在拷贝的时候指定文件名，如：authorized_keys_主机名。</div>
<div><br>
步骤8<span> </span>重复步骤7，将host2服务器上/root/.ssh/authorized_keys文件拷贝到其他服务器</div>
<div>$ scp /root/.ssh/authorized_keys root@host1:/root/.ssh/authorized_keys_host1<br>
$ scp /root/.ssh/authorized_keys root@host3:/root/.ssh/authorized_keys_host3</div>
<div><br>
步骤9<span> </span><span style="font-size:12px;">重复步骤7，将host3服务器上/root/.ssh/authorized_keys文件拷贝到其他服务器</span>
<div>$ scp /root/.ssh/authorized_keys root@host1:/root/.ssh/authorized_keys_host1<br>
$ scp /root/.ssh/authorized_keys root@host2:/root/.ssh/authorized_keys_host2</div>
<br>
步骤10<span> </span>分别在host1、host2、host3 服务器上执行如下命令，将密钥追加到authorized_keys。<br>
$ cat /root/.ssh/authorized_keys_* &gt;&gt; /root/.ssh/authorized_keys</div>
<div><br><br><h2><strong>三：配置启动hadoop</strong></h2>
</div>
<div>1、下载http://archive.apache.org/dist/hadoop/core/hadoop-0.20.2/ hadoop-0.20.2.tar.gz<br>
2、放到bin目录下并解压<br>
cd /bin/<br>
tar -xzvf hadoop-0.20.2.tar.gz<br>
cd /bin/hadoop-0.20.2/conf/<br>
修改hadoop-env.sh： vi hadoop-env.sh <br>
默认是被注释的，去掉注释，把JAVA_HOME 改成现有java安装目录</div>
<div><br></div>
<div>3、修改hdfs的配置相关文件<br><strong>core-site.xml  namenode配置</strong></div>
<div><pre><code class="language-html">&lt;configuration&gt;
	&lt;property&gt;
	    &lt;!-- namenode 所在的节点--&gt;
		&lt;name&gt;fs.default.name&lt;/name&gt;
		&lt;value&gt;hdfs://host1:9000&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
	    &lt;!-- 设置hadoop的工作目录，默认在linux的tmp目录，linux的tmp目录，每次重启都清空，其它一些目录（hdfs）都是以这些目录为基本目录的--&gt;
		&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
		&lt;value&gt;/usr/java/hadoop-1.2&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;</code></pre><br><strong>hdfs-site.xml  hdfs配置</strong></div>
<div><pre><code class="language-html">&lt;configuration&gt;
    &lt;property&gt;
	    &lt;!-- hdfs的配置文件，配置几个副本数，hdfs的规则是一个节点只能有一个副本。--&gt;
		&lt;!-- 伪分布式的情况下，只能为1，由于我配置的是两台，则那么只能配置2个副本 --&gt;
		&lt;name&gt;dfs.replication&lt;/name&gt;
		&lt;value&gt;2&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;</code></pre><br><strong>slaves           指定哪些为datanode<br></strong></div>
<div><pre><code class="language-html">host2
host3</code></pre></div>
<div><strong><br></strong></div>
<div><strong>masters        指定哪些为secondaryNameNode<br></strong></div>
<div><pre><code class="language-html">host2</code></pre>
<div><br></div>
这个时候就可以启动hdfs了；</div>
<div><pre><code class="language-html">bin/start-dfs.sh</code></pre>
<div><br></div>
4、OK，现在可以基于hadoop的启动离线计算框架 Map-Reduce了。<br><strong>mapred-site.xml  是map-reduce的核心配置文件</strong></div>
<div><pre><code class="language-html">&lt;configuration&gt;

     &lt;property&gt;
        &lt;!-- 指定jobtracker --&gt;
        &lt;name&gt;mapred.job.tracker&lt;/name&gt;
        &lt;value&gt;host1:9001&lt;/value&gt;
     &lt;/property&gt;

&lt;/configuration&gt;</code></pre><br>
将已经配置好的将已经配置好的hadoop-0.20.2，拷贝到其他虚拟机上<br>
scp -r /bin/hadoop-0.20.2 root@hadoops:/bin/ Hadoop云计算 http://tianhailong.com/ 33<br>
进入hadoop bin目录：cd /bin/hadoop-0.20.2/bin/<br>
Hadoop集群搭建验证<br>
格式化hadoop：hadoop namenode –format<br>
启动hadoop：./start-all.sh<br>
在master节点，输入jps，查看启动服务进程：<br>
Slave节点，输入jps：<br></div>
<div><br></div>
<div><br></div>
<div><strong>最后：做一个小案例，计算圆周率</strong></div>
<div><strong>./hadoop jar /bin/hadoop-0.20.2/hadoop-0.20.2-examples.jar pi 20 50</strong></div>
<div><strong><br></strong></div>
<div><br></div>
            </div>
                </div>