---
layout:     post
title:      1.Flume简介
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<h1><span style="font-size:24px;color:#ffffff;background-color:rgb(51,51,153);">什么是flume</span></h1>
<p><span style="font-size:14px;">flume是apache的一个<span style="color:#ff0000;">数据收集框架</span>。定义了一个数据流的模型。下面这张图hadoop业务开发流程图可以说明Flume的重要性：</span></p>
<p><img src="https://img-blog.csdn.net/20170310211106440" alt=""><br></p>
<p><span style="font-size:14px;">Flume是一个分布式、可靠、和<span><span>高可用</span></span>的海量日志聚合的系统，支持在系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。apache Flume 是一个从可以收集例如日志，事件等数据资源，并将这些数量庞大的数据从各项数据资源中集中起来存储的工具/服务，或者数集中机制。其设计的原理也是基于将数据流，如日志数据从各种网站服务器上汇集起来存储到HDFS，HBase等集中存储器中。其结构如下图所示：</span></p>
<p><img src="https://img-blog.csdn.net/20170310211115552" alt=""><br></p>
<p><br></p>
<h1><span style="font-size:24px;color:#ffffff;background-color:rgb(51,51,153);">Flume架构</span></h1>
<p><span style="color:rgb(51,51,51);font-family:'Helvetica Neue', Helvetica, Tahoma, Arial, STXihei, 'Microsoft YaHei', '微软雅黑', sans-serif;line-height:27.200000762939453px;text-indent:16px;background-color:rgb(254,254,254);"><span style="font-size:14px;">Flume以agent为最小的独立运行单位。一个agent就是一个JVM。单agent由Source、Sink和Channel三大组件构成</span></span><span style="color:rgb(51,51,51);font-family:'Helvetica Neue', Helvetica, Tahoma, Arial, STXihei, 'Microsoft YaHei', '微软雅黑', sans-serif;font-size:16px;line-height:27.200000762939453px;text-indent:16px;background-color:rgb(254,254,254);">，<span style="font-size:14px;text-indent:16px;">agent里面包含3个核心的组件：source—-&gt;channel—–&gt;sink,类似生产者、仓库、消费者的架构。</span></span><br></p>
<p><img src="https://img-blog.csdn.net/20170310212312037" alt=""></p>
<h1><span style="font-family:'Helvetica Neue', Helvetica, Tahoma, Arial, STXihei, 'Microsoft YaHei', '微软雅黑', sans-serif;line-height:1.6em;text-indent:1em;background-color:rgb(51,51,153);"><span style="font-size:24px;color:#ffffff;">Flume的一些核心概念：</span></span></h1>
<p><span style="font-size:14px;">Agent：使用JVM 运行Flume。每台机器运行一个agent，但是可以在一个agent中包含多个sources和sinks。<br>
Client：生产数据，运行在一个独立的线程。<br>
Source：从Client收集数据，传递给Channel。<br>
Sink<span> </span>从Channel收集数据，运行在一个独立线程。<br>
Channel：连接 sources 和 sinks ，这个有点像一个队列。<br>
Events：可以是日志记录、 avro 对象等。<br></span></p>
<h1><span style="font-size:24px;color:#ffffff;background-color:rgb(51,51,153);">Flume运行流程：</span></h1>
<p><span style="font-size:14px;">Flume的数据流由事件(Event)贯穿始终。事件是Flume的基本数据单位，它携带日志数据(字节数组形式)并且携带有头信息，这些Event由Agent外部的Source，比如上图中的Web Server生成。当Source捕获事件后会进行特定的格式化，然后Source会把事件推入(单个或多个)Channel中。你可以把Channel看作是一个缓冲区，它将保存事件直到Sink处理完该事件。Sink负责持久化日志或者把事件推向另一个Source。</span><span style="font-size:14px;text-indent:16px;">flume之所以这么神奇，是源于它自身的一个设计，这个设计就是agent，agent本身是一个</span><a href="http://lib.csdn.net/base/javase" rel="nofollow" class="replace_word" title="Java SE知识库" style="font-size:14px;text-indent:16px;">Java</a><span style="font-size:14px;text-indent:16px;">进程，运行在日志收集节点。</span></p>
<h1><span style="text-indent:16px;background-color:rgb(51,51,153);"><span style="font-size:24px;color:#ffffff;">三大组件介绍：</span></span></h1>
<p></p>
<h2><span style="font-size:14px;">Source:</span></h2>
<p></p>
<p><span style="font-size:14px;">从数据发生器接收数据,并将接收的数据以Flume的event格式传递给一个或者多个通道channal,Flume提供多种数据接收的方式,比如Avro,Thrift,twitter1%等</span></p>
<h2><span style="font-size:14px;">Channel:</span></h2>
<p><span style="font-size:14px;">channal是一种短暂的存储容器,它将从source处接收到的event格式的数据缓存起来,直到它们被sinks消费掉,它在source和sink间起着一共桥梁的作用,channal是一个完整的事务,这一点保证了数据在收发的时候的一致性. 并且它可以和任意数量的source和sink链接. 支持的类型有: JDBC channel
 , File System channel , Memort channel等.</span></p>
<h2><span style="font-size:14px;">sink:</span></h2>
<p><span style="font-size:14px;">sink将数据存储到集中存储器比如Hbase和HDFS,它从channals消费数据(events)并将其传递给目标地. 目标地可能是另一个sink,也可能HDFS,HBase.</span></p>
<h1><span style="font-size:24px;color:#ffffff;background-color:rgb(51,51,153);">单点Flume配置</span></h1>
<p><span style="font-size:14px;">1.上传解压Flume</span></p>
<p><span style="font-size:14px;">2.修改conf下的flume-env.xml文件</span></p>
<p><span style="font-size:14px;">JAVA_HOME=</span></p>
<p><span style="font-size:14px;">3.创建agentDemo.conf文件放置在conf目录下，添加内容如下：</span></p>
<p></p><pre><code class="language-html">#定义agent名:agentDemo， source、channel、sink的名称分别为r1,c1,k1
agentDemo.sources = r1
agentDemo.channels = c1
agentDemo.sinks = k1

#具体定义source类型，监听的目录
agentDemo.sources.r1.type = spooldir
agentDemo.sources.r1.spoolDir = /home/hadoop/logs

#具体定义channel，类型，容量（容纳多少条数据），事物容量
agentDemo.channels.c1.type = memory
agentDemo.channels.c1.capacity = 10000
agentDemo.channels.c1.transactionCapacity = 100

#定义拦截器，为消息添加时间戳（拦截器还可以拦截无效数据）
agentDemo.sources.r1.interceptors = i1
agentDemo.sources.r1.interceptors.i1.type = org.apache.flume.interceptor.TimestampInterceptor$Builder


#具体定义sink，数据写入位置，地址，数据文件前缀，文件类型（纯文本方式）
agentDemo.sinks.k1.type = hdfs
agentDemo.sinks.k1.hdfs.path = hdfs://ns1/flume/%Y%m%d
agentDemo.sinks.k1.hdfs.filePrefix = events-
agentDemo.sinks.k1.hdfs.fileType = DataStream
#不按照条数生成文件,几条进行写入，0不安条数
agentDemo.sinks.k1.hdfs.rollCount = 0
#HDFS上的文件达到128M时生成一个文件
agentDemo.sinks.k1.hdfs.rollSize = 134217728
#HDFS上的文件达到60秒生成一个文件
agentDemo.sinks.k1.hdfs.rollInterval = 60

#组装source、channel、sink
agentDemo.sources.r1.channels = c1
agentDemo.sinks.k1.channel = c1

</code></pre><span style="font-size:14px;">4.此时不知道其中配置的hdfs：ns1位置</span>
<p><span style="font-size:14px;">将hadoop集群配置中的core-site.xml和hdfs-site.xml拷贝到conf目录下<br></span></p>
<p><span style="font-size:14px;">5.拷贝缺少的hadoop中的jar到flume的lib中</span></p>
<p></p>
<div style="line-height:1.5;"><span style="font-size:14px;">hadoop-hdfs-2.6.5.jar  </span></div>
<div style="line-height:1.5;"><span style="font-size:14px;">hadoop-auth-2.6.5.jar  </span></div>
<div style="line-height:1.5;"><span style="line-height:1.5;"><span style="font-size:14px;">commons-configuration-1.6.jar</span></span></div>
<div style="line-height:1.5;"><span style="font-size:14px;">hadoop-common-2.6.5.jar</span></div>
<p></p>
<p><span style="font-size:14px;">6.别忘记配置文件中的指定目录是否存在，还有集群配置的主机名ip对应关系在本机是否存在</span></p>
<p><span style="font-size:14px;">7.启动Flume</span></p>
<p><span style="font-size:14px;"></span></p><pre><code class="language-html">bin/flume-ng agent -n agentDemo -c conf -f conf/agentDemo.conf -Dflume.root.logger=INFO,console

参数说明： 
-n 指定agent名称(与配置文件中代理的名字相同) 
-c 指定flume中配置文件的目录 
-f 指定配置文件 
-Dflume.root.logger=DEBUG,console 设置日志等级</code></pre>
<p></p>
<div style="font-size:14px;line-height:1.5;"><span style="font-size:16px;font-family:Tahoma;color:rgb(51,51,51);background-color:rgb(254,254,254);">PS：-Dflume.root.logger=INFO,console 仅为 debug 使用，请勿生产环境生搬硬套，否则大量的日志会返回到终端。</span></div>
<div><span style="font-family:Tahoma;color:#333333;"><span style="background-color:rgb(254,254,254);"><span style="font-size:14px;"><span style="line-height:24px;">启动时切记按照官方文档说明启动：</span></span></span></span>
<div style="line-height:1.5;"><pre><code class="language-html">$ bin/flume-ng agent --conf conf --conf-file example.conf --name a1 -Dflume.root.logger=INFO,console</code></pre></div>
<div><span style="line-height:22.5px;"><span style="font-size:14px;">不要cd到bin目录下使用./flume-ng，否则会找不到自带的log4j.properties文件</span></span></div>
<div style="font-size:14px;line-height:1.5;"><span style="font-size:12px;font-family:Tahoma;"></span>
<div style="line-height:1.5;font-size:14px;"><pre><code class="language-html">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
17/03/10 18:37:14 ERROR node.Application: A fatal error occurred while running. Exception follows.
org.apache.commons.cli.ParseException: The specified configuration file does not exist: /hadoop/flume-1.7.0/bin/conf/a4.conf
	at org.apache.flume.node.Application.main(Application.java:316)</code></pre><br></div>
<div style="line-height:1.5;font-size:14px;"><br></div>
</div>
</div>
<span style="font-size:14px;"><span style="color:rgb(51,51,51);font-family:'Helvetica Neue', Helvetica, Tahoma, Arial, STXihei, 'Microsoft YaHei', '微软雅黑', sans-serif;line-height:27.200000762939453px;text-indent:16px;background-color:rgb(254,254,254);">实际环境中有这样的需求，通过在多个agent端tail日志，发送给collector，collector再把数据收集，统一发送给HDFS存储起来，当HDFS文件大小超过一定的大小或者超过在规定的时间间隔会生成一个文件。</span><br></span>
<p></p>
<p><span style="font-size:14px;">多agent汇聚写入到HDFS中流程图：</span></p>
<p><img src="https://img-blog.csdn.net/20170310221612781" alt=""><br></p>
<p><br></p>
<p><br></p>
<p><br></p>
            </div>
                </div>