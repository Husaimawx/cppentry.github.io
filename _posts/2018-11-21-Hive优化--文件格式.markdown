---
layout:     post
title:      Hive优化--文件格式
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/boyu_tung/article/details/52878374				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<h1><a name="_Toc449193966">1.      Hive</a>调优前相关规划设计</h1>
<p>Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供Hive SQL（简称HQL）查询功能，可以将HQL语句转换为MapReduce、Tez、Spark任务运行。本文仅讨论Hive on MapReduce的性能调优场景。</p>
<p>在进行Hive参数调优和SQL调优之前，要进行相应的规划设计，包括：<strong>Hive表使用高效的文件格式</strong>，<strong>Hive表文件及中间文件使用合适的文件压缩格式</strong>，<strong>根据业务特征创建分区表以及创建分桶表</strong>。</p>
<h2><a name="_Toc449193967"><em>1.1.    Hive</em></a><em>表文件使用高效的文件格式</em></h2>
<p><strong><span style="color:#4F81BD;">（1</span>）建议使用ORC</strong></p>
<p>ORC文件格式可以提供一种高效的方法来存储Hive数据，运用ORC可以提高Hive的读、写以及处理数据的性能。</p>
<p><strong>以下两种场景需要应用方权衡是否使用ORC</strong>：</p>
<p>（a）文本文件加载到ORC格式的Hive表的场景：由于文本格式到ORC，需要耗费较高的CPU计算资源，相比于直接落地成文本格式Hive表而言加载性能会低很多；</p>
<p>（b）Hive表作为计算结果数据，导出给Hadoop之外的外部系统读取使用的场景：ORC格式的结果数据，相比于文本格式的结果数据而言其易读性低很多。</p>
<p><strong>除以上两种场景外，其他场景均建议使用ORC作为Hive表的存储格式。</strong></p>
<p><strong><span style="color:#4F81BD;">（2</span>）考虑使用Parquet</strong></p>
<p>Parquet的核心思想是使用“record shredding and assembly algorithm”来表示复杂的嵌套数据类型，同时辅以按列的高效压缩和编码技术，实现降低存储空间，提高IO效率，降低上层应用延迟。</p>
<p>Parquet是语言无关的，而且不与任何一种数据处理框架绑定在一起，适配多种语言和组件，能够与Parquet配合的组件有：</p>
<p>查询引擎：Hive、Impala、Pig；</p>
<p>计算框架：MapReduce、Spark、Cascading；</p>
<p>数据模型：Avro、Thrift、Protocol Buffers、POJOs。</p>
<p><strong>对于Impala和Hive共享数据和元数据的场景，建议Hive表存储格式为Parquet。</strong></p>
            </div>
                </div>