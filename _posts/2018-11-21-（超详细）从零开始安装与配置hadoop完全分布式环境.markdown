---
layout:     post
title:      （超详细）从零开始安装与配置hadoop完全分布式环境
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，转载请注明地址以方便大家一起学习讨论。					https://blog.csdn.net/wenyun_kang/article/details/77414018				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<blockquote>
  <p><strong>强调！！！</strong></p>
</blockquote>

<p><strong>用户名称要相同，否则可能出现稀奇古怪的错误！！！</strong>（我就因为这个问题，在后面快装完的时候不得不从头再来） <br>
原因：Hadoop要求所有机器上Hadoop的部署目录结构要求相同（因为在启动时按与主节点相同的目录启动其它任务节点），并且都有一个相同的用户名账户。参考各种文档上说的是所有机器都建立一个hadoop用户，使用这个账户来实现无密码认证。 <br>
<img src="https://img-blog.csdn.net/20170819162108711?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="0" title=""></p>

<p>我这里是在虚拟机上新建的系统，即装系统的时候将每个系统的下面这个界面的用户名填成一样的</p>

<p><img src="https://img-blog.csdn.net/20170819194938656?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="同名" title=""></p>

<blockquote>
  <p><strong>一、开发环境</strong></p>
</blockquote>

<p>硬件环境：ubuntu-16.04.3 服务器3台（一台 master 结点，两台 slave 结点），在虚拟机中搭建 <br>
软件环境：jdk1.8.0_144，hadoop-2.8.1 <br>
<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" rel="nofollow" target="_blank">jdk下载（下载对应版本以“.tar.gz”结尾的文件）</a> <br>
<img src="https://img-blog.csdn.net/20170819171629231?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="jdk" title=""></p>

<p><a href="http://www.apache.org/dyn/closer.cgi/hadoop/common" rel="nofollow" target="_blank">hadoop下载（选择图中标记出来的位置的链接）</a> <br>
<img src="https://img-blog.csdn.net/20170819171652577?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="hadoop" title=""></p>

<blockquote>
  <p><strong>二、集群拓扑图</strong></p>
</blockquote>

<p><img src="https://img-blog.csdn.net/20170819170213708?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="集群拓扑图" title=""></p>

<blockquote>
  <p><strong>三、与本地Win7系统共享本地文件</strong></p>
</blockquote>

<p>ps：省去在虚拟机中下载文件，方便很多</p>

<p><em>1、虚拟机设置</em></p>

<p>虚拟机菜单栏 -&gt; 虚拟机 -&gt; 设置 -&gt; 选项 -&gt; 共享文件夹 -&gt; 总是启用 -&gt; 添加（我将添加的共享目录命名为Shared） -&gt;确定</p>

<p><img src="https://img-blog.csdn.net/20170819141654600?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="1" title=""></p>

<p><em>2、VMware Tools安装</em></p>

<p>（1）虚拟机菜单栏 -&gt; 虚拟机 -&gt; 安装VMware Tools <br>
（2）等一会虚拟机会自己打开VMware Tools文件夹 <br>
（3）在该目录下，右键打开命令行，将压缩文件拷贝到桌面上，再到桌面上将其解压缩</p>



<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-keyword">cp</span> VMwareTools-<span class="hljs-number">10.1</span><span class="hljs-number">.6</span>-<span class="hljs-number">5214329.</span>tar<span class="hljs-preprocessor">.gz</span> /home/hadoop/Desktop/
cd /home/hadoop/Desktop/
tar -xzvf VMwareTools-<span class="hljs-number">10.1</span><span class="hljs-number">.6</span>-<span class="hljs-number">5214329.</span>tar<span class="hljs-preprocessor">.gz</span></code></pre>

<p><img src="https://img-blog.csdn.net/20170819140613178?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="2" title=""></p>

<p>（4）成功之后以管理员root身份执行解压缩之后文件目录里的vmware-install.pl文件即可进行安装</p>



<pre class="prettyprint"><code class=" hljs lasso">sudo vmware<span class="hljs-attribute">-tools</span><span class="hljs-attribute">-distrib</span>/vmware<span class="hljs-attribute">-install</span><span class="hljs-built_in">.</span>pl</code></pre>

<p><img src="https://img-blog.csdn.net/20170819141119360?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="3" title=""></p>

<p>（5）一路回车</p>

<p>酱紫就装好了</p>

<p><img src="https://img-blog.csdn.net/20170819142432469?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="4" title=""></p>

<p>（6）共享文件在 /mnt/hgfs/Shared 文件夹下 <br>
ps：Shared是刚添加共享目录时自己起的名字</p>

<p><em>3、将下载好的软件包放到共享文件夹下</em></p>

<blockquote>
  <p><strong>四、JDK的安装与配置</strong></p>
</blockquote>

<p><em>1、解压缩</em></p>

<p>（1）把压缩包拷贝到你想要安装的位置，我要装在 /usr/local 目录下</p>



<pre class="prettyprint"><code class=" hljs avrasm">sudo <span class="hljs-keyword">cp</span> jdk-<span class="hljs-number">8</span>u144-linux-x64<span class="hljs-preprocessor">.tar</span><span class="hljs-preprocessor">.gz</span> /usr/local</code></pre>

<p><img src="https://img-blog.csdn.net/20170819144157920?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="2" title=""></p>

<p>（2）进到对应目录下解压缩</p>



<pre class="prettyprint"><code class=" hljs lasso">cd /usr/<span class="hljs-built_in">local</span>
sudo tar <span class="hljs-attribute">-zxvf</span> jdk<span class="hljs-subst">-</span><span class="hljs-number">8</span>u144<span class="hljs-attribute">-linux</span><span class="hljs-attribute">-x64</span><span class="hljs-built_in">.</span>tar<span class="hljs-built_in">.</span>gz</code></pre>

<p><img src="https://img-blog.csdn.net/20170819144352258?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="3" title=""></p>

<p><em>2、配置环境变量</em></p>

<p>（1）修改配置文件</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">sudo</span> vi /etc/profile</code></pre>

<p>在末尾添加如下配置（Linux命令：G -&gt; o（字母小o） - &gt; 输入以下内容）</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-keyword">export</span> JAVA_HOME=/usr/local/jdk1.<span class="hljs-number">8.0</span>_144
<span class="hljs-keyword">export</span> CLASSPATH=.:<span class="hljs-variable">$JAVA_HOME</span>/lib/tools.jar:<span class="hljs-variable">$JAVA_HOME</span>/lib/dt.jar
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">$JAVA_HOME</span>/bin:<span class="hljs-variable">$PATH</span></code></pre>

<p>（Linux命令：Esc键 - &gt; 输入“:wq”退出）</p>

<p><img src="https://img-blog.csdn.net/20170819144809527?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="4" title=""></p>

<p>（2）重新加载/etc/profile，使配置生效</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">source</span> /etc/profile</code></pre>

<p>（3）检查是否配置成功</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-variable">$PATH</span>
java -version</code></pre>

<p><img src="https://img-blog.csdn.net/20170819145119886?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="5" title=""></p>

<blockquote>
  <p><strong>五、HOST文件配置</strong></p>
</blockquote>

<p>修改集群中<strong>每台服务器</strong>的 hosts 文件，配置主机名和 ip 地址的映射</p>



<pre class="prettyprint"><code class=" hljs ">vi /etc/hosts</code></pre>

<p><img src="https://img-blog.csdn.net/20170914144943808?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="hosts" title=""></p>

<blockquote>
  <p><strong>六、SSH的安装与配置</strong></p>
</blockquote>

<p><strong><em>1、软件安装</em></strong></p>

<p>（1）首先更新源（要确定系统可以联网，可以先打开浏览器访问以下百度主页，如果没连上网，可以试试到Win7系统上 “右键计算机 -&gt; 管理 -&gt; 服务和应用程序 -&gt; 服务 -&gt; 找到VMware相关的所有服务 -&gt; 右键 -&gt; 启动”）</p>

<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">sudo</span> apt-get update</code></pre>

<p>（2）安装 openssh</p>

<ul>
<li>服务端安装</li>
</ul>



<pre class="prettyprint"><code class=" hljs vbscript">sudo apt-<span class="hljs-keyword">get</span> install openssh-<span class="hljs-built_in">server</span></code></pre>

<p><img src="https://img-blog.csdn.net/20170819150602701?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="1" title=""></p>

<ul>
<li>客户端安装</li>
</ul>



<pre class="prettyprint"><code class=" hljs lasso">sudo apt<span class="hljs-attribute">-get</span> install openssh<span class="hljs-attribute">-client</span></code></pre>

<p><img src="https://img-blog.csdn.net/20170819151118529?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="2" title=""></p>

<p><strong>ps：如何区分该装服务端还是客户端？</strong> <br>
如果 slave1 系统想要登录 slave2 系统，那么 slave1 装客户端， slave2 装服务端，如果想要互相都能登录，就服务端和客户端都装</p>

<p>（3）测试是否可以登录</p>



<pre class="prettyprint"><code class=" hljs bash">ssh <span class="hljs-operator">-l</span> hadoop <span class="hljs-number">192.168</span>.<span class="hljs-number">195.133</span></code></pre>

<p>（ssh -l [用户名] [远程ip]） <br>
（ ip 可以用 ifconfig 命令查看）</p>

<p><img src="https://img-blog.csdn.net/20170819152128434?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="3" title=""></p>

<p>到现在，我们已经可以通过密码登录了</p>

<p><strong><em>2、配置免密码登录</em></strong></p>

<p>原理是验证公钥而不验证密码</p>

<p><em>（1）配置本机无密码登录</em></p>

<p>三台服务器均做如下设置</p>

<p>1）进入到宿主目录下，生成本机秘钥同时设置免密登录，<strong>注意，这里不能使用 root 用户生成秘钥，而是要使用你想要设置免密登录的用户</strong></p>



<pre class="prettyprint"><code class=" hljs lasso">cd /home/hadoop<span class="hljs-subst">/</span>
ssh<span class="hljs-attribute">-keygen</span> <span class="hljs-attribute">-t</span> rsa <span class="hljs-attribute">-P</span> <span class="hljs-string">""</span></code></pre>

<p>一路回车</p>

<p><img src="https://img-blog.csdn.net/20170819153226138?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="4" title=""></p>

<p>2）将公钥追加到 authorized_keys 文件中</p>



<pre class="prettyprint"><code class=" hljs avrasm">cat <span class="hljs-preprocessor">.ssh</span>/id_rsa<span class="hljs-preprocessor">.pub</span> &gt;&gt; <span class="hljs-preprocessor">.ssh</span>/authorized_keys</code></pre>

<p>赋予 authorized_keys 文件权限</p>



<pre class="prettyprint"><code class=" hljs perl"><span class="hljs-keyword">chmod</span> <span class="hljs-number">600</span> .ssh/authorized_keys</code></pre>

<p><img src="https://img-blog.csdn.net/20170819153854253?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="5" title=""></p>

<p>3）验证是否成功</p>



<pre class="prettyprint"><code class=" hljs ">ssh localhost</code></pre>

<p><img src="https://img-blog.csdn.net/20170819153907656?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="6" title=""></p>

<p><em>（2）配置 master 无密码登录 slave1 服务器</em></p>

<p>以下操作均在 slave1 服务器上操作</p>

<p>1）复制 master 的公钥到 slave1 上</p>



<pre class="prettyprint"><code class=" hljs ruby">scp hadoop<span class="hljs-variable">@192</span>.<span class="hljs-number">168.195</span>.<span class="hljs-number">130</span><span class="hljs-symbol">:/home/hadoop/</span>.ssh/id_rsa.pub /home/hadoop</code></pre>

<p>（scp master_userName@master_ip:master_file slave1 _folder）</p>

<p><img src="https://img-blog.csdn.net/20170819200439046?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="3" title=""></p>

<p>2）将 master 公钥追加到 slave1 的 authorized_keys 文件中，删除 master 公钥文件</p>



<pre class="prettyprint"><code class=" hljs avrasm">cat /home/hadoop/id_rsa<span class="hljs-preprocessor">.pub</span> &gt;&gt; <span class="hljs-preprocessor">.ssh</span>/authorized_keys
rm /home/hadoop/id_rsa<span class="hljs-preprocessor">.pub</span></code></pre>

<p><img src="https://img-blog.csdn.net/20170819161135742?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="8" title=""></p>

<p>3）验证是否成功（在master服务器上操作）</p>



<pre class="prettyprint"><code class=" hljs ">ssh slave1</code></pre>

<p>（ssh ip 在 /etc/hosts 文件中我们已经将 ip 和主机名做了映射，所以可以直接用主机名代替 ip）</p>

<p><img src="https://img-blog.csdn.net/20170819201425033?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="4" title=""></p>

<p><em>（3）参照上一步，完成以下配置</em> <br>
1）master -&gt; slave2 <br>
2）slave1 -&gt; master <br>
3）slave2 -&gt; master <br>
4）slave1 -&gt; slave2 <br>
5）slave2 -&gt; slave1</p>

<blockquote>
  <p><strong>七、Hadoop完全分布式环境的安装与配置</strong></p>
</blockquote>

<p>除特别说明外，以下操作均在 master 服务器上操作</p>

<p><em>1、创建文件目录</em></p>

<p>为了便于管理，给master的hdfs的NameNode、DataNode及临时文件，在根目录下创建目录： <br>
/data/hdfs/name <br>
/data/hdfs/data <br>
/data/hdfs/tmp</p>



<pre class="prettyprint"><code class=" hljs haskell"><span class="hljs-title">sudo</span> mkdir /<span class="hljs-typedef"><span class="hljs-keyword">data</span></span>
<span class="hljs-title">sudo</span> mkdir /<span class="hljs-typedef"><span class="hljs-keyword">data</span>/hdfs</span>
<span class="hljs-title">sudo</span> mkdir /<span class="hljs-typedef"><span class="hljs-keyword">data</span>/hdfs/name</span>
<span class="hljs-title">sudo</span> mkdir /<span class="hljs-typedef"><span class="hljs-keyword">data</span>/hdfs/<span class="hljs-keyword">data</span></span>
<span class="hljs-title">sudo</span> mkdir /<span class="hljs-typedef"><span class="hljs-keyword">data</span>/hdfs/tmp</span></code></pre>

<p><img src="https://img-blog.csdn.net/20170819202423937?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="5" title=""></p>

<p>修正分割线———————————– <br>
（ps：对之前看了这篇博客，照着搭建完出现问题的小伙伴表示万分抱歉，我也是在运行实例的时候找了好久才弄明白这个地方的错误的，求原谅T_T）</p>

<p>这里创建完各文件夹之后，记得要把文件夹的所有者和所属组改成 hadoop 用户，否则后面 hadoop 用户没有权限写入，会出错，我遇到的错误是 second 线程启动不起来，因为没有权限创建它所需要的文件夹及写入文件</p>



<pre class="prettyprint"><code class=" hljs haskell"><span class="hljs-title">sudo</span> chown hadoop /<span class="hljs-typedef"><span class="hljs-keyword">data</span></span>
<span class="hljs-title">sudo</span> chown hadoop /<span class="hljs-typedef"><span class="hljs-keyword">data</span>/hdfs</span>
<span class="hljs-title">sudo</span> chown hadoop /<span class="hljs-typedef"><span class="hljs-keyword">data</span>/hdfs/name</span>
<span class="hljs-title">sudo</span> chown hadoop /<span class="hljs-typedef"><span class="hljs-keyword">data</span>/hdfs/<span class="hljs-keyword">data</span></span>
<span class="hljs-title">sudo</span> chown hadoop /<span class="hljs-typedef"><span class="hljs-keyword">data</span>/hdfs/tmp</span></code></pre>

<p>修正分割线———————————–</p>

<p>分别在 slave1 和 slave2 服务器上执行以下命令</p>



<pre class="prettyprint"><code class=" hljs ruby">sudo scp -r hadoop<span class="hljs-variable">@master</span><span class="hljs-symbol">:/data</span> /</code></pre>

<p><em>2、解压缩</em></p>

<p>（1）将共享目录下的软件包拷贝到 /data 目录下</p>



<pre class="prettyprint"><code class=" hljs avrasm">sudo <span class="hljs-keyword">cp</span> /mnt/hgfs/Shared/hadoop-<span class="hljs-number">2.8</span><span class="hljs-number">.1</span><span class="hljs-preprocessor">.tar</span><span class="hljs-preprocessor">.gz</span> /data</code></pre>

<p>到 /data 目录下解压文件</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">cd</span> /data
<span class="hljs-built_in">sudo</span> tar -zxvf hadoop-<span class="hljs-number">2.8</span>.<span class="hljs-number">1</span>.tar.gz</code></pre>

<p>将解压完的 hadoop-2.8.1 文件的所有者及所属组改为 hadoop 用户，并删除压缩包</p>



<pre class="prettyprint"><code class=" hljs lasso">sudo chown <span class="hljs-attribute">-R</span> hadoop:hadoop /<span class="hljs-built_in">data</span>/hadoop<span class="hljs-subst">-</span><span class="hljs-number">2.8</span><span class="hljs-number">.1</span>
sudo rm <span class="hljs-attribute">-rf</span> hadoop<span class="hljs-subst">-</span><span class="hljs-number">2.8</span><span class="hljs-number">.1</span><span class="hljs-built_in">.</span>tar<span class="hljs-built_in">.</span>gz</code></pre>

<p><em>3、配置hadoop环境</em></p>

<p>（1）修改配置文件</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">sudo</span> vi /etc/profile</code></pre>

<p>在 JAVA_HOME 前面添加如下配置（Linux命令：G -&gt;k（上移到 JAVA_HOME 那一行） -&gt; o（字母小o） - &gt; 输入以下内容）</p>



<pre class="prettyprint"><code class=" hljs haskell"><span class="hljs-title">export</span> <span class="hljs-type">HADOOP_HOME</span>=/<span class="hljs-typedef"><span class="hljs-keyword">data</span>/hadoop-2.8.1</span></code></pre>

<p>修改 PATH 条目为</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">$JAVA_HOME</span>/bin:<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$HADOOP_HOME</span>/bin</code></pre>

<p>（Linux命令：Esc键 - &gt; 输入“:wq”退出）</p>

<p><img src="https://img-blog.csdn.net/20170819205922709?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="6" title=""></p>

<p>（2）重新加载 /etc/profile，使配置生效</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">source</span> /etc/profile</code></pre>

<p>（3）检查是否配置成功</p>



<pre class="prettyprint"><code class=" hljs ">hadoop</code></pre>

<p><img src="https://img-blog.csdn.net/20170819210038849?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="7" title=""></p>

<p>（4）修改 hadoop-env.sh 文件</p>

<p>hadoop 环境是基于 JVM 环境的，故需在 hadoop-env.sh 配置文件中指定 JDK 环境</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">sudo</span> vi hadoop-<span class="hljs-number">2.8</span>.<span class="hljs-number">1</span>/etc/hadoop/hadoop-env.sh</code></pre>

<p><img src="https://img-blog.csdn.net/20170819211152159?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="8" title=""></p>

<p>找到 JAVA_HOME 修改 <br>
（Linux 命令：L -&gt; j（下移两三行就能找到） -&gt; I -&gt; # -&gt; Esc键 -&gt; o （字母小o）-&gt; 输入）</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-keyword">export</span> JAVA_HOME=/usr/local/jdk1.<span class="hljs-number">8.0</span>_144</code></pre>

<p>保存退出（Linux 命令：Esc键 -&gt; ：wq!）</p>

<p><img src="https://img-blog.csdn.net/20170819211335905?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="9" title=""></p>

<p>（5）修改下列文件</p>

<p>在Linux系统桌面上新建以下文件，并修改相应内容（文件内容与上面的新建的 /data 文件夹有关）</p>

<p>1）core-site.xml</p>



<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-pi">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span class="hljs-pi">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>
<span class="hljs-comment">&lt;!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0
  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
--&gt;</span>

<span class="hljs-comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>io.file.buffer.size<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>131072<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>fs.default.name<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>hdfs://master:9000<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>/data/hdfs/tmp<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>

<p><strong>注意： hadoop.tmp.dir 的 value 填写对应前面创建的目录</strong></p>

<p>2）hdfs-site.xml</p>



<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-pi">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span class="hljs-pi">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>
<span class="hljs-comment">&lt;!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
--&gt;</span>

<span class="hljs-comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span>

<span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>2<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>file:/data/hdfs/name<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">final</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-title">final</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.blocksize<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>268435456<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.namenode.handler.count<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>100<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.datanode.data.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>file:/data/hdfs/data<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">final</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-title">final</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>

<p><strong>注意： dfs.namenode.name.dir 和 dfs.datanode.data.dir 的 value 填写对应前面创建的目录</strong></p>

<p>3）mapred-site.xml</p>



<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-pi">&lt;?xml version="1.0"?&gt;</span>
<span class="hljs-pi">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>
<span class="hljs-comment">&lt;!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
--&gt;</span>

<span class="hljs-comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span>

<span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>

<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.map.memory.mb<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>1536<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.map.java.opts<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>-Xmx1024M<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.reduce.memory.mb<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>3072<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.reduce.java.opts<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>-Xmx2560M<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.task.io.sort.mb<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>512<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.task.io.sort.factor<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>100<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.reduce.shuffle.parallelcopies<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>50<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapred.healthChecker.script.path<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>

<p>4）yarn-site.xml</p>



<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-pi">&lt;?xml version="1.0"?&gt;</span>

<span class="hljs-comment">&lt;!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at
   http://www.apache.org/licenses/LICENSE-2.0
  Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS,

  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.

  See the License for the specific language governing permissions and

  limitations under the License. See accompanying LICENSE file.

--&gt;</span>

<span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
<span class="hljs-comment">&lt;!-- Site specific YARN configuration properties --&gt;</span>

<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:8032<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
 <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:8030<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:8031<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>

<p>（6）替换掉 hadoop-2.8.1 文件夹下的相应文件</p>



<pre class="prettyprint"><code class=" hljs lasso">cd hadoop<span class="hljs-subst">-</span><span class="hljs-number">2.8</span><span class="hljs-number">.1</span>/etc/hadoop<span class="hljs-subst">/</span>
sudo rm yarn<span class="hljs-attribute">-site</span><span class="hljs-built_in">.</span><span class="hljs-built_in">xml</span> 
sudo rm hdfs<span class="hljs-attribute">-site</span><span class="hljs-built_in">.</span><span class="hljs-built_in">xml</span> 
sudo rm core<span class="hljs-attribute">-site</span><span class="hljs-built_in">.</span><span class="hljs-built_in">xml</span> 
sudo mv /home/hadoop/Desktop/yarn<span class="hljs-attribute">-site</span><span class="hljs-built_in">.</span><span class="hljs-built_in">xml</span>  <span class="hljs-built_in">.</span>
sudo mv /home/hadoop/Desktop/hdfs<span class="hljs-attribute">-site</span><span class="hljs-built_in">.</span><span class="hljs-built_in">xml</span> <span class="hljs-built_in">.</span>
sudo mv /home/hadoop/Desktop/core<span class="hljs-attribute">-site</span><span class="hljs-built_in">.</span><span class="hljs-built_in">xml</span> <span class="hljs-built_in">.</span>
sudo mv /home/hadoop/Desktop/mapred<span class="hljs-attribute">-site</span><span class="hljs-built_in">.</span><span class="hljs-built_in">xml</span> <span class="hljs-built_in">.</span></code></pre>

<p><img src="https://img-blog.csdn.net/20170819213529024?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="10" title=""></p>

<p>（7）修改 slaves 文件</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">sudo</span> vi slaves</code></pre>

<p>为</p>



<pre class="prettyprint"><code class=" hljs ">slave1
slave2</code></pre>

<p>（Linux 命令：D -&gt; i -&gt; 输入即可）</p>

<p><img src="https://img-blog.csdn.net/20170819213947125?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="11" title=""></p>

<p>保存退出（Linux 命令：Esc键 -&gt; ：wq!）</p>

<p>（8）复制到 slave1 和 slave2 服务器上</p>

<p>分别在 slave1 和 slave2 服务器上执行以下语句</p>



<pre class="prettyprint"><code class=" hljs ruby">sudo scp -r hadoop<span class="hljs-variable">@master</span><span class="hljs-symbol">:/data/hadoop-</span><span class="hljs-number">2.8</span>.<span class="hljs-number">1</span> /data</code></pre>

<p>（9）删除 slave1 和 slave2 服务器上的 slaves 文件，并更改 /data 文件夹的所有者及所属组为 hadoop 用户，分别在 slave1 和 slave2 服务器上执行以下语句</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">sudo</span> rm slaves
<span class="hljs-built_in">sudo</span> chown -R hadoop:hadoop /data</code></pre>

<p><img src="https://img-blog.csdn.net/20170820144500819?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="18" title=""></p>

<p><em>4、运行Hadoop</em></p>

<p>除特殊说明外，只在 master 上执行</p>

<p>（1）格式化NameNode</p>



<pre class="prettyprint"><code class=" hljs rsl">hadoop namenode -<span class="hljs-built_in">format</span></code></pre>

<p><img src="https://img-blog.csdn.net/20170820095210912?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="12" title=""></p>

<p><img src="https://img-blog.csdn.net/20170820095000817?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="13" title=""> <br>
<strong>注意：这一步可能会出现问题，最好从头到尾看一遍以确定格式化成功</strong></p>

<p>（2）启动HDFS文件管理系统</p>



<pre class="prettyprint"><code class=" hljs haskell"><span class="hljs-title">cd</span> /<span class="hljs-typedef"><span class="hljs-keyword">data</span>/hadoop-2.8.1/</span></code></pre>

<p>这边要保证三台服务器上的hadoop-2.8.1文件夹的所有者都是hadoop用户 <br>
（sudo chown hadoop /data/hadoop-2.8.1）</p>



<pre class="prettyprint"><code class=" hljs sql">sbin/<span class="hljs-operator"><span class="hljs-keyword">start</span>-<span class="hljs-keyword">all</span>.sh</span></code></pre>

<p><img src="https://img-blog.csdn.net/20170820102005435?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="14" title=""> <br>
<strong>可以照着 log 的保存路径查看一下 log 日志，尤其是，如果出现了什么错误，日志里会写的很清楚</strong></p>

<p>（3）查看启动进程 <br>
在 master 上执行</p>



<pre class="prettyprint"><code class=" hljs ">jps</code></pre>

<p>master服务器： <br>
<img src="https://img-blog.csdn.net/20170908201058764?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="jps" title=""> <br>
ps：SecondaryNameNode 线程没启动起来的话有可能是因为 hadoop 用户没有对 /data/hdfs 及其下的子文件夹的写权限</p>

<p>slave1服务器： <br>
<img src="https://img-blog.csdn.net/20170909175101389?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="1" title=""></p>

<p>slave2服务器： <br>
<img src="https://img-blog.csdn.net/20170909175129536?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="21" title=""></p>

<p>缺任何一个都是有问题的</p>

<p><em>5、测试Hadoop</em></p>

<p>（1）查看集群状态</p>



<pre class="prettyprint"><code class=" hljs vhdl">hadoop dfsadmin -<span class="hljs-keyword">report</span></code></pre>

<p><img src="https://img-blog.csdn.net/20170820152609174?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="22" title=""> <br>
<img src="https://img-blog.csdn.net/20170820152624435?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="23" title=""></p>

<p>（2）测试集群 <br>
在master上创建个新文件夹</p>



<pre class="prettyprint"><code class=" hljs perl">hdfs dfs -<span class="hljs-keyword">mkdir</span> /user</code></pre>

<p><img src="https://img-blog.csdn.net/20170820153326246?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="24" title=""></p>

<p>分别在三台服务器上查看刚新建的文件夹是否成功</p>



<pre class="prettyprint"><code class=" hljs mel">hdfs dfs -<span class="hljs-keyword">ls</span> /</code></pre>

<p>master服务器： <br>
<img src="https://img-blog.csdn.net/20170820153503051?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="25" title=""></p>

<p>slave1服务器： <br>
<img src="https://img-blog.csdn.net/20170820153525928?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="26" title=""></p>

<p>slave2服务器： <br>
<img src="https://img-blog.csdn.net/20170820153547409?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="27" title=""></p>

<p>（3）测试yarn <br>
ip 是master 服务器的 ip ，端口是在前面修改的文件中指定的</p>



<pre class="prettyprint"><code class=" hljs cs">http:<span class="hljs-comment">//192.168.195.130:18088/cluster</span></code></pre>

<p><img src="https://img-blog.csdn.net/20170820153820710?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="28" title=""></p>

<p>（4）测试 mapreduce <br>
Hadoop 安装包里有提供现成的 mapreduce 例子，在 Hadoop 的share/hadoop/mapreduce 目录下。运行例子：</p>



<pre class="prettyprint"><code class=" hljs lasso">bin/hadoop jar /<span class="hljs-built_in">data</span>/hadoop<span class="hljs-subst">-</span><span class="hljs-number">2.8</span><span class="hljs-number">.1</span>/share/hadoop/mapreduce/hadoop<span class="hljs-attribute">-mapreduce</span><span class="hljs-attribute">-examples</span><span class="hljs-subst">-</span><span class="hljs-number">2.8</span><span class="hljs-number">.1</span><span class="hljs-built_in">.</span>jar pi <span class="hljs-number">5</span> <span class="hljs-number">10</span></code></pre>

<p><img src="https://img-blog.csdn.net/20170820154520898?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="29" title=""></p>

<p>截图中是还没运行完毕的代码，如果电脑内存不是很大的话，他会在这里卡很久，我的电脑是8G，虚拟机分配的内存是1.5G（分配2G的话电脑就会卡到动不了。。。）</p>

<p><img src="https://img-blog.csdn.net/20170912212144340?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="1" title=""> <br>
<img src="https://img-blog.csdn.net/20170912212224857?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="2" title=""> <br>
<img src="https://img-blog.csdn.net/20170912212258514?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="3" title=""> <br>
<img src="https://img-blog.csdn.net/20170912212502255?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="4" title=""> <br>
<img src="https://img-blog.csdn.net/20170912212521796?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="5" title=""></p>

<p>运行了n遍都失败之后，决定最后运行一遍，然后扔那运行我就干别的去了。。。一个多小时之后回来发现。。。竟然成功了，失败的原因是，电脑性能跟不上</p>

<p>然后刷新刚才的网页 <br>
<img src="https://img-blog.csdn.net/20170820154709615?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="30" title=""></p>

<p>（5）查看HDFS</p>



<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-label">http:</span>//<span class="hljs-number">192.168</span><span class="hljs-number">.195</span><span class="hljs-number">.130</span>:<span class="hljs-number">50070</span>/dfshealth<span class="hljs-preprocessor">.html</span><span class="hljs-preprocessor">#tab-overview</span></code></pre>

<p><img src="https://img-blog.csdn.net/20170820155142833?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VueXVuX2thbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="31" title=""></p>

<p>唔哈哈哈哈哈~~~好啦，大功告成了，差不多花了一周的时间，踩了无数个坑才完成，激动！！！</p>



<h4 id="日后可能遇到的问题"><strong>日后可能遇到的问题</strong></h4>

<p><strong>1、namenode没有启动，每次开机都得重新格式化一下namenode才可以</strong> <br>
参考答案： <br>
<a href="http://blog.csdn.net/bychjzh/article/details/7830508" rel="nofollow" target="_blank">http://blog.csdn.net/bychjzh/article/details/7830508</a></p>

<p><strong>2、hadoop运行到mapreduce.job: Running job后停止运行</strong> <br>
参考答案： <br>
<a href="http://blog.csdn.net/zhangchaokun/article/details/49105037" rel="nofollow" target="_blank">http://blog.csdn.net/zhangchaokun/article/details/49105037</a></p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>