---
layout:     post
title:      Hadoop生态系统命令合集（更新中……）
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，转载请附上原文地址。					https://blog.csdn.net/u011239443/article/details/52168746				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h1 id="hdfs">HDFS</h1>



<h2 id="fsck">fsck</h2>

<p>hdfs  fsck</p>

<p>Usage: DFSck  [-move | -delete | -openforwrite] [-files [-blocks [-locations | -racks]]]</p>

<pre><code>    &lt;path&gt;             检查这个目录中的文件是否完整

    -move               破损的文件移至/lost+found目录
    -delete             删除破损的文件

    -openforwrite   打印正在打开写操作的文件

    -files                 打印正在check的文件名

    -blocks             打印block报告 （需要和-files参数一起使用）

    -locations         打印每个block的位置信息（需要和-files参数一起使用）

    -racks               打印位置信息的网络拓扑图 （需要和-files参数一起使用）
</code></pre>

<p>hdfs  fsck /</p>

<p>用这个命令可以检查整个文件系统的健康状况，但是要注意它不会主动恢复备份缺失的block，这个是由NameNode单独的线程异步处理的。</p>



<h1 id="hive">Hive</h1>



<h2 id="查看hive表中数据所在路径">查看hive表中数据所在路径</h2>



<pre class="prettyprint"><code class="language-shell hljs cs">hive&gt; describe database bak_spark_tpcds_parquet_1000;
OK
bak_spark_tpcds_parquet_1000        hdfs:<span class="hljs-comment">//holodesk01:8020/user/hive/warehouse/bak_spark_tpcds_parquet_1000.db      USER    </span>
Time taken: <span class="hljs-number">0.02</span> seconds, Fetched: <span class="hljs-number">1</span> row(s)</code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>