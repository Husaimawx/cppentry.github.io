---
layout:     post
title:      Spark 1.X DatandaLone伪分布环境搭建
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/xiewendong93/article/details/50935925				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h2 id="spark-1x-datandalone环境搭建伪分布">Spark 1.X DatandaLone环境搭建（伪分布）</h2>

<p><strong>Spark运行环境有：Local,SandaLone，YARN，Mesos</strong> <br>
<strong>安装步骤如下：</strong> <br>
- <strong>JDK 版本建议1.7</strong> <br>
- <strong>SCALA 版本 2.10.4</strong> <br>
- <strong>Hadoop 版本2.x （HDFS）</strong> <br>
- <strong>Spark StandaLone</strong></p>



<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor">##安装与spark编译版本一致的hadoop</span>
<span class="hljs-number">1.</span>安装JDK与Scala，解压，配置环境变量即可。

<span class="hljs-number">2.</span>安装hadoop 
tar -zxf hadoop-<span class="hljs-number">2.6</span><span class="hljs-number">.0</span>-cdh<span class="hljs-number">.5</span><span class="hljs-number">.4</span><span class="hljs-number">.0</span><span class="hljs-preprocessor">.tar</span><span class="hljs-preprocessor">.gz</span> -C /uer/local
<span class="hljs-preprocessor">#hadoop官方配置地址：</span>
<span class="hljs-label">http:</span>//hadoop<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.org</span>/docs/<span class="hljs-built_in">r2</span><span class="hljs-number">.6</span><span class="hljs-number">.0</span>/hadoop-project-dist/hadoop-common/SingleCluster<span class="hljs-preprocessor">.html</span>
  <span class="hljs-number">1.</span>修改（关于环境JDK等的配置文件）hadoop-env<span class="hljs-preprocessor">.xml</span>
  <span class="hljs-number">2.</span>修改（关于集群节点的配置文件）core-site<span class="hljs-preprocessor">.xml</span>
  <span class="hljs-number">3.</span>修改（关于hdfs配置文件） hdfs-site<span class="hljs-preprocessor">.xml</span>
  <span class="hljs-built_in">x</span>.设置节点（save<span class="hljs-preprocessor">.xml</span>）指向 指向子节点
  <span class="hljs-number">4.</span>格式化:bin/hdfs namenode -format
  <span class="hljs-number">5.</span>启动集群:start-all<span class="hljs-preprocessor">.sh</span>

<span class="hljs-number">3.</span>安装standalone
  <span class="hljs-number">1.</span>修改（关于spark环境的文件） spark-env<span class="hljs-preprocessor">.xml</span>
      <span class="hljs-number">1</span>（jdk）<span class="hljs-preprocessor">.JAVA</span>_HOME=/usr/java/jdk1<span class="hljs-number">.7</span>
      <span class="hljs-number">2</span>（SCALA）<span class="hljs-preprocessor">.SCALA</span>_HOME=/usr/local/scala
      <span class="hljs-number">3</span>(HADOOP配置).
        HADOOP_CONF_DIR=/usr/local/hadoop/env/hadoop
      <span class="hljs-number">4</span>（SPARK主机名）<span class="hljs-preprocessor">.SPARK</span>_MASTER_IP=localhost
      <span class="hljs-number">5</span>（SPARK端口）<span class="hljs-preprocessor">.SPARK</span>_MASTER_PORT=<span class="hljs-number">7077</span>
      <span class="hljs-number">6</span>（SPARKUI端口）<span class="hljs-preprocessor">.SPARK</span>_MASTER_WEIUI_PORT=<span class="hljs-number">8080</span>
      <span class="hljs-number">7</span>（SAPRK可以用CPU的<span class="hljs-number">1</span>核心）<span class="hljs-preprocessor">.SPARK</span>_WORKER_CORES=<span class="hljs-number">1</span>
      <span class="hljs-number">8</span>（work端口）<span class="hljs-preprocessor">.SPARK</span>_WORKER_PORT=<span class="hljs-number">7078</span>
      <span class="hljs-number">9</span>（可用内存）<span class="hljs-preprocessor">.SPARK</span>_WORKER_MEMORY=<span class="hljs-number">1000</span>m
      <span class="hljs-number">10</span>(一个实例)<span class="hljs-preprocessor">.SPARK</span>_WORKER_INSTANCES=<span class="hljs-number">1</span> 
  <span class="hljs-number">2.</span>修改:slave<span class="hljs-preprocessor">.xml</span><span class="hljs-preprocessor">.templete</span>改名 slave<span class="hljs-preprocessor">.xml</span>
      <span class="hljs-number">1.</span>内容指定 work工作节点
  <span class="hljs-number">3.</span>修改:spark-default<span class="hljs-preprocessor">.xml</span><span class="hljs-preprocessor">.templete</span>改名spark-default<span class="hljs-preprocessor">.xml</span>
      <span class="hljs-number">1.</span>spark<span class="hljs-preprocessor">.master</span>   spark://localhost:<span class="hljs-number">7077</span>

<span class="hljs-number">4.</span>启动
    <span class="hljs-number">0.</span>start-namenode<span class="hljs-preprocessor">.sh</span>,start-datanode<span class="hljs-preprocessor">.sh</span>
    JSP:NameNode,DataNode,Jps

    <span class="hljs-number">1.</span>sbin/start-master<span class="hljs-preprocessor">.sh</span>
    JPS:NameNode,DataNode,Master,Jps

    <span class="hljs-number">2.</span>sbin/start-slaves<span class="hljs-preprocessor">.sh</span>
    JPS:NameNode,DataNode,Master,Work,Jps
通过页面：localhost:<span class="hljs-number">8080</span>端口访问即可。
（<span class="hljs-number">8080</span>在SPARK_MASTER_WEIUI_PORT中设置）</code></pre>

<h2 id="功成">功成</h2>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>