---
layout:     post
title:      Hive学习路线
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p><strong>前言</strong> <br>
Hive是Hadoop家族中一款数据仓库产品，Hive最大的特点就是提供了类SQL的语法，封装了底层的MapReduce过程，让有SQL基础的业务人员，也可以直接利用Hadoop进行数据的操作。就是这一点，解决了原始数据分析人员对于大数据分析的瓶颈。</p>

<hr>

<p><strong>目录</strong></p>

<ol>
<li>Hive介绍</li>
<li>Hive学习路线图</li>
<li>我的使用经历</li>
<li>Hive的使用案例</li>
</ol>

<hr>

<h2 id="1hive介绍">1.Hive介绍</h2>

<p>Hive起源于Facebook，它使得针对Hadoop进行SQL查询成为可能，从而非程序员也可以方便地使用。Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的SQL查询功能，可以将SQL语句转换为MapReduce任务运行。 <br>
Hive是建立在 Hadoop 上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。Hive 定义了简单的类 SQL 查询语言，称为 HQL，它允许熟悉 SQL 的用户查询数据。同时，这个语言也允许熟悉 MapReduce 开发者的开发自定义的 mapper 和 reducer 来处理内建的 mapper 和 reducer 无法完成的复杂的分析工作。 <br>
详细地Hive安装和使用介绍，参考文章：Hive安装及使用攻略</p>

<hr>

<h2 id="2hive学习路线图">2.Hive学习路线图</h2>

<p><img src="https://img-blog.csdn.net/20150411212003867" alt="这里写图片描述" title=""> <br>
Hive的知识点，我已经列在图中，希望帮助其他人更好的理解Hive。 <br>
接下来，是我的使用经历：</p>

<hr>

<h2 id="3我的使用经历">3.我的使用经历</h2>

<p>我使用Hive考虑到两点：</p>

<ol>
<li>帮助无开发经验的数据分析人员，有能力处理大数据 <br>
<ol><li>构建标准化的MapReduce开发过程 <br>
1).帮助无开发经验的数据分析人员，有能力处理大数据 <br>
完全符合Hive的设计理念，一直强调，无需多言。 <br>
2).构建标准化的MapReduce开发过程 <br>
这个方面是我们努力的方向。 <br>
首先，Hive已经用类SQL的语法封装了MapReduce过程，这个封装过程就是MapReduce的标准化过程。 <br>
我们在做业务或者工具时，会针对场景用逻辑封装，这是第二层封装是在Hive之上的封装。在第二层封装时，我们要尽可能多的屏蔽Hive的细节，让接口单一化，低少灵活性，再次精简HQL的语法结构。只满足我们的系统要求，专用的接口。 <br>
在使用二次封装的接口时，我们已经可以不用知道Hive是什么, 更不用知道Hadoop是什么。我们只需要知道，SQL查询(SQL92标准)，怎么写效率高，怎么写可以完成业务需要就可以了。 <br>
当我们完成了Hive的二次封装后，我们可以构建标准化的MapReduce开发过程。 <br>
<img src="https://img-blog.csdn.net/20150411213114543" alt="这里写图片描述" title=""> <br>
通过上图的思路，我们可以统一企业内部各种应用对于Hive的依赖，并且当人员素质升高后，有可以剥离Hive，用更优秀的底层解决方案来替换，如果封装的接口的不变，甚至替换Hive时业务使用都不知道，我们已经替换了Hive。 <br>
这个过程是需要经历的，也是有意义的。当我在考虑构建Hadoop分析工具时，以Hive作为Hadoop访问接口是最有效的。 <br>
3).有关Hive的运维 <br>
因为Hive是基于Hadoop构建的，简单地说就是一套Hadoop的访问接口，Hive本身并没有太多的东西，所以运维上面我们注意下面几个问题就行了。</li>
<li>使用单独的数据库存储元数据</li>
<li>定义合理的表分区和键</li>
<li>设置合理的bucket数据量</li>
<li>进行表压缩</li>
<li>定义外部表使用规范</li>
<li>合理的控制Mapper, Reducer数量</li></ol></li>
</ol>

<hr>

<h2 id="4hive的使用案例">4.Hive的使用案例</h2>

<ol>
<li>Hive安装及使用攻略</li>
<li>Hive导入10G数据的测试</li>
<li>R利剑NoSQL系列文章 之 Hive</li>
<li>用RHive从历史数据中提取逆回购信息</li>
</ol>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>