---
layout:     post
title:      Spark视频王家林大神第1课： 30分钟彻底理解Spark核心API发展史：RDD、DataFrame、DataSet
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：王家林大咖2018年新书《SPARK大数据商业实战三部曲》清华大学出版，清华大学出版社官方旗舰店（天猫）https://qhdx.tmall.com/?spm=a220o.1000855.1997427721.d4918089.4b2a2e5dT6bUsM					https://blog.csdn.net/duan_zhihua/article/details/79149574				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>Spark视频王家林大神第1课： 30分钟彻底理解Spark核心API发展史：RDD、DataFrame、DataSet</p><p></p><p>本节通过Spark核心API的发展史，带领大家学习和理解Spark的内幕，在Spark的发展史上，经历了三代API：第一代是RDD、第二代是DataFrame、第三代是DataSet。RDD是Spark中绝对的核心和基础性的抽象，DataFrame是Spark 1.3.x推出的，为了处理交互型的关系数据库的数据，数据可以来源于Oracle、Mysql或者JSON，可以支撑各种格式，也可来自于RDD，或者HDFS的分布式文件系统；Spark 1.6.x的时候推出了第三代关键性的DataSet。之所以在机器学习的第一节以RDD第一代的核心API、DataFrame第二代的核心API、以及Spark1.6.x推出的实验性API并在Spark 2.x成熟的DataSet，以此为一条线贯通Spark前前后后的内容，有几个方面的原因：</p><p>1）第一点：作为开发者，无论是做机器学习的开发还是做其他方面的开发，Spark</p><p>这三代API都是绕不过去的，开发者必须首先理解这三代API。</p><p>2）第二点：我们编写代码的时候，不同的Spark版本，例如：Spark 1.3.x之前的</p><p>版本，Spark 1.3.x到Spark 1.6.x之间的版本，以及已经推出的Spark 2.0.x的版本，这三代API的编程风格虽然有一定的相似性，但是有所差异的。从第二个方面的角度考虑，我们写代码绕不开这三代API，而每一代API都带来了性能的极大提升。如果有机器学习的开发经验，体验应是非常的深刻，分布式系统性能一定是第一位的，在确保数据安全的情况下，如何加快计算速度，这是分布式系统的第一要务，也是所有分布式编程高手水平判断的更高标准。Spark机器学习对性能进行迭代，对性能的要求是毫无疑问的，每代Spark  API的推出都带来性能的极大提升，包括第一代API的RDD，当年推出RDD的时候，给业界的第一印象就是Spark太快了，后来的DataFrame、DataSet又不断长江后浪推前浪，带来性能的极大提升。</p><p> </p><p>(一)Spark第一代API:RDD。</p><p>RDD奠定了Spark辉煌的基础，DataFrame、DataSet的底层调度都依赖于RDD，RDD是最重要的。RDD代表了一系列数据的集合，如果要通过Spark操作相关的数据，一般情况下一定会用到RDD，如数据来自于数据库、Hbase等，可通过RDD把数据封装起来。</p><p>RDD的五大核心特征：</p><p>1)       A list of partitions 一系列分区的集合。</p><p>2)       A function for computing eachsplit 各个分区的计算函数。</p><p>3)       A list of dependencies on otherRDDs  RDD的依赖关系。</p><p>4)       Optionally, a Partitioner forkey-value RDDs (e.g. to say that the RDD is hash-partitioned)   基于key-value 类型RDD的分区器。</p><p>5)       Optionally, a list of preferredlocations to compute each split on (e.g. block locations for an HDFS file)  每个分区数据计算的本地性。</p><p> </p><p>(二) Spark第二代API: DataFrame。</p><p>DataFrame是Spark发展的里程碑，DataFrame底层有一个钨丝计划。</p><p>DataFrame的核心特征：</p><p>1)       包含了以Row为单位的每行数据的列的信息，此时DataFrame就是Table；</p><p>非常适合于关系型数据操作。</p><p><span style="color:#000000;">2)      </span>Tungsten：新的执行引擎。Tungsten不是取代了以RDD为核心的调度，而是</p><p>在第一代RDD调度系统的基础之上，基于元数据信息，获取更多的内容。基于更高维度的元数据信息进行优化，包括谓词下推、列裁剪等，提供了更多<span style="color:#000000;">丰富的算子，执行效率提升。例如：</span><span style="color:#000000;">filter</span><span style="color:#000000;">下推的时候在</span><span style="color:#000000;">join</span><span style="color:#000000;">计算之前，甚至可以下推到数据源，裁剪列名如果发现这一列的数据不需要，就可以裁剪。</span></p><p><span style="color:#000000;">3)      </span><span style="color:#000000;">Catalyst</span><span style="color:#000000;">：新的语法解析框架。提升计算效率，减少数据读取、底层计算优</span></p><p><span style="color:#000000;">化；</span></p><p> </p><p>(三) Spark第三代API: DataSet。</p><p>DataSet在DataFrame的基础之上，最关键的一点是Encoder，如果基于Scala开</p><p>发，Scala自动提供Encoder，如果基于Java开发，需手工开发Encoder。DataSet是在Spark 1.6.x版本推出的。DataSet是在Catalyst优化引擎的基础之上，Catalyst已有的功能DataSet都可以使用，基于Encoder提供类型安全检查。</p><p>DataSet的核心价值和好处：</p><p><span style="color:#000000;">1)      </span><span style="color:#000000;">编译时的类型安全检查，不需要在执行时期才发现类型不匹配。以前编写</span></p><p><span style="color:#000000;">RDD</span><span style="color:#000000;">和</span><span style="color:#000000;">DataFrame</span><span style="color:#000000;">的时候没有这个功能支持，假设字段</span><span style="color:#000000;">char</span><span style="color:#000000;">类型本来是</span><span style="color:#000000;">16</span><span style="color:#000000;">位的，如超过了</span><span style="color:#000000;">16</span><span style="color:#000000;">位的最大范围写成了</span><span style="color:#000000;">32</span><span style="color:#000000;">位的长整数类型，编译时感知不到。但如果是</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">，编译时就会进行安全类型检查。编译时期进行安全检查，无论是对于编码的效率，还是解除</span><span style="color:#000000;">BUG</span><span style="color:#000000;">，意义非常重大。因为不需要提交给集群中就可以发现很明显的错误，进行企业级开发的时候可节省资源。</span></p><p><span style="color:#000000;">2)      </span><span style="color:#000000;">性能的极大提升。如果基于</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">编写代码，</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">有自己一套</span><span style="color:#000000;">Encoder</span></p><p><span style="color:#000000;">的机制，直接在二进制的基础上进行很多操作，不需要物化的过程。什么是物化？就是操作一个对象序列化和反序列化的时候，基于原先</span><span style="color:#000000;">DataFrame</span><span style="color:#000000;">的</span><span style="color:#000000;">Tungsten</span><span style="color:#000000;">，需要在</span><span style="color:#000000;">Object</span><span style="color:#000000;">和</span><span style="color:#000000;">Tungsten</span><span style="color:#000000;">之间进行一些转换的工作，但如果是</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">，从操作的层面就不需要这些转换的工作了。</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">是基于</span><span style="color:#000000;">Catalyst</span><span style="color:#000000;">和</span><span style="color:#000000;">Tungsten</span><span style="color:#000000;">的，而</span><span style="color:#000000;">RDD</span><span style="color:#000000;">本身不会基于这些引擎的计算，相对基于</span><span style="color:#000000;">RDD</span><span style="color:#000000;">编程，基于</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">编程会有非常大的性能提升。</span></p><p><span style="color:#000000;">3)      </span><span style="color:#000000;">内存使用极大降低、减少</span><span style="color:#000000;">GC</span><span style="color:#000000;">。从</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">的角度，</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">是一个数据结构。</span></p><p><span style="color:#000000;">DataSet</span><span style="color:#000000;">中的数据可以进行优化。如果把数据放在</span><span style="color:#000000;">RDD</span><span style="color:#000000;">，</span><span style="color:#000000;">RDD</span><span style="color:#000000;">不知道元数据细节，</span><span style="color:#000000;">RDD</span><span style="color:#000000;">是最原始的引擎，不能进行很多优化。优化后，</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">的内存使用极大降低。</span></p><p><span style="color:#000000;">4)      </span><span style="color:#000000;">极大的减少网络数据的传输。</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">有自己的数据格式，</span><span style="color:#000000;">Spark</span><span style="color:#000000;">引擎基于更</span></p><p><span style="color:#000000;">多的信息对数据进行存储，内存使用降低</span><span style="color:#000000;">4</span><span style="color:#000000;">至</span><span style="color:#000000;">5</span><span style="color:#000000;">倍，从网络数据的传输，整个</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">的体积非常小，整个网络数据的传输会极大的降低。虽然</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">有</span><span style="color:#000000;">Encoder</span><span style="color:#000000;">，但还是有一个序列化和反序列化的过程，考虑</span><span style="color:#000000;">Encoder</span><span style="color:#000000;">本身，与原生的</span><span style="color:#000000;">JAVAinputStream</span><span style="color:#000000;">和</span><span style="color:#000000;">outStream</span><span style="color:#000000;">的序列化反序列化的方式，</span><span style="color:#000000;">Google</span><span style="color:#000000;">提供的序列化反序列化方式比较，</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">提供的</span><span style="color:#000000;">Encoder</span><span style="color:#000000;">性能和效率远远高于</span><em><span style="color:#000000;background:#FFFFFF;">Kryo</span></em><span style="color:#000000;background:#FFFFFF;"> </span><span style="color:#000000;">，而</span>Kryo<span style="color:#000000;"> </span><span style="color:#000000;">又高于</span><span style="color:#000000;">Java 1</span><span style="color:#000000;">倍，以</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">的方式存储数据，会降低</span><span style="color:#000000;">5</span><span style="color:#000000;">倍左右的空间，而且底层有</span><span style="color:#000000;">Tungsten</span><span style="color:#000000;">的引擎优化，在内存、数据存储、网络传输都会带来极大的好处。</span></p><p><span style="color:#000000;">5)      </span><span style="color:#000000;">极大的减少采用</span><span style="color:#000000;">Scala</span><span style="color:#000000;">和</span><span style="color:#000000;">Java</span><span style="color:#000000;">编程的代码的差异性。如果在工程中用</span><span style="color:#000000;">Scala</span><span style="color:#000000;">和</span></p><p><span style="color:#000000;">Java</span><span style="color:#000000;">，</span><span style="color:#000000;">Scala</span><span style="color:#000000;">和</span><span style="color:#000000;">Java</span><span style="color:#000000;">这两种语言都用的非常多，</span><span style="color:#000000;">Scala</span><span style="color:#000000;">和</span><span style="color:#000000;">Java</span><span style="color:#000000;">的差别性还是非常大的，但是如果使用</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">，</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">统一了</span><span style="color:#000000;">API</span><span style="color:#000000;">，统一了语言的差别。因为</span><span style="color:#000000;">DataSet</span><span style="color:#000000;">要进行类型检查，目前还不支持</span><span style="color:#000000;">Python</span><span style="color:#000000;">和</span><span style="color:#000000;">R</span><span style="color:#000000;">语言。</span></p><p>RDD、DataFrame、DataSet这三代API，DataSet和DataFrame转换还是非常容易的，DataSet是强类型的，DataFrame不是强类型，RDD与DataFrame、DataSet相比，RDD处理的类型在运行期间决定的。</p><p>l  DataSet会同时兼顾Functional和Relational programming。</p><p>l  DataSet可以统一流计算、SQL、机器学习的API编程。Spark使用一个技术</p><p>堆栈解决所有的问题，在Spark 2.x编程的时候，DataSet统一了流式编程、交互式查询编程、机器学习编程，统一了不同框架之间的编程，对于开发而言有极大的好处。</p><p>l  DataSet最最重要的是效率，包括底层的Tungsten优化，Encoder，数据在内</p><p>存和磁盘等的存储等等。从Scala的角度，Encoder还不支持第三方编码。 </p><p> </p><br>            </div>
                </div>