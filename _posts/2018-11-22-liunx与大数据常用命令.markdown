---
layout:     post
title:      liunx与大数据常用命令
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>hadoop常用命令<br>
启动一个MR任务<br>
bin/hadoop jar /home/chinahadoop/software/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.4.jar pi 2 10</p>

<p>Hadoop fs –ls<br>
Hadoop fs –put  文件(某文件路径下的文件)  文件(某文件下的文件)</p>

<p><br>
查询<br>
hadoop job -list <br>
hadoop job -kill job_1532599477759_0001</p>

<p>hadoop fs <br>
查看Hadoop HDFS支持的所有命令 </p>

<p>hadoop fs -ls /<br>
列出目录及文件信息 <br>
 <br>
hadoop fs -lsr /<br>
循环列出目录、子目录及文件信息  </p>

<p>hadoop fs -put test.txt /user/sunlightcs <br>
将本地文件系统的test.txt复制到HDFS文件系统的/user/sunlightcs目录下 </p>

<p>hadoop fs -get /user/sunlightcs/test.txt . <br>
将HDFS中的test.txt复制到本地文件系统中，与-put命令相反 </p>

<p>hadoop fs -cat /user/sunlightcs/test.txt <br>
查看HDFS文件系统里test.txt的内容</p>

<p>hadoop fs -tail /user/sunlightcs/test.txt <br>
查看最后1KB的内容 <br>
 <br>
hadoop fs -rm /user/sunlightcs/test.txt <br>
从HDFS文件系统删除test.txt文件，rm命令也可以删除空目录 <br>
 <br>
hadoop fs -rmr /user/sunlightcs <br>
删除/user/sunlightcs目录以及所有子目录 <br>
 <br>
hadoop fs -copyFromLocal test.txt /user/sunlightcs/test.txt <br>
从本地文件系统复制文件到HDFS文件系统，等同于put命令 <br>
 <br>
hadoop fs -copyToLocal /user/sunlightcs/test.txt test.txt <br>
从HDFS文件系统复制文件到本地文件系统，等同于get命令 </p>

<p>hadoop fs -chgrp [-R] /user/sunlightcs <br>
修改HDFS系统中/user/sunlightcs目录所属群组，选项-R递归执行，跟linux命令一样 </p>

<p>hadoop fs -chown [-R] /user/sunlightcs <br>
修改HDFS系统中/user/sunlightcs目录拥有者，选项-R递归执行 </p>

<p>hadoop fs -chmod [-R] MODE /user/sunlightcs <br>
修改HDFS系统中/user/sunlightcs目录权限，MODE可以为相应权限的3位数或+/-{rwx}，选项-R递归执行 </p>

<p>hadoop fs -count [-q] PATH <br>
查看PATH目录下，子目录数、文件数、文件大小、文件名/目录名 </p>

<p>hadoop fs -cp SRC [SRC …] DST      <br>
将文件从SRC复制到DST，如果指定了多个SRC，则DST必须为一个目录 </p>

<p>hadoop fs -du PATH <br>
显示该目录中每个文件或目录的大小 </p>

<p>hadoop fs -dus PATH <br>
类似于du，PATH为目录时，会显示该目录的总大小 </p>

<p>hadoop fs -expunge <br>
清空回收站，文件被删除时，它首先会移到临时目录.Trash/中，当超过延迟时间之后，文件才会被永久删除 </p>

<p>hadoop fs -getmerge SRC [SRC …] LOCALDST [addnl]     <br>
获取由SRC指定的所有文件，将它们合并为单个文件，并写入本地文件系统中的LOCALDST，选项addnl将在每个文件的末尾处加上一个换行符 </p>

<p>hadoop fs -touchz PATH  <br>
创建长度为0的空文件 </p>

<p>hadoop fs -test -[ezd] PATH    <br>
对PATH进行如下类型的检查： <br>
-e PATH是否存在，如果PATH存在，返回0，否则返回1 <br>
-z 文件是否为空，如果长度为0，返回0，否则返回1 <br>
-d 是否为目录，如果PATH为目录，返回0，否则返回1 </p>

<p>hadoop fs -text PATH <br>
显示文件的内容，当文件为文本文件时，等同于cat，文件为压缩格式（gzip以及hadoop的二进制序列文件格式）时，会先解压缩 </p>

<p>hadoop fs -help ls <br>
查看某个[ls]命令的帮助文档</p>

<p>Hadoop操作命令<br>
通过hadoop bin包下 激活nn1节点<br>
    bin/hdfs haadmin -transitionToActive nn1</p>

<p><strong>Linux 命令</strong></p>

<p>ssh-keygen：linux环境生成秘钥<br>
ssh-copy-id root(当前登录用户)@chinahadoop2(表示root要登录的环境<br>
这里表示root @登录chinahadoop2 环境)</p>

<p><br>
rsync chinahadoop@chinahadoop2:~/software/hadoop-2.7.4.tar softwart/<br>
表示:<br>
把 chinahadoop2 虚拟机上/home/chinahadoop/software/目录下的 hadoop-2.7.4.tar.gz 文件，拷贝到 chinahadoop1(这里表示当前环境的hostname中配置的名称也可以说当前机器) <br>
虚拟机的/home/chinahadoop/software/目录下。</p>

<p><br>
rsync -r hadoop software chinahadoop2(表示其他机器):~ (~表示其他机器的home目录 执行这条命令表示把当前的文件夹同步到其他机器上)<br>
把目录 software 和 hadoop/ha 以及 hadoop 压缩包全部拷贝到其他机器上。</p>

<p>tar 命令解压<br>
tar zxvf  ***.tar.gz </p>

<p><strong>关于linux 环境变量配置</strong></p>

<p><strong>/etc/profile设置的内容所有用户都会执行到，~/.bashrc只有当前用户才会用到<br>
公用的设置在/etc/profile里，单个用户的设置在~/.bash_profile里</strong></p>

<p> </p>

<p> </p>

<p><strong>liunx  查看权限</strong></p>

<p>只有管理员root可以查看/etc/shadow文件<br>
root@ubuntu:/home/linlin/linlin# ls -l /etc/shadow</p>

<p>cat /etc/sysconfig/network</p>

<p><img alt="" class="has" height="717" src="https://img-blog.csdn.net/20180804182334191?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYW5neXVueHVl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="989"></p>

<p> </p>

<p> </p>

<p><strong>linux 对于~/hadoop是哪个目录</strong></p>

<p><img alt="" class="has" height="165" src="https://img-blog.csdn.net/20180804233818564?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYW5neXVueHVl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="523"></p>

<p><strong>shell 基本写法</strong></p>

<p>if ....; then<br>
....<br>
elif ....; then<br>
....<br>
else<br>
....<br>
fi<br>
[ -f "somefile" ] ：判断是否是一个文件<br>
[ -x "/bin/ls" ] ：判断/bin/ls是否存在并有可执行权限<br>
[ -n "$var" ] ：判断$var变量是否有值<br>
[ "$a" = "$b" ] ：判断$a和$b是否相等<br>
-r file　　　　　用户可读为真<br>
-w file　　　　　用户可写为真<br>
-x file　　　　　用户可执行为真<br>
-f file　　　　　文件为正规文件为真<br>
-d file　　　　　文件为目录为真<br>
-c file　　　　　文件为字符特殊文件为真<br>
-b file　　　　　文件为块特殊文件为真<br>
-s file　　　　　文件大小非0时为真<br>
-t file　　　　　当文件描述符(默认为1)指定的设备为终端时为真</p>

<p>含条件选择的shell脚本 对于不含变量的任务简单shell脚本一般能胜任。但在执行一些决策任务时，就需要包含if/then的条件判断了。shell脚本编程支持此类运算，包括比较运算、判断文件是否存在等。<br>
基本的if条件命令选项有： - eq —比较两个参数是否相等（例如，if [ 2 –eq 5 ]）<br>
-ne —比较两个参数是否不相等<br>
-lt —参数1是否小于参数2<br>
-le —参数1是否小于等于参数2<br>
-gt —参数1是否大于参数2<br>
-ge —参数1是否大于等于参数2<br>
-f — 检查某文件是否存在（例如，if [ -f "filename" ]）<br>
-d — 检查目录是否存在<br>
几乎所有的判断都可以用这些比较运算符实现。脚本中常用-f命令选项在执行某一文件之前检查它是否存在</p>

<p><img alt="" class="has" height="314" src="https://img-blog.csdn.net/20180804234721701?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYW5neXVueHVl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="712"></p>

<p> </p>

<p> </p>

<p>echo: 表示输出</p>

<p>read -p "plese input(Y/N):" yn  表示输出打印 </p>

<p>$yn 表示 键盘enter键</p>

<p><img alt="" class="has" height="164" src="https://img-blog.csdn.net/20180804233953974?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYW5neXVueHVl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="501"></p>

<p><img alt="" class="has" height="61" src="https://img-blog.csdn.net/20180804234053840?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYW5neXVueHVl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="489"></p>

<p> </p>            </div>
                </div>