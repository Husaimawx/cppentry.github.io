---
layout:     post
title:      Spark01——Spark概述
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p></p><div class="toc"><h3>Spark概述</h3><ul><ul><li><a href="#1Spark_1" rel="nofollow">1、Spark是什么？</a></li><li><a href="#2Spark_7" rel="nofollow">2、Spark发展历史</a></li><li><a href="#3Spark_14" rel="nofollow">3、为什么要使用Spark?</a></li><li><a href="#4Spark_19" rel="nofollow">4、Spark的特点</a></li><ul><ul><li><a href="#_20" rel="nofollow">速度快</a></li><li><a href="#_30" rel="nofollow">使用方便</a></li><li><a href="#_33" rel="nofollow">通用性</a></li><li><a href="#_38" rel="nofollow">兼容性</a></li></ul></ul></ul></ul></div><p></p>
<h2><a id="1Spark_1"></a>1、Spark是什么？</h2>
<p>Apache Spark™ is a unified analytics engine for large-scale data processing.<br>
—— <a href="http://spark.apache.org/" rel="nofollow">http://spark.apache.org/</a><br>
Spark是用于大规模数据处理的统一分析引擎。<br>
Spark是基于内存计算的大数据并行计算框架。</p>
<h2><a id="2Spark_7"></a>2、Spark发展历史</h2>
<p>2009年诞生于加州大学伯克利分校AMPLab，<br>
2010年开源，<br>
2013年6月成为Apache孵化项目，<br>
2014年2月成为Apache顶级项目。<br>
目前，Spark生态系统已经发展成为一个包含多个子项目的集合，其中包含SparkSQL、Spark Streaming、GraphX、MLlib等子项目。</p>
<h2><a id="3Spark_14"></a>3、为什么要使用Spark?</h2>
<p>Spark是一个开源的类似于Hadoop MapReduce的通用的并行计算框架。<br>
它基于MapReduce算法实现的分布式计算，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Spark中的Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法。<br>
<strong>Spark是MapReduce的替代方案</strong>，兼容HDFS、Hive，并且可融入Hadoop的生态系统，能够弥补MapReduce的不足。</p>
<h2><a id="4Spark_19"></a>4、Spark的特点</h2>
<h4><a id="_20"></a>速度快</h4>
<p>与Hadoop的MapReduce相比，Spark基于内存的运算要快100倍以上，基于硬盘的运算也要快10倍以上。<br>
Spark实现了高效的DAG执行引擎，可以通过基于内存来高效处理数据流。<br>
<img src="https://img-blog.csdn.net/20180926175319485?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZlbmdnbXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="在这里插入图片描述"><br>
spark比MapReduce快的两个主要原因：<br>
–spark的job输出结果可以保存在内存中，MapReduce的job输出结果只能保存在磁盘中。spark可以在内存中获取前面job的数据，MapReduce只能够通过大量的磁盘io进行操作。<br>
–MapReduce是以进程方式运行在集群中；比如有100个maptask，就需要启动100个进程。<br>
spark是以线程的方式运行在进程中。100个maptask可以在一个进程中启动100个线程。</p>
<h4><a id="_30"></a>使用方便</h4>
<p>Spark支持Java、Python和Scala的API，还支持超过80种高级算法，使用户可以快速构建不同的应用。而且Spark支持交互式的Python和Scala的shell，可以非常方便地在这些shell中使用Spark集群来验证解决问题的方法。</p>
<h4><a id="_33"></a>通用性</h4>
<p>Spark提供了统一的解决方案。<br>
Spark可以用于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应用中无缝使用。<br>
<img src="https://img-blog.csdn.net/20180926175623666?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZlbmdnbXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="在这里插入图片描述"></p>
<h4><a id="_38"></a>兼容性</h4>
<p>Runs Everywhere。<br>
Spark可以非常方便地与其他的开源产品进行融合。<br>
例如，Spark可以使用Hadoop的YARN和Apache Mesos作为它的资源管理和调度器，并且可以处理所有Hadoop支持的数据。<br>
可以访问HDFS， Alluxio， Apache Cassandra， Apache HBase， Apache Hive和数百个其他数据源中的数据。<br>
spark程序就是一个计算任务的程序，哪里可以给当前这个任务提供计算资源，就可以把这个程序提交到哪里去运行.</p>
<p>参考Spark官网： <a href="http://spark.apache.org/" rel="nofollow">http://spark.apache.org/</a></p>

            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>