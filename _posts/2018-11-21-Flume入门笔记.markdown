---
layout:     post
title:      Flume入门笔记
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/paicMis/article/details/53607069				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>在具体介绍本文内容之前，先给大家看一下Hadoop业务的整体开发流程：  <br>
  <img src="https://img-blog.csdn.net/20161213103516860?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFpY01pcw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
从Hadoop的业务开发流程图中可以看出，在大数据的业务处理过程中，对于数据的采集是十分重要的一步，也是不可避免的一步，从而引出我们本文的主角—Flume。本文将围绕Flume的架构、Flume的应用(日志采集)进行详细的介绍。  <br>
<strong>（一）Flume架构介绍</strong>  <br>
<strong>1、Flume的概念</strong>  <br>
  <img src="https://img-blog.csdn.net/20161213103535280?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFpY01pcw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
flume是分布式的日志收集系统，它将各个服务器中的数据收集起来并送到指定的地方去，比如说送到图中的HDFS，简单来说flume就是收集日志的。  <br>
<strong>2、Event的概念</strong>  <br>
在这里有必要先介绍一下flume中event的相关概念：flume的核心是把数据从数据源(source)收集过来，在将收集到的数据送到指定的目的地(sink)。为了保证输送的过程一定成功，在送到目的地(sink)之前，会先缓存数据(channel),待数据真正到达目的地(sink)后，flume在删除自己缓存的数据。  <br>
在整个数据的传输的过程中，流动的是event，即事务保证是在event级别进行的。那么什么是event呢？—–event将传输的数据进行封装，是flume传输数据的基本单位，如果是文本文件，通常是一行记录，event也是事务的基本单位。event从source，流向channel，再到sink，本身为一个字节数组，并可携带headers(头信息)信息。event代表着一个数据的最小完整单元，从外部数据源来，向外部的目的地去。  <br>
为了方便大家理解，给出一张event的数据流向图：  <br>
  <img src="https://img-blog.csdn.net/20161213103556266?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFpY01pcw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
一个完整的event包括：event headers、event body、event信息(即文本文件中的单行记录)，如下所以：  <br>
  <img src="https://img-blog.csdn.net/20161213103616657?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFpY01pcw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
其中event信息就是flume收集到的日记记录。  <br>
<strong>3、flume架构介绍</strong>  <br>
flume之所以这么神奇，是源于它自身的一个设计，这个设计就是agent，agent本身是一个Java进程，运行在日志收集节点—所谓日志收集节点就是服务器节点。  <br>
agent里面包含3个核心的组件：source—-&gt;channel—–&gt;sink,类似生产者、仓库、消费者的架构。  <br>
source：source组件是专门用来收集数据的，可以处理各种类型、各种格式的日志数据,包括Avro、Thrift、Exec、JMS、Spooling Directory、Taildir、Twitter、Kafka、NetCat、Sequence、Syslog、Multiport Syslog TCP、Syslog UDP、HTTP、Stress Legacy、Avro Legacy、Thrift Legacy、Custom、Scribe。  <br>
channel：source组件把数据收集来以后，临时存放在channel中，即channel组件在agent中是专门用来存放临时数据的——对采集到的数据进行简单的缓存，可以存放在Memory、JDBC、Kafka、File、Spillable Memory、Pseudo Transaction、Custom <br>
sink：sink组件是用于把数据发送到目的地的组件，目的地包括HDFS、Hive、Logger、Avro、Thrift、IRC、File Roll、Null、HBase、AsyncHBase、MorphlineSolr、ElasticSearch、Kite Dataset、Kafka、Custom  <br>
<strong>4、flume的运行机制</strong>  <br>
flume的核心就是一个agent，这个agent对外有两个进行交互的地方，一个是接受数据的输入——source，一个是数据的输出sink，sink负责将数据发送到外部指定的目的地。source接收到数据之后，将数据发送给channel，chanel作为一个数据缓冲区会临时存放这些数据，随后sink会将channel中的数据发送到指定的地方—-例如HDFS等，注意：只有在sink将channel中的数据成功发送出去之后，channel才会将临时数据进行删除，这种机制保证了数据传输的可靠性与安全性。  <br>
<strong>5、flume的广义用法</strong>  <br>
flume之所以这么神奇—-其原因也在于flume可以支持多级flume的agent，即flume可以前后相继，例如sink可以将数据写到下一个agent的source中，这样的话就可以连成串了，可以整体处理了。flume还支持扇入(fan-in)、扇出(fan-out)。所谓扇入就是source可以接受多个输入，所谓扇出就是sink可以将数据输出多个目的地destination中。  <br>
 <img src="https://img-blog.csdn.net/20161213103641141?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFpY01pcw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
  <img src="https://img-blog.csdn.net/20161213103649235?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFpY01pcw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p><strong>（二）flume应用—日志采集</strong>  <br>
对于flume的原理其实很容易理解，我们更应该掌握flume的具体使用方法，flume提供了大量内置的Source、Channel和Sink类型。而且不同类型的Source、Channel和Sink可以自由组合—–组合方式基于用户设置的配置文件，非常灵活。比如：Channel可以把事件暂存在内存里，也可以持久化到本地硬盘上。Sink可以把日志写入HDFS, HBase，甚至是另外一个Source等等。下面我将用具体的案例详述flume的具体用法。  <br>
其实flume的用法很简单—-书写一个配置文件，在配置文件当中描述source、channel与sink的具体实现，而后运行一个agent实例，在运行agent实例的过程中会读取配置文件的内容，这样flume就会采集到数据。  <br>
配置文件的编写原则：  <br>
1&gt;从整体上描述代理agent中sources、sinks、channels所涉及到的组件</p>



<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor"># example.conf: A single-node Flume configuration</span>

<span class="hljs-preprocessor"># Name the components on this agent</span>
a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span>
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.channels</span> = c1</code></pre>

<p>2&gt;详细描述agent中每一个source、sink与channel的具体实现：即在描述source的时候，需要  <br>
指定source到底是什么类型的，即这个source是接受文件的、还是接受http的、还是接受thrift  <br>
的；对于sink也是同理，需要指定结果是输出到HDFS中，还是Hbase中啊等等；对于channel  <br>
需要指定是内存啊，还是数据库啊，还是文件啊等等。</p>



<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor"># Describe/configure the source</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = netcat
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.bind</span> = localhost
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.port</span> = <span class="hljs-number">44444</span>

<span class="hljs-preprocessor"># Describe the sink</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = logger

<span class="hljs-preprocessor"># Use a channel which buffers events in memory</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = memory
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.capacity</span> = <span class="hljs-number">1000</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.transactionCapacity</span> = <span class="hljs-number">100</span>
<span class="hljs-number">3</span>&gt;通过channel将source与sink连接起来</code></pre>



<h1 id="bind-the-source-and-sink-to-the-channel">Bind the source and sink to the channel</h1>



<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1</code></pre>

<p>4&gt;启动agent的shell操作：</p>



<pre class="prettyprint"><code class=" hljs brainfuck"><span class="hljs-comment">$</span> <span class="hljs-comment">bin/flume</span><span class="hljs-literal">-</span><span class="hljs-comment">ng</span> <span class="hljs-comment">agent</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">conf</span> <span class="hljs-comment">conf</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">conf</span><span class="hljs-literal">-</span><span class="hljs-comment">file</span> <span class="hljs-comment">example</span><span class="hljs-string">.</span><span class="hljs-comment">conf</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">name</span> <span class="hljs-comment">a1</span> <span class="hljs-literal">-</span><span class="hljs-comment">Dflume</span><span class="hljs-string">.</span><span class="hljs-comment">root</span><span class="hljs-string">.</span><span class="hljs-comment">logger=INFO</span><span class="hljs-string">,</span><span class="hljs-comment">console</span></code></pre>

<p>参数说明： -n 指定agent名称(与配置文件中代理的名字相同)  <br>
-c 指定flume中配置文件的目录  <br>
-f 指定配置文件  <br>
-Dflume.root.logger=DEBUG,console 设置日志等级</p>

<p>具体案例：  <br>
<strong>案例1：</strong> exec Source：监听一个指定的文件，即只要应用程序向这个文件里面写数据，这个source组件就可以获取到信息。 其中 Sink：logger Channel：memory </p>

<p>flume官网中exec Source描述： <br>
Property Name   Default Description <br>
channels    – <br>
type    –   The component type name, needs to be exec <br>
command –   需要执行的命令</p>

<p>a)  编写配置文件：</p>



<pre class="prettyprint"><code class=" hljs avrasm">a<span class="hljs-preprocessor">.sinks</span>=k1
a<span class="hljs-preprocessor">.sources</span>=s1 s2
a<span class="hljs-preprocessor">.channels</span>=<span class="hljs-built_in">r1</span>

a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>1<span class="hljs-preprocessor">.type</span>=exec
a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>1<span class="hljs-preprocessor">.command</span>=tail -F /root/a<span class="hljs-preprocessor">.log</span>

a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>2<span class="hljs-preprocessor">.type</span>=exec
a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>2<span class="hljs-preprocessor">.command</span>=tail -F /root/b<span class="hljs-preprocessor">.log</span>


a<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span>=logger
a<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span>=memory
a<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.capacity</span>=<span class="hljs-number">100</span>
a<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.transactionCapacity</span>=<span class="hljs-number">100</span>



a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>2<span class="hljs-preprocessor">.channels</span>=<span class="hljs-built_in">r1</span>
a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>1<span class="hljs-preprocessor">.channels</span>=<span class="hljs-built_in">r1</span>
a<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span>=<span class="hljs-built_in">r1</span></code></pre>

<p>b)  启动flume agent a1 服务端</p>



<pre class="prettyprint"><code class=" hljs brainfuck"><span class="hljs-string">.</span><span class="hljs-comment">/flume</span><span class="hljs-literal">-</span><span class="hljs-comment">ng</span> <span class="hljs-comment">agent</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">conf</span> <span class="hljs-comment">conf</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">conf</span><span class="hljs-literal">-</span><span class="hljs-comment">file</span> <span class="hljs-string">.</span><span class="hljs-string">.</span><span class="hljs-comment">/conf/flume_conf</span><span class="hljs-string">.</span><span class="hljs-comment">conf</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">name</span> <span class="hljs-comment">a</span> <span class="hljs-literal">-</span><span class="hljs-comment">Dflume</span><span class="hljs-string">.</span><span class="hljs-comment">root</span><span class="hljs-string">.</span><span class="hljs-comment">logger=INFO</span><span class="hljs-string">,</span><span class="hljs-comment">console</span></code></pre>

<p>c) 使用telnet发送数据</p>



<pre class="prettyprint"><code class=" hljs mel">[root<span class="hljs-variable">@SZB</span>-L0032016 ~]# echo <span class="hljs-string">"the big data"</span>&gt;&gt;./a.<span class="hljs-keyword">log</span>
[root<span class="hljs-variable">@SZB</span>-L0032016 ~]# echo <span class="hljs-string">"the big data"</span>&gt;&gt;./a.<span class="hljs-keyword">log</span></code></pre>

<p>d) 在控制台上查看flume收集到的日志数据： <br>
 <img src="https://img-blog.csdn.net/20161213103844705?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFpY01pcw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>**案例2：**exec Source：监听一个指定的文件，即只要应用程序向这个文件里面写数据，这个source组件就可以获取到信息。 其中 Sink：hdfs  Channel：file (相比于案例1的两个变化)  <br>
flume官网中HDFS Sink的描述：  <br>
Name    Default Description <br>
channel – <br>
type    –   The component type name, needs to be hdfs <br>
hdfs.path   –   HDFS的路径 <br>
hdfs.filePrefix  生成文件的路径 <br>
hdfs.fileSuffix –   文件的后缀 <br>
hdfs.inUsePrefix    正在使用的时候临时文件的路径 <br>
hdfs.inUseSuffix    正在使用的时候临时文件的后缀 <br>
hdfs.rollInterval   30  当前写入文件的滚动间隔，每个30S生成一个文件，0表示不基于时间间隔滚动 <br>
hdfs.rollSize   1024    基于文件大小滚动，单位是字节 0表示不基于大小滚动 <br>
hdfs.rollCount  10  写入的事件数触发文件的滚动，0表示不滚动 <br>
hdfs.idleTimeout    0   Timeout after which inactive files get closed (0 = disable automatic closing of idle files) <br>
hdfs.batchSize  100 事件写入HDFS的数量 <br>
hdfs.codeC  –   压缩 格式: gzip, bzip2, lzo, lzop, snappy <br>
hdfs.fileType   SequenceFile    文件格式 <br>
hdfs.maxOpenFiles   5000    允许文件打开的次数 <br>
a)  编写配置文件：</p>



<pre class="prettyprint"><code class=" hljs avrasm">a<span class="hljs-preprocessor">.sinks</span>=k1
a<span class="hljs-preprocessor">.sources</span>=s1 s2
a<span class="hljs-preprocessor">.channels</span>=<span class="hljs-built_in">r1</span>

a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>1<span class="hljs-preprocessor">.type</span>=exec
a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>1<span class="hljs-preprocessor">.command</span>=tail -F /root/a<span class="hljs-preprocessor">.log</span>

a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>2<span class="hljs-preprocessor">.type</span>=exec
a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>2<span class="hljs-preprocessor">.command</span>=tail -F /root/b<span class="hljs-preprocessor">.log</span>


a<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span>=hdfs
a<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.path</span> = hdfs://<span class="hljs-number">10.20</span><span class="hljs-number">.24</span><span class="hljs-number">.231</span>:<span class="hljs-number">8020</span>/flume
a<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.writeFormat</span> = Text
a<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.fileType</span> = DataStream
a<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.rollInterval</span> = <span class="hljs-number">10</span>
a<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.rollSize</span> = <span class="hljs-number">0</span>
a<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.rollCount</span> = <span class="hljs-number">0</span>
a<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.filePrefix</span> = %<span class="hljs-built_in">Y</span>-%m-%d-%H-%M-%S
a<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.useLocalTimeStamp</span> = true


a<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span>=file
a<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.checkpointDir</span>=/root/flume/checkpoint
a<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.dataDirs</span>=/root/flume/data

a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>2<span class="hljs-preprocessor">.channels</span>=<span class="hljs-built_in">r1</span>
a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>1<span class="hljs-preprocessor">.channels</span>=<span class="hljs-built_in">r1</span>
a<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span>=<span class="hljs-built_in">r1</span></code></pre>

<p>b) 启动flume agent a 服务端</p>



<pre class="prettyprint"><code class=" hljs lasso"><span class="hljs-built_in">.</span>/flume<span class="hljs-attribute">-ng</span>  agent <span class="hljs-attribute">-n</span> a <span class="hljs-attribute">-c</span> <span class="hljs-built_in">..</span>/conf  <span class="hljs-attribute">-f</span> <span class="hljs-built_in">..</span>/conf/flume_hdfs<span class="hljs-built_in">.</span>conf   <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>DEBUG,console</code></pre>

<p>c)  向文件追加内容</p>



<pre class="prettyprint"><code class=" hljs mel">[root<span class="hljs-variable">@SZB</span>-L0032016 ~]# echo <span class="hljs-string">"test big data"</span>&gt;./a.<span class="hljs-keyword">log</span></code></pre>

<p>d)  在HDFS中查看flume收集到的日志数据： <br>
 <img src="https://img-blog.csdn.net/20161213103916674?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFpY01pcw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>**案例3：**Spooling Directory Source：监听一个指定的目录，即只要应用程序向这个指定的目录中添加新的文件，source组件就可以获取到该信息，并解析该文件的内容，然后写入到channle。写入完成后，标记该文件已完成或者删除该文件。其中 Sink：logger Channel：memory  <br>
flume官网中Spooling Directory Source描述： <br>
Property Name       Default      Description <br>
channels              – <br>
type                  –          The component type name, needs to be spooldir. <br>
spoolDir              –          Spooling Directory Source监听的目录 <br>
fileSuffix         .COMPLETED    文件内容写入到channel之后，标记该文件 <br>
deletePolicy       never         文件内容写入到channel之后的删除策略: never or immediate <br>
fileHeader         false         Whether to add a header storing the absolute path filename. <br>
ignorePattern      ^$           Regular expression specifying which files to ignore (skip) <br>
interceptors          –          指定传输中event的head(头信息)，常用timestamp</p>

<p>Spooling Directory Source的两个注意事项： <br>
①If a file is written to after being placed into the spooling directory, Flume will print an error to its log file and stop processing. <br>
即：拷贝到spool目录下的文件不可以再打开编辑 <br>
②If a file name is reused at a later time, Flume will print an error to its log file and stop processing. <br>
即：不能将具有相同文件名字的文件拷贝到这个目录下 <br>
a)  编写配置文件：</p>



<pre class="prettyprint"><code class=" hljs avrasm">a<span class="hljs-preprocessor">.sinks</span>=k1
a<span class="hljs-preprocessor">.sources</span>=s1 s2
a<span class="hljs-preprocessor">.channels</span>=<span class="hljs-built_in">r1</span>

a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>1<span class="hljs-preprocessor">.type</span> = spooldir
a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>1<span class="hljs-preprocessor">.spoolDir</span> = /root/flume/spool
a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>1<span class="hljs-preprocessor">.fileHeader</span> = true
a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>1<span class="hljs-preprocessor">.interceptors</span> = i1
a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>1<span class="hljs-preprocessor">.interceptors</span><span class="hljs-preprocessor">.i</span>1<span class="hljs-preprocessor">.type</span> = timestamp

a<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span>=logger

a<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span>=memory
a<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.capacity</span>=<span class="hljs-number">100</span>
a<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.transactionCapacity</span>=<span class="hljs-number">100</span>

a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>2<span class="hljs-preprocessor">.channels</span>=<span class="hljs-built_in">r1</span>
a<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.s</span>1<span class="hljs-preprocessor">.channels</span>=<span class="hljs-built_in">r1</span>
a<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span>=<span class="hljs-built_in">r1</span></code></pre>

<p>b) 启动flume agent a1 服务端</p>



<pre class="prettyprint"><code class=" hljs lasso"><span class="hljs-built_in">.</span>/flume<span class="hljs-attribute">-ng</span>  agent <span class="hljs-attribute">-n</span> a  <span class="hljs-attribute">-c</span> <span class="hljs-built_in">..</span>/conf  <span class="hljs-attribute">-f</span> <span class="hljs-built_in">..</span>/conf/flume_spool<span class="hljs-built_in">.</span>conf   <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>DEBUG,console</code></pre>

<p>b)  使用cp命令向Spooling Directory 中发送数据</p>



<pre class="prettyprint"><code class=" hljs ruby">[root<span class="hljs-variable">@SZB</span>-<span class="hljs-constant">L0032016</span> flume]<span class="hljs-comment"># cp ~/a.log ./spool/</span></code></pre>

<p>c)  在控制台上查看flume收集到的日志数据 <br>
 <img src="https://img-blog.csdn.net/20161213103945877?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFpY01pcw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
从控制台显示的结果可以看出event的头信息中包含了时间戳信息。  <br>
同时我们查看一下Spooling Directory中的datafile信息—-文件内容写入到channel之后，该文件被标记了：</p>



<pre class="prettyprint"><code class=" hljs avrasm">[root@SZB-L0032016 spool]<span class="hljs-preprocessor"># ll</span>
total <span class="hljs-number">4</span>
-rw-r--r-- <span class="hljs-number">1</span> root root <span class="hljs-number">14</span> <span class="hljs-keyword">Dec</span> <span class="hljs-number">13</span> <span class="hljs-number">09</span>:<span class="hljs-number">38</span> a<span class="hljs-preprocessor">.log</span><span class="hljs-preprocessor">.COMPLETED</span></code></pre>

<p>参考文章<a href="http://blog.csdn.net/a2011480169/article/details/51544664" rel="nofollow">http://blog.csdn.net/a2011480169/article/details/51544664</a></p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>