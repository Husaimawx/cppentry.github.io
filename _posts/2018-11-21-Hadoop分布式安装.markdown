---
layout:     post
title:      Hadoop分布式安装
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>1、使用hadoop用户解压并安装到apps路径下<br>
1.1使用hadoop用户进入到在/home/hadoop/apps目录下<br>
cd /home/hadoop/apps</p>

<p>注意：如果没有/home/hadoop/apps路径，自行在/home/hadoop路径下创建apps文件夹：mkdir /home/Hadoop/apps<br>
1.2使用rz将本机的hadoop安装包上传到/home/hadoop/apps目录下<br>
1.3解压安装文件<br>
tar -zxvf hadoop-2.7.4.tar.gz<br>
1.4使用root用户创建软链接<br>
ln -s /home/hadoop/apps/hadoop-2.7.4 /usr/local/hadoop<br>
1.5使用root用户修改软链接属主<br>
chown -R hadoop:hadoop /usr/local/hadoop</p>

<p><br>
1.6使用root用户将hadoop相关内容添加到环境变量中<br>
注意：Hadoop配置文件路径是/usr/local/hadoop/etc/hadoop<br>
vim /etc/profile<br>
添加内容如下：<br>
export HADOOP_HOME=/usr/local/hadoop<br>
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop<br>
export YARN_HOME=$HADOOP_HOME<br>
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop<br>
export PATH=$PATH:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin<br>
1.7使用root用户重新编译环境变量使配置生效<br>
source /etc/profile</p>

<p>2. 配置HDFS<br>
2.1使用hadoop用户进入到Hadoop配置文件路径<br>
     cd /usr/local/hadoop/etc/hadoop<br>
2.2修改hadoop-env.sh<br>
修改JDK路径export JAVA_HOME=/usr/local/jdk<br>
2.3 配置core-site.xml<span style="color:#f33b45;">（具体配置文件在最下面）</span><br>
2.4 配置hdfs-site.xml</p>

<p>3. 配置YARN<br>
3.1 修改yarn-site.xml<br>
3.2 修改mapred-site.xml<br>
3.3 在/usr/local/hadoop路径下创建hdpdata文件夹<br>
cd /usr/local/hadoop<br>
mkdir hdpdata</p>

<p>4. 修改slaves文件，设置datanode和nodemanager启动节点主机名称<br>
在slaves文件中添加节点的主机名称<br>
node03<br>
node04<br>
node05</p>

<p>注意：node03，node04，node05是我的虚拟机主机名称，在这三台机器上启动datanode和nodemanager，同学根据自己集群主机名称情况自行修改。</p>

<p>5. 配置hadoop用户免密码登陆<br>
配置node01到node01、node02、node03、node04、node05的免密码登陆<br>
在node01上生产一对钥匙<br>
ssh-keygen -t rsa<br>
将公钥拷贝到其他节点，包括自己本机<br>
ssh-copy-id -i node01<br>
ssh-copy-id -i node02<br>
ssh-copy-id -i node03<br>
ssh-copy-id -i node04<br>
ssh-copy-id -i node05</p>

<p>配置node02到node01、node02、node03、node04、node05的免密码登陆<br>
在node02上生产一对钥匙<br>
ssh-keygen -t rsa<br>
将公钥拷贝到其他节点，包括自己本机<br>
ssh-copy-id -i node01<br>
ssh-copy-id -i node02<br>
ssh-copy-id -i node03<br>
ssh-copy-id -i node04<br>
ssh-copy-id -i node05<br>
注意：两个namenode之间要配置ssh免密码登陆</p>

<p>6. 将配置好的hadoop拷贝到其他节点<br>
scp -r hadoop-2.7.4 hadoop@node02:/home/hadoop/apps<br>
scp -r hadoop-2.7.4 hadoop@node03:/home/hadoop/apps<br>
scp -r hadoop-2.7.4 hadoop@node04:/home/hadoop/apps<br>
scp -r hadoop-2.7.4 hadoop@node05:/home/hadoop/apps</p>

<p>在每个节点分别执行如下四步操作<br>
第一步：使用root用户创建软链接<br>
ln -s /home/hadoop/apps/hadoop-2.7.4 /usr/local/hadoop<br>
第二步：使用root用户修改软链接属主<br>
chown -R hadoop:hadoop /usr/local/hadoop<br>
第三步：使用root用户添加环境变量<br>
vim /etc/profile<br>
添加内容：<br>
export HADOOP_HOME=/usr/local/hadoop<br>
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop<br>
export YARN_HOME=$HADOOP_HOME<br>
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop</p>

<p>export PATH=$PATH:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin<br>
第四步：使用root用户重新编译环境变量使配置生效<br>
source /etc/profile</p>

<p><br>
集群启动步骤<br>
（注意使用hadoop用户启动，严格按照顺序启动）<br>
su hadoop<br>
1. 启动journalnode（分别在node03、node04、node05上执行启动）<br>
/usr/local/hadoop/sbin/hadoop-daemon.sh start journalnode<br>
运行jps命令检验，node03、node04、node05上多了JournalNode进程<br>
2. 格式化HDFS<br>
在node01上执行命令:<br>
hdfs namenode -format<br>
格式化成功之后会在core-site.xml中的hadoop.tmp.dir指定的路径下生成dfs文件夹，将该文件夹拷贝到node02的相同路径下<br>
scp -r hdpdata hadoop@node02:/usr/local/hadoop</p>

<p>3. 在node01上执行格式化ZKFC操作<br>
hdfs zkfc -formatZK<br>
执行成功，日志输出如下信息<br>
INFO ha.ActiveStandbyElector: Successfully created /hadoop-ha/ns in ZK<br>
4. 在node01上启动HDFS<br>
sbin/start-dfs.sh<br>
5. 在node02上启动YARN<br>
sbin/start-yarn.sh<br>
在node01单独启动一个ResourceManager作为备份节点<br>
sbin/yarn-daemon.sh start resourcemanager<br>
6. 在node02上启动JobHistoryServer<br>
sbin/mr-jobhistory-daemon.sh start historyserver<br>
启动完成node02会增加一个JobHistoryServer进程<br>
7. hadoop安装启动完成<br>
HDFS HTTP访问地址<br>
NameNode (active)：http://192.168.183.100:50070<br>
NameNode (standby)：http://192.168.183.101:50070<br>
ResourceManager HTTP访问地址<br>
ResourceManager ：http://192.168.183.101:8088<br>
历史日志HTTP访问地址<br>
JobHistoryServer：http://192.168.183.101:19888</p>

<p>集群验证<br>
1. 验证HDFS 是否正常工作及HA高可用<br>
首先向hdfs上传一个文件</p>

<p>hadoop fs -put /usr/local/hadoop/README.txt /<br>
在active节点手动关闭active的namenode<br>
sbin/hadoop-daemon.sh stop namenode<br>
通过HTTP 50070端口查看standby namenode的状态是否转换为active<br>
手动启动上一步关闭的namenode<br>
sbin/hadoop-daemon.sh start namenode</p>

<p>2.验证YARN是否正常工作及ResourceManager HA高可用<br>
运行测试hadoop提供的demo中的WordCount程序：<br>
hadoop fs -mkdir /wordcount<br>
hadoop fs -mkdir /wordcount/input<br>
hadoop fs -mv /README.txt /wordcount/input<br>
hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.4.jar wordcount /wordcount/input  /wordcount/output</p>

<p>验证ResourceManager HA<br>
手动关闭node02的ResourceManager<br>
sbin/yarn-daemon.sh stop resourcemanager<br>
通过HTTP 8088端口访问node01的ResourceManager查看状态<br>
手动启动node02 的ResourceManager<br>
sbin/yarn-daemon.sh start resourcemanager</p>

<p> </p>

<p><span style="color:#f33b45;">配置文件（1）core-site.xml</span></p>

<p>&lt;?xml version="1.0" encoding="UTF-8"?&gt;<br>
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;<br>
&lt;!--<br>
  Licensed under the Apache License, Version 2.0 (the "License");<br>
  you may not use this file except in compliance with the License.<br>
  You may obtain a copy of the License at</p>

<p>    http://www.apache.org/licenses/LICENSE-2.0</p>

<p>  Unless required by applicable law or agreed to in writing, software<br>
  distributed under the License is distributed on an "AS IS" BASIS,<br>
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br>
  See the License for the specific language governing permissions and<br>
  limitations under the License. See accompanying LICENSE file.<br>
--&gt;</p>

<p>&lt;!-- Put site-specific property overrides in this file. --&gt;</p>

<p>&lt;configuration&gt;<br>
    &lt;!-- 指定hdfs的nameservice名称空间为ns --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;fs.defaultFS&lt;/name&gt;<br>
        &lt;value&gt;hdfs://ns&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 指定hadoop临时目录,默认在/tmp/{$user}目录下，不安全，每次开机都会被清空--&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;<br>
        &lt;value&gt;/usr/local/hadoop/hdpdata/&lt;/value&gt;<br>
        &lt;description&gt;需要手动创建hdpdata目录&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 指定zookeeper地址 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;<br>
        &lt;value&gt;node01:2181,node02:2181,node03:2181&lt;/value&gt;<br>
        &lt;description&gt;zookeeper地址，多个用逗号隔开&lt;/description&gt;<br>
    &lt;/property&gt;<br>
&lt;/configuration&gt;</p>

<p> </p>

<p><span style="color:#f33b45;">（2）hdfs-site.xml</span></p>

<p>&lt;?xml version="1.0" encoding="UTF-8"?&gt;<br>
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;<br>
&lt;!--<br>
  Licensed under the Apache License, Version 2.0 (the "License");<br>
  you may not use this file except in compliance with the License.<br>
  You may obtain a copy of the License at</p>

<p>    http://www.apache.org/licenses/LICENSE-2.0</p>

<p>  Unless required by applicable law or agreed to in writing, software<br>
  distributed under the License is distributed on an "AS IS" BASIS,<br>
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br>
  See the License for the specific language governing permissions and<br>
  limitations under the License. See accompanying LICENSE file.<br>
--&gt;</p>

<p>&lt;!-- Put site-specific property overrides in this file. --&gt;</p>

<p>&lt;configuration&gt;<br>
    &lt;!-- NameNode HA配置 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.nameservices&lt;/name&gt;<br>
        &lt;value&gt;ns&lt;/value&gt;<br>
        &lt;description&gt;指定hdfs的nameservice为ns，需要和core-site.xml中的保持一致&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.ha.namenodes.ns&lt;/name&gt;<br>
        &lt;value&gt;nn1,nn2&lt;/value&gt;<br>
        &lt;description&gt;ns命名空间下有两个NameNode，逻辑代号，随便起名字，分别是nn1，nn2&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.namenode.rpc-address.ns.nn1&lt;/name&gt;<br>
        &lt;value&gt;node01:9000&lt;/value&gt;<br>
        &lt;description&gt;nn1的RPC通信地址&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.namenode.http-address.ns.nn1&lt;/name&gt;<br>
        &lt;value&gt;node01:50070&lt;/value&gt;<br>
        &lt;description&gt;nn1的http通信地址&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.namenode.rpc-address.ns.nn2&lt;/name&gt;<br>
        &lt;value&gt;node02:9000&lt;/value&gt;<br>
        &lt;description&gt;nn2的RPC通信地址&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.namenode.http-address.ns.nn2&lt;/name&gt;<br>
        &lt;value&gt;node02:50070&lt;/value&gt;<br>
        &lt;description&gt;nn2的http通信地址&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;!--JournalNode配置 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;<br>
        &lt;value&gt;qjournal://node03:8485;node04:8485;node05:8485/ns&lt;/value&gt;<br>
        &lt;description&gt;指定NameNode的edits元数据在JournalNode上的存放位置&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;<br>
        &lt;value&gt;/usr/local/hadoop/journaldata&lt;/value&gt;<br>
        &lt;description&gt;指定JournalNode在本地磁盘存放数据的位置&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;!--namenode高可用主备切换配置 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;<br>
        &lt;value&gt;true&lt;/value&gt;<br>
        &lt;description&gt;开启NameNode失败自动切换&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.client.failover.proxy.provider.ns&lt;/name&gt;<br>
        &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;<br>
        &lt;description&gt;配置失败自动切换实现方式,使用内置的zkfc&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;<br>
        &lt;value&gt;<br>
            sshfence<br>
            shell(/bin/true)<br>
        &lt;/value&gt;<br>
        &lt;description&gt;配置隔离机制，多个机制用换行分割，先执行sshfence，执行失败后执行shell(/bin/true)，/bin/true会直接返回0表示成功&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;<br>
        &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;<br>
        &lt;description&gt;使用sshfence隔离机制时需要ssh免登陆&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;<br>
        &lt;value&gt;30000&lt;/value&gt;<br>
        &lt;description&gt;配置sshfence隔离机制超时时间&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;!--dfs文件属性设置--&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;dfs.replication&lt;/name&gt;<br>
        &lt;value&gt;3&lt;/value&gt;<br>
        &lt;description&gt;设置block副本数为3&lt;/description&gt;<br>
    &lt;/property&gt;</p>

<p>    &lt;property&gt;<br>
        &lt;name&gt;dfs.block.size&lt;/name&gt;<br>
        &lt;value&gt;134217728&lt;/value&gt;<br>
        &lt;description&gt;设置block大小是128M&lt;/description&gt;<br>
    &lt;/property&gt;<br>
&lt;/configuration&gt;</p>

<p> </p>

<p><span style="color:#f33b45;">（3）mapred-site.xml</span></p>

<p>&lt;?xml version="1.0"?&gt;<br>
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;<br>
&lt;!--<br>
  Licensed under the Apache License, Version 2.0 (the "License");<br>
  you may not use this file except in compliance with the License.<br>
  You may obtain a copy of the License at</p>

<p>    http://www.apache.org/licenses/LICENSE-2.0</p>

<p>  Unless required by applicable law or agreed to in writing, software<br>
  distributed under the License is distributed on an "AS IS" BASIS,<br>
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br>
  See the License for the specific language governing permissions and<br>
  limitations under the License. See accompanying LICENSE file.<br>
--&gt;</p>

<p>&lt;!-- Put site-specific property overrides in this file. --&gt;</p>

<p>&lt;configuration&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;<br>
        &lt;value&gt;yarn&lt;/value&gt;<br>
        &lt;description&gt;指定mr框架为yarn方式 &lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 历史日志服务jobhistory相关配置 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;<br>
        &lt;value&gt;node02:10020&lt;/value&gt;<br>
        &lt;description&gt;历史服务器端口号&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;<br>
        &lt;value&gt;node02:19888&lt;/value&gt;<br>
        &lt;description&gt;历史服务器的WEB UI端口号&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;mapreduce.jobhistory.joblist.cache.size&lt;/name&gt;<br>
        &lt;value&gt;2000&lt;/value&gt;<br>
        &lt;description&gt;内存中缓存的historyfile文件信息(主要是job对应的文件目录)&lt;/description&gt;<br>
    &lt;/property&gt;<br>
&lt;/configuration&gt;</p>

<p><br><span style="color:#f33b45;">（4）yarn-site.xml</span></p>

<p>&lt;?xml version="1.0"?&gt;<br>
&lt;!--<br>
  Licensed under the Apache License, Version 2.0 (the "License");<br>
  you may not use this file except in compliance with the License.<br>
  You may obtain a copy of the License at</p>

<p>    http://www.apache.org/licenses/LICENSE-2.0</p>

<p>  Unless required by applicable law or agreed to in writing, software<br>
  distributed under the License is distributed on an "AS IS" BASIS,<br>
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br>
  See the License for the specific language governing permissions and<br>
  limitations under the License. See accompanying LICENSE file.<br>
--&gt;<br>
&lt;configuration&gt;<br>
    &lt;!-- 开启RM高可用 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;<br>
        &lt;value&gt;true&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 指定RM的cluster id，一组高可用的rm共同的逻辑id --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;<br>
        &lt;value&gt;yarn-ha&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 指定RM的名字，可以随便自定义 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;<br>
        &lt;value&gt;rm1,rm2&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 分别指定RM的地址 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;<br>
        &lt;value&gt;node01&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.resourcemanager.webapp.address.rm1&lt;/name&gt;<br>
        &lt;value&gt;${yarn.resourcemanager.hostname.rm1}:8088&lt;/value&gt;<br>
        &lt;description&gt;HTTP访问的端口号&lt;/description&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;<br>
        &lt;value&gt;node02&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.resourcemanager.webapp.address.rm2&lt;/name&gt;<br>
        &lt;value&gt;${yarn.resourcemanager.hostname.rm2}:8088&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 指定zookeeper集群地址 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;<br>
        &lt;value&gt;node01:2181,node02:2181,node03:2181&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!--NodeManager上运行的附属服务，需配置成mapreduce_shuffle，才可运行MapReduce程序--&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;<br>
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 开启日志聚合 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;<br>
        &lt;value&gt;true&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 日志聚合HDFS目录 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;<br>
        &lt;value&gt;/data/hadoop/yarn-logs&lt;/value&gt;<br>
    &lt;/property&gt;<br>
    &lt;!-- 日志保存时间3days,单位秒 --&gt;<br>
    &lt;property&gt;<br>
        &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;<br>
        &lt;value&gt;259200&lt;/value&gt;<br>
    &lt;/property&gt;<br>
&lt;/configuration&gt;</p>

<p> </p>            </div>
                </div>