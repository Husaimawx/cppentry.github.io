---
layout:     post
title:      Flume指南
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：					https://blog.csdn.net/vinfly_li/article/details/79396991				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h1 id="flume基础">Flume基础</h1>

<p>标签（空格分隔）： Flume</p>

<hr>



<h2 id="flume概述">Flume概述</h2>

<p>Flume是一个分布式的,可靠的,可用的,非常有效率的对大数据量的日志数据进行收集,聚集,移动信息的服务,Flume仅仅运行在linux环境下,它是一个基于流式的数据的灵活的架构,具有健壮和容错性,官网中这样解释健壮和容错: <br>
The events are staged in a channel on each agent. The events are then delivered to the next agent or terminal repository (like HDFS) in the flow. The events are removed from a channel only after they are stored in the channel of next agent or in the terminal repository. This is a how the single-hop message delivery semantics in Flume provide end-to-end reliability of the flow.</p>

<p>Flume uses a transactional approach to guarantee the reliable delivery of the events. The sources and sinks encapsulate in a transaction the storage/retrieval, respectively, of the events placed in or provided by a transaction provided by the channel. This ensures that the set of events are reliably passed from point to point in the flow. In the case of a multi-hop flow, the sink from the previous hop and the source from the next hop both have their transactions running to ensure that the data is safely stored in the channel of the next hop. <br>
它的基本架构: <br>
<img src="http://static.zybuluo.com/vin123456/44k9tsj4jewa4bpt7ifm8q73/image_1av6f3ugq1ir5m9518uqol0jek9.png" alt="image_1av6f3ugq1ir5m9518uqol0jek9.png-169.4kB" title=""> <br>
Flume就是一个agent服务器,agent有source,channel,sink组成 <br>
<img src="http://static.zybuluo.com/vin123456/q00fodkols7zm4xpll1w6qmh/image_1av6f8ts232l1gi21jhdo9kurvm.png" alt="image_1av6f8ts232l1gi21jhdo9kurvm.png-107.7kB" title=""> <br>
Event是Flume数据传输的基本单元,Flume以事件Event的形式将数据从源头传送到最终目的地,Event由可选的header和载有数据的一个byte array构成,具有以下特点:</p>

<blockquote>
  <blockquote>
    <p>载有的数据对flume是不透明的 <br>
    header是容纳了key-value字符串对的无序集合,key在集合内是唯一的 <br>
    header可以在上下文路由中使用扩展</p>
  </blockquote>
</blockquote>



<h2 id="flume安装部署">Flume安装部署</h2>



<h3 id="解压配置">解压配置</h3>

<p>第一步:解压 <br>
<code>[vin@vin01 soft]$ tar -zxvf flume-ng-1.5.0-cdh5.3.6.tar.gz -C /opt/modules/</code> <br>
第二步:配置 <br>
进入Flume解压后的目录,其中conf为配置目录,编辑flume-env.sh文件,配置JDK安装目录 <br>
<code>export JAVA_HOME=/opt/modules/jdk1.7.0_67</code> <br>
使用说明: <br>
进入flume目录下使用命令:<code>bin/flume-ng</code>查看使用方法 <br>
其中参数说明: <br>
<img src="http://static.zybuluo.com/vin123456/jc10gu63dol9zob1zrqe4m1g/image_1av6mh9311rq11s691t4t14h1mf713.png" alt="image_1av6mh9311rq11s691t4t14h1mf713.png-27.6kB" title=""> <br>
使用案例:<code>bin/flume-ng agent --conf conf --name a1 --conf-file conf/test-conf</code></p>



<h3 id="flume官方案例">Flume官方案例</h3>

<p>Flume Agent的配置被存储在一个本地配置文件,这是一个根据java属性文件格式的文本文件,在这个配置文件中,包括了对source,sink,channel的属性配置,和其相关联的数据流的配置. <br>
官方案例功能描述: <br>
Flume Agent实时监控端口,收集数据,将其以日志的形式打印在控制台 <br>
实现步骤: <br>
1,编写conf文件,新建一个test-conf,按照Flume配置的三要素进行配置如下:</p>



<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor"># Name the components on this agent   //定义一个agent，名字为a1</span>
a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span>
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.channels</span> = c1

<span class="hljs-preprocessor"># Describe/configure the source</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = netcat
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.bind</span> = localhost                 //绑定主机名/IP
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.port</span> = <span class="hljs-number">44444</span>                   //端口号

<span class="hljs-preprocessor"># Describe the sink</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = logger

<span class="hljs-preprocessor"># Use a channel which buffers events in memory</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = memory
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.capacity</span> = <span class="hljs-number">1000</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.transactionCapacity</span> = <span class="hljs-number">100</span>

<span class="hljs-preprocessor"># Bind the source and sink to the channel</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1</code></pre>

<p>2,开启agent监控 <br>
使用命令:</p>



<pre class="prettyprint"><code class=" hljs lasso">bin/flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-attribute">-n</span> a1 <span class="hljs-attribute">-c</span> conf <span class="hljs-attribute">-f</span> conf/example0618<span class="hljs-built_in">.</span>conf <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>INFO,console</code></pre>

<p>其中<code>-Dflume.root.logger=INFO,console</code>是将日志信息在控制台进行显示,监控的端口是4444 <br>
打开效果如下: <br>
<img src="http://static.zybuluo.com/vin123456/1ks5t2r89vulu8bc24ps8h7t/image_1av6nkd3g15bcbjq1gvl113tkcu1g.png" alt="image_1av6nkd3g15bcbjq1gvl113tkcu1g.png-98.8kB" title=""> <br>
3,使用talnet工具打开端口4444并输入数据 <br>
在线安装：<code>sudo yum install telnet</code> <br>
安装完成后打开端口44444 <br>
<img src="http://static.zybuluo.com/vin123456/6rcxksqdoqu7pm6iorq8w40q/image_1av6nmco8b83nlf15ck1lt31act1t.png" alt="image_1av6nmco8b83nlf15ck1lt31act1t.png-64.1kB" title=""> <br>
在此端口上输入，Flume agent会自动监控 <br>
监控效果: <br>
<img src="http://static.zybuluo.com/vin123456/qnzha8ctytc9n5nkiu3eb814/image_1av6nnogrgtm7dq1d4cam31orm2a.png" alt="image_1av6nnogrgtm7dq1d4cam31orm2a.png-73.9kB" title=""> <br>
这个例子，管道类型是memory，所以数据是存储在内存当中，实际生产中应存储在数据库中 <br>
备注:上面例子运行在前段,如果远程命令关闭,程序也会关闭,所以要想运行在后台的话使用命令如下 <br>
<code>nohub bin/flume-ng agent --conf conf --name a1 --conf-file conf/test-conf</code></p>



<h2 id="flume核心">Flume核心</h2>

<p>Flume的开发其实就是配置conf文件,即配置source,channel,sink的类型及属性</p>



<h3 id="flume-常用source">Flume 常用source</h3>

<ul>
<li>Avro Source <br>
Listens on Avro port and receives events from external Avro client streams. When paired with the built-in Avro Sink on another (previous hop) Flume agent, it can create tiered collection topologies. Required properties are in bold.</li>
</ul>

<p>示例:</p>



<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span>
a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = avro
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.bind</span> = <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.port</span> = <span class="hljs-number">4141</span></code></pre>

<hr>

<ul>
<li>Exec Source <br>
Exec source runs a given Unix command on start-up and expects that process to continuously produce data on standard out (stderr is simply discarded, unless property logStdErr is set to true). If the process exits for any reason, the source also exits and will produce no further data. This means configurations such as cat [named pipe] or tail -F [file] are going to produce the desired results where as date will probably not - the former two commands produce streams of data where as the latter produces a single event and exits. <br>
示例:</li>
</ul>



<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span>
a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = exec
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.command</span> = tail -F /var/log/secure
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1</code></pre>

<hr>

<ul>
<li>Spooling Directory Source <br>
This source lets you ingest data by placing files to be ingested into a “spooling” directory on disk. This source will watch the specified directory for new files, and will parse events out of new files as they appear. The event parsing logic is pluggable. After a given file has been fully read into the channel, it is renamed to indicate completion (or optionally deleted).</li>
</ul>

<p>示例:</p>



<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.channels</span> = ch-<span class="hljs-number">1</span>
a1<span class="hljs-preprocessor">.sources</span> = src-<span class="hljs-number">1</span>

a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.src</span>-<span class="hljs-number">1.</span>type = spooldir
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.src</span>-<span class="hljs-number">1.</span>channels = ch-<span class="hljs-number">1</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.src</span>-<span class="hljs-number">1.</span>spoolDir = /var/log/apache/flumeSpool
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.src</span>-<span class="hljs-number">1.</span>fileHeader = true</code></pre>

<hr>

<ul>
<li>Kafka Source <br>
Kafka Source is an Apache Kafka consumer that reads messages from a Kafka topic. If you have multiple Kafka sources running, you can configure them with the same Consumer Group so each will read a unique set of partitions for the topic. <br>
示例:</li>
</ul>



<pre class="prettyprint"><code class=" hljs avrasm">tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.type</span> = org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.flume</span><span class="hljs-preprocessor">.source</span><span class="hljs-preprocessor">.kafka</span><span class="hljs-preprocessor">.KafkaSource</span>
tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.channels</span> = channel1
tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.zookeeperConnect</span> = localhost:<span class="hljs-number">2181</span>
tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.topic</span> = test1
tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.groupId</span> = flume
tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.kafka</span><span class="hljs-preprocessor">.consumer</span><span class="hljs-preprocessor">.timeout</span><span class="hljs-preprocessor">.ms</span> = <span class="hljs-number">100</span></code></pre>



<h3 id="flume常用channel">Flume常用channel</h3>

<ul>
<li>Memory Channel <br>
The events are stored in an in-memory queue with configurable max size. It’s ideal for flows that need higher throughput and are prepared to lose the staged data in the event of a agent failures. Required properties are in bold.</li>
</ul>

<p>示例:</p>



<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = memory
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.capacity</span> = <span class="hljs-number">10000</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.transactionCapacity</span> = <span class="hljs-number">10000</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.byteCapacityBufferPercentage</span> = <span class="hljs-number">20</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.byteCapacity</span> = <span class="hljs-number">800000</span></code></pre>

<hr>

<ul>
<li>JDBC Channel <br>
The events are stored in a persistent storage that’s backed by a database. The JDBC channel currently supports embedded Derby. This is a durable channel that’s ideal for flows where recoverability is important. Required properties are in bold. <br>
示例:</li>
</ul>



<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = jdbc</code></pre>

<hr>

<ul>
<li>File Channel <br>
示例</li>
</ul>



<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = file
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.checkpointDir</span> = /mnt/flume/checkpoint
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.dataDirs</span> = /mnt/flume/data</code></pre>



<h3 id="flume常用sink">Flume常用sink</h3>

<ul>
<li>HDFS Sink <br>
This sink writes events into the Hadoop Distributed File System (HDFS). It currently supports creating text and sequence files. It supports compression in both file types. The files can be rolled (close current file and create a new one) periodically based on the elapsed time or size of data or number of events. It also buckets/partitions data by attributes like timestamp or machine where the event originated. The HDFS directory path may contain formatting escape sequences that will replaced by the HDFS sink to generate a directory/file name to store the events. Using this sink requires hadoop to be installed so that Flume can use the Hadoop jars to communicate with the HDFS cluster. Note that a version of Hadoop that supports the sync() call is required.</li>
</ul>

<p>The following are the escape sequences supported:</p>



<pre class="prettyprint"><code class=" hljs haml">Alias   Description
<span class="hljs-tag">%{host}</span> Substitute value of event header named “host”. Arbitrary header names are supported.
<span class="hljs-tag">%<span class="hljs-title">t</span></span>  Unix time in milliseconds
<span class="hljs-tag">%<span class="hljs-title">a</span></span>  locale’s short weekday name (Mon, Tue, ...)
<span class="hljs-tag">%<span class="hljs-title">A</span></span>  locale’s full weekday name (Monday, Tuesday, ...)
<span class="hljs-tag">%<span class="hljs-title">b</span></span>  locale’s short month name (Jan, Feb, ...)
<span class="hljs-tag">%<span class="hljs-title">B</span></span>  locale’s long month name (January, February, ...)
<span class="hljs-tag">%<span class="hljs-title">c</span></span>  locale’s date and time (Thu Mar 3 23:05:25 2005)
<span class="hljs-tag">%<span class="hljs-title">d</span></span>  day of month (01)
<span class="hljs-tag">%<span class="hljs-title">e</span></span>  day of month without padding (1)
<span class="hljs-tag">%<span class="hljs-title">D</span></span>  date; same as %m/%d/%y
<span class="hljs-tag">%<span class="hljs-title">H</span></span>  hour (00..23)
<span class="hljs-tag">%<span class="hljs-title">I</span></span>  hour (01..12)
<span class="hljs-tag">%<span class="hljs-title">j</span></span>  day of year (001..366)
<span class="hljs-tag">%<span class="hljs-title">k</span></span>  hour ( 0..23)
<span class="hljs-tag">%<span class="hljs-title">m</span></span>  month (01..12)
<span class="hljs-tag">%<span class="hljs-title">n</span></span>  month without padding (1..12)
<span class="hljs-tag">%<span class="hljs-title">M</span></span>  minute (00..59)
<span class="hljs-tag">%<span class="hljs-title">p</span></span>  locale’s equivalent of am or pm
<span class="hljs-tag">%<span class="hljs-title">s</span></span>  seconds since 1970-01-01 00:00:00 UTC
<span class="hljs-tag">%<span class="hljs-title">S</span></span>  second (00..59)
<span class="hljs-tag">%<span class="hljs-title">y</span></span>  last two digits of year (00..99)
<span class="hljs-tag">%<span class="hljs-title">Y</span></span>  year (2010)
<span class="hljs-tag">%<span class="hljs-title">z</span></span>  +hhmm numeric timezone (for example, -0400)</code></pre>

<p>示例:</p>



<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = hdfs
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.path</span> = /flume/events/%<span class="hljs-built_in">y</span>-%m-%d/%H%M/%S
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.filePrefix</span> = events-
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.round</span> = true
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.roundValue</span> = <span class="hljs-number">10</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.roundUnit</span> = minute</code></pre>

<hr>

<ul>
<li>Hive Sink <br>
This sink streams events containing delimited text or JSON data directly into a Hive table or partition. Events are written using Hive transactions. As soon as a set of events are committed to Hive, they become immediately visible to Hive queries. Partitions to which flume will stream to can either be pre-created or, optionally, Flume can create them if they are missing. Fields from incoming event data are mapped to corresponding columns in the Hive table. This sink is provided as a preview feature and not recommended for use in production. <br>
重要配置项: <br>
<img src="http://static.zybuluo.com/vin123456/ncqtbxa9rb2gk38btw4sek8e/image_1av6pomf5v92etke51c8ji552n.png" alt="image_1av6pomf5v92etke51c8ji552n.png-36.2kB" title=""> <br>
示例:</li>
</ul>



<pre class="prettyprint"><code class=" hljs sql">//Example Hive table :
<span class="hljs-operator"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> weblogs ( id <span class="hljs-keyword">int</span> , msg string )
    partitioned <span class="hljs-keyword">by</span> (continent string, country string, <span class="hljs-keyword">time</span> string)
    clustered <span class="hljs-keyword">by</span> (id) <span class="hljs-keyword">into</span> <span class="hljs-number">5</span> buckets
    stored <span class="hljs-keyword">as</span> orc;</span></code></pre>



<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = memory
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = hive
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hive</span><span class="hljs-preprocessor">.metastore</span> = thrift://<span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">9083</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hive</span><span class="hljs-preprocessor">.database</span> = logsdb
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hive</span><span class="hljs-preprocessor">.table</span> = weblogs
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hive</span><span class="hljs-preprocessor">.partition</span> = asia,%{country},%<span class="hljs-built_in">y</span>-%m-%d-%H-%M
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.useLocalTimeStamp</span> = false
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.round</span> = true
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.roundValue</span> = <span class="hljs-number">10</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.roundUnit</span> = minute
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.serializer</span> = DELIMITED
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.serializer</span><span class="hljs-preprocessor">.delimiter</span> = <span class="hljs-string">"\t"</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.serializer</span><span class="hljs-preprocessor">.serdeSeparator</span> = <span class="hljs-string">'\t'</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.serializer</span><span class="hljs-preprocessor">.fieldnames</span> =id,,msg</code></pre>

<hr>

<ul>
<li>Avro Sink <br>
This sink forms one half of Flume’s tiered collection support. Flume events sent to this sink are turned into Avro events and sent to the configured hostname / port pair. The events are taken from the configured Channel in batches of the configured batch size. Required properties are in bold. <br>
重要配置项: <br>
<img src="http://static.zybuluo.com/vin123456/6zkwhem6htemw9xwstre83cl/image_1av6prd761fac1abpojv10d013eo34.png" alt="image_1av6prd761fac1abpojv10d013eo34.png-30.5kB" title=""> <br>
示例:</li>
</ul>



<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = avro
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hostname</span> = <span class="hljs-number">10.10</span><span class="hljs-number">.10</span><span class="hljs-number">.10</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.port</span> = <span class="hljs-number">4545</span></code></pre>

<hr>

<ul>
<li>Kafka Sink <br>
This is a Flume Sink implementation that can publish data to a Kafka topic. One of the objective is to integrate Flume with Kafka so that pull based processing systems can process the data coming through various Flume sources. This currently supports Kafka 0.8.x series of releases. <br>
示例:</li>
</ul>



<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.flume</span><span class="hljs-preprocessor">.sink</span><span class="hljs-preprocessor">.kafka</span><span class="hljs-preprocessor">.KafkaSink</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.topic</span> = mytopic
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.brokerList</span> = localhost:<span class="hljs-number">9092</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.requiredAcks</span> = <span class="hljs-number">1</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.batchSize</span> = <span class="hljs-number">20</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1</code></pre>



<h2 id="喜欢我的文章请关注微信公众号dtspider">喜欢我的文章请关注微信公众号<em>DTSpider </em></h2>

<p><img src="https://img-blog.csdn.net/2018022810145122?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdmluZmx5X2xp/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>