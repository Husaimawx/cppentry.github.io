---
layout:     post
title:      Hadoop 入门总结
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p><strong><span style="color:#366091;"><strong>目录</strong></span></strong></p>

<p style="margin-left:0pt;"><a href="#_Toc439057207" rel="nofollow"><u><span style="color:#0000ff;"><u>大纲（</u></span></u><u><span style="color:#0000ff;"><u>HADOOP</u></span></u><u><span style="color:#0000ff;"><u>）</u></span></u> 2</a></p>

<p style="margin-left:0pt;"><a href="#_Toc439057208" rel="nofollow"><u><span style="color:#0000ff;"><u>1. HADOOP </u></span></u><u><span style="color:#0000ff;"><u>快速入门</u></span></u> 3</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439057209" rel="nofollow"><u><span style="color:#0000ff;"><u>什么是</u></span></u><u><span style="color:#0000ff;"><u>HADOOP</u></span></u> 3</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439057210" rel="nofollow"><u><span style="color:#0000ff;"><u>HADOOP</u></span></u><u><span style="color:#0000ff;"><u>产生背景</u></span></u> 3</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439057211" rel="nofollow"><u><span style="color:#0000ff;"><u>HADOOP</u></span></u><u><span style="color:#0000ff;"><u>在大数据、云计算中的位置和关系</u></span></u> 3</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439057212" rel="nofollow"><u><span style="color:#0000ff;"><u>国内外</u></span></u><u><span style="color:#0000ff;"><u>HADOOP</u></span></u><u><span style="color:#0000ff;"><u>应用案例介绍</u></span></u> 4</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439057213" rel="nofollow"><u><span style="color:#0000ff;"><u>国内</u></span></u><u><span style="color:#0000ff;"><u>HADOOP</u></span></u><u><span style="color:#0000ff;"><u>的就业情况分析</u></span></u> 5</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439057214" rel="nofollow"><u><span style="color:#0000ff;"><u>HADOOP</u></span></u><u><span style="color:#0000ff;"><u>生态圈以及各组成部分的简介</u></span></u> 6</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439057215" rel="nofollow"><u><span style="color:#0000ff;"><u>分布式系统概述</u></span></u> 6</a></p>

<p style="margin-left:0pt;"><a href="#_Toc439057216" rel="nofollow"><u><span style="color:#0000ff;"><u>2. HIVE</u></span></u><u><span style="color:#0000ff;"><u>快速入门</u></span></u> 7</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439057217" rel="nofollow"><u><span style="color:#0000ff;"><u>2.1 Hive</u></span></u><u><span style="color:#0000ff;"><u>基本介绍</u></span></u> 7</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439057218" rel="nofollow"><u><span style="color:#0000ff;"><u>2.2 Hive</u></span></u><u><span style="color:#0000ff;"><u>的基本使用</u></span></u> 8</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439057219" rel="nofollow"><u><span style="color:#0000ff;"><u>2.3 </u></span></u><u><span style="color:#0000ff;"><u>数据仓库基本知识</u></span></u> 9</a></p>

<p style="margin-left:0pt;"><a href="#_Toc439057220" rel="nofollow"><u><span style="color:#0000ff;"><u>3. </u></span></u><u><span style="color:#0000ff;"><u>数据分析案列演示</u></span></u> 10</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439057221" rel="nofollow"><u><span style="color:#0000ff;"><u>3.1 </u></span></u><u><span style="color:#0000ff;"><u>需求分析</u></span></u> 10</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057222" rel="nofollow"><u><span style="color:#0000ff;"><u>3.1.1</u></span></u><u><span style="color:#0000ff;"><u>案例名称</u></span></u> 10</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057223" rel="nofollow"><u><span style="color:#0000ff;"><u>3.1.2 </u></span></u><u><span style="color:#0000ff;"><u>案例需求描述</u></span></u> 10</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057224" rel="nofollow"><u><span style="color:#0000ff;"><u>3.1.3 web</u></span></u><u><span style="color:#0000ff;"><u>点击流日志的数据格式</u></span></u> 10</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057225" rel="nofollow"><u><span style="color:#0000ff;"><u>3.1.4 </u></span></u><u><span style="color:#0000ff;"><u>分析指标</u></span></u> 11</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057226" rel="nofollow"><u><span style="color:#0000ff;"><u>3.1.5 </u></span></u><u><span style="color:#0000ff;"><u>统计结果数据可视化</u></span></u> 11</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439057227" rel="nofollow"><u><span style="color:#0000ff;"><u>3.2 </u></span></u><u><span style="color:#0000ff;"><u>数据来源分析</u></span></u> 12</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057228" rel="nofollow"><u><span style="color:#0000ff;"><u>3.2.1 </u></span></u><u><span style="color:#0000ff;"><u>企业中获取数据的几种方式</u></span></u> 12</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057229" rel="nofollow"><u><span style="color:#0000ff;"><u>3.2.2 </u></span></u><u><span style="color:#0000ff;"><u>数据采集</u></span></u> 12</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439057230" rel="nofollow"><u><span style="color:#0000ff;"><u>3.3 </u></span></u><u><span style="color:#0000ff;"><u>数据处理流程</u></span></u> 13</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057231" rel="nofollow"><u><span style="color:#0000ff;"><u>数据预处理</u></span></u><u><span style="color:#0000ff;"><u>/</u></span></u><u><span style="color:#0000ff;"><u>加载入库</u></span></u> 13</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057232" rel="nofollow"><u><span style="color:#0000ff;"><u>使用</u></span></u><u><span style="color:#0000ff;"><u>Hive</u></span></u><u><span style="color:#0000ff;"><u>做数据</u></span></u><u><span style="color:#0000ff;"><u>ETL</u></span></u> 14</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057233" rel="nofollow"><u><span style="color:#0000ff;"><u>使用</u></span></u><u><span style="color:#0000ff;"><u>Hive</u></span></u><u><span style="color:#0000ff;"><u>运算业务指标</u></span></u> 16</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057234" rel="nofollow"><u><span style="color:#0000ff;"><u>将结果数据导出到</u></span></u><u><span style="color:#0000ff;"><u>mysql</u></span></u><u><span style="color:#0000ff;"><u>（</u></span></u><u><span style="color:#0000ff;"><u>sqoop</u></span></u><u><span style="color:#0000ff;"><u>）</u></span></u> 17</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057235" rel="nofollow"><u><span style="color:#0000ff;"><u>结果展现——数据可视化</u></span></u> 17</a></p>

<p style="margin-left:0pt;"><a href="#_Toc439057236" rel="nofollow"><u><span style="color:#0000ff;"><u>4. </u></span></u><u><span style="color:#0000ff;"><u>集群搭建</u></span></u> 18</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439057237" rel="nofollow"><u><span style="color:#0000ff;"><u>4.1 HADOOP</u></span></u><u><span style="color:#0000ff;"><u>集群搭建</u></span></u> 18</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057238" rel="nofollow"><u><span style="color:#0000ff;"><u>4.1.1</u></span></u><u><span style="color:#0000ff;"><u>集群简介：</u></span></u> 18</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057239" rel="nofollow"><u><span style="color:#0000ff;"><u>4.1.2</u></span></u><u><span style="color:#0000ff;"><u>服务器准备</u></span></u> 18</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057240" rel="nofollow"><u><span style="color:#0000ff;"><u>4.1.3</u></span></u><u><span style="color:#0000ff;"><u>网络环境准备</u></span></u> 18</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057241" rel="nofollow"><u><span style="color:#0000ff;"><u>4.1.4</u></span></u><u><span style="color:#0000ff;"><u>服务器系统设置</u></span></u> 18</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057242" rel="nofollow"><u><span style="color:#0000ff;"><u>4.1.5 Jdk</u></span></u><u><span style="color:#0000ff;"><u>环境安装</u></span></u> 19</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057243" rel="nofollow"><u><span style="color:#0000ff;"><u>4.1.6 HADOOP</u></span></u><u><span style="color:#0000ff;"><u>安装部署</u></span></u> 19</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057244" rel="nofollow"><u><span style="color:#0000ff;"><u>4.1.7 </u></span></u><u><span style="color:#0000ff;"><u>启动集群</u></span></u> 21</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057245" rel="nofollow"><u><span style="color:#0000ff;"><u>4.1.8 </u></span></u><u><span style="color:#0000ff;"><u>测试</u></span></u> 21</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439057246" rel="nofollow"><u><span style="color:#0000ff;"><u>4.2 Hive</u></span></u><u><span style="color:#0000ff;"><u>搭建</u></span></u> 22</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057247" rel="nofollow"><u><span style="color:#0000ff;"><u>Hive</u></span></u><u><span style="color:#0000ff;"><u>的配置安装</u></span></u> 22</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057248" rel="nofollow"><u><span style="color:#0000ff;"><u>Hive</u></span></u><u><span style="color:#0000ff;"><u>的使用</u></span></u> 23</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439057249" rel="nofollow"><u><span style="color:#0000ff;"><u>Hive</u></span></u><u><span style="color:#0000ff;"><u>运行测试</u></span></u> 23</a></p>

<h1><strong><a name="_Toc439057207"></a><strong><strong>课程（HADOOP）</strong></strong></strong></h1>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td rowspan="6" style="width:78.85pt;">
			<p style="margin-left:0pt;">HADOOP快速入门</p>
			</td>
			<td rowspan="6" style="width:98.45pt;">
			<p style="margin-left:0pt;">HADOOP快速入门</p>
			</td>
			<td style="vertical-align:top;width:248.8pt;">
			<p style="margin-left:0pt;">HADOOP产生背景</p>
			</td>
		</tr><tr><td style="vertical-align:top;width:248.8pt;">
			<p style="margin-left:0pt;">HADOOP在大数据、云计算中的位置和关系</p>
			</td>
		</tr><tr><td style="vertical-align:top;width:248.8pt;">
			<p style="margin-left:0pt;">国内外HADOOP应用案例介绍</p>
			</td>
		</tr><tr><td style="vertical-align:top;width:248.8pt;">
			<p style="margin-left:0pt;">国内HADOOP的就业情况分析及课程大纲介绍</p>
			</td>
		</tr><tr><td style="vertical-align:top;width:248.8pt;">
			<p style="margin-left:0pt;">分布式系统概述</p>
			</td>
		</tr><tr><td style="vertical-align:top;width:248.8pt;">
			<p style="margin-left:0pt;">HADOOP生态圈以及各组成部分的简介</p>
			</td>
		</tr><tr><td rowspan="3" style="width:78.85pt;">
			<p style="margin-left:0pt;">Hive快速入门</p>
			</td>
			<td rowspan="3" style="width:98.45pt;">
			<p style="margin-left:0pt;">Hive快速入门</p>
			</td>
			<td style="vertical-align:top;width:248.8pt;">
			<p style="margin-left:0pt;">Hive基本介绍</p>
			</td>
		</tr><tr><td style="vertical-align:top;width:248.8pt;">
			<p style="margin-left:0pt;">Hive的使用</p>
			</td>
		</tr><tr><td style="vertical-align:top;width:248.8pt;">
			<p style="margin-left:0pt;">数据仓库基本知识</p>
			</td>
		</tr><tr><td rowspan="7" style="width:78.85pt;">
			<p style="margin-left:0pt;">数据分析案例演示</p>
			</td>
			<td style="width:98.45pt;">
			<p style="margin-left:0pt;">需求分析</p>
			</td>
			<td style="vertical-align:top;width:248.8pt;">
			<p style="margin-left:0pt;">案列：定义需求、介绍数据格式</p>
			</td>
		</tr><tr><td rowspan="3" style="width:98.45pt;">
			<p style="margin-left:0pt;">数据获取</p>
			</td>
			<td style="vertical-align:top;width:248.8pt;">
			<p style="margin-left:0pt;">企业中获取数据的几种方式</p>
			</td>
		</tr><tr><td style="vertical-align:top;width:248.8pt;">
			<p style="margin-left:0pt;">将文件直接导入到数据仓库</p>
			</td>
		</tr><tr><td style="vertical-align:top;width:248.8pt;">
			<p style="margin-left:0pt;">将数据库的数据导入到数据仓库（sqoop）</p>
			</td>
		</tr><tr><td style="width:98.45pt;">
			<p style="margin-left:0pt;">数据处理</p>
			</td>
			<td style="vertical-align:top;width:248.8pt;">
			<p style="margin-left:0pt;">使用Hive对数进行清洗（ETL的过程）</p>
			</td>
		</tr><tr><td style="width:98.45pt;">
			<p style="margin-left:0pt;">数据计算</p>
			</td>
			<td style="vertical-align:top;width:248.8pt;">
			<p style="margin-left:0pt;">使用Hive对数据进行计算</p>
			</td>
		</tr><tr><td style="width:98.45pt;">
			<p style="margin-left:0pt;">数据展现</p>
			</td>
			<td style="vertical-align:top;width:248.8pt;">
			<p style="margin-left:0pt;">将结果数据导出到mysql（sqoop）</p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;">建立起大数据和分布式的宏观概念</p>

<p style="margin-left:0pt;">1、理解hadoop是什么，用于做什么，大体上怎么用</p>

<p style="margin-left:0pt;">2、理解hive是什么，用于做什么，大体上怎么用</p>

<p style="margin-left:0pt;">3、通过一个案例的演示说明，理解数据挖掘系统的基本流程和结构</p>

<h1><strong><a name="_Toc439057208"></a><strong><strong>1. HADOOP</strong></strong><strong><strong>背景介绍</strong></strong></strong></h1>

<h2><strong><a name="_Toc439057209"></a><strong><strong>1.1 </strong></strong><strong><strong>什么是HADOOP</strong></strong></strong></h2>

<ol><li>HADOOP是apache旗下的一套开源<strong><strong>软件平台</strong></strong></li>
	<li>HADOOP提供的功能：利用服务器集群，根据用户的自定义业务逻辑，<strong><strong>对海量数据进行分布式处理</strong></strong></li>
	<li>HADOOP的核心组件有
	<ol><li>
		<ol><li>HDFS（分布式文件系统）</li>
			<li>YARN（运算资源调度系统）</li>
			<li>MAPREDUCE（分布式运算编程框架）</li>
		</ol></li>
	</ol></li>
	<li>广义上来说，HADOOP通常是指一个更广泛的概念——HADOOP生态圈</li>
</ol><h2><strong><a name="_Toc439057210"></a><strong><strong>1.2 </strong></strong><strong><strong>HADOOP产生背景</strong></strong></strong></h2>

<ol><li>HADOOP<strong><strong>最早起源于Nutch</strong></strong>。Nutch的设计目标是构建一个大型的全网搜索引擎，包括网页抓取、索引、查询等功能，但随着抓取网页数量的增加，<strong><strong>遇到了严重的可扩展性问题——</strong></strong>如何解决数十亿网页的存储和索引问题。</li>
	<li>2003年、2004年<strong><strong>谷歌发表的两篇论文为该问题提供了可行的解决方案</strong></strong>。</li>
</ol><p style="margin-left:21pt;">——分布式文件系统（GFS），可用于处理海量网页的<strong><strong>存储</strong></strong></p>

<p style="margin-left:21pt;">——分布式计算框架MAPREDUCE，可用于处理海量网页的<strong><strong>索引计算</strong></strong>问题。</p>

<ol><li>Nutch的开发人员完成了相应的<strong><strong>开源实现HDFS和MAPREDUCE</strong></strong>，并从Nutch中剥离成为独立项目HADOOP，到2008年1月，HADOOP成为Apache顶级项目，迎来了它的快速发展期。</li>
</ol><h2><strong><a name="_Toc439057211"></a><strong><strong>1.3 </strong></strong><strong><strong>HADOOP在大数据、云计算中的位置和关系</strong></strong></strong></h2>

<ol><li>云计算是分布式计算、并行计算、网格计算、多核计算、网络存储、虚拟化、负载均衡等传统计算机技术和互联网技术融合发展的产物。借助IaaS(基础设施即服务)、PaaS(平台即服务)、SaaS（软件即服务）等业务模式，把强大的计算能力提供给终端用户。</li>
	<li>现阶段，云计算的<strong><strong>两大底层支撑技术</strong></strong>为“<strong><strong>虚拟化</strong></strong>”和“<strong><strong>大数据技术</strong></strong>”</li>
	<li>而HADOOP则是云计算的PaaS层的解决方案之一，并不等同于PaaS，更不等同于云计算本身。</li>
</ol><h2><strong><a name="_Toc439057212"></a><strong><strong>1.4 </strong></strong><strong><strong>国内外HADOOP应用案例介绍</strong></strong></strong></h2>

<p style="margin-left:0pt;"><strong><strong>1、HADOOP应用于数据服务基础平台建设</strong></strong></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="323" src="https://img-blog.csdn.net/20180908171337238?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MjAyNzU2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="408"></p>

<p style="margin-left:0pt;"><strong><strong>2  HADOOP用于用户画像</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>3、HADOOP用于网站点击流日志</strong></strong><strong><strong>数据</strong></strong><strong><strong>挖掘</strong></strong></p>

<h2><strong><a name="_Toc439057213"></a><strong><strong>1.5 </strong></strong><strong><strong>国内HADOOP的就业情况分析</strong></strong></strong></h2>

<ol><li>HADOOP就业整体情况</li>
</ol><ol><li>大数据产业已纳入<strong><strong>国家十三五规划</strong></strong></li>
	<li>各大城市都在进行<strong><strong>智慧城市项目</strong></strong>建设，而智慧城市的根基就是大数据综合平台</li>
	<li>互联网时代数据的种类，增长都呈现<strong><strong>爆发式增长</strong></strong>，各行业对数据的价值日益重视</li>
	<li>相对于传统JAVAEE技术领域来说，大数据领域的<strong><strong>人才相对稀缺</strong></strong></li>
	<li>随着现代社会的发展，数据处理和数据挖掘的重要性只会增不会减，因此，大数据技术是一个尚在蓬勃发展且具有<strong><strong>长远前景的领域</strong></strong></li>
	<li>HADOOP就业职位要求</li>
</ol><p style="margin-left:0pt;">大数据是个复合专业，包括应用开发、软件平台、算法、数据挖掘等，因此，<strong><strong>大数据技术领域的就业选择是多样的</strong></strong>，但就HADOOP而言，通常都需要具备以下技能或知识：</p>

<ol><li>HADOOP分布式集群的平台搭建</li>
	<li>HADOOP分布式文件系统HDFS的原理理解及使用</li>
	<li>HADOOP分布式运算框架MAPREDUCE的原理理解及编程</li>
	<li>Hive数据仓库工具的熟练应用</li>
	<li>Flume、sqoop、oozie等辅助工具的熟练使用</li>
	<li>Shell/python等脚本语言的开发能力</li>
	<li>HADOOP相关职位的薪资水平</li>
</ol><p style="margin-left:0pt;">大数据技术或具体到HADOOP的就业需求目前主要集中在北上广深一线城市，<strong><strong>薪资待遇普遍高于传统JAVAEE开发人员</strong></strong>，以北京为例：</p>

<p style="margin-left:0pt;"> </p>

<h2><strong><a name="_Toc439057214"></a><strong><strong>1.6 </strong></strong><strong><strong>HADOOP生态圈以及各组成部分的简介</strong></strong></strong></h2>

<p style="margin-left:0pt;"><img alt="" class="has" height="383" src="https://img-blog.csdn.net/20180908171442256?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MjAyNzU2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="565"></p>

<p style="margin-left:0pt;">各组件简介</p>

<p style="margin-left:0pt;">重点组件：</p>

<p style="margin-left:0pt;"><span style="color:#ff0000;">HDFS：分布式文件系统</span></p>

<p style="margin-left:0pt;"><span style="color:#ff0000;">MAPREDUCE：分布式运算程序开发框架</span></p>

<p style="margin-left:0pt;"><span style="color:#ff0000;">HIVE：基于大数据技术（文件系统+运算框架）的SQL数据仓库工具</span></p>

<p style="margin-left:0pt;">HBASE：基于HADOOP的分布式海量数据库</p>

<p style="margin-left:0pt;"><strong><span style="color:#ff0000;"><strong>ZOOKEEPER：分布式协调服务基础组件</strong></span></strong></p>

<p style="margin-left:0pt;">Mahout：基于mapreduce/spark/flink等分布式运算框架的机器学习算法库</p>

<p style="margin-left:0pt;">Oozie：工作流调度框架</p>

<p style="margin-left:0pt;">Sqoop：数据导入导出工具</p>

<p style="margin-left:0pt;">Flume：日志数据采集框架</p>

<h1><strong><strong><strong>2 </strong></strong><strong><strong>分布式系统概述</strong></strong></strong></h1>

<p style="margin-left:0pt;"><em><em>注：由于大数据技术领域的各类技术框架基本上都是分布式系统，因此，理解hadoop、storm、spark等技术框架，都需要具备基本的分布式系统概念</em></em></p>

<h2><strong><strong><strong>2.1 </strong></strong><strong><strong>分布式软件系统(Distributed Software Systems)</strong></strong></strong></h2>

<ul><li>该软件系统会划分成多个子系统或模块，各自运行在不同的机器上，子系统或模块之间通过网络通信进行协作，实现最终的整体功能</li>
	<li>比如分布式操作系统、分布式程序设计语言及其编译(解释)系统、分布式文件系统和分布式数据库系统等。</li>
</ul><p style="margin-left:0pt;"> </p>

<h2><strong><strong><strong>2.2 </strong></strong><strong><strong>分布式软件系统举例：solrcloud</strong></strong><strong> </strong></strong></h2>

<ol><li>一个solrcloud集群通常有多台solr服务器</li>
	<li>每一个solr服务器节点负责存储整个索引库的若干个shard（数据分片）</li>
	<li>每一个shard又有多台服务器存放若干个副本互为主备用</li>
	<li>索引的建立和查询会在整个集群的各个节点上并发执行</li>
	<li>solrcloud集群作为整体对外服务，而其内部细节可对客户端透明</li>
</ol><p style="margin-left:0pt;"><strong><strong>总结：利用多个节点共同协作完成一项或多项具体业务功能的系统就是分布式系统。</strong></strong></p>

<h2><strong><strong><strong>2.3 分布式应用系统模拟开发</strong></strong></strong></h2>

<p style="margin-left:0pt;"><strong><strong>需求：</strong></strong>可以实现由主节点将运算任务发往从节点，并将各从节点上的任务启动；</p>

<p style="margin-left:0pt;"><strong><strong>程序清单：</strong></strong></p>

<p style="margin-left:0pt;">AppMaster</p>

<p style="margin-left:0pt;">AppSlave/APPSlaveThread</p>

<p style="margin-left:0pt;">Task</p>

<p style="margin-left:0pt;"><strong><strong>程序运行逻辑流程：</strong></strong></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="197" src="https://img-blog.csdn.net/20180908171458589?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MjAyNzU2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="447"></p>

<h1><strong><a name="_Toc439057220"></a><strong><strong>3. </strong></strong><strong><strong>离线</strong></strong><strong><strong>数据分析</strong></strong><strong><strong>流程介绍</strong></strong></strong></h1>

<p style="margin-left:0pt;"><em><em>注：本环节主要感受数据分析系统的宏观概念及处理流程，初步理解hadoop等框架在其中的应用环节，不用过于关注代码细节</em></em></p>

<p style="margin-left:0pt;">一个应用广泛的数据分析系统：“web日志数据挖掘”</p>

<p style="margin-left:0pt;"><img alt="" class="has" height="432" src="https://img-blog.csdn.net/20180908171533614?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MjAyNzU2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="619"></p>

<h2><strong><a name="_Toc439057221"></a><strong><strong>3.1 需求分析</strong></strong></strong></h2>

<h3><strong><a name="_Toc439057222"></a><strong><strong>3.1.1 案例名称</strong></strong></strong></h3>

<p style="margin-left:0pt;">“网站或APP点击流日志数据挖掘系统”。</p>

<p style="margin-left:0pt;">一般中型的网站(10W的PV以上)，每天会产生1G以上Web日志文件。大型或超大型的网站，可能每小时就会产生10G的数据量。</p>

<p style="margin-left:0pt;">具体来说，比如某电子商务网站，在线团购业务。每日PV数100w，独立IP数5w。用户通常在工作日上午10:00-12:00和下午15:00-18:00访问量最大。日间主要是通过PC端浏览器访问，休息日及夜间通过移动设备访问较多。网站搜索浏量占整个网站的80%，PC用户不足1%的用户会消费，移动用户有5%会消费。</p>

<p style="margin-left:0pt;">对于日志的这种规模的数据，用HADOOP进行日志分析，是最适合不过的了。</p>

<h3><strong><a name="_Toc439057223"></a><strong><strong>3.1.2 案例需求描述</strong></strong></strong></h3>

<p style="margin-left:0pt;">“Web点击流日志”包含着网站运营很重要的信息，通过日志分析，我们可以知道网站的访问量，哪个网页访问人数最多，哪个网页最有价值，广告转化率、访客的来源信息，访客的终端信息等。</p>

<h3><strong><strong><strong>3.1.3 数据来源</strong></strong></strong></h3>

<p style="margin-left:0pt;">本案例的数据主要由<strong><strong>用户的点击行为记录</strong></strong></p>

<p style="margin-left:0pt;">获取方式：在页面预埋一段js程序，为页面上想要监听的标签绑定事件，只要用户点击或移动到标签，即可触发ajax请求到后台servlet程序，用log4j记录下事件信息，从而在web服务器（nginx、tomcat等）上形成不断增长的日志文件。</p>

<p style="margin-left:0pt;">形如：</p>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;">58.215.204.118 - - [18/Sep/2013:06:51:35 +0000] "GET /wp-includes/js/jquery/jquery.js?ver=1.10.2 HTTP/1.1" 304 0 "http://blog.fens.me/nodejs-socketio-chat/" "Mozilla/5.0 (Windows NT 5.1; rv:23.0) Gecko/20100101 Firefox/23.0"</p>
			</td>
		</tr></tbody></table><h2><strong><a name="_Toc439057230"></a><strong><strong>3.2 数据处理流程</strong></strong></strong></h2>

<h3><strong><strong><strong>3.2.1 流程图解析</strong></strong></strong></h3>

<p style="margin-left:0pt;">本案例跟典型的BI系统极其类似，整体流程如下：</p>

<p style="margin-left:0pt;"><img alt="" class="has" height="268" src="https://img-blog.csdn.net/20180908171607467?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MjAyNzU2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="599"></p>

<p style="margin-left:0pt;">但是，由于本案例的前提是处理海量数据，因而，流程中各环节所使用的技术则跟传统BI完全不同，后续课程都会一一讲解：</p>

<ol><li>数据采集：定制开发采集程序，或使用开源框架FLUME</li>
	<li>数据预处理：定制开发mapreduce程序运行于hadoop集群</li>
	<li>数据仓库技术：基于hadoop之上的Hive</li>
	<li>数据导出：基于hadoop的sqoop数据导入导出工具</li>
	<li>数据可视化：定制开发web程序或使用kettle等产品</li>
	<li>整个过程的流程调度：hadoop生态圈中的oozie工具或其他类似开源产品</li>
</ol><h3><strong><strong><strong>3.2.2 项目技术架构图</strong></strong></strong></h3>

<p style="margin-left:0pt;"><img alt="" class="has" height="346" src="https://img-blog.csdn.net/20180908171628342?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MjAyNzU2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="502"></p>

<h3><strong><strong><strong>3.2.3 项目相关截图（感性认识，欣赏即可）</strong></strong></strong></h3>

<ol><li>Mapreudce程序运行</li>
</ol><p style="margin-left:0pt;"><img alt="" class="has" height="380" src="https://img-blog.csdn.net/20180908171654825?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MjAyNzU2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="692"></p>

<p style="margin-left:0pt;"> </p>

<ol><li>在Hive中查询数据</li>
</ol><p style="margin-left:0pt;"></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="360" src="https://img-blog.csdn.net/20180908171707497?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MjAyNzU2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="693"></p>

<ol><li>将统计结果导入mysql</li>
</ol><table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;">./sqoop export --connect jdbc:mysql://localhost:3306/weblogdb --username root --password root  --table t_display_xx  --export-dir /user/hive/warehouse/uv/dt=2014-08-03</p>
			</td>
		</tr></tbody></table><h2><strong><strong><strong>3.3 项目最终效果</strong></strong></strong></h2>

<p style="margin-left:0pt;">经过完整的数据处理流程后，会周期性输出各类统计指标的报表，在生产实践中，最终需要将这些报表数据以可视化的形式展现出来，本案例采用web程序来实现数据可视化</p>

<p style="margin-left:0pt;">效果如下所示：</p>

<p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;"><img alt="" class="has" height="422" src="https://img-blog.csdn.net/20180908171711442?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MjAyNzU2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="695"></p>

<h1><strong><a name="_Toc439057236"></a><strong><strong>4. 集群搭建</strong></strong></strong></h1>

<h2><strong><a name="_Toc439057237"></a><strong><strong>4.1 HADOOP集群搭建</strong></strong></strong></h2>

<h3><strong><a name="_Toc439057238"></a><strong><strong>4.1.1集群简介</strong></strong></strong></h3>

<p style="margin-left:0pt;">HADOOP集群具体来说包含两个集群：HDFS集群和YARN集群，两者逻辑上分离，但物理上常在一起</p>

<p style="margin-left:0pt;">HDFS集群：</p>

<p style="margin-left:0pt;">负责海量数据的存储，集群中的角色主要有 NameNode / DataNode</p>

<p style="margin-left:0pt;">YARN集群：</p>

<p style="margin-left:0pt;">负责海量数据运算时的资源调度，集群中的角色主要有 ResourceManager /NodeManager</p>

<p style="margin-left:0pt;"><em><em>(那mapreduce是什么呢？它其实是一个应用程序开发包)</em></em></p>

<p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;">本集群搭建案例，以5节点为例进行搭建，角色分配如下：</p>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;">hdp-node-01    NameNode  SecondaryNameNode</p>

			<p style="margin-left:0pt;">hdp-node-02    ResourceManager</p>

			<p style="margin-left:0pt;">hdp-node-03 DataNode    NodeManager</p>

			<p style="margin-left:0pt;">hdp-node-04 DataNode    NodeManager</p>

			<p style="margin-left:0pt;">hdp-node-05 DataNode    NodeManager</p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;"><a name="_Toc439057239"></a>部署图如下：</p>

<p style="margin-left:0pt;"><img alt="" class="has" height="293" src="https://img-blog.csdn.net/20180908171722435?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MjAyNzU2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="693"></p>

<p style="margin-left:0pt;"></p>

<h3><strong><strong><strong>4.1.2服务器准备</strong></strong></strong></h3>

<p style="margin-left:0pt;">本案例使用虚拟机服务器来搭建HADOOP集群，所用软件及版本：</p>

<ul><li>Vmware 11.0</li>
	<li>Centos  6.5  64bit</li>
</ul><p style="margin-left:0pt;"> </p>

<h3><strong><a name="_Toc439057240"></a><strong><strong>4.1.3网络环境准备</strong></strong></strong></h3>

<ul><li>采用NAT方式联网</li>
	<li>网关地址：192.168.33.1</li>
	<li>3个服务器节点IP地址：192.168.33.101、192.168.33.102、192.168.33.103</li>
	<li>子网掩码：255.255.255.0</li>
</ul><h3><strong><a name="_Toc439057241"></a><strong><strong>4.1.4服务器系统设置</strong></strong></strong></h3>

<ul><li>添加HADOOP用户</li>
	<li>为HADOOP用户分配sudoer权限</li>
	<li>同步时间</li>
	<li>设置主机名
	<ol><li>hdp-node-01</li>
		<li>hdp-node-02</li>
		<li>hdp-node-03</li>
	</ol></li>
	<li>配置内网域名映射：
	<ol><li>192.168.33.101          hdp-node-01</li>
		<li>192.168.33.102          hdp-node-02</li>
		<li>192.168.33.103          hdp-node-03</li>
	</ol></li>
	<li>配置ssh免密登陆</li>
	<li>配置防火墙</li>
</ul><h3><strong><a name="_Toc439057242"></a><strong><strong>4.1.5 </strong></strong><strong><strong>J</strong></strong><strong><strong>dk环境安装</strong></strong></strong></h3>

<ul><li>上传jdk安装包</li>
	<li>规划安装目录  /home/hadoop/apps/jdk_1.7.65</li>
	<li>解压安装包</li>
	<li>配置环境变量 /etc/profile</li>
</ul><h3><strong><a name="_Toc439057243"></a><strong><strong>4.1.6 </strong></strong><strong><strong>HADOOP</strong></strong><strong><strong>安装部署</strong></strong></strong></h3>

<ul><li>上传HADOOP安装包</li>
	<li>规划安装目录  /home/hadoop/apps/hadoop-2.6.1</li>
	<li>解压安装包</li>
	<li>修改配置文件  $HADOOP_HOME/etc/hadoop/</li>
</ul><p style="margin-left:0pt;">最简化配置如下：</p>

<p style="margin-left:0pt;">vi  hadoop-env.sh</p>

<table border="1" cellspacing="0" style="width:381.05pt;"><tbody><tr><td style="vertical-align:top;width:381.05pt;">
			<p style="margin-left:0pt;"># The java implementation to use.</p>

			<p style="margin-left:0pt;">export JAVA_HOME=/home/hadoop/apps/jdk1.7.0_51</p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;">vi  core-site.xml</p>

<table border="1" cellspacing="0" style="width:381.05pt;"><tbody><tr><td style="vertical-align:top;width:381.05pt;">
			<p style="margin-left:0pt;">&lt;configuration&gt;</p>

			<p style="margin-left:0pt;">&lt;property&gt;</p>

			<p style="margin-left:0pt;">&lt;name&gt;fs.defaultFS&lt;/name&gt;</p>

			<p style="margin-left:0pt;">&lt;value&gt;hdfs://hdp-node-01:9000&lt;/value&gt;</p>

			<p style="margin-left:0pt;">&lt;/property&gt;</p>

			<p style="margin-left:0pt;">&lt;property&gt;</p>

			<p style="margin-left:0pt;">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</p>

			<p style="margin-left:0pt;">&lt;value&gt;/home/HADOOP/apps/hadoop-2.6.1/tmp&lt;/value&gt;</p>

			<p style="margin-left:0pt;">&lt;/property&gt;</p>

			<p style="margin-left:0pt;">&lt;/configuration&gt;</p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;">vi  hdfs-site.xml</p>

<table border="1" cellspacing="0" style="width:381.05pt;"><tbody><tr><td style="vertical-align:top;width:381.05pt;">
			<p style="margin-left:0pt;">&lt;configuration&gt;</p>

			<p style="margin-left:0pt;">&lt;property&gt;</p>

			<p style="margin-left:0pt;">&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</p>

			<p style="margin-left:0pt;">&lt;value&gt;/home/hadoop/data/name&lt;/value&gt;</p>

			<p style="margin-left:0pt;">&lt;/property&gt;</p>

			<p style="margin-left:0pt;">&lt;property&gt;</p>

			<p style="margin-left:0pt;">&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</p>

			<p style="margin-left:0pt;">&lt;value&gt;/home/hadoop/data/data&lt;/value&gt;</p>

			<p style="margin-left:0pt;">&lt;/property&gt;</p>

			<p style="margin-left:0pt;"> </p>

			<p style="margin-left:0pt;">&lt;property&gt;</p>

			<p style="margin-left:0pt;">&lt;name&gt;dfs.replication&lt;/name&gt;</p>

			<p style="margin-left:0pt;">&lt;value&gt;3&lt;/value&gt;</p>

			<p style="margin-left:0pt;">&lt;/property&gt;</p>

			<p style="margin-left:0pt;"> </p>

			<p style="margin-left:0pt;">&lt;property&gt;</p>

			<p style="margin-left:0pt;">&lt;name&gt;dfs.secondary.http.address&lt;/name&gt;</p>

			<p style="margin-left:0pt;">&lt;value&gt;hdp-node-01:50090&lt;/value&gt;</p>

			<p style="margin-left:0pt;">&lt;/property&gt;</p>

			<p style="margin-left:0pt;">&lt;/configuration&gt;</p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;">vi  mapred-site.xml</p>

<table border="1" cellspacing="0" style="width:381.05pt;"><tbody><tr><td style="vertical-align:top;width:381.05pt;">
			<p style="margin-left:0pt;">&lt;configuration&gt;</p>

			<p style="margin-left:0pt;">&lt;property&gt;</p>

			<p style="margin-left:0pt;">&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</p>

			<p style="margin-left:0pt;">&lt;value&gt;yarn&lt;/value&gt;</p>

			<p style="margin-left:0pt;">&lt;/property&gt;</p>

			<p style="margin-left:0pt;">&lt;/configuration&gt;</p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;">vi  yarn-site.xml</p>

<table border="1" cellspacing="0" style="width:381.05pt;"><tbody><tr><td style="vertical-align:top;width:381.05pt;">
			<p style="margin-left:0pt;">&lt;configuration&gt;</p>

			<p style="margin-left:0pt;">&lt;property&gt;</p>

			<p style="margin-left:0pt;">&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</p>

			<p style="margin-left:0pt;">&lt;value&gt;hadoop01&lt;/value&gt;</p>

			<p style="margin-left:0pt;">&lt;/property&gt;</p>

			<p style="margin-left:0pt;"> </p>

			<p style="margin-left:0pt;">&lt;property&gt;</p>

			<p style="margin-left:0pt;">&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</p>

			<p style="margin-left:0pt;">&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</p>

			<p style="margin-left:0pt;">&lt;/property&gt;</p>

			<p style="margin-left:0pt;">&lt;/configuration&gt;</p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;">vi  salves</p>

<table border="1" cellspacing="0" style="width:381.05pt;"><tbody><tr><td style="vertical-align:top;width:381.05pt;">
			<p style="margin-left:0pt;">hdp-node-01</p>

			<p style="margin-left:0pt;">hdp-node-02</p>

			<p style="margin-left:0pt;">hdp-node-03</p>
			</td>
		</tr></tbody></table><h3><strong><a name="_Toc439057244"></a><strong><strong>4.1.7 启动集群</strong></strong></strong></h3>

<p style="margin-left:0pt;">初始化HDFS</p>

<table border="1" cellspacing="0" style="width:381.05pt;"><tbody><tr><td style="vertical-align:top;width:381.05pt;">
			<p>bin/hadoop  namenode  -format</p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;">启动HDFS</p>

<table border="1" cellspacing="0" style="width:381.05pt;"><tbody><tr><td style="vertical-align:top;width:381.05pt;">
			<p>sbin/start-dfs.sh</p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;">启动YARN</p>

<table border="1" cellspacing="0" style="width:381.05pt;"><tbody><tr><td style="vertical-align:top;width:381.05pt;">
			<p style="margin-left:0pt;">sbin/start-yarn.sh</p>
			</td>
		</tr></tbody></table><h3><strong><a name="_Toc439057245"></a><strong><strong>4.1.8 测试</strong></strong></strong></h3>

<p><strong><strong><strong>1、上传文件到HDFS</strong></strong></strong></p>

<p style="margin-left:0pt;">从本地上传一个文本文件到hdfs的/wordcount/input目录下</p>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;">[HADOOP@hdp-node-01 ~]$ HADOOP fs -mkdir -p /wordcount/input</p>

			<p style="margin-left:0pt;">[HADOOP@hdp-node-01 ~]$ HADOOP fs -put /home/HADOOP/somewords.txt  /wordcount/input</p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;"> </p>

<p><strong><strong><strong>2、运行一个mapreduce程序</strong></strong></strong></p>

<p style="margin-left:0pt;">在HADOOP安装目录下，运行一个示例mr程序</p>

<table border="1" cellspacing="0" style="width:428.05pt;"><tbody><tr><td style="vertical-align:top;width:428.05pt;">
			<p style="margin-left:0pt;">cd $HADOOP_HOME/share/hadoop/mapreduce/</p>

			<p style="margin-left:0pt;">hadoop jar mapredcue-example-2.6.1.jar wordcount /wordcount/input  /wordcount/output</p>
			</td>
		</tr></tbody></table><h1><strong><strong><strong>5 集群使用初步</strong></strong></strong></h1>

<h2><strong><strong><strong>5.1 HDFS使用</strong></strong></strong></h2>

<p style="margin-left:0pt;">1、查看集群状态</p>

<p style="margin-left:0pt;">命令：   hdfs  dfsadmin  –report</p>

<p style="margin-left:0pt;">可以看出，集群共有3个datanode可用</p>

<p style="margin-left:0pt;">也可打开web控制台查看HDFS集群信息，在浏览器打开<a href="http://hdp-node-01:50070/" rel="nofollow"><u><span style="color:#0000ff;"><u>http://hdp-node-01:50070/</u></span></u></a></p>

<p style="margin-left:0pt;">2、上传文件到HDFS</p>

<ul><li>查看HDFS中的目录信息</li>
</ul><p style="margin-left:0pt;">命令：   hadoop  fs  –ls  /</p>

<ul><li>上传文件</li>
</ul><p style="margin-left:0pt;">命令：   hadoop  fs  -put  ./ scala-2.10.6.tgz  to  /</p>

<ul><li>从HDFS下载文件</li>
</ul><p style="margin-left:21pt;">命令：  hadoop  fs  -get  /yarn-site.xml</p>

<h2><strong><strong><strong>5.2 MAPREDUCE使用</strong></strong></strong></h2>

<p style="margin-left:0pt;">mapreduce是hadoop中的分布式运算编程框架，只要按照其编程规范，只需要编写少量的业务逻辑代码即可实现一个强大的海量数据并发处理程序</p>

<h3><strong><strong><strong>5.2.1 Demo开发——wordcount</strong></strong></strong></h3>

<p style="margin-left:0pt;">1、需求</p>

<p style="margin-left:0pt;">从大量（比如T级别）文本文件中，统计出每一个单词出现的总次数</p>

<p style="margin-left:0pt;">2、mapreduce实现思路</p>

<p style="margin-left:0pt;">Map阶段：</p>

<ol><li>从HDFS的源数据文件中逐行读取数据</li>
	<li>将每一行数据切分出单词</li>
	<li>为每一个单词构造一个键值对(单词，1)</li>
	<li>将键值对发送给reduce</li>
</ol><p style="margin-left:0pt;">Reduce阶段：</p>

<ol><li>接收map阶段输出的单词键值对</li>
	<li>将相同单词的键值对汇聚成一组</li>
	<li>对每一组，遍历组中的所有“值”，累加求和，即得到每一个单词的总次数</li>
	<li>将(单词，总次数)输出到HDFS的文件中</li>
	<li>具体编码实现</li>
</ol><p style="margin-left:0pt;"><span style="color:#000000;">(1)定义一个mapper类</span></p>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;">//首先要定义四个泛型的类型</p>

			<p style="margin-left:0pt;">//keyin:  LongWritable    valuein: Text</p>

			<p style="margin-left:0pt;">//keyout: Text            valueout:IntWritable</p>

			<p style="margin-left:0pt;"> </p>

			<p style="margin-left:0pt;">public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt;{</p>

			<p style="margin-left:0pt;">//map方法的生命周期：  框架每传一行数据就被调用一次</p>

			<p style="margin-left:0pt;">//key :  这一行的起始点在文件中的偏移量</p>

			<p style="margin-left:0pt;">//value: 这一行的内容</p>

			<p style="margin-left:0pt;">@Override</p>

			<p style="margin-left:0pt;">protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {</p>

			<p style="margin-left:0pt;">//拿到一行数据转换为string</p>

			<p style="margin-left:0pt;">String line = value.toString();</p>

			<p style="margin-left:0pt;">//将这一行切分出各个单词</p>

			<p style="margin-left:0pt;">String[] words = line.split(" ");</p>

			<p style="margin-left:0pt;">//遍历数组，输出&lt;单词，1&gt;</p>

			<p style="margin-left:0pt;">for(String word:words){</p>

			<p style="margin-left:0pt;">context.write(new Text(word), new IntWritable(1));</p>

			<p style="margin-left:0pt;">}</p>

			<p style="margin-left:0pt;">}</p>

			<p style="margin-left:0pt;">}</p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;"><span style="color:#000000;">(2)定义一个reducer类</span></p>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><span style="color:#000000;">//生命周期：框架每传递进来一个kv 组，reduce方法被调用一次</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">@Override</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">//定义一个计数器</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">int count = 0;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">//遍历这一组kv的所有v，累加到count中</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">for(IntWritable value:values){</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">count += value.get();</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">}</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">context.write(key, new IntWritable(count));</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">}</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">}</span></p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;"><span style="color:#000000;">(3)定义一个主类，用来描述job并提交job</span></p>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><span style="color:#000000;">public class WordCountRunner {</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">//把业务逻辑相关的信息（哪个是mapper，哪个是reducer，要处理的数据在哪里，输出的结果放哪里。。。。。。）描述成一个job对象</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">//把这个描述好的job提交给集群去运行</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">public static void main(String[] args) throws Exception {</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">Configuration conf = new Configuration();</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">Job wcjob = Job.getInstance(conf);</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">//指定我这个job所在的jar包</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">//</span> <span style="color:#000000;">wcjob.setJar("/home/hadoop/wordcount.jar");</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">wcjob.setJarByClass(WordCountRunner.class);</span></p>

			<p style="margin-left:0pt;"> </p>

			<p style="margin-left:0pt;"><span style="color:#000000;">wcjob.setMapperClass(WordCountMapper.class);</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">wcjob.setReducerClass(WordCountReducer.class);</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">//设置我们的业务逻辑Mapper类的输出key和value的数据类型</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">wcjob.setMapOutputKeyClass(Text.class);</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">wcjob.setMapOutputValueClass(IntWritable.class);</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">//设置我们的业务逻辑Reducer类的输出key和value的数据类型</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">wcjob.setOutputKeyClass(Text.class);</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">wcjob.setOutputValueClass(IntWritable.class);</span></p>

			<p style="margin-left:0pt;"> </p>

			<p style="margin-left:0pt;"><span style="color:#000000;">//指定要处理的数据所在的位置</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">FileInputFormat.setInputPaths(wcjob, "hdfs://hdp-server01:9000/wordcount/data/big.txt");</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">//指定处理完成之后的结果所保存的位置</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">FileOutputFormat.setOutputPath(wcjob, new Path("hdfs://hdp-server01:9000/wordcount/output/"));</span></p>

			<p style="margin-left:0pt;"> </p>

			<p style="margin-left:0pt;"><span style="color:#000000;">//向yarn集群提交这个job</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">boolean res = wcjob.waitForCompletion(true);</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">System.exit(res?0:1);</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">}</span></p>
			</td>
		</tr></tbody></table><h3><strong><strong><strong>5.2.2 程序打包运行</strong></strong></strong></h3>

<ol><li>将程序打包</li>
	<li>准备输入数据</li>
</ol><p style="margin-left:0pt;">vi  /home/hadoop/test.txt</p>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;">Hello tom</p>

			<p style="margin-left:0pt;">Hello jim</p>

			<p style="margin-left:0pt;">Hello ketty</p>

			<p style="margin-left:0pt;">Hello world</p>

			<p style="margin-left:0pt;">Ketty tom</p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;">在hdfs上创建输入数据文件夹：</p>

<p style="margin-left:0pt;">hadoop   fs  mkdir  -p  /wordcount/input</p>

<p style="margin-left:0pt;">将words.txt上传到hdfs上</p>

<p style="margin-left:0pt;">hadoop  fs  –put  /home/hadoop/words.txt  /wordcount/input</p>

<ol><li>将程序jar包上传到集群的任意一台服务器上</li>
	<li>使用命令启动执行wordcount程序jar包</li>
</ol><p style="margin-left:21pt;">$ hadoop jar wordcount.jar cn.itcast.bigdata.mrsimple.WordCountDriver /wordcount/input /wordcount/out</p>

<ol><li>查看执行结果</li>
</ol><p style="margin-left:21pt;">$ hadoop fs –cat /wordcount/out/part-r-00000</p>            </div>
                </div>