---
layout:     post
title:      Hadoop 资源+配置+性能
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p><span style="font-size:small;">Hadoop 资源</span></p>
<p><span style="font-size:small;"> </span></p>
<p><span style="font-size:small;">淘宝Hadoop的技术分享</span></p>
<p><a href="http://rdc.taobao.com/blog/dw/archives/category/hadoop" rel="nofollow"><span style="font-size:small;">http://rdc.taobao.com/blog/dw/archives/category/hadoop</span></a></p>
<p><a href="http://rdc.taobao.com/blog/dw/archives/244" rel="nofollow"><span style="font-size:small;">http://rdc.taobao.com/blog/dw/archives/244</span></a></p>
<p><span style="font-size:small;"> </span></p>
<p><span style="font-size:small;">Hadoop基本流程与应用开发</span></p>
<p><a href="http://www.infoq.com/cn/articles/hadoop-process-develop" rel="nofollow"><span style="font-size:small;">http://www.infoq.com/cn/articles/hadoop-process-develop</span></a></p>
<p><span style="font-size:small;"> </span></p>
<p><span style="font-size:small;">Hadoop性能调优</span></p>
<p><a href="http://wiki.apache.org/hadoop/PerformanceTuning" rel="nofollow">http://wiki.apache.org/hadoop/PerformanceTuning</a></p>
<p> </p>
<p>HBase性能调优</p>
<p><a href="http://wiki.apache.org/hadoop/Hbase/PerformanceEvaluation" rel="nofollow">http://wiki.apache.org/hadoop/Hbase/PerformanceEvaluation</a></p>
<p> </p>
<p> </p>
<p>hadoop中使用lzo压缩格式</p>
<p><a href="http://code.google.com/p/hadoop-gpl-compression/wiki/FAQ" rel="nofollow">http://code.google.com/p/hadoop-gpl-compression/wiki/FAQ</a></p>
<p><a href="http://blog.csdn.net/workhardupc100/archive/2010/03/04/5345013.aspx" rel="nofollow">http://blog.csdn.net/workhardupc100/archive/2010/03/04/5345013.aspx</a></p>
<p><a href="http://www.cloudera.com/blog/2009/11/hadoop-at-twitter-part-1-splittable-lzo-compression/" rel="nofollow">http://www.cloudera.com/blog/2009/11/hadoop-at-twitter-part-1-splittable-lzo-compression/</a></p>
<p> </p>
<p>给MR加jar</p>
<p><span class="codefrag">hadoop jar hadoop-examples.jar wordcount -files cachefile.txt -libjars mylib.jar input output </span></p>
<p> </p>
<p><span class="codefrag">Hadoop DFS Used是如何计算的？ （集群中所有dfs.data.dir目录相加）</span></p>
<p><span class="codefrag">bin/hadoop fs -du /</span></p>
<p><span class="codefrag"><a href="http://hadoop.hadoopor.com/redirect.php?tid=562&amp;goto=lastpost" rel="nofollow">http://hadoop.hadoopor.com/redirect.php?tid=562&amp;goto=lastpost</a></span></p>
<p> </p>
<p><span style="font-size:small;">-----------------------------------------------------------------</span></p>
<p><span style="font-size:small;">Hadoop 集群参数配置</span></p>
<p><a><span style="font-size:small;">hadoop-0.20.2\docs\cluster_setup.html</span></a></p>
<p><span style="font-size:small;"> </span></p>
<p><span style="font-size:small;">MapReduce的同时 ，（DFS Used : 8.21 GB  ）大小会增加，因为被使用。默认存放Job中间文件的路径是dfs.data.dir（/tmp目录，由Hadoop自动清理，或者手动hadoop fs -rmr /tmp ）</span></p>
<p> </p>
<p><span style="font-size:small;color:#ff0000;"><strong>默认提交的Job，都会在后台执行，即使前台停止。</strong></span></p>
<p> </p>
<p><span style="font-size:small;">Kiss不要的Job</span></p>
<p><span>bin/hadoop job -kill  job_201004141024_0002</span></p>
<p> </p>
<p><span style="font-size:small;">配置每个Task对应的Map和Reduce数量</span></p>
<p><span class="codefrag"><span style="font-size:small;">conf/mapred-site.xml </span></span></p>
<p><span style="font-size:small;">(The maximum number of Map/Reduce tasks, which are run simultaneously on a given <span class="codefrag">TaskTracker</span>, individually. )</span></p>
<p><span style="font-size:small;">mapred.tasktracker.map.tasks.maximum=2</span></p>
<p><span style="font-size:small;">mapred.tasktracker.reduce.tasks.maximum=2</span></p>
<p><span style="font-size:small;">默认为2，如果有3台hadoop机器，则同时最多6个Map在执行。</span></p>
<p><span style="font-size:small;"> </span></p>
<p><span style="font-size:small;font-family:'Courier New';">mapred.map.tasks (The default number of map tasks per job.)</span></p>
<p><span style="font-size:small;font-family:'Courier New';">配置MapReduce的大小</span></p>
<p><span style="font-size:small;"> </span></p>
<p><span style="font-size:small;">关于多少Map和Reduce的建议</span></p>
<p>Map的数目通常是由输入数据的大小决定的，一般就是所有输入文件的总块（block）数。 </p>
<p> </p>
<p>Reduce的数目建议是<span class="codefrag">0.95</span>或<span class="codefrag">1.75</span>乘以 (&lt;<em>no. of nodes</em>&gt; * <span class="codefrag">mapred.tasktracker.reduce.tasks.maximum</span>)。 </p>
<p>用0.95，所有reduce可以在maps一完成时就立刻启动，开始传输map的输出结果。用1.75，速度快的节点可以在完成第一轮reduce任务后，可以开始第二轮，这样可以得到比较好的负载均衡的效果。</p>
<p> </p>
<p><a href="http://wiki.apache.org/hadoop/HowManyMapsAndReduces" rel="nofollow"><span style="font-size:small;">http://wiki.apache.org/hadoop/HowManyMapsAndReduces</span></a></p>
<p><span style="font-size:small;"> </span></p>
<p><span style="font-size:small;">-----------------------------------------------------------------</span></p>
<p><span style="font-size:small;">Hadoop + Hbase 性能</span></p>
<p> </p>
<p> <span style="font-size:small;">-----------------------------------------------------------------</span></p>
<p><span style="font-size:small;">Hadoop 性能测试</span></p>
<p> </p>
<p><span style="font-size:small;">1千万条记录，3台机器,每台机器最多并行10个Map</span></p>
<p><span style="font-size:small;">/home/bmb/jdk1.6.0_16/bin/java  -cp examples.zip examples.CreateLogFile  test.log 10000000</span></p>
<p><span style="font-size:small;">1KW=350.74MB =5.46 Block</span></p>
<p> </p>
<p><span style="font-size:small;">bin/hadoop fs -put test.log hadoop-performance-test</span></p>
<p> </p>
<p><span style="font-size:small;">计算文件中，同一时间生成的行数</span></p>
<p><span style="font-size:small;">/home/iic/hadoop-0.20.2/bin/hadoop jar hadoop-examples.zip examples.HadoopMRTest hadoop-performance-test  hadoop-performance-test-out  1</span></p>
<p> </p>
<p><span style="font-size:small;">第一次启动，Hadoop自动分配 map6, reduce 1</span></p>
<p>1KW/39=25W/s</p>
<p>10/04/14 13:43:36 </p>
<p>10/04/14 13:44:15</p>
<p> </p>
<p><span style="font-size:small;">从Job的Complet Map中，可以看到，每台机器运行2个Map</span></p>
<p> </p>
<p><span style="font-size:small;">查看结果</span></p>
<p><span style="font-size:small;">bin/hadoop fs -cat hadoop-performance-test-out/part-r-00000</span></p>
<p>1271222992947 349</p>
<p><span style="font-size:small;">验证：</span></p>
<p>grep 1271222992947 test.log |wc -l</p>
<p><span style="font-size:small;">删除目录，方便重新测试</span></p>
<p><span style="font-size:small;">bin/hadoop fs -rmr hadoop-performance-test-out</span></p>
<p><span style="font-size:small;">bin/hadoop fs -rmr hadoop-performance-test</span></p>
<p>  </p>
<p> </p>
<p>1亿条记录==3.61GB=58 Block</p>
<p><span style="font-size:small;">/home/bmb/jdk1.6.0_16/bin/java  -cp examples.zip examples.CreateLogFile  test_10KW.log 100000000</span></p>
<p><span style="font-size:small;">bin/hadoop fs -put test_10KW.log hadoop-performance-test</span></p>
<p> </p>
<p>/home/iic/hadoop-0.20.2/bin/hadoop jar hadoop-examples.zip examples.HadoopMRTest hadoop-performance-test  hadoop-performance-test-out 6</p>
<p> </p>
<p><span style="font-size:small;">指定reduce 6，Hadoop自动分配 map 58 </span></p>
<p><span style="font-size:x-small;">10KW/197=50.76W/s</span></p>
<p>10/04/14 14:14:40</p>
<p>10/04/14 14:17:57  </p>
<p> </p>
<p> </p>
<p> <span style="font-size:small;">-----------------------------------------------------------------</span></p>
<p><span style="font-size:small;">此例子3台机器, replication=2 , 默认块大小64M，功能，把表mrtest的列content的值反转到列text里面</span></p>
<p> </p>
<p><span style="font-size:small;">初始100W数据，执行Map Reduce，只有1个Map. </span></p>
<p><span style="font-size:small;">（重新清理Hadoop后，统计得：刚开始DFS Used : 100.03 KB ，创建完后DFS Used : 234.27 MB,Replication=2,</span></p>
<p><span style="font-size:small;">一次MR后，DFS Used : 345.88 MB ，同时HBase中表mrtest的内容被重新分布（原因是Hbase是Readonly，当执行Update操作，必然导致重新创建），DFS Used之所以增大，是因为Hadoop保存数据默认3个时间版本，所以一次MR后，多了一个版本的数据</span></p>
<p><span style="font-size:small;">重启Hadoop，DFS Used : 262.87 MB </span></p>
<p><span style="font-size:small;">第二次MR后，DFS Used : 537.04 MB ，重启Hadoop，DFS Used : 358.61 MB </span></p>
<p>第三次MR后，DFS Used : 431.89 MB  ，重启Hadoop，DFS Used : 454.35 MB </p>
<p><span style="font-size:small;">）</span></p>
<p> </p>
<p><span lang="en-us" xml:lang="en-us"><span style="font-family:Calibri;"><span style="font-size:small;">/home/iic/hadoop-0.20.2/bin/hadoop jar  examples.zip  examples.TestTableMapReduce<span> </span>examples.TestTableMapReduce</span></span></span></p>
<p> </p>
<p><span lang="en-us" xml:lang="en-us"><span style="font-family:Calibri;"><span style="font-size:small;">时间执行 (100W / (8*60) ) = 2083个记录/每秒</span></span></span></p>
<p><span lang="en-us" xml:lang="en-us"><span style="font-family:Calibri;"><span style="font-size:small;">10/04/13 14:08:33</span></span></span></p>
<p><span lang="en-us" xml:lang="en-us"><span style="font-family:Calibri;"><span style="font-size:small;">10/04/13 14:16:25</span></span></span></p>
<p><span style="font-size:small;"> </span></p>
<p><span lang="en-us" xml:lang="en-us"><span style="font-family:Calibri;"><span style="font-size:small;">cd /home/iic/hadoop-0.20.2/examples</span></span></span></p>
<p><span lang="en-us" xml:lang="en-us"><span style="font-size:small;font-family:Calibri;">./run_test.sh 生成900W的数据</span></span></p>
<p><span lang="en-us" xml:lang="en-us"><span style="font-size:small;font-family:Calibri;">/home/iic/bmb/jdk1.6.0_16/bin/java  -cp .: com.test.hadoop.hbase.HBaseTest  1 10000000</span></span></p>
<p><span style="font-size:small;"> </span></p>
<p><span lang="en-us" xml:lang="en-us"><span style="font-size:small;font-family:Calibri;">同样环境，测试1000W数据</span></span></p>
<p><span lang="en-us" xml:lang="en-us"><span style="font-size:small;font-family:Calibri;">出现java.lang.ClassNotFoundException: org.apache.hadoop.hbase.mapreduce.TableOutputFormat</span></span></p>
<p><span lang="en-us" xml:lang="en-us"><span style="font-size:small;font-family:Calibri;">原因：新增的Hadoop机器：5.12类路径没有包含HBase，在conf/hadoop-env.sh中，加入类库引用</span></span></p>
<p><span lang="en-us" xml:lang="en-us"><span style="font-size:small;">export HBASE_HOME=/home/iic/hbase-0.20.3<br>export HADOOP_CLASSPATH=$HBASE_HOME/hbase-0.20.3.jar:$HBASE_HOME/hbase-0.20.3-test.jar:$HBASE_HOME/conf:${HBASE_HOME}/lib/zookeeper-3.3.0.jar</span></span></p>
<p><span style="font-size:small;"> </span></p>
<p><span><span style="font-size:small;"><span> </span><span> </span></span></span></p>
<p><span style="font-size:small;">1000W的数据，大小达到3个Block, 执行Map Reduce，这时Map数量为3，由于是对Hbase进行MapReduce，而HBase最多的Map值是通过以下计算（for the list of regions and makes a map-per-region or <code>mapred.map.tasks maps</code>, whichever is smaller ）。</span></p>
<p><span style="font-size:small;"> </span></p>
<p><span lang="en-us" xml:lang="en-us"><span style="font-family:Calibri;"><span style="font-size:small;">时间执行 (1000W / (33*60) ) = 5050个记录/每秒</span></span></span></p>
<p><span style="font-size:small;">10/04/13 18:48:52 </span></p>
<p><span style="font-size:small;"><span>10/04/13 19:20:06</span> <span> </span></span></p>
<p><span style="font-size:small;"> </span></p>
<p><span style="font-size:small;">修改Map为6（实际Hadoop Job自动生成5）和Reduce的数量3</span></p>
<p><span style="font-size:small;">从5.11拷贝到2.79</span></p>
<p><span style="font-size:small;">cd  /home/iic/hadoop-0.20.2</span></p>
<p><span style="font-size:small;">scp examples.zip </span><a href="mailto:iic@192.168.2.79:/home/iic/hadoop-0.20.2/" rel="nofollow"><span style="font-size:small;">iic@192.168.2.79:/home/iic/hadoop-0.20.2/</span></a></p>
<p><span style="font-size:small;"> </span></p>
<p><span lang="en-us" xml:lang="en-us"><span style="font-family:Calibri;"><span style="font-size:small;">时间执行 (1000W / (21*60) ) = 7936个记录/每秒</span></span></span></p>
<p><span style="font-size:small;">10/04/13 19:43:55</span></p>
<p><span style="font-size:small;">10/04/13 20:04:17</span></p>
<p><span style="font-size:small;"> </span></p>
<p><span style="font-size:small;">修改map为9（Hadoop自动转成16,同时把<a href="/admin/blogs/642785/browseDirectory.jsp?dir=/&amp;namenodeInfoPort=50070" rel="nofollow">/</a><a href="/admin/blogs/642785/browseDirectory.jsp?dir=/hbase&amp;namenodeInfoPort=50070" rel="nofollow">hbase</a>/mrtest分成17个目录，17个Block），Reduce为9</span></p>
<p><span style="font-size:small;">（注：Hadoop会缓存mapred.map.tasks，除非出现新的参数）</span></p>
<p><span style="font-size:small;">mapred-site.xml</span></p>
<p><span style="font-size:small;">  &lt;property&gt; <br>    &lt;name&gt;mapred.map.tasks&lt;/name&gt; <br>    &lt;value&gt;9&lt;/value&gt; <br>  &lt;/property&gt; </span></p>
<p><span style="font-size:small;"><span lang="en-us" xml:lang="en-us"><span style="font-family:Calibri;"><span style="font-size:small;">时间执行 (1000W / (18*60) ) = 9259个记录/每秒</span></span></span></span></p>
<p><span style="font-size:small;">10/04/14 09:27:36</span></p>
<p>10/04/14 09:45:55</p>
<p> </p>
<p>按照上面的配置，再次执行一遍，Map变成17（Hadoop和Hbase会自动根据Block大小，增加Map数量）。</p>
<p>从日志看，Reduce会存在网络的Block复制，如果网速快，也会增加MR的速率</p>
<p>当Map为17的时候，每台机器的CPU从Map为3的20%增加到100%多。</p>
<p>但是执行到最后，2.79和5.11的Hbase，region server当掉。导致执行失败。</p>
<p> </p>
<p>重启Hadoop和Hbase，再执行</p>
<p>Map自动变成18，Reduce 9</p>
<p><span lang="en-us" xml:lang="en-us"><span style="font-family:Calibri;"><span style="font-size:small;">时间执行 (1000W / (18*60) ) = 9259个记录/每秒</span></span></span></p>
<p>10/04/14 10:27:39</p>
<p>10/04/14 10:45:48</p>
<p> </p>
<p>每次执行后，Block数量一直在增加</p>
<p>虽然Map是18，但是由于只有3台机器，而且默认<span style="font-size:small;">mapred.tasktracker.map.tasks.maximum=2，每个TaskTracker最多同时并行2个Map，所以18个Map不是全部并行执行。</span></p>
<p><span style="font-size:small;">最多同时6个Map。同理最多同时6个Task。</span></p>
<p> </p>
<p><span style="font-size:small;">修改3台机器的参数mapred-site.xml，重启Hadoop</span></p>
<p> &lt;property&gt;<br>  &lt;name&gt;mapred.tasktracker.map.tasks.maximum&lt;/name&gt;<br>  &lt;value&gt;10&lt;/value&gt;<br> &lt;/property&gt;</p>
<p> &lt;property&gt;<br>  &lt;name&gt;mapred.tasktracker.reduce.tasks.maximum&lt;/name&gt;<br>  &lt;value&gt;10&lt;/value&gt;<br> &lt;/property&gt;</p>
<p> </p>
<p><span lang="en-us" xml:lang="en-us"><span style="font-family:Calibri;"><span style="font-size:small;">时间执行 (1000W / (15*60) ) = 11111个记录/每秒</span></span></span></p>
<p>10/04/14 11:36:49</p>
<p>10/04/14 11:51:56</p>
<p> </p>
<p> </p>
<p> 测试的时候，2.79的region server 挂了，用以下命令重启</p>
<p>bin/hbase-daemon.sh start regionserver</p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>            </div>
                </div>