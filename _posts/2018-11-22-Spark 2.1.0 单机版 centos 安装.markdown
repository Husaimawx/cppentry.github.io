---
layout:     post
title:      Spark 2.1.0 单机版 centos 安装
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/heywakeup/article/details/57075098				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<h2>spark/hadoop 学习记录</h2>
一、Spark 2.1.0 单机版 centos 安装
<p><strong>单机操作系统版本：</strong></p>
<p>centos 7 64bit</p>
<p><strong>安装前准备</strong></p>
<pre><span style="font-size:10px;">1.安装包地址</span></pre>
<p><em>scala-2.12.1</em><br></p>
<p>    http://downloads.lightbend.com/scala/2.12.1/scala-2.12.1.tgz</p>
<p><em>jdk1.8</em><br></p>
   http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html
<p><em>spark-2.1.0-bin-hadoop2.7</em></p>
<p>   http://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz<br></p>
<p>2.创建 spark 目录 并下载安装包</p>
<p></p>
<pre><code class="language-plain">cd /
mkdir spark
cd /spark
wget http://downloads.lightbend.com/scala/2.12.1/scala-2.12.1.tgz
wget --no-check-certificate --no-cookies --header "Cookie: oraclelicense=accept-securebackup-cookie" http://download.oracle.com/otn-pub/java/jdk/8u91-b14/jdk-8u91-linux-x64.rpm
wget http://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz
</code></pre>ps：如果没有安装 wget 工具使用和安装 自行google.如果wget速度比较慢，可考虑使用其他第三方工具（如迅雷）下载后通过WinSCP等工具将安装包上传到spark 目录<br>
3.安装 依次 jdk-&gt;scala -&gt; spark
<p></p>
<p></p>
<pre><code class="language-plain">rpm -ivh jdk-8u91-linux-x64.rpm
tar -zxf  scala-2.12.1.tgz
#将scala 放在 /usr/bin下
mv  scala-2.12.1 ../usr/bin
#解压spark
tar -zxf  spark-2.1.0-bin-hadoop2.7.tgz</code></pre>配置环境变量:
<p></p>
<p></p>
<pre><code class="language-plain">cd /
vi etc/profile</code></pre>在文档末尾添加如下环境变量
<p></p>
<p></p>
<pre><code class="language-plain">SCALA_HOME=/usr/lib/scala-2.12.1
SPARK_HOME=/spark/spark-2.1.0-bin-hadoop2.7
#具体JDK位置，此处不一定相同
JAVA_HOME=/usr/java/jdk1.8.0_91
#具体JRE位置，此处不一定相同
JRE_HOME=/usr/java/jdk1.8.0_91/jre
PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin:$SCALA_HOME/bin
CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib
export JAVA_HOME JRE_HOME PATH CLASSPATH</code></pre><br>
保存退出刷新环境变量配置
<p></p>
<p></p>
<pre><code class="language-plain">source etc/profile</code></pre>
<p>测试使用官方 example </p>
<p></p><pre><code class="language-plain">cd /
cd /spark/spark-2.1.0-bin-hadoop2.7
./bin/run-example SparkPi
./bin/spark-shell </code></pre><br><p>官方scala shell 使用example 请参考 <br>
http://spark.apache.org/docs/latest/quick-start.html</p>
            </div>
                </div>