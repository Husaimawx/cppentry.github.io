---
layout:     post
title:      流式计算Storm和Kafka知识点
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h1 style="font-family:'PingFang SC', 'Microsoft YaHei', 'Helvetica Neue', Helvetica, Arial, sans-serif;color:rgb(68,68,68);background-color:rgb(255,255,255);">企业级消息队列（Kafka）</h1><ul style="border:1px solid rgb(238,238,238);list-style-position:inside;color:rgb(68,68,68);font-family:'PingFang SC', 'Microsoft YaHei', 'Droid Serif', Georgia, 'Times New Roman', STHeiti, serif;font-size:14px;background-color:rgb(255,255,255);"><li>Kafka是什么？ 消息队列</li><li>为什么要有消息队列？ 解耦、异构、并行</li><li>Kafka数据生成方式<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>producer--&gt;kafka----&gt;保存到本地</li><li>consumer---主动拉取数据</li></ul></li><li>Kafka核心概念<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>producer(生产者)<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>消息不丢失</li><li>数据分发策略</li></ul></li><li>kafka brokers<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>topic（主题）：一类消息，比如用户信息、商品信息、订单信息</li><li>partition<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>为什么要有partition？ 数据太大，单个节点无法存储。</li><li>partition的物理形态？ 文件夹</li><li>partition的数量设计？<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>如果集群很小（10），将partition设置为broker的数量</li><li>如果集群大于10台，就要根据数据量来设计</li></ul></li></ul></li><li>replication<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>为什么要有replication？ 保证数据安全，数据容错的考虑。</li><li>设置几个副本？<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>数据的越重要，副本数可以设的越高。但是，数据冗余高，ack时间越长，效率越低。</li><li>平常设置2个。</li></ul></li></ul></li><li>segment（段）<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>为什么要分段？ 如果文件巨大，删除麻烦、查找麻烦。<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>分段大小，1G。这个可以设置。</li><li>删除数据的过期时间，168小时，等于7天。注意，在规划Kafka集群的是，要考虑数据存储几天的。Kafka集群的数量，建议3-5台。 24T * 5 = 120T</li><li>segment物理形态：有个log文件和index索引文件。<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>log 存放的原始数据</li><li>index 存放的是offset和物理地址值</li><li>数据查找中会有二分查找法（掌握）</li></ul></li></ul></li></ul></li><li>pagecache<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>现代操作系统提供缓存技术，Kafka将当前生产的数据保存在缓存中。</li><li>由于生产和消费时间差很小，所以消费者消费数据的时候，基本上都是从内存中获取数据。</li></ul></li><li>sendfile<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>作为消费者，想消费历史的数据。senfile技术不经过应用，在操作系统层面，读取完数据之后，直接输出到网卡。</li></ul></li><li>partition isr<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>如果partition有多个副本，需要选择一个leader出来，负责数据的读写读写读写操作。</li><li>这个leader有可能挂掉，因为压力大。</li><li>如果使用投票机制，会有相对来说比较大时间消费，时刻准备好备胎。</li><li>满足什么样条件才能isr成员？同步leader的数据，在某个时间阈值和数量阈值内。不满足条件就踢出ISR。</li></ul></li><li>partition leader<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>leader是针对partition的描述。</li><li>负责数据的读写。</li></ul></li></ul></li><li>consumer<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>consumerGroup，消费数据都是以消费组的形式 出现的。</li><li>消费组中的成员，消费数据是互不干扰的。当有一个消费者挂了之后，会在确定消费者无法重新消费后，触发负载均衡。</li><li>两个不同的消费组，消费同一个topic的数据，都是完整。注意：在实际开发过程，要将自己的消费组设计成唯一的。</li><li>consumer消费offset管理。<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>0.8版本，offset是有zookeeper进行管理的。</li><li>0.8+，可以选择使用kafka的consumer_offset的topic进行管理。</li></ul></li></ul></li></ul></li><li>Kafka常见问题？<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>Kafka为什么那么快？ pageche、sendfile</li><li>Kafka消费不丢失机制？ producer、broker、consumer。</li><li>Kafka消费数据全局有序？ 单个partition是有序，全局有序违背设计的初衷。</li></ul></li></ul><h1 style="font-family:'PingFang SC', 'Microsoft YaHei', 'Helvetica Neue', Helvetica, Arial, sans-serif;color:rgb(68,68,68);background-color:rgb(255,255,255);">流式计算框架（Storm）</h1><ul style="border:1px solid rgb(238,238,238);list-style-position:inside;color:rgb(68,68,68);font-family:'PingFang SC', 'Microsoft YaHei', 'Droid Serif', Georgia, 'Times New Roman', STHeiti, serif;font-size:14px;background-color:rgb(255,255,255);"><li>流式计算框架的组成：一般flume+kafka+storm+redis，每个组件都可以被替换掉。</li><li>Storm是什么？ 流式计算框架，一旦启动，永不停止。</li><li>Storm架构是什么？<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>client：用来创建一个stormtopology，然后将stormtopology序列化之后，通过rpc的提交到nimbus。</li><li>nimbus：发布rpc的服务，接受client的任务提交，对任务进行校验。将任务放入任务队列中（阻塞队列）。后台线程读取队列，获得任务信息，进行任务分配。<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>获取当前集群中，空闲的worker资源。</li><li>获取当前任务需要多少个Task。Task数量就是所有component（组件）的并行数量加上每个worker会启动的一个ackerBolt之和。</li><li>将任务信息保存到zookeeper。</li></ul></li><li>zookeeper：zookeeper保存任务信息及节点各种其他信息。</li><li>supervisor：通过watch机制，得到任务信息，然后启动属于自己的worker。</li><li>worker：被supervisor启动，负责具体的任务执行。<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>Task：本质上是个线程，是个executor。分为三种类型 SpoutTask、BoltTask、AckerTask。</li></ul></li></ul></li><li>Storm的编程模型？<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>Spout extends baseRichSpout<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>open ：初始化方法</li><li>nextTuple ：有个while一直调用该方法，调用一次发送一次数据。</li><li>field：声明输出的字段名称和数量</li></ul></li><li>bolt1 extends baseRichBolt (手动ack)<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>prepare：初始化方法</li><li>execute： 执行方法</li><li>field：声明输出的字段名称和数量</li></ul></li><li>bolt2 extends baseBasicBolt(自动ack)<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>execute： 执行方法</li><li>field：声明输出的字段名称和数量</li></ul></li><li>驱动类：topologybuilder</li><li>运行模式：本地模式、集群模式</li></ul></li><li>Storm组件的并行度怎么设置？<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>Spout是根据上游kafka的topic的分区数量设置。</li><li>Bolt1是根据Spout发送的数据/bolt1处理每条数据量（单位时间 1S）</li><li>Bolt2是根据Spout发送的数据/bolt1处理每条数据量（单位时间 1S）</li></ul></li><li>Spout的worker的数量怎么设置？<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>根据所有组件的并行度之和，进行设置。</li><li>可以一个worker有两个Spout或者多个Spout。</li><li>如果Spout下游不同层级的所有的bolt的数量很多情况下，运算压力，可以考虑worker和spout数量保持一致。<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>压力更大，只能修改partition的数量。</li><li>如果修改不了partition数量，只能曾加worker数，任由数据充斥在网络中。</li></ul></li></ul></li><li>Spout上下游衔接策略（StreamGrouping）<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>localorshuffle 分组策略是任何时候的第一选择。</li><li>fieldGroup 字段分组。</li></ul></li></ul><h1 style="font-family:'PingFang SC', 'Microsoft YaHei', 'Helvetica Neue', Helvetica, Arial, sans-serif;color:rgb(68,68,68);background-color:rgb(255,255,255);">Storm的原理</h1><ul style="border:1px solid rgb(238,238,238);list-style-position:inside;color:rgb(68,68,68);font-family:'PingFang SC', 'Microsoft YaHei', 'Droid Serif', Georgia, 'Times New Roman', STHeiti, serif;font-size:14px;background-color:rgb(255,255,255);"><li>任务提交流程<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>用来创建一个stormtopology，然后将stormtopology序列化之后，通过rpc的提交到nimbus。</li><li>扩展：RPC框架，动态+反射技术+网络通信技术。</li></ul></li><li>集群启动流程<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>Java系统流程： Java -jar、Java -server、Java -client</li><li>手动启动：nimbus、supervisor</li><li>自动启动：supervisor根据任务信息启动worker。</li></ul></li><li>任务执行流程<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>与nimbus、supervisor没有半毛钱关系，都在worker。</li><li>SpoutTask.open() 一般用来打开外部的数据源</li><li>while 方式调用 nextTuple方法。发送数据，需要考虑数据的分组策略。<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>发送数据都是发送Tuple，会携带当前Tuple要发送给哪个taskid。</li><li>然后根据task分配信息，得到taskid所在的worker。</li><li>通过网络请求将tuple发送给远端的worker。</li><li>远端的worker有个接受的线程，根据taskid找到对应的Bolt的输入队列（无锁队列，每秒处理600万订单），将tuple放到bolt的输入中。</li><li>每个Task都是一个线程，后台不停的消费输入队列的内容。消费到消息之后，会调用bolt的execute方法，将数据传入给bolt。</li></ul></li><li>Bolt的execute方法接收到了Tuple，经过一顿处理。然后向下游发送数据Tuple。<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>发送数据时，会根据下游的分组策略。比如：localorshuffle。</li><li>如果是localorshuffle方式，直接找到当前worker中的对应Task，进行分发。将数据放入响应bolt的输入队列。</li><li>每个Task都是一个线程，后台不停的消费输入队列的内容。消费到消息之后，会调用bolt的execute方法，将数据传入给bolt。</li></ul></li><li>如此循环。</li></ul></li><li>消息不丢失机制<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>如何开启消息不丢失机制？<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>spout端发送数据的时候，要加上messageid.</li><li>spout要重写ack和fail方法。</li><li>在topologybuiler的config文件中设置setNumAckers的数量大于1.默认是1</li><li>在下游个每个层级bolt上，需要增加锚点。</li></ul></li><li>现象是什么？<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>当消息处理成功，会调用ack方法。</li><li>当消息处理失败<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>超时处理，默认30S，会调用faile方法，并传入messageid。</li><li>真的异常了，消息重发。 消息重发，需要手动设置。<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>消息重发，最好是在spout发送tuple的时候，将tuple本身当做messageid传入，失败后，直接发送messageid</li></ul></li></ul></li></ul></li><li>实现机制？异或机制。<ul style="border:1px solid rgb(238,238,238);list-style-position:inside;"><li>相同为0，不同为1。</li><li>需要上游发送时候的时候，发一个状态。并且需要下游处理完数据之后，发送一个状态。这两个状态值是一样的。</li><li>每个层级都会产生新的锚点id。64位长整型。</li></ul></li></ul></li></ul>            </div>
                </div>