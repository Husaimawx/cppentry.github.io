---
layout:     post
title:      MQ(一)kafka简介
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/yjp198713/article/details/79824219				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p></p><div class="toc"><div class="toc">
<ul>
<li><a href="#%E6%91%98%E8%A6%81" rel="nofollow">摘要</a></li>
<li><a href="#%E4%B8%80kfaka%E7%AE%80%E4%BB%8B" rel="nofollow">一、kfaka简介</a><ul>
<li><a href="#11kafka%E5%88%9B%E5%BB%BA%E8%83%8C%E6%99%AF" rel="nofollow">1.1、Kafka创建背景</a></li>
<li><a href="#12kafka%E8%AE%BE%E8%AE%A1%E7%9B%AE%E6%A0%87" rel="nofollow">1.2、Kafka设计目标</a></li>
<li><a href="#13%E6%96%B0%E7%89%88%E6%9C%AC%E7%AE%80%E4%BB%8B" rel="nofollow">1.3、新版本简介</a></li>
</ul>
</li>
<li><a href="#%E4%BA%8Ckafka%E9%80%82%E5%90%88%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E5%9C%BA%E6%99%AF" rel="nofollow">二、Kafka适合什么样的场景?</a></li>
<li><a href="#%E4%B8%89kafka%E5%9B%9B%E4%B8%AA%E6%A0%B8%E5%BF%83api" rel="nofollow">三、Kafka四个核心API</a></li>
<li><a href="#%E5%9B%9Bkafka%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5" rel="nofollow">四、Kafka相关概念:</a><ul>
<li><a href="#41topic-%E5%92%8C-%E6%97%A5%E5%BF%97" rel="nofollow">4.1、Topic 和 日志</a></li>
<li><a href="#42%E5%88%86%E5%B8%83%E5%BC%8F" rel="nofollow">4.2、分布式</a></li>
<li><a href="#43%E7%94%9F%E4%BA%A7%E8%80%85" rel="nofollow">4.3、生产者</a></li>
<li><a href="#44%E6%B6%88%E8%B4%B9%E8%80%85" rel="nofollow">4.4、消费者</a></li>
</ul>
</li>
<li><a href="#%E4%BA%94kafka%E4%BF%9D%E8%AF%81" rel="nofollow">五、Kafka保证</a></li>
<li><a href="#%E5%85%ADkafka%E4%BD%9C%E4%B8%BA%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F" rel="nofollow">六、Kafka作为消息系统</a></li>
<li><a href="#%E4%B8%83kafka-%E4%BD%9C%E4%B8%BA%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F" rel="nofollow">七、Kafka 作为存储系统</a></li>
<li><a href="#%E5%85%ABkafka%E7%94%A8%E5%81%9A%E6%B5%81%E5%A4%84%E7%90%86" rel="nofollow">八、Kafka用做流处理</a></li>
<li><a href="#%E4%B9%9D%E6%89%B9%E5%A4%84%E7%90%86" rel="nofollow">九、批处理</a></li>
<li><a href="#%E5%8D%81%E5%8F%82%E8%80%83" rel="nofollow">十、参考</a></li>
</ul>
</div>
</div>




<h1 id="摘要">摘要</h1>

<p>　　Kafka是由LinkedIn开发并开源的分布式消息系统，因其分布式及高吞吐率而被广泛使用，现已与Cloudera Hadoop，Apache Storm，Apache Spark集成。本文介绍了Kafka的创建背景，设计目标，使用消息系统的优势以及目前流行的消息系统对比。并介绍了Kafka的架构，Producer消息路由，Consumer Group以及由其实现的不同消息分发方式，Topic &amp; Partition，最后介绍了Kafka Consumer为何使用pull模式以及Kafka提供的三种delivery guarantee。</p>



<h1 id="一kfaka简介">一、kfaka简介</h1>

<p><strong>定位：Apache Kafka® 是 一个分布式流处理平台</strong>。</p>

<h2 id="11kafka创建背景">1.1、Kafka创建背景</h2>

<p>　　Kafka是一个消息系统，原本开发自LinkedIn，用作LinkedIn的活动流（Activity Stream）和运营数据处理管道（Pipeline）的基础。现在它已被多家不同类型的公司 作为多种类型的数据管道和消息系统使用。 <br>
　　活动流数据是几乎所有站点在对其网站使用情况做报表时都要用到的数据中最常规的部分。活动数据包括页面访问量（Page View）、被查看内容方面的信息以及搜索情况等内容。这种数据通常的处理方式是先把各种活动以日志的形式写入某种文件，然后周期性地对这些文件进行统计分析。运营数据指的是服务器的性能数据（CPU、IO使用率、请求时间、服务日志等等数据)。运营数据的统计方法种类繁多。 <br>
　　近年来，活动和运营数据处理已经成为了网站软件产品特性中一个至关重要的组成部分，这就需要一套稍微更加复杂的基础设施对其提供支持。 </p>

<h2 id="12kafka设计目标">1.2、Kafka设计目标</h2>

<p>　　Kafka是一种分布式的，基于发布/订阅的消息系统。主要设计目标如下：</p>

<ul>
<li>以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能</li>
<li>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条以上消息的传输</li>
<li>支持Kafka Server间的消息分区，及分布式消费，同时保证每个Partition内的消息顺序传输</li>
<li>同时支持离线数据处理和实时数据处理</li>
<li>Scale out：支持在线水平扩展</li>
</ul>

<h2 id="13新版本简介">1.3、新版本简介</h2>

<p>Kafka从首次发布之日起，已经走过了七个年头。从最开始的大规模消息系统，发展成为功能完善的分布式流式处理平台，用于发布和订阅、存储及实时地处理大规模流数据。来自世界各地的数千家公司在使用Kafka，包括三分之一的500强公司。Kafka以稳健的步伐向前迈进，首先加入了复制功能和无边界的键值数据存储，接着推出了用于集成外部存储系统的Connect API，后又推出了为实时应用和事件驱动应用提供原生流式处理能力的Streams API，并于今年春季开始支持仅一次处理语义。如此广泛的应用和完备的功能以及如此悠久的历史，无一不在说明Kafka已经成为一款稳定的企业级产品。而更为激动人心的是，Kafka现在正式迎来了1.0.0版本！</p>

<p>Kafka 1.0.0发布的主要内容如下。</p>

<ul>
<li>0.10.0版本里开始引入的Streams API在1.0.0版本里继续演进，改进了builder API（KIP-120），新增了用于查看运行时活跃任务的API（KIP-130）和用于聚合分区的cogroup API（KIP-150）。增强的print()和writeAsText()方法让调试变得更容易（KIP-160）。其他更多信息可以参考Streams文档。</li>
<li>改进了Connect的度量指标（KIP-196），新增了大量用于健康监测的度量指标（KIP-188），并提供了集群的GloabalTopicCount和GlobalPartitionCount度量指标（KIP-168）。</li>
<li>支持Java 9，实现更快的TLS和CRC32C，加快了加密速度，降低了计算开销。</li>
<li>调整了SASL认证模块的错误处理逻辑（KIP-152），原先的认证错误信息现在被清晰地记录到日志当中。</li>
<li>更好地支持磁盘容错（KIP-112），更优雅地处理磁盘错误，单个JBOD上的磁盘错误不会导致整个集群崩溃。</li>
<li>0.11.0版本中引入的幂等性生产者需要将max.in.flight.requests.per.connection参数设置为1，这对吞吐量造成了一定的限制。而在1.0.0版本里，这个参数最大可以被设置为5（KAFKA-5949），极大提升了吞吐量范围。</li>
</ul>

<h1 id="二kafka适合什么样的场景">二、Kafka适合什么样的场景?</h1>

<p>它可以用于两大类别的应用:</p>

<ul>
<li>构造实时流数据管道，它可以在系统或应用之间可靠地获取数据。 (相当于message queue)</li>
<li>构建实时流式应用程序，对这些流数据进行转换或者影响。 (就是流处理，通过kafka stream topic和topic之间内部进行变化)</li>
</ul>

<p><img src="https://img-blog.csdn.net/20180405095745402?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lqcDE5ODcxMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>



<h1 id="三kafka四个核心api">三、Kafka四个核心API</h1>

<ul>
<li>The Producer API 允许一个应用程序发布一串流式的数据到一个或者多个Kafka topic。</li>
<li>The Consumer API 允许一个应用程序订阅一个或多个 topic ，并且对发布给他们的流式数据进行处理。</li>
<li>The Streams API 允许一个应用程序作为一个流处理器，消费一个或者多个topic产生的输入流，然后生产一个输出流到一个或多个topic中去，在输入输出流中进行有效的转换。</li>
<li>The Connector API 允许构建并运行可重用的生产者或者消费者，将Kafka topics连接到已存在的应用程序或者数据系统。比如，连接到一个关系型数据库，捕捉表（table）的所有变更内容。 <br>
让我们首先深入了解下Kafka的核心概念:提供一串流式的记录— topic 。</li>
</ul>



<h1 id="四kafka相关概念">四、Kafka相关概念:</h1>

<p>Kafka作为一个集群，运行在一台或者多台服务器上.Kafka 通过 topic 对存储的流数据进行分类。每条记录中包含一个key，一个value和一个timestamp（时间戳）。</p>



<h2 id="41topic-和-日志">4.1、Topic 和 日志</h2>

<p>Topic 就是数据主题，是数据记录发布的地方,可以用来区分业务系统。Kafka中的Topics总是多订阅者模式，一个topic可以拥有一个或者多个消费者来订阅它的数据。对于每一个topic， Kafka集群都会维持一个分区日志，如下所示：</p>

<p><img src="https://img-blog.csdn.net/20180405100206597?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lqcDE5ODcxMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<p>每个分区都是有序且顺序不可变的记录集，并且不断地追加到结构化的commit log文件。分区中的每一个记录都会分配一个id号来表示顺序，我们称之为offset，offset用来唯一的标识分区中每一条记录。</p>

<p>Kafka 集群保留所有发布的记录—无论他们是否已被消费—并通过一个可配置的参数——保留期限来控制. 举个例子， 如果保留策略设置为2天，一条记录发布后两天内，可以随时被消费，两天过后这条记录会被抛弃并释放磁盘空间。Kafka的性能和数据大小无关，所以长时间存储数据没有什么问题.</p>

<p><img src="https://img-blog.csdn.net/20180405100313183?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lqcDE5ODcxMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<p>事实上，在每一个消费者中唯一保存的元数据是offset（偏移量）即消费在log中的位置.偏移量由消费者所控制:通常在读取记录后，消费者会以线性的方式增加偏移量，但是实际上，由于这个位置由消费者控制，所以消费者可以采用任何顺序来消费记录。例如，一个消费者可以重置到一个旧的偏移量，从而重新处理过去的数据；也可以跳过最近的记录，从”现在”开始消费。</p>

<p>这些细节说明Kafka 消费者是非常廉价的—消费者的增加和减少，对集群或者其他消费者没有多大的影响。比如，你可以使用命令行工具，对一些topic内容执行 tail操作，并不会影响已存在的消费者消费数据。</p>

<p>日志中的 partition（分区）有以下几个用途。第一，当日志大小超过了单台服务器的限制，允许日志进行扩展。每个单独的分区都必须受限于主机的文件限制，不过一个主题可能有多个分区，因此可以处理无限量的数据。第二，可以作为并行的单元集—关于这一点。</p>



<h2 id="42分布式">4.2、分布式</h2>

<p>日志的分区partition （分布）在Kafka集群的服务器上。每个服务器在处理数据和请求时，共享这些分区。每一个分区都会在已配置的服务器上进行备份，确保容错性.</p>

<p>每个分区都有一台 server 作为 “leader”，零台或者多台server作为 follwers 。leader server 处理一切对 partition （分区）的读写请求，而follwers只需被动的同步leader上的数据。当leader宕机了，followers 中的一台服务器会自动成为新的 leader。每台 server 都会成为某些分区的 leader 和某些分区的 follower，因此集群的负载是平衡的。</p>



<h2 id="43生产者">4.3、生产者</h2>

<p>生产者可以将数据发布到所选择的topic（主题）中。生产者负责将记录分配到topic的哪一个 partition（分区）中。可以使用循环的方式来简单地实现负载均衡，也可以根据某些语义分区函数(例如：记录中的key)来完成。</p>



<h2 id="44消费者">4.4、消费者</h2>

<p>消费者使用一个 消费组 名称来进行标识，发布到topic中的每条记录被分配给订阅消费组中的一个消费者实例.消费者实例可以分布在多个进程中或者多个机器上。如果所有的消费者实例在同一消费组中，消息记录会负载平衡到每一个消费者实例。如果所有的消费者实例在不同的消费组中，每条消息记录会广播到所有的消费者进程.</p>

<p><img src="https://img-blog.csdn.net/20180405100813486?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lqcDE5ODcxMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<p>如图，这个 Kafka 集群有两台 server 的，四个分区(p0-p3)和两个消费者组。消费组A有两个消费者，消费组B有四个消费者。通常情况下，每个 topic 都会有一些消费组，一个消费组对应一个”逻辑订阅者”。一个消费组由许多消费者实例组成，便于扩展和容错。这就是发布和订阅的概念，只不过订阅者是一组消费者而不是单个的进程。</p>

<p><strong>在Kafka中实现消费的方式是将日志中的分区划分到每一个消费者实例上，以便在任何时间，每个实例都是分区唯一的消费者</strong>。维护消费组中的消费关系由Kafka协议动态处理。如果新的实例加入组，他们将从组中其他成员处接管一些 partition 分区;如果一个实例消失，拥有的分区将被分发到剩余的实例。</p>

<p><strong>Kafka 只保证分区内的记录是有序的，而不保证主题中不同分区的顺序</strong>。每个 partition 分区按照key值排序足以满足大多数应用程序的需求。但如果你需要总记录在所有记录的上面，可使用仅有一个分区的主题来实现，这意味着每个消费者组只有一个消费者进程。</p>



<h1 id="五kafka保证">五、Kafka保证</h1>

<p>high-level Kafka给予以下保证:</p>

<ul>
<li>生产者发送到特定topic partition 的消息将按照发送的顺序处理。也就是说，如果记录M1和记录M2由相同的生产者发送，并先发送M1记录，那么M1的偏移比M2小，并在日志中较早出现。</li>
<li>一个消费者实例按照日志中的顺序查看记录。</li>
<li>对于具有N个副本的主题，我们最多容忍N-1个服务器故障，从而保证不会丢失任何提交到日志中的记录。</li>
</ul>



<h1 id="六kafka作为消息系统">六、Kafka作为消息系统</h1>

<p>Kafka streams的概念与传统的企业消息系统相比如何？</p>

<p>传统的消息系统有两个模块: 队列 和 发布-订阅。 在队列中，消费者池从server读取数据，每条记录被池子中的一个消费者消费; 在发布订阅中，记录被广播到所有的消费者。两者均有优缺点。 队列的优点在于它允许你将处理数据的过程分给多个消费者实例，使你可以扩展处理过程。 不好的是，队列不是多订阅者模式的—一旦一个进程读取了数据，数据就会被丢弃。 而发布-订阅系统允许你广播数据到多个进程，但是无法进行扩展处理，因为每条消息都会发送给所有的订阅者。</p>

<p>消费组在Kafka有两层概念。在队列中，消费组允许你将处理过程分发给一系列进程(消费组中的成员)。 在发布订阅中，Kafka允许你将消息广播给多个消费组。<strong>Kafka的优势在于每个topic都有以下特性—可以扩展处理并且允许多订阅者模式—不需要只选择其中一个.</strong></p>

<p>Kafka相比于传统消息队列还具有更严格的顺序保证</p>

<ul>
<li>传统队列在服务器上保存有序的记录，如果多个消费者消费队列中的数据， 服务器将按照存储顺序输出记录。虽然服务器按顺序输出记录，但是记录被异步传递给消费者， 因此记录可能会无序的到达不同的消费者。<strong>这意味着在并行消耗的情况下， 记录的顺序是丢失的。因此消息系统通常使用“唯一消费者”的概念</strong>，即只让一个进程从队列中消费， <strong>但这就意味着不能够并行地处理数据。</strong></li>
<li>Kafka 设计的更好。topic中的partition是一个并行的概念。Kafka能够为一个消费者池提供顺序保证和负载平衡，是通过将topic中的partition分配给消费者组中的消费者来实现的，以便每个分区由消费组中的一个消费者消耗。通过这样，<strong>我们能够确保消费者是该分区的唯一读者，并按顺序消费数据。 众多分区保证了多个消费者实例间的负载均衡</strong>。<strong>但请注意，消费者组中的消费者实例个数不能超过分区的数量</strong>。</li>
</ul>



<h1 id="七kafka-作为存储系统">七、Kafka 作为存储系统</h1>

<p>许多消息队列可以发布消息，除了消费消息之外还可以充当中间数据的存储系统。那么Kafka作为一个优秀的存储系统有什么不同呢?</p>

<p>数据写入Kafka后被写到磁盘，并且进行备份以便容错。直到完全备份，Kafka才让生产者认为完成写入，即使写入失败Kafka也会确保继续写入。Kafka使用磁盘结构，<strong>具有很好的扩展性—50kb和50TB的数据在server上表现一致</strong>。可以存储大量数据，并且可通过客户端控制它读取数据的位置，<strong>您可认为Kafka是一种高性能、低延迟、具备日志存储、备份和传播功能的分布式文件系统。</strong></p>



<h1 id="八kafka用做流处理">八、Kafka用做流处理</h1>

<p><strong>Kafka 流处理不仅仅用来读写和存储流式数据，它最终的目的是为了能够进行实时的流处理。在Kafka中，流处理器不断地从输入的topic获取流数据，处理数据后，再不断生产流数据到输出的topic中去。</strong></p>

<p>例如，零售应用程序可能会接收销售和出货的输入流，经过价格调整计算后，再输出一串流式数据。简单的数据处理可以直接用生产者和消费者的API。对于复杂的数据变换，Kafka提供了Streams API。 Stream API 允许应用做一些复杂的处理，比如将流数据聚合或者join。这一功能有助于解决以下这种应用程序所面临的问题：处理无序数据，当消费端代码变更后重新处理输入，执行有状态计算等。</p>

<p>Streams API建立在Kafka的核心之上：它使用Producer和Consumer API作为输入，使用Kafka进行有状态的存储， 并在流处理器实例之间使用相同的消费组机制来实现容错。</p>



<h1 id="九批处理">九、批处理</h1>

<p>将消息、存储和流处理结合起来，使得Kafka看上去不一般，但这是它作为流平台所备的，像HDFS这样的分布式文件系统可以存储用于批处理的静态文件。 一个系统如果可以存储和处理历史数据是非常不错的。</p>

<p>传统的企业消息系统允许处理订阅后到达的数据。以这种方式来构建应用程序，并用它来处理即将到达的数据。Kafka结合了上面所说的两种特性。作为一个流应用程序平台或者流数据管道，这两个特性，对于Kafka 来说是至关重要的。</p>

<p>通过组合存储和低延迟订阅，流式应用程序可以同样的方式处理过去和未来的数据。 <strong>一个单一的应用程序可以处理历史记录的数据，并且可以持续不断地处理以后到达的数据，而不是在到达最后一条记录时结束进程。 这是一个广泛的流处理概念，其中包含批处理以及消息驱动应用程序</strong></p>

<p>同样，作为流数据管道，能够订阅实时事件使得Kafk具有非常低的延迟; 同时Kafka还具有可靠存储数据的特性，可用来存储重要的支付数据， 或者与离线系统进行交互，系统可间歇性地加载数据，也可在停机维护后再次加载数据。流处理功能使得数据可以在到达时转换数据。</p>



<h1 id="十参考">十、参考</h1>

<blockquote>
  <p><a href="https://kafka.apache.org/downloads" rel="nofollow">https://kafka.apache.org/downloads</a> <br>
  <a href="https://kafka.apache.org/" rel="nofollow">https://kafka.apache.org/</a> <br>
  <a href="http://www.infoq.com/cn/news/2017/11/Kafka-release-1.0.0" rel="nofollow">http://www.infoq.com/cn/news/2017/11/Kafka-release-1.0.0</a></p>
</blockquote>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>