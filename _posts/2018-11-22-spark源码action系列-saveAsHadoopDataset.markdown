---
layout:     post
title:      spark源码action系列-saveAsHadoopDataset
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/u014393917/article/details/50607567				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<h3>RDD.saveAsHadoopDataset</h3>
<p>这个功能是<span style="font-family:'Times New Roman';">spark</span><span style="font-family:SimSun;">中的</span><span style="font-family:'Times New Roman';">saveAsTextFile,saveASHadoopFile</span><span style="font-family:SimSun;">的基础实现</span><span style="font-family:'Times New Roman';">.</span></p>
<p>这个<span style="font-family:'Times New Roman';">action</span><span style="font-family:SimSun;">用于把</span><span style="font-family:'Times New Roman';">task</span><span style="font-family:SimSun;">中的数据通过指定的</span><span style="font-family:'Times New Roman';">output format</span><span style="font-family:SimSun;">写入到</span><span style="font-family:'Times New Roman';">hadoop</span><span style="font-family:SimSun;">的实现接口中</span><span style="font-family:'Times New Roman';">,</span></p>
<p>由<span style="font-family:'Times New Roman';">PairRDDFunctions</span><span style="font-family:SimSun;">类进行实现</span><span style="font-family:'Times New Roman';">.</span></p>
<p><span style="color:#33FF33;">执行前的准备:</span></p>
<p>得到<span style="font-family:'Times New Roman';">hadoopConfiguration</span><span style="font-family:SimSun;">的实例</span><span style="font-family:'Times New Roman';">,</span><span style="font-family:SimSun;">取出</span><span style="font-family:'Times New Roman';">OutputFormat</span><span style="font-family:SimSun;">的实现类</span><span style="font-family:'Times New Roman';">,key,value</span><span style="font-family:SimSun;">的类</span><span style="font-family:'Times New Roman';">.</span></p>
<p style="background:rgb(255,255,255);"><span style="background:rgb(228,228,255);">val</span><span style="background:rgb(255,255,255);"> </span><span style="color:#000000;background:rgb(255,255,255);">hadoopConf = </span><span style="color:#000000;background:rgb(228,228,255);">conf</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="background:rgb(255,255,255);">val </span><span style="color:#000000;background:rgb(255,255,255);">outputFormatInstance = hadoopConf.getOutputFormat</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="background:rgb(255,255,255);">val </span><span style="color:#000000;background:rgb(255,255,255);">keyClass = hadoopConf.getOutputKeyClass</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="background:rgb(255,255,255);">val </span><span style="color:#000000;background:rgb(255,255,255);">valueClass = hadoopConf.getOutputValueClass</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="background:rgb(255,255,255);">.....................................</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">SparkHadoopUtil.</span><span style="color:#000000;background:rgb(255,255,255);">get</span><span style="color:#000000;background:rgb(255,255,255);">.addCredentials(hadoopConf)</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">logDebug(</span><span style="background:rgb(255,255,255);">"Saving as hadoop file of type (" </span><span style="color:#000000;background:rgb(255,255,255);">+ keyClass.getSimpleName + </span><span style="background:rgb(255,255,255);">", " </span><span style="color:#000000;background:rgb(255,255,255);">+</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">  valueClass.getSimpleName + </span><span style="background:rgb(255,255,255);">")"</span><span style="color:#000000;background:rgb(255,255,255);">)</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="background:rgb(255,255,255);">if </span><span style="color:#000000;background:rgb(255,255,255);">(isOutputSpecValidationEnabled) {</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">  </span><span style="color:#808080;background:rgb(255,255,255);">// FileOutputFormat ignores the filesystem parameter</span><span style="color:#808080;background:rgb(255,255,255);"><br></span><span style="color:#808080;background:rgb(255,255,255);">  </span><span style="background:rgb(255,255,255);">val </span><span style="color:#000000;background:rgb(255,255,255);">ignoredFs = FileSystem.</span><span style="color:#000000;background:rgb(255,255,255);">get</span><span style="color:#000000;background:rgb(255,255,255);">(hadoopConf)</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">  hadoopConf.getOutputFormat.checkOutputSpecs(ignoredFs</span><span style="color:#cc7832;background:rgb(255,255,255);">, </span><span style="color:#000000;background:rgb(255,255,255);">hadoopConf)</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">}</span><span style="color:#000000;background:rgb(255,255,255);"><br></span></p>
<p style="background:rgb(255,255,255);"><span style="color:#000000;background:rgb(255,255,255);">生成一个用于执行写入操作的writer实例,这个实例中包含有向hadoop写入的recordWriter.</span></p>
<p style="background:rgb(255,255,255);"><span style="color:#000000;background:rgb(255,255,255);">在这里recordWriter实例还没有具体的生成.</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="background:rgb(255,255,255);">val </span><span style="color:#000000;background:rgb(255,255,255);">writer = </span><span style="background:rgb(255,255,255);">new </span><span style="color:#000000;background:rgb(255,255,255);">SparkHadoopWriter(hadoopConf)</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">writer.preSetup()</span></p>
<p> </p>
<p><span style="color:#33FF33;">Task<span style="font-family:SimSun;">的执行的</span><span style="font-family:'Times New Roman';">function</span><span style="font-family:SimSun;">的定义</span>:</span></p>
<p>这里生成的<span style="font-family:'Times New Roman';">writeToFile</span><span style="font-family:SimSun;">是一个需要在</span><span style="font-family:'Times New Roman';">task</span><span style="font-family:SimSun;">中执行的</span><span style="font-family:'Times New Roman';">function</span><span style="font-family:SimSun;">的定义</span><span style="font-family:'Times New Roman';">.</span></p>
<p style="background:rgb(255,255,255);"><span style="background:rgb(255,255,255);">val </span><span style="color:#000000;background:rgb(255,255,255);">writeToFile = (context: TaskContext</span><span style="color:#cc7832;background:rgb(255,255,255);">, </span><span style="color:#000000;background:rgb(255,255,255);">iter: </span><span style="color:#20999d;background:rgb(255,255,255);">Iterator</span><span style="color:#000000;background:rgb(255,255,255);">[(</span><span style="color:#20999d;background:rgb(255,255,255);">K</span><span style="color:#cc7832;background:rgb(255,255,255);">, </span><span style="color:#20999d;background:rgb(255,255,255);">V</span><span style="color:#000000;background:rgb(255,255,255);">)]) =&gt; {</span></p>
<p style="background:rgb(255,255,255);"><span style="color:#000000;background:rgb(255,255,255);">1,先得到执行尝试的id.</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">  </span><span style="color:#808080;background:rgb(255,255,255);">// Hadoop wants a 32-bit task attempt ID, so if ours is bigger than </span></p>
<p style="background:rgb(255,255,255);"><span style="color:#808080;background:rgb(255,255,255);">       Int.MaxValue, roll it</span><span style="color:#808080;background:rgb(255,255,255);"><br></span><span style="color:#808080;background:rgb(255,255,255);">  // around by taking a mod. We expect that no task will be attempted 2 billion times.</span><span style="color:#808080;background:rgb(255,255,255);"><br></span><span style="color:#808080;background:rgb(255,255,255);">  </span><span style="background:rgb(255,255,255);">val </span><span style="color:#000000;background:rgb(255,255,255);">taskAttemptId = (context.taskAttemptId % </span><span style="color:#cc7832;background:rgb(255,255,255);">Int</span><span style="color:#000000;background:rgb(255,255,255);">.</span><span style="background:rgb(255,255,255);">MaxValue</span><span style="color:#000000;background:rgb(255,255,255);">).toInt</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">2,生成一个用于写入的metrics的实例.</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">  </span><span style="background:rgb(255,255,255);">val </span><span style="color:#000000;background:rgb(255,255,255);">(outputMetrics</span><span style="color:#cc7832;background:rgb(255,255,255);">, </span><span style="color:#000000;background:rgb(255,255,255);">bytesWrittenCallback) = initHadoopOutputMetrics(context)</span><span style="color:#000000;background:rgb(255,255,255);"><br></span></p>
<p style="background:rgb(255,255,255);"><span style="color:#000000;background:rgb(255,255,255);">3,根据stageId,partition,attempt对writer进行初始化,主要是对task对应的jobId,taskid进行初始化操作.</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">  writer.setup(context.stageId</span><span style="color:#cc7832;background:rgb(255,255,255);">, </span><span style="color:#000000;background:rgb(255,255,255);">context.partitionId</span><span style="color:#cc7832;background:rgb(255,255,255);">, </span><span style="color:#000000;background:rgb(255,255,255);">taskAttemptId)</span></p>
<p style="background:rgb(255,255,255);"><span style="color:#000000;background:rgb(255,255,255);">4,这里(如果是对hdfs文件进行操作,生成对应此task的输出文件的路径),通过outputFormat生成对应的RecordWriter的实例.</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">  writer.open()</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">  </span><span style="background:rgb(255,255,255);">var </span><span style="color:#000000;background:rgb(255,255,255);">recordsWritten = </span><span style="background:rgb(255,255,255);">0L</span><span style="background:rgb(255,255,255);"><br></span><span style="background:rgb(255,255,255);"><br></span><span style="background:rgb(255,255,255);">  </span><span style="color:#000000;background:rgb(255,255,255);">Utils.</span><span style="color:#000000;background:rgb(255,255,255);">tryWithSafeFinally </span><span style="color:#000000;background:rgb(255,255,255);">{</span></p>
<p style="background:rgb(255,255,255);"><span style="color:#000000;background:rgb(255,255,255);">5,这里通过对partition中的数据进行迭代,并通过recordWriter写入数据,记录metrics</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">    </span><span style="background:rgb(255,255,255);">while </span><span style="color:#000000;background:rgb(255,255,255);">(iter.hasNext) {</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">      </span><span style="background:rgb(255,255,255);">val </span><span style="color:#000000;background:rgb(255,255,255);">record = iter.next()</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">      writer.write(record._1.asInstanceOf[AnyRef]</span><span style="color:#cc7832;background:rgb(255,255,255);">, </span><span style="color:#000000;background:rgb(255,255,255);">record._2.asInstanceOf[AnyRef])</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">      </span><span style="color:#808080;background:rgb(255,255,255);">// Update bytes written metric every few records</span><span style="color:#808080;background:rgb(255,255,255);"><br></span><span style="color:#808080;background:rgb(255,255,255);">      </span><span style="color:#000000;background:rgb(255,255,255);">maybeUpdateOutputMetrics(bytesWrittenCallback</span><span style="color:#cc7832;background:rgb(255,255,255);">, </span><span style="color:#000000;background:rgb(255,255,255);">outputMetrics</span><span style="color:#cc7832;background:rgb(255,255,255);">, </span><span style="color:#000000;background:rgb(255,255,255);">recordsWritten)</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">      recordsWritten += </span><span style="background:rgb(255,255,255);">1</span><span style="background:rgb(255,255,255);"><br></span><span style="background:rgb(255,255,255);">    </span><span style="color:#000000;background:rgb(255,255,255);">}</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">  } {</span></p>
<p style="background:rgb(255,255,255);"><span style="color:#000000;background:rgb(255,255,255);">执行对iterator的写入操作后,关闭recordWriter的实例,也就是调用其关闭函数.</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">    writer.close()</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">  }</span></p>
<p style="background:rgb(255,255,255);"><span style="color:#000000;background:rgb(255,255,255);">根据</span><span style="background:rgb(255,255,255);">mapred.output.committer.class</span><span style="color:#000000;background:rgb(255,255,255);">配置的</span><span style="color:#000000;background:rgb(228,228,255);">OutputCommitter</span><span style="color:#000000;background:rgb(255,255,255);">实现,执行commitTask操作.</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">  writer.commit()</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">  bytesWrittenCallback.foreach { fn =&gt; outputMetrics.setBytesWritten(fn()) }</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">  outputMetrics.setRecordsWritten(recordsWritten)</span><span style="color:#000000;background:rgb(255,255,255);"><br></span><span style="color:#000000;background:rgb(255,255,255);">}</span></p>
<p style="background:rgb(255,255,255);"><span style="color:#000000;background:rgb(255,255,255);"> </span></p>
<p style="background:rgb(255,255,255);"><span style="color:#000000;background:rgb(255,255,255);">这里通过runJob并把上面生成的函数传进去,执行task</span></p>
<p style="background:rgb(255,255,255);"><span style="color:#000000;background:rgb(255,255,255);">self.context.runJob(self</span><span style="color:#cc7832;background:rgb(255,255,255);">, </span><span style="color:#000000;background:rgb(255,255,255);">writeToFile)</span></p>
<p style="background:rgb(255,255,255);"><span style="color:#000000;background:rgb(255,255,255);"> </span></p>
<p style="background:rgb(255,255,255);"><span style="color:#33FF33;background:rgb(255,255,255);">任务结束后的处理</span><span style="color:#33FF33;background:rgb(255,255,255);">:</span></p>
<p style="background:rgb(255,255,255);"><span style="color:#000000;background:rgb(255,255,255);">根据</span><span style="background:rgb(255,255,255);">mapred.output.committer.class</span><span style="color:#000000;background:rgb(255,255,255);">配置的</span><span style="color:#000000;background:rgb(228,228,255);">OutputCommitter</span><span style="color:#000000;background:rgb(255,255,255);">实现,执行commitJob操作.</span></p>
<p style="background:rgb(255,255,255);"><span style="color:#000000;background:rgb(228,228,255);">writer</span><span style="color:#000000;background:rgb(255,255,255);">.commitJob()</span></p>
            </div>
                </div>