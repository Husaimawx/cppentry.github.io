---
layout:     post
title:      Flume(日志收集系统)简介
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p><strong>一、Flume简介</strong></p>

<p>　　<strong>flume是一个分布式、可靠、高可用的海量日志采集、聚合和传输的系统</strong>。支持在日志系统中定制各类数据发送方，用于收集数据 ; 同时，Flume提供对数据进行简单处理，并写到各种数据接受方(比如文本、HDFS、Hbase等)的能力 。</p>

<p>　　<strong>flume的数据流由事件(Event)贯穿始终</strong>。事件是Flume的基本数据单位，它携带日志数据(字节数组形式)并且携带有头信息，这些Event由Agent外部的Source生成，<strong><span style="color:#f33b45;"><em>当Source捕获事件后会进行特定的格式化，然后Source会把事件推入(单个或多个)Channel中。你可以把Channel看作是一个缓冲区，它将保存事件直到Sink处理完该事件。Sink负责持久化日志或者把事件推向另一个Source。</em></span></strong></p>

<p>　　(1)flume的可靠性 </p>

<p>　　当节点出现故障时，日志能够被传送到其他节点上而不会丢失。Flume提供了三种级别的可靠性保障，从强到弱依次分别为：end-to-end（收到数据agent首先将event写到磁盘上，当数据传送成功后，再删除；如果数据发送失败，可以重新发送），Store on failure（这也是scribe采用的策略，当数据接收方crash时，将数据写到本地，待恢复后，继续发送），Besteffort（数据发送到接收方后，不会进行确认）。</p>

<p>　　(2)flume的可恢复性</p>

<p>　　还是靠Channel。推荐使用FileChannel，事件持久化在本地文件系统里(性能较差)。</p>

<p><strong>二、Flume的一些核心概念</strong></p>

<p>　　Client：Client生产数据，运行在一个独立的线程。</p>

<p>　　Event： 一个数据单元，消息头和消息体组成。（Events可以是日志记录、 avro 对象等）</p>

<p>　　Flow： Event从源点到达目的点的迁移的抽象。</p>

<p>　　Agent： 一个独立的Flume进程，包含组件Source、 Channel、 Sink。（Agent使用JVM 运行Flume。每台机器运行一个agent，但是可以在一个agent中包含多个sources和sinks）</p>

<p>　　Source： 数据收集组件。（source从Client收集数据，传递给Channel）</p>

<p>　　Channel： 中转Event的一个临时存储，保存由Source组件传过来的Event（Channel连接 sources 和 sinks ，这个有点像一个队列）</p>

<p>　　Sink： 从Channel中读取并移除Event， 将Event传递到FlowPipeline中的下一个Agent（如果有的话）（Sink从Channel收集数据，运行在一个独立线程）</p>

<p>2.1、Agent结构　　</p>

<p>　　<strong>Flume 运行的核心是 Agent。Flume以agent为最小的独立运行单位</strong>。一个agent就是一个JVM。它是一个完整的数据收集工具，含有三个核心组件，分别是 source、 channel、 sink。通过这些组件， Event 可以从一个地方流向另一个地方，如下图所示。</p>

<p><img alt="" class="has" height="239" src="https://img-blog.csdnimg.cn/2018110810471913.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6ejEyNzMzMzA5Mg==,size_16,color_FFFFFF,t_70" width="624"></p>

<p>2.2、source</p>

<p>　　Source是数据的收集端，负责将数据捕获后进行特殊的格式化，将数据封装到事件（event）里，然后将事件推入Channel中。 Flume提供了很多内置的Source， 支持 Avro， log4j， syslog 和 http post(body为json格式)。可以让应用程序同已有的Source直接打交道，如AvroSource，SyslogTcpSource。 如果内置的Source无法满足需要， Flume还支持自定义Source。</p>

<p><img alt="" class="has" height="197" src="https://img-blog.csdnimg.cn/20181108104739965.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6ejEyNzMzMzA5Mg==,size_16,color_FFFFFF,t_70" width="628"></p>

<p>　　source类型：　</p>

<p><img alt="" class="has" height="486" src="https://img-blog.csdnimg.cn/20181108104754481.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6ejEyNzMzMzA5Mg==,size_16,color_FFFFFF,t_70" width="632"></p>

<p>2.3、Channel</p>

<p>　　Channel是连接Source和Sink的组件，大家可以将它看做一个数据的缓冲区（数据队列），它可以将事件暂存到内存中也可以持久化到本地磁盘上， 直到Sink处理完该事件。介绍<strong>两个较为常用的Channel， MemoryChannel和FileChannel</strong>。</p>

<p>　　Channel类型：</p>

<p><img alt="" class="has" height="312" src="https://img-blog.csdnimg.cn/20181108104829466.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6ejEyNzMzMzA5Mg==,size_16,color_FFFFFF,t_70" width="659"></p>

<p>2.4、Sink</p>

<p>　　Sink从Channel中取出事件，然后将数据发到别处，可以向文件系统、数据库、 hadoop存数据， 也可以是其他agent的Source。在日志数据较少时，可以将数据存储在文件系统中，并且设定一定的时间间隔保存数据。</p>

<p><img alt="" class="has" height="168" src="https://img-blog.csdnimg.cn/20181108104848169.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6ejEyNzMzMzA5Mg==,size_16,color_FFFFFF,t_70" width="522"></p>

<p>　　Sink类型：　</p>

<p><img alt="" class="has" height="380" src="https://img-blog.csdnimg.cn/20181108104904528.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6ejEyNzMzMzA5Mg==,size_16,color_FFFFFF,t_70" width="485"></p>

<p><strong>三、Flume拦截器、数据流以及可靠性</strong></p>

<p>3.1、Flume拦截器</p>

<p>　　当我们需要对数据进行过滤时，除了我们在Source、Channel和Sink进行代码修改之外， Flume为我们提供了拦截器，拦截器也是chain形式的。</p>

<p>　　拦截器的位置在Source和Channel之间，当我们为Source指定拦截器后，我们在拦截器中会得到event，根据需求我们可以对event进行保留还是抛弃，抛弃的数据不会进入Channel中。</p>

<p><img alt="" class="has" height="145" src="https://img-blog.csdnimg.cn/20181108105100880.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6ejEyNzMzMzA5Mg==,size_16,color_FFFFFF,t_70" width="549"></p>

<p>3.2、Flume数据流</p>

<p>　　1）Flume 的核心是把数据从数据源收集过来，再送到目的地。为了保证输送一定成功，在送到目的地之前，会先缓存数据，待数据真正到达目的地后，删除自己缓存的数据。</p>

<p>　　2） Flume 传输的数据的基本单位是 Event，如果是文本文件，通常是一行记录，这也是事务的基本单位。 Event 从 Source，流向 Channel，再到 Sink，本身为一个 byte 数组，并可携带 headers 信息。 Event 代表着一个数据流的最小完整单元，从外部数据源来，向外部的目的地去。</p>

<p><img alt="" class="has" height="321" src="https://img-blog.csdnimg.cn/20181108105121203.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6ejEyNzMzMzA5Mg==,size_16,color_FFFFFF,t_70" width="567"></p>

<p>　　值得注意的是，Flume提供了大量内置的Source、Channel和Sink类型。不同类型的Source,Channel和Sink可以自由组合。组合方式基于用户设置的配置文件，非常灵活。</p>

<p>　　比如：Channel可以把事件暂存在内存里，也可以持久化到本地硬盘上。Sink可以把日志写入HDFS, HBase，甚至是另外一个Source等等。Flume支持用户建立多级流，也就是说，多个agent可以协同工作，并且支持Fan-in、Fan-out、Contextual Routing、Backup Routes，这也正是Flume强大之处。如下图所示：　</p>

<p><img alt="" class="has" height="314" src="https://img-blog.csdnimg.cn/2018110810514566.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6ejEyNzMzMzA5Mg==,size_16,color_FFFFFF,t_70" width="570"></p>

<p>3.3、Flume可靠性</p>

<p>　　Flume 使用事务性的方式保证传送Event整个过程的可靠性。 Sink 必须在Event 被存入 Channel 后，或者，已经被传达到下一站agent里，又或者，已经被存入外部数据目的地之后，才能把 Event 从 Channel 中 remove 掉。这样数据流里的 event 无论是在一个 agent 里还是多个 agent 之间流转，都能保证可靠，因为以上的事务保证了 event 会被成功存储起来。比如 Flume支持在本地保存一份文件 channel 作为备份，而memory channel 将event存在内存 queue 里，速度快，但丢失的话无法恢复。</p>

<p><strong>四、Flume使用场景</strong></p>

<p>　　Flume在英文中的意思是水道， 但Flume更像可以随意组装的消防水管，下面根据官方文档，展示几种Flow。</p>

<p>4.1、多个agent顺序连接</p>

<p><img alt="" class="has" height="154" src="https://img-blog.csdnimg.cn/20181108105243152.png" width="701"></p>

<p>　　可以将多个Agent顺序连接起来，将最初的数据源经过收集，存储到最终的存储系统中。这是最简单的情况，一般情况下，应该控制这种顺序连接的Agent 的数量，因为数据流经的路径变长了，如果不考虑failover的话，出现故障将影响整个Flow上的Agent收集服务。 </p>

<p>4.2、多个Agent的数据汇聚到同一个Agent </p>

<p><img alt="" class="has" height="370" src="https://img-blog.csdnimg.cn/20181108105308369.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6ejEyNzMzMzA5Mg==,size_16,color_FFFFFF,t_70" width="739"></p>

<p>　　这种情况应用的场景比较多，比如要收集Web网站的用户行为日志， Web网站为了可用性使用的负载集群模式，每个节点都产生用户行为日志，可以为每个节点都配置一个Agent来单独收集日志数据，然后多个Agent将数据最终汇聚到一个用来存储数据存储系统，如HDFS上。</p>

<p>4.3、多级流</p>

<p>　　Flume还支持多级流，什么多级流？结合在云开发中的应用来举个例子，当syslog， java， nginx、 tomcat等混合在一起的日志流开始流入一个agent后，可以agent中将混杂的日志流分开，然后给每种日志建立一个自己的传输通道。　</p>

<p><img alt="" class="has" height="325" src="https://img-blog.csdnimg.cn/20181108105331348.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6ejEyNzMzMzA5Mg==,size_16,color_FFFFFF,t_70" width="603"></p>

<p> </p>

<p>参考文章：<a href="https://www.cnblogs.com/zhangyinhua/p/7803486.html" rel="nofollow">https://www.cnblogs.com/zhangyinhua/p/7803486.html</a></p>

<p> </p>            </div>
                </div>