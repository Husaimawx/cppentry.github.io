---
layout:     post
title:      Hadoop 学习笔记一 基础知识及常用命令
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：（谢厂节的博客）博主文章绝大部分非原创，转载望留链接。					https://blog.csdn.net/xundh/article/details/46572183				</div>
								            <div id="content_views" class="markdown_views prism-tomorrow-night">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>今天开始对Hadoop进行系统化的学习。此博文系列将会记录我的学习过程。</p>



<h1 id="了解hadoop">了解Hadoop</h1>



<h2 id="简介">简介</h2>

<p> Hadoop目前属于Apache基金会，是针对海量数据处理的理想工具。我的学习教材主要是Hadoop权威指南（中文版）。 <br>
 Hadoop起源于Nutch，在Yahoo的帮助下，Nutch的分布式运算这部分被独立出来，命名为Hadoop。Hadoop克隆了Google运行系统的主要框架，包括文件系统HDFS、计算架构MapReduce及结构化数据处理的HBase等。 <br>
    Hadoop最核心的设计就是HDFS和MapReduce <br>
    Hadoop的知识体系： <br>
    <a href="http://lib.csdn.net/base/20/structure" rel="nofollow">http://lib.csdn.net/base/20/structure</a> <br>
Hadoop生态： <br>
<img src="https://img-blog.csdn.net/20170416200230139?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHVuZGg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>hadoop文档地址： <br>
<a href="http://hadoop.apache.org/docs/r1.0.4/cn/index.html" rel="nofollow">http://hadoop.apache.org/docs/r1.0.4/cn/index.html</a></p>



<h2 id="工作原理">工作原理</h2>

<p> 海量数据处理的一重要问题是当前数据访问速度比较慢，一个1T的硬盘要读取整体磁盘花费的时间可能需要2个半小时以上。为了提高访问速度，一个有效的方式是并行访问多块硬盘，让数据冗余放置。要解决的问题是：</p>

<ul>
<li>问题一、硬件故障：解决方法，复制冗余放置数据。</li>
<li><p>问题二、数据合并</p>

<ul><li>海量数据存储 HDFS实现</li>
<li>数据分析由MapReduce实现</li>
<li>非结构化数据收集处理——Fuse、WebDAV、Chukwa、Flume、Scribe。</li>
<li>数据导入HDFS中，RDBSM也可以加入到HDFS——HHO、Sqoop。</li>
<li>数据处理还可以使用Pig Hive Jaql。</li>
<li>让数据可见——Drilldown、Intellicus。</li>
<li>用高级语言管理你的任务流——Oozie、Cascading。</li>
<li>Hadoop自己监控管理工具——Hue、Karmasphere、Eclipse plugin、Cacti、Ganglia。</li>
<li>数据序列化处理与任务调度——Avro、ZooKeeper。</li>
<li>构建在Hadoop上层的服务——Mahout、Elastic map reduce。</li>
<li>OLTP存储系统——Hbase。</li>
<li>基于Hadoop的实时分析——Impala。</li></ul></li>
</ul>



<h2 id="关系型数据库与mapreduce比较">关系型数据库与MapReduce比较：</h2>

<table>
<thead>
<tr>
  <th align="center">项目</th>
  <th align="center">关系型数据库</th>
  <th align="center">MapReduce</th>
</tr>
</thead>
<tbody><tr>
  <td align="center">数据大小</td>
  <td align="center">GB</td>
  <td align="center">PB</td>
</tr>
<tr>
  <td align="center">访问</td>
  <td align="center">交互型和批处理</td>
  <td align="center">批处理</td>
</tr>
<tr>
  <td align="center">更新</td>
  <td align="center">多次读写</td>
  <td align="center">一次写入多次读取</td>
</tr>
<tr>
  <td align="center">结构</td>
  <td align="center">静态模式</td>
  <td align="center">动态模式</td>
</tr>
<tr>
  <td align="center">集成度</td>
  <td align="center">高</td>
  <td align="center">低</td>
</tr>
<tr>
  <td align="center">伸缩性</td>
  <td align="center">非线性</td>
  <td align="center">线性</td>
</tr>
<tr>
  <td align="center">结构化数据数量</td>
  <td align="center">结构化数据</td>
  <td align="center">可以有效处理大结构化数据</td>
</tr>
</tbody></table>




<h2 id="hadoop常用项目">Hadoop常用项目</h2>

<ul>
<li>Hive 基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整 SQL 查询功能，可以将SQL语句转换为MapReduce任务进行运行。</li>
<li>Pig 基于Hadoop的大规模数据分析平台。</li>
<li>Mahout 提供一些可扩展的机器学习领域经典算法的实现。</li>
<li>Flume Cloudera提供的一个高可用的、高可靠的、分布式的海量日志采集、聚合、传输的系统。</li>
<li>Sqoop 将Hadoop和关系型数据库中的数据相互转移的工具，可以将关系型数据库中的数据导入Hadoop的HDFS中。</li>
<li>Oozie JavaWeb应用程序，运行Tomcat中，并使用数据库来存储工作流。</li>
<li>ZooKeeper 针对大型分布式系统的可靠协调系统。</li>
<li>Impala 采用与Hive相同的元数据、SQL语法、ODBC驱动程序和用户接口。</li>
</ul>



<h1 id="hadoop安装方式">Hadoop安装方式</h1>

<ul>
<li>单机模式：安装简单</li>
<li>伪分布式模式 ：单节点上同时启动NameNode、DataNode、JobTracker、TaskTracker、Secondary Namenode等5个进程 ， 模拟分布式运行的各个节点。</li>
<li>完全分布式模式</li>
</ul>



<h1 id="常用命令">常用命令</h1>

<p><strong>格式化namenode</strong></p>



<pre class="prettyprint"><code class=" hljs rsl">hdfs namenode -<span class="hljs-built_in">format</span></code></pre>

<p><strong>*列出文件</strong></p>



<pre class="prettyprint"><code class=" hljs mel">hdfs dfs -<span class="hljs-keyword">ls</span> /</code></pre>

<p><strong>修改hdfs权限</strong></p>



<pre class="prettyprint"><code class=" hljs lasso">hdfs dfs <span class="hljs-attribute">-chmod</span> <span class="hljs-attribute">-R</span> <span class="hljs-number">755</span> <span class="hljs-subst">/</span></code></pre>

<p><strong>修改所有者</strong></p>



<pre class="prettyprint"><code class=" hljs lasso">hdfs dfs <span class="hljs-attribute">-chown</span> <span class="hljs-attribute">-R</span> larry <span class="hljs-subst">/</span></code></pre>

<p><strong>解除安全模式</strong></p>



<pre class="prettyprint"><code class=" hljs lasso">hdfs dfsadmin <span class="hljs-attribute">-safemode</span> leave</code></pre>

<p><strong>改变文件所属组</strong></p>



<pre class="prettyprint"><code class=" hljs lasso">hdfs dfs <span class="hljs-attribute">-chgrp</span> <span class="hljs-preprocessor">[</span><span class="hljs-attribute">-R</span><span class="hljs-preprocessor">]</span><span class="hljs-markup"> GROUP URI</span></code></pre>

<p>这里也记录了一部分命令： <br>
<a href="http://blog.csdn.net/xundh/article/details/50905100#t30" rel="nofollow">http://blog.csdn.net/xundh/article/details/50905100#t30</a></p>

<h1 id="hadoop-安全问题">Hadoop 安全问题</h1>

<p>认证优先级</p>

<p><strong>user获取</strong> <br>
优先从kerberos获取（kerberos模式）； <br>
从系统HADOOP_USER_NAME变量获取； <br>
从java属性HADOOP_USER_NAME获取； <br>
获取操作系统当前用户 <br>
<strong>group获取</strong> <br>
从定义的group映射关系获取hadoop.user.group.static.mapping.overrides； <br>
从配置的group映射 类获取（hadoop.security.group.mapping）； <br>
从系统groups user获取</p>

<p>如果出现： <br>
<img src="https://img-blog.csdn.net/20170503095041564?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHVuZGg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
Access denied for user hadoop.Superuser privilege is required <br>
这时可以看看</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-variable">$HADOOP_USER_NAME</span>
vi ~/bash_profile
</code></pre>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-keyword">export</span> HADOOP_USER_NAME=root</code></pre>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">source</span> ~/bash_profile</code></pre>

<p>这样就把当前用户切换为root了。</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>