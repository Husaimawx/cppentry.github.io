---
layout:     post
title:      hadoop  集群安装与部署（大数据系列）
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/qq_18377515/article/details/82560167				</div>
								            <div id="content_views" class="markdown_views prism-dracula">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p></p><div class="toc"><h3>文章目录</h3><ul><li><a href="#_1" rel="nofollow">什么是大数据</a></li><ul><li><a href="#_2" rel="nofollow">基本概念</a></li><li><a href="#_38" rel="nofollow">大数据在现实生活中的具体应用</a></li></ul><li><a href="#hadoop_49" rel="nofollow">什么是hadoop</a></li><li><a href="#hdfs_57" rel="nofollow">hdfs整体运行机制</a></li><li><a href="#hdfs_89" rel="nofollow">搭建hdfs分布式集群</a></li><ul><li><a href="#hdfs_90" rel="nofollow">hdfs集群组成结构：</a></li><li><a href="#hdfs_93" rel="nofollow">安装hdfs集群的具体步骤：</a></li></ul><li><a href="#hdfs_168" rel="nofollow">安装hdfs集群</a></li><ul><li><a href="#hdfs_291" rel="nofollow">hdfs客户端的常用操作命令</a></li></ul><li><a href="#hdfs_374" rel="nofollow">hdfs的核心工作原理</a></li><ul><li><a href="#namenode_375" rel="nofollow">namenode元数据管理要点</a></li></ul><li><a href="#mapreduceYARN_419" rel="nofollow">mapreduce运行平台YARN</a></li><li><a href="#mapreduce_463" rel="nofollow">运行mapreduce程序</a></li><li><a href="#zookeeper__519" rel="nofollow">zookeeper 集群搭建</a></li></ul></div><p></p>
<h1><a id="_1"></a>什么是大数据</h1>
<h2><a id="_2"></a>基本概念</h2>
<p>《数据处理》<br>
在互联网技术发展到现今阶段，大量日常、工作等事务产生的数据都已经信息化，人类产生的数据量相比以前有了爆炸式的增长，以前的传统的数据处理技术已经无法胜任，需求催生技术，一套用来处理海量数据的软件工具应运而生，这就是大数据！</p>
<p>处理海量数据的核心技术：<br>
海量数据存储：分布式<br>
海量数据运算：分布式</p>
<p>这些核心技术的实现是不需要用户从零开始造轮子的<br>
存储和运算，都已经有大量的成熟的框架来用</p>
<p>存储框架：<br>
HDFS——分布式文件存储系统（HADOOP中的存储框架）<br>
HBASE——分布式数据库系统<br>
KAFKA——分布式消息缓存系统(实时流式数据处理场景中应用广泛)</p>
<p>运算框架：（要解决的核心问题就是帮用户将处理逻辑在很多机器上并行）<br>
MAPREDUCE—— 离线批处理/HADOOP中的运算框架<br>
SPARK —— 离线批处理/实时流式计算<br>
STORM —— 实时流式计算</p>
<p>辅助类的工具（解放大数据工程师的一些繁琐工作）：<br>
HIVE —— 数据仓库工具：可以接收sql，翻译成mapreduce或者spark程序运行<br>
FLUME——数据采集<br>
SQOOP——数据迁移<br>
ELASTIC SEARCH —— 分布式的搜索引擎<br>
…</p>
<p>换个角度说，大数据是：<br>
1、有海量的数据<br>
2、有对海量数据进行挖掘的需求<br>
3、有对海量数据进行挖掘的软件工具（hadoop、spark、storm、flink、tez、impala…）</p>
<h2><a id="_38"></a>大数据在现实生活中的具体应用</h2>
<p>数据处理的最典型应用：公司的产品运营情况分析</p>
<p>电商推荐系统：基于海量的浏览行为、购物行为数据，进行大量的算法模型的运算，得出各类推荐结论，以供电商网站页面来为用户进行商品推荐</p>
<p>精准广告推送系统：基于海量的互联网用户的各类数据，统计分析，进行用户画像（得到用户的各种属性标签），然后可以为广告主进行有针对性的精准的广告投放</p>
<h1><a id="hadoop_49"></a>什么是hadoop</h1>
<p>hadoop中有3个核心组件：<br>
分布式文件系统：HDFS —— 实现将文件分布式存储在很多的服务器上<br>
分布式运算编程框架：MAPREDUCE —— 实现在很多机器上分布式并行运算<br>
分布式资源调度平台：YARN —— 帮用户调度大量的mapreduce程序，并合理分配运算资源</p>
<h1><a id="hdfs_57"></a>hdfs整体运行机制</h1>
<p>hdfs：分布式文件系统<br>
hdfs有着文件系统共同的特征：<br>
1、有目录结构，顶层目录是：  /<br>
2、系统中存放的就是文件<br>
3、系统可以提供对文件的：创建、删除、修改、查看、移动等功能</p>
<p>hdfs跟普通的单机文件系统有区别：<br>
1、单机文件系统中存放的文件，是在一台机器的操作系统中<br>
2、hdfs的文件系统会横跨N多的机器<br>
3、单机文件系统中存放的文件，是在一台机器的磁盘上<br>
4、hdfs文件系统中存放的文件，是落在n多机器的本地单机文件系统中（hdfs是一个基于linux本地文件系统之上的文件系统）</p>
<p>hdfs的工作机制：<br>
1、客户把一个文件存入hdfs，其实hdfs会把这个文件切块后，分散存储在N台linux机器系统中（负责存储文件块的角色：data node）&lt;准确来说：切块的行为是由客户端决定的&gt;</p>
<p>2、一旦文件被切块存储，那么，hdfs中就必须有一个机制，来记录用户的每一个文件的切块信息，及每一块的具体存储机器（负责记录块信息的角色是：name node）</p>
<p>3、为了保证数据的安全性，hdfs可以将每一个文件块在集群中存放多个副本（到底存几个副本，是由当时存入该文件的客户端指定的）</p>
<p>综述：一个hdfs系统，由一台运行了namenode的服务器，和N台运行了datanode的服务器组成！</p>
<h1><a id="hdfs_89"></a>搭建hdfs分布式集群</h1>
<h2><a id="hdfs_90"></a>hdfs集群组成结构：</h2>
<p><img src="https://img-blog.csdn.net/20180909170927529?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE4Mzc3NTE1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p>
<h2><a id="hdfs_93"></a>安装hdfs集群的具体步骤：</h2>
<p><strong>一、首先需要准备N台linux服务器</strong><br>
学习阶段，用虚拟机即可！<br>
先准备4台虚拟机：1个namenode节点  + 3 个datanode 节点</p>
<p><strong>二、修改各台机器的主机名和ip地址</strong><br>
主机名：hdp-01  对应的ip地址：192.168.33.61<br>
主机名：hdp-02  对应的ip地址：192.168.33.62<br>
主机名：hdp-03  对应的ip地址：192.168.33.63<br>
主机名：hdp-04  对应的ip地址：192.168.33.64<br>
<img src="https://img-blog.csdn.net/20180909171013153?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE4Mzc3NTE1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p>
<p><strong>三、从windows中用CRT软件进行远程连接</strong><br>
在windows中将各台linux机器的主机名配置到的windows的本地域名映射文件中：<br>
c:/windows/system32/drivers/etc/hosts<br>
192.168.33.61	hdp-01<br>
192.168.33.62	hdp-02<br>
192.168.33.63	hdp-03<br>
192.168.33.64	hdp-04</p>
<p>用crt连接上后，修改一下crt的显示配置（字号，编码集改为UTF-8）：<br>
<img src="https://img-blog.csdn.net/20180909171052571?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE4Mzc3NTE1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p>
<p><strong>四、配置linux服务器的基础软件环境</strong></p>
<p>1.防火墙<br>
关闭防火墙：service iptables stop<br>
关闭防火墙自启： chkconfig iptables off</p>
<p>2.安装jdk：（hadoop体系中的各软件都是java开发的）<br>
1)利用alt+p 打开sftp窗口，然后将jdk压缩包拖入sftp窗口<br>
2)然后在linux中将jdk压缩包解压到/root/apps 下<br>
3)配置环境变量：JAVA_HOME   PATH<br>
vi /etc/profile   在文件的最后，加入：<br>
export JAVA_HOME=/root/apps/jdk1.8.0_60<br>
export PATH=<span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>A</mi><mi>T</mi><mi>H</mi><mo>:</mo></mrow><annotation encoding="application/x-tex">PATH:</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.13889em;">P</span><span class="mord mathit">A</span><span class="mord mathit" style="margin-right: 0.13889em;">T</span><span class="mord mathit" style="margin-right: 0.08125em;">H</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">:</span></span></span></span></span>JAVA_HOME/bin<br>
4)修改完成后，记得 source /etc/profile使配置生效<br>
5)检验：在任意目录下输入命令： java -version 看是否成功执行<br>
6)将安装好的jdk目录用scp命令拷贝到其他机器<br>
7)将/etc/profile配置文件也用scp命令拷贝到其他机器并分别执行source命令</p>
<p>3.集群内主机的域名映射配置<br>
在hdp-01上，vi /etc/hosts<br>
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4<br>
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6<br>
192.168.33.61   hdp-01<br>
192.168.33.62   hdp-02<br>
192.168.33.63   hdp-03<br>
192.168.33.64   hdp-04<br>
然后，将hosts文件拷贝到集群中的所有其他机器上<br>
scp /etc/hosts hdp-02:/etc/<br>
scp /etc/hosts hdp-03:/etc/<br>
scp /etc/hosts hdp-04:/etc/</p>
<p>补充<br>
提示:	如果在执行scp命令的时候，提示没有scp命令，则可以配置一个本地yum源来安装<br>
1、先在虚拟机中配置cdrom为一个centos的安装镜像iso文件<br>
2、在linux系统中将光驱挂在到文件系统中（某个目录）<br>
3、mkdir /mnt/cdrom<br>
4、mount -t iso9660 -o loop /dev/cdrom /mnt/cdrom<br>
5、检验挂载是否成功： ls /mnt/cdrom<br>
6、3、配置yum的仓库地址配置文件<br>
7、yum的仓库地址配置文件目录： /etc/yum.repos.d<br>
8、先将自带的仓库地址配置文件批量更名：<br>
<img src="https://img-blog.csdn.net/20180909171241659?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE4Mzc3NTE1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p>
<p>9、然后，拷贝一个出来进行修改<br>
<img src="https://img-blog.csdn.net/20180909171305426?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE4Mzc3NTE1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>
<img src="https://img-blog.csdn.net/20180909171314304?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE4Mzc3NTE1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>
10、修改完配置文件后，再安装scp命令：<br>
11、yum install openssh-clients -y</p>
<h1><a id="hdfs_168"></a>安装hdfs集群</h1>
<p>1、上传hadoop安装包到hdp-01</p>
<p>2、修改配置文件<br>
要点提示	核心配置参数：<br>
1)指定hadoop的默认文件系统为：hdfs<br>
2)指定hdfs的namenode节点为哪台机器<br>
3)指定namenode软件存储元数据的本地目录<br>
4)指定datanode软件存放文件块的本地目录</p>
<p>hadoop的配置文件在：/root/apps/hadoop安装目录/etc/hadoop/</p>
<ol>
<li>
<p><a href="http://xn--hadoop-env-yu6pe85r.sh" rel="nofollow">修改hadoop-env.sh</a><br>
export JAVA_HOME=/root/apps/jdk1.8.0_60</p>
</li>
<li>
<p>修改core-site.xml</p>
</li>
</ol>
<pre><code>&lt;configuration&gt;
&lt;property&gt;
&lt;name&gt;fs.defaultFS&lt;/name&gt;
&lt;value&gt;hdfs://hdp-01:9000&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<ol start="3">
<li>修改hdfs-site.xml</li>
</ol>
<pre><code>&lt;configuration&gt;
&lt;property&gt;
&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
&lt;value&gt;/root/hdpdata/name/&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
&lt;value&gt;/root/hdpdata/data&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
&lt;value&gt;hdp-02:50090&lt;/value&gt;
&lt;/property&gt;

&lt;/configuration&gt;
</code></pre>
<ol start="4">
<li>
<p>拷贝整个hadoop安装目录到其他机器<br>
scp -r /root/apps/hadoop-2.8.1  hdp-02:/root/apps/<br>
scp -r /root/apps/hadoop-2.8.1  hdp-03:/root/apps/<br>
scp -r /root/apps/hadoop-2.8.1  hdp-04:/root/apps/</p>
</li>
<li>
<p>启动HDFS</p>
</li>
</ol>
<p>所谓的启动HDFS，就是在对的机器上启动对的软件<br>
要点<br>
提示：	要运行hadoop的命令，需要在linux环境中配置HADOOP_HOME和PATH环境变量<br>
vi /etc/profile<br>
export JAVA_HOME=/root/apps/jdk1.8.0_60<br>
export HADOOP_HOME=/root/apps/hadoop-2.8.1<br>
export PATH=<span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>A</mi><mi>T</mi><mi>H</mi><mo>:</mo></mrow><annotation encoding="application/x-tex">PATH:</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.13889em;">P</span><span class="mord mathit">A</span><span class="mord mathit" style="margin-right: 0.13889em;">T</span><span class="mord mathit" style="margin-right: 0.08125em;">H</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">:</span></span></span></span></span>JAVA_HOME/bin:<span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi><mi>A</mi><mi>D</mi><mi>O</mi><mi>O</mi><msub><mi>P</mi><mi>H</mi></msub><mi>O</mi><mi>M</mi><mi>E</mi><mi mathvariant="normal">/</mi><mi>b</mi><mi>i</mi><mi>n</mi><mo>:</mo></mrow><annotation encoding="application/x-tex">HADOOP_HOME/bin:</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathit" style="margin-right: 0.08125em;">H</span><span class="mord mathit">A</span><span class="mord mathit" style="margin-right: 0.02778em;">D</span><span class="mord mathit" style="margin-right: 0.02778em;">O</span><span class="mord mathit" style="margin-right: 0.02778em;">O</span><span class="mord"><span class="mord mathit" style="margin-right: 0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.328331em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right: 0.08125em;">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathit" style="margin-right: 0.02778em;">O</span><span class="mord mathit" style="margin-right: 0.10903em;">M</span><span class="mord mathit" style="margin-right: 0.05764em;">E</span><span class="mord">/</span><span class="mord mathit">b</span><span class="mord mathit">i</span><span class="mord mathit">n</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">:</span></span></span></span></span>HADOOP_HOME/sbin</p>
<p>首先，初始化namenode的元数据目录<br>
要在hdp-01上执行hadoop的一个命令来初始化namenode的元数据存储目录<br>
hadoop namenode -format<br>
1.创建一个全新的元数据存储目录<br>
2.生成记录元数据的文件fsimage<br>
3.生成集群的相关标识：如：集群id——clusterID</p>
<p>然后，启动namenode进程（在hdp-01上）<br>
<a href="http://hadoop-daemon.sh" rel="nofollow">hadoop-daemon.sh</a> start namenode<br>
启动完后，首先用jps查看一下namenode的进程是否存在</p>
<p>然后，在windows中用浏览器访问namenode提供的web端口：50070<br>
<a href="http://hdp-01:50070" rel="nofollow">http://hdp-01:50070</a></p>
<p>然后，启动众datanode们（在任意地方）<br>
<a href="http://hadoop-daemon.sh" rel="nofollow">hadoop-daemon.sh</a> start datanode</p>
<ol start="6">
<li>用自动批量启动脚本来启动HDFS<br>
1)先配置hdp-01到集群中所有机器（包含自己）的免密登陆<br>
2)配完免密后，可以执行一次  ssh 0.0.0.0<br>
3)修改hadoop安装目录中/etc/hadoop/slaves（把需要启动datanode进程的节点列入）<br>
hdp-01<br>
hdp-02<br>
hdp-03<br>
hdp-04</li>
</ol>
<p>4)在hdp-01上用脚本：<a href="http://start-dfs.sh" rel="nofollow">start-dfs.sh</a> 来自动启动整个集群<br>
5)如果要停止，则用脚本：<a href="http://stop-dfs.sh" rel="nofollow">stop-dfs.sh</a><br>
#hdfs的客户端操作<br>
##客户端的理解<br>
hdfs的客户端有多种形式：<br>
1、网页形式<br>
2、命令行形式<br>
3、客户端在哪里运行，没有约束，只要运行客户端的机器能够跟hdfs集群联网</p>
<p>文件的切块大小和存储的副本数量，都是由客户端决定！<br>
所谓的由客户端决定，是通过配置参数来定的<br>
hdfs的客户端会读以下两个参数，来决定切块大小、副本数量：<br>
切块大小的参数： dfs.blocksize<br>
副本数量的参数： dfs.replication</p>
<p>上面两个参数应该配置在客户端机器的hadoop目录中的hdfs-site.xml中配置</p>
<pre><code>&lt;property&gt;
&lt;name&gt;dfs.blocksize&lt;/name&gt;
&lt;value&gt;64m&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.replication&lt;/name&gt;
&lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;

</code></pre>
<h2><a id="hdfs_291"></a>hdfs客户端的常用操作命令</h2>
<p>0、查看hdfs中的目录信息<br>
hadoop fs -ls /hdfs路径</p>
<p>1、上传文件到hdfs中<br>
hadoop fs -put /本地文件  /aaa<br>
hadoop fs -copyFromLocal /本地文件  /hdfs路径   ##  copyFromLocal等价于 put</p>
<p>hadoop fs -moveFromLocal /本地文件  /hdfs路径  ## 跟copyFromLocal的区别是：从本地移动到hdfs中</p>
<p>2、下载文件到客户端本地磁盘<br>
hadoop fs -get /hdfs中的路径   /本地磁盘目录<br>
hadoop fs -copyToLocal /hdfs中的路径 /本地磁盘路径   ## 跟get等价<br>
hadoop fs -moveToLocal /hdfs路径  /本地路径  ## 从hdfs中移动到本地</p>
<p>3、在hdfs中创建文件夹<br>
hadoop fs -mkdir  -p /aaa/xxx</p>
<p>4、移动hdfs中的文件（更名）<br>
hadoop fs -mv /hdfs的路径  /hdfs的另一个路径</p>
<p>5、删除hdfs中的文件或文件夹<br>
hadoop fs -rm -r /aaa</p>
<p>6、修改文件的权限<br>
hadoop fs -chown user:group /aaa<br>
hadoop fs -chmod 700 /aaa</p>
<p>7、追加内容到已存在的文件<br>
hadoop fs -appendToFile /本地文件   /hdfs中的文件</p>
<p>8、显示文本文件的内容<br>
hadoop fs -cat /hdfs中的文件<br>
hadoop fs -tail /hdfs中的文件</p>
<p>补充：hdfs命令行客户端的所有命令列表</p>
<pre><code>Usage: hadoop fs [generic options]
        [-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]
        [-cat [-ignoreCrc] &lt;src&gt; ...]
        [-checksum &lt;src&gt; ...]
        [-chgrp [-R] GROUP PATH...]
        [-chmod [-R]  &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]
        [-chown [-R] [OWNER][:[GROUP]] PATH...]
        [-copyFromLocal [-f] [-p] [-l] [-d] &lt;localsrc&gt; ... &lt;dst&gt;]
        [-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]
        [-count [-q] [-h] [-v] [-t [&lt;storage type&gt;]] [-u] [-x] &lt;path&gt; ...]
        [-cp [-f] [-p | -p[topax]] [-d] &lt;src&gt; ... &lt;dst&gt;]
        [-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]]
        [-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;]
        [-df [-h] [&lt;path&gt; ...]]
        [-du [-s] [-h] [-x] &lt;path&gt; ...]
        [-expunge]
        [-find &lt;path&gt; ... &lt;expression&gt; ...]
        [-get [-f] [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]
        [-getfacl [-R] &lt;path&gt;]
        [-getfattr [-R] {-n name | -d} [-e en] &lt;path&gt;]
        [-getmerge [-nl] [-skip-empty-file] &lt;src&gt; &lt;localdst&gt;]
        [-help [cmd ...]]
        [-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [&lt;path&gt; ...]]
        [-mkdir [-p] &lt;path&gt; ...]
        [-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]
        [-moveToLocal &lt;src&gt; &lt;localdst&gt;]
        [-mv &lt;src&gt; ... &lt;dst&gt;]
        [-put [-f] [-p] [-l] [-d] &lt;localsrc&gt; ... &lt;dst&gt;]
        [-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;]
        [-rm [-f] [-r|-R] [-skipTrash] [-safely] &lt;src&gt; ...]
        [-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]
        [-setfacl [-R] [{-b|-k} {-m|-x &lt;acl_spec&gt;} &lt;path&gt;]|[--set &lt;acl_spec&gt; &lt;path&gt;]]
        [-setfattr {-n name [-v value] | -x name} &lt;path&gt;]
        [-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...]
        [-stat [format] &lt;path&gt; ...]
        [-tail [-f] &lt;file&gt;]
        [-test -[defsz] &lt;path&gt;]
        [-text [-ignoreCrc] &lt;src&gt; ...]
        [-touchz &lt;path&gt; ...]
        [-truncate [-w] &lt;length&gt; &lt;path&gt; ...]
        [-usage [cmd ...]]
</code></pre>
<h1><a id="hdfs_374"></a>hdfs的核心工作原理</h1>
<h2><a id="namenode_375"></a>namenode元数据管理要点</h2>
<p>1、什么是元数据？<br>
hdfs的目录结构及每一个文件的块信息（块的id，块的副本数量，块的存放位置）</p>
<p>2、元数据由谁负责管理？<br>
namenode</p>
<p>3、namenode把元数据记录在哪里？<br>
namenode的实时的完整的元数据存储在内存中；<br>
namenode还会在磁盘中（dfs.namenode.name.dir）存储内存元数据在某个时间点上的镜像文件；<br>
namenode会把引起元数据变化的客户端操作记录在edits日志文件中；</p>
<p>secondarynamenode会定期从namenode上下载fsimage镜像和新生成的edits日志，然后加载fsimage镜像到内存中，然后顺序解析edits文件，对内存中的元数据对象进行修改（整合）<br>
整合完成后，将内存元数据序列化成一个新的fsimage，并将这个fsimage镜像文件上传给namenode</p>
<p>上述过程叫做：checkpoint操作<br>
提示：secondary namenode每次做checkpoint操作时，都需要从namenode上下载上次的fsimage镜像文件吗？<br>
第一次checkpoint需要下载，以后就不用下载了，因为自己的机器上就已经有了。<br>
<img src="https://img-blog.csdn.net/20180909172536234?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE4Mzc3NTE1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>
补充：secondary namenode启动位置的配置<br>
默认值</p>
<pre><code>&lt;property&gt;
  &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
  &lt;value&gt;0.0.0.0:50090&lt;/value&gt;
&lt;/property&gt;

</code></pre>
<p>把默认值改成你想要的机器主机名即可</p>
<p>secondarynamenode保存元数据文件的目录配置：<br>
默认值</p>
<pre><code>&lt;property&gt;
  &lt;name&gt;dfs.namenode.checkpoint.dir&lt;/name&gt;
  &lt;value&gt;file://${hadoop.tmp.dir}/dfs/namesecondary&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<p>改成自己想要的路径即可：/root/dfs/namesecondary</p>
<h1><a id="mapreduceYARN_419"></a>mapreduce运行平台YARN</h1>
<p>mapreduce程序应该是在很多机器上并行启动，而且先执行map task，当众多的maptask都处理完自己的数据后，还需要启动众多的reduce task，这个过程如果用用户自己手动调度不太现实，需要一个自动化的调度平台——hadoop中就为运行mapreduce之类的分布式运算程序开发了一个自动化调度平台——YARN</p>
<p>安装yarn集群<br>
yarn集群中有两个角色：<br>
主节点：Resource Manager  1台<br>
从节点：Node Manager   N台</p>
<p>Resource Manager一般安装在一台专门的机器上<br>
Node Manager应该与HDFS中的data node重叠在一起</p>
<p>修改配置文件：<br>
yarn-site.xml</p>
<pre><code>&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
&lt;value&gt;hdp-04&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;

</code></pre>
<p>然后复制到每一台机器上</p>
<p>然后在hdp-04上，修改hadoop的slaves文件，列入要启动nodemanager的机器<br>
然后将hdp-04到所有机器的免密登陆配置好<br>
然后，就可以用脚本启动yarn集群：<br>
sbin/start-yarn.sh<br>
停止：<br>
sbin/stop-yarn.sh</p>
<p>启动完成后，可以在windows上用浏览器访问resourcemanager的web端口：<br>
<a href="http://hdp-04:8088" rel="nofollow">http://hdp-04:8088</a><br>
看resource mananger是否认出了所有的node manager节点</p>
<h1><a id="mapreduce_463"></a>运行mapreduce程序</h1>
<p>首先，为你的mapreduce程序开发一个提交job到yarn的客户端类（模板代码）：<br>
1.描述你的mapreduce程序运行时所需要的一些信息(比如用哪个mapper、reducer、map和reduce输出的kv类型、jar包所在路径、reduce task的数量、输入输出数据的路径)<br>
2.将信息和整个工程的jar包一起交给yarn<br>
然后，将整个工程（yarn客户端类+ mapreduce所有jar和自定义类）打成jar包<br>
然后，将jar包上传到hadoop集群中的任意一台机器上<br>
最后，运行jar包中的（YARN客户端类）</p>
<p>[root@hdp-04 ~]# hadoop jar wc.jar cn.edu360.hadoop.mr.wc.JobSubmitter</p>
<p>#安装yarn集群<br>
yarn集群中有两个角色：<br>
主节点：Resource Manager  1台<br>
从节点：Node Manager   N台</p>
<p>Resource Manager一般安装在一台专门的机器上<br>
Node Manager应该与HDFS中的data node重叠在一起</p>
<p>修改配置文件：<br>
yarn-site.xml</p>
<pre><code>&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
&lt;value&gt;hdp-04&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
&lt;value&gt;2048&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;
&lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<p>然后复制到每一台机器上</p>
<p>然后在hdp-04上，修改hadoop的slaves文件，列入要启动nodemanager的机器<br>
然后将hdp-04到所有机器的免密登陆配置好<br>
然后，就可以用脚本启动yarn集群：<br>
sbin/start-yarn.sh<br>
停止：<br>
sbin/stop-yarn.sh</p>
<p>启动完成后，可以在windows上用浏览器访问resourcemanager的web端口：<br>
<a href="http://hdp-04:8088" rel="nofollow">http://hdp-04:8088</a><br>
看resource mananger是否认出了所有的node manager节点</p>
<h1><a id="zookeeper__519"></a>zookeeper 集群搭建</h1>
<p>1.上传安装包，解压<br>
2.修改conf/zoo.cfg</p>
<pre><code># The number of milliseconds of each tick
tickTime=2000
# The number of ticks that the initial
# synchronization phase can take
initLimit=10
# The number of ticks that can pass between
# sending a request and getting an acknowledgement
syncLimit=5
# the directory where the snapshot is stored.
# do not use /tmp for storage, /tmp here is just
# example sakes.
dataDir=/root/zkdata
# the port at which the clients will connect
clientPort=2181
# Set to "0" to disable auto purge feature
#autopurge.purgeInterval=1
server.1=hdp-01:2888:3888
server.2=hdp-02:2888:3888
server.3=hdp-03:2888:3888
</code></pre>
<p>配置文件修改完后，将安装包拷贝给hdp-02 和 hdp-03</p>
<p>接着，到hdp-01上，新建数据目录/root/zkdata，并在目录中生成一个文件myid，内容为1<br>
接着，到hdp-02上，新建数据目录/root/zkdata，并在目录中生成一个文件myid，内容为2<br>
接着，到hdp-03上，新建数据目录/root/zkdata，并在目录中生成一个文件myid，内容为3</p>
<p>脚本批量启动zookeeper集群：</p>
<pre><code>#!/usr/bin/env bash
for host in hdp-01 hdp-02 hdp-03
do
echo ${host}:${1}ing....
ssh $host " source /etc/profile;/usr/zookeeper-3.4.6/bin/zkServer.sh ${1}"
done
</code></pre>

            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>