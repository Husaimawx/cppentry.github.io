---
layout:     post
title:      1005-Hive的QL语法
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><span style="color:#FF0000;">语法１——</span>本地数据</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><br></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';">1、本地数据加载到hive数据仓库中</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><br></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';">create table t_order(id int ,name string)<br>
row format delimited<br>
fields terminated by '\t';</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';">load data local inpath '/home/hadoop/order.log' into table t_order;</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><br></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><br></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';">2、hdfs上的数据加载到hive数据仓库中</span>
<div><span style="font-family:'仿宋';"><br></span></div>
<span style="font-family:'仿宋';color:#E30000;">2.1 hdfs上创建文件</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><strong>[hadoop@cloud04 ~]$ hadoop fs -cat /order3.log</strong><br>
101     dami<br>
102     miantao<br>
103     mifan</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><br></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';color:#E30000;">2.2 hdfs上的文件order3.log 上传至hive数据仓库中</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';">注意： 在执行load数据到指定的表之前，首先要进行对应的表目录</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><strong>hive&gt; show databases;</strong><br>
OK<br>
default<br>
jf01<br>
Time taken: 0.387 seconds, Fetched: 2 row(s)<br><strong>hive&gt; use jf01;</strong><br>
OK<br>
Time taken: 0.034 seconds<br><strong>hive&gt; show tables;</strong><br>
OK<br>
t_order</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><br></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><strong>hive&gt; load data inpath 'hdfs://ns1/order3.log' into table t_order;</strong><br>
Loading data to table jf01.t_order<br>
Table jf01.t_order stats: [num_partitions: 0, num_files: 3, num_rows: 0, total_size: 89, raw_data_size: 0]<br>
OK<br>
Time taken: 0.988 seconds</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><br></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';">总结：通过以上的操作后，再次执行命令：<strong>[hadoop@cloud04 ~]$ hadoop fs -cat /order3.log</strong></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';">会发现原来存放的位置的文件已经不存在了</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><br></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';color:#E30000;">2.3 在hive 中执行drop table t_order; 命令后</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';">第一步： 删除前查看hive的目录</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><br></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';">第二步：执行drop table t_order命令</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';">hive&gt; drop table t_order;</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><br></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';">第三步：查看t_order 在数据库存储内容</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';">总结：drop table 表名  ，该数据从此就会从hdfs和hive上消失</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><br></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';">综上所述，总结得出该方式存在的几个缺点：</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';">—— 数据从hdfs上移动到hive的数据仓库中，原来的数据就不存在了</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';">——drop table 表名  ，该数据从此就会从hdfs和hive上消失</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><br></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><br></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><br></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';color:#E30000;"><strong>—————————————————————————————————————</strong></span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;"><span style="font-family:'仿宋';"><span>语法２——</span>通过建立外部表，然后把本地/hdfs的数据加载到hive数据仓库中</span></div>
<div style="background-color:rgb(255,255,255);font-size:19px;">
<div><span style="font-family:'仿宋';color:#E30000;">1.1  建立数据存储的目录</span></div>
<div><span style="font-family:'仿宋';">hadoop fs -mkdir  /jf </span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span style="font-family:'仿宋';color:#E30000;">1.2 上传数据 wareinfo.menu 到/jf目录下</span></div>
<div><span style="font-family:'仿宋';">[hadoop@cloud01 ~]$ hadoop fs -cat /jf/wareinfo.menu<br>
100 50元话费<br>
200 100元话费<br>
300 200元话费<br>
[hadoop@cloud01 ~]$</span></div>
<div><span style="font-family:'仿宋';color:#E30000;">1.3 在hive下创建外部表并指定该表在hdfs上存放位置</span></div>
<div><span style="font-family:'仿宋';">hive&gt; create database jfdb;</span></div>
<div><span style="font-family:'仿宋';">hive&gt; use jfdb;<br>
hive&gt; create<span> </span><strong><span style="color:#FF0000;">external</span></strong><span> </span>table ware_info(id int ,name string)<br>
    &gt; row format delimited<br>
    &gt; fields terminated by '\t'<br>
    &gt; location '<span style="color:#2D4FC9;">/jf';</span><br><br></span></div>
<div><span style="font-family:'仿宋';">从这里发现，外部表可以不在/user/hive/warehouse下面，可以任意建立一个目录，例如： hdfs下的/jf目录下 hadoop fs -put wareinfo.menu <span style="color:#3665EE;">/jf</span></span></div>
<div><span style="font-family:'仿宋';color:#3665EE;"><br></span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span style="font-family:'仿宋';color:#E30000;">1.4 进行hive数据仓库，执行删除表</span></div>
<div><span style="font-family:'仿宋';">hive&gt; drop table ware_info;</span></div>
<div><span style="font-family:'仿宋';">hive&gt; show tables;</span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span style="font-family:'仿宋';">通过执行drop table 命令后，ware_info 在mysql上的元数据被删除了。而发现/jf/wareinfo.menu 仍然存在，通过下面的命令验证：</span></div>
<div><span style="font-family:'仿宋';">[hadoop@cloud01 ~]$ hadoop fs -cat /jf/wareinfo.menu;<br>
100     50元话费<br>
200     100元话费<br>
300     200元话费</span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span style="font-family:'仿宋';">可以发现：对于外部表，hive执行删除表后，元数据删除了，但hdfs上 /jf/wareinfo.menu中数据扔然存在，故工作中多用于该方案。。</span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span style="font-family:'仿宋';">总结该方案的优点： </span></div>
<div><span style="font-family:'仿宋';">——drop table 表名  ，数据仅从hive上删除，正在的数据还在hdfs行存储，故实际工作</span></div>
<div><span style="font-family:'仿宋';">采用外部表建立hdfs的关联</span></div>
<div><span style="font-family:'仿宋';color:#E30000;"><strong><br>
————————————————————————————————————</strong></span></div>
<div><span style="font-family:'仿宋';"><span>语法3——</span>根据已经存在的表生成需要的表</span></div>
<div><span><span style="font-family:'仿宋';">1. 数据源表</span></span></div>
<div><span style="font-family:'仿宋';">create table t_order(orderNo int ,wareName string)</span></div>
<div><span style="font-family:'仿宋';">row format delimited<br>
fields terminated by '\t';</span></div>
<div><span style="font-family:'仿宋';">load data local inpath '/home/hadoop/myorder.log' into table t_order;</span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span><span style="font-family:'仿宋';">2、创建新表</span></span></div>
<div><span style="font-family:'仿宋';">create table test1 as select wareName , count(*)  from t_order group by wareName ;</span></div>
<div><strong style="color:rgb(227,0,0);"><span style="font-family:'仿宋';">—————————————————————————————————————</span></strong></div>
<div><span style="font-family:'仿宋';"><span>语法4——</span><span>文件已顺序文件存储</span></span></div>
<div><span style="font-family:'仿宋';">1、创建表</span></div>
<div><span style="font-family:'仿宋';">create table tab_order_seq(id int,name string)<br>
    row format delimited<br>
    fields terminated by ','<br>
    stored as sequencefile;<br>
insert overwrite table<span> </span><span style="color:#FF0000;"><strong>tab_order_seq</strong></span><span> </span>select * from<span> </span><span style="color:#FF0000;"><strong>t_order</strong></span>;<br></span></div>
<div><span style="font-family:'仿宋';"><br>
注意： 该文件的格式和文本文件存储有什么区别呢？</span></div>
<div><span style="font-family:'仿宋';">——文本文件存储： 获取后，可以看懂，是普通文本存储的</span></div>
<div><span style="font-family:'仿宋';">——文件序列存储：所有数据以k：v格式，以二进制方式存储</span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span style="font-family:'仿宋';">2、验证数据存储情况</span></div>
<div><span style="font-family:'仿宋';">[hadoop@cloud01 ~]$ hadoop fs -cat /user/hive/warehouse/jfdb.db/tab_order_seq/000000_0<br></span></div>
<div><strong style="color:rgb(227,0,0);"><span style="font-family:'仿宋';">—————————————————————————————————————</span></strong></div>
<div><span><span style="font-family:'仿宋';">语法5——分区表创建</span></span></div>
<div><span style="font-family:'仿宋';color:#E30000;">1、创建分区表</span></div>
<div><span style="font-family:'仿宋';">create table tab_order_part(id int,name string)<br>
partitioned by (type string)<br>
row format delimited </span></div>
<div><span style="font-family:'仿宋';">fields terminated by '\t';</span></div>
<div><span style="font-family:'仿宋';"><br><span style="color:#E30000;">2、插入数据</span></span></div>
<div><span style="font-family:'仿宋';">load data local inpath '/home/hadoop/order.log' overwrite into table tab_order_part   partition(type='fruit');</span></div>
<div><span style="font-family:'仿宋';">load data local inpath '/home/hadoop/order2.log' overwrite into table tab_order_part   partition(type='fruit2');</span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span style="font-family:'仿宋';color:#E30000;">3、验证数据</span></div>
<div><span style="font-family:'仿宋';">3.1 界面查询</span></div>
<div><span style="font-family:'仿宋';"></span></div>
<div><span style="font-family:'仿宋';">3.2命令行查询</span></div>
<div><span style="font-family:'仿宋';">hive&gt; select * from tab_order_part;                  <br>
OK<br>
1     apple     fruit<br>
2     oracle     fruit<br>
3     banana     fruit<br>
11     apple1     fruit2<br>
21     oracle1     fruit2<br>
31     banana1     fruit2<br>
Time taken: 0.1 seconds, Fetched: 6 row(s)<br>
hive&gt; select * from tab_order_part where type='fruit';<br>
OK<br>
1     apple     fruit<br>
2     oracle     fruit<br>
3     banana     fruit<br>
Time taken: 0.081 seconds, Fetched: 3 row(s)</span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span style="font-family:'仿宋';">3.3 如何查看标的partition</span></div>
<div><span style="font-family:'仿宋';">通过show partitions 表名 ，这个命令查看某个表拥有的partition</span></div>
<div><span style="font-family:'仿宋';">hive&gt; show partitions tab_order_part;<br>
OK<br>
type=fruit<br>
type=fruit2</span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span style="font-family:'仿宋';">——目的：是可以按照指定的分区查询数据，提供查询效率</span></div>
<div>
<div><span style="font-family:'仿宋';">——存储格式： 分区数据在hdfs上格式</span></div>
<div><span style="font-family:'仿宋';">——查询分区数据方法</span></div>
<span style="font-family:'仿宋';"><br></span></div>
<div><span style="font-family:'仿宋';"><span>语法6——</span>hive命令行操作hdfs</span></div>
<div><span style="font-family:'仿宋';">通过命令行方式登录到hive，然后使用dfs命令即可完成hive在命令行下操作hdfs</span></div>
<div><span style="font-family:'仿宋';">hive&gt; dfs -ls /;<br>
Found 3 items<br>
drwxr-xr-x   - hadoop supergroup          0 2015-05-30 08:16 /jf<br>
drwx------   - hadoop supergroup          0 2015-04-27 07:03 /tmp<br>
drwxr-xr-x   - hadoop supergroup          0 2015-04-27 08:57 /user</span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span><span style="font-family:'仿宋';">语法7——hive查询结果写数据到hdfs</span></span></div>
<div><span style="font-family:'仿宋';">7.1 查询结果到hdfs上的/hiveout目录下</span></div>
<div><span style="font-family:'仿宋';">insert overwrite directory '/hiveout' select * from ware_info;</span></div>
<div><span style="font-family:'仿宋';">7.2 hive上执行sql查询结果存放到/home/hadoop/hiveout上</span></div>
<div><span style="font-family:'仿宋';">insert overwrite local directory '/home/hadoop/hiveout' select * from ware_info;</span></div>
</div>
<div style="background-color:rgb(255,255,255);">
<div><span><span style="font-family:'仿宋';">语法8——map格式数据存储hive上</span></span></div>
<div><span style="font-family:'仿宋';"><br><strong>8.1 存储数据为<br></strong><br></span></div>
<div><span style="font-family:'仿宋';">[hadoop@cloud04 ~]$ cat /home/hadoop/tab_map.txt<br>
10001     age:20,sex:1<br>
10002     age:21,sex:0<br>
10003     age:22,sex:1         <br>
10004     age:23,sex:0<br><br>
#登录hive后，执行下面的命令<br>
hive&gt; load data local inpath '/home/hadoop/tab_map.txt' overwrite into table tab_map;</span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<div><span style="font-family:'仿宋';"><strong>8.2 hive建表语句 <br></strong>create table tab_map(code string,info map&lt;string,string&gt;)<br>
row format delimited<br>
fields terminated by '\t'<br>
collection items terminated by ','<br>
map keys terminated by ':';<br><br></span></div>
<div><strong><span style="font-family:'仿宋';">8.3 hive命令行查询结果</span></strong></div>
<div><span style="font-family:'仿宋';">第一种：查看所有列表</span></div>
<div><span style="font-family:'仿宋';">hive&gt; select * from tab_map;<br>
OK<br>
10001     {"age":"20","sex":"1"}<br>
10002     {"age":"21","sex":"0"}<br>
10003     {"age":"22","sex":"1"}<br>
10004     {"age":"23","sex":"0"}</span></div>
<div><strong><span style="font-family:'仿宋';"><br></span></strong></div>
<div><span style="font-family:'仿宋';">第二种：查看指定字段内容，map中的内容通过map['字段'] 获取对应的数值<br>
hive&gt; select code,info['age'],info['sex'] from tab_map;</span></div>
<div><span style="font-family:'仿宋';"><br></span></div>
<br></div>
</div>
            </div>
                </div>