---
layout:     post
title:      Hadoop伪分布安装
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h1 id="hadoop伪分布安装">Hadoop伪分布安装</h1>

<hr>



<h2 id="hadoop框架">hadoop框架</h2>



<h3 id="hadoop-common">Hadoop Common:</h3>

<pre><code>公共模块
</code></pre>



<h3 id="hadoop-distributed-file-system-hdfs">Hadoop Distributed File System (HDFS™):</h3>

<pre><code>分布式文件系统
主从架构
    主节点：NameNode
        管理存储文件的元数据：
        文件的名称、文件存储路径、block、副本数
    从节点：DataNode
        真正的存储文件数据，blocks
</code></pre>



<h3 id="hadoop-yarn">Hadoop YARN:</h3>

<pre><code>一种分布式集群资源管理和任务调度资源管理框架
主节点：ResourceManager
    管理整个集群的资源（内存、CPUCore）接收Client提交的应用（比如提交运行的MapReduce程序），分配资源
从节点：NodeManagers
    管理每台机器的资源，接收RM发送的请求，运行Task
</code></pre>



<h3 id="hadoop-mapreduce">Hadoop MapReduce:</h3>

<pre><code>并行处理框架（分布式处理海量数据）
</code></pre>

<hr>

<p><img src="https://img-blog.csdn.net/20171105123632548?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2FpdHRpbmdfZm9yX3lvdXRo/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p><strong>任务监控</strong></p>

<p>提交任务后由JobTracker协调，先执行Map阶段（图中M1，M2和M3），然后执行Reduce阶段（图中R1和R2）。 <br>
Map阶段和Reduce阶段动作都受到TaskTracker监控，并运行在独立于TaskTracker的Java虚拟机中。</p>

<p><strong>输入</strong></p>

<p>输入通过InputFormat实现： <br>
    InputSplit：对数据进行划分（图中的splite1到splite5，就是划分以后的结果） <br>
    RecordReader：从输入中生成(key,value)对（map()方法处理的就是(key,value)对格式）</p>

<p><strong>Map phase</strong></p>

<ul>
<li>Map()：</li>
</ul>



<pre class="prettyprint"><code class=" hljs vhdl">自定义业务逻辑和输出(key,value)对的类型，<span class="hljs-keyword">map</span>操作通过<span class="hljs-keyword">context</span>.collect（最终通过OutputCollector.collect）将结果写到<span class="hljs-keyword">context</span>中。</code></pre>

<ul>
<li>shuffer:</li>
</ul>



<pre class="prettyprint"><code class=" hljs mel">从map()函数输出处理结果数据开始, 一直到reduce()函数开始数据。
内存是一个 环形缓冲区，默认大小为<span class="hljs-number">100</span>MB，当达到<span class="hljs-number">80</span><span class="hljs-variable">%的</span>时候，需要将数据spill到本地磁盘中。
（<span class="hljs-number">1</span>）自定义（可优化部分：Combiner）：
目的：
<span class="hljs-number">1.</span>减少MapTask向本地磁盘写的数据量，同事也减少了ReduceTask拉取时读取数据的量
<span class="hljs-number">2.</span>减少了ReduceTask拉取数据时，网络IO流。
流程：
在Mapper输出它的&lt;k,v&gt;时，键值对不会被马上写到输出里，他们会被收集在list里（一个key值一个list），当写入一定数量的键值对时，这部分缓冲会被Combiner中进行合并，然后再输出到Partitioner中（图中M1的黄颜色部分对应着Combiner和Partitioner）。并不是所有的MapReduce都可以设置的，比如求平均值就不可以。
（<span class="hljs-number">2</span>）分区（Partitioner）:
在内存中进行分区， 每个分区的数据 给一个redeuceTask处理
（<span class="hljs-number">3</span>）排序（<span class="hljs-keyword">sort</span>）:
在spill写入之前，会先进行二次排序:快速排序算法
<span class="hljs-number">1.</span>数据所属的<span class="hljs-keyword">partition</span>进行排序
<span class="hljs-number">2.</span>每个<span class="hljs-keyword">partition</span>中的数据再按key来排序。
<span class="hljs-keyword">partition</span>的目的是将记录划分到不同的Reducer上去，以期望能够达到负载均衡，以后的Reducer就会根据<span class="hljs-keyword">partition</span>来读取自己对应的数据。
（<span class="hljs-number">4</span>）溢写（spill）:
达到<span class="hljs-number">80</span><span class="hljs-variable">%，</span>内存数据溢写到磁盘上
（<span class="hljs-number">5</span>）自定义（可优化部分：Compress）：
目的：
<span class="hljs-number">1.</span>减少本地磁盘IO读写
<span class="hljs-number">2.</span>减少网络IO传输
对MapTask输出的结果数据进行压缩，消耗电脑CPU资源。
通常压缩算法：
<span class="hljs-number">1.</span>google开源算法：snappy
<span class="hljs-number">2.</span>lz4
（<span class="hljs-number">6</span>）合并成文件:
反复操作，直到mapTask输出结束，此时本地会有多个spill文件，将所有的spil文件进行合并和排序：归并排序算法。最终合并完成以后，形成一个文件（分区的、排序的）</code></pre>

<p><strong>Reduce phase</strong></p>

<ul>
<li>shuffer:</li>
</ul>



<pre class="prettyprint"><code class=" hljs mel">（<span class="hljs-number">1</span>）copy：
ReduceTask将会接收到AppMaster指令，到MapTask运行的主机的本地磁盘中拉取要处理的分区数据。Map端进行<span class="hljs-keyword">partition</span>的时候，实际上就相当于指定了每个Reducer要处理的数据(<span class="hljs-keyword">partition</span>就对应了Reducer）
每个Reducer会处理一个或者多个<span class="hljs-keyword">partition</span>，拉取所有MapTask上属于自己要处理的数据
首先放在内存中，达到阀值，进行排序，spill（类似map端）
（<span class="hljs-number">2</span>）<span class="hljs-keyword">sort</span>：
当所有的拉取完成以后，合并所有的文件，并且文件进行排序:归并排序算法。</code></pre>

<ul>
<li>reduce()：</li>
</ul>



<pre class="prettyprint"><code class=" hljs avrasm">Reduce阶段，上面通过处理后得到的（key,list（value1，value2..<span class="hljs-preprocessor">.valuen</span>)）会送到Reducer<span class="hljs-preprocessor">.reduce</span>方法中处理。</code></pre>

<p><strong>输出</strong></p>

<p>输出的结果通过OutputFormat，输出到DFS中。</p>

<hr>



<h2 id="环境配置">环境配置</h2>



<h3 id="创建普通用户和设置密码">创建普通用户和设置密码</h3>

<p>新建用户：<code># useradd eclound</code> <br>
 修改密码：<code># passwd eclound</code></p>



<h3 id="创建普通用户的root权限">创建普通用户的root权限</h3>

<p><em>切换用户</em>  <br>
 切换到普通用户： <br>
 <code># su</code>  <br>
 切换到root用户： <br>
<code>$ su eclound</code> <br>
 <em>给/etc/sudoers赋予写的权限:</em>  <br>
 <code># chmod u+w /etc/sudoers</code> <br>
 <em>编辑/etc/sudoers文件</em> <br>
 <code># vim /etc/sudoers</code> <br>
 <em>在文件的首行加入：</em> <br>
 <code>eclound ALL=(root)NOPASSWD:ALL</code> <br>
 <em>收回/etc/sudoers写的权限:</em> <br>
 <code># chmod u-w /etc/sudoers</code> <br>
 <em>查看防火墙状态:</em> <br>
<code>$ sudo service iptables status</code></p>



<h3 id="更改ip地址">更改ip地址：</h3>

<p>即时生效：<code># ifconfig eth0 192.168.133.130 netmask 255.255.255.0</code> <br>
启动生效：<code># sudo vim /etc/sysconfig/network-scripts/ifcfg-eth0</code></p>



<h3 id="更改主机名">更改主机名：</h3>

<p>即时生效：<code># hostname bigdata-hadoop.eclound.com</code> <br>
启动生效：<code># vim /etc/sysconfig/network</code></p>



<h3 id="更改映射">更改映射</h3>

<p>主机名 -&gt; /etc/hosts文件(域名解析) -&gt; 找到ip地址</p>

<ul>
<li>Linux系统（虚拟机）：</li>
</ul>

<p><code>#vim  /etc/hosts</code> <br>
192.168.133.130 bigdata-hadoop.eclound.com bigdata-eclound <br>
第一部份：IP地址 <br>
第二部份：主机名或域名 <br>
第三部份：主机名别名；</p>

<ul>
<li>Windows系统（本机）：</li>
</ul>

<p>编辑hosts文件 <br>
C:\Windows\System32\drivers\etc\hosts <br>
192.168.133.130 bigdata-hadoop.eclound.com</p>



<h3 id="关闭防火墙和禁用selinux">关闭防火墙和禁用SELINUX</h3>

<p>永久性服务开启和关闭管理命令:# chkconfig 服务名称 on|off <br>
    范例： <br>
            <em>永久性关闭防火墙:</em> <br>
             <code>$ sudo chkconfig iptables off</code> <br>
            <em>查看服务是否随着系统的启动而开启或者关闭:</em> <br>
            <code>$ sudo chkconfig --list|grep iptables</code></p>



<h3 id="禁用selinux">禁用SELINUX</h3>

<p><code>$ sudo vim /etc/sysconfig/selinux</code> <br>
更改selinux的状态：</p>

<blockquote>
  <p>SELINUX=disabled</p>
</blockquote>



<h3 id="卸载自带jdk">卸载自带JDK</h3>

<ul>
<li><em>查看自带java版本：</em></li>
</ul>

<p><code>$ java -version</code></p>

<ul>
<li><em>查看具体信息：</em></li>
</ul>

<p><code>$ sudo rpm -qa|grep java</code></p>

<ul>
<li><em>卸载(可以卸载多个）：</em></li>
</ul>

<p><code>$ sudo rpm -e --nodeps ... ... ...</code> <br>
<code>$ sudo rpm -e --nodeps java-1.5.0-gcj-1.5.0.0-29.1.el6.x86_64</code></p>



<h3 id="新建安装目录">新建安装目录</h3>

<p><code>$ sudo mkdir /opt/modules</code> <br>
 <code>$ sudo mkdir /opt/softwares</code> <br>
    为了方便起见，目录新建在root根目录下，需要更改权限</p>

<ul>
<li><p><em>查看权限：</em></p>

<p><code>$ ll /opt/modules</code> <br>
<code>$ ll /opt/softwares</code></p></li>
<li><p><em>更改权限：</em></p>

<p><code>$ sudo chown -R ecloud:ecloud /opt/*</code></p></li>
</ul>



<h3 id="文件传输">文件传输</h3>

<ul>
<li><p><em>windows传输到虚拟机上:</em></p>

<p>windows下载XManager(xshell,xftp)，通过xshell传输文件</p></li>
<li><p><em>lrzsz传输文件</em></p>

<p>Linux下载lrzsz-0.12.20-27.1.el6.x86_64.rpm，安装后 <br>
<code>$ rz</code></p></li>
</ul>



<h3 id="软件的安装rpmtar">软件的安装rpm、tar</h3>

<ul>
<li><p><em>rpm包的安装</em></p>

<p><code>$  rpm -ivh lrzsz-0.12.20-27.1.el6.x86_64.rpm.rpm</code> <br>
(安装过程中显示正在安装的文件信息及安装进度) <br>
<em>zip包的解压</em> <br>
范例： <br>
<code>$ unzip xx.zip -d ...</code> <br>
(-d 目标地址）</p></li>
<li><p><em>jar包的解压</em></p>

<p><code>$ tar -zxvf jdk-7u67-linux-x64.tar.gz -C /opt/modules/</code> <br>
<code>$ tar -zxvf hadoop-2.6.0-cdh5.7.6.tar.gz -C /opt/modules/</code> <br>
（-C 目标地址）</p></li>
<li><p>设置系统全局环境变量 <br>
<code>$ sudo vim /etc/profile</code> <br>
export JAVA_HOME=/opt/modules/jdk-7u67-linux-x64/ <br>
export PATH=<span>$</span>{PATH}:${JAVA_HOME}/bin <br>
export HADOOP_HOME=/opt/modules/hadoop-2.6.0-cdh-5.7.6</p></li>
</ul>

<hr>

<h2 id="安装部署">安装部署</h2>



<h3 id="修改配置文件">修改配置文件</h3>

<p><code>$ cd ${HADOOP_HOME}/etc/hadoop</code></p>

<ul>
<li><p>a. Hadoop Common</p>

<pre><code>hadoop-env.sh  
core-site.xml
</code></pre></li>
<li><p>b. HDFS</p>

<pre><code>hdfs-site.xml
salves
</code></pre></li>
<li><p>c. YARN</p>

<pre><code>yarn-env.sh
yarn-site.xml
</code></pre></li>
<li><p>d. MapReduce</p>

<pre><code>mapred-env.sh
mapred-site.xml  
拷贝 mapred-site.xml.template
</code></pre></li>
</ul>

<p>注意： <br>
HADOOP框架JAR包存放在${HADOOP_HOME}/share/hadoop</p>

<hr>



<h3 id="配置hadoop-common">配置Hadoop Common</h3>

<ul>
<li><p>配置hadoop-env.sh文件 <br>
<code>$ vim hadoop-env.sh</code> <br>
<code>$ vim yarn-env.sh</code> <br>
<code>$ vim mapred-env.sh</code> <br>
export JAVA_HOME=/opt/modules/jdk1.7.0_67</p></li>
<li><p>配置core-site.xml文件 <br>
<code>$ vim core-site.xml</code> <br>
指定文件系统为HDFS及NameNode主节点所运行的机器和端口号</p></li>
</ul>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>
        fs.defaultFS
    <span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>
        hdfs://bigdata-hadoop.eclound.com:8020
    <span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>

<p>指定HDFS文件系统的本地的临时目录，默认值为当前系统的/tmp</p>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>
        hadoop.tmp.dir
    <span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>
        /opt/modules/hadoop-2.7.3/data/tmpData
    <span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>

<p>创建对应的目录 <br>
<code>$ cd ${HADOOP_HOME}/</code> <br>
<code>$ mkdir -p data/tmpData</code></p>

<hr>



<h3 id="配置hdfs">配置HDFS</h3>

<ul>
<li>配置hdfs-site.xml文件 <br>
<code>$ vim hdfs-site.xml</code> <br>
HDFS文件系统存储文件，将文件划分为一块一块的方式进行存储，称为block，每个block的大小为128MB（此版本的默认大小），并且每个block有三个副本，存储在不同的dataNode上，此处是伪分布式一台机器，设置副本为1即可。  (实际情况根据需求设置block副本数）</li>
</ul>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-title">val
</span>&lt;/<span class="hljs-attribute">property</span>&gt;</span></code></pre>

<ul>
<li>配置slaves文件 <br>
指明DataNodes节点运行的机器 <br>
<code>$ vim slaves</code></li>
</ul>



<pre class="prettyprint"><code class=" hljs avrasm">bigdata-hadoop<span class="hljs-preprocessor">.eclound</span><span class="hljs-preprocessor">.com</span></code></pre>

<ul>
<li><p>启动HDFS服务 <br>
a. 格式文件系统(第一次启动需要格式化） <br>
<code>$ bin/hdfs namenode -format</code> <br>
b. 启动服务 <br>
NameNode: <br>
<code>$ sbin/hadoop-daemon.sh start namenode</code> <br>
DataNode: <br>
<code>$ sbin/hadoop-daemon.sh start datanode</code> <br>
c. 验证  <br>
方式一： <br>
<code>$ jps</code> <br>
2916 DataNode <br>
2866 NameNode <br>
方式二： <br>
WEB UI监控页面： <br>
<a href="http://namenode-address:50070" rel="nofollow" target="_blank">http://namenode-address:50070</a></p></li>
<li><p>测试HDFS <br>
创建目录 <br>
<code>$ bin/hdfs dfs -mkdir -p /conf/tmp</code> <br>
例举目录下文件 <br>
<code>$ bin/hdfs dfs -ls -R /</code> <br>
上传文件 <br>
<code>$ bin/hdfs dfs -put etc/hadoop/core-site.xml /conf/tmp</code> <br>
读取HDFS上小文件内容 <br>
<code>$ bin/hdfs dfs -text /conf/tmp/core-site.xml</code> <br>
下载HDFS上文件 <br>
<code>$ bin/hdfs dfs -get /conf/tmp/core-site.xml get-site.xml</code> <br>
删除文件 <br>
<code>$ bin/hdfs dfs -rm /conf/tmp/core-site.xml</code></p></li>
</ul>

<hr>



<h3 id="配置yarn">配置YARN</h3>

<ul>
<li>配置yarn-site.xml文件 <br>
<code>$ vim yarn-site.xml</code></li>
</ul>

<p>指定ResourceManager运行的主机</p>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>
           yarn.resourcemanager.hostname
    <span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>
        bigdata-hadoop.eclound.com
    <span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>

<p>配置nodemanager所属的shuffle服务，运行MapReduce需要</p>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>
        yarn.nodemanager.aux-services
    <span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>
        mapreduce_shuffle
    <span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>

<ul>
<li><p>启动YARN的服务 <br>
主节点： <br>
<code>$ sbin/yarn-daemon.sh start resourcemanager</code> <br>
从节点: <br>
<code>$ sbin/yarn-daemon.sh start nodemanager</code></p></li>
<li><p>验证 <br>
WEB UI 界面： <br>
<a href="http://resourcemanager-address:8088/" rel="nofollow" target="_blank">http://resourcemanager-address:8088/</a></p></li>
</ul>

<hr>



<h3 id="配置mrjobhistory-历史服务器">配置MRJobHistory[ 历史服务器 ]</h3>

<ul>
<li>配置mapred-site.xml文件</li>
</ul>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.framework.name <span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>
        mapreduce.jobhistory.address
    <span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>
        bigdata-hadoop.eclound.com:10020
    <span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>
        mapreduce.jobhistory.webapp.address
    <span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>
        bigdata-hadoop.eclound.com:19888
    <span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>

<ul>
<li>启动服务 <br>
<code>$ sbin/mr-jobhistory-daemon.sh start historyserver</code></li>
<li>验证： <br>
WEB UI 界面： <br>
<a href="http://mr-job-history-address:19888/" rel="nofollow" target="_blank">http://mr-job-history-address:19888/</a></li>
</ul>

<hr>



<h3 id="配置日志聚集功能">配置日志聚集功能</h3>

<p>当我们去查看已经运行完成的MapReduce任务的监控信息的时候，出现如下错误：Aggregation is not enabled <br>
默认情况下，我们运行MR任务完成以后，它的AppMaster和所有的Task日志实际所运行的NodeManager节点目录 <br>
Aggregation： <br>
表示的是将日志信息放到HDFS文件系统上。</p>

<ul>
<li>配置yarn-site.xml文件</li>
</ul>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.log-aggregation-enable<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>
            yarn.log-aggregation.retain-seconds
        <span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>
            604800
        <span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>
            yarn.log-aggregation.retain-check-interval-seconds
        <span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>
            86400
        <span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>

<ul>
<li>重启服务 <br>
YARN 服务全部重启 <br>
MRJobHistoryServer 服务也要重启</li>
</ul>



<h3 id="测试运行mapreduce">测试运行MapReduce</h3>

<p><code>$ bin/yarn xxx.jar xx.class input output</code></p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>