---
layout:     post
title:      flume学习的总结
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<div style="font-family:Tahoma;font-size:14px;"><span style="font-family:Arial, Helvetica, sans-serif;font-size:12px;">最近刚开始接触并使用flume，之前只是知道flume是用于日志收集的系统，没怎么系统研究过，最近工作中要用到flume，感觉还是flume的功能还是非常强大的，官网上有个非常详细的介绍，我觉得还是看看官网的介绍就足够了，比在网上搜到的东西讲的都好，要养成看官网文档的习惯：</span><a href="http://flume.apache.org/FlumeUserGuide.html" rel="nofollow">http://flume.apache.org/FlumeUserGuide.html</a></div>
<div style="font-family:Tahoma;font-size:14px;"><br></div>
<div style="font-family:Tahoma;font-size:14px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">flume是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。</span><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">支持在日志系统中定制各类</span><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><a href="http://cpro.baidu.com/cpro/ui/uijs.php?c=news&amp;cf=1001&amp;ch=0&amp;di=128&amp;fv=16&amp;jk=7d469efe166c2a71&amp;k=%CA%FD%BE%DD&amp;k0=%CA%FD%BE%DD&amp;kdi0=0&amp;luki=1&amp;n=10&amp;p=baidu&amp;q=92051019_cpr&amp;rb=0&amp;rs=1&amp;seller_id=1&amp;sid=712a6c16fe9e467d&amp;ssp2=1&amp;stid=0&amp;t=tpclicked3_hc&amp;tu=u1692056&amp;u=http%3A%2F%2Fwww.aboutyun.com%2Fthread-8917-1-1.html&amp;urlid=0" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;"><span style="color:rgb(0,0,255);">数据</span></a></span><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">发送方，用于收集数据;同时，Flume提供对数据进行简单处理，并写到各种数据接受方(比如文本、HDFS、Hbase等)的能力，</span><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">flume的数据流由事件(Event)贯穿始终。事件是Flume的基本数据单位，它携带日志数据(字节数组形式)并且携带有头信息，这些Event由Agent外部的Source生成，当Source捕获事件后会进行特定的格式化，然后Source会把事件推入(单个或多个)Channel中。你可以把Channel看作是一个缓冲区，它将保存事件直到Sink处理完该事件。Sink负责持久化日志或者把事件推向另一个Source。</span></div>
<div style="font-family:Tahoma;font-size:14px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><br></span></div>
<div style="font-family:Tahoma;font-size:14px;"><span style="font-weight:700;color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">flume的一些核心概念：</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><ul style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><li style="list-style:decimal;">
Agent        使用JVM 运行Flume。每台机器运行一个agent，但是可以在一个agent中包含多个sources和sinks。</li><li style="list-style:decimal;">
Client        生产数据，运行在一个独立的线程。</li><li style="list-style:decimal;">
Source        从Client收集数据，传递给Channel。</li><li style="list-style:decimal;">
Sink        从Channel收集<span><a href="http://cpro.baidu.com/cpro/ui/uijs.php?c=news&amp;cf=1001&amp;ch=0&amp;di=128&amp;fv=16&amp;jk=7d469efe166c2a71&amp;k=%CA%FD%BE%DD&amp;k0=%CA%FD%BE%DD&amp;kdi0=0&amp;luki=1&amp;n=10&amp;p=baidu&amp;q=92051019_cpr&amp;rb=0&amp;rs=1&amp;seller_id=1&amp;sid=712a6c16fe9e467d&amp;ssp2=1&amp;stid=0&amp;t=tpclicked3_hc&amp;tu=u1692056&amp;u=http%3A%2F%2Fwww.aboutyun.com%2Fthread-8917-1-1.html&amp;urlid=0" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;"><span style="color:rgb(0,0,255);">数据</span></a></span>，运行在一个独立线程。</li><li style="list-style:decimal;">
Channel        连接 sources 和 sinks ，这个有点像一个队列。</li><li style="list-style:decimal;">
Events        可以是日志记录、 avro 对象等。</li></ul><div><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;color:#444444;"><span style="font-size:14px;line-height:21px;"><br></span></span></div>
</div>
<div style="font-family:Tahoma;font-size:14px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">Flume以agent为最小的独立运行单位。一个agent就是一个JVM。单agent由Source、Sink和Channel三大组件构成，如下图：</span></div>
<div style="font-family:Tahoma;font-size:14px;"><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><img src="http://flume.apache.org/_images/UserGuide_image00.png" alt=""><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">
 <br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">　　值得注意的是，Flume提供了大量内置的Source、Channel和Sink类型。不同类型的Source,Channel和Sink可以自由组合。组合方式基于用户设置的配置文件，非常灵活。比如：Channel可以把事件暂存在内存里，也可以持久化到本地硬盘上。Sink可以把日志写入HDFS,
 HBase，甚至是另外一个Source等等。Flume支持用户建立多级流，也就是说，多个agent可以协同工作，并且支持Fan-in、Fan-out、Contextual Routing、Backup Routes，这也正是NB之处。如下图所示:</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><br><img src="http://flume.apache.org/_images/UserGuide_image01.png" alt=""><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><br></div>
<div style="font-family:Tahoma;font-size:14px;"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;color:#444444;"><span style="font-size:14px;line-height:21px;"><br></span></span></div>
<div style="font-family:Tahoma;font-size:14px;"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;color:#444444;"><span style="font-size:14px;line-height:21px;">从上面两个图可以看出来，flume其实非常强大，他可以支持从一个目录或流中收集数据，进行处理之后输出到hdfs或本地文件系统，也可以作为另外一个flume的数据源(source),</span></span></div>
<div style="font-family:Tahoma;font-size:14px;"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;color:#444444;"><span style="font-size:14px;line-height:21px;">我这边有个需求就是收集不同节点上收集的数据，将其汇总后，不同格式的数据取不同的字段，然后写到ftp不同的目录中，因为前期不同节点上也是部署这单独的flume
 agent用于收集和处理数据入hdfs的，sink直接指向了hdfs，那么我这里需要做的就是在那两台flume 的agent上多加一个channel和sink，传到ftp上传的那个flume上</span></span></div>
<div style="font-family:Tahoma;font-size:14px;"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;color:#444444;"><span style="font-size:14px;line-height:21px;"><br></span></span></div>
<p><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;color:#444444;"><span style="font-size:14px;line-height:21px;">a1节点flume agent配置如下：</span></span></p>
<p><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;color:#444444;"><span style="font-size:14px;line-height:21px;">agent-a.channels = ch-1 ch-2<br>
agent-a.sources = src-1<br>
agent-a.sinks = avro-sink ftp-sink<br><br>
agent-a.channels.ch-1.type = memory<br>
agent-a.channels.ch-1.capacity = 10000<br>
agent-a.channels.ch-1.transactionCapacity  = 1000<br>
agent-a.channels.ch-1.byteCapacityBufferPercentage = 20<br>
agent-a.channels.ch-1.byteCapacity = 800000<br>
agent-a.channels.ch-1.checkpointDir = /home/hadoop/apache-flume-1.5.0.1-bin/data/a/checkpointDir<br>
agent-a.channels.ch-1.dataDirs = /home/hadoop/apache-flume-1.5.0.1-bin/data/a/dataDirs<br><br>
agent-a.channels.ch-2.type = memory<br>
agent-a.channels.ch-2.capacity = 10000<br>
agent-a.channels.ch-2.transactionCapacity  = 1000<br>
agent-a.channels.ch-2.byteCapacityBufferPercentage = 20<br>
agent-a.channels.ch-2.byteCapacity = 800000<br>
agent-a.channels.ch-2.checkpointDir = /home/hadoop/apache-flume-1.5.0.1-bin/data/a/ftpcheckpointDir<br>
agent-a.channels.ch-2.dataDirs = /home/hadoop/apache-flume-1.5.0.1-bin/data/a/ftpdataDirs<br><br>
agent-a.sinks.avro-sink.type = avro<br>
agent-a.sinks.avro-sink.hostname = hostname_a<br>
agent-a.sinks.avro-sink.port = 1422<br>
agent-a.sinks.avro-sink.channel = ch-1<br><br>
agent-a.sinks.ftp-sink.type = avro<br>
agent-a.sinks.ftp-sink.hostname = hostname_ftp<br>
agent-a.sinks.ftp-sink.port = 1422<br>
agent-a.sinks.ftp-sink.channel = ch-2<br><br>
agent-a.sources.src-1.type = spooldir<br>
agent-a.sources.src-1.channels = ch-1 ch-2<br>
agent-a.sources.src-1.spoolDir = /data/html/030.100.000.001/<br>
agent-a.sources.src-1.fileHeader = true<br>
agent-a.sources.src-1.fileHeaderKey = filename<br>
agent-a.sources.src-1.deletePolicy = immediate<br></span></span></p>
<p><span style="font-size:14px;line-height:21px;color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;"><br></span></p>
<p><span style="font-size:14px;line-height:21px;color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;">a2节点的配置如下：</span></p>
<p><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;color:#444444;"><span style="font-size:14px;line-height:21px;">agent-b.channels = ch-2 ch-1 ch-3<br>
agent-b.sources = src-1<br>
agent-b.sinks = tab-sink avro-sink ftp-sink<br><br>
agent-b.channels.ch-1.type = file<br>
agent-b.channels.ch-1.capacity = 10000<br>
agent-b.channels.ch-1.transactionCapacity  = 5000<br>
agent-b.channels.ch-1.byteCapacityBufferPercentage = 20<br>
agent-b.channels.ch-1.byteCapacity = 80000<br>
agent-b.channels.ch-1.checkpointDir = /home/hadoop/apache-flume-1.5.0.1-bin/channel/checkpointDir_hdfs<br>
agent-b.channels.ch-1.dataDirs = /home/hadoop/apache-flume-1.5.0.1-bin/channel/dataDirs_hdfs<br><br><br>
agent-b.channels.ch-2.type = file<br>
agent-b.channels.ch-2.capacity = 10000 <br>
agent-b.channels.ch-2.transactionCapacity  = 5000  <br>
agent-b.channels.ch-2.byteCapacityBufferPercentage = 20<br>
agent-b.channels.ch-2.byteCapacity = 80000 <br>
agent-b.channels.ch-2.checkpointDir = /home/hadoop/apache-flume-1.5.0.1-bin/checkpointDir_hbase<br>
agent-b.channels.ch-2.dataDirs = /home/hadoop/apache-flume-1.5.0.1-bin/channel/dataDirs_hbase<br><br>
agent-b.channels.ch-3.type = file<br>
agent-b.channels.ch-3.capacity = 10000 <br>
agent-b.channels.ch-3.transactionCapacity  = 5000  <br>
agent-b.channels.ch-3.byteCapacityBufferPercentage = 20<br>
agent-b.channels.ch-3.byteCapacity = 80000 <br>
agent-b.channels.ch-3.checkpointDir = /home/hadoop/apache-flume-1.5.0.1-bin/checkpointDir_ftp<br>
agent-b.channels.ch-3.dataDirs = /home/hadoop/apache-flume-1.5.0.1-bin/channel/dataDirs_ftp<br><br>
agent-b.sinks.avro-sink.type = avro<br>
agent-b.sinks.avro-sink.hostname = 192.168.10.14<br>
agent-b.sinks.avro-sink.port = 1422<br>
agent-b.sinks.avro-sink.channel = ch-1<br><br>
agent-b.sinks.tab-sink.debug = true<br>
agent-b.sinks.tab-sink.batchSize = 1000<br>
agent-b.sinks.tab-sink.channel = ch-2<br>
****<br><br>
agent-b.sinks.ftp-sink.type = avro<br>
agent-b.sinks.ftp-sink.hostname = hostname_ftp<br>
agent-b.sinks.ftp-sink.port = 1422<br>
agent-b.sinks.ftp-sink.channel = ch-3<br><br>
agent-b.sources.src-1.type = spooldir<br>
agent-b.sources.src-1.channels = ch-2 ch-1 ch-3<br>
agent-b.sources.src-1.deserializer = LINE<br>
#agent-b.sources.src-1.spoolDir = /data/empty/<br>
agent-b.sources.src-1.spoolDir = /data/b/bcp/<br>
agent-b.sources.src-1.fileHeader = true<br>
agent-b.sources.src-1.fileHeaderKey = filename<br>
agent-b.sources.src-1.deletePolicy = never<br></span></span></p>
<p><span style="font-size:14px;line-height:21px;color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;">在上传ftp的flume节点的配置如下:</span></p>
<p><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;color:#444444;"><span style="font-size:14px;line-height:21px;">uploadtoftp.channels = ch-3<br>
uploadtoftp.sources = src-1<br>
uploadtoftp.sinks = ftp-sink<br><br>
uploadtoftp.channels.ch-3.type = file<br>
uploadtoftp.channels.ch-3.capacity = 10000<br>
uploadtoftp.channels.ch-3.transactionCapacity  = 5000<br>
uploadtoftp.channels.ch-3.byteCapacityBufferPercentage = 20<br>
uploadtoftp.channels.ch-3.byteCapacity = 80000<br>
uploadtoftp.channels.ch-3.checkpointDir = /home/hadoop/lx/data/channel/checkpointDir_hdfs<br>
uploadtoftp.channels.ch-3.dataDirs = /home/hadoop/lx/data/channel/dataDirs_hdfs<br><br>
uploadtoftp.sources.src-1.type = avro<br>
uploadtoftp.sources.src-1.bind = 0.0.0.0<br>
uploadtoftp.sources.src-1.port = 1423<br>
uploadtoftp.sources.src-1.channels = ch-3<br><br>
uploadtoftp.sinks.ftp-sink.type = file_roll<br>
uploadtoftp.sinks.ftp-sink.sink.directory = /home/hadoop/lx/data-output<br>
uploadtoftp.sinks.ftp-sink.channel = ch-3<br><br>
uploadtoftp.sinks.ftp-sink.type = com.lx.filesink.MultiFileSink<br>
uploadtoftp.sinks.ftp-sink.file.path = /home/hadoop/lx/data-output/flume/lx_mysink/%y-%m-%d<br>
uploadtoftp.sinks.ftp-sink.file.filePrefix = lxtestlog-%{y}%{m}-%{d}-<br>
uploadtoftp.sinks.ftp-sink.file.srctype = air1,air2<br>
uploadtoftp.sinks.ftp-sink.extractIndexs.air1 = 3,6,7,9,13,14<br>
uploadtoftp.sinks.ftp-sink.extractIndexs.air2 = 4,5,6,7<br>
uploadtoftp.sinks.ftp-sink.typeIndexs.air1 = 0<br>
uploadtoftp.sinks.ftp-sink.typeIndexs.air2 = 0<br>
uploadtoftp.sinks.ftp-sink.ftp.url = ftp-url<br>
uploadtoftp.sinks.ftp-sink.ftp.port = ftp-port<br>
uploadtoftp.sinks.ftp-sink.ftp.user = ftp-user<br>
uploadtoftp.sinks.ftp-sink.ftp.passwd = ftp-passwd<br>
uploadtoftp.sinks.ftp-sink.file.ftppath = /lxtest/data/<br>
uploadtoftp.sinks.ftp-sink.file.localtmppath = /home/hadoop/lx/data-output/ftpsink-out/<br>
uploadtoftp.sinks.ftp-sink.file.useLocalTimeStamp = true<br>
uploadtoftp.sinks.ftp-sink.file.txnEventMax = 10000<br>
uploadtoftp.sinks.ftp-sink.file.maxOpenFiles = 5<br></span></span></p>
<p><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;color:#444444;"><span style="font-size:14px;line-height:21px;"><br></span></span></p>
<p><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;color:#444444;"><span style="font-size:14px;line-height:21px;">其中MultiFileSink为自定义的一个ftp多目录输出的yigeflume sink，当然涉及到ftp-sink.*的这些配置都是在自定义方法中的输入参数context中设置的，不同的数据做不同处理的逻辑也是在<span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">MultiFileSink中处理的。</span></span></span></p>
<p><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;color:#444444;"><span style="font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><br></span></span></span></p>
<p><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;color:#444444;"><span style="font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">之前一直想不明白ftp节点是如何接收数据的，自己做了个简单的实验，配置source.type=arvo
 hostname port之后，在本地监听1422端口，就发现启动agent之后，也会启动一个1422的端口的实例，应该是用于接收数据了，当然要验证的话也很简单，将以上的三个配好测一下就ok。</span></span></span></p>
<p><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;color:#444444;"><span style="font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><br></span></span></span></p>
            </div>
                </div>