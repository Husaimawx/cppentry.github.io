---
layout:     post
title:      Flume核心概念
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<div style="background-color:inherit;"><span></span>Flume是Cloudera提供的日志收集系统，具有分布式、高可靠、高可用性等特点，对海量日志采集、聚合和传输，Flume支持在日志系统中定制各类数据发送方，同时，Flume提供对数据进行简单处理，并写到各种数据接受方的能力。</div>
<div style="background-color:inherit;">        </div>
<div style="background-color:inherit;">        Flume传输的数据的基本单位是Event，如果是文本文件，通常是一行记录，这也是事务的基本单位。Event从Source，流向Channel，再到Sink，本身是一个byte数组，并可携带headers信息。Evnet代表着一个数据流的最小完整单元，从外部数据源来，向外部的目的地去。</div>
<div style="background-color:inherit;"><br style="background-color:inherit;"></div>
<div style="background-color:inherit;"><br style="background-color:inherit;"></div>
<div style="background-color:inherit;">        Flume运行的核心是Agent，它是一个完整的数据收集工具，含有三个核心组件、分别是Source、Channel、Sink。通过这些组件，Event可以从一个地方流向另一个地方。</div>
<div style="background-color:inherit;">        <img src="https://img-blog.csdn.net/20160527105905375" alt=""></div>
<strong></strong>
<div style="background-color:inherit;font-size:14px;"><strong><span style="font-size:14px;background-color:inherit;"><br style="background-color:inherit;"></span></strong></div>
<span style="font-size:18px;background-color:inherit;">Flume的优点</span>
<div style="background-color:inherit;"><span style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="font-size:18px;background-color:inherit;line-height:27px;">    </span><span style="font-size:14px;background-color:inherit;line-height:1.5;"> 可靠性</span></span>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">
<div>            Flume的核心是把数据从数据源手机过来，再送到目的地。为了保证输送一定成功，在送到目的地之前，会先缓冲数据，待数据真正到达目的地后，删除自己缓存的数据。</div>
<div>            Flume使用事务性的方式保证传送Event整个过程的可靠性。Sink必须在Event被存入Channel后，或者，已经被传送到下一站Agent里，又或者，已经被存入外部数据目的地之后，才能把Event从Channel中remove掉。这样数据流里的event无论是在一个agent里还是多个agent之间流传，都能保证可靠，因为以上的事务保证了event会被成功存储起来。而Channel的多种实现在可恢复性又不同的保证。也保证了Event不同程度的可靠性。比如支持本地保存一份文件channel作为备份，而memorychannel将event存在内存queue里，速度快，但丢失的话无法恢复。</div>
<div><strong><span style="font-size:14px;background-color:inherit;"><br style="background-color:inherit;"></span></strong></div>
<div><strong><span style="font-size:14px;background-color:inherit;">    可恢复性    </span></strong></div>
<div><span style="font-size:14px;background-color:inherit;"><strong>           </strong></span>通过File Channel。因为File Channel会把事件持久化在本地磁盘中。</div>
<div><br style="background-color:inherit;"></div>
<div><br style="background-color:inherit;"></div>
<strong><span style="font-size:14px;background-color:inherit;">    可扩展性</span></strong>
<div>            Flume采用了三层架构，分别为agent、collector和storage，每一层都可以水平扩展。所有agent和collector由master同一管理，这使得系统容易监控和维护，且master也许有多个（使用Zookeeper进行管理和负载均衡），避免了单点故障问题。</div>
<div>
<div style="background-color:inherit;"><br style="background-color:inherit;"></div>
<div style="background-color:inherit;"><br style="background-color:inherit;"></div>
</div>
<strong><span style="font-size:14px;background-color:inherit;">    可管理性</span></strong>       <span style="background-color:inherit;">        </span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="background-color:inherit;">            所有agent和colletor由master统一管理</span><span style="background-color:inherit;">，这使得系统便于维护。多master情况，Flume利用ZooKeeper和gossip，保证动态配置数据的一致性。用户可以在master上查看各个数据源或者数据流执行情况，且可以对各个数据源配置和动态加载。Flume提供了web
 和shell script command两种形式对数据流进行管理。</span><br style="background-color:inherit;"></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">            Source可以接受外部源发送过来的数据。不同的source，可以接受不同的数据格式。比如目录池（spooling directory）数据源，可以监控指定文件夹中的新文件变化，如果目录中有文件产生，就会立刻读取其中的内容。</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">            Channel是一个存储地，接受Source的输出，直到有Sink消费掉Channel中的数据。Channel中的数据直到进入到下一个Channel中或者进入终端才会被删除。当Sink写入失败后，可以自动重启，不会造成数据丢失，因此可靠。</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">            Sink会消费Channel中的数据，然后送给外部源或者其他Source。如数据可以写入到HDFS或者HBASE中。</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="background-color:inherit;line-height:1.5;"><br style="background-color:inherit;"></span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="background-color:inherit;line-height:1.5;">            日志收集中的一个非常常见的场景是大量的日志生成客户端发送数据到存储子系统中的一些用户代理。例如，从Web服务器日志收集数百个代理发送写HDFS集群。</span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">
<div><img src="https://img-blog.csdn.net/20160527110024345" alt=""><br style="background-color:inherit;"></div>
<div>        </div>
</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">
<p style="font-family:Simsun;text-align:justify;">
<span style="background-color:inherit;"><span style="font-size:18px;background-color:inherit;"><span style="line-height:1.5;">Flume核心</span><span style="line-height:1.5;">组件：</span></span></span></p>
<p style="font-family:Simsun;font-size:16px;text-align:justify;">
<span style="line-height:1.5;">    <span style="color:#ff0000;background-color:inherit;"><span style="background-color:inherit;">Source</span></span></span></p>
<p style="font-family:Simsun;font-size:16px;text-align:justify;">
<span style="line-height:1.5;">        Client端操作消费数据的来源。</span><span style="line-height:1.5;">Flume</span><span style="font-size:14px;line-height:1.5;">支持下面的机制来读取数据从流行的日志流类型，如：</span></p>
<ol style="font-family:Simsun;font-size:16px;"><li><ol style="background-color:inherit;"><li style="background-color:inherit;"><span style="text-align:justify;line-height:1.5;">Avro</span></li><li style="background-color:inherit;"><span style="text-align:justify;line-height:1.5;">Thrift</span></li><li style="background-color:inherit;">Syslog</li><li style="background-color:inherit;text-align:justify;">Netcat</li></ol></li></ol></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">    <img src="https://img-blog.csdn.net/20160527110103011" alt=""></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="background-color:inherit;line-height:1.5;"></span>
<p style="background-color:inherit;">        Flume支持复用事件流到一个或多个目的地。这是通过定义一个可以复制或有选择地将事件路由到一个或多个通道的流多路复用器来实现的。</p>
</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><img src="https://img-blog.csdn.net/20160527110109277" alt=""><br style="background-color:inherit;"></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">     <span style="font-size:18px;background-color:inherit;"><span style="background-color:inherit;">对于直接读取文件Source，有两种方式：</span></span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">            <span style="color:#ff0000;background-color:inherit;">ExecSource</span>：以运行Linux命令的方式，持续的输出最新的数据，such as：<span style="color:#ff0000;background-color:inherit;">tail -F 文件名 </span><span style="line-height:1.5;">指令，在这种方式下，读取的文件名必须是指定的，
 ExecSource可以实现对日志的实时收集，但是存在Flume不运行或者指令执行错误时，将无法收集到日志数据，无法保证日志数据的完整性。</span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="line-height:1.5;">            <span style="color:#ff0000;background-color:inherit;">SpoolSource</span>：检测配置的目录下新增的文件，并将文件中的数据读取出来。</span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="line-height:1.5;">                注意：拷贝到spool目录下的文件不可以再打开编辑；spool目录下不可以包含想要的子目录。SpoolSource虽然无法实现的收集数据，但是可以使用以分钟的方式分割文件，趋近于实时。如果应用无法实现以分钟切割日志文件的话，可以两种收集方式结合。也可以使用log4j，将文件分割机制设为1分钟一次，将文件拷贝到spool的监控目录。使用TimeRolling插件，可以把log4j分割文件到spool目录。基本实现实时监控。</span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="line-height:1.5;">            * 被Flume修改后的文件，后缀会变为.COMPLETED</span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="line-height:1.5;"><br style="background-color:inherit;"></span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="line-height:1.5;">    </span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><br style="background-color:inherit;"></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">    <span style="background-color:inherit;"><span style="color:#ff0000;background-color:inherit;">Channel</span></span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="line-height:1.5;">        channel有（Memory Channel、JDBC Channel、File Channel、Psuedo Transaction Channel)</span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="line-height:1.5;">        1.  MemoryChannel可以实现高速的吞吐，但是无法保证数据的完整性。</span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="line-height:1.5;">        2.  MemoryChannel被FileChannel替换。</span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="line-height:1.5;">        3.  FileChannel保证数据的完整性于一致性。在具体配置FileChannel时，把FileChannel设置的目录和程序日志文件保存的目录设成不同的磁盘，以便提高效率。</span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="line-height:1.5;">        FileChannel是一个持久化的隧道（channel），它持久化所有的事件，并将其存储到磁盘中。因此，即使Java虚拟机宕机，或者系统崩溃重启，再或者事件没有在管道中成功传递到下一个代理（agent），都不会造成数据丢失。只要磁盘空间足够，就可以将所有事件数据存储到磁盘上。  
   </span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="line-height:1.5;">        MemoryChannel是一个不稳定的隧道（channel），因为它在内存中存储所有事件，如果Java进程死掉，任何存储在内存的事件将会丢失。而且内存的空间受到RAM大小的限制。</span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><br style="background-color:inherit;"></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">   <span style="background-color:inherit;"><span style="color:#ff0000;background-color:inherit;"> Sink</span></span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">        Sink在设置存储事件时，可以向文件系统、数据库、hdfs存数据，在日志数据较少时，可以将数据存储在文件系统中，并且设定一定的时间间隔保存数据。在日志数据较多时，可以将相应的日志数据存储到hdfs中，方便日后进行相应的数据分析。</div>
<div><br></div>
</div>
            </div>
                </div>