---
layout:     post
title:      如何安装spark
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p><span style="font-size:18px;">第一步：</span></p>
<p><span style="font-size:18px;">Spark官网下载相应版本的spark，http://spark.apache.org/</span></p>
<p><span style="font-size:18px;">第二步：</span></p>
<p><span style="font-size:18px;">解压安装spark</span></p>
<p><span style="font-size:18px;"><code>sudo tar -zxf spark-2.0.0-bin-hadoop2.7.tgz -C /usr/local</code></span></p>
<p><span style="font-size:18px;">第三步：</span></p>
<p><span style="font-size:18px;">重命名</span></p>
<p></p><pre class="shell"><span style="font-size:18px;"><code class="hljs bash"><span class="hljs-built_in">cd</span> /usr/<span class="hljs-built_in">local</span>
sudo mv spark-2.0.0-bin-hadoop2.7 spark</code></span></pre><span style="font-size:18px;">第四步：</span>
<p><span style="font-size:18px;">声明环境变量，并修改权限</span></p>
<p></p><pre class="shell"><span style="font-size:18px;"><code class="hljs bash">sudo vim /etc/profile
<span class="hljs-comment"># 添加以下内容</span>
<span class="hljs-built_in">export</span> SPARK_HOME=/usr/<span class="hljs-built_in">local</span>/spark
<span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$SPARK_HOME</span>/bin:<span class="hljs-variable">$SPARK_HOME</span>/sbin:<span class="hljs-variable">$PATH</span></code></span></pre>
<p><span style="font-size:18px;">在local文件路径下修改权限</span></p>
<p></p><pre class="shell"><span style="font-size:18px;"><code class="hljs perl">cd /usr/<span class="hljs-keyword">local</span></code></span></pre>
<p></p><pre class="shell"><span style="font-size:18px;"><code class="hljs perl">sudo <span class="hljs-keyword">chown</span> -R yourusername:yourusername ./spark   #其中yourusername为你的计算机名字

<span style="font-size:24px;">第五步：
修改配置文件</span>
</code></span></pre><pre class="shell"><code class="hljs dts">cd <span class="hljs-meta-keyword">/usr/</span>local/spark
cp .<span class="hljs-meta-keyword">/conf/</span>spark-env.sh.template .<span class="hljs-meta-keyword">/conf/</span>spark-env.sh

</code></pre><pre class="shell"><code class="hljs dts">vim .<span class="hljs-meta-keyword">/conf/</span>spark-env.sh
<span class="hljs-meta"># 添加以下内容</span>
export SPARK_DIST_CLASSPATH=$(<span class="hljs-meta-keyword">/<span style="color:#CC0000;">path</span></span><span class="hljs-meta-keyword">/hadoop/</span>bin/hadoop classpath)
export JAVA_HOME=<span class="hljs-meta-keyword">/<span style="color:#FF0000;">path</span></span><span class="hljs-meta-keyword">/jvm/</span>jdk</code></pre>#其中的path为你的hadoop和java安装路径，可以用echo $HADOOP_HOME 和echo $JAVA_HOME查看<br><pre></pre>
<span style="font-size:24px;">第六步：</span><br><span style="font-size:18px;"><code>/usr/local/spark/bin/run-example SparkPi 2&gt;&amp;1 | grep "Pi is roughly"</code></span><span style="font-size:18px;"><br></span><span style="font-size:18px;">启动Spark</span><span style="font-size:18px;"><code></code></span><span style="font-size:18px;"><code><br>
usr/local/spark/sbin/start-all.sh<br></code></span><span style="font-size:18px;"><code class="hljs perl"></code></span><span style="font-size:18px;"><code class="hljs perl"></code></span>
<pre></pre>
<span style="font-size:18px;">浏览器中输入地址:<code>localhost:8080</code></span><br><p></p>
            </div>
                </div>