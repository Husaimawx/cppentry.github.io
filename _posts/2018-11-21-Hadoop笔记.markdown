---
layout:     post
title:      Hadoop笔记
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/yy15642766973/article/details/79825091				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <span style="font-size:18px;">Hadoop笔记 linux中搭建hadoop开发环境<br><br>hadoop是什么？<br></span><p><span style="font-size:18px;">hadoop是一个平台，是一个适合大数据的分布式存储和计算的平台。</span></p><p><span style="font-size:18px;">hadoop核心：1.HDFS；2.MapReduce。</span></p><span style="font-size:18px;">hadoop安装方式|hadoop部署方式<br>hadoop安装方式只有三种：单机安装；伪分布安装；集群安装。<br>单机方式：在一台上安装运行Hadoop系统，<br>伪分布式：在单机上用伪分布方式用不同的Java进程模拟分布运行中的namenode、datanode、jobtracker、tasktracker等各类节点。<br>集群分布：在一个真实的集群环境下运行Hadoop系统，单机模式和和伪分布模式均是用于调试和开发的目的，真正的Hadoop 应用是采用的集群模式。因此我们需要几台服务器主机。<br><br><br><br>0.下载jdk<br>登录网址：http://www.oracle.com/technetwork/java/javase/downloads/<br>选择对应jdk版本下载。（可在Windows下下载完成后，通过文件夹共享到Linux上）<br><br>1.登录Linux，切换到root用户<br><br>2.在usr目录下建立java安装目录<br><br>命令mkdir   usr/java<br><br>3.将jdk-10-linux-x64.tar.gz拷贝到java目录下并解压<br><br>命令：cp    /mnt/hgfs/Ubuntu\ share/jdk-10-linux-x64.tar.gz    /usr/java<br><br></span><p><span style="font-size:18px;">         tar   -zxvf    jdk-10-linux-x64.tar.gz</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20180405113554652" alt=""><br></span></p><span style="font-size:18px;">解压后会生成一个目录：jdk-10，为了便于后期配置java环境变量，我们把这个目录重命名为jdk。<br>命令：mv /usr/java/jdk-10 /usr/java/jdk；<br><br>4.接着配置jdk环境变量，编辑/etc/profile文件。<br>命令：vi /etc/profile<br>添加如下内容：<br>JAVA_HOME=/usr/java/jdk<br>CLASSPATH=$JAVA_HOME/lib/<br>PATH=$PATH:$JAVA_HOME/bin<br>export PATH JAVA_HOME CLASSPATH<br><br></span><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20180405113630296" alt=""></span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/2018040511370144" alt=""><br></span></p><span style="font-size:18px;">重启机器或执行<br>命令：source/etc/profile<br>查看安装情况:java-version<br><img src="https://img-blog.csdn.net/20180405113715784" alt=""><br><br>5.配置ssh无密码认证。<br>执行如下命令：ssh-keygen。此处可以一直敲回车。执行完之后<br>ls /root/.ssh/<br>可以在目录下看见两个密钥这是SSH的一对私钥和公钥，<br>类似于钥匙及锁，把id_dsa.pub（公钥）追加到授权的key里面去。<br>输入命令：<br>cp  /root/.ssh/id_dsa.pub  /root/.ssh/authorized_keys<br>这条命令是把公钥加到用于认证的公钥文件中，这里的authorized_keys是用于认证的公钥文件<br><br></span><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20180405113757921" alt=""></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;">验证SSH是否可以无密码登录本机  ssh localhost</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20180407203818653" alt=""><br></span></p><span style="font-size:18px;">6.解压安装Hadoop<br>官网下载Hadoop  http://mirrors.hust.edu.cn/apache/hadoop/common/<br>拷贝到/usr/java目录下，并解压缩。<br>命令：tar zxvf hadoop-2.9.0.tar.gz；<br>解压后会生成一个名为 hadoop-2.9.0的目录，我们接着把这个目录重命名为hadoop。<br></span><p><span style="font-size:18px;">命令：mv /usr/java/hadoop-2.9.0  /usr/Java/hadoop;</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20180407203913386" alt=""><br></span></p><span style="font-size:18px;">7.接着配置环境变量。（伪分布模式的配置）<br><br>                conf/hadoop-env.sh; Hadoop环境变量<br>                conf/core-site.xml  主要完成namenode的ip和端口设置<br>                conf/hdfs-site.xml  主要完成hdfs的数据块副本等参数设置<br>                conf/mapred-site.xml主要完成jobtrackerip和端口设置<br>                conf/masters        完成master结点ip设置<br></span><p><span style="font-size:18px;">                conf/slaves         完成slaves结点ip设置</span></p><p><span style="font-size:18px;"><br></span></p><span style="font-size:18px;">命令ls /usr/java/hadoop/etc/hadoop/四个配置文件在这里<br>a.指定JDK的安装位置：<br>在Hadoop-env.sh中：<br>export  JAVA_HOME=””<br><img src="https://img-blog.csdn.net/20180407203946192" alt=""><br><br>b.配置HDFS的地址和端口号：<br>在core-site.xml中：<br><br><img src="https://img-blog.csdn.net/20180407204004531" alt=""><br>在mapred-site.xml中：<br>.<br><img src="https://img-blog.csdn.net/20180407204038119" alt=""><br><br>在hdfs-site.xml中：<br><br><br><img src="https://img-blog.csdn.net/20180407204059602" alt=""><br><br><br>格式化Hadoop并启动验证：<br>格式化Hadoop：<br>./bin/hadoop namenode -format<br>启动Hadoop：<br>./bin/start-all.sh(全部启动)<br><br><img src="https://img-blog.csdn.net/20180407204238491" alt=""><br><br>验证Hadoop是否安装成功，打开浏览器，分别输入网址：<br>http://localhost:50030(MapReduce的web页面)<br>http://localhost:50070(HDFS的web页面)<br></span><p><span style="font-size:18px;">若都能查看，说明Hadoop已经安装成功。</span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:24px;">但是但是</span><span style="font-size:18px;">我没有安装成功<img alt="尴尬" src="https://static-blog.csdn.net/xheditor/xheditor_emot/default/awkward.gif">，笔者也是一名新手，安装路上遇到过很多问题，下面来解决问题。</span></p><p><span style="font-size:18px;">以上安装方法也是笔者在网上查到并执行，但是笔者忘了很多的方法也都过时了，拿Hadoop来说，上面的方法是1.0版的，但是我下载的Hadoop是最新版的2.x，1和2的文件配置有很大的不同。</span></p><p><span style="font-size:18px;">下面来讲2.x版本的文件配置</span></p><p><span style="font-size:18px;">a.         在hadoop文件下建立tmp文件</span></p><p><span style="font-size:18px;">            命令    mkdir tmp</span></p><p><span style="font-size:18px;"><span style="font-size:18px;"><span style="font-size:18px;">b.         hdfs-site.xml</span><br></span></span></p><p><span style="font-size:18px;"><span style="font-size:18px;"><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20180411152212129" alt=""><br></span></span></span></p><p><span style="font-size:18px;"><span style="font-size:18px;">c.       core-site.xml</span><br></span></p><p><span style="font-size:18px;"><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20180411152611132" alt=""><br></span></span></p><p><span style="font-size:18px;"><span style="font-size:18px;"><span style="font-size:18px;">d.    mapred-site.xml.template</span><br></span></span></p><p><span style="font-size:18px;"><span style="font-size:18px;"><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20180411152851868" alt=""><br></span></span></span></p><p><span style="font-size:18px;"><span style="font-size:18px;">e.    多了一个文件配置yarn-site.xml，版本1是没有的。</span></span></p><p><span style="font-size:18px;"><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20180411152953519" alt=""><br></span></span></p><p><span style="font-size:18px;">f.    格式化和启动也有所不同</span></p><p><span style="font-size:18px;"><span style="font-size:18px;">      格式化  ./hdfs namenode -format</span><br></span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20180411153013187" alt=""><br></span></p><p>说明格式化成功了</p><p><span style="font-size:18px;">  </span></p><p><span style="font-size:18px;">g.  启动     </span><span style="font-size:18px;">Hadoop版本1在bin目录下，版本2在sbin下面  </span><span style="font-size:18px;">sbin#</span><span style="font-size:18px;">    ./start-hfs.sh     start-yarn.sh</span></p><p><span style="font-size:18px;"><br></span></p><p>hadoop2以后没有tasktracker 与jobtracker 了，</p><p>详细参考：yarn详解：http://www.aboutyun.com/thread-7678-1-1.html</p><p>这个让你明白为什么没有tasktracker 与jobtracker <br></p><p><br></p><p><span style="font-size:18px;">  </span></p><p><span style="font-size:18px;">h.   下面打开浏览器，验证是否安装成功</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20180411153229377" alt=""><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;">50070 成功</span></p><p><span style="font-size:18px;">错误：</span></p><p><span style="font-size:18px;">jps用不了了。不知道为什么。尝试各种方法，后来发现要先source etc/profile  ，问题解决如图</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20180416111002139" alt=""><br></span></p><p><span style="font-size:18px;"><br></span></p><p><br></p>            </div>
                </div>