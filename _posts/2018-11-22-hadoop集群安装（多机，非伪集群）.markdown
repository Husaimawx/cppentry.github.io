---
layout:     post
title:      hadoop集群安装（多机，非伪集群）
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/AC_great/article/details/47087741				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<pre><span style="font-size:18px;">1. 创建用户</span></pre>
<pre><span style="font-size:18px;">创建hadoop用户组：sudo addgroup hadoop</span></pre>
<pre><span style="font-size:18px;">创建hadoop用户：sudo adduser -ingroup hadoop hadoop</span></pre>
<pre><span style="font-size:18px;">
为hadoop用户分配root权限：sudo gedit /etc/sudoers</span></pre>
<pre><span style="font-size:18px;">按回车键就可以打开sudoers文件</span></pre>
<pre><span style="font-size:18px;">在root    ALL=(ALL:ALL) ALL下面添加hadoop ALL=(ALL:ALL) ALL </span></pre>
<pre><span style="font-size:18px;">
2. 修改机器名</span></pre>
<pre><span style="font-size:18px;">    系统安装之后默认的名称为"ubuntu"，为了在集群中能够分辨各台服务器，我们需要修改机器名，机器名由/etc/hostname文件决定。</span></pre>
<pre><span style="font-size:18px;">打开/etc/hostname文件：sudo gedit /etc/hostname</span></pre>
<pre><span style="font-size:18px;">将"ubuntu"改为规定的机器名，比如"master"</span></pre>
<pre><span style="font-size:18px;">
3. 安装JDK</span></pre>
<pre><span style="font-size:18px;">将已经下载的jdk-7u79-linux-x64.tar.gz复制到ubuntu上。</span></pre>
<pre><span style="font-size:18px;">拷贝到/usr/local路径:</span></pre>
<pre><span style="font-size:18px;">解压：cd /usr/local进入到jdk压缩包所在路径；解压缩sudo tar -zxvf jdk-7u79-linux-x64.tar.gz，回车出现量的压缩信息，压缩完之后查看该目录下的文件，会发现多了个文件夹，如图</span></pre>
<pre><span style="font-size:18px;">设置环境变量</span></pre>
<pre><span style="font-size:18px;">打开/etc/profile文件，将以下内容拷贝进去。</span></pre>
<img src="https://img-blog.csdn.net/20150802170240171?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br><br><pre><span style="font-size:18px;">sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/java-7-sun/bin/java 300   
    sudo update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/java-7-sun/bin/javac 300  
    sudo update-alternatives --config java 

sudo update-alternatives --remove-all 变量名


测试JDK</span></pre>
<pre><span style="font-size:18px;">输入java -version测试环境</span></pre>
<pre><span style="font-size:18px;">
系统Java环境安装完毕</span></pre>
<pre><span style="font-size:18px;">4. 安装SSH服务</span></pre>
<pre><span style="font-size:18px;">hdfs通过ssh控制节点之间的通讯，所以ssh一定要设置。</span></pre>
<pre><span style="font-size:18px;">sudo apt-get install ssh openssh-server </span></pre>
<pre><span style="font-size:18px;">
5. 设置SSH免密码连接，在master节点上生成key</span></pre>
<pre><span style="font-size:18px;"></span></pre>
成功流程: <br>
    hadoop@master 用户下 sudo gedit /home/sudoers    添加权限 <br><p>    hadoop@master 用户下 sudo gedit /etc/hosts   添加客户机/服务器</p>
<p>    cd ~/.ssh</p>
<p>   ssh-keygen -t rsa 然后无脑回车<br></p>
    <span id="transmark"></span> <br>
    cat id_rsa.pub &gt;&gt; authorized_keys    将密钥写入公钥 <br>
    cat authorized_keys             查看公钥 <br>
    sudo scp authorized_keys hadoop@slave03:/home/hadoop/.ssh             将公钥发给客户机/3号服务器<br>
    ssh slave03  链接客户机/服务器
<pre><span style="font-size:18px;">

</span></pre>
<pre><span style="font-size:18px;">
</span></pre>
<pre><span style="font-size:18px;">出现上图所示就说明可以连通，输入exit命令，推出ssh登陆状态。
再次输入ssh slave03即可自动链接，否则没成功
</span></pre>
<pre><span style="font-size:18px;">二、 配置集群</span></pre>
<pre><span style="font-size:18px;">1. 解压hadoop安装包</span></pre>
<pre><span style="font-size:18px;">    与安装jdk的步骤一样，将hadoop-2.6.0.tar.gz移动到/usr/local下，解压后在/usr/local目录下多一个文件夹，如图</span></pre>
<pre><span style="font-size:18px;">
将hadoop-2.6.0.tar.gz文件重命名为hadoop</span></pre>
<pre><span style="font-size:18px;">sudo mv hadoop-2.6.0.tar.gz  hadoop

</span></pre>
<pre><span style="font-size:18px;">2. 将hadoop文件的权限添加给hadoop组的hadoop用户</span></pre>
<pre><span style="font-size:18px;">sudo chown -R hadoop:hadoop hadoop</span></pre>
<pre><span style="font-size:18px;">
3. 设置linux系统的hadoop环境变量</span></pre>
<pre><span style="font-size:18px;"></span></pre>
<pre><span style="font-size:18px;">export JAVA_HOME=/opt/jdk1.7.0_79</span></pre>
<pre><span style="font-size:18px;">export JRE_HOME=$JAVA_HOME/jre  </span></pre>
<pre><span style="font-size:18px;">export HADOOP_HOME=/usr/local/hadoop</span></pre>
<pre><span style="font-size:18px;">export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib  </span></pre>
<pre><span style="font-size:18px;">export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$HADOOP_HOME/bin:$PATH</span></pre>
<pre><span style="font-size:18px;"></span></pre>
<pre><span style="font-size:18px;">
4. 修改/etc/hosts文件</span></pre>
<pre><span style="font-size:18px;">打开/etc/hosts文件，将各个节点的机器名与IP对应</span></pre>
<pre>211.69.255.01 slave01
                                   ................
</pre>
<pre><span style="font-size:18px;">5. 配置/etc/hadoop/hadoop-env.sh文件</span></pre>
<pre><span style="font-size:18px;">指定其中的jdk路径</span></pre><pre><span style="font-size:18px;">/opt/jdk1.7.0_79</span></pre>
<pre><span style="font-size:18px;">
6. 配置/etc/hadoop/core-site.xml文件</span></pre>
<pre><span style="font-size:18px;">打开core-site.xml文件，配置如下。
&lt;property&gt; 
&lt;name&gt;fs.default.name&lt;/name&gt; 
&lt;value&gt;hdfs://master:9000&lt;/value&gt; 
&lt;/property&gt; 

   &lt;property&gt; 
&lt;name&gt;hadoop.tmp.dir&lt;/name&gt; 
&lt;value&gt;/home/hadoop/hadoop-datastore/hadoop-hadoop&lt;/value&gt; 
&lt;/property&gt; 


</span></pre>
<pre><span style="font-size:18px;">
（注：其中的hadoop.tmp.dir项不要按默认的设置，默认的设置会将这个文件夹指定到tmp目录下，一旦NameNode关机或者重启，集群中所有的存储文件将丢失）</span></pre>
<pre><span style="font-size:18px;">7. 配置hdfs-site.xml文件

</span></pre>
<pre><span style="font-size:18px;">打开hdfs-site.xml文件，配置如下
&lt;property&gt; 
&lt;name&gt;dfs.replication&lt;/name&gt; 
&lt;value&gt;3&lt;/value&gt; 
&lt;/property&gt; 
&lt;property&gt;

   &lt;name&gt;dfs.permissions&lt;/name&gt;

   &lt;value&gt;false&lt;/value&gt;

 &lt;/property&gt;

8。配置mapred-site.xml文件


&lt;property&gt; 
&lt;name&gt;mapred.job.tracker&lt;/name&gt; 
&lt;value&gt;master:9001&lt;/value&gt; 
&lt;/property&gt; 


</span></pre>
<pre><span style="font-size:18px;">
9. 配置slaves文件</span></pre>
<pre><span style="font-size:18px;">里面配置的都是集群中的机器名，与hosts文件形成映射。</span></pre>
<pre><span style="font-size:18px;">
打开etc/hadoop/slaves文件，配置如下
master
slave01
slave02
slave03

</span></pre>
<pre><span style="font-size:18px;">(注意这里必须加入master主机域名)

10. 将配置好的hadoop发给每一个slave节点
scp -r /usr/local/hadoop hadoop@slave01:/usr/local

这个命令很6哦，如果发现一台机子配置没配好，或者有更改，就用这种命令将文件发给每一台机子

</span></pre>
<pre><span style="font-size:18px;">
在slave节点上，分别把得到的hadoo文件的权限分配给hadoop用户组的hadoop用户，执行如下命令</span></pre>
<pre><span style="font-size:18px;">sudo chown -R hadoop:hadoop hadoop

</span></pre>
<pre><span style="font-size:18px;">11. 启动hadoop
这里则要注意是在bin的上一层目录执行

</span></pre>
<pre><span style="font-size:18px;">第一次启动hadoop集群需要对namenode进行格式化，执行命令：bin/hdfs  namenode -format。
只有第一次启动的时候需要格式化，以后都不需要。</span></pre>
<pre><span style="font-size:18px;">格式化完成后执行sbin/start-all.sh脚本启动全部服务。</span></pre>
<pre></pre>
<pre><span style="font-size:18px;">
三、 测试集群</span></pre>
<pre><span style="font-size:18px;">    运行</span><span style="font-size:18px;"> bin/hdfs</span><span style="font-size:18px;">  dfsadmin -report在控制台查看dfs的状态</span></pre>
<pre><span style="font-size:18px;">
也可在浏览器访问master节点的50070端口</span></pre>
<pre><span style="font-size:18px;">
可以看到有3个活着的datanode。
注意：
（1）如果搭建不成功则sbin/stop-all.sh关闭服务，清除tmp和你配置的存储数据的文件夹，清空后，然后在配置
</span></pre>
<pre><span style="font-size:18px;">
</span></pre>
<pre><span style="font-size:18px;">  恭喜你搭建成功</span></pre>
            </div>
                </div>