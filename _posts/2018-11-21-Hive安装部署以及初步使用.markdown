---
layout:     post
title:      Hive安装部署以及初步使用
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/qq_37142346/article/details/79809771				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h2 id="一hive概述">一、Hive概述</h2>

<p><strong>HIve是什么？为什么要使用hive？对于一个初步接触hive的初学者，这些都是迷惑的，因此本文主要带你入门hive，让你了解到hive的安装使用以及在hive在大数据中的位置。</strong></p>

<hr>

<p><strong>1.为什么要使用hive?</strong></p>

<p>在了解hive之前，相信大家都使用过mapreduce以及hdfs，提及mapreduce我们都会想到对于一些数据的处理总是要自己去编写mapreduce程序去处理，一大堆的Java代码，提高了用户的学习成本，基于这个原因，Facebook实现并且开源Hive。</p>

<p><strong>2.什么是Hive?</strong></p>

<p>对于hive的介绍，我们先来看看官网的介绍（<a href="https://cwiki.apache.org/confluence/display/Hive/Home" rel="nofollow">https://cwiki.apache.org/confluence/display/Hive/Home</a>）：</p>



<pre class="prettyprint"><code class=" hljs livecodeserver">The Apache Hive™ data warehouse software facilitates reading, writing, <span class="hljs-operator">and</span> managing large datasets residing <span class="hljs-operator">in</span> distributed storage <span class="hljs-operator">and</span> queried <span class="hljs-keyword">using</span> SQL syntax. 

Built <span class="hljs-command"><span class="hljs-keyword">on</span> <span class="hljs-title">top</span> <span class="hljs-title">of</span> <span class="hljs-title">Apache</span> <span class="hljs-title">Hadoop</span>™, <span class="hljs-title">Hive</span> <span class="hljs-title">provides</span> <span class="hljs-title">the</span> <span class="hljs-title">following</span> <span class="hljs-title">features</span>:</span>

*Tools <span class="hljs-built_in">to</span> enable easy access <span class="hljs-built_in">to</span> data via SQL, thus enabling data warehousing tasks such <span class="hljs-keyword">as</span> extract/transform/<span class="hljs-built_in">load</span> (ETL), reporting, <span class="hljs-operator">and</span> data analysis.
*A mechanism <span class="hljs-built_in">to</span> impose structure <span class="hljs-command"><span class="hljs-keyword">on</span> <span class="hljs-title">a</span> <span class="hljs-title">variety</span> <span class="hljs-title">of</span> <span class="hljs-title">data</span> <span class="hljs-title">formats</span></span>
Access <span class="hljs-built_in">to</span> <span class="hljs-built_in">files</span> stored either directly <span class="hljs-operator">in</span> Apache HDFS™ <span class="hljs-operator">or</span> <span class="hljs-operator">in</span> other data storage systems such <span class="hljs-keyword">as</span> Apache HBase™ 

*Query execution via Apache Tez™, Apache Spark™, <span class="hljs-operator">or</span> MapReduce
Procedural language <span class="hljs-operator">with</span> HPL-SQL
*Sub-<span class="hljs-keyword">second</span> query retrieval via Hive LLAP, Apache YARN <span class="hljs-operator">and</span> Apache Slider.</code></pre>

<p>简单总结一下： <br>
1.hive是由Facebook开源的用于解决海量结构化日志的数据统计。 <br>
2.hive基于hadoop建立的数据仓库工具，可以将结构化日志数据映射到一张表，使用SQL语句进行查询处理。 <br>
3.hive建立在hadoop之上提供了以下功能： <br>
    （1）、可以将数据通过sql语句来处理，支持提取，转换，加载以及数据分析等大数据作业。 <br>
    （2）、可以将结构化日志数据转化为文件存储在HDFS或者Hase等数据存储系统上。 <br>
     （3）、底层用mapreduce对数据进行计算，也可以自己通过mapreduce，spark编写程序来拓展hive的功能来实现更多自定义的数据处理。 <br>
  4.hive的实质就是将HQL语言转化为mapreduce。它适合离线数据的处理。</p>

<p>下面有一张图我们来简单了解一下hive在hadoop生态系统的位置： <br>
<img src="https://img-blog.csdn.net/20180403203641149?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3MTQyMzQ2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
由上图可以看出hive在数据处理方面占着很重要的位置，同时也可以看出它是运行在yarn上面的。</p>

<p><strong>3.hive的工作原理</strong> <br>
在知道了什么是hive之后，我们有必要了解一下hive的工作原理。 <br>
<img src="https://img-blog.csdn.net/20180403204011179?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3MTQyMzQ2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<p>我们来通过上面hive的架构图来看看它的工作原理： <br>
我们在上述hive的介绍当中了解到hive是将数据转换为文件存储在hdfs文件系统当中的，它对数据的计算处理底层实质上也是mapreduce。hive的元数据（表名，所属的数据库，拥有者，字段，表所在的目录，表的类型等等）都是存储在Meta store中，对于meta store下文会讲解，读者这里不必深究。在了解上面hive的核心之后再看他的架构图就很简单了。首先客户通过CLI（客户端工具，命令行）或者JDBC连接到hive服务器，Driver需要读取元数据（meta store）来加载数据，当客户端输入HQL命令时，Driver首先会通过SQL Parser来解析该sql，将sql语句转换成抽象语法树（AST），并且判断是否存在该表，字段是否存在，再通过编译器将AST转换为逻辑执行计划（比如map,reduce），然后通过Query Optimizer对执行计划进行优化，最后将优化后的逻辑执行计划交给mapreduce进行执行处理，将结果存储到hdfs文件系统上。</p>

<p><strong>4.hive的优点以及使用场景：</strong> <br>
*hive使用简单的HQL语句对数据进行查询处理，降低了程序员的学习成本，提高了开发效率。</p>

<p>*避免去写繁琐的程序（mapreduce），提高开发效率，元数据共享，支持多多客户端操作，同时也易于扩展。</p>



<h2 id="二安装部署hive">二、安装部署Hive</h2>

<p>这里是hive的下载地址：（<a href="http://archive.apache.org/dist/hive/" rel="nofollow">http://archive.apache.org/dist/hive/</a>） <br>
本文选择hive 0.13的版本进行安装，读者可以选择自己需要的版本进行安装。 <br>
<img src="https://img-blog.csdn.net/2018040320572726?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3MTQyMzQ2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
上面是hive安装所需的环境（来自官网），因此读者必须安装jdk1.7或以上的版本，并且需要hadoop环境的安装。对于这些环境读者可以查阅相关资料来安装，也可阅读我前面的文章进行安装。这里不赘述。</p>

<p>1.在下载好hive安装包之后，先将其解压：</p>



<pre class="prettyprint"><code class=" hljs avrasm">$ tar -xzvf hive-<span class="hljs-built_in">x</span><span class="hljs-preprocessor">.y</span><span class="hljs-preprocessor">.z</span><span class="hljs-preprocessor">.tar</span><span class="hljs-preprocessor">.gz</span></code></pre>

<p>如果读者阅读官网会让你配置hive的环境变量并且导出变量，这样做的目的是方便在任何目录下启动hive，这里我习惯上在hive的安装目录下启动，因此就不配置环境变量了，如果想配置可以查看官方文档。</p>

<p>2.在hive的安装目录下回有以下文件夹： <br>
<img src="https://img-blog.csdn.net/20180403210417759?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3MTQyMzQ2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
然后进入hive的安装目录下有一个conf文件夹我们将hive-env.sh.template文件重命名为hive-env.sh然后修改下面配置（分别是hadoop安装目录和hive conf文件夹所在目录）。</p>



<pre class="prettyprint"><code class=" hljs sql"># <span class="hljs-operator"><span class="hljs-keyword">Set</span> HADOOP_HOME <span class="hljs-keyword">to</span> point <span class="hljs-keyword">to</span> a specific hadoop install directory
HADOOP_HOME=/opt/modules/hadoop-<span class="hljs-number">2.5</span><span class="hljs-number">.0</span>

# Hive Configuration Directory can be controlled <span class="hljs-keyword">by</span>:
export HIVE_CONF_DIR=/opt/modules/hive-<span class="hljs-number">0.13</span><span class="hljs-number">.1</span>/conf</span></code></pre>

<p>要想启动hive首先要启动hdfs文件系统，接着还要在hdfs文件系统上创建下面的目录并且修改权限：</p>



<pre class="prettyprint"><code class=" hljs lasso"> $ <span class="hljs-variable">$HADOOP_HOME</span>/bin/hadoop fs <span class="hljs-attribute">-mkdir</span>       /tmp
  $ <span class="hljs-variable">$HADOOP_HOME</span>/bin/hadoop fs <span class="hljs-attribute">-mkdir</span>  <span class="hljs-attribute">-p</span> /user/hive/warehouse
  $ <span class="hljs-variable">$HADOOP_HOME</span>/bin/hadoop fs <span class="hljs-attribute">-chmod</span> g<span class="hljs-subst">+</span>w   /tmp
  $ <span class="hljs-variable">$HADOOP_HOME</span>/bin/hadoop fs <span class="hljs-attribute">-chmod</span> g<span class="hljs-subst">+</span>w   /user/hive/warehouse</code></pre>

<p>3.在执行完上面的操作后我们就可以启动hive了，切换到hive安装目录下：</p>

<pre class="prettyprint"><code class=" hljs ruby">[shinelon<span class="hljs-variable">@hadoop</span>-senior hive-<span class="hljs-number">0</span>.<span class="hljs-number">13.1</span>]<span class="hljs-variable">$ </span>bin/hive</code></pre>

<p>4.我们可以对hive进行简单的测试：</p>



<pre class="prettyprint"><code class=" hljs sql"><span class="hljs-operator"><span class="hljs-keyword">show</span> databases ;</span>
use default;
<span class="hljs-operator"><span class="hljs-keyword">show</span> tables ;</span>
<span class="hljs-operator"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> shinelon_log(id <span class="hljs-keyword">int</span>,name string);</span>
<span class="hljs-operator"><span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> shinelon_log;</span>
<span class="hljs-operator"><span class="hljs-keyword">select</span> <span class="hljs-aggregate">count</span>(*) <span class="hljs-keyword">from</span> shinelon_log;</span></code></pre>

<p>其实和MySQL语句很相似，几乎差不多，经过上面的测试我们就可以感受到hive的使用很简单，不过在执行select count(*) from shinelon_log;语句时我们会发现hive其实运行的是mapreduce程序，这也就很好的解释了上述hive的原理。下面我们为了更好的理解hive，可以创建一个文件（student.txt），在里面写入测试数据，其中列之间用tab键隔开：</p>



<pre class="prettyprint"><code class=" hljs ">1001    zhangsan
1002    lisi
1003    wangwu</code></pre>

<p>然后在hive创建一张表：</p>



<pre class="prettyprint"><code class=" hljs sql"><span class="hljs-operator"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> student(id <span class="hljs-keyword">int</span>, name string) <span class="hljs-keyword">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="hljs-keyword">BY</span> <span class="hljs-string">'\t'</span>;</span></code></pre>

<p>上面的语句可能后半段不容易让初学者明白，ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘\t’是设置数据分隔符，刚开始我们介绍到hive对结构化日志数据的处理，所谓结构化数据就是列与列之间有一定的界定符号来分割。</p>



<pre class="prettyprint"><code class=" hljs sql"><span class="hljs-operator"><span class="hljs-keyword">load</span> data <span class="hljs-keyword">local</span> inpath <span class="hljs-string">'/opt/datas/student.txt'</span><span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> student ;</span>
<span class="hljs-operator"><span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> student ;</span>
<span class="hljs-operator"><span class="hljs-keyword">select</span> id <span class="hljs-keyword">from</span> student ;</span></code></pre>

<p>然后我们执行上述语句就会发现hive已经成功的将数据映射到student表当中。</p>

<p>5.在开发hive时我们会启动多个客户端来进行操作，但是对于刚安装的hive它会将元数据存储在自己的内存数据库（derby）当中，由于启动hive它就要加载元数据，而此时元数据存储在内存数据库中，资源竞争，所以只允许启动一个hive客户端。怎么解决呢？我们一般将元数据存储在MySQL服务器或者oracle服务器中，这里我们来讲解将元数据存储到MySQL中。</p>

<p><strong>三、linux下安装MySQL并且设置hive元数据存储</strong></p>

<p><strong>1.安装MySQL</strong> <br>
注意：MySQL和hive是安装在同一台服务器上。</p>

<p>首先下载MySQL安装包，将其解压，然后判断服务器是否安装有MySQL，并且将其卸载：</p>



<pre class="prettyprint"><code class=" hljs ruby">[shinelon<span class="hljs-variable">@hadoop</span>-senior softwares]<span class="hljs-variable">$ </span>unzip mysql-libs.zip
[shinelon<span class="hljs-variable">@hadoop</span>-senior mysql-libs]<span class="hljs-variable">$ </span>sudo rpm -qa|grep mysql
[shinelon<span class="hljs-variable">@hadoop</span>-senior mysql-libs]<span class="hljs-variable">$ </span>sudo rpm -e --nodeps mysql-libs-<span class="hljs-number">5.1</span>.<span class="hljs-number">66</span>-<span class="hljs-number">2</span>.el6_3.x86_64
[shinelon<span class="hljs-variable">@hadoop</span>-senior mysql-libs]<span class="hljs-variable">$ </span>sudo rpm -ivh <span class="hljs-constant">MySQL</span>-server-<span class="hljs-number">5.6</span>.<span class="hljs-number">24</span>-<span class="hljs-number">1</span>.el6.x86_64.rpm 
[shinelon<span class="hljs-variable">@hadoop</span>-senior mysql-libs]<span class="hljs-variable">$ </span>sudo rpm -ivh <span class="hljs-constant">MySQL</span>-client-<span class="hljs-number">5.6</span>.<span class="hljs-number">24</span>-<span class="hljs-number">1</span>.el6.x86_64.rpm </code></pre>

<p>安装好MySQL之后，就可以登录测试一下，linux下MySQL root用户初始随机密码防止在/root/.mysql_secret文件下，可以查看复制登录。 <br>
<img src="https://img-blog.csdn.net/20180403212930757?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3MTQyMzQ2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
默认的在mysql数据库下有一个user表存储着服务器用户名以及密码，因为只允许MySQL 的root用户登录，因此我们不能远程登录，可能会受到权限的限制，为了防止后续任务出现问题，这里我们将host为localhost的一条记录改为host为%：</p>



<pre class="prettyprint"><code class=" hljs cs">mysql&gt; update user <span class="hljs-keyword">set</span> host=<span class="hljs-string">'%'</span> <span class="hljs-keyword">where</span> host=<span class="hljs-string">'localhost'</span>;</code></pre>

<p>然后删除其他字段，只留这一条记录，这样我们就可以远程在其他主机上登录了。</p>

<p><strong>2.设置hive元数据存储位置</strong> <br>
下面我们将hive的元数据存储到mysql中。 <br>
在hive安装目录的conf目录下创建一个文件夹hive-site.xml文件，添加如下配置：</p>



<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-pi">&lt;?xml version="1.0"?&gt;</span>
<span class="hljs-pi">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>jdbc:mysql://hadoop-senior.shinelon.com/metastore?createDatabaseIfNotExist=true<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">description</span>&gt;</span>JDBC connect string for a JDBC metastore<span class="hljs-tag">&lt;/<span class="hljs-title">description</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>

    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">description</span>&gt;</span>Driver class name for a JDBC metastore<span class="hljs-tag">&lt;/<span class="hljs-title">description</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>

    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>root<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">description</span>&gt;</span>username to use against metastore database<span class="hljs-tag">&lt;/<span class="hljs-title">description</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>

    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>123456<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">description</span>&gt;</span>password to use against metastore database<span class="hljs-tag">&lt;/<span class="hljs-title">description</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span>
</code></pre>

<p>然后还要将MySQL驱动包拷贝到hive的lib目录下：</p>



<pre class="prettyprint"><code class=" hljs lasso"><span class="hljs-preprocessor">[</span>shinelon@hadoop<span class="hljs-attribute">-senior</span> mysql<span class="hljs-attribute">-connector</span><span class="hljs-attribute">-java</span><span class="hljs-subst">-</span><span class="hljs-number">5.1</span><span class="hljs-number">.27</span><span class="hljs-preprocessor">]</span><span class="hljs-markup">$ cp mysql-connector-java-5.1.27-bin.jar /opt/modules/hive-0.13.1/lib/</span></code></pre>

<p>至此，我们就配置好元数据，在我们重启hive以及MySQL数据库后会发MySQL数据库多了一个数据库metastore，这个数据库也是我们上面配置文件connectionUrl中执行的。 <br>
<img src="https://img-blog.csdn.net/20180403214101833?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3MTQyMzQ2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<p>这时我们也可以启动多个hive客户端进行操作了。</p>

<hr>

<p>上述是我对hive的认识以及安装部署总结，不足之处还望指教，谢谢！</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>