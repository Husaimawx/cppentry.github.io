---
layout:     post
title:      Spark学习一
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h1 id="spark学习一">Spark学习一</h1>

<p>标签（空格分隔）： Spark</p>

<hr>

<p></p><div class="toc">
<ul>
<li><a href="#spark%E5%AD%A6%E4%B9%A0%E4%B8%80" rel="nofollow">Spark学习一</a><ul>
<li><a href="#%E4%B8%80%E6%A6%82%E8%BF%B0" rel="nofollow">一概述</a></li>
<li><a href="#%E4%BA%8Cspark%E7%9A%84%E5%AE%89%E8%A3%85" rel="nofollow">二spark的安装</a></li>
<li><a href="#%E4%B8%89spark%E7%9A%84%E5%88%9D%E6%AD%A5%E4%BD%BF%E7%94%A8" rel="nofollow">三spark的初步使用</a></li>
<li><a href="#%E5%9B%9Bspark%E7%9A%84standalone%E6%A8%A1%E5%BC%8F%E7%9A%84%E9%85%8D%E7%BD%AE" rel="nofollow">四spark的standalone模式的配置</a></li>
</ul>
</li>
</ul>
</div>




<h2 id="一概述">一，概述</h2>

<ul>
<li>列表项</li>
</ul>

<p>和mapreduce计算的比较 <br>
<img src="http://static.zybuluo.com/forrestxing/g38ta9eb2q13df415x8mklpu/001.png" alt="001.png-11.2kB" title=""></p>

<p><img src="http://static.zybuluo.com/forrestxing/md2kxxzb24en8ytxuz08ue88/001.png" alt="001.png-13.5kB" title=""></p>

<ul>
<li>what is spark <br>
Apache Spark™ is a fast and general engine for large-scale data processing. <br>
1,Speed:Run programs up to 100x faster than Hadoop MapReduce in memory, or 10x faster on disk <br>
2,Ease of Use:Write applications quickly in Java, Scala, Python,Spark offers over 80 high-level operators that make it easy to build parallel apps. And you can use it interactively from the Scala, Python and R shells. <br>
3,Generality:Combine SQL, streaming, and complex analytics. <br>
4,Runs Everywhere:Spark runs on Hadoop, Mesos, standalone, or in the cloud. It can access diverse data sources including HDFS, Cassandra, HBase, and S3</li>
</ul>

<p><img src="http://static.zybuluo.com/forrestxing/6exap0ip12o6msyrgutbar3d/001.png" alt="001.png-43kB" title=""></p>

<p>学好spark的路径： <br>
*,<a href="http://spark.apache.org/" rel="nofollow">http://spark.apache.org/</a> <br>
*,spark源码:<a href="https://github.com/apache/spark" rel="nofollow">https://github.com/apache/spark</a> <br>
*,<a href="https://databricks.com/blog" rel="nofollow">https://databricks.com/blog</a></p>



<h2 id="二spark的安装">二，spark的安装</h2>

<ul>
<li>解压scala安装包</li>
</ul>



<pre class="prettyprint"><code class=" hljs ruby">[hadoop001<span class="hljs-variable">@xingyunfei001</span> app]<span class="hljs-variable">$ </span>chmod u+x scala-<span class="hljs-number">2.10</span>.<span class="hljs-number">4</span>.tgz
[hadoop001<span class="hljs-variable">@xingyunfei001</span> app]<span class="hljs-variable">$ </span>tar -zxf scala-<span class="hljs-number">2.10</span>.<span class="hljs-number">4</span>.tgz -<span class="hljs-constant">C</span> /opt/app</code></pre>

<ul>
<li>修改/etc/profile配置文件</li>
</ul>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-keyword">export</span> SCALA_HOME=/opt/app/scala-<span class="hljs-number">2.10</span>.<span class="hljs-number">4</span>
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$SCALA_HOME</span>/bin</code></pre>



<pre class="prettyprint"><code class=" hljs ruby">[hadoop001<span class="hljs-variable">@xingyunfei001</span> app]<span class="hljs-variable">$ </span>scala -version</code></pre>

<p><img src="http://static.zybuluo.com/forrestxing/8pfsxoydap7qis42n4cw5nkb/001.png" alt="001.png-14.2kB" title=""></p>



<pre class="prettyprint"><code class=" hljs ruby">[hadoop001<span class="hljs-variable">@xingyunfei001</span> scala-<span class="hljs-number">2.10</span>.<span class="hljs-number">4</span>]<span class="hljs-variable">$ </span>source /etc/profile</code></pre>

<ul>
<li>解压spark安装包</li>
</ul>



<pre class="prettyprint"><code class=" hljs ruby">[hadoop001<span class="hljs-variable">@xingyunfei001</span> app]<span class="hljs-variable">$ </span>chmod u+x spark-<span class="hljs-number">1.3</span>.<span class="hljs-number">0</span>-bin-<span class="hljs-number">2.5</span>.tar.gz
[hadoop001<span class="hljs-variable">@xingyunfei001</span> app]<span class="hljs-variable">$ </span>tar -zxf spark-<span class="hljs-number">1.3</span>.<span class="hljs-number">0</span>-bin-<span class="hljs-number">2.5</span>.tar.gz -<span class="hljs-constant">C</span> /opt/app</code></pre>

<ul>
<li>配置spark的配置文件（spark-env.sh.template—&gt;spark-env.sh）</li>
</ul>



<pre class="prettyprint"><code class=" hljs javascript">JAVA_HOME=<span class="hljs-regexp">/opt/</span>app/jdk1<span class="hljs-number">.7</span><span class="hljs-number">.0</span>_67
SCALA_HOME=<span class="hljs-regexp">/opt/</span>app/scala-<span class="hljs-number">2.10</span><span class="hljs-number">.4</span>
HADOOP_CONF_DIR=<span class="hljs-regexp">/opt/</span>app/hadoop_2<span class="hljs-number">.5</span><span class="hljs-number">.0</span>_cdh</code></pre>

<ul>
<li>启动spark</li>
</ul>



<pre class="prettyprint"><code class=" hljs livecodeserver">bin/spark-<span class="hljs-built_in">shell</span></code></pre>

<p><img src="http://static.zybuluo.com/forrestxing/vxfl89yy0d3xkqh1ksuk7ndq/001.png" alt="001.png-46.7kB" title=""></p>



<h2 id="三spark的初步使用">三，spark的初步使用</h2>

<ul>
<li>第一个案例</li>
</ul>



<pre class="prettyprint"><code class=" hljs cs"><span class="hljs-keyword">var</span> rdd=sc.textFile(<span class="hljs-string">"/opt/datas/beifeng.log"</span>)</code></pre>

<p><img src="http://static.zybuluo.com/forrestxing/v1vtxct77uwn1qnginktnzx6/001.png" alt="001.png-46.2kB" title=""></p>



<pre class="prettyprint"><code class=" hljs axapta">rdd.<span class="hljs-keyword">count</span>    <span class="hljs-comment">//显示总条数</span></code></pre>

<p><img src="http://static.zybuluo.com/forrestxing/mth2ird28acvufb6eqz2gtph/001.png" alt="001.png-146.5kB" title=""></p>



<pre class="prettyprint"><code class=" hljs livecodeserver">rdd.<span class="hljs-keyword">first</span> <span class="hljs-comment"> //显示第一条数据</span></code></pre>

<p><img src="http://static.zybuluo.com/forrestxing/eap8bczry2d3hkerebmsmdaz/001.png" alt="001.png-130.9kB" title=""></p>



<pre class="prettyprint"><code class=" hljs oxygene">rdd.<span class="hljs-keyword">take</span>(<span class="hljs-number">2</span>)  <span class="hljs-comment">//获取头2条数据</span></code></pre>

<p><img src="http://static.zybuluo.com/forrestxing/kuf1ly8p527agqgnq6lwck17/001.png" alt="001.png-132.8kB" title=""></p>



<pre class="prettyprint"><code class=" hljs avrasm">rdd<span class="hljs-preprocessor">.filter</span>(<span class="hljs-built_in">x</span>=&gt;<span class="hljs-built_in">x</span><span class="hljs-preprocessor">.contains</span>(<span class="hljs-string">"yarn"</span>))<span class="hljs-preprocessor">.collect</span>
rdd<span class="hljs-preprocessor">.filter</span>(_<span class="hljs-preprocessor">.contains</span>(<span class="hljs-string">"yarn"</span>))<span class="hljs-preprocessor">.collect</span></code></pre>

<p><img src="http://static.zybuluo.com/forrestxing/9vutwgauz9vb5v18ejg3awlm/001.png" alt="001.png-111.3kB" title=""></p>



<pre class="prettyprint"><code class=" hljs axapta">rdd.cache     <span class="hljs-comment">//将数据放到内存中</span>
rdd.<span class="hljs-keyword">count</span></code></pre>

<p><img src="http://static.zybuluo.com/forrestxing/j4l8axrcy3zzd83l12bcbok4/001.png" alt="001.png-24.9kB" title=""></p>



<pre class="prettyprint"><code class=" hljs coffeescript">rdd.flatMap<span class="hljs-function"><span class="hljs-params">(x=&gt;x.split(<span class="hljs-string">" "</span>))</span>.<span class="hljs-title">map</span><span class="hljs-params">(x=&gt;(x,<span class="hljs-number">1</span>))</span>.<span class="hljs-title">reduceByKey</span><span class="hljs-params">((x,y)=&gt;(x+y))</span>.<span class="hljs-title">collect</span></span></code></pre>

<p><img src="http://static.zybuluo.com/forrestxing/3p18f8mxs5aaz22w29flx6li/001.png" alt="001.png-24.7kB" title=""></p>



<h2 id="四spark的standalone模式的配置">四，spark的standalone模式的配置</h2>

<p><img src="http://static.zybuluo.com/forrestxing/47pvkow8s40kw7u8zj42p76g/001.png" alt="001.png-27.4kB" title=""></p>

<p>sparkcpntext: <br>
1,application申请资源 <br>
2，读取数据，创建rdd</p>

<ul>
<li>修改配置文件spark-env.sh</li>
</ul>



<pre class="prettyprint"><code class=" hljs ini"><span class="hljs-setting">SPARK_MASTER_IP=<span class="hljs-value">xingyunfei001.com.cn</span></span>
<span class="hljs-setting">SPARK_MASTER_PORT=<span class="hljs-value"><span class="hljs-number">7077</span></span></span>
<span class="hljs-setting">SPARK_MASTER_WEBUI_PORT=<span class="hljs-value"><span class="hljs-number">8080</span></span></span>
<span class="hljs-setting">SPARK_WORKER_CORES=<span class="hljs-value"><span class="hljs-number">2</span></span></span>
<span class="hljs-setting">SPARK_WORKER_MEMORY=<span class="hljs-value"><span class="hljs-number">2</span>g</span></span>
<span class="hljs-setting">SPARK_WORKER_PORT=<span class="hljs-value"><span class="hljs-number">7078</span></span></span>
<span class="hljs-setting">SPARK_WORKER_WEBUI_PORT=<span class="hljs-value"><span class="hljs-number">8081</span></span></span>
<span class="hljs-setting">SPARK_WORKER_INSTANCES=<span class="hljs-value"><span class="hljs-number">1</span></span></span></code></pre>

<ul>
<li>修改配置文件slaves</li>
</ul>



<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor"># A Spark Worker will be started on each of the machines listed below.</span>
xingyunfei001<span class="hljs-preprocessor">.com</span><span class="hljs-preprocessor">.cn</span></code></pre>

<ul>
<li>启动standalone模式</li>
</ul>



<pre class="prettyprint"><code class=" hljs ruby">[hadoop001<span class="hljs-variable">@xingyunfei001</span> spark-<span class="hljs-number">1.3</span>.<span class="hljs-number">0</span>-bin-<span class="hljs-number">2.5</span>.<span class="hljs-number">0</span>]<span class="hljs-variable">$ </span>sbin/start-master.sh </code></pre>

<p><img src="http://static.zybuluo.com/forrestxing/6exap0ip12o6msyrgutbar3d/001.png" alt="001.png-24.6kB" title=""></p>



<pre class="prettyprint"><code class=" hljs ruby">[hadoop001<span class="hljs-variable">@xingyunfei001</span> spark-<span class="hljs-number">1.3</span>.<span class="hljs-number">0</span>-bin-<span class="hljs-number">2.5</span>.<span class="hljs-number">0</span>]<span class="hljs-variable">$ </span>sbin/start-slaves.sh</code></pre>

<p><img src="http://static.zybuluo.com/forrestxing/he3d5nvkptvm0egajyw4vjd5/001.png" alt="001.png-20.3kB" title=""></p>

<p><img src="http://static.zybuluo.com/forrestxing/tljwt8yychl7totuqbwx7c6a/001.png" alt="001.png-52.3kB" title=""></p>

<ul>
<li>提交应用</li>
</ul>



<pre class="prettyprint"><code class=" hljs coffeescript">bin<span class="hljs-regexp">/spark-shell --master spark:/</span>/xingyunfei001.com.<span class="hljs-attribute">cn</span>:<span class="hljs-number">7070</span>
<span class="hljs-reserved">var</span> rdd=sc.textFile(<span class="hljs-string">"/opt/datas/input.txt"</span>)
val wordcount=rdd.flatMap<span class="hljs-function"><span class="hljs-params">(x=&gt;x.split(<span class="hljs-string">" "</span>))</span>.<span class="hljs-title">map</span><span class="hljs-params">(x=&gt;(x,<span class="hljs-number">1</span>))</span>.<span class="hljs-title">reduceByKey</span><span class="hljs-params">((x,y)=&gt;(x+y))</span>.<span class="hljs-title">collect</span>
<span class="hljs-title">sc</span>.<span class="hljs-title">stop</span>
</span></code></pre>

<p><img src="http://static.zybuluo.com/forrestxing/sifeyxl3ukj12wm4p5ukcree/001.png" alt="001.png-26.9kB" title=""> <br>
<img src="http://static.zybuluo.com/forrestxing/bre3jhnvljd2sjroppdc81hm/001.png" alt="001.png-50.1kB" title=""></p>



<pre class="prettyprint"><code class=" hljs java">[hadoop001<span class="hljs-annotation">@xingyunfei</span>001 spark-<span class="hljs-number">1.3</span><span class="hljs-number">.0</span>-bin-<span class="hljs-number">2.5</span><span class="hljs-number">.0</span>]$ bin/spark-shell local[<span class="hljs-number">2</span>]  <span class="hljs-comment">//本地模式启动2个线程</span>

[hadoop001<span class="hljs-annotation">@xingyunfei</span>001 spark-<span class="hljs-number">1.3</span><span class="hljs-number">.0</span>-bin-<span class="hljs-number">2.5</span><span class="hljs-number">.0</span>]$ bin/spark-shell local[*]  <span class="hljs-comment">//根据本地配置自动设置线程数目</span></code></pre>

<ul>
<li>web监控界面：<a href="http://xingyunfei001.com.cn:4040/jobs/" rel="nofollow">http://xingyunfei001.com.cn:4040/jobs/</a> <br>
<img src="http://static.zybuluo.com/forrestxing/eedt3ina428498onuxr7kt3v/001.png" alt="001.png-25.7kB" title=""></li>
</ul>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>