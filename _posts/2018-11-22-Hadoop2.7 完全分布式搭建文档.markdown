---
layout:     post
title:      Hadoop2.7 完全分布式搭建文档
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <div class="iteye-blog-content-contain">
<h6 style="font-size:14px;"><strong>1. 集群信息如下：</strong></h6>
<table style="font-size:12px;border-collapse:collapse;border-spacing:0px;border:1px solid #C0C0C0;color:#444444;font-family:tahoma, arial, sans-serif;line-height:18px;width:660px;" border="1" cellspacing="0" cellpadding="0"><tbody><tr><td style="border:1px solid #C0C0C0;border-collapse:collapse;" valign="top" width="73">
<p style="line-height:1.5;">主机名</p>
</td>
<td style="border:1px solid #C0C0C0;border-collapse:collapse;" valign="top" width="94">
<p style="line-height:1.5;">Hadoop角色</p>
</td>
<td style="border:1px solid #C0C0C0;border-collapse:collapse;" valign="top" width="151">
<p style="line-height:1.5;">Hadoop jps命令结果</p>
</td>
<td style="border:1px solid #C0C0C0;border-collapse:collapse;" valign="top" width="132">
<p style="line-height:1.5;">Hadoop用户</p>
</td>
<td style="border:1px solid #C0C0C0;border-collapse:collapse;" valign="top" width="123">
<p style="line-height:1.5;">Hadoop安装目录</p>
</td>
</tr><tr><td style="border:1px solid #C0C0C0;border-collapse:collapse;" valign="top" width="73">
<p style="line-height:1.5;">master</p>
<p style="line-height:1.5;">server152</p>
</td>
<td style="border:1px solid #C0C0C0;border-collapse:collapse;" valign="top" width="94">
<p style="line-height:1.5;">Master</p>
<p style="line-height:1.5;">slaves</p>
</td>
<td style="border:1px solid #C0C0C0;border-collapse:collapse;" valign="top" width="151">
<p style="line-height:1.5;">NameNode</p>
<p style="line-height:1.5;">DataNode</p>
<p style="line-height:1.5;">JobTracker</p>
<p style="line-height:1.5;">TaskTracker</p>
<p style="line-height:1.5;">SecondaryNameNode</p>
</td>
<td style="border:1px solid #C0C0C0;border-collapse:collapse;" rowspan="3" valign="top" width="132">
<p style="line-height:1.5;" align="left">创建相同的用户的组名：hadoop。</p>
<p style="line-height:1.5;" align="left">安装hadoop-2.7.2时使用hadoop用户，并且hadoop的文件夹归属也是hadoop：hadoop</p>
</td>
<td style="border:1px solid #C0C0C0;border-collapse:collapse;" rowspan="3" valign="top" width="123">
<p style="line-height:1.5;">/usr/local/hadoop</p>
</td>
</tr><tr><td style="border:1px solid #C0C0C0;border-collapse:collapse;" valign="top" width="73">
<p style="line-height:1.5;">slave1</p>
<p style="line-height:1.5;">server153</p>
</td>
<td style="border:1px solid #C0C0C0;border-collapse:collapse;" valign="top" width="94">
<p style="line-height:1.5;">slaves</p>
</td>
<td style="border:1px solid #C0C0C0;border-collapse:collapse;" valign="top" width="151">
<p style="line-height:1.5;">DataNode</p>
<p style="line-height:1.5;">TaskTracker</p>
</td>
</tr><tr><td style="border:1px solid #C0C0C0;border-collapse:collapse;" valign="top" width="73">
<p style="line-height:1.5;">slave2</p>
<p style="line-height:1.5;">server154</p>
</td>
<td style="border:1px solid #C0C0C0;border-collapse:collapse;" valign="top" width="94">
<p style="line-height:1.5;">slaves</p>
</td>
<td style="border:1px solid #C0C0C0;border-collapse:collapse;" valign="top" width="151">
<p style="line-height:1.5;">DataNode</p>
<p style="line-height:1.5;">TaskTracker</p>
</td>
</tr></tbody></table><p style="line-height:18px;color:#444444;font-family:tahoma, arial, sans-serif;font-size:12px;">注：master即使master又是slave.</p>
<p style="font-size:14px;">3台64位centos6.5 + Hadoop2.7.2 + java7</p>
<p style="font-size:14px;"> </p>
<h6 style="font-size:14px;"><strong>2. 配置服务器的主机名</strong></h6>
<p style="font-size:14px;">Namenode节点对应的主机名为server152</p>
<p style="font-size:14px;">Datanode节点对应的主机名分别为server153、server154</p>
<p style="font-size:14px;"> </p>
<h6 style="font-size:14px;">
<strong>3. 编辑每台机器的hosts， 以及主机名hostname。 (以server153为例子)</strong> </h6>
<pre><code class="language-java">[root@server153 ~]# vi /etc/hosts
192.168.1.152 server152
192.168.1.153 server153
192.168.1.154 server154</code></pre>
<p style="font-size:14px;"> </p>
<pre><code class="language-java">[root@server153 ~]# cat /etc/sysconfig/network
NETWORKING=yes
HOSTNAME=server153
NETWORKING_IPV6=yes
IPV6_AUTOCONF=no</code></pre>
<p style="font-size:14px;"> </p>
<h6 style="font-size:14px;">
<strong>4. </strong><strong>创建用户组</strong>
</h6>
<p style="font-size:14px;">　groupadd hadoop  添加一个组</p>
<p style="font-size:14px;">　useradd hadoop -g hadoop  添加用户</p>
<p style="font-size:14px;"> </p>
<h6 style="font-size:14px;"><strong>5. 安装hadoop</strong></h6>
<p style="font-size:14px;">    下载：<a href="http://mirrors.cnnic.cn/apache/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gz" rel="nofollow">http://mirrors.cnnic.cn/apache/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gz</a></p>
<p style="font-size:14px;">　 解压到/usr/local/hadoop/hadoop2.7.2</p>
<p style="font-size:14px;">　 hadoop也要设置环境变量，使用vi /etc/profile命令编辑添加如下内容：</p>
<pre><code class="language-java">[root@server153 ~]# cat /etc/profile
export HADOOP_HOME=/usr/local/hadoop/hadoop2.7.2
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH

#执行source /etc/profile使配置文件生效
[root@server153 ~]# source /etc/profile

#修改所有者改为hadoop
[root@server153 ~]#chown -R hadoop:hadoop /usr/local/hadoop/ </code></pre>
<h6 style="font-size:14px;"> </h6>
<h6 style="font-size:14px;">
<strong>5. </strong><strong>SSH设置无密码验证</strong>
</h6>
<p style="font-size:14px;">　a)安装SSH，并让master免验证登陆自身服务器、节点服务器 </p>
<pre><code class="language-java">#执行下面命令，让master节点能够免验证登陆自身服务器
ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
cat ~/.ssh/id_dsa &gt;&gt; ~/.ssh/authorized_keys
export HADOOP\_PREFIX=/usr/local/hadoop/hadoop2.7.2</code></pre>
<p style="font-size:14px;"> </p>
<p style="font-size:14px;">    b) 让主结点(master)能通过SSH免密码登录两个子结点（slave）</p>
<pre><code class="language-java">#为了实现这个功能，两个slave结点的公钥文件中必须要包含主结点的公钥信息，这样当master就可以顺利安全地访问这两个slave结点了
# 在slave的机器上执行一下命令
scp hadoop@server152:~/.ssh/id_dsa.pub  ~/.ssh/id_dsa.pub
cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
#设置权限，否则ssh依然需要输入密码
chmod -R 700 ~/.ssh </code></pre>
<p style="font-size:14px;"> </p>
<p style="font-size:14px;"><strong> 6. 安装Hadoop</strong><strong style="line-height:1.5;"><br></strong></p>
<p>    解压到/usr目录下面，改名为hadoop。</p>
<p>    hadoop也要设置环境变量，使用vi /etc/profile命令编辑添加如下内容：</p>
<pre><code class="language-java">export HADOOP_HOME=/usr/local/hadoop/hadoop2.7.2
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH</code></pre>
<p> </p>
<h6 style="font-size:14px;"> <strong style="line-height:1.5;">7. 配置Hadoop</strong>
</h6>
<p>    配置之前，需要在server152本地文件系统创建以下文件夹：</p>
<pre><code class="language-java">/usr/loacal/hadoop/name
/usr/loacal//hadoop/data
/usr/loacal//hadoop/temp</code></pre>
<p> </p>
<p>    这里要涉及到的配置文件有7个：</p>
<pre><code class="language-java">~/hadoop-2.7.2/etc/hadoop/hadoop-env.sh
~/hadoop-2.7.2/etc/hadoop/yarn-env.sh
~/hadoop-2.7.2/etc/hadoop/slaves
~/hadoop-2.7.2/etc/hadoop/core-site.xml
~/hadoop-2.7.2/etc/hadoop/hdfs-site.xml
~/hadoop-2.7.2/etc/hadoop/mapred-site.xml
~/hadoop-2.7.2/etc/hadoop/yarn-site.xml</code></pre>
<p> </p>
<p>    <strong style="font-family:monospace;line-height:1.5;">core-site.xml：</strong></p>
<pre><code class="language-java">&lt;configuration&gt;
	&lt;property&gt;
	  &lt;name&gt;fs.defaultFS&lt;/name&gt;
	  &lt;value&gt;hdfs://server152:9000&lt;/value&gt;
	&lt;/property&gt;
        &lt;property&gt;  
	  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;  
	  &lt;value&gt;file:/usr/local/hadoop/fs/temp&lt;/value&gt;  
	  &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;  
        &lt;/property&gt;
&lt;/configuration&gt;</code></pre>
<p> </p>
<p>    <strong style="font-family:monospace;line-height:1.5;">hdfs-site.xml:</strong></p>
<pre><code class="language-java">&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
		&lt;value&gt;hdfs://server152:9001&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
		&lt;value&gt;file:/usr/local/hadoop/fs/name&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
		&lt;value&gt;file:/usr/local/hadoop/fs/data&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.replication&lt;/name&gt;
		&lt;value&gt;3&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
		&lt;value&gt;true&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;</code></pre>
<p> </p>
<p>    <strong style="font-family:monospace;line-height:1.5;">mapred-site.xml：</strong></p>
<pre><code class="language-java">&lt;configuration&gt;
	&lt;property&gt;
	  &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
	  &lt;value&gt;yarn&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
	  &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
	  &lt;value&gt;server152:10020&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
	  &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
	  &lt;value&gt;server152:19888&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;</code></pre>
<p style="font-size:14px;">    </p>
<p style="font-size:14px;"><strong style="font-family:monospace;line-height:1.5;"> yarn-site.xml:</strong></p>
<pre><code class="language-java">&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services.mapreduce_shuffle.class&lt;/name&gt;
    &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
    &lt;value&gt;server152:8030&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
    &lt;value&gt;server152:8031&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
    &lt;value&gt;server152:8032&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
    &lt;value&gt;server152:8033&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
    &lt;value&gt;server152:8088&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;</code></pre>
<p style="font-size:14px;"> </p>
<h6 style="font-size:14px;">
<strong style="font-family:monospace;line-height:1.5;"> </strong> <strong style="font-family:monospace;line-height:1.5;">slave.xml:</strong>
</h6>
<p> </p>
<pre class="c">server153
server154</pre>
<p> </p>
<p style="font-size:14px;"><strong style="font-size:1em;line-height:1.5;">    </strong></p>
<h6 style="font-size:14px;"><strong style="font-family:monospace;line-height:1.5;"> 复制到hadoop 到其他节点:</strong></h6>
</div>
<div class="iteye-blog-content-contain">
<div class="iteye-blog-content-contain">
<pre><code class="language-python">scp -r /usr/local/hadoop/* hadoop@server153:/usr/local/hadoop/
scp -r /usr/local/hadoop/* hadoop@server154:/usr/local/hadoop/</code></pre>
    </div>
<h6 style="font-size:14px;"> <strong style="line-height:1.5;">7.启动hadoop</strong>
</h6>
<p>    a) 格式化namenode</p>
<p> </p>
<pre><code class="language-python">[hadoop@server152 hadoop2.7.2] ./bin/hdfs namenode  -format

#看到提示：
#“Exitting with status 0″ 成功，
#“Exitting with status 1″ 失败。</code></pre>
    
<p> </p>
<p>    b) 启动hdfs</p>
<p> </p>
<pre><code class="language-java">[hadoop@server152 hadoop2.7.2]./sbin/start-dfs.sh

#server152上面运行的进程有：NameNode  SecondaryNameNode
#server153和server154上面运行的进程有：DataNode
#使用ps -ef|grep hadoop 查看进程</code></pre>
    c) 启动yarn
<p> </p>
<p> </p>
<pre><code class="language-java">[hadoop@server152 hadoop2.7.2]./sbin/start-yarn.sh
#YARN 是从 MapReduce 中分离出来的，负责资源管理与任务调度。YARN 运行于 MapReduce 之上，提供了高可用性、高扩展性
#server152上面运行的进程有：NameNode  SecondaryNameNode ResourceManager
#server153和server154上面运行的进程有：DataNode NodeManager
#启动完成后，可以通过命令 jps 来判断是否成功启动，若成功启动则会列出如下进程: “NameNode”、”DataNode” 和 “SecondaryNameNode

[hadoop@server152 hadoop2.7.2]$ jps</code></pre>
<span style="color:#333333;font-family:Arial;"> </span>
<p> </p>
<h6 style="font-size:14px;">
<strong>8</strong><strong style="line-height:1.5;">.</strong>检测运行事例</h6>
<p>查看集群状态：./bin/hdfs dfsadmin -report</p>
<p>出现 </p>
<p>Live datanodes (2):</p>
<p>这个信息才表示集群建立成功</p>
<p>成功启动后，可以访问 Web 界面 http://192.168.1.152:50070 查看 NameNode 和 Datanode 信息，还可以在线查看 HDFS 中的文件。</p>
<p>启动 YARN 可以通过 Web 界面查看任务的运行情况：http://192.168.1.152:8088/cluster</p>
<div class="iteye-blog-content-contain"> </div>
<div class="iteye-blog-content-contain">
<strong style="line-height:1.5;">9</strong><strong style="line-height:1.5;">.</strong><strong style="line-height:1.5;"><span style="line-height:1.5;">操作hdfs 的命令</span></strong>
</div>
<div class="iteye-blog-content-contain">
<div class="iteye-blog-content-contain">
<p>hadoop fs</p>
<p>这个命令可以列出所有的 hdfs的子命令的帮助界面。基本上语法和linux上的文件操作类似</p>
<p>例如 : 复制本地文件到 hdfs 系统 </p>
<p>hadoop fs -copyFromLocal *.log hdfs://192.168.1.151:9000/data/weblogs</p>
<p>命令详解，官方文档</p>
<p>https://hadoop.apache.org/docs/r1.0.4/cn/hdfs_shell.html</p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p>引用：http://blog.csdn.net/remote_roamer/article/details/50579874</p>
</div>
</div>
</div>            </div>
                </div>