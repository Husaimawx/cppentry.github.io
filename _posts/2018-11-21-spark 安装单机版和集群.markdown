---
layout:     post
title:      spark 安装单机版和集群
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主编写文章，未经博主允许转载，转载请注明出处。					https://blog.csdn.net/u012373815/article/details/53212780				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>本文介绍安装mac单机版的spark，和spark 集群安装 分以下步骤</p>

<ul>
<li>安装scala </li>
<li>下载spark 压缩包并解压</li>
<li>修改spark的配置文件</li>
<li>配置环境变量</li>
<li>验证安装情况 <br>
<hr></li>
</ul>



<h1 id="安装scala">安装Scala</h1>

<p><a href="http://blog.csdn.net/u012373815/article/details/53231292" rel="nofollow">mac安装scala教程</a></p>

<hr>



<h1 id="下载spark压缩包并解压">下载spark压缩包并解压</h1>

<p>到官网下载spark的安装包（我用的是spark-2.0.1-bin-hadoop2.7.tgz）</p>

<p><a href="http://mirror.bit.edu.cn/apache/spark/" rel="nofollow">http://mirror.bit.edu.cn/apache/spark/</a></p>

<p>进入安装包存放目录，解压安装包  </p>



<pre class="prettyprint"><code class=" hljs lasso">tar <span class="hljs-attribute">-zxvf</span>  spark<span class="hljs-subst">-</span><span class="hljs-number">2.0</span><span class="hljs-number">.1</span><span class="hljs-attribute">-bin</span><span class="hljs-attribute">-hadoop2</span><span class="hljs-number">.7</span><span class="hljs-built_in">.</span>tgz</code></pre>

<p>解压后进入conf 文件夹下将 spark-env.sh.template 改名为 spark-env.sh</p>



<pre class="prettyprint"><code class=" hljs avrasm">mv spark-env<span class="hljs-preprocessor">.sh</span><span class="hljs-preprocessor">.template</span> spark-env<span class="hljs-preprocessor">.sh</span></code></pre>

<p>操作如下图</p>

<p><img src="https://img-blog.csdn.net/20161118100339825" alt="这里写图片描述" title=""></p>

<hr>



<h1 id="单机版安装">单机版安装</h1>



<h2 id="修改spark的配置文件">修改spark的配置文件</h2>

<p>修改 spark-env.sh 文件添加信息</p>



<pre class="prettyprint"><code class=" hljs rust">vi spark-env.sh
<span class="hljs-comment">//添加如下信息</span>

<span class="hljs-keyword">export</span> SCALA_HOME=/Users/yangyibo/Software/scala
<span class="hljs-keyword">export</span> JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.<span class="hljs-number">8.0_92</span>.jdk/Contents/Home
<span class="hljs-keyword">export</span> SPARK_MASTER_IP=<span class="hljs-number">192.168</span>.<span class="hljs-number">100.176</span>
<span class="hljs-keyword">export</span> SPARK_WORKER_MEMORY=<span class="hljs-number">512</span>m 
<span class="hljs-keyword">export</span> master=spark:<span class="hljs-comment">//192.168.100.176:7070</span>
</code></pre>

<p>如下图 <br>
<img src="https://img-blog.csdn.net/20161118101226217" alt="这里写图片描述" title=""></p>

<p><img src="https://img-blog.csdn.net/20161118101241454" alt="这里写图片描述" title=""></p>

<hr>

<p>修改 slaves.template 添加信息</p>



<pre class="prettyprint"><code class=" hljs d">vi slaves.<span class="hljs-keyword">template</span>
<span class="hljs-comment">//添加如下信息</span>
master</code></pre>

<p>如下图 <br>
<img src="https://img-blog.csdn.net/20161118101411422" alt="这里写图片描述" title=""></p>

<p><img src="https://img-blog.csdn.net/20161118101423017" alt="这里写图片描述" title=""></p>

<hr>



<h2 id="配置环境变量">配置环境变量</h2>

<p>Mac修改 .bash_profile 文件，此文件是mac 当前用户的环境配置文件。</p>

<p>/etc/profile 是当前系统的环境配置文件（Linux，系统可修改这个）</p>

<p>.bash_profile 文件的路径是在当前用户下。</p>



<h4 id="操作如下">操作如下：</h4>

<p>新打开终端输入命令</p>



<pre class="prettyprint"><code class=" hljs lasso">vi <span class="hljs-built_in">.</span>bash_profile
<span class="hljs-comment">//添加如下信息</span>
<span class="hljs-variable">#SPARK</span> VARIABLES START
export SPARK_HOME<span class="hljs-subst">=</span>/Users/yangyibo/Software/spark<span class="hljs-subst">-</span><span class="hljs-number">2.0</span><span class="hljs-number">.1</span><span class="hljs-attribute">-bin</span><span class="hljs-attribute">-hadoop2</span><span class="hljs-number">.7</span>
export PATH<span class="hljs-subst">=</span><span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$SPARK_HOME</span>/bin</code></pre>

<p>如下图，mac 注意路径哦，</p>

<p><img src="https://img-blog.csdn.net/20161118102430530" alt="这里写图片描述" title=""></p>

<p><img src="https://img-blog.csdn.net/20161118102639141" alt="这里写图片描述" title=""></p>

<hr>



<h1 id="集群安装">集群安装</h1>



<h2 id="修改slaves">修改slaves</h2>

<p>集群安装与单机版安装相同 只是在修改 slaves.template 添加信息</p>



<pre class="prettyprint"><code class=" hljs nginx"><span class="hljs-title">vi</span> slaves.template
//添加work 节点ip如下信息
<span class="hljs-number">192.168.100.23</span>
<span class="hljs-number">192.168.100.24</span>
<span class="hljs-number">192.168.100.25</span></code></pre>



<h2 id="将配置好的单机版spark复制到work节点上">将配置好的单机版spark复制到work节点上</h2>



<pre class="prettyprint"><code class=" hljs javascript"><span class="hljs-comment">// 当然节点机器的 scala 和 jdk 的安装配置要和 master 相同</span>
scp -rp /opt/apps/scala-<span class="hljs-number">2.11</span><span class="hljs-number">.7</span> root@work1IP:<span class="hljs-regexp">/opt/</span>apps
scp -rp /opt/apps/jdk/current root@work1IP:<span class="hljs-regexp">/opt/</span>apps
scp -rp /opt/apps/spark-<span class="hljs-number">2.2</span><span class="hljs-number">.1</span> root@work1IP:<span class="hljs-regexp">/opt/</span>apps</code></pre>



<h1 id="验证安装情况">验证安装情况</h1>

<p>此时就可以检验成果喽</p>

<p>进入安装包的sbin 目录执行  start-all.sh 脚本</p>



<pre class="prettyprint"><code class=" hljs sql">./<span class="hljs-operator"><span class="hljs-keyword">start</span>-<span class="hljs-keyword">all</span>.sh</span></code></pre>

<p><img src="https://img-blog.csdn.net/20161118103228604" alt="这里写图片描述" title=""></p>

<p>此时可能会出现这个情况，我们可以直接忽略</p>

<p><img src="https://img-blog.csdn.net/20161118103039619" alt="这里写图片描述" title=""></p>

<p>此时我们可以通过jps 命令 检验运行情况</p>

<p><img src="https://img-blog.csdn.net/20161118103538232" alt="这里写图片描述" title=""></p>

<p>打开Spark Master 页面查看集群情况，我相信你会直接点击。</p>

<p><a href="http://localhost:8080/" rel="nofollow">http://localhost:8080/</a></p>

<p>如图</p>

<p><img src="https://img-blog.csdn.net/20161118103749875" alt="这里写图片描述" title=""></p>

<hr>

<p>停止spark  <br>
进入spark的sbin目录，执行命令</p>



<pre class="prettyprint"><code class=" hljs ruby"><span class="hljs-variable">$ </span>./stop-all.sh</code></pre>

<hr>

<p>如果要给已经启动的spark 集群附加 worker 节点的话 按照集群配置以后 进入sbin 目录以后： <br>
通过start-slave.sh 脚本 启动一个 slave</p>

<pre class="prettyprint"><code class=" hljs avrasm"> sh start-slave<span class="hljs-preprocessor">.sh</span> spark://<span class="hljs-number">192.168</span><span class="hljs-number">.100</span><span class="hljs-preprocessor">.xx</span>:<span class="hljs-number">7077</span></code></pre>

<p>接下来就是spark 的小程序了 <br>
<a href="http://blog.csdn.net/u012373815/article/details/53231580" rel="nofollow">Spark进阶体验</a></p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>