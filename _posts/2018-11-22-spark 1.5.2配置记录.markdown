---
layout:     post
title:      spark 1.5.2配置记录
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/hanhuili/article/details/50128559				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>1）slaves</p>
<p></p>
<pre><code class="language-html"># A Spark Worker will be started on each of the machines listed below.
dataNode</code></pre><br>
2）spark-env.sh
<p></p>
<p></p>
<pre><code class="language-html">export HADOOP_CONF_DIR=/home/hadoop/hadoop/etc/hadoop
export YARN_CONF_DIR=/home/hadoop/hadoop/etc/hadoop</code></pre><br>
3）启动(命令在$SPARK/sbin)
<p></p>
<p></p>
<pre><code class="language-html"># start-all.sh</code></pre><br>
4)jps查看结果
<p></p>
<p></p>
<pre><code class="language-html"># jps
25911 Master
26104 Worker
6218 Jps</code></pre><br>
5）查看集群状态<br><p></p>
<p>http://localhost:8080/<br></p>
<p><br></p>
            </div>
                </div>