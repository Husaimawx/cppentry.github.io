---
layout:     post
title:      HBase 系统架构
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<h1 class="postTitle" style="font-size:14.7px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
<a id="cb_post_title_url" class="postTitle2" href="http://www.cnblogs.com/shitouer/archive/2012/06/04/2533518.html" rel="nofollow" style="text-decoration:none;color:rgb(26,139,200);">HBase 系统架构</a></h1>
<div id="cnblogs_post_body" style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:13px;line-height:19.5px;">
<p style="line-height:1.5;">HBase是Apache Hadoop的数据库，能够对大型数据提供随机、实时的读写访问。HBase的目标是存储并处理大型的数据。HBase是一个开源的，分布式的，多版本的，面向列的存储模型。它存储的是松散型数据。</p>
<p style="line-height:1.5;"><span style="line-height:1.5;font-size:18pt;"><strong>HBase特性：</strong></span></p>
<p style="line-height:1.5;">1 高可靠性</p>
<p style="line-height:1.5;">2 高效性</p>
<p style="line-height:1.5;">3 面向列</p>
<p style="line-height:1.5;">4 可伸缩</p>
<p style="line-height:1.5;">5 可在廉价PC Server搭建大规模结构化存储集群</p>
<p style="line-height:1.5;"><span style="line-height:1.5;font-size:14pt;"><strong>HBase是Google BigTable的开源实现</strong></span>，其相互对应如下：</p>
<p style="line-height:1.5;">　　　　　　　　　　<strong>Google 　　　　　　　　　　 HBase</strong><br>
文件存储系统 　　　  GFS 　　　　　　　　　　　  HDFS<br>
海量数据处理 　　　  MapReduce Hadoop 　　　　MapReduce<br>
协同服务管理　　　　Chubby 　　　　　　　　　　Zookeeper</p>
<p style="line-height:1.5;"> </p>
<p style="line-height:1.5;"><span style="line-height:1.5;font-size:14pt;"><strong>HBase关系图：</strong></span></p>
<p style="line-height:1.5;"><img src="http://pic002.cnblogs.com/images/2012/79891/2012060400463595.jpg" alt="" style="border:0px;display:block;margin-left:auto;"></p>
<p style="line-height:1.5;">HBase位于结构化存储层，围绕HBase，各部件对HBase的支持情况：<br><strong>Hadoop部件　　　　　　　　　　　　作用</strong><br>
HDFS　　　　　　　　　　　　　　高可靠的底层存储支持<br>
MapReduce 　　　　　　　　　　  高性能的计算能力<br>
Zookeeper 　　　　　　　　　　　稳定服务和failover机制<br>
Pig&amp;Hive　　　　　　　　　　　　 高层语言支持，便于数据统计<br>
Sqoop　　　　　　　　　　　　　 提供RDBMS数据导入，便于传统数据库向HBase迁移</p>
<p style="line-height:1.5;"><span style="line-height:1.5;font-size:14pt;"><strong>访问HBase的接口</strong></span></p>
<p style="line-height:1.5;"><strong>方式　　　　　　　　　　　　特点　　　　　　　　　　　　　　场合</strong><br>
Native Java API　　　　　　最常规和高效 　　　　　　　　　　 Hadoop MapReduce Job并行处理HBase表数据<br>
HBase Shell　　　　　　　  最简单接口 　　　　　　　　　　　 HBase管理使用<br>
Thrift Gateway　　　　　　利用Thrift序列化支持多种语言 　　  异构系统在线访问HBase表数据<br>
Rest Gateway　　　　　　 解除语言限制 　　　　　　　　　　 Rest风格Http API访问<br>
Pig　　　　　　　　　　　　Pig Latin六十编程语言处理数据 　　数据统计<br>
Hive　　　　　　　　　　　 简单，SqlLike</p>
<p style="line-height:1.5;"><span style="line-height:1.5;font-size:18pt;"><strong>HBase 数据模型</strong></span></p>
<p style="line-height:1.5;"><img src="http://pic002.cnblogs.com/images/2012/79891/2012060400513336.jpg" alt="" style="border:0px;"></p>
<p style="line-height:1.5;">组成部件说明：</p>
<p style="line-height:1.5;">Row Key：　　 　　Table主键 行键 Table中记录按照Row Key排序<br>
Timestamp：   　　每次对数据操作对应的时间戳，也即数据的version number<br>
Column Family： 　列簇，一个table在水平方向有一个或者多个列簇，列簇可由任意多个Column组成，列簇支持动态扩展，无须预定义数量及类型，二进制存储，用户需自行进行类型转换</p>
<p style="line-height:1.5;"><span style="line-height:1.5;font-size:14pt;"><strong>Table&amp;Region</strong></span></p>
<p style="line-height:1.5;"><img src="http://pic002.cnblogs.com/images/2012/79891/2012060400532513.jpg" alt="" style="border:0px;display:block;margin-left:auto;"></p>
<p style="line-height:1.5;">1. Table随着记录增多不断变大，会自动分裂成多份Splits，成为Regions<br>
2. 一个region由[startkey，endkey)表示<br>
3. 不同region会被Master分配给相应的RegionServer进行管理</p>
<p style="line-height:1.5;"><span style="line-height:1.5;font-size:14pt;"><strong>两张特殊表：-ROOT- &amp; .META.</strong></span></p>
<p style="line-height:1.5;"><img src="http://pic002.cnblogs.com/images/2012/79891/2012060400544147.jpg" alt="" style="border:0px;display:block;margin-left:auto;"></p>
<p style="line-height:1.5;">.META. 　　记录用户表的Region信息，同时，.META.也可以有多个region<br>
-ROOT- 　  记录.META.表的Region信息，但是，-ROOT-只有一个region<br>
Zookeeper中记录了-ROOT-表的location<br>
客户端访问数据的流程：<br>
Client -&gt; Zookeeper -&gt; -ROOT- -&gt; .META. -&gt; 用户数据表<br>
多次网络操作，不过client端有cache缓存</p>
<p style="line-height:1.5;"><span style="line-height:1.5;font-size:18pt;"><strong>HBase 系统架构图</strong></span></p>
<p style="line-height:1.5;text-align:center;"><img src="http://pic002.cnblogs.com/images/2012/79891/2012060400561367.jpg" alt="" style="border:0px;"></p>
<p style="line-height:1.5;">组成部件说明<br><strong>Client：</strong><br>
使用HBase RPC机制与HMaster和HRegionServer进行通信<br>
Client与HMaster进行通信进行管理类操作<br>
Client与HRegionServer进行数据读写类操作<br><br><strong>Zookeeper：</strong><br>
Zookeeper Quorum存储-ROOT-表地址、HMaster地址<br>
HRegionServer把自己以Ephedral方式注册到Zookeeper中，HMaster随时感知各个HRegionServer的健康状况<br>
Zookeeper避免HMaster单点问题<br><br><strong>HMaster：</strong><br>
HMaster没有单点问题，HBase中可以启动多个HMaster，通过Zookeeper的Master Election机制保证总有一个Master在运行<br>
主要负责Table和Region的管理工作：<br>
1 管理用户对表的增删改查操作<br>
2 管理HRegionServer的负载均衡，调整Region分布<br>
3 Region Split后，负责新Region的分布<br>
4 在HRegionServer停机后，负责失效HRegionServer上Region迁移<br><br><strong>HRegionServer：</strong><br>
HBase中最核心的模块，主要负责响应用户I/O请求，向HDFS文件系统中读写数据</p>
<p style="line-height:1.5;text-align:center;"><img src="http://pic002.cnblogs.com/images/2012/79891/2012060400572691.jpg" alt="" style="border:0px;"></p>
<p style="line-height:1.5;"><br>
HRegionServer管理一些列HRegion对象；<br>
每个HRegion对应Table中一个Region，HRegion由多个HStore组成；<br>
每个HStore对应Table中一个Column Family的存储；<br>
Column Family就是一个集中的存储单元，故将具有相同IO特性的Column放在一个Column Family会更高效</p>
<p style="line-height:1.5;"><strong>HStore：</strong><br>
HBase存储的核心。由MemStore和StoreFile组成。<br>
MemStore是Sorted Memory Buffer。用户写入数据的流程：</p>
<p style="line-height:1.5;text-align:center;"><img src="http://pic002.cnblogs.com/images/2012/79891/2012060400574793.gif" alt="" style="border:0px;"></p>
<p style="line-height:1.5;"><br>
Client写入 -&gt; 存入MemStore，一直到MemStore满 -&gt; Flush成一个StoreFile，直至增长到一定阈值 -&gt; 出发Compact合并操作 -&gt; 多个StoreFile合并成一个StoreFile，同时进行版本合并和数据删除 -&gt; 当StoreFiles Compact后，逐步形成越来越大的StoreFile -&gt; 单个StoreFile大小超过一定阈值后，触发Split操作，把当前Region Split成2个Region，Region会下线，新Split出的2个孩子Region会被HMaster分配到相应的HRegionServer上，使得原先1个Region的压力得以分流到2个Region上<br>
由此过程可知，HBase只是增加数据，有所得更新和删除操作，都是在Compact阶段做的，所以，用户写操作只需要进入到内存即可立即返回，从而保证I/O高性能。</p>
<p style="line-height:1.5;"><strong>HLog</strong><br>
引入HLog原因：<br>
在分布式系统环境中，无法避免系统出错或者宕机，一旦HRegionServer以外退出，MemStore中的内存数据就会丢失，引入HLog就是防止这种情况<br>
工作机制：<br>
每个HRegionServer中都会有一个HLog对象，HLog是一个实现Write Ahead Log的类，每次用户操作写入Memstore的同时，也会写一份数据到HLog文件，HLog文件定期会滚动出新，并删除旧的文件(已持久化到StoreFile中的数据)。当HRegionServer意外终止后，HMaster会通过Zookeeper感知，HMaster首先处理遗留的HLog文件，将不同region的log数据拆分，分别放到相应region目录下，然后再将失效的region重新分配，领取到这些region的HRegionServer在Load
 Region的过程中，会发现有历史HLog需要处理，因此会Replay HLog中的数据到MemStore中，然后flush到StoreFiles，完成数据恢复。</p>
<p style="line-height:1.5;"><strong>HBase存储格式</strong><br>
HBase中的所有数据文件都存储在Hadoop HDFS文件系统上，格式主要有两种：<br>
1 HFile HBase中KeyValue数据的存储格式，HFile是Hadoop的二进制格式文件，实际上StoreFile就是对HFile做了轻量级包装，即StoreFile底层就是HFile<br>
2 HLog File，HBase中WAL（Write Ahead Log） 的存储格式，物理上是Hadoop的Sequence File</p>
<p style="line-height:1.5;"><strong>HFile</strong></p>
<p style="line-height:1.5;text-align:center;"><img src="http://pic002.cnblogs.com/images/2012/79891/2012060400581450.jpg" alt="" style="border:0px;"></p>
<p style="line-height:1.5;"><br>
图片解释：<br>
HFile文件不定长，长度固定的块只有两个：Trailer和FileInfo<br>
Trailer中指针指向其他数据块的起始点<br>
File Info中记录了文件的一些Meta信息，例如：AVG_KEY_LEN, AVG_VALUE_LEN, LAST_KEY, COMPARATOR, MAX_SEQ_ID_KEY等<br>
Data Index和Meta Index块记录了每个Data块和Meta块的起始点<br>
Data Block是HBase I/O的基本单元，为了提高效率，HRegionServer中有基于LRU的Block Cache机制<br>
每个Data块的大小可以在创建一个Table的时候通过参数指定，大号的Block有利于顺序Scan，小号Block利于随机查询<br>
每个Data块除了开头的Magic以外就是一个个KeyValue对拼接而成, Magic内容就是一些随机数字，目的是防止数据损坏</p>
<p style="line-height:1.5;">HFile里面的每个KeyValue对就是一个简单的byte数组。这个byte数组里面包含了很多项，并且有固定的结构。</p>
<p style="line-height:1.5;text-align:center;"><img src="http://pic002.cnblogs.com/images/2012/79891/2012060400583891.jpg" alt="" style="border:0px;"></p>
<p style="line-height:1.5;"><br>
KeyLength和ValueLength：两个固定的长度，分别代表Key和Value的长度<br>
Key部分：Row Length是固定长度的数值，表示RowKey的长度，Row 就是RowKey<br>
Column Family Length是固定长度的数值，表示Family的长度<br>
接着就是Column Family，再接着是Qualifier，然后是两个固定长度的数值，表示Time Stamp和Key Type（Put/Delete）<br>
Value部分没有这么复杂的结构，就是纯粹的二进制数据</p>
<p style="line-height:1.5;"><strong>HLog File</strong></p>
<p style="line-height:1.5;text-align:center;"><img src="http://pic002.cnblogs.com/images/2012/79891/2012060400590244.jpg" alt="" style="border:0px;"></p>
<p style="line-height:1.5;"><br>
HLog文件就是一个普通的Hadoop Sequence File，Sequence File 的Key是HLogKey对象，HLogKey中记录了写入数据的归属信息，除了table和region名字外，同时还包括 sequence number和timestamp，timestamp是“写入时间”，sequence number的起始值为0，或者是最近一次存入文件系统中sequence number。<br>
HLog Sequece File的Value是HBase的KeyValue对象，即对应HFile中的KeyValue</p>
<p style="line-height:1.5;"><br></p>
<p style="line-height:1.5;"><br></p>
<p style="line-height:1.5;">转载自：http://www.cnblogs.com/shitouer/archive/2012/06/04/2533518.html</p>
</div>
            </div>
                </div>