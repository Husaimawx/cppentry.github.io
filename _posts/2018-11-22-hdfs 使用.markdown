---
layout:     post
title:      hdfs 使用
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>hdfs常用命令：<br>
上传：<br>
hadoop fs -put wp.txt /user<br>
添加文件到hdfs上已经有的文件：<br>
hadoop fs -appendToFile a.txt /user/wp.txt<br>
hdfs删除文件：<br>
hadoop fs -rm -r 路径<br>
把一个目录下的文件mv到另一个目录</p>
<pre><code>hadoop fs -mv /user/vpetest.cripac/source_data/result/ssd/20181020/* /user/vpetest.cripac/source_data/result/ssd2/20181020
</code></pre>
<p>重命名</p>
<pre><code>hadoop fs -mv /user/vpetest.cripac/source_data/result/ssd2 /user/vpetest.cripac/source_data/result/ssd
</code></pre>
<p>查看hadoop 状态<br>
hadoop dfsadmin -report</p>
<p>磁盘写满：<br>
<a href="http://qindongliang.iteye.com/blog/2091989" rel="nofollow">http://qindongliang.iteye.com/blog/2091989</a><br>
<a href="http://www.linuxidc.com/Linux/2015-02/113638.htm" rel="nofollow">http://www.linuxidc.com/Linux/2015-02/113638.htm</a><br>
<a href="http://www.125135.com/949815.html" rel="nofollow">http://www.125135.com/949815.html</a></p>
<p>hdfs参数：<br>
<a href="http://m.blog.csdn.net/article/details?id=51190839" rel="nofollow">http://m.blog.csdn.net/article/details?id=51190839</a><br>
<a href="https://segmentfault.com/a/1190000000709725" rel="nofollow">https://segmentfault.com/a/1190000000709725</a></p>
<p>hadoop本地库：</p>
<pre><code>export HADOOP_ROOT_LOGGER=DEBUG,console
ll /lib64/libc.so.6
mkdir zip
cd zip
wget http://ftp.gnu.org/gnu/glibc/glibc-2.14.1.tar.gz
wget http://ftp.gnu.org/gnu/glibc/glibc-linuxthreads-2.5.tar.bz2

tar -zxvf glibc-2.14.1.tar.gz
cd glibc-2.14.1
tar -jxvf ../glibc-linuxthreads-2.5.tar.bz2
cd ..
export CFLAGS="-g -O2"
./glibc-2.14.1/configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/bin
make
make install

</code></pre>
<p>make时间比较长，日志很多，别慌<br>
make install 会报两个错，但并不影响，重启hadoop后，本地库正常加载</p>
<p><a href="http://f.dataguru.cn/thread-544498-1-1.html" rel="nofollow">http://f.dataguru.cn/thread-544498-1-1.html</a><br>
<a href="http://www.linuxidc.com/Linux/2012-04/59200.htm" rel="nofollow">http://www.linuxidc.com/Linux/2012-04/59200.htm</a></p>
<p><a href="http://www.cnblogs.com/gpcuster/archive/2011/02/17/1957042.html" rel="nofollow">http://www.cnblogs.com/gpcuster/archive/2011/02/17/1957042.html</a><br>
<a href="http://blog.csdn.net/jiedushi/article/details/7496327" rel="nofollow">http://blog.csdn.net/jiedushi/article/details/7496327</a><br>
<a href="http://www.aboutyun.com/thread-7175-1-1.html" rel="nofollow">http://www.aboutyun.com/thread-7175-1-1.html</a></p>
<p>无法启动nameNode或者dataNode<br>
dfs.journalnode.edits.dir和hadoop.tmp.dir的父目录应该相同，而且</p>
<pre><code>scp -r tmp/  THadoop2:/home/idata/hadoop-2.4.1/
</code></pre>
<p>后边不能加上tmp，scp会把目录也拷贝过去<br>
<a href="http://tianxingzhe.blog.51cto.com/3390077/1711811" rel="nofollow">http://tianxingzhe.blog.51cto.com/3390077/1711811</a><br>
<a href="http://m.oschina.net/blog/488342" rel="nofollow">http://m.oschina.net/blog/488342</a></p>
<p>HDFS的WEB UI外网无法访问的问题<br>
因为在CDH中hdfs-site.xml配置文件中WEB UI配置的是域名，而域名在Hosts又被解析成内网IP。</p>
<p>你使用netstat -apn | grep 50700看一下监听情况。</p>
<p>你会发现监听的是你的内网IP，而不是外网IP，所以HDFS的WEB UI就无法访问啦。</p>
<p>解决办法：如果你使用的是Apache Hadoop，那么需要去手动修改hdfs-site.xml的dfs.namenode.http-address，修改为0.0.0.0:50070。如果使用的是ClouderaManager，那么去HDFS-&gt;配置-&gt;搜索NameNode Default Group  ，然后把NameNode Default Group圈上即可。</p>
<p>注意调整完毕后，需要重新启动HDFS</p>
<p><a href="http://www.cnblogs.com/hark0623/p/4177794.html" rel="nofollow">http://www.cnblogs.com/hark0623/p/4177794.html</a></p>
<p><a href="http://qindongliang.iteye.com/blog/2256266" rel="nofollow">http://qindongliang.iteye.com/blog/2256266</a></p>
<p>Name node is in safe mode的解决方法</p>
<pre><code>bin/hadoop dfsadmin -safemode leave  
</code></pre>
<pre><code>Java.io.IOException: No FileSystem for scheme: hdfs
Configuration conf = new Configuration();  
conf.set("fs.hdfs.impl",org.apache.hadoop.hdfs.DistributedFileSystem.class.getName());  
</code></pre>
<p>hdfs移动</p>
<pre><code>hadoop fs -mv /user/vpetest.cripac/source_data/video/CAM01/2014-03* /user/vpetest.cripac/source_data/video/CAM02/
</code></pre>
<p>统计HDFS文件数量,大小,以及在某范围大小的文件数量</p>
<pre><code>hadoop fs -count 路径
</code></pre>
<p><a href="https://blog.csdn.net/u014469615/article/details/78534062" rel="nofollow">https://blog.csdn.net/u014469615/article/details/78534062</a></p>
<p>HDFS用户权限管理<br>
<a href="https://blog.csdn.net/csfreebird/article/details/49681847" rel="nofollow">https://blog.csdn.net/csfreebird/article/details/49681847</a></p>
<p>命令<br>
<a href="http://www.cnblogs.com/xiaoliu66007/p/9329634.html" rel="nofollow">http://www.cnblogs.com/xiaoliu66007/p/9329634.html</a><br>
<a href="https://segmentfault.com/a/1190000002672666" rel="nofollow">https://segmentfault.com/a/1190000002672666</a></p>
<p>Hadoop中sequencefile和mapfile的区别<br>
<a href="https://blog.csdn.net/tiandd12/article/details/71433626" rel="nofollow">https://blog.csdn.net/tiandd12/article/details/71433626</a></p>

            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>