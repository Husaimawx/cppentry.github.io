---
layout:     post
title:      DataFrame------29
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h5><span style="background-color:rgb(204,255,255);"><span style="color:#cc0000;">理论：</span></span></h5><p><span style="background-color:rgb(204,255,255);">SparkSQL:</span></p><span style="background-color:rgb(204,255,255);">*SPARK中原生的RDD是没有数据结构的（主要部件：SPARK CORE[是spark的核心；rdd是spark core的核心]；Spark SQL；Spark Streaming；MLlib；GraphX）[spark的最底层大部分基于HDFS的，Shark中的数据信息等也是对应HDFS的文件]<br>*对RDD的变换和操作不能采用传统的SQL方法<br>*SparkSQL应运而生并建立在SHARK上，伯克利实验室Spark生态环境的组件之一（shark底层依赖于Hive引擎的，但在shark平台上，shark的解析速度是Hive的几多倍；）<br>*SHARK最初很大程度上依赖于HIVE如语法解析器、查询优化器等。（相当于mysql数据库用来存储数据的，可写SQL语句，做数据分析，和mysql区别它将数据存储在HDFS上。）<br>*改进的SparkSQL框架摆脱了对Hive的依懒性，所以无论在数据兼容、性能优化、组件扩展方面都得到了极大的方便。<br><br>优势：<br>数据兼容：数据结果本身就是SPARK RDD。（spark SQL不能直接处理RDD数据集，因为它不是结构化的，所以我们需要把RDD 转成Spark的）;<br>性能优化;<br>组件扩展。<br><br><br>SparkSQL运行架构<br>运行步骤：查询，解析，绑定，最优计划，执行<br>SQL执行顺序：先将语句进行解析，找出SQL关键词并判定SQL的合法性；在将SQL语句和数据库字典绑定，相关的字段存在，就执行SQL语句；数据库会在计划中选择一个最优计划（optimize）；计划执行（Execute），按Operation[操作]--&gt;Data Source[数据源]--&gt;Result[结果]的次序来进行的，在执行过程中不需读取物理表就可以返回结果，如重新运行刚运行过的SQL语句，可直接从数据库的缓冲池获取返回结果。<br><br>产生SchemaRDD（结构化的RDD）为了实现SPARKSQL必须将一般的RDD转换成带数据结构的数据集DataFrame<br>SchemaRDD本身就是一个RDD（rdd的子集），但它本身包含是由行对象（row object）组成。每个行代表一条记录。<br>SchemaRDD提供了一些新的操作应用使得应用函数使得数据操作和分析更高效和简洁。<br>可以将SchemaRDD注册成表，这样就可以用SQL访问RDD的数据了。而结果集本身也是SchemaRDD即DataFrame</span><br><br><br>1、用createDataFrame产生DataFrame<br>sqlContext=SQLContext（sc）<br>通过rows=sqlContext.createDataFrame([Row(a=1,b="男",c=50),Row(a=2,b="女",c=90)])将其转换成结构化的RDD<br>最后输出时collect（）是一行的，show（）是表格型的<br><br>2、用sc.parallelize产生DataFrame<br>namelist=['join','marry','larry']<br>agelist=[23,45,56]<br>gradelist=[88,99,100]<br>data=zip(namelist,agelist,gradelist)<br>#for i in data:<br> #print(i)<br>df=sc.parallelize(data).toDF(schema=['name','age','grade'])<br>df.select("name","grade").show()#写select查询语句<br><br>pandas 是基于NumPy（是Python的一种开源的数据计算扩展。做数值计算的。比Python中自身嵌套列表结构高效）的一种工具。主要为解决数据分析任务而创建。（因其本身纳入大量的库和一些标准的数据模型。）单机进行运算。<br>数据结构：[Serice：一维数组，与Numpy中的一维array类似，二者与Python基本的数据结构List也很相近，区别是list中的元素可以是不同的数据类型，而Array和Series中则只允许存储相同的数据类型，可更有效的使用内存，提高运算效率；Time-Series：以时间为索引Series；DataFrame：二维表格型数据结构；Panel：三维数组，理解为DataFrame的容器]（一维就是一行行数据。二维是一个表。）<br><br>StructType（） 将StructField处理后的列名转换成Data Frame可用的格式<br>StructField （）定义列（名称和数据类型和是否为空）<br>from pyspark.sql.types import *<br>st=StructType([StructField('id',IntegerType(),True),StructField('name',StringType(),True)])<br>ids=[1,2,3,4]<br>names=['aa','bb','cc','dd']<br>rdd=sc.parallelize(zip(ids,names))<br>df=rdd.toDF(st)<br><p>print(df.show())</p><p>题目：</p><p><img src="https://img-blog.csdn.net/20180512103615174?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21hbmdndW95YW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p>做法：</p><p><img src="https://img-blog.csdn.net/20180512105849688?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21hbmdndW95YW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p><img src="https://img-blog.csdn.net/20180512110241695?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21hbmdndW95YW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p><img src="https://img-blog.csdn.net/20180512110303516?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21hbmdndW95YW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p><img src="https://img-blog.csdn.net/20180512110416346?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21hbmdndW95YW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p><img src="https://img-blog.csdn.net/20180512110435704?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21hbmdndW95YW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p>            </div>
                </div>