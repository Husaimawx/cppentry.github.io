---
layout:     post
title:      Flume环境部署和配置详解及案例(转)
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                flume是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。支持在日志系统中定制各类数据发送方，用于收集数据;同时，Flume提供对数据进行简单处理，并写到各种数据接受方(比如文本、HDFS、Hbase等)的能力 。<br>　　一、什么是Flume?<br>　　flume 作为 cloudera 开发的实时日志收集系统，受到了业界的认可与广泛应用。Flume 初始的发行版本目前被统称为 Flume OG（original generation），属于 cloudera。但随着 FLume 功能的扩展，Flume OG 代码工程臃肿、核心组件设计不合理、核心配置不标准等缺点暴露出来，尤其是在 Flume OG 的最后一个发行版本 0.94.0 中，日志传输不稳定的现象尤为严重，为了解决这些问题，2011 年 10 月 22 号，cloudera 完成了 Flume-728，对 Flume 进行了里程碑式的改动：重构核心组件、核心配置以及代码架构，重构后的版本统称为 Flume NG（next generation）；改动的另一原因是将 Flume 纳入 apache 旗下，cloudera Flume 改名为 Apache Flume。<br><br>flume的特点：<br>　　flume是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。支持在日志系统中定制各类数据发送方，用于收集数据;同时，Flume提供对数据进行简单处理，并写到各种数据接受方(比如文本、HDFS、Hbase等)的能力 。<br>　　flume的数据流由事件(Event)贯穿始终。事件是Flume的基本数据单位，它携带日志数据(字节数组形式)并且携带有头信息，这些Event由Agent外部的Source生成，当Source捕获事件后会进行特定的格式化，然后Source会把事件推入(单个或多个)Channel中。你可以把Channel看作是一个缓冲区，它将保存事件直到Sink处理完该事件。Sink负责持久化日志或者把事件推向另一个Source。<br><br>flume的可靠性 <br>　　当节点出现故障时，日志能够被传送到其他节点上而不会丢失。Flume提供了三种级别的可靠性保障，从强到弱依次分别为：end-to-end（收到数据agent首先将event写到磁盘上，当数据传送成功后，再删除；如果数据发送失败，可以重新发送。），Store on failure（这也是scribe采用的策略，当数据接收方crash时，将数据写到本地，待恢复后，继续发送），Besteffort（数据发送到接收方后，不会进行确认）。<br><br>flume的可恢复性：<br>　　还是靠Channel。推荐使用FileChannel，事件持久化在本地文件系统里(性能较差)。 <br><br>　　flume的一些核心概念：<br>Agent使用JVM 运行Flume。每台机器运行一个agent，但是可以在一个agent中包含多个sources和sinks。<br>Client生产数据，运行在一个独立的线程。<br>Source从Client收集数据，传递给Channel。<br>Sink从Channel收集数据，运行在一个独立线程。<br>Channel连接 sources 和 sinks ，这个有点像一个队列。<br>Events可以是日志记录、 avro 对象等。<br><br>　　Flume以agent为最小的独立运行单位。一个agent就是一个JVM。单agent由Source、Sink和Channel三大组件构成，如下图：<br><br>　　值得注意的是，Flume提供了大量内置的Source、Channel和Sink类型。不同类型的Source,Channel和Sink可以自由组合。组合方式基于用户设置的配置文件，非常灵活。比如：Channel可以把事件暂存在内存里，也可以持久化到本地硬盘上。Sink可以把日志写入HDFS, HBase，甚至是另外一个Source等等。Flume支持用户建立多级流，也就是说，多个agent可以协同工作，并且支持Fan-in、Fan-out、Contextual Routing、Backup Routes，这也正是NB之处。如下图所示:<br><br>　　二、flume的官方网站在哪里？<br>　　http://flume.apache.org/<br>　　三、在哪里下载？<br>　　http://www.apache.org/dyn/closer.cgi/flume/1.5.0/apache-flume-1.5.0-bin.tar.gz<br>　　四、如何安装？<br>　　　　1)将下载的flume包，解压到/home/hadoop目录中，你就已经完成了50%：）简单吧<br>　　　　2)修改 flume-env.sh 配置文件,主要是JAVA_HOME变量设置<br>root@m1:/home/hadoop/flume-1.5.0-bin# cp conf/flume-env.sh.template conf/flume-env.sh<br>root@m1:/home/hadoop/flume-1.5.0-bin# vi conf/flume-env.sh<br># Licensed to the Apache Software Foundation (ASF) under one<br># or more contributor license agreements. See the NOTICE file<br># distributed with this work for additional information<br># regarding copyright ownership. The ASF licenses this file<br># to you under the Apache License, Version 2.0 (the<br># "License"); you may not use this file except in compliance<br># with the License. You may obtain a copy of the License at<br>#<br>#   http://www.apache.org/licenses/LICENSE-2.0<br>#<br># Unless required by applicable law or agreed to in writing, software<br># distributed under the License is distributed on an "AS IS" BASIS,<br># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br># See the License for the specific language governing permissions and<br># limitations under the License.<br><br># If this file is placed at FLUME_CONF_DIR/flume-env.sh, it will be sourced<br># during Flume startup.<br><br># Enviroment variables can be set here.<br><br>JAVA_HOME=/usr/lib/jvm/java-7-oracle<br><br># Give Flume more memory and pre-allocate, enable remote monitoring via JMX<br>#JAVA_OPTS="-Xms100m -Xmx200m -Dcom.sun.management.jmxremote"<br><br># Note that the Flume conf directory is always included in the classpath.<br>#FLUME_CLASSPATH=""<br><br><br>　　　　3)验证是否安装成功<br>root@m1:/home/hadoop# /home/hadoop/flume-1.5.0-bin/bin/flume-ng version<br>Flume 1.5.0<br>Source code repository: https://git-wip-us.apache.org/repos/asf/flume.git<br>Revision: 8633220df808c4cd0c13d1cf0320454a94f1ea97<br>Compiled by hshreedharan on Wed May 7 14:49:18 PDT 2014<br>From source with checksum a01fe726e4380ba0c9f7a7d222db961f<br>root@m1:/home/hadoop#<br>　　　　出现上面的信息，表示安装成功了<br><br>五、flume的案例<br>    案例1：Syslogtcp<br>　　　　Syslogtcp监听TCP的端口做为数据源<br>　　　　　　a)创建agent配置文件<br>root@flume1 flume# vi ./conf/syslog_tcp.conf<br>a1.sources = r1<br>a1.sinks = k1<br>a1.channels = c1<br># Describe/configure the source<br>a1.sources.r1.type = syslogtcp<br>a1.sources.r1.port = 5140<br>a1.sources.r1.host = localhost<br>a1.sources.r1.channels = c1<br># Describe the sink<br>a1.sinks.k1.type = logger<br># Use a channel which buffers events in memory<br>a1.channels.c1.type = memory<br>a1.channels.c1.capacity = 1000<br>a1.channels.c1.transactionCapacity = 100<br># Bind the source and sink to the channel<br>a1.sources.r1.channels = c1<br>a1.sinks.k1.channel = c1<br>　　　　　　b)启动flume agent a1<br>root@flume1 flume# ./bin/flume-ng agent --conf conf --conf-file ./conf/syslog_tcp.conf --name a1 -Dflume.root.logger=INFO,console<br>　　　　　　c)新连接shh,测试产生syslog<br>root@flume1 flume# echo "hello idoall.org syslog" | nc localhost 5140<br>　　　　　　d)在1的控制台，可以看到以下信息：<br>/08/10 11:41:45 INFO node.PollingPropertiesFileConfigurationProvider: Reloading configuration file:/home/hadoop/flume-1.5.0-bin/conf/syslog_tcp.conf<br>/08/10 11:41:45 INFO conf.FlumeConfiguration: Added sinks: k1 Agent: a1<br>/08/10 11:41:45 INFO conf.FlumeConfiguration: Processing:k1<br>/08/10 11:41:45 INFO conf.FlumeConfiguration: Processing:k1<br>/08/10 11:41:45 INFO conf.FlumeConfiguration: Post-validation flume configuration contains configuration for agents: [a1]<br>/08/10 11:41:45 INFO node.AbstractConfigurationProvider: Creating channels<br>/08/10 11:41:45 INFO channel.DefaultChannelFactory: Creating instance of channel c1 type memory<br>/08/10 11:41:45 INFO node.AbstractConfigurationProvider: Created channel c1<br>/08/10 11:41:45 INFO source.DefaultSourceFactory: Creating instance of source r1, type syslogtcp<br>/08/10 11:41:45 INFO sink.DefaultSinkFactory: Creating instance of sink: k1, type: logger<br>/08/10 11:41:45 INFO node.AbstractConfigurationProvider: Channel c1 connected to [r1, k1]<br>/08/10 11:41:45 INFO node.Application: Starting new configuration:{ sourceRunners:{r1=EventDrivenSourceRunner: { source:org.apache.flume.source.SyslogTcpSource{name:r1,state:IDLE} }} sinkRunners:{k1=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@6538b14 counterGroup:{ name:null counters:{} } }} channels:{c1=org.apache.flume.channel.MemoryChannel{name: c1}} }<br>/08/10 11:41:45 INFO node.Application: Starting Channel c1<br>/08/10 11:41:45 INFO instrumentation.MonitoredCounterGroup: Monitored counter group for type: CHANNEL, name: c1: Successfully registered new MBean.<br>/08/10 11:41:45 INFO instrumentation.MonitoredCounterGroup: Component type: CHANNEL, name: c1 started<br>/08/10 11:41:45 INFO node.Application: Starting Sink k1<br>/08/10 11:41:45 INFO node.Application: Starting Source r1<br>/08/10 11:41:45 INFO source.SyslogTcpSource: Syslog TCP Source starting...<br>/08/10 11:42:15 WARN source.SyslogUtils: Event created from Invalid Syslog data.<br>/08/10 11:42:15 INFO sink.LoggerSink: Event: { headers:{Severity=0, flume.syslog.status=Invalid, Facility=0} body: 68 65 6C 6C 6F 20 69 64 6F 61 6C 6C 2E 6F 72 67 hello idoall.org }<br><br>案例2：netcat<br>a)创建agent配置文件<br>root@flume1 flume# vi ./conf/netcat_example.conf<br><br># example.conf: A single-node Flume configuration<br><br><br># Name the components on this agent<br>a1.sources = r1<br>a1.sinks = k1<br>a1.channels = c1<br><br><br># Describe/configure the source<br>a1.sources.r1.type = netcat<br>a1.sources.r1.bind = localhost<br>a1.sources.r1.port = 44444<br><br><br># Describe the sink<br>a1.sinks.k1.type = logger<br><br><br># Use a channel which buffers events in memory<br>a1.channels.c1.type = memory<br>a1.channels.c1.capacity = 1000<br>a1.channels.c1.transactionCapacity = 100<br><br><br># Bind the source and sink to the channel<br>a1.sources.r1.channels = c1<br>a1.sinks.k1.channel = c1<br><br>　　　　　　b)启动flume agent a1<br>root@flume1 flume# ./bin/flume-ng agent --conf conf --conf-file ./conf/example.conf --name a1 -Dflume.root.logger=INFO,console<br>　　　　　　c)新连接shh,测试产生syslog<br># curl -X GET http://localhost:44444?w=DDDDDDDDDDDDDDDDDDDD<br>OK<br>OK<br>OK<br>OK<br>d)在1的控制台，可以看到以下信息：<br>2016-02-02 14:59:11,849 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] Event: { headers:{} body: 47 45 54 20 2F 3F 77 3D 44 44 44 44 44 44 44 44 GET /?w=DDDDDDDD }<br>2016-02-02 14:59:11,849 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] Event: { headers:{} body: 55 73 65 72 2D 41 67 65 6E 74 3A 20 63 75 72 6C User-Agent: curl }<br>2016-02-02 14:59:11,849 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] Event: { headers:{} body: 48 6F 73 74 3A 20 6C 6F 63 61 6C 68 6F 73 74 3A Host: localhost: }<br>2016-02-02 14:59:11,849 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] Event: { headers:{} body: 41 63 63 65 70 74 3A 20 2A 2F 2A 0D             Accept: */*. }<br>2016-02-02 14:59:11,850 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] Event: { headers:{} body: 0D                                              . }            </div>
                </div>