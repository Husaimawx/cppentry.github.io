---
layout:     post
title:      spark内核揭秘-01-spark内核核心术语解析
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/stark_summer/article/details/42833609				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p><span style="color:#ff0000;">Application:</span></p>
<p><span></span>Application是创建了SparkContext实例对象的spark用户，包含了Driver程序：</p>
<p><img src="https://img-blog.csdn.net/20150117112557572?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc3Rhcmtfc3VtbWVy/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></p>
<p>Spark-shell是一个应用程序，因为spark-shell在启动的时候创建了一个SparkContext对象，其名称为sc:</p>
<p><span style="color:#ff0000;">Job:</span></p>
<p><span></span>和Spark的action相对应，每一个action例如count、saveAsTextFile等都会对应一个job实例，该job实例包含多任务的并行计算。</p>
<p><span style="color:#ff0000;">Driver Program：</span></p>
<p><span></span>运行main函数并且创建SparkContext实例的程序</p>
<p><span style="color:#ff0000;">Cluster Manager：</span></p>
<p><span></span>集群资源的管理外部服务，在spark上现在有standalone、yarn、mesos等三种集群资源管理器，spark自带的standalone模式能够满足大部分的spark计算环境对集群资源管理的需求，基本上只有在集群中运行多套计算框架的时候才考虑yarn和mesos</p>
<p>Worker Node：</p>
<p><span></span>集群中可以运行应用代码的工作节点，相当于Hadoop的slave节点</p>
<p><span style="color:#ff0000;">Executor：</span></p>
<p><span></span>在一个Worker Node上为应用启动的工作进程，在进程中赋值任务的运行，并且负责将数据存放在内存或磁盘上，必须注意的是，每个应用在一个Worker Node上只会有一个Executor，在Executor内部通过多线程的方式并发处理应用的任务。</p>
<p><img src="https://img-blog.csdn.net/20150117185540533?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc3Rhcmtfc3VtbWVy/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></p>
<p><span style="color:#ff0000;">Task：</span></p>
<p><span></span>被Driver送到Executor上的工作单元，通常情况下一个task会处理一个split的数据，每个split一般就是一个Block块的大小：</p>
<p><img src="https://img-blog.csdn.net/20150117185739250?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc3Rhcmtfc3VtbWVy/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></p>
<p><span style="color:#ff0000;">State：</span></p>
<p><span></span>一个job会被拆分成很多任务，每一组任务被称为state，这个MapReduce的map和reduce任务很像，划分state的依据在于：state开始一般是由于读取外部数据或者shuffle数据、一个state的结束一般是由于发生shuffle（例如reduceByKey操作）或者整个job结束时，例如要把数据放到hdfs等存储系统上：</p>
<p><br></p>
            </div>
                </div>