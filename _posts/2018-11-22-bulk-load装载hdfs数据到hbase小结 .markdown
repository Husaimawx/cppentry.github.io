---
layout:     post
title:      bulk-load装载hdfs数据到hbase小结 
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                HBaseHadoopMapreduceXMLApache.bulk-load的作用是用mapreduce的方式将hdfs上的文件装载到hbase中，对于海量数据装载入hbase非常有用，参考http://hbase.apache.org/docs/r0.89.20100621/bulk-loads.html： <br><br>hbase提供了现成的程序将hdfs上的文件导入hbase,即bulk-load方式。它包括两个步骤（也可以一次完成）： <br>1 将文件包装成hfile，hadoop jar /path/to/hbase.jar importtsv -Dimporttsv.columns=a,b,c &lt;tablename&gt; &lt;inputdir&gt; <br>比如: <br><br>Java代码  <br>1.hadoop dfs -cat test/1  <br>2.1       2  <br>3.3       4  <br>4.5       6  <br>5.7       8  <br>	hadoop dfs -cat test/1<br>	1       2<br>	3       4<br>	5       6<br>	7       8<br>执行 <br><br>Java代码  <br>1.hadoop jar ~/hbase/hbase-0.90.2.jar importtsv -Dimporttsv.columns=HBASE_ROW_KEY,f1 t8 test  <br>	hadoop jar ~/hbase/hbase-0.90.2.jar importtsv -Dimporttsv.columns=HBASE_ROW_KEY,f1 t8 test<br>将会启动mapreduce程序在hdfs上生成t8这张表，它的rowkey分别为1 3 5 7，对应的value为2 4 6 8 <br>注意，源文件默认以"\t"为分割符，如果需要换成其它分割符，在执行时加上-Dimporttsv.separator=","，则变成了以","分割 <br><br>2 在上一步中，如果设置了输出目录,如 <br><br>Java代码  <br>1.hadoop jar ~/hbase/hbase-0.90.2.jar importtsv -Dimporttsv.bulk.output=tmp -Dimporttsv.columns=HBASE_ROW_KEY,f1 t8 test  <br>   hadoop jar ~/hbase/hbase-0.90.2.jar importtsv -Dimporttsv.bulk.output=tmp -Dimporttsv.columns=HBASE_ROW_KEY,f1 t8 test<br>那么t8表还暂时不会生成，只是将hfile输出到tmp文件夹下，我们可以查看tmp: <br><br>Java代码  <br>1.hadoop dfs -du tmp   <br>2.Found 3 items   <br>3.0           hdfs://namenode:9000/user/test/tmp/_SUCCESS   <br>4.65254       hdfs://namenode:9000/user/test/tmp/_logs   <br>5.462         hdfs://namenode:9000/user/test/tmp/f1  <br>	hadoop dfs -du tmp<br>	Found 3 items<br>	0           hdfs://namenode:9000/user/test/tmp/_SUCCESS<br>	65254       hdfs://namenode:9000/user/test/tmp/_logs<br>	462         hdfs://namenode:9000/user/test/tmp/f1<br>然后执行hadoop jar hbase-VERSION.jar completebulkload /user/todd/myoutput mytable将这个输出目录中的hfile转移到对应的region中,这一步因为只是mv，所以相当快。如： <br>hadoop jar ~/hbase/hbase-0.90.2.jar completebulkload tmp t8 <br>然后 <br><br>Java代码  <br>1.hadoop dfs -du /hbase/t8/c408963c084d328490cc2f809ade9428   <br>2.    Found 4 items   <br>3.    124         hdfs://namenode:9000/hbase/t8/c408963c084d328490cc2f809ade9428/.oldlogs   <br>4.    692         hdfs://namenode:9000/hbase/t8/c408963c084d328490cc2f809ade9428/.regioninfo   <br>5.    0           hdfs://namenode:9000/hbase/t8/c408963c084d328490cc2f809ade9428/.tmp   <br>6.    462         hdfs://namenode:9000/hbase/t8/c408963c084d328490cc2f809ade9428/f1  <br>hadoop dfs -du /hbase/t8/c408963c084d328490cc2f809ade9428<br>	Found 4 items<br>	124         hdfs://namenode:9000/hbase/t8/c408963c084d328490cc2f809ade9428/.oldlogs<br>	692         hdfs://namenode:9000/hbase/t8/c408963c084d328490cc2f809ade9428/.regioninfo<br>	0           hdfs://namenode:9000/hbase/t8/c408963c084d328490cc2f809ade9428/.tmp<br>	462         hdfs://namenode:9000/hbase/t8/c408963c084d328490cc2f809ade9428/f1<br>此时己经生成了表t8 <br>注意，如果数据特别大，而表中原来就有region，那么会执行切分工作，查找数据对应的region并装载 <br><br>        程序使用中注意： <br>1 因为是执行hadoop程序，不会自动查找hbase的config路径，也就找不到hbase的环境变量。因此需要将hbase-site.xml加入到hadoop-conf变量中 <br>2 还需要将hbase/lib中的jar包放入classpath中 <br>3 执行以上的步骤2时需要将zookeeper的配置写入core-site.xml中，因为在那一步时甚至不会读取hbase-site.xml，否则会连不上zookeeper            </div>
                </div>