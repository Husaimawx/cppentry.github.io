---
layout:     post
title:      hodoop安装步骤
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/haoxiaoyan/article/details/52523749				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
1.Hadoop 下载地址
<p>http://mirror.bit.edu.cn/apache/hadoop/common/</p>
<p></p>
<p>建立hadoop运行帐号即为hadoop</p>
<h3><span style="color:#333333;">2.集群专门设置一个用户组及用户，这部分比较简单，参考示例如下：</span></h3>
<p><span style="color:#ffffff;background:rgb(51,51,51);">$ useradd hadoop</span></p>
<p><span style="color:#ffffff;background:rgb(51,51,51);">$ groupadd -G hadoop    hadoop</span><span style="color:#333333;">在所有的机器上都建立相同的组（<span style="font-family:Arial;">hadoop</span><span style="font-family:'宋体';">）和用户（</span><span style="font-family:Arial;">hadoop</span><span style="font-family:'宋体';">）。</span></span><span style="color:#333333;">(<span style="font-family:'宋体';">最好不要使用</span><span style="font-family:Arial;">root</span><span style="font-family:'宋体';">安装</span><span style="font-family:Arial;">,</span><span style="font-family:'宋体';">因为不推荐各个机器之间使用</span><span style="font-family:Arial;">root</span><span style="font-family:'宋体';">访问 </span><span style="font-family:Arial;">)</span></span></p>
<p>sudo groupadd hadoop    //设置hadoop</p>
<p> 上述4个结点均需要进行以上步骤来完成hadoop运行帐号的建立。 </p>
3.把本机上的软件上传到其中的一台服务器上,用crt客户端的sftp可以上传
<p>sftp&gt; pwd</p>
<p>/home/centos</p>
<p>sftp&gt; lcd soft/</p>
<p>sftp&gt; lpwd</p>
<p>/home/h/soft</p>
<p>sftp&gt; <span>put /home/h/soft/hadoop-2.7.2.tar.gz /home/centos</span></p>
<p>Uploading hadoop-2.7.2.tar.gz to /home/centos/hadoop-2.7.2.tar.gz</p>
<p>  100% 207076KB   3286KB/s 00:01:03     </p>
<p>/home/h/soft/hadoop-2.7.2.tar.gz: 212046774 bytes transferred in 63 seconds (3286 KB/s)</p>
<p>sftp&gt; </p>
<p>4.把上传上来的软件分别在拷贝到其他服务器上</p>
<p>[centos@slavenode1 ~]$ sudo -s</p>
<p>[root@masternode centos]# ls</p>
<p>hadoop-2.7.2.tar.gz  jdk-7u79-linux-x64.tar.gz</p>
<p>[root@masternode centos]# pwd</p>
<p>/home/centos</p>
<p>[root@masternode centos]# <span>scp /home/centos/* root@10.10.1.4:/opt/hadoop/</span></p>
<p>hadoop-2.7.2.tar.gz                                                                            100%  202MB 101.1MB/s   00:02    </p>
<p>jdk-7u79-linux-x64.tar.gz                                                                      100%  146MB  73.2MB/s   00:02    </p>
<p>[root@masternode centos]# <span>scp /home/centos/* root@10.10.1.5:/opt/hadoop</span>/</p>
<p>hadoop-2.7.2.tar.gz                                                                            100%  202MB 202.2MB/s   00:01    </p>
<p>jdk-7u79-linux-x64.tar.gz                                                                      100%  146MB 146.4MB/s   00:01    </p>
<p>[root@masternode centos]# <span>scp /home/centos/* root@10.10.1.6:/opt/hadoop/</span></p>
<p>hadoop-2.7.2.tar.gz                                                                            100%  202MB 202.2MB/s   00:01    </p>
<p>jdk-7u79-linux-x64.tar.gz   </p>
<p>5.hadoop 机器部署</p>
<p>Hadoop是Apache软件基金会旗下的一个开源分布式计算平台。以Hadoop分布式文件系统<span>HDFS</span>(Hadoop Distributed Filesystem）和<span>MapReduce</span>（Google MapReduce的开源实现）为<span>核心</span>的Hadoop为用户提供了系统底层细节透明的分布式基础架构。</p>
<p>对于Hadoop的集群来讲，可以分成两大类角色：<span style="color:#333399;">Master</span>和<span style="color:#333399;">Salve</span>。一个HDFS集群是由一个<span style="color:#333399;">NameNode</span>和若干个<span style="color:#333399;">DataNode</span>组成的。其中NameNode作为主服务器，管理文件系统的命名空间和客户端对文件系统的访问操作；集群中的DataNode管理存储的数据。MapReduce框架是由一个单独运行在主节点上的JobTracker和运行在每个从节点的TaskTracker共同组成的。主节点负责调度构成一个作业的所有任 务，这些任务分布在不同的从节点上。主节点监控它们的执行情况，并且重新执行之前的失败任务；从节点仅负责由主节点指派的任务。当一个Job被提交时，JobTracker接收到提交作业和配置信息之后，就会将配置信息等分发给从节点，同时调度任务并监控TaskTracker的执行。</p>
<p>从上面的介绍可以看出，HDFS和MapReduce共同组成了Hadoop分布式系统体系结构的核心。<span>HDFS</span>在集群上实现<span>分布式文件系统</span>，<span>MapReduce</span>在集群上实现了<span>分布式计算</span>和<span>任务处理</span>。HDFS在MapReduce任务处理过程中提供了文件操作和存储等支持，MapReduce在HDFS的基础上实现了任务的分发、跟踪、执行等工作，并收集结果，二者相互作用，完成了Hadoop分布式集群的主要任务。</p>
<p>6.我的环境是在云主机中配置的，Hadoop集群中包括4个节点：1个Master，3个Salve，节点之间局域网连接，可以相互ping通，节点IP地址分布如下：</p>
<p> </p>
<table align="center"><tbody><tr><td valign="top" style="background:rgb(224,224,224);">
<p style="background:rgb(224,224,224);"><span style="background:rgb(224,224,224);">虚拟机系统</span></p>
</td>
<td valign="top" style="background:rgb(224,224,224);">
<p style="background:rgb(224,224,224);"><span style="background:rgb(224,224,224);">机器名称</span></p>
</td>
<td valign="top" style="background:rgb(224,224,224);">
<p style="background:rgb(224,224,224);"><span style="background:rgb(224,224,224);">IP地址</span></p>
</td>
</tr><tr><td valign="top">
<p>CentOS release 6.6 (Final)</p>
</td>
<td valign="top">
<p>masternode.novalocal</p>
</td>
<td valign="top">
<p>10.10.10.4（125.208.30.88）</p>
</td>
</tr><tr><td valign="top">
<p>CentOS release 6.6 (Final)</p>
</td>
<td valign="top">
<p>Slavenode1.novalocal</p>
</td>
<td valign="top">
<p>10.10.10.3（125.208.30.89）</p>
</td>
</tr><tr><td valign="top">
<p>CentOS release 6.6 (Final)</p>
</td>
<td valign="top">
<p>Slavenode2.novalocal</p>
</td>
<td valign="top">
<p>10.10.10.5（125.208.30.90）</p>
</td>
</tr><tr><td valign="top">
<p>CentOS release 6.5 (Final)</p>
</td>
<td valign="top">
<p>slavenode3.novalocal</p>
</td>
<td valign="top">
<p>10.10.10.6（125.208.30.91）</p>
</td>
</tr></tbody></table><p>7.修改文件<span>/etc/hostname</span>里的值即可，修改成功后用<span>hostname</span>命令查看当前主机名是否设置成功。</p>
<p>[root@masternode centos]# cat /etc/hosts</p>
<p>#127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</p>
<p>#::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</p>
<p><span style="background:rgb(255,255,0);">10.10.1.3 slavenode1.novalocal slavenode1</span></p>
<p><span style="background:rgb(255,255,0);">10.10.1.4 masternode.novalocal masternode</span></p>
<p><span style="background:rgb(255,255,0);">10.10.1.5 slavenode2.novalocal slavenode2</span></p>
<p><span style="background:rgb(255,255,0);">10.10.1.6 slavenode3.novalocal slavenode3</span></p>
<p> </p>
<p>12.在主节点机器上设置ssh免密码登陆</p>
<p> su - hadoop<br></p>
<p>1) 首先在主机器上核对ssh是否安装</p>
<p>[hadoop@masternode ~]# rpm -qa |grep ssh </p>
<p>libssh2-1.4.2-1.el6.x86_64</p>
<p>openssh-5.3p1-104.el6_6.1.x86_64</p>
<p>openssh-server-5.3p1-104.el6_6.1.x86_64</p>
<p>openssh-clients-5.3p1-104.el6_6.1.x86_64</p>
<p>2) 生产密钥 </p>
<p>[hadoop@masternode ~]# cd .ssh/</p>
<p>[hadoop@masternode .ssh]# ls</p>
<p><span>authorized_keys</span></p>
<p>[hadoop@masternode .ssh]# cd /</p>
<p>[hadoop@masternode /]#<span> ssh-keygen -t rsa</span></p>
<p>Generating public/private rsa key pair.</p>
<p>Enter file in which to save the key (/root/.ssh/id_rsa): </p>
<p>Enter passphrase (empty for no passphrase): </p>
<p>Enter same passphrase again: </p>
<p>Your identification has been saved in /hadoop/.ssh/id_rsa.</p>
<p>Your public key has been saved in /hadoop/.ssh/id_rsa.pub.</p>
<p>The key fingerprint is:</p>
<p>e8:3d:75:11:0b:6a:a9:f5:39:e5:04:71:2e:94:21:94 hadoop@masternode.novalocal</p>
<p>The key's randomart image is:</p>
<p>+--[ RSA 2048]----+</p>
<p>|       .o.*+o    |</p>
<p>|        E=.= o   |</p>
<p>|        = . *    |</p>
<p>|       = . * .   |</p>
<p>|      o S = o    |</p>
<p>|     . . . o     |</p>
<p>|      . o        |</p>
<p>|         .       |</p>
<p>|                 |</p>
<p>+-----------------+</p>
<p>[hadoop@masternode /]# cd </p>
<p>[hadoop@masternode ~]# cd .ssh/</p>
<p>[hadoop@masternode .ssh]# ls</p>
<p>authorized_keys <span> id_rsa  id_rsa.pub 生产的密钥</span></p>
<p>[hadoop@masternode .ssh]# cat id_rsa.pub &gt;&gt; authorized_keys</p>
<p>3)把密钥传输到其他节点机器上 </p>
<p>（1）用ssh-copy-id命令将公钥传送到远程主机上(这里以Slave1node3为例)。</p>
<p>[hadoop@masternode ~]# <span>ssh-copy-id root@slavenode3</span></p>
<p> </p>
<p>（2）如果在用命令ssh-copy-id时发现找不到该命令“<span>ssh-copy-id：Command not found</span>”，则可能是ssh服务的版本太低的原因，比如若你的机器是Redhat系统就可能该问题，解决办法是：手动复制本地的pubkey内容到远程服务器，命令如下：</p>
<p> cat ~/.ssh/id_rsa.pub | ssh root@<span>slavenode3</span> 'cat &gt;&gt; ~/.ssh/authorized_keys'</p>
<p>该命令等价于下面两个命令：</p>
<p>①在本地机器上执行：scp ~/.ssh/id_rsa.pub root@<span>slavenode3</span>:/~</p>
<p>②到远程机器上执行：cat ~/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</p>
<p>[hadoop@masternode .ssh]# scp authorized_keys hadoop@125.208.3.89:/root/.ssh</p>
lost connection
<p> </p>
<p>[hadoop@masternode .ssh]# vi authorized_keys </p>
<p>cat id_rsa.pub &gt;&gt; authorized_keysd_rsa.pub </p>
<p>[hadoop@masternode .ssh]# scp .ssh/authorized_keys <a href="mailto:root@slavenode1:~/.ssh/" rel="nofollow"><span>hadoop@mslavenode1:~/.ssh/</span></a></p>
<p>[hadoop@masternode .ssh]# scp .ssh/authorized_keys <a href="mailto:root@slavenode1:~/.ssh/" rel="nofollow"><span>hadoop@slavenode2:~/.ssh/</span></a></p>
<p>[hadoop@masternode .ssh]# scp .ssh/authorized_keys <a href="mailto:root@slavenode1:~/.ssh/" rel="nofollow"><span>hadoop@slavenode3:~/.ssh/</span></a></p>
<p> </p>
<p>[hadoop@masternode ~]# cat .ssh/authorized_keys </p>
<br><p> </p>
<p>13.把主机hosts拷贝到其他从机器上</p>
<p>[hadoop@masternode centos]# scp /etc/hosts hadoop@10.10.1.5:/etc/hosts</p>
<p>hosts                                                                                          100%  332     0.3KB/s   00:00    </p>
<p>[hadoop@masternode centos]# scp /etc/hosts hadoop@10.10.1.3:/etc/hosts</p>
<p>hosts                                                                                          100%  332     0.3KB/s   00:00    </p>
<p>[hadoop@masternode centos]# scp /etc/hosts hadoop@10.10.1.6:/etc/hosts</p>
<p>二.安装java软件</p>
<p>1)解压java软件包</p>
<p>   cd /usr/java/</p>
<p>tar -xvf jdk-7u79-linux-x64.tar.gz </p>
<p>chown -R hadoop:hadoop jdk-7u79</p>
<p> </p>
<p>2）编辑环境变量</p>
<p>编辑"/etc/profile"文件，在后面添加Java的"JAVA_HOME"、"CLASSPATH"以及"PATH"内容如下：</p>
<p> vi /etc/profile</p>
<p><span style="background:rgb(255,255,0);">export JAVA_HOME=/usr/java/jdk1.7.0_79/</span></p>
<p><span style="background:rgb(255,255,0);">export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span></p>
<p><span style="background:rgb(255,255,0);">export PATH=$PATH:$JAVA_HOME/bin</span></p>
<p><span style="color:#3366ff;">3</span><span style="color:#3366ff;">）使配置生效</span></p>
<p>保存并退出，执行下面命令使其配置立即生效。</p>
<p><span>source /etc/profile </span>或 . /etc/profile</p>
<p> </p>
<p>Vi ~/.bash_profile </p>
<p>export JAVA_HOME=/usr/java/jdk1.7.0_79/</p>
<p>export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</p>
<p>export PATH=$PATH:$JAVA_HOME/bin</p>
<p>#set hadoop path</p>
<p>export HADOOP_HOME=/opt/hadoop/hadoop-2.7.2</p>
<p>export PATH=$PATH:$HADOOP_HOME/bin</p>
<p>Source ~/.bash_profile</p>
<p>4）验证安装成功</p>
<p>配置完毕并生效后，用下面命令判断是否成功。</p>
<p>[hadoop@masternode java]# <span>java -version</span></p>
<p>java version "1.7.0_79"</p>
<p>Java(TM) SE Runtime Environment (build 1.7.0_79-b15)</p>
<p>Java HotSpot(TM) 64-Bit Server VM (build 24.79-b02, mixed mode)</p>
<p>5） 安装剩余机器java</p>
<p>通过scp命令格式把"/usr/java/"文件复制到其他Slave上面，剩下的事儿就是在其余的Slave服务器上按照上图的步骤配置环境变量和测试是否安装成功，这里以Slavenode2为例：</p>
<p>[hadoop@masternode java]# scp -r jdk1.7.0_79/ <a href="mailto:root@10.10.10.3:/opt/hadoop/" rel="nofollow"><span>hadoop@10.10.1.3:</span>/usr/java/</a></p>
<p>[hadoop@masternode java]# scp -r jdk1.7.0_79/ <a href="mailto:root@10.10.10.3:/opt/hadoop/" rel="nofollow"><span>hadoop@10.10.1.5:/</span>usr/java/</a></p>
<p>[hadoop@masternode java]# scp -r jdk1.7.0_79/ <a href="mailto:root@10.10.10.6:/opt/hadoop/" rel="nofollow"><span>hadoop@10.10.1.6:</span>/usr/java/</a></p>
<p><span>此时不可以选择较低版本的JDK进行安装</span>，<span>因为</span><span>所有集群中的JDK版本必须相同</span></p>
<p>三.安装hadoop软件包</p>
<p> 1 解压hadoop软件包</p>
<p>Cd /opt/hadoop/</p>
<p> tar -xvf hadoop-2.7.2.tar.gz </p>
<p>[root@masternode hadoop]# ls</p>
<p>hadoop-2.7.2         jdk1.7.0_79                lost+found</p>
<p>hadoop-2.7.2.tar.gz  jdk-7u79-linux-x64.tar.gz</p>
<p>[root@masternode hadoop]# cd hadoop-2.7.2</p>
<p>[root@masternode hadoop-2.7.2]# ls</p>
<p>bin  include  libexec      NOTICE.txt  sbin</p>
<p>etc  lib      LICENSE.txt  README.txt  share</p>
<p>2设置环境变量</p>
<p>并把Hadoop的安装路径添加到"<span>/etc/profile</span>"中，修改"/etc/profile"文件，将以下语句添加到<span>末尾</span>，并使其生效(. /etc/profile)：</p>
<p>#set hadoop path</p>
<p><span>export HADOOP_HOME=/opt/hadoop/hadoop-2.7.2</span></p>
<p><span>export PATH=$PATH:$HADOOP_HOME/bin</span></p>
<p>[root@masternode conf]# hadoop version</p>
<p>Hadoop 2.7.2</p>
<p>Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41</p>
<p>Compiled by jenkins on 2016-01-26T00:08Z</p>
<p>Compiled with protoc 2.5.0</p>
<p>From source with checksum d0fda26633fa762bff87ec759ebe689c</p>
<p>This command was run using /opt/hadoop/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar</p>
<p>3 创建临时目录</p>
<p>su - hadoop<br></p>
<p>[hadoop@masternode hadoop-2.7.2]# mkdir -p ~/tmp</p>
<p>[hadoop@masternode hadoop-2.7.2]# mkdir -p ~/dfs/data</p>
<p>[hadoop@masternode hadoop-2.7.2]# mkdir -p ~/dfs/name</p>
<br><p>4配置hadoop</p>
<p>修改配置文件</p>
<p>需要修改的配置文件主要有下面几个：</p>
<p>./core-site.xml </p>
<p>./hdfs-site.xml </p>
<p>./mapred-site.xml（开始的安装包中是没有这个文件的，需要将文</p>
<p>件./mapred-site.xml.template复制并且重名为mapred-site.xml）。</p>
<p>./yarn-site.xml </p>
<p>./yarn-env.sh </p>
<p>./hadoop-env.sh </p>
<p>./slave</p>
<p>[root@masternode hadoop-2.7.2]# pwd</p>
<p>/opt/hadoop/hadoop-2.7.2</p>
<p>[root@masternode hadoop-2.7.2]# ls</p>
<p>bin  include  libexec      NOTICE.txt  sbin</p>
<p>etc  lib      LICENSE.txt  README.txt  share</p>
<p>[root@masternode hadoop-2.7.2]# cd etc/hadoop/</p>
<p>/opt/hadoop/hadoop-2.7.2/etc/hadoop</p>
<p><span style="color:#3366ff;">（1）配置hadoop-env.sh</span></p>
<p>配置 hadoop-env.sh文件--&gt;修改JAVA_HOME</p>
<p><span style="background:rgb(255,255,0);">export JAVA_HOME=/usr/java/jdk1.7.0_79/</span></p>
<p><span style="color:#3366ff;">(2）配置</span><span>yarn-env.sh</span><span style="color:#3366ff;">文件 </span></p>
<p>配置 yarn-env.sh 文件--&gt;&gt;修改JAVA_HOME</p>
<p># some Java parameters</p>
<p><span style="background:rgb(255,255,0);">export JAVA_HOME=/usr/java/jdk1.7.0_79/</span></p>
<p><span style="color:#3366ff;">（3）</span><span style="color:#3366ff;">配置</span><span style="color:#3366ff;">slaves</span></p>
<p>配置slaves文件--&gt;&gt;增加slave节点</p>
<p><span style="background:rgb(255,255,0);">slavenode1</span></p>
<p><span style="background:rgb(255,255,0);">slavenode2</span></p>
<p><span style="background:rgb(255,255,0);">slavenode3</span></p>
<p> </p>
<p> </p>
<p>(4)配置 core-site.xml文件</p>
<p>--&gt;&gt;增加hadoop核心配置（hdfs文件端口是9000、file://root/hadoop/tmp、）</p>
<p>&lt;configuration&gt;</p>
<p> &lt;property&gt;</p>
<p>  &lt;name&gt;fs.defaultFS&lt;/name&gt;</p>
<p>  &lt;value&gt;<span>hdfs://masternode:9000</span>&lt;/value&gt;</p>
<p> &lt;/property&gt;</p>
<p> </p>
<p> &lt;property&gt;</p>
<p>  &lt;name&gt;io.file.buffer.size&lt;/name&gt;</p>
<p>  &lt;value&gt;131072&lt;/value&gt;</p>
<p> &lt;/property&gt;</p>
<p> &lt;property&gt;</p>
<p>  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</p>
<p>  &lt;value&gt;f<span>ile:/<span>home/</span>hadoop/tmp</span>&lt;/value&gt;</p>
<p>  &lt;description&gt;Abasefor other temporary directories.&lt;/description&gt;</p>
<p> &lt;/property&gt;</p>
<p> &lt;property&gt;</p>
<p>  &lt;name&gt;hadoop.proxyuser.spark.hosts&lt;/name&gt;</p>
<p>  &lt;value&gt;*&lt;/value&gt;</p>
<p> &lt;/property&gt;</p>
<p>&lt;property&gt;</p>
<p>  &lt;name&gt;hadoop.proxyuser.spark.groups&lt;/name&gt;</p>
<p>  &lt;value&gt;*&lt;/value&gt;</p>
<p> &lt;/property&gt;</p>
<p>&lt;/configuration&gt;</p>
<p> </p>
<p>(5)配置  hdfs-site.xml 文件--&gt;&gt;增加hdfs配置信息（namenode、datanode端口和目录位置）</p>
<p>&lt;configuration&gt;</p>
<p>&lt;property&gt;</p>
<p>  &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</p>
<p>  &lt;value&gt;<span>masternode:9001</span>&lt;/value&gt;</p>
<p> &lt;/property&gt;</p>
<p>  &lt;property&gt;</p>
<p>   &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</p>
<p>   &lt;value&gt;<span>file:/<span>home</span>/hadoop/dfs/name</span>&lt;/value&gt;</p>
<p> &lt;/property&gt;</p>
<p> &lt;property&gt;</p>
<p>  &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</p>
<p>  &lt;value&gt;<span>file:/<span>home</span>/hadoop/dfs/data</span>&lt;/value&gt;</p>
<p>  &lt;/property&gt;</p>
<p> &lt;property&gt;</p>
<p>  &lt;name&gt;dfs.replication&lt;/name&gt;</p>
<p>  &lt;value&gt;3&lt;/value&gt;</p>
<p> &lt;/property&gt;</p>
<p> &lt;property&gt;</p>
<p>  &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;</p>
<p>  &lt;value&gt;true&lt;/value&gt;</p>
<p> &lt;/property&gt;</p>
<p>&lt;/configuration&gt;</p>
<p><span style="color:#ff6666;">(6)</span><span style="color:#ff6666;">配置  mapred-site.xml 文件</span></p>
<p><span style="color:#ff6666;">--&gt;&gt;增加mapreduce配置（使用yarn框架、jobhistory使用地址以及web地址）</span></p>
<p><span style="color:#ff6666;">[</span><span style="color:#ff6666;">root@masternode</span><span style="color:#ff6666;"> hadoop]# mv mapred-site.xml.template mapred-site.xml</span></p>
<p> vi mapred-site.xml</p>
<p>&lt;configuration&gt;</p>
<p>&lt;property&gt;</p>
<p>   &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</p>
<p>   &lt;value&gt;yarn&lt;/value&gt;</p>
<p> &lt;/property&gt;</p>
<p> &lt;property&gt;</p>
<p>  &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</p>
<p>  &lt;value&gt;<span>masternode:10020</span>&lt;/value&gt;</p>
<p> &lt;/property&gt;</p>
<p> &lt;property&gt;</p>
<p>  &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</p>
<p>  &lt;value&gt;<span>masternode:19888</span>&lt;/value&gt;</p>
<p> &lt;/property&gt;</p>
<p> </p>
<p>&lt;/configuration&gt;</p>
<p>(7)配置yarn-site.xml  文件--&gt;&gt;增加yarn功能</p>
<p>&lt;configuration&gt;</p>
<p> </p>
<p>&lt;!-- Site specific YARN configuration properties --&gt;</p>
<p> </p>
<p> &lt;property&gt;</p>
<p>   &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</p>
<p>   &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</p>
<p>  &lt;/property&gt;</p>
<p>  &lt;property&gt;</p>
<p>   &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;</p>
<p>   &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</p>
<p>  &lt;/property&gt;</p>
<p>  &lt;property&gt;</p>
<p>   &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</p>
<p>   &lt;value&gt;<span>masternode</span>:8032&lt;/value&gt;</p>
<p>  &lt;/property&gt;</p>
<p>  &lt;property&gt;</p>
<p>   &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</p>
<p>   &lt;value&gt;<span>masternode</span>:8030&lt;/value&gt;</p>
<p>  &lt;/property&gt;</p>
<p>  &lt;property&gt;</p>
<p>   &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</p>
<p>   &lt;value&gt;<span>masternode</span>:8035&lt;/value&gt;</p>
<p>  &lt;/property&gt;</p>
<p>  &lt;property&gt;</p>
<p>   &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</p>
<p>   &lt;value&gt;<span>masternode</span>:8033&lt;/value&gt;</p>
<p>  &lt;/property&gt;</p>
<p>  &lt;property&gt;</p>
<p>   &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</p>
<p>   &lt;value&gt;<span>masternode</span>:8088&lt;/value&gt;</p>
<p>  &lt;/property&gt;</p>
<p> </p>
<p>&lt;/configuration&gt;</p>
<p>现在在Master机器上的Hadoop配置就结束了，剩下的就是配置Slave机器上的Hadoop。</p>
<p><span>最简单的方法是</span>将 Master上配置好的hadoop所在文件夹"<span>/</span><span>opt</span><span>/hadoop</span><span>/</span><span>hadoop-2.7.2</span><span>"复制到所有的</span>Slave的"/opt/hadoop"目录下（实际上Slave机器上的slavers文件是不必要的， 复制了也没问题）。用下面命令格式进行。（<span>备注：</span>此时用户可以为普通用户也可以为root）   <br></p>
<p>chown -R hadoop:hadoop <a href="mailto:root@10.10.10.4:/opt/hadoop/" rel="nofollow">
<span>/opt/hadoop/hadoop-2.7.2</span></a><br></p>
<p>5.将配置好的hadoop文件copy到另一台slave机器上</p>
<p>[hadoop@masternode hadoop]# scp -r hadoop-2.7.2/ <a href="mailto:root@10.10.10.4:/opt/hadoop/" rel="nofollow"><span>hadoop@10.10.1.4:/opt/hadoop/</span></a></p>
<p>[hadoop@masternode hadoop]# scp -r hadoop-2.7.2/ <a href="mailto:root@10.10.10.4:/opt/hadoop/" rel="nofollow"><span>hadoop@10.10.1.5:/opt/hadoop/</span></a></p>
<p>[hadoop@masternode hadoop]# scp -r hadoop-2.7.2/ <a href="mailto:root@10.10.10.4:/opt/hadoop/" rel="nofollow"><span>hadoop@10.10.1.6:/opt/hadoop/</span></a></p>
<p>接着在"Slave1 .Hadoop"上修改"/etc/profile"文件，将以下语句添加到末尾，并使其有效（source /etc/profile）：</p>
<p><span>export HADOOP_HOME=/opt/hadoop/hadoop-2.7.2</span></p>
<p><span>export PATH=$PATH:$HADOOP_HOME/bin</span></p>
<p>保存并退出，执行下面命令使其配置立即生效。</p>
<p><span>source /etc/profile </span>或 . /etc/profile</p>
<p>6.启动及验证</p>
<p>1)、格式化namenode:</p>
<p>[hadoop@masternode hadoop]# pwd</p>
<p>/opt/hadoop</p>
<p>[hadoop@masternode hadoop]# cd hadoop-2.7.2</p>
<p>[hadoop@masternode hadoop-2.7.2]# ls</p>
<p>bin  include  libexec      NOTICE.txt  sbin</p>
<p>etc  lib      LICENSE.txt  README.txt  share</p>
<p>[hadoop@masternode hadoop-2.7.2]# <span style="background:rgb(255,255,0);">./bin/hdfs namenode -format</span></p>
<p>2).启动hadoop</p>
<p>hadoop@masternode centos]# cd /opt/hadoop/hadoop-2.7.2</p>
<p>[hadoop@masternode hadoop-2.7.2]# sbin/start-all.sh </p>
<p>7.验证hadoop</p>
<p>（1）验证方法一：用"jps"命令</p>
<p>在Master上用 java自带的小工具jps查看进程。</p>
<p>[hadoop@masternodehadoop-2.7.2]# jps </p>
<p>19495 Jps</p>
<p>18849 NameNode</p>
<p>19051 SecondaryNameNode</p>
<p>19228 ResourceManager</p>
<p>[hadoop@masternode  centos]# jps</p>
<p>11664 Jps</p>
<p>11418 DataNode</p>
<p>11519 NodeManager</p>
<p>2）必须要关闭防火墙</p>
<p>[root@masternode hadoop-2.7.2]# service iptables stop</p>
<p>http://125.208.3.88:50070/dfshealth.html#tab-datanode</p>
<p><span style="color:#3366ff;">3</span><span style="color:#3366ff;">）禁用selinux</span></p>
<p>    编辑 "<span>/etc/selinux/config</span>"文件，设置"<span>SELINUX</span>=<span>disabled</span>"</p>
<p>或者setenforce 0</p>
<p>8.网页查看集群</p>
<p><span style="color:#3366ff;">（1）访问"http://</span><span style="color:#3366ff;">125.208.3.88</span><span style="color:#3366ff;">:50070"</span></p>
<p>Hadoop安装完成之后，会有两个web管理界面，可以分别通过下面的url查看。 在浏览器中输入http://<span style="color:#3366ff;">125.208.3.88</span>:8088/，网址为master的ip： </p>
<p>在浏览器中输入：http://<span style="color:#3366ff;">125.208.3.88</span>:50070/，网址为master结点所对应的IP： </p>
<p><a href="http://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-common/ClusterSetup.html" rel="nofollow"><span>http://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-common/ClusterSetup.html</span></a></p>
<p>9.HDFS的使用 </p>
<p>9.1 帮助 </p>
<p>如果配置好了环境变量，直接运行hdfs命令，不加任何参数就能得到hdfs的帮助。也可以用hdfs –help得到HDFS的帮助。</p>
<p><span>[hadoop@masternode hadoop]# hdfs -help</span></p>
<p>Usage: hdfs [--config confdir] [--loglevel loglevel] COMMAND</p>
<p>       where COMMAND is one of:</p>
<p>  dfs                  run a filesystem command on the file systems supported in Hadoop.</p>
<p>  classpath            prints the classpath</p>
<p>从上面可以看到，dfs命令是执行一个HDFS文件系统支持的命令。可以进一步查看dfs的帮助。下面列出的是hdfs的dfs命令支持的一些文件系统操作，实际上，具体的各个操作的格式可以也从下面看到具体的说明。</p>
<p><span>[hadoop@masternode hadoop]# hdfs dfs -help</span></p>
<br>            </div>
                </div>