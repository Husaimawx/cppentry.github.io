---
layout:     post
title:      Spark 源码阅读一-启动脚本
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：技术专栏，转载请注明！					https://blog.csdn.net/wankunde/article/details/48655585				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h1 id="spark-complile">Spark Complile</h1>

<p><a href="http://spark.apache.org/docs/latest/building-spark.html" rel="nofollow">Help Links</a></p>



<pre class="prettyprint"><code class=" hljs lasso"><span class="hljs-comment">// Because spark 1.5 need maven version:3.3.3 ,so i track the branch-1.4</span>
git branch <span class="hljs-attribute">-a</span>
git checkout <span class="hljs-subst">--</span>track origin/branch<span class="hljs-subst">-</span><span class="hljs-number">1.4</span>
git <span class="hljs-built_in">tag</span> 
git checkout v1<span class="hljs-number">.4</span><span class="hljs-number">.1</span>

<span class="hljs-comment">//Building for Scala 2.11 </span>
<span class="hljs-built_in">.</span>/dev/change<span class="hljs-attribute">-version</span><span class="hljs-attribute">-to</span><span class="hljs-subst">-</span><span class="hljs-number">2.11</span><span class="hljs-built_in">.</span>sh 

export MAVEN_OPTS<span class="hljs-subst">=</span><span class="hljs-string">"-Xmx2g -XX:MaxPermSize=512M -XX:ReservedCodeCacheSize=512m"</span>

<span class="hljs-comment">// edit ~/sql/catalyst/pom.xml replace quasiquotes_2.10 artifactId name</span>
mvn clean package <span class="hljs-attribute">-DskipTests</span> <span class="hljs-attribute">-Pscala</span><span class="hljs-subst">-</span><span class="hljs-number">2.11</span> <span class="hljs-attribute">-Pyarn</span> <span class="hljs-attribute">-Phadoop</span><span class="hljs-subst">-</span><span class="hljs-number">2.4</span> <span class="hljs-attribute">-Dhadoop</span><span class="hljs-built_in">.</span>version<span class="hljs-subst">=</span><span class="hljs-number">2.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.2</span><span class="hljs-number">.0</span>
<span class="hljs-comment">// some other option  -Psbt -Pjava8-tests -Phive-thriftserver -Ptest-java-home </span>

<span class="hljs-comment">// Building a Runnable Distribution</span>
<span class="hljs-built_in">.</span>/make<span class="hljs-attribute">-distribution</span><span class="hljs-built_in">.</span>sh <span class="hljs-subst">--</span>name custom<span class="hljs-attribute">-spark</span> <span class="hljs-subst">--</span>tgz <span class="hljs-attribute">-DskipTests</span> <span class="hljs-attribute">-Pscala</span><span class="hljs-subst">-</span><span class="hljs-number">2.11</span> <span class="hljs-attribute">-Pyarn</span> <span class="hljs-attribute">-Phadoop</span><span class="hljs-subst">-</span><span class="hljs-number">2.4</span> <span class="hljs-attribute">-Dhadoop</span><span class="hljs-built_in">.</span>version<span class="hljs-subst">=</span><span class="hljs-number">2.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-cdh5</span><span class="hljs-number">.2</span><span class="hljs-number">.0</span>  </code></pre>

<p><strong>Note</strong></p>

<ul>
<li>If you compile error in hive-thrift module, add the following dependency in the pom </li>
</ul>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-tag">&lt;<span class="hljs-title">dependency</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">groupId</span>&gt;</span>jline<span class="hljs-tag">&lt;/<span class="hljs-title">groupId</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">artifactId</span>&gt;</span>jline<span class="hljs-tag">&lt;/<span class="hljs-title">artifactId</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">version</span>&gt;</span>0.9.94<span class="hljs-tag">&lt;/<span class="hljs-title">version</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">dependency</span>&gt;</span></code></pre>



<h1 id="configuration">Configuration</h1>



<h2 id="examples">examples</h2>



<pre class="prettyprint"><code class=" hljs avrasm">spark<span class="hljs-preprocessor">.master</span>                     spark://master:<span class="hljs-number">7077</span>
spark<span class="hljs-preprocessor">.master</span>                     yarn-client
spark<span class="hljs-preprocessor">.eventLog</span><span class="hljs-preprocessor">.enabled</span>           true
spark<span class="hljs-preprocessor">.eventLog</span><span class="hljs-preprocessor">.dir</span>               hdfs://dmp<span class="hljs-preprocessor">.zamplus</span><span class="hljs-preprocessor">.net</span>:<span class="hljs-number">9000</span>/logs/spark
spark<span class="hljs-preprocessor">.serializer</span>                 org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.spark</span><span class="hljs-preprocessor">.serializer</span><span class="hljs-preprocessor">.KryoSerializer</span>
spark<span class="hljs-preprocessor">.driver</span><span class="hljs-preprocessor">.memory</span>              <span class="hljs-number">2</span>g
spark<span class="hljs-preprocessor">.executor</span><span class="hljs-preprocessor">.extraJavaOptions</span>  -XX:+PrintGCDetails -XX:+PrintGCTimeStamps

spark<span class="hljs-preprocessor">.yarn</span><span class="hljs-preprocessor">.jar</span>                    hdfs://dmp<span class="hljs-preprocessor">.zamplus</span><span class="hljs-preprocessor">.net</span>:<span class="hljs-number">9000</span>/libs/spark-assembly-<span class="hljs-number">1.4</span><span class="hljs-number">.1</span>-hadoop2<span class="hljs-number">.4</span><span class="hljs-number">.0</span><span class="hljs-preprocessor">.jar</span></code></pre>



<h2 id="helps">Helps</h2>

<ul>
<li>Spark website:  <br>
<ul><li>Configuration:<a href="http://spark.apache.org/docs/latest/configuration.html" rel="nofollow">http://spark.apache.org/docs/latest/configuration.html</a></li></ul></li>
<li>Other documents: <br>
<ul><li><a href="http://www.cnblogs.com/chengxin1982/p/4023111.html" rel="nofollow">http://www.cnblogs.com/chengxin1982/p/4023111.html</a></li>
<li>Test Case : <a href="http://www.tuicool.com/articles/eyi63aa" rel="nofollow">http://www.tuicool.com/articles/eyi63aa</a></li>
<li>FAQ : <a href="http://blog.csdn.net/xiao_jun_0820/article/details/45038205" rel="nofollow">http://blog.csdn.net/xiao_jun_0820/article/details/45038205</a></li>
-</ul></li>
</ul>



<h2 id="spark-default-configuration">Spark default Configuration</h2>

<ul>
<li>executors <br>
<ul><li>–num-executors (default : 2)</li>
<li>–executor-cores (default : 1)</li></ul></li>
<li>memory <br>
<ul><li>–driver-memory 4g</li>
<li>–executor-memory 2g</li></ul></li>
<li>Java OPTS <br>
<ul><li>-verberos:gc -XX;+PrintGCDetails -XX:+PrintGCTimeStamps </li>
<li>spark.driver.extraJavaOptions -XX:PermSize=128M -XX:MaxPermSize=256M   ( same as –driver-java-options in the command line)</li></ul></li>
<li>spark.serializer <br>
<ul><li>default : org.apache.spark.serializer.KryoSerializer</li>
-</ul></li>
</ul>

<p><strong>[TODO]</strong></p>

<ul>
<li>I don’t know when i use <code>spark-shell</code> script ,I must add a parameter <code>-Dspark.master=spark://dmp.zamplus.net:7077</code>. This really pullzed me.</li>
</ul>

<h1 id="startup-script-execution">Startup script execution</h1>

<ul>
<li><code>$SPARK_HOME/bin/spark-shell</code></li>
<li><code>$SPARK_HOME/bin/spark-submit --class org.apache.spark.repl.Main</code></li>
<li><code>$SPARK_HOME/bin/spark-class org.apache.spark.deploy.SparkSubmit --class org.apache.spark.repl.Main</code></li>
<li><code>$JAVA_HOME/java -cp $SPARK_HOME/lib/spark-assembly-1.4.1-hadoop2.4.0.jar org.apache.spark.launcher.Main org.apache.spark.deploy.SparkSubmit --class org.apache.spark.repl.Main</code></li>
<li><code>$JAVA_HOME/java-cp$SPARK_HOME/conf/:$SPARK_HOME/lib/spark-assembly-1.4.1-hadoop2.4.0.jar:$SPARK_HOME/lib/datanucleus-api-jdo-3.2.6.jar:$SPARK_HOME/lib/datanucleus-core-3.2.10.jar:$SPARK_HOME/lib/datanucleus-rdbms-3.2.9.jar:/home/wankun/hadoop/etc/hadoop/-Xms2g -Xmx2g -XX:MaxPermSize=256morg.apache.spark.deploy.SparkSubmit--classorg.apache.spark.repl.Mainspark-shell</code></li>
</ul>

<p><strong>Notes</strong></p>

<ul>
<li>The output cmds is separated by ‘\0’.</li>
</ul>



<h2 id="faq">FAQ</h2>

<ul>
<li>Q1</li>
</ul>

<blockquote>
  <p>Invalid initial heap size: -Xms2g <br>
  Error: Could not create the Java Virtual Machine. <br>
  Error: A fatal exception has occurred. Program will exit.</p>
</blockquote>

<p>This error is because of error configuration in <strong>spark-default.properties</strong> . Two space after the <em>spark.driver.memory</em> parameter.</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>