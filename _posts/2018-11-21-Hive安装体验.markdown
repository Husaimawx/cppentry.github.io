---
layout:     post
title:      Hive安装体验
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>只需要在一台机器上安装hive就行了，一般在namenode上，只是一个工具而已了<br>
</p>
<p><br>
</p>
<p>http://mirrors.hust.edu.cn/apache/hive/hive-2.2.0/</p>
<p>此处下载的是2.2版本的</p>
<p>hive是一个数据仓库，以我理解就是把一些的数据放到hive里面去进行分析，用于替代mapreduce</p>
<p>mapreduce编写复杂 所以hive 运用而生 用sql来进行处理</p>
<p>hive依赖于一个数据库如最常用的mysql，用来存放元数据，比如hive的建表语句crud等语句操作的存储</p>
<p>而真正的数据存放在hdfs上，如果说把hdfs hive目录删除了，然后再启动hive还是会有原来的那些自己创建的</p>
<p>库表，只不过其中的数据为空<br>
</p>
<p>启动hive则会在相应的hdfs上创建一个工作目录，然后通过sqoop将数据库中的数据导入到此目录进行分析</p>
<p>所以首先安装mysql</p>
<p>tar -zxvr hive</p>
<p>修改配置文件<br>
</p>
<p>cd conf</p>
<p>vim hive-site.xml</p>
<p><br>
</p>
<p>&lt;configuration&gt;<br>
&lt;property&gt;<br>
&lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;<br>
&lt;value&gt;jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;<br>
&lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;<br>
&lt;/property&gt;<br>
<br>
&lt;property&gt;<br>
&lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;<br>
&lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;<br>
&lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;<br>
&lt;/property&gt;<br>
<br>
&lt;property&gt;<br>
&lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;<br>
&lt;value&gt;root&lt;/value&gt;<br>
&lt;description&gt;username to use against metastore database&lt;/description&gt;<br>
&lt;/property&gt;<br>
<br>
&lt;property&gt;<br>
&lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;<br>
&lt;value&gt;root&lt;/value&gt;<br>
&lt;description&gt;password to use against metastore database&lt;/description&gt;<br>
&lt;/property&gt;<br>
&lt;/configuration&gt;<br>
<br>
</p>
<p>将mysql驱动jar包放到 hive/lib中</p>
<p>然后 提前start-dfs.sh  bin/hive</p>
<p>就可以启动了，不需要配置其他的乱七八糟的，会自动的加载hadoop的配置</p>
<p>但是我出现了一个错误</p>
<p></p>
<h1 class="csdn_top">java.base/jdk.internal.loader.ClassLoaders$AppClassLoader cannot be cast to java.base/java.net.URLCl</h1>
其原因是jdk版本过高，我用的是9 ，所以将jdk改为1.8即可，但我还是报这个错误，原因是我没有删除原来的9，hadoop配置的是9。而hive会自动加载hadoop配置
<p></p>
<p>so 更改hadoop配置 vim hadoop-env.sh</p>
<p>结论：程序还是用stable 不用最新版</p>
<p>hive 2已经不支持mr，太慢改为spark ，如果要hive支持mr 用hive1.x</p>
<p><br>
</p>
<p>hive允许远程链接只需遵循thrift协议</p>
<p><br>
</p>
<p>服务端 bin/hiveserver2</p>
<p>客户端 cd hive/bin</p>
<p>./beeline</p>
<p>!connect jdbc:hive2://localhost:10000</p>
<p>username hdfsusername</p>
<p>passwd null<br>
</p>
<p><br>
</p>
<p>hive -e xxx执行一条sql语句</p>
<p>hive -f xx执行放在文件中的sql</p>
<p>执行的sql语句需加引号否则报解析错误<br>
</p>
            </div>
                </div>