---
layout:     post
title:      Hadoop启动过程
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>1、hadoop四大模块：</p>

<p style="text-indent:50px;">（1）hadoop common：通用模块，是hadoop其他模块的基础，对应core-site.xml文件</p>

<p style="text-indent:50px;">fs.defaultFS------hdfs://s101 ====== 指定hadoop的文件系统，hdfs文件系统</p>

<p style="text-indent:50px;">hadoop.tmp.dir------/home/centos/hadoop ====== hadoop工作目录位置</p>

<p style="text-indent:50px;">（2）hdfs：对应用数据提供高吞吐量的访问，对应hdfs-site.xml文件</p>

<p style="text-indent:50px;">dfs.replication------3 ====== 副本数，相当于备份数</p>

<p style="text-indent:50px;">（3）yarn：分布式调度模块，，对应yarn-site.xml文件</p>

<p style="text-indent:50px;">resourcemanager------s101 ====== resourcemanager进程的地址，只在master节点上存在</p>

<p style="text-indent:50px;">（4）mapreduce：分布式计算模块，，对应mapred-site.xml文件</p>

<p style="text-indent:50px;">framework------yarn ====== mapreduce的资源调度框架，yarn是mapreduce的第二代资源调度框架</p>

<p style="text-indent:0;">2、启动hadoop：在s101上输入"start-all.sh"，通过"jps"查看主节点进程，也可以分为两步启动</p>

<p style="text-indent:50px;">（1）start-dfs.sh ====== 启动hdfs,分布式存储</p>

<p style="text-indent:50px;">namenode：名称节点，存储元数据，比如块大小，文件名，副本，权限等等</p>

<p style="text-indent:50px;">      hdfs getconf -namenode ====== 获取namenode节点</p>

<p style="text-indent:50px;">      hadoop-daemons.sh  --hostnames s101  start namenode ====== 单独启动namenode节点</p>

<p style="text-indent:50px;">      hadoop-daemon.sh start namenode ====== （简写）单独启动namenode节点</p>

<p style="text-indent:50px;">datanode：数据节点，存储真实数据，以"blk"形式存储</p>

<p style="text-indent:50px;">      hadoop-daemons.sh start datanode ====== 单独启动namenode节点</p>

<p style="text-indent:50px;">secondary namenode：辅助名称节点（在哪个节点启动都可以），检查点：用作日志滚动和镜像文件融合，备份数据</p>

<p style="text-indent:50px;">      hdfs getconf -secondarynamenodes 2&gt;/dev/null ====== 获取2nn节点地址，并将错误信息重定向到"/dev/null"</p>

<p style="text-indent:50px;">      hadoop-daemons.sh --hostnames 0.0.0.0 start secondarynamenode ====== 单独启动2nn节点</p>

<p style="text-indent:50px;">      hadoop-daemon.sh start secondarynamenode ====== （简写）单独启动2nn节点</p>

<p style="text-indent:50px;">（2）start-yarn.sh ====== 启动yarn，分布式计算和调度</p>

<p style="text-indent:50px;">resourcemanager：资源管理器</p>

<p style="text-indent:50px;">yarn-daemon.sh start resourcemanager ====== 单独启动资源管理器</p>

<p style="text-indent:50px;">nodemanager：节点管理器</p>

<p style="text-indent:50px;">yarn-daemons.sh start nodemanager ====== 单独启动节点管理器</p>

<p style="text-indent:50px;">（3）总结：</p>

<p style="text-indent:50px;">在s101上启动所有进程：start-all.sh</p>

<p style="text-indent:50px;">在s101上启动所有hdfs进程：start-dfs.sh</p>

<p style="text-indent:50px;">在s101上启动namenode进程：hadoop-daemon.sh start namenode</p>

<p style="text-indent:50px;">在s101启动所有datanode进程：hadoop-daemons.sh start datanode</p>

<p style="text-indent:50px;">在s101上启动2nn进程：hadoop-daemon.sh start secondarynamenode</p>

<p style="text-indent:50px;">在s101上启动resourcemanager：yarn-daemon.sh start resourcemanager        </p>

<p style="text-indent:50px;">在s101上启动nodemanager：yarn-daemons.sh start nodemanager</p>

<p style="text-indent:50px;"><span style="color:#f33b45;"><strong>hadoop-daemon.sh ====== 启动当前节点的进程</strong></span></p>

<p style="text-indent:50px;"><span style="color:#f33b45;"><strong>hadoop-daemons.sh ====== 启动其所有节点的进程</strong></span></p>

<p style="text-indent:50px;">停止进程：将所有"start"改为"stop"：</p>

<p style="text-indent:50px;">hadoop-daemon.sh启动过程：通过PID文件验证进程是否存在，若存在，提示在启动之前先关闭</p>

<p style="text-indent:50px;">hadoop-daemon.sh关闭过程：通过PID文件验证进程是否存在，若存在，则通过"kill"命令杀死进程，如果在超时时间未正常关闭，则通过"kill -9"命令强制杀死进程</p>

<p style="text-indent:0;">3、启动过程常见错误及解决方案：</p>

<p style="text-indent:50px;">（1）多次格式化出现错误，datanode无法正常启动，解决思路：</p>

<p style="text-indent:50px;">查看对应主机的相关日志信息：cd /soft/hadoop/logs，cat hadoop-centos-datanode-s102.log</p>

<p style="text-indent:50px;">得到信息：多次格式化，导致namenode和datanode的集群id不匹配，由于格式化只对namenode有效，对其它节点无效</p>

<p style="text-indent:50px;">删除对应文件夹：ssh s102 "rm -rf /home/centos/hadoop"（s103，s104）</p>

<p style="text-indent:50px;">在s101重新启动datanode：hadoop-daemons.sh start datanode</p>

<p style="text-indent:50px;">（2）没有格式化文件系统，导致namenode无法正常启动，解决思路：</p>

<p style="text-indent:50px;">查看对应主机的相关日志信息：cd /soft/hadoop/logs，cat hadoop-centos-namenode-s101.log</p>

<p style="text-indent:50px;">得到信息：namenode的工作目录不存在或者无法访问</p>

<p style="text-indent:50px;">格式化文件系统：hdfs namenode -format</p>

<p style="text-indent:50px;">在s101重新启动namenode：hadoop-daemon.sh start namenode</p>

<p style="text-indent:50px;">又出现<strong><span style="color:#f33b45;">错误（1）</span></strong>，查看错误（1）的解决思路</p>

<p style="text-indent:50px;">（3）进程正常启动，datanode无法使用，解决思路：</p>

<p style="text-indent:50px;">查看日志：cd /soft/hadoop/logs，cat hadoop-centos-datanode-s103.log</p>

<p style="text-indent:50px;">得到信息：本机连通s101出现问题，将主机名s101解析为其他IP地址</p>

<p style="text-indent:50px;">修改hosts文件：sudo nano /etc/hosts</p>

<p style="text-indent:50px;">重新启动hadoop</p>

<p style="text-indent:50px;">（4）进程正常启动，datanode无法使用，上传文件失败</p>

<p style="text-indent:50px;">防火墙没有关闭，查看本机防火墙，并关闭</p>            </div>
                </div>