---
layout:     post
title:      HIVE服务启动与HIVE命令冲突解决办法
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/sdauzyh/article/details/47000475				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>首先应配置hive文件，一共有如下六个文件。</p>
<p><img src="https://img-blog.csdn.net/20150722111133725?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></p>
<p>在根目录下输入gedit .bashrc 改一下环境变量</p>
<p># Source global definitions<br>
if [ -f /etc/bashrc ]; then<br><span></span>. /etc/bashrc<br>
fi<br><br>
# User specific aliases and functions<br><br><br>
export JAVA_HOME=/usr/lib/jvm/java-openjdk<br>
export MAVEN_HOME=/home/hadoop/maven<br>
export ANT_HOME=/home/hadoop/antexport <br>
export HIVE_HOME=/home/hadoop/hive<br>
export SPARK_HOME=/home/hadoop/spark<br><br>
export HADOOP_HOME=/home/hadoop/hadoop<br>
export PATH=$PATH:$JAVA_HOME/bin:$HIVE_HOME/bin:$SPARK_HOME/bin:$MAVEN_HOME/bin:/home/hadoop/protobuf/bin:$ANT_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:/home/hadoop/hbase/bin:/home/hadoop/redis/bin:.<br>
export CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar<br></p>
<p><br></p>
<p>配置完成</p>
<p>启动配置</p>
<p>[hadoop@master ~]$ start-all.sh<br>
This script is Deprecated. Instead use start-dfs.sh and start-yarn.sh<br>
Starting namenodes on [master]<br>
master: starting namenode, logging to /home/hadoop/hadoop/logs/hadoop-hadoop-namenode-master.out<br>
master: starting datanode, logging to /home/hadoop/hadoop/logs/hadoop-hadoop-datanode-master.out<br>
Starting secondary namenodes [master]<br>
master: starting secondarynamenode, logging to /home/hadoop/hadoop/logs/hadoop-hadoop-secondarynamenode-master.out<br>
starting yarn daemons<br>
starting resourcemanager, logging to /home/hadoop/hadoop/logs/yarn-hadoop-resourcemanager-master.out<br>
master: starting nodemanager, logging to /home/hadoop/hadoop/logs/yarn-hadoop-nodemanager-master.out<br>
[hadoop@master ~]$ jps<br>
4919 SecondaryNameNode<br>
5069 ResourceManager<br>
5170 NodeManager<br>
4637 NameNode<br>
5395 Jps<br>
4737 DataNode</p>
<p>启动hive服务，用于连接jdbc使用<br>
[hadoop@master ~]$ hive --service hiveserver &amp;<br>
[1] 5494<br>
[hadoop@master ~]$ Starting Hive Thrift Server<br>
hive<br><br><br>
Logging initialized using configuration in file:/home/hadoop/hive/conf/hive-log4j.properties<br>
hive&gt; exit;<br>
[hadoop@master ~]$ OK<br>
OK<br>
Copying data from file:/home/hadoop/hadoop/input/hive_test.log<br>
Copying file: file:/home/hadoop/hadoop/input/hive_test.log<br>
Loading data to table default.testhivedrivertable<br>
Table default.testhivedrivertable stats: [numFiles=1, numRows=0, totalSize=811, rawDataSize=0]<br>
OK<br>
Total jobs = 1<br>
Launching Job 1 out of 1<br>
Number of reduce tasks is set to 0 since there's no reduce operator<br>
Starting Job = job_1437530693126_0001, Tracking URL = http://master:8088/proxy/application_1437530693126_0001/<br>
Kill Command = /home/hadoop/hadoop/bin/hadoop job  -kill job_1437530693126_0001<br>
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0<br>
2015-07-22 10:10:22,534 Stage-1 map = 0%,  reduce = 0%<br>
2015-07-22 10:10:32,485 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.75 sec<br>
MapReduce Total cumulative CPU time: 1 seconds 750 msec<br>
Ended Job = job_1437530693126_0001<br>
MapReduce Jobs Launched: <br>
Job 0: Map: 1   Cumulative CPU: 1.75 sec   HDFS Read: 1038 HDFS Write: 366 SUCCESS<br>
Total MapReduce CPU Time Spent: 1 seconds 750 msec<br>
OK<br><br><br>
hive命令和$ hive --service hiveserver &amp;命令启动程序运行后 两者不能不能同时运行，需要将其中一个命令退出才能执行</p>
<p>退出hive命令使用exit</p>
<p>退出$ hive --service hiveserver &amp;服务需要将此服务的端口退出。使用kill 端口号<br>
详见下面语句。<br><br><br><br><span></span>at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)<br><span></span>at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)<br><span></span>at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)<br><span></span>at java.lang.reflect.Constructor.newInstance(Constructor.java:526)<br><span></span>at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)<br><span></span>at com.jolbox.bonecp.BoneCP.&lt;init&gt;(BoneCP.java:422)<br><span></span>at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)<br><span></span>at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:501)<br><span></span>at org.datanucleus.store.rdbms.RDBMSStoreManager.&lt;init&gt;(RDBMSStoreManager.java:298)<br><span></span>at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)<br><span></span>at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)<br><span></span>at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)<br><span></span>at java.lang.reflect.Constructor.newInstance(Constructor.java:526)<br><span></span>at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:631)<br><span></span>at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)<br><span></span>at org.datanucleus.NucleusContext.createStoreManagerForProperties(NucleusContext.java:1187)<br><span></span>at org.datanucleus.NucleusContext.initialise(NucleusContext.java:356)<br><span></span>at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:775)<br><span></span>... 46 more<br>
Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader sun.misc.Launcher$AppClassLoader@56ad4264, see the next exception for details.<br><span></span>at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source)<br><span></span>at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)<br><span></span>at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)<br><span></span>at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)<br><span></span>at org.apache.derby.impl.jdbc.EmbedConnection.&lt;init&gt;(Unknown Source)<br><span></span>at org.apache.derby.impl.jdbc.EmbedConnection40.&lt;init&gt;(Unknown Source)<br><span></span>at org.apache.derby.jdbc.Driver40.getNewEmbedConnection(Unknown Source)<br><span></span>at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)<br><span></span>at org.apache.derby.jdbc.Driver20.connect(Unknown Source)<br><span></span>at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)<br><span></span>at java.sql.DriverManager.getConnection(DriverManager.java:571)<br><span></span>at java.sql.DriverManager.getConnection(DriverManager.java:187)<br><span></span>at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)<br><span></span>at com.jolbox.bonecp.BoneCP.&lt;init&gt;(BoneCP.java:416)<br><span></span>... 58 more<br>
Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader sun.misc.Launcher$AppClassLoader@56ad4264, see the next exception for details.<br><span></span>at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)<br><span></span>at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source)<br><span></span>... 72 more<br>
Caused by: java.sql.SQLException: Another instance of Derby may have already booted the database /home/hadoop/metastore_db.<br><span></span>at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)<br><span></span>at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source)<br><span></span>at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source)<br><span></span>at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)<br><span></span>... 69 more<br>
Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /home/hadoop/metastore_db.<br><span></span>at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)<br><span></span>at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)<br><span></span>at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)<br><span></span>at java.security.AccessController.doPrivileged(Native Method)<br><span></span>at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)<br><span></span>at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)<br><span></span>at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)<br><span></span>at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)<br><span></span>at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)<br><span></span>at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)<br><span></span>at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)<br><span></span>at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)<br><span></span>at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)<br><span></span>at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)<br><span></span>at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)<br><span></span>at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)<br><span></span>at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)<br><span></span>at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)<br><span></span>at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)<br><span></span>at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)<br><span></span>at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)<br><span></span>at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)<br><span></span>at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)<br><span></span>at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)<br><span></span>at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)<br><span></span>at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)<br><span></span>at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)<br><span></span>at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)<br><span></span>at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)<br><span></span>... 69 more<br>
[hadoop@master ~]$ hive --service hiveserver &amp;<br>
[2] 6384<br>
[hadoop@master ~]$ Starting Hive Thrift Server<br>
org.apache.thrift.transport.TTransportException: Could not create ServerSocket on address 0.0.0.0/0.0.0.0:10000.<br><span></span>at org.apache.thrift.transport.TServerSocket.&lt;init&gt;(TServerSocket.java:93)<br><span></span>at org.apache.thrift.transport.TServerSocket.&lt;init&gt;(TServerSocket.java:75)<br><span></span>at org.apache.hadoop.hive.metastore.TServerSocketKeepAlive.&lt;init&gt;(TServerSocketKeepAlive.java:34)<br><span></span>at org.apache.hadoop.hive.service.HiveServer.main(HiveServer.java:674)<br><span></span>at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<br><span></span>at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)<br><span></span>at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)<br><span></span>at java.lang.reflect.Method.invoke(Method.java:606)<br><span></span>at org.apache.hadoop.util.RunJar.main(RunJar.java:212)<br>
lsof -i:10000<br>
COMMAND  PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME<br>
java    5494 hadoop  267u  IPv4  49258      0t0  TCP *:ndmp (LISTEN)<br>
[2]+  Done                    hive --service hiveserver<br>
[hadoop@master ~]$ kill 5494<br>
[hadoop@master ~]$ hive<br><br><br>
Logging initialized using configuration in file:/home/hadoop/hive/conf/hive-log4j.properties<br>
hive&gt; show tables;<br>
OK<br>
testhivedrivertable<br>
Time taken: 1.166 seconds, Fetched: 1 row(s)<br>
hive&gt; exit;<br>
[1]+  Exit 143                hive --service hiveserver<br>
[hadoop@master ~]$ <br><br><br><br><br><br><br><br><br></p>
<p><br></p>
<p><br></p>
            </div>
                </div>