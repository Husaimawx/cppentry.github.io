---
layout:     post
title:      【大数据】HDFS
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/cheidou123/article/details/83759282				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h3><a id="HDFS_0"></a>一、什么是HDFS</h3>
<p>HDFS是什么：HDFS即Hadoop分布式文件系统（Hadoop Distributed Filesystem），以流式数据访问模式来存储超大文件，运行于商用硬件集群上，是管理网络中跨多台计算机存储的文件系统。</p>
<p>HDFS不适合用在：要求低时间延迟数据访问的应用，存储大量的小文件，多用户写入，任意修改文件。</p>
<h3><a id="HDFS_4"></a>二、HDFS的原理</h3>
<h4><a id="1hdfs_5"></a>1.hdfs数据块</h4>
<p>HDFS上的文件被划分为块大小的多个分块，作为独立的存储单元，称为数据块，起初默认大小是64MB,从2.7.3版本改成了128MB，这个块大小可以在hdfs-site.xml修改它的大小</p>
<h5><a id="11_7"></a>1.1使用数据块的好处：</h5>
<h6><a id="_8"></a>⑴一个文件的大小可以大于网络中任意一个磁盘的容量</h6>
<h6><a id="_9"></a>⑵使用抽象块概念而非整个文件作为存储单元，大大简化存储子系统的设计</h6>
<h6><a id="_3_10"></a>⑶提高可用性 将每个块复制到少数几个物理上相互独立的机器上（默认为3个），可以确保在块、磁盘或机器发生故障后数据不会丢失。如果发现一个块不可用，系统会从其他地方读取另一个副本。</h6>
<h5><a id="12_11"></a>1.2数据块为什么不能太大</h5>
<h6><a id="_12"></a>⑴重启过程中，数据块越大，系统加载时间越长</h6>
<h6><a id="_13"></a>⑵数据量的大小与问题解决的复杂度呈线性关系。对于同一个算法，处理的数据量越大，时间复杂度越高。</h6>
<h6><a id="Map_ReduceMapReduce_14"></a>⑶在Map Reduce框架里，Map之后的数据是要经过排序才执行Reduce操作的。这通常涉及到归并排序，而归并排序的算法思想便是“对小文件进行排序，然后将小文件归并成大文件”，因此“小文件”不宜过大。</h6>
<h6><a id="_15"></a>⑷数据量的大小与问题解决的复杂度呈线性关系。对于同一个算法，处理的数据量越大，时间复杂度越高。</h6>
<h5><a id="13_16"></a>1.3数据块为什么不能太小</h5>
<h6><a id="__17"></a>⑴减少硬盘寻道时间 如果数据块太多，会增加底层硬盘的寻道时间，这是数据量不能太小的根本原因！！！</h6>
<h6><a id="NameNode_namenode_18"></a>⑵减少NameNode内存消耗 数据块信息太多，会增加namenode的内存消耗</h6>
<h4><a id="2hdfs_19"></a>2.hdfs结构</h4>
<p><img src="https://img-blog.csdnimg.cn/20181111211904370.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoZWlkb3UxMjM=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h5><a id="Client__21"></a>⑴Client 客户端</h5>
<h6><a id="_HDFS_Client__Block_22"></a>文件切分。文件上传 HDFS 的时候，Client 将文件切分成 一个一个的Block，然后进行存储。</h6>
<h6><a id="_NameNode__23"></a>与 NameNode 交互，获取文件的位置信息</h6>
<h6><a id="_DataNode__24"></a>与 DataNode 交互，读取或者写入数据。</h6>
<h6><a id="Client__HDFSHDFS_25"></a>Client 提供一些命令来管理 HDFS，比如启动或者关闭HDFS</h6>
<h6><a id="Client__HDFS_26"></a>Client 可以通过一些命令来访问 HDFS</h6>
<h5><a id="NameNode__masternamenodefsimageedits_27"></a>⑵NameNode 就是 master，它是一个主管、管理者，namenode内存中存储的是=fsimage+edits。</h5>
<h6><a id="_HDFS__28"></a>管理 HDFS 的名称空间</h6>
<h6><a id="Block_29"></a>管理数据块（Block）映射信息</h6>
<h6><a id="_30"></a>配置副本策略</h6>
<h6><a id="_31"></a>处理客户端读写请求</h6>
<h5><a id="Secondary_NameNode__NameNode_NameNodeNameNode__NameNode__32"></a>⑶Secondary NameNode 并非 NameNode 的热备，存储NameNode的一部分信息。当NameNode 挂掉的时候，它并不能马上替换 NameNode 并提供服务</h5>
<h6><a id="_NameNodeSecondaryNameNode1namenodefsimageeditsnamenodenamenode_33"></a>辅助 NameNode，分担其工作量，SecondaryNameNode负责定时默认1小时，从namenode上，获取fsimage和edits来进行合并，然后再发送给namenode。减少namenode的工作量。</h6>
<h6><a id="_fsimagefseditsNameNode_34"></a>定期合并 fsimage和fsedits，并推送给NameNode</h6>
<h6><a id="_NameNode_35"></a>在紧急情况下，可辅助恢复 NameNode</h6>
<h5><a id="DataNodeSlaveNameNode_DataNode__36"></a>⑷DataNode：就是Slave。NameNode 下达命令，DataNode 执行实际的操作</h5>
<h6><a id="_37"></a>存储实际的数据块</h6>
<h6><a id="_38"></a>执行数据块的读/写操作</h6>
<h5><a id="fsimage__39"></a>⑸fsimage 元数据镜像文件（文件系统的目录树。）</h5>
<h5><a id="edits__40"></a>⑹edits 元数据的操作日志（针对文件系统做的修改操作记录）</h5>
<h4><a id="3hdfs_41"></a>3.hdfs写入</h4>
<p><img src="https://img-blog.csdnimg.cn/20181111212858555.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoZWlkb3UxMjM=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h5><a id="NameNodenamenode_43"></a>⑴客户端向NameNode发出写文件请求，namenode检查目标文件是否已存在，父目录是否存在</h5>
<h5><a id="namenode_44"></a>⑵namenode返回是否可以上传</h5>
<h5><a id="clientblok128m300m3128M128M44M_45"></a>⑶client会先对文件进行切分，比如一个blok块128m，文件有300m就会被切分成3个块，一个128M、一个128M、一个44M</h5>
<h5><a id="_46"></a>⑷</h5>
<h5><a id="_47"></a>⑸</h5>
<h4><a id="4hdfs_48"></a>4.hdfs读取</h4>
<p><img src="https://img-blog.csdnimg.cn/20181116101823726.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoZWlkb3UxMjM=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h5><a id="namenodeblockdatanodedatanode_50"></a>⑴跟namenode通信查询元数据（block所在的datanode节点），找到文件块所在的datanode服务器</h5>
<h5><a id="datanodesocket_51"></a>⑵挑选一台datanode（就近原则，然后随机）服务器，请求建立socket流</h5>
<h5><a id="datanodepacket_52"></a>⑶datanode开始发送数据（从磁盘里面读取数据放入流，以packet为单位来做校验）</h5>
<h5><a id="packetblockappendblock_53"></a>⑷客户端以packet为单位接收，先在本地缓存，然后写入目标文件，后面的block块就相当于是append到前面的block块最后合成最终需要的文件。</h5>

            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>