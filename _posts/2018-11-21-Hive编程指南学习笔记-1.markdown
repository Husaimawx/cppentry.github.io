---
layout:     post
title:      Hive编程指南学习笔记-1
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h1><a id="_0"></a>基础操作部分</h1>
<p></p><div class="toc"><h3>文章目录</h3><ul><li><a href="#_0" rel="nofollow">基础操作部分</a></li><ul><li><a href="#1Hive_4" rel="nofollow">1.Hive安装</a></li><ul><li><a href="#11_Hadoop_17" rel="nofollow">1.1 测试Hadoop</a></li><li><a href="#12_Hive_25" rel="nofollow">1.2 启动Hive</a></li></ul><li><a href="#2_53" rel="nofollow">2.数据类型和文件格式</a></li><ul><li><a href="#21__55" rel="nofollow">2.1 基本数据类型</a></li><li><a href="#22__79" rel="nofollow">2.2 集合数据类型</a></li><li><a href="#23_89" rel="nofollow">2.3文本文件数据编码</a></li><li><a href="#24_105" rel="nofollow">2.4读时模式</a></li></ul></ul></ul></div><p></p>
<h2><a id="1Hive_4"></a>1.Hive安装</h2>
<p>在学习中,不应该反复的困在安装软件中,应该更多的把精力放在应用和原理方面.这里省略了安装的整理.<br>
(实验环境使用打包好的大数据软件环境,Hive使用本地模式.)</p>
<blockquote>
<p>note:hive使用本地模式会运行的更快,可以设置属性来测试.</p>
</blockquote>
<pre><code class="prism language-shell"><span class="token punctuation">(</span>支持在分布式或者伪分布式下的场景<span class="token punctuation">)</span>
sethive.exec.mode.local.auto<span class="token operator">=</span>true
</code></pre>
<h3><a id="11_Hadoop_17"></a>1.1 测试Hadoop</h3>
<pre><code class="prism language-shell">hadoop dfs -ls / 
hadoop jar demo.jar wc_in wc_out
hadoop dfs -cat wc_out/
</code></pre>
<h3><a id="12_Hive_25"></a>1.2 启动Hive</h3>
<p>Hive支持命令行CLI运行.(hive)</p>
<pre><code class="prism language-shell">hive -help

<span class="token comment">#hive一次使用</span>
hive -e <span class="token string">"select * from dual;"</span>
hive -s -e  <span class="token string">"select name from dual;"</span> <span class="token operator">&gt;</span> /demo <span class="token comment">#把结果写到一个文件里面.(-S 开启静默模式)</span>

<span class="token comment">#从文件中执行Hive查询</span>
hive -f test.hql

<span class="token comment">#Hive支持Tab补全快捷键</span>
<span class="token comment">#查看操作历史:$HOME/.hivehistory (存最近的100条)</span>

<span class="token comment">#执行shell命令</span>
hive<span class="token operator">&gt;</span> <span class="token operator">!</span>/bin/echo <span class="token string">"Hello"</span><span class="token punctuation">;</span>
hive<span class="token operator">&gt;</span> <span class="token operator">!</span> <span class="token function">pwd</span>
<span class="token comment">#执行Hadoop dfs命令</span>
hive<span class="token operator">&gt;</span>dfs -ls /
<span class="token comment">#hive脚本注释:--</span>

<span class="token comment"># 显示字段名称:set hive.cli.print.header=true </span>
<span class="token comment"># 如果需要长期显示,键入配置文件.hiverc</span>
</code></pre>
<h2><a id="2_53"></a>2.数据类型和文件格式</h2>
<h3><a id="21__55"></a>2.1 基本数据类型</h3>

<table>
<thead>
<tr>
<th><strong>数据类型</strong></th>
<th><strong>长度</strong></th>
<th><strong>备注</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>tinyint</strong></td>
<td>1byte</td>
<td></td>
</tr>
<tr>
<td><strong>smailint</strong></td>
<td>2byte</td>
<td></td>
</tr>
<tr>
<td><strong>int</strong></td>
<td>4byte</td>
<td></td>
</tr>
<tr>
<td><strong>bigint</strong></td>
<td>8byte</td>
<td></td>
</tr>
<tr>
<td><strong>boolean</strong></td>
<td>布尔</td>
<td></td>
</tr>
<tr>
<td><strong>float</strong></td>
<td>单精度浮点数</td>
<td></td>
</tr>
<tr>
<td><strong>double</strong></td>
<td>双精度浮点数</td>
<td></td>
</tr>
<tr>
<td><strong>string</strong></td>
<td>字符序列</td>
<td></td>
</tr>
<tr>
<td><strong>timestamp</strong></td>
<td>时间戳</td>
<td></td>
</tr>
<tr>
<td><strong>binary</strong></td>
<td>字节数组</td>
<td></td>
</tr>
</tbody>
</table><p>说明:</p>
<ol>
<li>这些都是保留关键词.</li>
<li>这些都在对应的java数据类型.</li>
<li>工作中较多用到的是string,bigint,double,(Hadoop和hive中,强调优化磁盘的读写性能,对数据的长度限制不是很强)</li>
<li>CAST,类型转换</li>
</ol>
<h3><a id="22__79"></a>2.2 集合数据类型</h3>

<table>
<thead>
<tr>
<th><strong>数据类型</strong></th>
<th><strong>长度</strong></th>
<th><strong>备注</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>struct</td>
<td></td>
<td>struct(‘Jon’,‘DOe’)</td>
</tr>
<tr>
<td>map</td>
<td></td>
<td>map(“name”,yxy",“Age”,“12”)</td>
</tr>
<tr>
<td>array</td>
<td></td>
<td>Array(“Jon”,“Bool”)</td>
</tr>
</tbody>
</table><blockquote>
<p>说明:在工作的时候,遇到的这个次数不多,暂时跳过这部分.在后面再学习补充.</p>
</blockquote>
<h3><a id="23_89"></a>2.3文本文件数据编码</h3>

<table>
<thead>
<tr>
<th>分隔符</th>
<th>说明</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>\n</td>
<td>换行</td>
<td></td>
</tr>
<tr>
<td>^A  (ctrl A)</td>
<td>分割字段,可以使用\001</td>
<td></td>
</tr>
<tr>
<td>^B</td>
<td>用于在ARRAY,STRUCT,MAP之间做分割,可以用\002</td>
<td></td>
</tr>
<tr>
<td>^C</td>
<td>用于MAP中键的分割.可以输入\003代替</td>
<td></td>
</tr>
</tbody>
</table><p>说明:</p>
<ul>
<li>在存储数据的时候,需要额外注意一些问题,慎重处理分隔符问题.因为在一些情况下是存在\t.\n等奇怪的符号的,建议用一些特殊的符号.</li>
<li>Hive在建表的时候支持定义字段的分隔符.这方便了数据的ETL过程.</li>
<li>自定义语句格式
<ul>
<li><code>row format delimited fields terminated by '\t'</code></li>
</ul>
</li>
</ul>
<h3><a id="24_105"></a>2.4读时模式</h3>
<p>和传统数据库写入数据不一样,在大数据的场景下,入库的数据可能有很多.因此会存在一些特殊场景,(数据和表结构不一致).hive在这种情况下,会使用null来填充,尽量纠正这些问题.</p>

            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>