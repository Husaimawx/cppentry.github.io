---
layout:     post
title:      hive cli
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>Hive Cli </p>
<p> </p>
<p>= hive启动  = </p>
<p>*$ hive –f script.q </p>
<p>*$ hive -e 'SELECT *FROM dummy‘ </p>
<p>*$ hive -S -e 'SELECT* FROM dummy‘ </p>
<p>*$ hive -hiveconfhive.root.logger=DEBUG,console </p>
<p> </p>
<p>= set  = </p>
<p>*hive&gt;SET hive.enforce.bucketing=true;  //设置值 </p>
<p>*hive&gt;SET hive.enforce.bucketing;  // 显示值 </p>
<p>*hive&gt;set -v;  //显示所有的值，包括hadoop的。 </p>
<p>*hive&gt; set;//显示跟基本的hadoop不同的配置，原理就是比对当前的所有选项与基本的配置是否不同，如修改过，已经不同了就打印该值。 </p>
<p> </p>
<p>= dfs 命令 = </p>
<p>dfs 命令可以执行 Shell 环境下的hadoop fs 的所有命令 </p>
<p>例如： </p>
<p>列出 HDFS 上的文件： </p>
<p>hive&gt; dfs -ls/user/hive; </p>
<p> </p>
<p>= add  = </p>
<p>*ADD { FILE[S] |JAR[S] | ARCHIVE[S] } &lt;filepath1&gt; [&lt;filepath2&gt;]* </p>
<p>*hive&gt; add jar/tmp/a.jar; </p>
<p>*hive&gt; add jar/tmp/a.jar /tmp/b.jar; </p>
<p> </p>
<p>= delete  = </p>
<p>*DELETE { FILE[S] |JAR[S] | ARCHIVE[S] } [&lt;filepath1&gt; &lt;filepath2&gt; ..] </p>
<p> </p>
<p>= list  = </p>
<p>*LIST { FILE[S] |JAR[S] | ARCHIVE[S] } [&lt;filepath1&gt; &lt;filepath2&gt; ..] </p>
<p>*hive&gt; list jar; </p>
<p>*hive&gt; list jars; </p>
<p> </p>
<p>= show  = </p>
<p>*hive&gt; showfunctions; </p>
<p>*hive&gt; showtables; </p>
<p>*hive&gt; show tables'*tianzhao*'; </p>
<p>*hive&gt; showpartition tablename; </p>
<p>*hive&gt; show tableextended like table_with_partitions partition(ds=101); </p>
<p> </p>
<p>= desc  = </p>
<p>*hive&gt;desc/describe function length; </p>
<p>*hive&gt;desc/describe tablename; </p>
<p>*hive&gt;desc/describe extended tablename;  //显示表的信息 </p>
<p>*hive&gt;desc/describe extended tablename partition(ds=1); //显示partition的信息 </p>
<p>*hive&gt;desc/describe formatted tablename;  //显示表的信息,跟extended相比，显示更友好 </p>
<p> </p>
<p>= source  = </p>
<p>*hive&gt; source/home/username/sql/test.sql; </p>
<p> </p>
<p>= !  = </p>
<p>*hive&gt;!ls;  //ls当前目录 </p>
<p> </p>
<p>= quit  = </p>
<p>hive&gt;quit; 或者  hive&gt; exit; </p>
<p> </p>
<p>= hiveserver  = </p>
<p>* $hive --servicehiveserver </p>
<p>* $hive --servicehelp </p>
<p>Usage ./hive&lt;parameters&gt; --service serviceName &lt;service parameters&gt; </p>
<p>Service List: clihelp hiveserver hwi jar lineage metastore rcfilecat start-hive stop-hive</p>
<p>Parameters parsed: </p>
<p> --auxpath : Auxillary jars </p>
<p> --config : Hive configuration directory </p>
<p> --service : Starts specific service/component. cli is default </p>
<p>Parameters used: </p>
<p> HADOOP_HOME : Hadoop install directory </p>
<p> HIVE_OPT : Hive options </p>
<p>For help on aparticular service: </p>
<p> ./hive --service serviceName --help </p>
<p> </p>
<p> </p>
<p>*$hive --servicestart-hive </p>
<p>Starting Hive ThriftServer in Daemon Mode </p>
<p>starting jar, loggingto /home/tianzhao/hive/hadoop-0.19.1/bin/../logs/hadoop-tianzhao-jar-ubuntu.out</p>
<p>*$hive --servicestop-hive </p>
<p>Stopping Hive ThriftServer in Daemon Mode </p>
<p>stopping jar </p>
<p> </p>
<p> </p>
<p>[<a href="http://wiki.apache.org/hadoop/Hive/LanguageManual/Cli" rel="nofollow">http://wiki.apache.org/hadoop/Hive/LanguageManual/Cli</a>官方的配置Wiki]</p>
<p> </p>
<p>altertable s_spu set TBLPROPERTIES ('EXTERNAL'='TRUE'); //内部表转外部表 </p>
<p> </p>
<p>sethive.auto.convert.join=true; </p>
<p>sethive.exec.mode.local.auto=true; </p>
<p>sethive.mapred.local.mem = 200; </p>
<p>sethive.groupby.skewindata=true; </p>
<p> </p>
<p>alter serde </p>
<p>数据： </p>
<p>a,b </p>
<p>c,d </p>
<p>e,f </p>
<p>hive&gt; create tabledelim(key string, value string); </p>
<p>hive&gt; load datalocal inpath '/home/tianzhao/Documents/delim' into table delim;</p>
<p>hive&gt; select *from delim; </p>
<p>a,b NULL </p>
<p>c,d NULL </p>
<p>e,f NULL </p>
<p>hive&gt; ALTER TABLEdelim SET SERDEPROPERTIES ('field.delim' = ','); </p>
<p>a b </p>
<p>c d </p>
<p>e f </p>
<p> </p>
<p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-DropPartitions" rel="nofollow">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-DropPartitions</a></p>
<p>ALTER TABLE page_viewDROP PARTITION (dt='2008-08-08', country='us'); </p>
<p> </p>
<p>ALTER TABLE web_logADD IF NOT EXISTS PARTITION (pt='20120325') LOCATION'hdfs://localhost:9000/group/log1/2012/20120325';</p>
<p>ALTER TABLE web_logPARTITION(pt='20120325') SET FILEFORMAT SequenceFile; </p>
<p>ALTER TABLE r_tableSET SERDEPROPERTIES ('serialization.null.format'=); </p>
<p> </p>
<p>日志在：/tmp/$USER/hive.log  中 </p>
<p> </p>
<p>=kill job=<br></p>
<p>/dhwdata/hadoop/bin/../bin/hadoopjob  -Dmapred.job.tracker=hdpjt:9001-kill job_201208241319_843121</p>
<br>            </div>
                </div>