---
layout:     post
title:      Spark介绍及RDD整合
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-light">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h4><a id="Spark_0"></a>Spark介绍</h4>
<p>Spark是一个计算框架。<br>
它是一个快速可通用的引擎，主要用于<font color="red">大规模数据处理</font>。<br>
Apache Spark是一个<font color="red">开源的</font>计算系统，以使数据分析程序的书写和运行更快为目的。<br>
Spark另外的一个目的：<br>
<img src="https://img-blog.csdnimg.cn/20181118211432864.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuZHJlYV9udWxs,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h5><a id="Spark_6"></a>Spark历史</h5>
<p>Spark的开发团队：伯克利大学的AMP实验室<br>
以下图就是AMP实验室所开发出来的计算框架做数据分析时所用到的技术<br>
<img src="https://img-blog.csdnimg.cn/20181118205548392.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuZHJlYV9udWxs,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h6><a id="Spark06_10"></a>Spark第一个版本是0.6版本</h6>
<p>Spark第一个版本到现在已经是6年了，hadoop第一个版本到现在已经12年了。<br>
Spark是美国加州大学伯克利分校的AMP实验室(主要创始人lester和Matei)开发的通用的大数据处理框架<br>
2009伯克利大学开始编写最初的源代码<br>
2010年才开放的源码<br>
2012年2月发布了0.6.0版本<br>
2013年6月进入了Apache孵化器项目<br>
2013年年中Spark的主要成员成立的DataBricks公司<br>
2014年2月成为了Apache的顶级项目（8个月的时间）<br>
2015年5月底Spark1.0.0发布</p>
<p><font color="orange">Spark成立了一家公司叫做DataBricks</font>，它通过Apache来开源宣传技术，它来解决Spark的bug为商业提供服务。<br>
<font color="orange">Hadoop成立一家公司叫做CDH</font>，它也是通过Apache来开源宣传技术，它来解决Hadoop的bug为商业提供服务。<br>
商业版本都会比开源版本好用。</p>
<h5><a id="Sparkapi_25"></a>能够开发Spark的api汇总</h5>
<p>java(兼容性很好),scala(兼容性很好),python(兼容性不错),R语言(兼容性一般)都可以开发Spark<br>
java和scala开发spark它的兼容性，效率上没区别，因为都是基于JVM的编程语言，都是编译成.class再在虚拟机里执行。Spark是使用scala来写的，它的所有进程都是JVM进程。<br>
如果使用Python来写，它的解释器是CPython解释器，如果要在集群中运行，这个解释器与JVM会进行一个交互通信。存在①兼容性问题②传输效率问题</p>
<h5><a id="SparkMapReduce_29"></a>Spark比MapReduce快的原因</h5>
<p><img src="https://img-blog.csdnimg.cn/20181118214002866.png" alt="在这里插入图片描述"><br>
原因1：Spark支持基于内存迭代，MapReduce不支持<br>
<img src="https://img-blog.csdnimg.cn/20181118214402321.png" alt="在这里插入图片描述"><br>
原因2：因为DAG<br>
因为DAG能把Task根据宽窄依赖划分成结果集TaskSet，TaskSet给TaskScheduler进行Pipeline计算<br>
【注】<br>
迭代：每次的逻辑一模一样，利用上一次的结果进行计算<br>
递归：重复调用函数自身实现循环<br>
Spark支持内存迭代，MapReduce不支持</p>
<h5><a id="Spark_39"></a>Spark运行模式</h5>
<p><img src="https://img-blog.csdnimg.cn/20181118215936325.png" alt="在这里插入图片描述"></p>
<h4><a id="WordCount_41"></a>WordCount案例</h4>
<p>WordCount案例的目的是统计每一个单词出现的次数<br>
<img src="https://img-blog.csdnimg.cn/20181118222717860.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuZHJlYV9udWxs,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>
注：创建完项目之后，需要修改scala依赖包，还要创建Spark依赖包（去官网下）。<br>
思路：<br>
①创建配置对象<br>
②创建上下文，加载数据到RDD中<br>
③分词<br>
④分组，聚合<br>
⑤排序<br>
⑥输出</p>
<pre><code>object WCSpark {
  def main(args: Array[String]): Unit = {
    //创建配置对象
    val conf = new SparkConf()
    //设置App的名称   有啥用？ 方便在监控页面找到  MR-》Yarn 8088
    conf.setAppName("WCSpark")
    //设置Spark的运行模式  local本地运行  用于测试环境
    conf.setMaster("local")
    
    //创建Spark上下文 他是通往集群的唯一通道
    val sc = new SparkContext(conf)
       val lineRDD = sc.textFile("d:/wc.txt")
    //基于lineRDD中的数据 进行分词
    val wordRDD = lineRDD.flatMap { _.split(" ") }
    //每一个单词计数为1  pairRDD  K:word V:1
    val pairRDD = wordRDD.map { (_,1) }    
    //相同的单词进行分组，对组内的数据进行累加
    //restRDD K:word V:count
    val restRDD = pairRDD.reduceByKey((v1,v2)=&gt;v1+v2)
    }
}
</code></pre>
<p>根据单词出现的次数来排序<br>
方法1：sortByKey 根据key来排序</p>
<pre><code>restRDD
.map(_.swap)
.sortByKey(false)
.map(_.swap)
.foreach(println)
</code></pre>
<p>方法2：使用sortBy这个方法，来指定根据哪一个字段来排序</p>
<pre><code> restRDD
      .sortBy(x=&gt;x._2, false)
      .foreach(println)
</code></pre>
<p>最后，释放资源</p>
<pre><code> sc.stop()
</code></pre>
<h4><a id="RDD_94"></a>RDD</h4>
<p>R（Resilient）D（Distributed ）D（Dataset）：弹性分布式数据集<br>
对一个RDD执行一个方法，返回RDD。一切的计算基于RDD。</p>
<h5><a id="RDD_97"></a>RDD的五大特性</h5>
<h6><a id="RDDpartition_98"></a>RDD是由一系列partition组成的</h6>
<h6><a id="RDDpartition_99"></a>RDD提供的每一个函数实际上是作用在每一个partition上的</h6>
<h6><a id="RDDRDDRDD_100"></a>RDD是有一系列的依赖关系的，一个RDD依赖于其他RDD</h6>
<h6><a id="	KVRDD_101"></a>可选项	分区器是作用在KV格式的RDD上的</h6>
<h6><a id="	RDD_102"></a>可选项	RDD会提供一系列最佳的计算位置</h6>

            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>