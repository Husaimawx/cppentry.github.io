---
layout:     post
title:      Spark1.6.0-Hadoop2.6配置过程
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>spark目录下的conf文件夹下存放着spark的一系列配置文件 <br>
1、配置spark-env.sh</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-keyword">export</span> JAVA_HOME=/usr/lib/java/jdk1.<span class="hljs-number">7.0</span>_80
<span class="hljs-keyword">export</span> SCALA_HOME=/usr/lib/scala/scala-<span class="hljs-number">2.10</span>.<span class="hljs-number">4</span>
<span class="hljs-keyword">export</span> HADOOP_HOME=/usr/local/hadoop/hadoop-<span class="hljs-number">2.6</span>.<span class="hljs-number">0</span>
<span class="hljs-keyword">export</span> HADOOP_CONF_DIR=/usr/local/hadoop/hadoop-<span class="hljs-number">2.6</span>.<span class="hljs-number">0</span>/etc/hadoop
<span class="hljs-keyword">export</span> SPARK_MASTER_IP=master
<span class="hljs-keyword">export</span> SPARK_WORKER_MEMORY=<span class="hljs-number">4</span>g
<span class="hljs-keyword">export</span> SPARK_EXECUTOR_MEMORY=<span class="hljs-number">4</span>g
<span class="hljs-keyword">export</span> SPARK_DRIVER_MEMEORY=<span class="hljs-number">4</span>g
<span class="hljs-keyword">export</span> SPARK_WORKER_CORES=<span class="hljs-number">8</span></code></pre>

<p>2、配置slaves</p>



<pre class="prettyprint"><code class=" hljs ">slave01
slave02</code></pre>

<p>3、配置spark-defaults.conf</p>



<pre class="prettyprint"><code class=" hljs avrasm">spark<span class="hljs-preprocessor">.executor</span><span class="hljs-preprocessor">.extraJavaOptions</span>   -XX:+PrintGCDetails -DKey=value -Dnumbers=<span class="hljs-string">"one tow three"</span>
spark<span class="hljs-preprocessor">.eventLog</span><span class="hljs-preprocessor">.enabled</span>            true
spark<span class="hljs-preprocessor">.eventLog</span><span class="hljs-preprocessor">.dir</span>                hdfs://master:<span class="hljs-number">9000</span>/historyserverforSpark
spark<span class="hljs-preprocessor">.yarn</span><span class="hljs-preprocessor">.historyServer</span><span class="hljs-preprocessor">.address</span>  master:<span class="hljs-number">18080</span>
spark<span class="hljs-preprocessor">.history</span><span class="hljs-preprocessor">.fs</span><span class="hljs-preprocessor">.logDirectory</span>     hdfs://master:<span class="hljs-number">9000</span>/historyserverforSpark
<span class="hljs-preprocessor">#spark.default.parallelism        100</span></code></pre>

<p>4、配置~/.bashrc，修改完成之后source一下</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-keyword">export</span> JRE_HOME=<span class="hljs-variable">${JAVA_HOME}</span>/jre
<span class="hljs-keyword">export</span> HADOOP_HOME=/usr/local/hadoop/hadoop-<span class="hljs-number">2.6</span>.<span class="hljs-number">0</span>
<span class="hljs-keyword">export</span> HADOOP_CONF_DIR=<span class="hljs-variable">${HADOOP_HOME}</span>/etc/hadoop
<span class="hljs-keyword">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="hljs-variable">${HADOOP_HOME}</span>/lib/native
<span class="hljs-keyword">export</span> HADOOP_OPTS=<span class="hljs-string">"-Djava.library.path=<span class="hljs-variable">${HADOOP_HOME}</span>/lib"</span>
<span class="hljs-keyword">export</span> SCALA_HOME=/usr/lib/scala/scala-<span class="hljs-number">2.10</span>.<span class="hljs-number">4</span>
<span class="hljs-keyword">export</span> SPARK_HOME=/usr/local/spark/spark-<span class="hljs-number">1.6</span>.<span class="hljs-number">0</span>-bin-hadoop2.<span class="hljs-number">6</span>
<span class="hljs-keyword">export</span> IDEA_HOME=/usr/local/idea/idea-IC-<span class="hljs-number">135.1306</span>
<span class="hljs-keyword">export</span> CLASS_PATH=.:<span class="hljs-variable">${JAVA_HOME}</span>/lib:<span class="hljs-variable">${JRE_HOME}</span>/lib
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">${IDEA_HOME}</span>/bin:<span class="hljs-variable">${SPARK_HOME}</span>/bin:<span class="hljs-variable">${SCALA_HOME}</span>/bin:<span class="hljs-variable">${JAVA_HOME}</span>/bin:<span class="hljs-variable">${HADOOP_HOME}</span>/bin:<span class="hljs-variable">$PATH</span></code></pre>

<p>5、将整个spark1.6.0-hadoop2.6以及.bashrc文件拷贝到集群中的其他节点上，并且bashrc需要source一下 <br>
6、通过hdfs创建HistoryServer的文件夹，historyserverforSpark</p>



<pre class="prettyprint"><code class=" hljs perl">Hadoop dfs -<span class="hljs-keyword">mkdir</span> /historyserverforSpark</code></pre>

<p>7、启动spark和historyServer</p>

<pre class="prettyprint"><code class=" hljs sql">./<span class="hljs-operator"><span class="hljs-keyword">start</span>-<span class="hljs-keyword">all</span>.sh和./<span class="hljs-keyword">start</span>-history-server.sh</span></code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>