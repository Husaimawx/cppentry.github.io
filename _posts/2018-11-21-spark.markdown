---
layout:     post
title:      spark
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>Apache Hive 是 Hadoop 上的 SQL 引擎，Spark SQL 编译时可以包含 Hive 支持，也可以<br>
不包含。包含 Hive 支持的 Spark SQL 可以支持 Hive 表访问、UDF（用户自定义函数）、<br>
SerDe（序列化格式和反序列化格式），以及 Hive 查询语言（HiveQL/HQL）<br>
带有 Hive 支持的 Spark SQL 的 Maven 索引</p>
<pre><code>groupId = org.apache.spark
artifactId = spark-hive_2.10
version = 1.2.0
</code></pre>
<p>DataFrame(SchemaRDD) 是一个由 Row 对象组成的 RDD，附带包含每列数据类型的结构信息。Row 对象只是对基本数据类型（如整型和字符串型等）的数组的封装。可以把任意 SchemaRDD 注册为临时表，这样就可以使用 HiveContext.sql 或 SQLContext.sql 来对它进行查询了。你可以通过 SchemaRDD 的 registerTempTable() 方法这么做。临时表是当前使用的 HiveContext 或 SQLContext 中的临时变量，在你的应用退出时这些临时表就不再存在了。</p>

            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>