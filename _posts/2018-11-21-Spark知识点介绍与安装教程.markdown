---
layout:     post
title:      Spark知识点介绍与安装教程
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h1 id="spark介绍与安装教程linux系统" style="margin-left:0px;">Spark介绍与安装教程（Linux系统）</h1>

<p><img alt="这里写图片描述" class="has" height="300" src="https://img-blog.csdn.net/20160424140949011" width="300"></p>

<p> </p>

<ul><li><span style="color:#0c89cf;">Spark介绍与安装教程Linux系统</span>

	<ul><li><span style="color:#0c89cf;">Spark的介绍</span>

		<ul><li><span style="color:#0c89cf;">Hadoop与Strom</span></li>
			<li><span style="color:#0c89cf;">大数据处理</span></li>
			<li><span style="color:#0c89cf;">Spark特点与应用场景</span></li>
			<li><span style="color:#0c89cf;">框架</span></li>
			<li><span style="color:#0c89cf;">RDD</span></li>
			<li><span style="color:#0c89cf;">依赖</span></li>
			<li><span style="color:#0c89cf;">懒惰计算</span></li>
			<li><span style="color:#0c89cf;">DAG</span></li>
			<li><span style="color:#0c89cf;">调度过程</span></li>
			<li><span style="color:#0c89cf;">容错</span></li>
		</ul></li>
		<li><span style="color:#0c89cf;">Spark的安装教程</span>
		<ul><li><span style="color:#0c89cf;">安装JDK与Scala</span></li>
			<li><span style="color:#0c89cf;">安装Spark</span></li>
			<li><span style="color:#0c89cf;">测试</span></li>
			<li><span style="color:#0c89cf;">Wordcount示例</span></li>
		</ul></li>
	</ul></li>
</ul><p> </p>

<h2 id="spark的介绍" style="margin-left:0px;"><a name="t1"></a>Spark的介绍</h2>

<h3 id="hadoop与strom" style="margin-left:0px;"><a name="t2"></a>Hadoop与Strom</h3>

<p><a class="replace_word" href="http://lib.csdn.net/base/hadoop" rel="nofollow">Hadoop</a>：</p>

<ol><li>MapReduce：为海量数据提供了计算，但只有Map和Reduce操作，操作不灵活。</li>
	<li>HDFS（分布式文件系统）：为海量的数据提供了存储。（把全部计算机的存储能力合在一起，数据通过网络在节点之间传输）。 <br><img alt="这里写图片描述" class="has" height="200" src="https://img-blog.csdn.net/20160424140856914" width="300"> <br>
	Strom：一个分布式的、容错的实时计算系统。 <br><img alt="这里写图片描述" class="has" height="150" src="https://img-blog.csdn.net/20160424140932370" width="400"></li>
</ol><h3 id="大数据处理" style="margin-left:0px;"><a name="t3"></a>大数据处理</h3>

<ol><li>复杂的批量数据处理（batch data processing）</li>
	<li>基于历史数据的交互式查询（interactive query）</li>
	<li>基于实时数据流的数据处理（streaming data processing）</li>
</ol><h3 id="spark特点与应用场景" style="margin-left:0px;"><a name="t4"></a>Spark特点与应用场景</h3>

<p>  <a class="replace_word" href="http://lib.csdn.net/base/spark" rel="nofollow">Spark</a>是通用的并行化计算框架，基于MapReduce实现分布式计算，其中间结果可以保存在内存中，从而不再需要读写HDFS。</p>

<p>特点：</p>

<ol><li>简单方便，使用scala语言。（与RDD很好结合）</li>
	<li>计算速度快，中间结果缓存在内存中。</li>
	<li>高错误容忍。</li>
	<li>操作丰富。</li>
	<li>广播，每个节点可以保留一份小数据集。</li>
</ol><p><span style="color:#555555;">核心：</span><span style="color:#cc0000;">RDD(Resilient Distributed Datasets弹性分布式数据集)</span></p>

<p>应用场景：</p>

<ol><li>迭代式算法：迭代式机器学习、图算法，包括PageRank、K-means聚类和逻辑回归(logistic regression)。</li>
	<li>
	<p>交互式数据挖掘工具：用户在同一数据子集上运行多个Adhoc查询。</p>

	<h3 id="框架" style="margin-left:0px;"><a name="t5"></a>框架</h3>

	<p><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20160424141441669"></p>
	</li>
</ol><h3 id="rdd" style="margin-left:0px;"><a name="t6"></a>RDD</h3>

<p>  RDD是一种只读的、分区的记录集合。Spark借助RDD实现对类存的管理。</p>

<p>操作：</p>

<ol><li>转换（transformation）：生成新的RDD。（map/filter/groupBy/join）</li>
	<li>动作（action）：将RDD上的某项操作的结果返回给程序，不产生RDD。（count/reduce/collect/save）</li>
</ol><p>分区：对RDD分区，保存在多个节点上，实现分布式计算。 <br>
持久化：RDD缓存。（在内存中或者溢出到磁盘）（容错&amp;加速） <br>
血统（lineage）：RDD有足够信息关于它是如何从其他RDD产生而来的。（容错）</p>

<p><strong>对象： </strong><br><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20160424141814318"></p>

<h3 id="依赖" style="margin-left:0px;"><a name="t7"></a>依赖</h3>

<p><span style="color:#cc0000;">转换操作产生新的RDD </span><br><span style="color:#555555;"><img alt="这里写图片描述" class="has" height="300" src="https://img-blog.csdn.net/20160424141945976" width="400"> </span><br><span style="color:#555555;">窄依赖：父RDD只有一个子分区。 </span><br><span style="color:#555555;">宽依赖：每个子RDD依赖所有父RDD分区。</span></p>

<h3 id="懒惰计算" style="margin-left:0px;"><a name="t8"></a>懒惰计算</h3>

<p>懒惰计算（lazy evaluation）：Spark在遇到 Transformations操作时只会记录需要这样的操作，并不会去执行，需要等到有Actions操作的时候才会真正启动计算过程进行计算。（不像<a class="replace_word" href="http://lib.csdn.net/base/python" rel="nofollow">Python</a>和matlab马上执行）。</p>

<p>一个系统知道全部RDD的计算路径的时候，它才拥有最大的优化空间。</p>

<h3 id="dag" style="margin-left:0px;"><a name="t9"></a>DAG</h3>

<p>优化任意操作算子图 <br><img alt="这里写图片描述" class="has" height="300" src="https://img-blog.csdn.net/20160424142049039" width="400"></p>

<p>Spark会尽可能地管道化，并基于是否要重新组织数据来划分阶段(stage)。</p>

<p>窄依赖：多个RDD合并成一个，在一个节点进行，不用生成中间RDD结果。（管道化） <br>
宽依赖：没啥优化。</p>

<h3 id="调度过程" style="margin-left:0px;"><a name="t10"></a>调度过程</h3>

<p><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20160424142235657"> <br><img alt="这里写图片描述" class="has" height="500" src="https://img-blog.csdn.net/20160424142304298" width="500"></p>

<h3 id="容错" style="margin-left:0px;"><a name="t11"></a>容错</h3>

<ol><li>Checkpoint：数据备份，检测数据完整性。比较占用空间，数据复制需要消耗时间。（hadoop只有这个）</li>
	<li>loggingthe updates：依靠lineage chains，记录每个RDD产生方法，根据存储信息重构数据集合，其他节点帮组重构。节省空间，如果血缘关系复杂，可能导致全部节点重新计算。</li>
</ol><h2 id="spark的安装教程" style="margin-left:0px;"><span style="color:#ff0000;"><a name="t12"></a>Spark的安装教程</span></h2>

<h3 id="安装jdk与scala" style="margin-left:0px;"><a name="t13"></a>安装JDK与Scala</h3>

<ol><li>下载JDK：sudo apt-get install openjdk-7-jre-headless。</li>
	<li>下载Scala： <a href="http://www.scala-lang.org/" rel="nofollow">http://www.scala-lang.org/</a>。</li>
	<li>解压缩：tar –zxvf scala-2.10.6.tgz。</li>
	<li><strong>进入sudo vim /etc/profile在下面添加路径：</strong></li>
</ol><pre class="prettyprint">
<code>PATH=<span style="color:#660066;">$PATH</span>:<span style="color:#660066;">${SCALA_HOME}</span>/bin</code></pre>

<ol><li>使修改生效source /etc/profile。</li>
	<li>在命令行输入scala测试。</li>
</ol><h3 id="安装spark" style="margin-left:0px;"><a name="t14"></a>安装Spark</h3>

<ol><li>下载Spark： <a href="http://spark.apache.org/downloads.html" rel="nofollow">http://spark.apache.org/downloads.html</a> <br><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20160424142810347"></li>
	<li>解压缩： tar –zxvf spark-1.5.1-bin-hadoop2.6.tgz</li>
	<li><strong>进入sudo  vim /etc/profile在下面添加路径：</strong></li>
</ol><pre class="prettyprint">
<code>SPARK_HOME=<span style="color:#008800;">/home/spark</span><span style="color:#008800;">/spark-lectures/spark</span>-<span style="color:#006666;">1.5</span>.<span style="color:#006666;">1</span>-bin-hadoop2.<span style="color:#006666;">6</span> （解压后的包所在的路径）
PATH=<span style="color:#660066;">$PATH</span><span style="color:#006666;">:</span><span style="color:#660066;">${</span>SPARK_HOME}/bin</code></pre>

<p><a name="t15"></a>测试</p>

<ol><li><span style="color:#ff0000;">在命令行输入：spark-shell（可在安装目录中bin里面找到） </span><br><span style="color:#555555;"><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20160424143418308"></span></li>
	<li><span style="color:#cc0000;"><strong>进入bin目录，输入./run-example SparkPi 10(迭代次数) 计算π的值</strong></span></li>
	<li><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20160424143401355"></li>
	<li>bin目录： <br><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20160424143346317"></li>
</ol><h3 id="wordcount示例" style="margin-left:0px;"><a name="t16"></a>Wordcount示例</h3>

<ul><li>列表内容</li>
</ul><p>在命令行输入：spark-shell开启spark（<a class="replace_word" href="http://lib.csdn.net/base/scala" rel="nofollow">Scala</a>）</p>

<ul><li><strong>把输入文件加载进RDD：<span style="color:#008800;">YOUR_INPUT_FILE文件名称</span></strong></li>
</ul><pre class="prettyprint">
<code><span style="color:#000088;">val</span> textFile = sc.textFile(<span style="color:#008800;">"YOUR_INPUT_FILE"</span>)</code></pre>

<ul><li><strong>MapReduce操作，以work为key，1为value：</strong></li>
</ul><pre class="prettyprint">
<code> val wordCounts = textFile.flatMap<span style="color:#660066;">(line =&gt; line.split(<span style="color:#008800;">" "</span>))</span>.map<span style="color:#660066;">(word =&gt; (word, <span style="color:#006666;">1</span>))</span>.reduceByKey<span style="color:#660066;">((a, b) =&gt; a + b)</span></code></pre>

<ul><li><strong>查看每个单词出现的次数</strong></li>
</ul><pre class="prettyprint">
<code>  wordCounts<span style="color:#444444;">.collect</span>()</code>
</pre>

<p><img alt="这里写图片描述" class="has" src="https://img-blog.csdn.net/20160424143812069"></p>

<p> </p>            </div>
                </div>