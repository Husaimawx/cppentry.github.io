---
layout:     post
title:      HIve应用知识
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p><strong><span style="color:rgb(54,96,145);"><span style="font-family:'宋体';">目录</span></span></strong></p><p><a href="#_Toc16059" rel="nofollow"><span style="font-family:'宋体';">课程大纲（</span>HIVE<span style="font-family:'宋体';">增强）</span>	2</a></p><p><a href="#_Toc155" rel="nofollow">1. Hive<span style="font-family:'宋体';">基本概念</span>	3</a></p><p><a href="#_Toc21096" rel="nofollow">1.1 Hive<span style="font-family:'宋体';">简介</span>	3</a></p><p><a href="#_Toc4773" rel="nofollow">1.1.1 <span style="font-family:'宋体';">什么是</span><span style="font-family:Calibri;">Hive</span>	3</a></p><p><a href="#_Toc32048" rel="nofollow">1.1.2 <span style="font-family:'宋体';">为什么使用</span><span style="font-family:Calibri;">Hive</span>	3</a></p><p><a href="#_Toc5949" rel="nofollow">1.1.3 Hive<span style="font-family:'宋体';">的特点</span>	3</a></p><p><a href="#_Toc27062" rel="nofollow">1.2 Hive<span style="font-family:'宋体';">架构</span>	4</a></p><p><a href="#_Toc18265" rel="nofollow">1.2.1 <span style="font-family:'宋体';">架构图</span>	4</a></p><p><a href="#_Toc19067" rel="nofollow">1.2.2 <span style="font-family:'宋体';">基本组成</span>	4</a></p><p><a href="#_Toc23402" rel="nofollow">1.2.3 <span style="font-family:'宋体';">各组件的基本功能</span>	4</a></p><p><a href="#_Toc20043" rel="nofollow">1.3 Hive<span style="font-family:'宋体';">与</span>Hadoop<span style="font-family:'宋体';">的</span><span style="font-family:'宋体';">关系</span>	5</a></p><p><a href="#_Toc26251" rel="nofollow">1.4 Hive<span style="font-family:'宋体';">与传统数据库对比</span>	5</a></p><p><a href="#_Toc25944" rel="nofollow">1.5 Hive<span style="font-family:'宋体';">的数据存储</span>	6</a></p><p><a href="#_Toc950" rel="nofollow">1.6 HIVE<span style="font-family:'宋体';">的安装部署</span>	6</a></p><p><a href="#_Toc17399" rel="nofollow">1.6.1 <span style="font-family:'宋体';">安装</span>	6</a></p><p><a href="#_Toc11796" rel="nofollow">1.6.2 <span style="font-family:'宋体';">使用方式</span>	6</a></p><p><a href="#_Toc14412" rel="nofollow">2. Hive<span style="font-family:'宋体';">基本操作	</span>8</a></p><p><a href="#_Toc9321" rel="nofollow">2.1 DDL<span style="font-family:'宋体';">操作</span>	8</a></p><p><a href="#_Toc21109" rel="nofollow">2.1.1 创建表	8</a></p><p><a href="#_Toc31004" rel="nofollow">2.1.2 <span style="font-family:'宋体';">修改表</span>	10</a></p><p><a href="#_Toc6897" rel="nofollow">2.1.3 <span style="font-family:'宋体';">显示命令</span>	12</a></p><p><a href="#_Toc15233" rel="nofollow">2.1.4 <span style="font-family:'宋体';">保存</span><span style="font-family:Calibri;">select</span><span style="font-family:'宋体';">查询结果到其他表</span>	12</a></p><p><a href="#_Toc12630" rel="nofollow">2.2 DML<span style="font-family:'宋体';">操作</span>	13</a></p><p><a href="#_Toc19515" rel="nofollow">2.2.1 Load	13</a></p><p><a href="#_Toc15758" rel="nofollow">2.2.2 Insert	14</a></p><p><a href="#_Toc15866" rel="nofollow">2.2.3 SELECT	17</a></p><p><a href="#_Toc12347" rel="nofollow">2.3 Hive Join	21</a></p><p><a href="#_Toc27871" rel="nofollow">3 Hive Shell<span style="font-family:'宋体';">参数</span>	24</a></p><p><a href="#_Toc29419" rel="nofollow">3.1 Hive<span style="font-family:'宋体';">命令行</span>	24</a></p><p><a href="#_Toc2636" rel="nofollow">3.2 Hive<span style="font-family:'宋体';">参数配置方式</span>	26</a></p><p><a href="#_Toc28487" rel="nofollow">4. Hive<span style="font-family:'宋体';">函数</span>	27</a></p><p><a href="#_Toc2030" rel="nofollow">4.1 <span style="font-family:'宋体';">内置运算符</span>	27</a></p><p><a href="#_Toc19556" rel="nofollow">4.2 <span style="font-family:'宋体';">内置函数</span>	27</a></p><p><a href="#_Toc25654" rel="nofollow">4.3 Hive<span style="font-family:'宋体';">自定义函数和</span>Transform	27</a></p><p><a href="#_Toc31700" rel="nofollow">4.3.1 <span style="font-family:'宋体';">自定义函数类别</span>	27</a></p><p><a href="#_Toc11180" rel="nofollow"><span style="background:rgb(255,255,255);">4.3.2 UDF<span style="font-family:'宋体';">开发实例</span></span>	27</a></p><p><a href="#_Toc15419" rel="nofollow">4.3.3 Transform<span style="font-family:'宋体';">实现</span>	28</a></p><p><a href="#_Toc23994" rel="nofollow">5. Hive<span style="font-family:'宋体';">实战</span>	29</a></p><p><a href="#_Toc9573" rel="nofollow">Hive <span style="font-family:'宋体';">实战案例</span><span style="font-family:Calibri;">1</span><span style="font-family:'宋体';">——数据</span><span style="font-family:Calibri;">ETL</span>	29</a></p><p><a href="#_Toc6366" rel="nofollow"><span style="font-family:'宋体';">需求：</span>	29</a></p><p><a href="#_Toc12851" rel="nofollow"><span style="font-family:'宋体';">数据示例：</span>	29</a></p><p><a href="#_Toc20841" rel="nofollow"><span style="font-family:'宋体';">实现步骤：</span>	30</a></p><p><a href="#_Toc7900" rel="nofollow">Hive <span style="font-family:'宋体';">实战案例</span><span style="font-family:Calibri;">2</span><span style="font-family:'宋体';">——访问时长统计</span>	32</a></p><p><a href="#_Toc12080" rel="nofollow"><span style="font-family:'宋体';">需求：</span>	32</a></p><p><a href="#_Toc26202" rel="nofollow"><span style="font-family:'宋体';">实现步骤：</span>	32</a></p><p><a href="#_Toc20960" rel="nofollow">Hive<span style="font-family:'宋体';">实战案例</span><span style="font-family:Calibri;">3</span><span style="font-family:'宋体';">——级联求和</span>	33</a></p><p><a href="#_Toc16366" rel="nofollow"><span style="font-family:'宋体';">需求：</span>	33</a></p><p><a href="#_Toc30932" rel="nofollow"><span style="font-family:'宋体';">实现步骤</span>	33</a></p><p> </p><p> </p><h1><a></a><strong><span style="font-family:'宋体';">课程大纲（</span>HIVE<span style="font-family:'宋体';">增强）</span></strong></h1><p> </p><table><tbody><tr><td valign="top" rowspan="15"><p>Hive<span style="font-family:'宋体';">增强</span></p></td><td valign="top"><p>HIVE<span style="font-family:'宋体';">基本概念</span></p></td></tr><tr><td valign="top"><p>HIVE<span style="font-family:'宋体';">架构及运行机制</span></p></td></tr><tr><td valign="top"><p>HQL-DDL<span style="font-family:'宋体';">基本语法</span></p></td></tr><tr><td valign="top"><p>HQL-DML<span style="font-family:'宋体';">基本语法</span></p></td></tr><tr><td valign="top"><p>HIVE<span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">join</span></p></td></tr><tr><td valign="top"><p>HIVE UDF<span style="font-family:'宋体';">函数</span></p></td></tr><tr><td valign="top"><p>HIVE shell<span style="font-family:'宋体';">基本操作</span></p></td></tr><tr><td valign="top"><p>HIVE <span style="font-family:'宋体';">参数配置</span></p></td></tr><tr><td valign="top"><p>HIVE <span style="font-family:'宋体';">自定义函数和</span><span style="font-family:Calibri;">Transform</span></p></td></tr><tr><td valign="top"><p>HIVE <span style="font-family:'宋体';">执行</span><span style="font-family:Calibri;">HQL</span><span style="font-family:'宋体';">的实例分析</span></p></td></tr><tr><td valign="top"><p>HIVE<span style="font-family:'宋体';">最佳实践注意点</span></p></td></tr><tr><td valign="top"><p>HIVE<span style="font-family:'宋体';">优化策略</span></p></td></tr><tr><td valign="top"><p>HIVE<span style="font-family:'宋体';">实战案例</span><span style="font-family:Calibri;">1</span></p></td></tr><tr><td valign="top"><p>HIVE<span style="font-family:'宋体';">实战案例</span><span style="font-family:Calibri;">2</span></p></td></tr><tr><td valign="top"><p>HIVE<span style="font-family:'宋体';">实战案例</span><span style="font-family:Calibri;">3</span></p></td></tr></tbody></table><p> </p><p> </p><p>学习目标：</p><p>1<span style="font-family:'宋体';">、熟练掌握</span><span style="font-family:Calibri;">hive</span><span style="font-family:'宋体';">的使用</span></p><p>2<span style="font-family:'宋体';">、熟练掌握</span><span style="font-family:Calibri;">hql</span><span style="font-family:'宋体';">的编写</span></p><p>3<span style="font-family:'宋体';">、理解</span><span style="font-family:Calibri;">hive</span><span style="font-family:'宋体';">的工作原理</span></p><p>4<span style="font-family:'宋体';">、具备</span><span style="font-family:Calibri;">hive</span><span style="font-family:'宋体';">应用实战能力</span></p><p><br clear="all"><strong></strong></p><h1><a></a>1. <strong><a>H</a>ive<span style="font-family:'宋体';">基本概念</span></strong></h1><h2><span style="color:rgb(0,0,0);">1.1 </span><strong> <a></a><a>Hive<span style="font-family:'宋体';">简介</span></a></strong></h2><h3><a></a>1.1.1 <strong><a><span style="font-family:'宋体';">什么是</span>Hive</a></strong></h3><p>Hive<span style="font-family:'宋体';">是基于</span><span style="font-family:Calibri;">Hadoop</span><span style="font-family:'宋体';">的一个数据仓库工具，可以将</span><span style="color:rgb(255,0,0);">结构化的</span>数据文件<span style="color:rgb(255,0,0);">映射</span>为<span style="color:rgb(255,0,0);">一张数据库表</span>，并提供类</p><h3><a></a>1.1.2 <strong><a></a><a><span style="font-family:'宋体';">为什么使用</span>Hive</a></strong></h3><p>Ø <span style="font-family:'宋体';">直接使用</span>hadoop<span style="font-family:'宋体';">所面临的问题 </span></p><p><span style="font-family:'宋体';">人员学习成本太高</span> </p><p><span style="font-family:'宋体';">项目周期要求太短</span> </p><p>MapReduce<span style="font-family:'宋体';">实现复杂查询逻辑开发难度太大 </span></p><p> </p><p>Ø <span style="font-family:'宋体';">为什么要使用</span>Hive </p><p><span style="font-family:'宋体';">操作接口采用类</span>SQL<span style="font-family:'宋体';">语法，提供快速开发的能力。 </span></p><p><span style="font-family:'宋体';">避免了去写</span>MapReduce<span style="font-family:'宋体';">，减少开发人员的学习成本。 </span></p><p>扩展功能很方便。</p><h3><a></a>1.1.3 <strong><a></a><a>Hive<span style="font-family:'宋体';">的特点</span></a></strong></h3><p>Ø <span style="font-family:'宋体';">可扩展</span> </p><p>Hive<span style="font-family:'宋体';">可以自由的扩展集群的规模，一般情况下不需要重启服务。</span></p><p> </p><p>Ø <span style="font-family:'宋体';">延展性</span> </p><p>Hive<span style="font-family:'宋体';">支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。</span></p><p> </p><p>Ø <span style="font-family:'宋体';">容错</span> </p><p><span style="font-family:'宋体';">良好的容错性，节点出现问题</span>SQL<span style="font-family:'宋体';">仍可完成执行。</span></p><h2><span style="color:rgb(0,0,0);">1.2 </span><strong> <a></a><a></a><a>H</a>ive<span style="font-family:'宋体';">架构</span></strong></h2><h3><a></a>1.2.1 <strong><a></a><a><span style="font-family:'宋体';">架构图</span></a></strong></h3><p><span style="color:rgb(0,0,255);"> </span></p><p><span style="color:rgb(0,0,255);">Jobtracker是hadoop1.x中的组件，它的功能相当于： Resourcemanager+AppMaster</span></p><p><span style="color:rgb(0,0,255);"> </span></p><p><span style="color:rgb(0,0,255);">TaskTracker 相当于：  Nodemanager  +  yarnchild</span></p><p><span style="color:rgb(0,0,255);"> </span></p><p><span style="color:rgb(0,0,255);"> </span></p><p><span style="color:rgb(0,0,255);"> </span></p><p><span style="color:rgb(0,0,255);"> </span></p><h3><a></a>1.2.2 <strong><a></a><a><span style="font-family:'宋体';">基本组成</span></a></strong></h3><p>Ø <span style="font-family:'宋体';">用户接口</span>：<span style="font-family:'宋体';">包括</span> CLI、JDBC/ODBC、WebGUI。</p><p>Ø <span style="font-family:'宋体';">元数据存储</span>：<span style="font-family:'宋体';">通常是存储在关系数据库如</span> mysql , derby<span style="font-family:'宋体';">中</span>。</p><p>Ø <span style="font-family:'宋体';">解释器、编译器、优化器、执行器</span>。</p><h3><a></a>1.2.3 <a></a><a><span style="font-family:'宋体';">各组件的基本功能</span></a></h3><p>Ø <span style="font-family:'宋体';">用户接口</span>主要由三个：CLI、JDBC/ODBC和WebGUI<span style="font-family:'宋体';">。其中，</span>CLI<span style="font-family:'宋体';">为</span><span style="font-family:Verdana;">shell</span><span style="font-family:'宋体';">命令行；</span><span style="font-family:Verdana;">JDBC/ODBC</span><span style="font-family:'宋体';">是</span><span style="font-family:Verdana;">Hive</span><span style="font-family:'宋体';">的</span><span style="font-family:Verdana;">JAVA</span><span style="font-family:'宋体';">实现，与传统数据库</span><span style="font-family:Verdana;">JDBC</span><span style="font-family:'宋体';">类似；</span><span style="font-family:Verdana;">WebGUI</span><span style="font-family:'宋体';">是通过浏览器访问</span><span style="font-family:Verdana;">Hive</span><span style="font-family:'宋体';">。</span></p><p>Ø <span style="font-family:'宋体';">元数据存储</span>：Hive <span style="font-family:'宋体';">将元数据存储在数据库中。</span><span style="font-family:Verdana;">Hive </span><span style="font-family:'宋体';">中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等</span>。</p><p>Ø <span style="font-family:'宋体';">解释器、编译器、优化器完成</span> HQL <span style="font-family:'宋体';">查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在 </span><span style="font-family:Verdana;">HDFS </span><span style="font-family:'宋体';">中，并在随后有 </span><span style="font-family:Verdana;">MapReduce </span><span style="font-family:'宋体';">调用执行</span>。</p><h2><a></a><span style="color:rgb(0,0,0);">1.3 </span><strong><a></a><a>Hive</a>与Hadoop的<span style="font-family:'宋体';">关系</span> </strong></h2><p>Hive<span style="font-family:'宋体';">利用</span><span style="font-family:Calibri;">HDFS</span><span style="font-family:'宋体';">存储数据，利用</span><span style="font-family:Calibri;">MapReduce</span><span style="font-family:'宋体';">查询数据</span></p><p> </p><p> </p><p> </p><h2><a></a><span style="color:rgb(0,0,0);">1.4 </span><strong><a></a><a>Hive</a>与传统数据库对比</strong></h2><p> </p><p> </p><p><em><span style="background:rgb(127,127,127);"><span style="font-family:'宋体';">总结</span></span><span style="background:rgb(127,127,127);"><span style="font-family:'宋体';">：</span></span><span style="background:rgb(127,127,127);">hive<span style="font-family:'宋体';">具有</span><span style="font-family:Calibri;">sql</span><span style="font-family:'宋体';">数据库的外表</span></span><span style="background:rgb(127,127,127);"><span style="font-family:'宋体';">，</span></span><span style="background:rgb(127,127,127);"><span style="font-family:'宋体';">但应用场景完全不同</span></span><span style="background:rgb(127,127,127);"><span style="font-family:'宋体';">，</span></span><span style="background:rgb(127,127,127);">hive<span style="font-family:'宋体';">只适合用来做</span></span><span style="background:rgb(127,127,127);"><span style="font-family:'宋体';">批量</span></span><span style="background:rgb(127,127,127);"><span style="font-family:'宋体';">数据统计分析</span></span></em></p><h2><a></a><span style="color:rgb(0,0,0);">1.5 </span><strong><a></a><a>Hive<span style="font-family:'宋体';">的数据存储</span></a></strong></h2><p>1<span style="font-family:'宋体';">、</span>Hive<span style="font-family:'宋体';">中所有的数据都存储在</span> HDFS <span style="font-family:'宋体';">中</span>，<span style="font-family:'宋体';">没有专门的数据存储格式</span><span style="font-family:'宋体';">（可支持</span>Text<span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">SequenceFile</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">ParquetFile</span><span style="font-family:'宋体';">，</span>RCFILE等）</p><p>2<span style="font-family:'宋体';">、</span><span style="font-family:'宋体';">只需要在创建表的时候告诉</span> Hive <span style="font-family:'宋体';">数据中的列分隔符和行分隔符，</span>Hive <span style="font-family:'宋体';">就可以解析数据。</span></p><p>3<span style="font-family:'宋体';">、</span>Hive <span style="font-family:'宋体';">中包含以下数据模型：</span>DB<span style="font-family:'宋体';">、</span>Table<span style="font-family:'宋体';">，</span>External Table<span style="font-family:'宋体';">，</span>Partition<span style="font-family:'宋体';">，</span>Bucket<span style="font-family:'宋体';">。</span></p><p>² db<span style="font-family:'宋体';">：在</span><span style="font-family:Calibri;">hdfs</span><span style="font-family:'宋体';">中表现为</span>${hive.metastore.warehouse.dir}目录下一个文件夹</p><p>² table<span style="font-family:'宋体';">：在</span><span style="font-family:Calibri;">hdfs</span><span style="font-family:'宋体';">中表现所属</span><span style="font-family:Calibri;">db</span><span style="font-family:'宋体';">目录下一个文件夹</span></p><p>² external table<span style="font-family:'宋体';">：</span><span style="font-family:'宋体';">外部表</span>, <span style="font-family:'宋体';">与</span>table<span style="font-family:'宋体';">类似，不过其</span>数据存放位置可以在任意指定路径</p><p><span style="font-family:'宋体';">普通表</span>: <span style="font-family:'宋体';">删除表后</span><span style="font-family:Calibri;">, hdfs</span><span style="font-family:'宋体';">上的文件都删了</span></p><p>External<span style="font-family:'宋体';">外部表删除后</span><span style="font-family:Calibri;">, hdfs</span><span style="font-family:'宋体';">上的文件没有删除</span><span style="font-family:Calibri;">, </span><span style="font-family:'宋体';">只是把文件删除了</span></p><p>² partition<span style="font-family:'宋体';">：在</span><span style="font-family:Calibri;">hdfs</span><span style="font-family:'宋体';">中表现为</span><span style="font-family:Calibri;">table</span><span style="font-family:'宋体';">目录下的子目录</span></p><p>² bucket<span style="font-family:'宋体';">：</span><span style="font-family:'宋体';">桶</span>, <span style="font-family:'宋体';">在</span>hdfs<span style="font-family:'宋体';">中表现为同一个表目录下根据</span><span style="font-family:Calibri;">hash</span><span style="font-family:'宋体';">散列之后的多个文件</span>, <span style="font-family:'宋体';">会根据不同的文件把数据放到不同的文件中 </span></p><p> </p><p> </p><h2><a></a><strong><a>1.6 HIVE<span style="font-family:'宋体';">的安装部署</span></a></strong></h2><h3><a></a><strong><a>1.6.1 <span style="font-family:'宋体';">安装</span></a></strong></h3><p>单机版：</p><p><span style="font-family:'宋体';">元数据库</span>mysql<span style="font-family:'宋体';">版：</span></p><p> </p><h3><a></a><strong><a>1.6.2 <span style="font-family:'宋体';">使用方式</span></a></strong></h3><h4><a></a><strong>Hive<span style="font-family:'宋体';">交互</span><span style="font-family:Cambria;">shell</span></strong></h4><p>bin/hive</p><p> </p><p> </p><h4><a></a><strong>Hive thrift<span style="font-family:'宋体';">服务</span></strong></h4><p> </p><p><span style="font-family:'宋体';">启动方式，（假如是在</span>hadoop01<span style="font-family:'宋体';">上）：</span></p><p><span style="font-family:'宋体';">启动为前台：</span>bin/hiveserver2</p><p><span style="font-family:'宋体';">启动为后台：</span>nohup bin/hiveserver2 1&gt;/var/log/hiveserver.log 2&gt;/var/log/hiveserver.err &amp;</p><p> </p><p><span style="font-family:'宋体';">启动成功后，可以在别的节点上用</span>beeline<span style="font-family:'宋体';">去连接</span></p><p>v <span style="font-family:'宋体';">方式（</span>1<span style="font-family:'宋体';">）</span></p><p>hive/bin/beeline  <span style="font-family:'宋体';">回车，进入</span><span style="font-family:Calibri;">beeline</span><span style="font-family:'宋体';">的命令界面</span></p><p><span style="font-family:'宋体';">输入命令连接</span>hiveserver2</p><p>beeline&gt; !connect jdbc:hive2//mini1:10000</p><p><span style="font-family:'宋体';">（</span>hadoop01<span style="font-family:'宋体';">是</span><span style="font-family:Calibri;">hiveserver2</span><span style="font-family:'宋体';">所启动的那台主机名，端口默认是</span><span style="font-family:Calibri;">10000</span><span style="font-family:'宋体';">）</span></p><p>v <span style="font-family:'宋体';">方式（</span>2<span style="font-family:'宋体';">）</span></p><p>或者启动就连接：</p><p><strong><span style="color:rgb(0,0,255);">bin/beeline -u jdbc:hive2://mini1:10000 -n hadoop</span></strong></p><p> </p><p><span style="font-family:'宋体';">接下来就可以做正常</span>sql<span style="font-family:'宋体';">查询了</span></p><p> </p><p> </p><h4><a></a><strong>Hive<span style="font-family:'宋体';">命令</span></strong></h4><p>[hadoop@hdp-node-02 ~]$ hive  -e  ‘sql’</p><p> </p><p> </p><h1><a></a>2. <strong><a>H</a>ive<span style="font-family:'宋体';">基本操作</span></strong></h1><h2><span style="color:rgb(0,0,0);">2.1 </span><strong> <a></a><a></a><a>DDL<span style="font-family:'宋体';">操作</span></a></strong></h2><h3><a></a>2.1.1 <strong><a></a><a><span style="font-family:'宋体';">创建表</span></a></strong></h3><h4><a></a><strong>建表语法</strong></h4><p>CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name </p><p>   [(col_name data_type [COMMENT col_comment], ...)]   #<span style="font-family:'宋体';">列名 列数据类型 列的注释</span></p><p>   [COMMENT table_comment]              #<span style="font-family:'宋体';">表的注释，位于表名（列名）之后</span></p><p> [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]  #<span style="font-family:'宋体';">分区（不能和</span><span style="font-family:Calibri;">table</span><span style="font-family:'宋体';">（字段，字段。。。）相同，另写一个字段。）</span></p><p> <span style="color:rgb(255,0,0);">[</span>CLUSTERED BY (col_name, col_name, ...)   #<span style="font-family:'宋体';">分桶（按那些字段分桶）</span></p><p>[SORTED BY (col_name [ASC|DESC], ...)]   #<span style="font-family:'宋体';">分桶（按那些字段排序）</span></p><p>INTO num_buckets BUCKETS<span style="color:rgb(255,0,0);">] </span><span style="color:rgb(255,0,0);">     </span>#<span style="font-family:'宋体';">分成几个桶</span></p><p>   [ROW FORMAT row_format]  #<span style="font-family:'宋体';">列的分隔格式</span></p><p>   [STORED AS file_format]     #<span style="font-family:'宋体';">保存成什么类型</span></p><p>   [LOCATION hdfs_path]    #<span style="font-family:'宋体';">外部表的存储位置</span></p><p> </p><p>说明：</p><p>1、 CREATE TABLE 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS <span style="font-family:'宋体';">选项来忽略这个异常</span>。</p><p>2、 EXTERNAL<span style="font-family:'宋体';">关键字可以让用户创建一个外部表，在建表的同时指定一个指向实际数据的路径（</span>LOCATION），Hive 创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。</p><p>3、 LIKE 允许用户复制现有的表结构，但是不复制数据。</p><p>4、 ROW FORMAT </p><p>DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char] </p><p>        [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char] </p><p>   | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]</p><p><span style="font-family:'宋体';">用户在建表的时候可以自定义</span> SerDe 或者使用自带的 SerDe。如果没有指定 ROW FORMAT 或者 ROW FORMAT DELIMITED，将会使用自带的 SerDe。在建表的时候，用户还需要为表指定列，用户在指定表的列的同时也会指定自定义的 SerDe，Hive通过 SerDe 确定表的具体的列的数据。</p><p>5、 STORED AS </p><p>SEQUENCEFILE|TEXTFILE|RCFILE</p><p><span style="font-family:'宋体';">如果文件数据是纯文本，可以使用</span> STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE。</p><p> </p><p>6、CLUSTERED BY</p><p><span style="font-family:'宋体';">对于每一个表（</span>table）或者分区， Hive可以进一步组织成桶，也就是说桶是更为细粒度的数据范围划分。Hive也是 针对某一列进行桶的组织。Hive采用对列值哈希，然后除以桶的个数求余的方式决定该条记录存放在哪个桶当中。 </p><p><span style="font-family:'宋体';">把表（或者分区）组织成桶（</span>Bucket）有两个理由：</p><p><span style="font-family:'宋体';">（</span>1）获得更高的查询处理效率。桶为表加上了额外的结构，Hive 在处理有些查询时能利用这个结构。具体而言，连接两个在（包含连接列的）相同列上划分了桶的表，可以使用 Map 端连接 （Map-side join）高效的实现。比如JOIN操作。对于JOIN操作两个表有一个相同的列，如果对这两个表都进行了桶操作。那么将保存相同列值的桶进行JOIN操作就可以，可以大大较少JOIN的数据量。</p><p><span style="font-family:'宋体';">（</span>2）使取样（sampling）更高效。在处理大规模数据集时，在开发和修改查询的阶段，如果能在数据集的一小部分数据上试运行查询，会带来很多方便。</p><p> </p><p> </p><h4><a></a><strong>具体实例</strong></h4><p><a></a>1、 <span style="font-family:'宋体';">创建内部表</span>mytable<span style="font-family:'宋体';">。</span></p><p> </p><p> </p><p><a></a>2、 <span style="font-family:'宋体';">创建外部表</span>pageview<span style="font-family:'宋体';">。</span></p><p> </p><p> </p><p><a></a>3、 <span style="font-family:'宋体';">创建分区表</span>invites<span style="font-family:'宋体';">。</span></p><table><tbody><tr><td valign="top"><p>create table student_p(Sno int,Sname string,Sex string,Sage int,Sdept string)</p><p> partitioned by(part string)</p><p> row format delimited fields terminated by ','</p><p>stored as textfile;</p></td></tr></tbody></table><p> </p><p> </p><p> </p><p><a></a>4、 <span style="font-family:'宋体';">创建带桶的表</span>student<span style="font-family:'宋体';">。</span></p><p> </p><table><tbody><tr><td valign="top"><p>create table student(id int,age int,name string)</p><p> partitioned by(stat_date string)</p><p><span style="color:rgb(255,0,0);">Clustered by(id) sorted by (age) into 2 buckets</span></p><p> row format delimited fields terminated by ','stored as textfile;</p></td></tr></tbody></table><p> </p><p> </p><h3><a></a>2.1.2 <strong><a></a><a><span style="font-family:'宋体';">修改表</span></a></strong></h3><h4><a></a><strong><span style="font-family:'宋体';">增加</span>/<span style="font-family:'宋体';">删除分区</span></strong></h4><p>ü 语法结构</p><p>ALTER TABLE table_name ADD [IF NOT EXISTS] partition_spec [ LOCATION 'location1' ] partition_spec [ LOCATION 'location2' ] ...</p><p>partition_spec:</p><p>: PARTITION (partition_col = partition_col_value, partition_col = partiton_col_value, ...)</p><p> </p><p>ALTER TABLE table_name DROP partition_spec, partition_spec,...</p><p>ü 具体实例</p><table><tbody><tr><td valign="top"><p>alter table student_p add partition(part='a') partition(part='b');</p></td></tr></tbody></table><p> </p><p> </p><p> </p><p> </p><h4><a></a><strong>重命名表</strong></h4><p>ü 语法结构</p><p>ALTER TABLE table_name RENAME TO new_table_name</p><p>ü 具体实例</p><p> </p><h4><a></a><strong><span style="font-family:'宋体';">增加</span>/<span style="font-family:'宋体';">更新列</span></strong></h4><p>ü 语法结构</p><p>ALTER TABLE table_name ADD|REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...) </p><p> </p><p><em><span style="font-family:'宋体';">注：</span>ADD<span style="font-family:'宋体';">是代表新增一字段，字段位置在所有列后面</span><span style="font-family:Calibri;">(partition</span><span style="font-family:'宋体';">列前</span><span style="font-family:Calibri;">)</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">REPLACE</span><span style="font-family:'宋体';">则是表示替换表中所有字段。</span></em></p><p> </p><p>ALTER TABLE table_name CHANGE [COLUMN] col_old_name col_new_name column_type [COMMENT col_comment] [FIRST|AFTER column_name]</p><p>ü 具体实例</p><p> </p><h3><a></a>2.1.3 <strong><a></a><a><span style="font-family:'宋体';">显示命令</span></a></strong></h3><p>show tables</p><p>show databases   </p><p>use  database-name   使用某个数据库</p><p>show partitions table-name   查看某个表的分区</p><p>show functions  </p><p>desc extended extended t_name;    查看函数用法<br></p><p>desc extended t_name;</p><p>desc formatted table_name;    会显示：列名  数据类型 （int varchar  string decimal（10,3））   注释（comment）</p><h3><a></a>2.1.4 <span style="font-family:'宋体';">保存</span><span style="font-family:Calibri;">select</span><span style="font-family:'宋体';">查询结果到其他表</span></h3><p>1. 将查询结果保存到一张新建表中</p><table><tbody><tr><td valign="top"><p>Create table table1</p><p>As</p><p>Select * from emp<span style="font-family:'宋体';">；</span></p></td></tr></tbody></table><p> </p><p>2. 将查询结果保存到已经存在的表中  </p><p>intert into///insert overwrite  追加插入和覆盖文件中已有的文件</p><table><tbody><tr><td valign="top"><p>Inset into<span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">overwrite</span><span style="font-family:'宋体';">）</span><span style="font-family:Calibri;">Table table2 partition</span><span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">country=</span><span style="font-family:'宋体';">“</span><span style="font-family:Calibri;">eng</span><span style="font-family:'宋体';">”）</span></p><p>Select * from emp where partition<span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">country=</span><span style="font-family:'宋体';">“</span><span style="font-family:Calibri;">English</span><span style="font-family:'宋体';">”）；</span><strong></strong></p></td></tr></tbody></table><p>3、将查询结果保存到本地</p><p>intert into///insert overwrite  追加插入和覆盖文件中已有的文件<br></p><table><tbody><tr><td valign="top"><p>Insert into<span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">overwrite</span><span style="font-family:'宋体';">）</span><span style="font-family:Calibri;">local directory </span><span style="font-family:'宋体';">‘</span><span style="font-family:Calibri;">/root/hive/daba/</span><span style="font-family:'宋体';">’</span></p><p>Select * from emp where partition<span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">country=</span><span style="font-family:'宋体';">“</span><span style="font-family:Calibri;">English</span><span style="font-family:'宋体';">”）；</span><span style="font-family:Calibri;">(linux </span><span style="font-family:'宋体';">目录下</span><span style="font-family:Calibri;">)</span></p><p> </p><p>Insert into<span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">overwrite</span><span style="font-family:'宋体';">） </span><span style="font-family:Calibri;">directory </span><span style="font-family:'宋体';">‘</span><span style="font-family:Calibri;">/root/hive/daba/</span><span style="font-family:'宋体';">’</span></p><p>Select * from emp where partition<span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">country=</span><span style="font-family:'宋体';">“</span><span style="font-family:Calibri;">English</span><span style="font-family:'宋体';">”）；</span><span style="font-family:Calibri;">(hdfs</span><span style="font-family:'宋体';">中</span><span style="font-family:Calibri;">)</span></p><p> </p></td></tr></tbody></table><p><strong> </strong></p><h2><span style="color:rgb(0,0,0);">2.2 </span><strong> <a></a><a></a><a>DML<span style="font-family:'宋体';">操作</span></a></strong></h2><h3><a></a>2.2.1 <strong><a></a><a>Load</a></strong></h3><p> 语法结构</p><p>LOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO </p><p>TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]</p><p> </p><p>说明：</p><p>1、 Load <span style="font-family:'宋体';">操作只是单纯的复制</span><span style="font-family:Verdana;">/</span><span style="font-family:'宋体';">移动操作，将数据文件移动到 </span><span style="font-family:Verdana;">Hive </span><span style="font-family:'宋体';">表对应的位置。</span></p><p>2、 filepath<span style="font-family:'宋体';">：</span></p><p><span style="font-family:'宋体';">相对路径，例如：</span>project/data1 </p><p><span style="font-family:'宋体';">绝对路径，例如：</span>/user/hive/project/data1 </p><p><span style="font-family:'宋体';">包含模式的完整</span> URI，列如：</p><p>hdfs://namenode:9000/user/hive/project/data1</p><p>3、 LOCAL<span style="font-family:'宋体';">关键字</span></p><p><span style="font-family:'宋体';">如果指定了</span> LOCAL<span style="font-family:'宋体';">， </span><span style="font-family:Verdana;">load </span><span style="font-family:'宋体';">命令会去查找本地文件系统中的 </span><span style="font-family:Verdana;">filepath</span><span style="font-family:'宋体';">。</span></p><p><span style="font-family:'宋体';">如果没有指定</span> LOCAL <span style="font-family:'宋体';">关键字，则根据</span><span style="font-family:Verdana;">inpath</span><span style="font-family:'宋体';">中的</span><span style="font-family:Verdana;">uri</span>查找文件</p><p> </p><p> </p><p>4、 OVERWRITE 关键字</p><p><span style="font-family:'宋体';">如果使用了</span> OVERWRITE  Into（注意不是overwirte啊）<span style="font-family:'宋体';">关键字，则目标表（或者分区）中的内容会被删除，然后再将 </span><span style="font-family:Calibri;">filepath </span><span style="font-family:'宋体';">指向的文件</span><span style="font-family:Calibri;">/</span><span style="font-family:'宋体';">目录中的内容添加到表</span><span style="font-family:Calibri;">/</span><span style="font-family:'宋体';">分区中。 </span></p><p><span style="font-family:'宋体';">如果目标表（分区）已经有一个文件，并且文件名和</span> filepath <span style="font-family:'宋体';">中的文件名冲突，那么现有的文件会被新文件所替代。 </span></p><p> </p><p> 具体实例</p><p><a></a>1、 加载相对路径数据。</p><table><tbody><tr><td valign="top"><p>LOAD DATA LOCAL INPATH './buckets.txt'  <span style="color:#ff0000;">overwrite INTO</span> TABLE tablename </p><p>PARTITION (stat_date=’20131231’);</p><p> </p></td></tr></tbody></table><p> </p><p> </p><p> </p><p><a></a>2、 加载绝对路径数据。</p><p> </p><p> </p><p><a></a>3、 加载包含模式数据。</p><p> </p><p> </p><p><a></a>4、 OVERWRITE关键字使用。</p><p> </p><h3><a></a>2.2.2 <strong><a></a><a>Insert</a></strong></h3><p> <span style="font-family:'宋体';">将查询结果插入</span>Hive<span style="font-family:'宋体';">表</span></p><p>ü 语法结构</p><p>INSERT OVERWRITE TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...)] select_statement1 FROM from_statement</p><p> </p><p>Multiple inserts:</p><p>FROM from_statement </p><p>INSERT OVERWRITE TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...)] select_statement1 </p><p>[INSERT OVERWRITE TABLE tablename2 [PARTITION ...] select_statement2] ...</p><p> </p><p>Dynamic partition inserts:</p><p>INSERT OVERWRITE TABLE tablename PARTITION (partcol1[=val1], partcol2[=val2] ...) select_statement FROM from_statement</p><p> </p><p>ü 具体实例</p><p><a></a>1<span style="font-family:'宋体';">、基本模式插入。</span></p><p> </p><p> </p><p> </p><p> </p><p> </p><p> </p><p> </p><p> </p><p> </p><p> </p><p><a></a>2<span style="font-family:'宋体';">、多插入模式。</span></p><p> </p><p> </p><p><a></a>3<span style="font-family:'宋体';">、自动分区模式。</span></p><p> </p><p>4. 向分桶表中插入数据</p><table><tbody><tr><td valign="top"><p>##<span style="font-family:'宋体';">首先创建分桶表</span><br>create table stu_buck(sno int,sname string,sex string,sage int,sdept string)<br>clustered by(sno) <br>sorted by(sno DESC)<br>into 4 buckets<br>row format delimited<br>fields terminated by ',';<br><br>##<span style="font-family:'宋体';">设置变量</span><span style="font-family:Calibri;">,</span><span style="font-family:'宋体';">设置分桶为</span><span style="font-family:Calibri;">true, </span><span style="font-family:'宋体';">设置</span><span style="font-family:Calibri;">reduce</span><span style="font-family:'宋体';">数量是分桶的数量个数</span><br>set hive.enforce.bucketing = true;<br>set mapreduce.job.reduces=4;<br><br>#<span style="font-family:'宋体';">开会往创建的分通表插入数据</span><span style="font-family:Calibri;">(</span><span style="font-family:'宋体';">插入数据需要是已分桶</span><span style="font-family:Calibri;">, </span><span style="font-family:'宋体';">且排序的</span><span style="font-family:Calibri;">)</span><br>#<span style="font-family:'宋体';">可以使用</span><span style="font-family:Calibri;">distribute by(sno) sort by(sno asc)   </span><span style="font-family:'宋体';">或是排序和分桶的字段相同的时候使用</span><span style="font-family:Calibri;">Cluster by(</span><span style="font-family:'宋体';">字段</span><span style="font-family:Calibri;">)</span><br>#<span style="font-family:'宋体';">注意使用</span><span style="font-family:Calibri;">cluster by  </span><span style="font-family:'宋体';">就等同于</span><span style="font-family:Calibri;">distribute by+ sort by</span><span style="font-family:'宋体';">（）</span><br><span style="color:rgb(255,0,0);">insert into table stu_buck partition<span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">country=</span></span><span style="color:rgb(255,0,0);">”</span><span style="color:rgb(255,0,0);">Chinese</span><span style="color:rgb(255,0,0);">”</span><span style="color:rgb(255,0,0);">）</span><span style="color:rgb(255,0,0);"><br></span><span style="color:rgb(255,0,0);">select sno,sname,sex,sage,sdept from student where country=</span><span style="color:rgb(255,0,0);">”</span><span style="color:rgb(255,0,0);">Chinese</span><span style="color:rgb(255,0,0);">”</span><span style="color:rgb(255,0,0);"> distribute by(sno);  </span></p><p><span style="color:rgb(255,0,0);">#<span style="font-family:'宋体';">按照分桶的数据查询，并将结果插入到</span><span style="font-family:Calibri;">stu_buck</span><span style="font-family:'宋体';">的分区表中。</span></span></p><p> </p></td></tr></tbody></table><p> </p><p> </p><p><span style="color:rgb(0,0,0);"> </span></p><p><span style="color:rgb(0,0,0);">v </span><span style="color:rgb(0,0,0);">导出表数据</span></p><p><span style="color:rgb(0,0,0);">ü </span><span style="color:rgb(0,0,0);">语法结构</span></p><p>INSERT OVERWRITE [LOCAL] DIRECTORY directory1 SELECT ... FROM ...</p><p> </p><p> </p><p>multiple inserts:</p><p>FROM from_statement</p><p>INSERT OVERWRITE [LOCAL] DIRECTORY directory1 select_statement1</p><p>[INSERT OVERWRITE [LOCAL] DIRECTORY directory2 select_statement2] ...</p><p> </p><p>ü 具体实例</p><p><a></a>1<span style="font-family:'宋体';">、导出文件到本地。</span></p><p> </p><p> </p><p>说明：</p><p><em><span style="font-family:'宋体';">数据写入到文件系统时进行文本序列化，且每列用</span>^A来区分，\n为换行符。用more命令查看时不容易看出分割符，可以使用: sed -e 's/\x01/|/g' filename来查看。</em></p><p> </p><p><a></a>2<span style="font-family:'宋体';">、导出数据到</span><span style="font-family:Calibri;">HDFS</span><span style="font-family:'宋体';">。</span></p><p> </p><h3><a></a>2.2.3 <strong><a></a><a>SELECT</a></strong></h3><p> <span style="font-family:'宋体';">基本的</span>Select<span style="font-family:'宋体';">操作</span></p><p>ü 语法结构</p><p>SELECT [ALL | DISTINCT] select_expr, select_expr, ... </p><p>FROM table_reference</p><p>[WHERE where_condition] </p><p>[GROUP BY col_list [HAVING condition]] </p><p>[CLUSTER BY col_list </p><p>  | [DISTRIBUTE BY col_list] [SORT BY| ORDER BY col_list] </p><p>] </p><p>[LIMIT number]</p><p> </p><p><span style="font-family:'宋体';">注：</span>1<span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">order by </span><span style="font-family:'宋体';">会对输入做全局排序，因此只有一个</span><span style="font-family:Calibri;">reducer</span><span style="font-family:'宋体';">，会导致当输入规模较大时，需要较长的计算时间。</span><span style="font-family:Calibri;">2</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">sort by</span><span style="font-family:'宋体';">不是全局排序，</span>而是对划分成的每个分桶进行排序，（或者说就是在MapReduce<span style="font-family:'宋体';">中，</span><span style="font-family:'宋体';">在数据进入</span>reducer<span style="font-family:'宋体';">前完成排序。</span>）<span style="font-family:'宋体';">因此，如果用</span>sort by<span style="font-family:'宋体';">进行排序，并且设置</span><span style="font-family:Calibri;">mapred.reduce.tasks&gt;1</span><span style="font-family:'宋体';">，则</span><span style="font-family:Calibri;">sort by</span><span style="font-family:'宋体';">只保证每个</span><span style="font-family:Calibri;">reducer</span><span style="font-family:'宋体';">的输出有序，不保证全局有序。</span></p><p>3<span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">distribut  e by</span><span style="font-family:'宋体';">根据</span><span style="font-family:Calibri;">distribute by</span><span style="font-family:'宋体';">指定的内容将数据分到同一个</span><span style="font-family:Calibri;">reducer</span><span style="font-family:'宋体';">。</span></p><p>4、Cluster by <span style="font-family:'宋体';">除了具有</span><span style="font-family:Calibri;">Distribute by</span><span style="font-family:'宋体';">的功能外，还会对该字段进行排序。因此，常常认为</span><span style="font-family:Calibri;">cluster by = distribute by + sort by</span></p><p> </p><p> </p><p>ü 具体实例</p><p><a></a>1<span style="font-family:'宋体';">、获取年龄大的</span><span style="font-family:Calibri;">3</span><span style="font-family:'宋体';">个学生。</span></p><p> </p><p> </p><p><a></a>2<span style="font-family:'宋体';">、查询学生信息按年龄，降序排序。</span></p><p> </p><p> </p><p> </p><p> </p><p> </p><p><a></a>3<span style="font-family:'宋体';">、按学生名称汇总学生年龄。</span></p><p> </p><p> </p><h2><a></a><strong><a>2.3 Hive Join</a></strong></h2><p> 语法结构</p><p>join_table:</p><p>  table_reference JOIN table_factor [join_condition]</p><p>  | table_reference {LEFT|RIGHT|FULL} [OUTER] JOIN table_reference join_condition</p><p>  | table_reference LEFT SEMI JOIN table_reference join_condition</p><p>Hive 支持等值连接（equality joins）、外连接（outer joins）和（left/right joins）。Hive <strong>不支持非等值的连接</strong><span style="font-family:'宋体';">，因为非等值连接非常难转化到</span> map/reduce 任务。</p><p><span style="font-family:'宋体';">另外，</span>Hive 支持多于 2 个表的连接。</p><p><span style="font-family:'宋体';">写</span> join 查询时，需要注意几个关键点：</p><p><a></a><strong>1. <span style="font-family:'宋体';">只支持等值</span>join</strong></p><p><span style="font-family:'宋体';">例如：</span> </p><p>  SELECT a.* FROM a JOIN b ON (a.id = b.id)</p><p>  SELECT a.* FROM a JOIN b</p><p>    ON (a.id = b.id AND a.department = b.department)</p><p><span style="font-family:'宋体';">是正确的，然而</span>:</p><p>  SELECT a.* FROM a JOIN b ON (a.id&gt;b.id)</p><p>是错误的。</p><p> </p><p><a></a><strong>2. <span style="font-family:'宋体';">可以</span> join 多于 2 个表。</strong></p><p>例如</p><p>  SELECT a.val, b.val, c.val FROM a JOIN b</p><p>    ON (a.key = b.key1) JOIN c ON (c.key = b.key2)</p><p><span style="font-family:'宋体';">如果</span>join中多个表的 join key 是同一个，则 join 会被转化为单个 map/reduce 任务，例如：</p><p>  SELECT a.val, b.val, c.val FROM a JOIN b</p><p>    ON (a.key = b.key1) JOIN c</p><p>    ON (c.key = b.key1)</p><p><span style="font-family:'宋体';">被转化为单个</span> map/reduce 任务，因为 join 中只使用了 b.key1 作为 join key。</p><p>SELECT a.val, b.val, c.val FROM a JOIN b ON (a.key = b.key1)</p><p>  JOIN c ON (c.key = b.key2)</p><p><span style="font-family:'宋体';">而这一</span> join 被转化为 2 个 map/reduce 任务。因为 b.key1 用于第一次 join 条件，而 b.key2 用于第二次 join。</p><p>   </p><p><a></a><strong>3<span style="font-family:'宋体';">．</span>join 时，每次 map/reduce 任务的逻辑：</strong></p><p>    reducer 会缓存 join 序列中除了最后一个表的所有表的记录，再通过最后一个表将结果序列化到文件系统。这一实现有助于在 reduce 端减少内存的使用量。实践中，应该把最大的那个表写在最后（否则会因为缓存浪费大量内存）。例如：</p><p> SELECT a.val, b.val, c.val FROM a</p><p>    JOIN b ON (a.key = b.key1) JOIN c ON (c.key = b.key1)</p><p><span style="font-family:'宋体';">所有表都使用同一个</span> join key（使用 1 次 map/reduce 任务计算）。Reduce 端会缓存 a 表和 b 表的记录，然后每次取得一个 c 表的记录就计算一次 join 结果，类似的还有：</p><p>  SELECT a.val, b.val, c.val FROM a</p><p>    JOIN b ON (a.key = b.key1) JOIN c ON (c.key = b.key2)</p><p><span style="font-family:'宋体';">这里用了</span> 2 次 map/reduce 任务。第一次缓存 a 表，用 b 表序列化；第二次缓存第一次 map/reduce 任务的结果，然后用 c 表序列化。</p><p> </p><p><a></a><strong>4．LEFT，RIGHT 和 FULL OUTER 关键字用于处理 join 中空记录的情况</strong></p><p>例如：</p><p>  SELECT a.val, b.val FROM </p><p><a></a>a LEFT OUTER  JOIN b ON (a.key=b.key)</p><p><span style="font-family:'宋体';">对应所有</span> a 表中的记录都有一条记录输出。输出的结果应该是 a.val, b.val，当 a.key=b.key 时，而当 b.key 中找不到等值的 a.key 记录时也会输出:</p><p><a></a>a.val, NULL</p><p><span style="font-family:'宋体';">所以</span> a 表中的所有记录都被保留了；</p><p>“a RIGHT OUTER JOIN b”会保留所有 b 表的记录。</p><p><strong> </strong></p><p><strong>Join 发生在 WHERE 子句之前</strong><span style="font-family:'宋体';">。如果你想限制</span> join 的输出，应该在 WHERE 子句中写过滤条件——或是在 join 子句中写。这里面一个容易混淆的问题是表分区的情况：</p><p>  SELECT a.val, b.val FROM a</p><p>  LEFT OUTER JOIN b ON (a.key=b.key)</p><p>  WHERE a.ds='2009-07-07' AND b.ds='2009-07-07'</p><p><span style="font-family:'宋体';">会</span> join a 表到 b 表（OUTER JOIN），列出 a.val 和 b.val 的记录。WHERE 从句中可以使用其他列作为过滤条件。但是，如前所述，如果 b 表中找不到对应 a 表的记录，b 表的所有列都会列出 NULL，<strong><span style="font-family:'宋体';">包括</span> ds 列</strong><span style="font-family:'宋体';">。也就是说，</span>join 会过滤 b 表中不能找到匹配 a 表 join key 的所有记录。这样的话，LEFT OUTER 就使得查询结果与 WHERE 子句无关了。解决的办法是在 OUTER JOIN 时使用以下语法：</p><p>  SELECT a.val, b.val FROM a LEFT OUTER JOIN b</p><p>  ON (a.key=b.key AND</p><p>      <a>b.ds='2009-07-07' AND</a></p><p>      <a>a.ds='2009-07-07')</a></p><p><span style="font-family:'宋体';">这一查询的结果是预先在</span> join 阶段过滤过的，所以不会存在上述问题。这一逻辑也可以应用于 RIGHT 和 FULL 类型的 join 中。</p><p> </p><p><strong>Join 是不能交换位置的。</strong><span style="font-family:'宋体';">无论是</span> LEFT 还是 RIGHT join，都是左连接的。</p><p>  SELECT a.val1, a.val2, b.val, c.val</p><p>  FROM a</p><p>  JOIN b ON (a.key = b.key)</p><p>  LEFT OUTER JOIN c ON (a.key = c.key)</p><p><span style="font-family:'宋体';">先</span> join a 表到 b 表，丢弃掉所有 join key 中不匹配的记录，然后用这一中间结果和 c 表做 join。这一表述有一个不太明显的问题，就是当一个 key 在 a 表和 c 表都存在，但是 b 表中不存在的时候：整个记录在第一次 join，即 a JOIN b 的时候都被丢掉了（包括a.val1，a.val2和a.key），然后我们再和 c 表 join 的时候，如果 c.key 与 a.key 或 b.key 相等，就会得到这样的结果：NULL, NULL, NULL, c.val</p><p> </p><p> 具体实例</p><p>1、 获取已经分配班级的学生姓名。</p><p> </p><p> </p><p>2、 获取尚未分配班级的学生姓名。</p><p> </p><p> </p><p>3、 LEFT  SEMI  JOIN<span style="font-family:'宋体';">是</span>IN/EXISTS<span style="font-family:'宋体';">的高效实现。</span></p><p> </p><p> </p><p> </p><h1><a></a><strong><a>3 </a><a>Hive Shell</a>参数</strong></h1><h3><a></a><strong><a></a><a>3.1 Hive<span style="font-family:'宋体';">命令行</span></a></strong></h3><p> 语法结构</p><p>hive [-hiveconf x=y]* [&lt;-i filename&gt;]* [&lt;-f filename&gt;|&lt;-e query-string&gt;] [-S]</p><p>说明：</p><p>1、 -i <span style="font-family:'宋体';">从文件初始化</span><span style="font-family:Verdana;">HQL</span>。</p><p>2、 -e<span style="font-family:'宋体';">从命令行执行指定的</span><span style="font-family:Verdana;">HQL，在liunux中执行hql命令</span></p><p>3、 -f <span style="font-family:'宋体';">执行</span><span style="font-family:Verdana;">HQL</span><span style="font-family:'宋体';">脚本，<span style="font-family:Verdana;">在liunux中执行hql命令</span></span></p><p>4、 -v <span style="font-family:'宋体';">输出执行的</span><span style="font-family:Verdana;">HQL</span><span style="font-family:'宋体';">语句到控制台 </span></p><p>5、 -p &lt;port&gt; connect to Hive Server on port number </p><p>6、 -hiveconf x=y Use this to set hive/hadoop configuration variables.</p><p> 具体实例</p><p>1<span style="font-family:'宋体';">、运行一个查询。</span></p><p> hive -e ‘select * from emp’</p><p> </p><p>2<span style="font-family:'宋体';">、运行一个文件。</span></p><p> hive -f ‘test.sql’</p><p> </p><p>3<span style="font-family:'宋体';">、运行参数文件。</span></p><p> </p><p><br clear="all"></p><h3><a></a><strong><a>3.2 Hive<span style="font-family:'宋体';">参数配置方式</span></a></strong></h3><p><em><span style="background:rgb(217,217,217);">Hive<span style="font-family:'宋体';">参数大全：</span></span></em></p><p><em><span style="background:rgb(217,217,217);">https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties</span></em></p><p> </p><p><span style="font-family:'宋体';">开发</span>Hive<span style="font-family:'宋体';">应用时，不可避免地需要设定</span>Hive<span style="font-family:'宋体';">的参数。设定</span>Hive<span style="font-family:'宋体';">的参数可以调优</span>HQL<span style="font-family:'宋体';">代码的执行效率，或帮助定位问题。然而实践中经常遇到的一个问题是，为什么设定的参数没有起作用？这通常是错误的设定方式导致的。</span></p><p> </p><p><strong><span style="color:rgb(0,0,0);"><span style="font-family:'宋体';">对于一般参数，有以下三种设定方式：</span></span></strong></p><p><span style="color:rgb(0,0,0);">l </span><span style="color:rgb(0,0,0);"><span style="font-family:'宋体';">配置文件</span></span><span style="color:rgb(0,0,0);"> </span></p><p><span style="color:rgb(0,0,0);">l </span><span style="color:rgb(0,0,0);"><span style="font-family:'宋体';">命令行参数</span></span><span style="color:rgb(0,0,0);"> </span></p><p><span style="color:rgb(0,0,0);">l </span><span style="color:rgb(0,0,0);"><span style="font-family:'宋体';">参数声明</span></span><span style="color:rgb(0,0,0);"> </span></p><p><strong> </strong></p><p><strong><span style="font-family:'宋体';">配置文件</span></strong><span style="font-family:'宋体';">：</span>Hive<span style="font-family:'宋体';">的配置文件包括</span></p><p>l <span style="font-family:'宋体';">用户自定义配置文件：</span>$HIVE_CONF_DIR/hive-site.xml </p><p>l <span style="font-family:'宋体';">默认配置文件：</span>$HIVE_CONF_DIR/hive-default.xml </p><p><span style="color:rgb(192,0,0);"><span style="font-family:'宋体';">用户自定义配置会覆盖默认配置。</span></span></p><p><span style="font-family:'宋体';">另外，</span>Hive<span style="font-family:'宋体';">也会读入</span>Hadoop<span style="font-family:'宋体';">的配置，因为</span>Hive<span style="font-family:'宋体';">是作为</span>Hadoop<span style="font-family:'宋体';">的客户端启动的，</span>Hive<span style="font-family:'宋体';">的配置会覆盖</span>Hadoop<span style="font-family:'宋体';">的配置。</span></p><p><span style="font-family:'宋体';">配置文件的设定对本机启动的所有</span>Hive<span style="font-family:'宋体';">进程都有效。</span></p><p> </p><p><strong><span style="font-family:'宋体';">命令行参数</span></strong><span style="font-family:'宋体';">：启动</span>Hive<span style="font-family:'宋体';">（客户端或</span>Server<span style="font-family:'宋体';">方式）时，可以在命令行添加</span>-hiveconf param=value<span style="font-family:'宋体';">来设定参数，例如：</span></p><p>bin/hive -hiveconf hive.root.logger=INFO,console</p><p><span style="font-family:'宋体';">这一设定对本次启动的</span>Session<span style="font-family:'宋体';">（对于</span>Server<span style="font-family:'宋体';">方式启动，则是所有请求的</span>Sessions<span style="font-family:'宋体';">）有效。</span></p><p> </p><p><strong><span style="font-family:'宋体';">参数声明</span></strong><span style="font-family:'宋体';">：可以在</span>HQL<span style="font-family:'宋体';">中使用</span>SET<span style="font-family:'宋体';">关键字设定参数，例如：</span></p><p>set mapred.reduce.tasks=100;</p><p><span style="font-family:'宋体';">这一设定的作用域也是</span>session<span style="font-family:'宋体';">级的。</span></p><p> </p><p><span style="font-family:'宋体';">上述三种设定方式的优先级依次递增。即参数声明覆盖命令行参数，命令行参数覆盖配置文件设定。注意某些系统级的参数，例如</span>log4j<span style="font-family:'宋体';">相关的设定，必须用前两种方式设定，因为那些参数的读取在</span>Session<span style="font-family:'宋体';">建立以前已经完成了。</span></p><p> </p><p> </p><p> </p><h1><a></a><strong>4. Hive<span style="font-family:'宋体';">函数</span></strong></h1><h2><a></a><strong>4.1 内置运算符</strong></h2><p><em><span style="background:rgb(127,127,127);"><span style="font-family:'宋体';">内容较多，见《</span>Hive</span><span style="background:rgb(127,127,127);"><span style="font-family:'宋体';">官方文档</span></span><span style="background:rgb(127,127,127);"><span style="font-family:'宋体';">》</span></span></em></p><p><em><span style="background:rgb(127,127,127);"> </span></em></p><h2><a></a><strong>4.2 <span style="font-family:'宋体';">内置函数</span></strong></h2><p><em><span style="background:rgb(127,127,127);"><span style="font-family:'宋体';">内容较多，见《</span>Hive</span><span style="background:rgb(127,127,127);"><span style="font-family:'宋体';">官方文档</span></span><span style="background:rgb(127,127,127);"><span style="font-family:'宋体';">》</span></span></em></p><p> </p><p> </p><p> </p><h2><a></a><strong><a>4.3 Hive<span style="font-family:'宋体';">自定义函数和</span></a></strong><span style="color:rgb(51,51,51);">Transform</span></h2><p><span style="font-family:'宋体';">当</span>Hive<span style="font-family:'宋体';">提供的内置函数无法满足你的业务处理需要时，此时就可以考虑使用用户自定义函数（</span><span style="font-family:Calibri;">UDF</span><span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">user-defined function</span><span style="font-family:'宋体';">）。</span></p><h3><a></a><strong><a>4.3.1 <span style="font-family:'宋体';">自定义函数类别</span></a></strong></h3><p>UDF  <span style="font-family:'宋体';">作用于单个数据行，产生一个数据行作为输出。（数学函数，字符串函数）</span></p><p>UDAF<span style="font-family:'宋体';">（用户定义聚集函数）：接收多个输入数据行，并产生一个输出数据行。（</span><span style="font-family:Calibri;">count</span><span style="font-family:'宋体';">，</span><span style="font-family:Calibri;">max</span><span style="font-family:'宋体';">）</span></p><p><a></a> </p><h3><a></a><strong><span style="background:rgb(255,255,255);">4.3.2 UDF<span style="font-family:'宋体';">开发实例</span></span></strong></h3><p>1<span style="font-family:'宋体';">、先开发一个</span><span style="font-family:Calibri;">java</span><span style="font-family:'宋体';">类，继承</span><span style="font-family:Calibri;">UDF</span><span style="font-family:'宋体';">，并重载</span><span style="font-family:Calibri;">evaluate</span><span style="font-family:'宋体';">方法</span></p><table><tbody><tr><td valign="top"><p>package cn.itcast.bigdata.udf</p><p>import org.apache.hadoop.hive.ql.exec.UDF;</p><p>import org.apache.hadoop.io.Text;</p><p> </p><p>public final class Lower extends UDF{</p><p>	public Text evaluate(final Text s){</p><p>		if(s==null){return null;}</p><p>		return new Text(s.toString().toLowerCase());</p><p>	}</p><p>}</p></td></tr></tbody></table><p> </p><p>2<span style="font-family:'宋体';">、打成</span><span style="font-family:Calibri;">jar</span><span style="font-family:'宋体';">包上传到服务器</span></p><p>3<span style="font-family:'宋体';">、将</span><span style="font-family:Calibri;">jar</span><span style="font-family:'宋体';">包添加到</span><span style="font-family:Calibri;">hive</span><span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">classpath</span></p><p>hive&gt;add JAR /home/hadoop/udf.jar;</p><p>4、<span style="font-family:'宋体';">创建临时函数与开发好的</span>java class<span style="font-family:'宋体';">关联</span></p><table><tbody><tr><td valign="top"><p>Hive&gt;create temporary function toprovince as 'cn.itcast.bigdata.udf.ToProvince';</p></td></tr></tbody></table><p> </p><p>5、<span style="font-family:'宋体';">即可在</span>hql<span style="font-family:'宋体';">中使用自定义的函数</span>strip </p><p>Select strip(name),age from t_test;</p><h3><a></a><strong><a>4.3.3 </a>Transform实现</strong></h3><p>Hive<span style="font-family:'宋体';">的 </span><span style="font-family:Calibri;">TRANSFORM </span><span style="font-family:'宋体';">关键字</span><strong><em><span style="background:rgb(127,127,127);"><span style="font-family:'宋体';">提供了在</span>SQL<span style="font-family:'宋体';">中调用自写脚本的功能</span></span></em></strong></p><p><span style="font-family:'宋体';">适合实现</span>Hive<span style="font-family:'宋体';">中没有的功能又不想写</span><span style="font-family:Calibri;">UDF</span><span style="font-family:'宋体';">的情况</span></p><p> </p><p><span style="font-family:'宋体';">使用示例</span>1<span style="font-family:'宋体';">：</span><span style="font-family:'宋体';">下面这句</span>sql<span style="font-family:'宋体';">就是借用了</span><span style="color:rgb(0,0,0);">weekday_mapper.py<span style="font-family:'宋体';">对数据进行了处理</span></span><span style="color:rgb(0,0,0);">.</span></p><table><tbody><tr><td valign="top"><p>CREATE TABLE u_data_new (</p><p>  movieid INT,</p><p>  rating INT,</p><p>  weekday INT,</p><p>  userid INT)</p><p>ROW FORMAT DELIMITED</p><p>FIELDS TERMINATED BY '\t';</p><p> </p><p>add FILE weekday_mapper.py;</p><p> </p><p>INSERT OVERWRITE TABLE u_data_new</p><p>SELECT</p><p>  TRANSFORM (movieid, rating, unixtime,userid)</p><p>  USING 'python weekday_mapper.py'</p><p>  AS (movieid, rating, weekday,userid)</p><p>FROM u_data;</p></td></tr></tbody></table><p><span style="color:rgb(0,0,0);"> </span></p><p><span style="color:rgb(0,0,0);"><span style="font-family:'宋体';">其中</span>weekday_mapper.py内容如下</span></p><table><tbody><tr><td valign="top"><p>#!/bin/python</p><p>import sys</p><p>import datetime</p><p> </p><p>for line in sys.stdin:</p><p>  line = line.strip()</p><p>  movieid, rating, unixtime,userid = line.split('\t')</p><p>  weekday = datetime.datetime.fromtimestamp(float(unixtime)).isoweekday()</p><p>  print '\t'.join([movieid, rating, str(weekday),userid])</p></td></tr></tbody></table><p> </p><p><span style="font-family:'宋体';">使用示例</span>2：<span style="font-family:'宋体';">下面的例子则是使用了</span>shell的cat命令来处理数据</p><table><tbody><tr><td valign="top"><p>FROM invites a INSERT OVERWRITE TABLE events SELECT TRANSFORM(a.foo, a.bar) AS (oof, rab) USING '/bin/cat' WHERE a.ds &gt; '2008-08-09';</p></td></tr></tbody></table><h1><a></a><strong><a></a><a>5. Hive<span style="font-family:'宋体';">实战</span></a></strong></h1><h2><a></a><strong><a>Hive <span style="font-family:'宋体';">实战案例</span><span style="font-family:Cambria;">1</span><span style="font-family:'宋体';">——数据</span><span style="font-family:Cambria;">ETL</span></a></strong></h2><h3><a></a><strong><a>需求：</a></strong></h3><p>ü <span style="font-family:'宋体';">对</span>web<span style="font-family:'宋体';">点击流日志基础数据表进行</span><span style="font-family:Calibri;">etl</span><span style="font-family:'宋体';">（按照仓库模型设计）</span></p><p>ü 按<span style="font-family:'宋体';">各时间维度统计来源域名</span>top10</p><p><span style="font-family:'宋体';">已有数据表</span> “t_orgin_weblog” <span style="font-family:'宋体';">：</span></p><table><tbody><tr><td valign="top"><p>+------------------+------------+----------+--+</p><p>|     col_name     | data_type  | comment  |</p><p>+------------------+------------+----------+--+</p><p>| valid            | string     |          |</p><p>| remote_addr      | string     |          |</p><p>| remote_user      | string     |          |</p><p>| time_local       | string     |          |</p><p>| request          | string     |          |</p><p>| status           | string     |          |</p><p>| body_bytes_sent  | string     |          |</p><p>| http_referer     | string     |          |</p><p>| http_user_agent  | string     |          |</p><p>+------------------+------------+----------+--+</p></td></tr></tbody></table><p> </p><p> </p><p> </p><p> </p><h3><a></a><strong><a>数据示例：</a></strong></h3><table><tbody><tr><td valign="top"><p>| true|1.162.203.134| - | 18/Sep/2013:13:47:35| /images/my.jpg                        | 200| 19939 | "http://www.angularjs.cn/A0d9"                      | "Mozilla/5.0 (Windows   |</p><p> </p><p>| true|1.202.186.37 | - | 18/Sep/2013:15:39:11| /wp-content/uploads/2013/08/windjs.png| 200| 34613 | "http://cnodejs.org/topic/521a30d4bee8d3cb1272ac0f" | "Mozilla/5.0 (Macintosh;|</p></td></tr></tbody></table><p> </p><p> </p><p> </p><p> </p><h3><a></a><strong><a>实现步骤：</a></strong></h3><p><a></a>1<span style="font-family:'宋体';">、对原始数据进行抽取转换</span></p><p>--<span style="font-family:'宋体';">将来访</span><span style="font-family:Calibri;">url</span><span style="font-family:'宋体';">分离出</span><span style="font-family:Calibri;">host  path  query  query id</span></p><table><tbody><tr><td valign="top"><p>drop table if exists t_etl_referurl;</p><p>create table t_etl_referurl as</p><p>SELECT a.*,b.*</p><p>FROM t_orgin_weblog a LATERAL VIEW parse_url_tuple(regexp_replace(http_referer, "\"", ""), 'HOST', 'PATH','QUERY', 'QUERY:id') b as host, path, query, query_id </p><p> </p></td></tr></tbody></table><p> </p><p>3<span style="font-family:'宋体';">、从前述步骤进一步分离出日期时间形成</span><span style="font-family:Calibri;">ETL</span><span style="font-family:'宋体';">明细表“</span><span style="font-family:Calibri;">t_etl_detail</span><span style="font-family:'宋体';">”    </span><span style="font-family:Calibri;">day tm   </span></p><table><tbody><tr><td valign="top"><p>drop table if exists t_etl_detail;</p><p>create table t_etl_detail as </p><p>select b.*,substring(time_local,0,11) as daystr,</p><p>substring(time_local,13) as tmstr,</p><p>substring(time_local,4,3) as month,</p><p>substring(time_local,0,2) as day,</p><p>substring(time_local,13,2) as hour</p><p>from t_etl_referurl b;</p><p> </p></td></tr></tbody></table><p> </p><p> </p><p><a></a>3<span style="font-family:'宋体';">、对</span><span style="font-family:Calibri;">etl</span><span style="font-family:'宋体';">数据进行分区</span><span style="font-family:Calibri;">(</span><span style="font-family:'宋体';">包含所有数据的结构化信息</span><span style="font-family:Calibri;">)</span></p><table><tbody><tr><td valign="top"><p>drop table t_etl_detail_prt;</p><p>create table t_etl_detail_prt(</p><p>valid                   string,</p><p>remote_addr            string,</p><p>remote_user            string,</p><p>time_local               string,</p><p>request                 string,</p><p>status                  string,</p><p>body_bytes_sent         string,</p><p>http_referer             string,</p><p>http_user_agent         string,</p><p>host                   string,</p><p>path                   string,</p><p>query                  string,</p><p>query_id               string,</p><p>daystr                 string,</p><p>tmstr                  string,</p><p>month                  string,</p><p>day                    string,</p><p>hour                   string) </p><p>partitioned by (mm string,dd string);</p></td></tr></tbody></table><p> </p><p> </p><p> </p><p> </p><p>导入数据</p><table><tbody><tr><td valign="top"><p>insert into table t_etl_detail_prt partition(mm='Sep',dd='18')</p><p>select * from t_etl_detail where daystr='18/Sep/2013';</p><p> </p><p>insert into table t_etl_detail_prt partition(mm='Sep',dd='19')</p><p>select * from t_etl_detail where daystr='19/Sep/2013';</p></td></tr></tbody></table><p> </p><p><span style="font-family:'宋体';">分个时间维度统计各</span>referer_host<span style="font-family:'宋体';">的访问次数并排序</span></p><table><tbody><tr><td valign="top"><p>create table t_refer_host_visit_top_tmp as</p><p>select referer_host,count(*) as counts,mm,dd,hh from t_display_referer_counts group by hh,dd,mm,referer_host order by hh asc,dd asc,mm asc,counts desc;</p><p> </p></td></tr></tbody></table><p> </p><p><a></a>4<span style="font-family:'宋体';">、来源访问次数</span><span style="font-family:Calibri;">topn</span><span style="font-family:'宋体';">各时间维度</span><span style="font-family:Calibri;">URL</span></p><p><span style="font-family:'宋体';">取各时间维度的</span>referer_host<span style="font-family:'宋体';">访问次数</span><span style="font-family:Calibri;">topn</span></p><table><tbody><tr><td valign="top"><p>select * from (select referer_host,counts,concat(hh,dd),row_number() over (partition by concat(hh,dd) order by concat(hh,dd) asc) as od from t_refer_host_visit_top_tmp) t where od&lt;=3;</p><p> </p></td></tr></tbody></table><p> </p><p> </p><p> </p><p> </p><p><br clear="all"></p><h2><a></a><strong><a>Hive <span style="font-family:'宋体';">实战案例</span><span style="font-family:Cambria;">2</span><span style="font-family:'宋体';">——访问时长统计</span></a></strong></h2><h3><a></a><strong><a>需求：</a></strong></h3><p><span style="font-family:'宋体';">从</span>web<span style="font-family:'宋体';">日志中统计每日访客平均停留时间</span></p><h3><a></a><strong><a>实现步骤：</a></strong></h3><p>1、 <span style="font-family:'宋体';">由于要从大量请求中分辨出用户的各次访问，逻辑相对复杂，通过</span>hive<span style="font-family:'宋体';">直接实现有困难，因此编写一个</span><span style="font-family:Calibri;">mr</span><span style="font-family:'宋体';">程序来求出访客访问信息（详见代码）</span></p><p><span style="font-family:'宋体';">启动</span>mr<span style="font-family:'宋体';">程序获取结果：</span></p><table><tbody><tr><td valign="top"><p>[hadoop@hdp-node-01 ~]$ hadoop jar weblog.jar cn.itcast.bigdata.hive.mr.UserStayTime /weblog/input /weblog/stayout</p></td></tr></tbody></table><p> </p><p> </p><p>2、 <span style="font-family:'宋体';">将</span>mr<span style="font-family:'宋体';">的处理结果导入</span><span style="font-family:Calibri;">hive</span><span style="font-family:'宋体';">表</span></p><table><tbody><tr><td valign="top"><p>drop table t_display_access_info_tmp;</p><p>create table t_display_access_info_tmp(remote_addr string,firt_req_time string,last_req_time string,stay_long bigint)</p><p>row format delimited fields terminated by '\t';</p><p> </p><p>load data inpath '/weblog/stayout4' into table t_display_access_info_tmp;</p></td></tr></tbody></table><p> </p><p>3<span style="font-family:'宋体';">、得出访客访问信息表 </span><span style="font-family:Calibri;">"t_display_access_info"</span></p><p><span style="font-family:'宋体';">由于有一些访问记录是单条记录，</span>mr<span style="font-family:'宋体';">程序处理处的结果给的时长是</span><span style="font-family:Calibri;">0</span><span style="font-family:'宋体';">，所以考虑给单次请求的停留时间一个默认市场</span><span style="font-family:Calibri;">30</span><span style="font-family:'宋体';">秒</span></p><table><tbody><tr><td valign="top"><p>drop table t_display_access_info;</p><p>create table t_display_access_info as</p><p>select remote_addr,firt_req_time,last_req_time,</p><p>case stay_long</p><p>when 0 then 30000</p><p>else stay_long</p><p>end as stay_long</p><p>from t_display_access_info_tmp;</p></td></tr></tbody></table><p> </p><p> </p><p>4<span style="font-family:'宋体';">、统计所有用户停留时间平均值</span></p><p>select avg(stay_long) from t_display_access_info;</p><p> </p><p> </p><p> </p><p><br clear="all"></p><h2><a></a><strong><a>Hive<span style="font-family:'宋体';">实战案例</span><span style="font-family:Cambria;">3</span><span style="font-family:'宋体';">——级联求和</span></a></strong></h2><h3><a></a><strong><a>需求：</a></strong></h3><p><span style="font-family:'宋体';">有如下访客访问次数统计表</span> t_access_times</p><table><tbody><tr><td valign="top"><p>访客</p></td><td valign="top"><p>月份</p></td><td valign="top"><p>访问次数</p></td></tr><tr><td valign="top"><p>A</p></td><td valign="top"><p>2015-01-02</p></td><td valign="top"><p>5</p></td></tr><tr><td valign="top"><p>A</p></td><td valign="top"><p>2015-01-03</p></td><td valign="top"><p>15</p></td></tr><tr><td valign="top"><p>B</p></td><td valign="top"><p>2015-01-01</p></td><td valign="top"><p>5</p></td></tr><tr><td valign="top"><p>A</p></td><td valign="top"><p>2015-01-04</p></td><td valign="top"><p>8</p></td></tr><tr><td valign="top"><p>B</p></td><td valign="top"><p>2015-01-05</p></td><td valign="top"><p>25</p></td></tr><tr><td valign="top"><p>A</p></td><td valign="top"><p>2015-01-06</p></td><td valign="top"><p>5</p></td></tr><tr><td valign="top"><p>A</p></td><td valign="top"><p>2015-02-02</p></td><td valign="top"><p>4</p></td></tr><tr><td valign="top"><p>A</p></td><td valign="top"><p>2015-02-06</p></td><td valign="top"><p>6</p></td></tr><tr><td valign="top"><p>B</p></td><td valign="top"><p>2015-02-06</p></td><td valign="top"><p>10</p></td></tr><tr><td valign="top"><p>B</p></td><td valign="top"><p>2015-02-07</p></td><td valign="top"><p>5</p></td></tr><tr><td valign="top"><p>……</p></td><td valign="top"><p>……</p></td><td valign="top"><p>……</p></td></tr></tbody></table><p> </p><p><span style="font-family:'宋体';">需要输出报表：</span>t_access_times_accumulate</p><table><tbody><tr><td valign="top"><p>访客</p></td><td valign="top"><p>月份</p></td><td valign="top"><p>月访问总计</p></td><td valign="top"><p>累计访问总计</p></td></tr><tr><td valign="top"><p>A</p></td><td valign="top"><p>2015-01</p></td><td valign="top"><p>33</p></td><td valign="top"><p>33</p></td></tr><tr><td valign="top"><p>A</p></td><td valign="top"><p>2015-02</p></td><td valign="top"><p>10</p></td><td valign="top"><p>43</p></td></tr><tr><td valign="top"><p>…….</p></td><td valign="top"><p>…….</p></td><td valign="top"><p>…….</p></td><td valign="top"><p>…….</p></td></tr><tr><td valign="top"><p>B</p></td><td valign="top"><p>2015-01</p></td><td valign="top"><p>30</p></td><td valign="top"><p>30</p></td></tr><tr><td valign="top"><p>B</p></td><td valign="top"><p>2015-02</p></td><td valign="top"><p>15</p></td><td valign="top"><p>45</p></td></tr><tr><td valign="top"><p>…….</p></td><td valign="top"><p>…….</p></td><td valign="top"><p>…….</p></td><td valign="top"><p>…….</p></td></tr></tbody></table><p> </p><h3><a></a><strong><a>实现步骤</a></strong></h3><p><span style="font-family:'宋体';">可以用一个</span>hql<span style="font-family:'宋体';">语句即可实现：</span></p><table><tbody><tr><td valign="top"><p>select A.username,A.month,max(A.salary) as salary,sum(B.salary) as accumulate</p><p>from </p><p>(select username,month,sum(salary) as salary from t_access_times group by username,month) A </p><p>inner join </p><p>(select username,month,sum(salary) as salary from t_access_times group by username,month) B</p><p>on</p><p>A.username=B.username</p><p>where B.month &lt;= A.month</p><p>group by A.username,A.month</p><p>order by A.username,A.month;</p></td></tr></tbody></table><p><span style="color:rgb(0,51,0);"> </span></p>            </div>
                </div>