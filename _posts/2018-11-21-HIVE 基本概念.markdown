---
layout:     post
title:      HIVE 基本概念
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/zz657114506/article/details/53566595				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p><strong>Hive架构</strong> <br>
</p><center> <br>
<img src="https://img-blog.csdn.net/20161211005447064?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveno2NTcxMTQ1MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""><br> <br>
<strong>hive架构图</strong> <br>
<center></center></center><p></p>

<ul>
<li><p>hive组件</p>

<ul><li><p>用户接口 <br>
CLI、JDBC/ODBC和WebGUI。其中，CLI为shell命令行；JDBC/ODBC是Hive的JAVA实现，与传统数据库JDBC类似；WebGUI是通过浏览器访问Hive。</p></li>
<li><p>元数据存储  <br>
Hive 将元数据存储在数据库中。Hive 中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。</p></li>
<li><p>解释器、编译器、优化器、执行器 <br>
解释器、编译器、优化器完成 HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在 HDFS 中，并在随后有 MapReduce 调用执行。</p>

<p>Hive的数据存储在HDFS中，大部分的查询、计算由MapReduce完成（包含<em>的查询，比如select </em> from tbl不会生成MapRedcue任务）。</p></li></ul></li>
<li><p>Hive与Hadoop的关系 <br>
Hive利用HDFS存储数据，利用MapReduce查询数据 <br>
</p><center> <br>
<img src="https://img-blog.csdn.net/20161211012615921?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveno2NTcxMTQ1MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="Hive与Hadoop关系" title=""><br> <br>
<strong>Hive与Hadoop关系图</strong> <br>
</center><p></p></li>
<li><p>Hive的数据存储 <br>
1、Hive中所有的数据都存储在 HDFS 中，没有专门的数据存储格式（可支持Text，SequenceFile，ParquetFile，RCFILE等）</p>

<p>2、只需要在创建表的时候告诉 Hive 数据中的列分隔符和行分隔符，Hive 就可以解析数据。</p>

<p>3、Hive 中包含以下数据模型：DB、Table，External Table，Partition，Bucket。</p>

<ul><li>db：在hdfs中表现为${hive.metastore.warehouse.dir}目录下一个文件夹</li>
<li>table：在hdfs中表现所属db目录下一个文件夹</li>
<li>external table：与table类似，不过其数据存放位置可以在任意指定路径</li>
<li>partition：在hdfs中表现为table目录下的子目录</li>
<li>bucket：在hdfs中表现为同一个表目录下根据hash散列之后的多个文件</li></ul></li>
<li><p>Hive操作符Operator <br>
•  编译器将一个Hive QL转换操作符 <br>
•  操作符是Hive的最小的处理单元 <br>
•  每个操作符代表HDFS的一个操作或者一道MapReduce作业Operator <br>
•  Operator都是hive定义的一个处理过程</p>

<p>• Operator都定义有: <br>
    • protected List &lt;Operator&lt;?  extends Serializable &gt;&gt; childOperators;  <br>
    • protected List &lt;Operator&lt;?  extends Serializable &gt;&gt; parentOperators;  <br>
    • protected boolean done; // 初始化值为false <br>
    • 所有的操作构成了 Operator图，hive正是基于这些图关系来处理诸如limit, group by, join等操作</p></li>
</ul>

<p><br></p>



<h3 id="hivesql执行流程"><strong>HiveSql执行流程</strong></h3>

<blockquote>
  <p>1、 提交sql ，交给驱动</p>
  
  <p>2、驱动编译，解析相关的字段表信息</p>
  
  <p>3、去metastore查询相关的信息，返回字段表信息</p>
  
  <p>4、编译返回信息 发给驱动</p>
  
  <p>5、驱动发送一个执行计划，交给执行引擎</p>
  
  <p>6.0、DDLs 对数据库表的操作的  直接和metastore交互 <br>
          create table tab(name string);</p>
  
  <p>6.1、把job交给job tracker 让task tracker执行 返回执行信息</p>
  
  <p>6.2、完成job返回数据信息，找namenode查数据</p>
  
  <p>6.3、namenode交互 <br>
          select count(1) from tab;</p>
  
  <p>6.1、dfs ops 直接和直接去数据 <br>
          select * from tab;</p>
  
  <p>7、返回结果信息集</p>
</blockquote>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>