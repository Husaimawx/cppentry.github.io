---
layout:     post
title:      Hadoop开发---经验总结2
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/a2011480169/article/details/51758200				</div>
								            <div id="content_views" class="markdown_views prism-tomorrow-night">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>最近一段时间又在忙hadoop了，针对最近开发过程中遇到的问题总结一下： <br>
(1)HDFS命令  hadoop   fs  -rmr   /*  的一个漏洞问题 <br>
实例如下： <br>
<img src="https://img-blog.csdn.net/20160625105718060" alt="这里写图片描述" title=""> <br>
解决方案：将HDFS的具体访问路径在命令行中写出： <br>
hadoop  fs  -rmr  hdfs://hadoop20:9000/*  <br>
<img src="https://img-blog.csdn.net/20160625110012392" alt="这里写图片描述" title=""> <br>
(2) HDFS中block块的具体理解:我们都知道文件在HDFS中是以block块的形式来进行存储的，但归根到底文件最终还是存储在了本地文件系统linux中，而其具体存储路径是由下面的配置文件决定的： <br>
<img src="https://img-blog.csdn.net/20160625111429561" alt="这里写图片描述" title=""> <br>
在实战中无意间发现了下面一个有趣的问题：block块的内容竟然是可以阅读的！这正好说明了block块是按固定的大小,顺序的对文件进行划分–流式的划分，然而在内容上并不对我们的文件进行任何的处理。 <br>
<img src="https://img-blog.csdn.net/20160625112207720" alt="这里写图片描述" title=""> <br>
(3)eclipse中导入jar包的一个优异方式 <br>
以前导入jar包的时候，是用的这种方式： <br>
<img src="https://img-blog.csdn.net/20160625124316940" alt="这里写图片描述" title=""> <br>
这种方式虽然简单，但是缺点也是显而易见的，就是导入的jar包太冗余，这几天学会了一种新的导入jar包的方式：自己建立library，进而在library中导入相应的jar包 <br>
<img src="https://img-blog.csdn.net/20160625125040170" alt="这里写图片描述" title=""> <br>
(4)Hadoop中HDFS的Java Api—–FileSystem的具体用法： <br>
注意： <br>
1&gt;上传文件的前提：必须在hdfs中先创建一个文件 create <br>
2&gt;下载文件的前提:必须在hdfs中先打开这个文件  open <br>
①创建文件夹</p>



<pre class="prettyprint"><code class=" hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> App1
{
     <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span>(String[] args) throws Exception
    {
         Configuration conf = <span class="hljs-keyword">new</span> Configuration();
         FileSystem fileSystem = FileSystem.<span class="hljs-keyword">get</span>(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">"hdfs://hadoop20:9000/"</span>), conf, <span class="hljs-string">"root"</span>);

         <span class="hljs-comment">//创建文件夹的方式：可以迭代创建</span>
         fileSystem.mkdirs(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">"hdfs://hadoop20:9000/dir1/dir2"</span>));
    }
}</code></pre>

<p><img src="https://img-blog.csdn.net/20160625130919547" alt="这里写图片描述" title=""> <br>
②从本地文件系统(本地参考的是eclipse安装在linux上还是windows上)上传文件到HDFS上</p>



<pre class="prettyprint"><code class=" hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> App1
{
     <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span>(String[] args) throws Exception
    {
         Configuration conf = <span class="hljs-keyword">new</span> Configuration();
         FileSystem fileSystem = FileSystem.<span class="hljs-keyword">get</span>(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">"hdfs://hadoop20:9000/"</span>), conf, <span class="hljs-string">"root"</span>);

         <span class="hljs-comment">//从本地上传文件到HDFS</span>
         FSDataOutputStream fw = fileSystem.create(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">"/dir1/dir2/file.txt"</span>));
         FileInputStream fr = <span class="hljs-keyword">new</span> FileInputStream(<span class="hljs-string">"C:\\file.txt"</span>);
         IOUtils.copyBytes(fr,fw,<span class="hljs-number">1024</span>,<span class="hljs-keyword">true</span>);
    }
}</code></pre>

<p>上面的代码也可以用下面简单的代码来替代：</p>



<pre class="prettyprint"><code class=" hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> App1
{
     <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span>(String[] args) throws Exception
    {
         Configuration conf = <span class="hljs-keyword">new</span> Configuration();
         FileSystem fileSystem = FileSystem.<span class="hljs-keyword">get</span>(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">"hdfs://hadoop20:9000/"</span>), conf, <span class="hljs-string">"root"</span>);

         <span class="hljs-comment">//从本地上传文件到HDFS</span>
         fileSystem.copyFromLocalFile(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">"C:\\file.txt"</span>), <span class="hljs-keyword">new</span> Path(<span class="hljs-string">"hdfs://hadoop20:9000/dir1/dir2/file.txt"</span>));
    }
}</code></pre>

<p>③从HDFS中下载文件到本地（本地参考的是eclipse安装在linux上还是windows上）</p>



<pre class="prettyprint"><code class=" hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> App1
{
     <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span>(String[] args) throws Exception
    {
         Configuration conf = <span class="hljs-keyword">new</span> Configuration();
         FileSystem fileSystem = FileSystem.<span class="hljs-keyword">get</span>(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">"hdfs://hadoop20:9000/"</span>), conf, <span class="hljs-string">"root"</span>);

         <span class="hljs-comment">//从hdfs中下载文件到本地</span>
         FSDataInputStream fr = fileSystem.open(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">"hdfs://hadoop20:9000/dir1/dir2/file.txt"</span>));
         IOUtils.copyBytes(fr,System.<span class="hljs-keyword">out</span>, <span class="hljs-number">1024</span>, <span class="hljs-keyword">true</span>);
    }
}</code></pre>

<p><img src="https://img-blog.csdn.net/20160625132410983" alt="这里写图片描述" title=""> <br>
当然，上面的代码也可以用下面的代码来替代：</p>



<pre class="prettyprint"><code class=" hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> App1
{
     <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span>(String[] args) throws Exception
    {
         Configuration conf = <span class="hljs-keyword">new</span> Configuration();
         FileSystem fileSystem = FileSystem.<span class="hljs-keyword">get</span>(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">"hdfs://hadoop20:9000/"</span>), conf, <span class="hljs-string">"root"</span>);

         <span class="hljs-comment">//从hdfs中下载文件到本地</span>
         fileSystem.copyToLocalFile(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">"hdfs://hadoop20:9000/dir1/dir2/file.txt"</span>), <span class="hljs-keyword">new</span> Path(<span class="hljs-string">"D:\\file.txt"</span>));
    }
}</code></pre>

<p>运行结果： <br>
<img src="https://img-blog.csdn.net/20160625132814056" alt="这里写图片描述" title="">　　 <br>
调试方式：</p>



<pre class="prettyprint"><code class=" hljs cs">fileSystem.copyToLocalFile(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">"hdfs://hadoop20:9000/dir1/dir2/file.txt"</span>), <span class="hljs-keyword">new</span> Path(<span class="hljs-string">"D:\\file.txt"</span>));
         改为：
         fileSystem.copyToLocalFile(<span class="hljs-keyword">false</span>,<span class="hljs-keyword">new</span> Path(<span class="hljs-string">"hdfs://hadoop20:9000/dir1/dir2/file.txt"</span>), <span class="hljs-keyword">new</span> Path(<span class="hljs-string">"D:\\file.txt"</span>),<span class="hljs-keyword">true</span>);</code></pre>

<p>错误原因： <br>
在使用copyToLocalFile(Path src, Path dst)方法时可能导致 setPermission文件本地文件效验失败，因此使用copyToLocalFile( boolean delSrc,Path src, Path dst, boolean useRawLocalFileSystem)，其中： <br>
         boolean delSrc 指是否将原文件删除 <br>
         Path src 指要下载的文件路径 <br>
         Path dst 指将文件下载到的路径 <br>
         boolean useRawLocalFileSystem 是否开启文件效验 <br>
④删除文件夹</p>



<pre class="prettyprint"><code class=" hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> App1
{
     <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span>(String[] args) throws Exception
    {
         Configuration conf = <span class="hljs-keyword">new</span> Configuration();
         FileSystem fileSystem = FileSystem.<span class="hljs-keyword">get</span>(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">"hdfs://hadoop20:9000/"</span>), conf, <span class="hljs-string">"root"</span>);

         <span class="hljs-comment">//删除文件或文件夹</span>
         fileSystem.delete(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">"hdfs://hadoop20:9000/dir1/dir2/file.txt"</span>), <span class="hljs-keyword">false</span>);
    }
}</code></pre>

<p><img src="https://img-blog.csdn.net/20160625133839404" alt="这里写图片描述" title="">　　　 <br>
(５)Exception in thread “main” org.apache.hadoop.security.AccessControlException: Permission denied: user=Administrator, access=EXECUTE, inode=”/tmp”:hadoop:supergroup:drwx—— <br>
这句话的含义当前用户是Administrator、想对/tmp这个目录执行执行操作，但是不具有相应的权限。 <br>
处理方式：</p>

<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>      
    <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.permissions<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>     
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span> 
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>



<pre class="prettyprint"><code class=" hljs cs">         FileSystem fileSystem = FileSystem.<span class="hljs-keyword">get</span>(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">"hdfs://hadoop20:9000/"</span>), conf);
         改为：
         FileSystem fileSystem = FileSystem.<span class="hljs-keyword">get</span>(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">"hdfs://hadoop20:9000/"</span>), conf, <span class="hljs-string">"root"</span>);
／／指定以ｒｏｏｔ的身份去访问</code></pre>

<p>或者： <br>
<img src="https://img-blog.csdn.net/20160625134354609" alt="这里写图片描述" title="">　　　 <br>
或者：</p>



<pre class="prettyprint"><code class=" hljs perl">hadoop fs -<span class="hljs-keyword">chmod</span> <span class="hljs-number">777</span> /tmp     从而修改/tmp目录的权限</code></pre>

<p>从而适合： <br>
<img src="https://img-blog.csdn.net/20160701214648119" alt="这里写图片描述" title=""> <br>
对于以上问题，如有问题，欢迎留言指正！</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>