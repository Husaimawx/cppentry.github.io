---
layout:     post
title:      Spark生态顶级项目汇总
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p style="clear:both;min-height:1em;color:rgb(62,62,62);font-family:'Helvetica Neue', Helvetica, 'Hiragino Sans GB', 'Microsoft YaHei', Arial, sans-serif;font-size:16px;line-height:25.6px;">
</p>
<p style="border:0px;font-size:14px;line-height:25.2px;clear:both;width:610px;font-family:'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', '微软雅黑', STHeiti, 'WenQuanYi Micro Hei', SimSun, Helvetica, sans-serif;">
现在Apache Spark已形成一个丰富的生态系统，包括官方的和第三方开发的组件或工具。后面主要给出5个使用广泛的第三方项目。</p>
<p style="border:0px;font-size:14px;line-height:25.2px;clear:both;width:610px;font-family:'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', '微软雅黑', STHeiti, 'WenQuanYi Micro Hei', SimSun, Helvetica, sans-serif;">
Spark官方构建了一个非常紧凑的生态系统组件，提供各种处理能力。 下面是Spark官方给出的生态系统组件（引自Spark官方文档）。<br style="border:0px;"><img alt="" src="http://cdn2.infoqstatic.com/statics_s1_20160301-0105u6/resource/news/2016/03/spark-eco-project/zh/resources/6631232692448704313.jpg" style="border:0px;width:499px;"></p>
<ol style="border:0px;width:549px;clear:left;font-family:'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', '微软雅黑', STHeiti, 'WenQuanYi Micro Hei', SimSun, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><li style="border:none;clear:none;text-align:left;">
Spark DataFrames：列式存储的分布式数据组织，类似于关系型数据表。</li><li style="border:none;clear:none;text-align:left;">
Spark SQL：可以执行SQL查询，包括基本的SQL语法和HiveQL语法。读取的数据源包括Hive表、Parquent文件、JSON数据、关系数据库（MySQL等）等。</li><li style="border:none;clear:none;text-align:left;">
Spark Streaming：Spark Streaming是Spark核心API，易扩展、高吞吐量、流式数据容错。</li><li style="border:none;clear:none;text-align:left;">
MLlib：Spark的机器学习库，由常规的机器学习算法和基础构成，包括但不限于分类算法、回归算法、聚类算法、协调过滤算法、降维算法等。</li><li style="border:none;clear:none;text-align:left;">
GraphX：Spark GraphX是一个分布式图处理框架，基于Spark平台提供对图计算和图挖掘的接口，方便用户对分布式图处理的需求。</li><li style="border:none;clear:none;text-align:left;">
Spark Core API：Spark提供多种语言的API，包括R、SQL、Python、Scala和Java。</li></ol><p style="border:0px;font-size:14px;line-height:25.2px;clear:both;width:610px;font-family:'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', '微软雅黑', STHeiti, 'WenQuanYi Micro Hei', SimSun, Helvetica, sans-serif;">
除了上述官方的Spark组件外，还有些是在某种情形下必用的项目。以下只是简单的列出这些重量级 项目，而不涉及一些性能指标。</p>
<ol style="border:0px;width:549px;clear:left;font-family:'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', '微软雅黑', STHeiti, 'WenQuanYi Micro Hei', SimSun, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><li style="border:none;clear:none;text-align:left;">
Mesos<br style="border:0px;">
Mesos是开源的资源统一管理和调度平台。抽象物理机的CPU、内存、存储和计算资源，再由框架自身的调度器决定资源的使用者。<br style="border:0px;">
Mesos是Master／Slave结构，由Mesos－master，Mesos－slave，Framework和executor四个组件构成。<br style="border:0px;">
为什么官方选用Mesos，而不是Spark standalone模式或者基于Yarn框架？由Spark开发者所写的书<a href="http://www.amazon.com/dp/1449358624/" rel="nofollow" style="text-decoration:none;color:rgb(40,106,178);border:0px;">《Learning Spark》</a>：Mesos优于其它两个资源框架是因为Mesos的细粒度调度，这样可让多用户运行Spark
 shell占有更少的CPU。<br style="border:0px;"><img alt="" src="http://cdn2.infoqstatic.com/statics_s1_20160301-0105u6/resource/news/2016/03/spark-eco-project/zh/resources/4871487422031625959.png" style="border:0px;width:550px;"></li><li style="border:none;clear:none;text-align:left;">
Spark Cassandra Connector<br style="border:0px;">
Cassandra是一个易扩展、高性能的数据库。 Spark Cassandra Connector现在是Spark和Cassandra表间直接交互的连接器，高度活跃的开源软件。 Spark Cassandra Connector库让你读Cassandra表就如同Spark RDD一样，同样可以写Spark RDD到Cassandra表，并可以在Spark程序中执行CQL语句。</li><li style="border:none;clear:none;text-align:left;">
<p style="border:0px;line-height:1.8;clear:both;width:539px;">
Zepellin<br style="border:0px;">
Zepellin是一个集成IPythoon notebook风格的Spark应用。Zepellin可以基于Spark和Scala，允许用户很简单直接的在他们的博客或者网站发布代码执行的结果。<br style="border:0px;">
Zepellin也支持其它语言插件，包括Scala和Spark，Python和Spark，SparkSQL，HIve，Markdown和Shell。<br style="border:0px;"><img alt="" src="http://cdn2.infoqstatic.com/statics_s1_20160301-0105u6/resource/news/2016/03/spark-eco-project/zh/resources/14912864243608086074.jpg" style="border:0px;width:499px;"></p>
</li><li style="border:none;clear:none;text-align:left;">
<p style="border:0px;line-height:1.8;clear:both;width:539px;">
Spark Job Server<br style="border:0px;">
Spark Job Server提供RESTful接口来提交和管理Spark jobs，jar包和job上下文。Spark Job Server提供Spark任务相关的运行健康信息。</p>
</li><li style="border:none;clear:none;text-align:left;">
Alluxio<br style="border:0px;">
Alluxio是一个分布式内存文件系统，它在减轻Spark内存压力的同时，也赋予Spark内存快速读写海量数据的能力。Alluxio以前叫做Tachyon，即钨丝。Spark jobs可以不做任何改变即可运行在Alluxio上，并能得到极大的性能优化。Alluxio宣称：“百度使用Alluxio可以提高30倍多数据处理能力”。</li></ol><br>            </div>
                </div>