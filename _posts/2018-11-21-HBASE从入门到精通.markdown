---
layout:     post
title:      HBASE从入门到精通
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p><br>
</p>
<p>一、 HBase技术介绍</p>
<p> </p>
<h1>HBase简介</h1>
<p>HBase – Hadoop Database，是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用HBase技术可在廉价PC Server上搭建起大规模结构化存储集群。</p>
<p>HBase是Google Bigtable的开源实现，类似Google Bigtable利用GFS作为其文件存储系统，HBase利用Hadoop HDFS作为其文件存储系统；Google运行MapReduce来处理Bigtable中的海量数据，HBase同样利用Hadoop MapReduce来处理HBase中的海量数据；Google Bigtable利用 Chubby作为协同服务，HBase利用Zookeeper作为对应。</p>
<p> </p>
<p>上图描述了Hadoop EcoSystem中的各层系统，其中HBase位于结构化存储层，Hadoop HDFS为HBase提供了高可靠性的底层存储支持，Hadoop MapReduce为HBase提供了高性能的计算能力，Zookeeper为HBase提供了稳定服务和failover机制。</p>
<p>此外，Pig和Hive还为HBase提供了高层语言支持，使得在HBase上进行数据统计处理变的非常简单。 Sqoop则为HBase提供了方便的RDBMS数据导入功能，使得传统数据库数据向HBase中迁移变的非常方便。</p>
<p>HBase访问接口</p>
<p>1.       Native Java API，最常规和高效的访问方式，适合Hadoop MapReduce Job并行批处理HBase表数据</p>
<p>2.       HBase Shell，HBase的命令行工具，最简单的接口，适合HBase管理使用</p>
<p>3.       Thrift Gateway，利用Thrift序列化技术，支持C++，PHP，Python等多种语言，适合其他异构系统在线访问HBase表数据</p>
<p>4.       REST Gateway，支持REST 风格的Http API访问HBase, 解除了语言限制</p>
<p>5.       Pig，可以使用Pig Latin流式编程语言来操作HBase中的数据，和Hive类似，本质最终也是编译成MapReduce Job来处理HBase表数据，适合做数据统计</p>
<p>6.       Hive，当前Hive的Release版本尚没有加入对HBase的支持，但在下一个版本Hive 0.7.0中将会支持HBase，可以使用类似SQL语言来访问HBase</p>
<p>HBase数据模型</p>
<p>Table &amp; Column Family</p>
<table>
<tbody>
<tr>
<td valign="center" rowspan="2">
<p>Row Key</p>
</td>
<td valign="center" rowspan="2">
<p>Timestamp</p>
</td>
<td width="384" valign="center" colspan="2">
<p>Column Family</p>
</td>
</tr>
<tr>
<td valign="center">
<p>URI</p>
</td>
<td valign="center">
<p>Parser</p>
</td>
</tr>
<tr>
<td valign="center" rowspan="3">
<p>r1</p>
</td>
<td valign="center">
<p>t3</p>
</td>
<td valign="center">
<p>url=http://www.taobao.com</p>
</td>
<td valign="center">
<p>title=天天特价</p>
</td>
</tr>
<tr>
<td valign="center">
<p>t2</p>
</td>
<td valign="center">
<p>host=taobao.com</p>
</td>
<td valign="center">
<p> </p>
</td>
</tr>
<tr>
<td valign="center">
<p>t1</p>
</td>
<td valign="center">
<p> </p>
</td>
<td valign="center">
<p> </p>
</td>
</tr>
<tr>
<td valign="center" rowspan="2">
<p>r2</p>
</td>
<td valign="center">
<p>t5</p>
</td>
<td valign="center">
<p>url=http://www.alibaba.com</p>
</td>
<td valign="center">
<p>content=每天…</p>
</td>
</tr>
<tr>
<td valign="center">
<p>t4</p>
</td>
<td valign="center">
<p>host=alibaba.com</p>
</td>
<td valign="center">
<p> </p>
</td>
</tr>
</tbody>
</table>
<p>Ø  Row Key: 行键，Table的主键，Table中的记录按照Row Key排序</p>
<p>Ø  Timestamp: 时间戳，每次数据操作对应的时间戳，可以看作是数据的version number</p>
<p>Ø  Column Family：列簇，Table在水平方向有一个或者多个Column Family组成，一个Column Family中可以由任意多个Column组成，即Column Family支持动态扩展，无需预先定义Column的数量以及类型，所有Column均以二进制格式存储，用户需要自行进行类型转换。</p>
<p>Table &amp; Region</p>
<p>当Table随着记录数不断增加而变大后，会逐渐分裂成多份splits，成为regions，一个region由[startkey,endkey)表示，不同的region会被Master分配给相应的RegionServer进行管理：</p>
<p> </p>
<p>-ROOT- &amp;&amp; .META. Table</p>
<p>HBase中有两张特殊的Table，-ROOT-和.META.</p>
<p>Ø  .META.：记录了用户表的Region信息，.META.可以有多个regoin</p>
<p>Ø  -ROOT-：记录了.META.表的Region信息，-ROOT-只有一个region</p>
<p>Ø  Zookeeper中记录了-ROOT-表的location</p>
<p> </p>
<p>Client访问用户数据之前需要首先访问zookeeper，然后访问-ROOT-表，接着访问.META.表，最后才能找到用户数据的位置去访问，中间需要多次网络操作，不过client端会做cache缓存。</p>
<p>MapReduce on HBase</p>
<p>在HBase系统上运行批处理运算，最方便和实用的模型依然是MapReduce，如下图：</p>
<p> </p>
<p>HBase Table和Region的关系，比较类似HDFS File和Block的关系，HBase提供了配套的TableInputFormat和TableOutputFormat API，可以方便的将HBase Table作为Hadoop MapReduce的Source和Sink，对于MapReduce Job应用开发人员来说，基本不需要关注HBase系统自身的细节。</p>
<p>HBase系统架构</p>
<p> </p>
<p>Client</p>
<p>HBase Client使用HBase的RPC机制与HMaster和HRegionServer进行通信，对于管理类操作，Client与HMaster进行RPC；对于数据读写类操作，Client与HRegionServer进行RPC</p>
<p>Zookeeper</p>
<p>Zookeeper Quorum中除了存储了-ROOT-表的地址和HMaster的地址，HRegionServer也会把自己以Ephemeral方式注册到Zookeeper中，使得HMaster可以随时感知到各个HRegionServer的健康状态。此外，Zookeeper也避免了HMaster的单点问题，见下文描述</p>
<p>HMaster</p>
<p>HMaster没有单点问题，HBase中可以启动多个HMaster，通过Zookeeper的Master Election机制保证总有一个Master运行，HMaster在功能上主要负责Table和Region的管理工作：</p>
<p>1.       管理用户对Table的增、删、改、查操作</p>
<p>2.       管理HRegionServer的负载均衡，调整Region分布</p>
<p>3.       在Region Split后，负责新Region的分配</p>
<p>4.       在HRegionServer停机后，负责失效HRegionServer 上的Regions迁移</p>
<p>HRegionServer</p>
<p>HRegionServer主要负责响应用户I/O请求，向HDFS文件系统中读写数据，是HBase中最核心的模块。</p>
<p> </p>
<p>HRegionServer内部管理了一系列HRegion对象，每个HRegion对应了Table中的一个Region，HRegion中由多个HStore组成。每个HStore对应了Table中的一个Column Family的存储，可以看出每个Column Family其实就是一个集中的存储单元，因此最好将具备共同IO特性的column放在一个Column Family中，这样最高效。</p>
<p>HStore存储是HBase存储的核心了，其中由两部分组成，一部分是MemStore，一部分是StoreFiles。MemStore是Sorted Memory Buffer，用户写入的数据首先会放入MemStore，当MemStore满了以后会Flush成一个StoreFile（底层实现是HFile），当StoreFile文件数量增长到一定阈值，会触发Compact合并操作，将多个StoreFiles合并成一个StoreFile，合并过程中会进行版本合并和数据删除，因此可以看出HBase其实只有增加数据，所有的更新和删除操作都是在后续的compact过程中进行的，这使得用户的写操作只要进入内存中就可以立即返回，保证了HBase I/O的高性能。当StoreFiles Compact后，会逐步形成越来越大的StoreFile，当单个StoreFile大小超过一定阈值后，会触发Split操作，同时把当前Region Split成2个Region，父Region会下线，新Split出的2个孩子Region会被HMaster分配到相应的HRegionServer上，使得原先1个Region的压力得以分流到2个Region上。下图描述了Compaction和Split的过程：</p>
<p> </p>
<p>在理解了上述HStore的基本原理后，还必须了解一下HLog的功能，因为上述的HStore在系统正常工作的前提下是没有问题的，但是在分布式系统环境中，无法避免系统出错或者宕机，因此一旦HRegionServer意外退出，MemStore中的内存数据将会丢失，这就需要引入HLog了。每个HRegionServer中都有一个HLog对象，HLog是一个实现Write Ahead Log的类，在每次用户操作写入MemStore的同时，也会写一份数据到HLog文件中（HLog文件格式见后续），HLog文件定期会滚动出新的，并删除旧的文件（已持久化到StoreFile中的数据）。当HRegionServer意外终止后，HMaster会通过Zookeeper感知到，HMaster首先会处理遗留的 HLog文件，将其中不同Region的Log数据进行拆分，分别放到相应region的目录下，然后再将失效的region重新分配，领取 到这些region的HRegionServer在Load Region的过程中，会发现有历史HLog需要处理，因此会Replay HLog中的数据到MemStore中，然后flush到StoreFiles，完成数据恢复。</p>
<p>HBase存储格式</p>
<p>HBase中的所有数据文件都存储在Hadoop HDFS文件系统上，主要包括上述提出的两种文件类型：</p>
<p>1.       HFile， HBase中KeyValue数据的存储格式，HFile是Hadoop的二进制格式文件，实际上StoreFile就是对HFile做了轻量级包装，即StoreFile底层就是HFile</p>
<p>2.       HLog File，HBase中WAL（Write Ahead Log） 的存储格式，物理上是Hadoop的Sequence File</p>
<p>HFile</p>
<p>下图是HFile的存储格式：</p>
<p> </p>
<p>首先HFile文件是不定长的，长度固定的只有其中的两块：Trailer和FileInfo。正如图中所示的，Trailer中有指针指向其他数据块的起始点。File Info中记录了文件的一些Meta信息，例如：AVG_KEY_LEN, AVG_VALUE_LEN, LAST_KEY, COMPARATOR, MAX_SEQ_ID_KEY等。Data Index和Meta Index块记录了每个Data块和Meta块的起始点。</p>
<p>Data Block是HBase I/O的基本单元，为了提高效率，HRegionServer中有基于LRU的Block Cache机制。每个Data块的大小可以在创建一个Table的时候通过参数指定，大号的Block有利于顺序Scan，小号Block利于随机查询。每个Data块除了开头的Magic以外就是一个个KeyValue对拼接而成, Magic内容就是一些随机数字，目的是防止数据损坏。后面会详细介绍每个KeyValue对的内部构造。</p>
<p>HFile里面的每个KeyValue对就是一个简单的byte数组。但是这个byte数组里面包含了很多项，并且有固定的结构。我们来看看里面的具体结构：</p>
<p> </p>
<p>开始是两个固定长度的数值，分别表示Key的长度和Value的长度。紧接着是Key，开始是固定长度的数值，表示RowKey的长度，紧接着是RowKey，然后是固定长度的数值，表示Family的长度，然后是Family，接着是Qualifier，然后是两个固定长度的数值，表示Time Stamp和Key Type（Put/Delete）。Value部分没有这么复杂的结构，就是纯粹的二进制数据了。</p>
<p>HLogFile</p>
<p> </p>
<p>上图中示意了HLog文件的结构，其实HLog文件就是一个普通的Hadoop Sequence File，Sequence File 的Key是HLogKey对象，HLogKey中记录了写入数据的归属信息，除了table和region名字外，同时还包括 sequence number和timestamp，timestamp是“写入时间”，sequence number的起始值为0，或者是最近一次存入文件系统中sequence number。</p>
<p>HLog Sequece File的Value是HBase的KeyValue对象，即对应HFile中的KeyValue，可参见上文描述。</p>
<p>结束</p>
<p>本文对HBase技术在功能和设计上进行了大致的介绍，由于篇幅有限，本文没有过多深入地描述HBase的一些细节技术。目前一淘的存储系统就是基于HBase技术搭建的，后续将介绍“一淘分布式存储系统”，通过实际案例来更多的介绍HBase应用。</p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p>二、 HBASE官方文档</p>
<p><a target="_blank" name="d613e2"></a><a target="_blank" href="http://www.hbase.org" rel="nofollow"><span style="color:rgb(0,0,255)">HBase</span></a><span style="color:rgb(153,0,0)"> 官方文档</span></p>
<p>Copyright © 2010 Apache Software Foundation, <a target="_blank" href="http://www.yankay.com/" rel="nofollow"><span style="color:rgb(0,0,255)">盛大游戏-数据仓库团队-颜开</span></a>(译)</p>
<table>
<tbody>
<tr>
<td width="561" valign="top" colspan="2">
<p>Revision History</p>
</td>
</tr>
<tr>
<td valign="center">
<p>Revision 0.90.4</p>
</td>
<td valign="center">
<p> </p>
</td>
</tr>
<tr>
<td width="561" valign="center" colspan="2">
<p>配置，数据模型使用入门</p>
</td>
</tr>
</tbody>
</table>
<p>Abstract</p>
<p>这是 <a target="_blank" href="http://www.hbase.org/" rel="nofollow"><span style="color:rgb(0,0,255)">Apache HBase</span></a>的官方文档, Hbase是一个分布式,版本化(versioned)，构建在 <a target="_blank" href="http://hadoop.apache.org/" rel="nofollow"><span style="color:rgb(0,0,255)">Apache Hadoop</span></a>和 <a target="_blank" href="http://zookeeper.apache.org/" rel="nofollow"><span style="color:rgb(0,0,255)">Apache ZooKeeper</span></a>上的列数据库.</p>
<p>我(译者)熟悉Hbase的源代码，从事Hbase的开发运维工作，如果有什么地方不清楚，欢迎一起讨论。邮箱yankaycom@gmail.com </p>
<p></p>
<p>Table of Contents</p>
<p><a target="_blank" href="#preface" rel="nofollow"><span style="color:rgb(0,0,255)">序</span></a></p>
<p><a target="_blank" href="#getting_started" rel="nofollow"><span style="color:rgb(0,0,255)">1. 入门</span></a></p>
<p><a target="_blank" href="#d613e75" rel="nofollow"><span style="color:rgb(0,0,255)">1.1. 介绍</span></a></p>
<p><a target="_blank" href="#quickstart" rel="nofollow"><span style="color:rgb(0,0,255)">1.2. 快速开始</span></a></p>
<p><a target="_blank" href="#d613e91" rel="nofollow"><span style="color:rgb(0,0,255)">1.2.1. 下载解压最新版本</span></a></p>
<p><a target="_blank" href="#start_hbase" rel="nofollow"><span style="color:rgb(0,0,255)">1.2.2. 启动 HBase</span></a></p>
<p><a target="_blank" href="#shell_exercises" rel="nofollow"><span style="color:rgb(0,0,255)">1.2.3. Shell 练习</span></a></p>
<p><a target="_blank" href="#stopping" rel="nofollow"><span style="color:rgb(0,0,255)">1.2.4. 停止 HBase</span></a></p>
<p><a target="_blank" href="#d613e242" rel="nofollow"><span style="color:rgb(0,0,255)">1.2.5. 下一步该做什么</span></a></p>
<p><a target="_blank" href="#notsoquick" rel="nofollow"><span style="color:rgb(0,0,255)">1.3. 慢速开始(相对快速开始)</span></a></p>
<p><a target="_blank" href="#requirements" rel="nofollow"><span style="color:rgb(0,0,255)">1.3.1. 需要的软件</span></a></p>
<p><a target="_blank" href="#standalone_dist" rel="nofollow"><span style="color:rgb(0,0,255)">1.3.2. HBase运行模式:单机和分布式</span></a></p>
<p><a target="_blank" href="#example_config" rel="nofollow"><span style="color:rgb(0,0,255)">1.3.3. 配置例子</span></a></p>
<p><a target="_blank" href="#upgrading" rel="nofollow"><span style="color:rgb(0,0,255)">2. 升级</span></a></p>
<p><a target="_blank" href="#upgrade0.90" rel="nofollow"><span style="color:rgb(0,0,255)">2.1. 从HBase 0.20.x or 0.89.x 升级到 HBase 0.90.x </span></a></p>
<p><a target="_blank" href="#configuration" rel="nofollow"><span style="color:rgb(0,0,255)">3. 配置</span></a></p>
<p><a target="_blank" href="#hbase.site" rel="nofollow"><span style="color:rgb(0,0,255)">3.1. </span><span style="color:rgb(0,122,0)">hbase-site.xml</span><span style="color:rgb(0,0,255)"> 和 </span><span style="color:rgb(0,122,0)">hbase-default.xml</span></a></p>
<p><a target="_blank" href="#hbase_default_configurations" rel="nofollow"><span style="color:rgb(0,0,255)">3.1.1. HBase 默认配置</span></a></p>
<p><a target="_blank" href="#hbase.env.sh" rel="nofollow"><span style="color:rgb(0,0,255)">3.2. </span><span style="color:rgb(0,122,0)">hbase-env.sh</span></a></p>
<p><a target="_blank" href="#log4j" rel="nofollow"><span style="color:rgb(0,0,255)">3.3. </span><span style="color:rgb(0,122,0)">log4j.properties</span></a></p>
<p><a target="_blank" href="#important_configurations" rel="nofollow"><span style="color:rgb(0,0,255)">3.4. 重要的配置</span></a></p>
<p><a target="_blank" href="#required_configuration" rel="nofollow"><span style="color:rgb(0,0,255)">3.5. 必须的配置 </span></a></p>
<p><a target="_blank" href="#recommended_configurations" rel="nofollow"><span style="color:rgb(0,0,255)">3.6. 推荐的配置</span></a></p>
<p><a target="_blank" href="#zookeeper.session.timeout" rel="nofollow"><span style="color:rgb(0,0,255)">3.6.1. zookeeper.session.timeout</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.handler.count" rel="nofollow"><span style="color:rgb(0,0,255)">3.6.2. hbase.regionserver.handler.count</span></a></p>
<p><a target="_blank" href="#big_memory" rel="nofollow"><span style="color:rgb(0,0,255)">3.6.3. 大内存机器的配置 </span></a></p>
<p><a target="_blank" href="#lzo" rel="nofollow"><span style="color:rgb(0,0,255)">3.6.4. LZO 压缩</span></a></p>
<p><a target="_blank" href="#bigger.regions" rel="nofollow"><span style="color:rgb(0,0,255)">3.6.5. 更大的 Regions</span></a></p>
<p><a target="_blank" href="#disable.splitting" rel="nofollow"><span style="color:rgb(0,0,255)">3.6.6. 管理 Splitting</span></a></p>
<p><a target="_blank" href="#client_dependencies" rel="nofollow"><span style="color:rgb(0,0,255)">3.7. 连接Hbase集群的客户端配置和依赖</span></a></p>
<p><a target="_blank" href="#d613e2045" rel="nofollow"><span style="color:rgb(0,0,255)">3.7.1. Java客户端配置</span></a></p>
<p><a target="_blank" href="#shell" rel="nofollow"><span style="color:rgb(0,0,255)">4. The HBase Shell</span></a></p>
<p><a target="_blank" href="#scripting" rel="nofollow"><span style="color:rgb(0,0,255)">4.1. 使用脚本</span></a></p>
<p><a target="_blank" href="#shell_tricks" rel="nofollow"><span style="color:rgb(0,0,255)">4.2. Shell 技巧</span></a></p>
<p><a target="_blank" href="#d613e2127" rel="nofollow"><span style="color:rgb(0,0,255)">4.2.1. </span><span style="color:rgb(0,122,0)">irbrc</span></a></p>
<p><a target="_blank" href="#d613e2145" rel="nofollow"><span style="color:rgb(0,0,255)">4.2.2. LOG 时间转换</span></a></p>
<p><a target="_blank" href="#d613e2163" rel="nofollow"><span style="color:rgb(0,0,255)">4.2.3. Debug</span></a></p>
<p><a target="_blank" href="#build" rel="nofollow"><span style="color:rgb(0,0,255)">5. 构建 HBase</span></a></p>
<p><a target="_blank" href="#mvn_repo" rel="nofollow"><span style="color:rgb(0,0,255)">5.1. 将一个 HBase release 加入到 Apache's Maven Repository</span></a></p>
<p><a target="_blank" href="#build" rel="nofollow"><span style="color:rgb(0,0,255)">6. Developers</span></a></p>
<p><a target="_blank" href="#ides" rel="nofollow"><span style="color:rgb(0,0,255)">6.1. IDEs</span></a></p>
<p><a target="_blank" href="#eclipse" rel="nofollow"><span style="color:rgb(0,0,255)">6.1.1. Eclipse</span></a></p>
<p><a target="_blank" href="#unit.tests" rel="nofollow"><span style="color:rgb(0,0,255)">6.2. 单元测试</span></a></p>
<p><a target="_blank" href="#mockito" rel="nofollow"><span style="color:rgb(0,0,255)">6.2.1. Mocito</span></a></p>
<p><a target="_blank" href="#mapreduce" rel="nofollow"><span style="color:rgb(0,0,255)">7. HBase 和 MapReduce</span></a></p>
<p><a target="_blank" href="#splitter" rel="nofollow"><span style="color:rgb(0,0,255)">7.1. 默认 HBase MapReduce 分割器(Splitter)</span></a></p>
<p><a target="_blank" href="#mapreduce.example" rel="nofollow"><span style="color:rgb(0,0,255)">7.2. HBase Input MapReduce 例子</span></a></p>
<p><a target="_blank" href="#mapreduce.htable.access" rel="nofollow"><span style="color:rgb(0,0,255)">7.3. 在一个MapReduce Job中访问其他的HBase Tables</span></a></p>
<p><a target="_blank" href="#mapreduce.specex" rel="nofollow"><span style="color:rgb(0,0,255)">7.4. 预测执行</span></a></p>
<p><a target="_blank" href="#schema" rel="nofollow"><span style="color:rgb(0,0,255)">8. HBase 的 Schema 设计</span></a></p>
<p><a target="_blank" href="#schema.creation" rel="nofollow"><span style="color:rgb(0,0,255)">8.1. Schema 创建 </span></a></p>
<p><a target="_blank" href="#number.of.cfs" rel="nofollow"><span style="color:rgb(0,0,255)">8.2. column families的数量 </span></a></p>
<p><a target="_blank" href="#timeseries" rel="nofollow"><span style="color:rgb(0,0,255)">8.3. 单调递增Row Keys/时序数据(log) </span></a></p>
<p><a target="_blank" href="#keysize" rel="nofollow"><span style="color:rgb(0,0,255)">8.4. 尽量最小化row和column的大小</span></a></p>
<p><a target="_blank" href="#schema.versions" rel="nofollow"><span style="color:rgb(0,0,255)">8.5. 版本的时间 </span></a></p>
<p><a target="_blank" href="#hbase_metrics" rel="nofollow"><span style="color:rgb(0,0,255)">9. Metrics</span></a></p>
<p><a target="_blank" href="#metric_setup" rel="nofollow"><span style="color:rgb(0,0,255)">9.1. Metric 安装</span></a></p>
<p><a target="_blank" href="#rs_metrics" rel="nofollow"><span style="color:rgb(0,0,255)">9.2. RegionServer Metrics</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.blockCacheCount" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.1. hbase.regionserver.blockCacheCount</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.blockCacheFree" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.2. hbase.regionserver.blockCacheFree</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.blockCacheHitRatio" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.3. hbase.regionserver.blockCacheHitRatio</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.blockCacheSize" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.4. hbase.regionserver.blockCacheSize</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.compactionQueueSize" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.5. hbase.regionserver.compactionQueueSize</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.fsReadLatency_avg_time" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.6. hbase.regionserver.fsReadLatency_avg_time</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.fsReadLatency_num_ops" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.7. hbase.regionserver.fsReadLatency_num_ops</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.fsSyncLatency_avg_time" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.8. hbase.regionserver.fsSyncLatency_avg_time</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.fsSyncLatency_num_ops" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.9. hbase.regionserver.fsSyncLatency_num_ops</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.fsWriteLatency_avg_time" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.10. hbase.regionserver.fsWriteLatency_avg_time</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.fsWriteLatency_num_ops" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.11. hbase.regionserver.fsWriteLatency_num_ops</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.memstoreSizeMB" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.12. hbase.regionserver.memstoreSizeMB</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.regions" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.13. hbase.regionserver.regions</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.requests" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.14. hbase.regionserver.requests</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.storeFileIndexSizeMB" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.15. hbase.regionserver.storeFileIndexSizeMB</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.stores" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.16. hbase.regionserver.stores</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.storeFiles" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.17. hbase.regionserver.storeFiles</span></a></p>
<p><a target="_blank" href="#cluster_replication" rel="nofollow"><span style="color:rgb(0,0,255)">10. 跨集群复制</span></a></p>
<p><a target="_blank" href="#datamodel" rel="nofollow"><span style="color:rgb(0,0,255)">11. 数据模型</span></a></p>
<p><a target="_blank" href="#conceptual.view" rel="nofollow"><span style="color:rgb(0,0,255)">11.1. 概念视图</span></a></p>
<p><a target="_blank" href="#physical.view" rel="nofollow"><span style="color:rgb(0,0,255)">11.2. 物理视图</span></a></p>
<p><a target="_blank" href="#table" rel="nofollow"><span style="color:rgb(0,0,255)">11.3. 表</span></a></p>
<p><a target="_blank" href="#row" rel="nofollow"><span style="color:rgb(0,0,255)">11.4. 行</span></a></p>
<p><a target="_blank" href="#columnfamily" rel="nofollow"><span style="color:rgb(0,0,255)">11.5. Column Family</span></a></p>
<p><a target="_blank" href="#cells" rel="nofollow"><span style="color:rgb(0,0,255)">11.6. Cells</span></a></p>
<p><a target="_blank" href="#versions" rel="nofollow"><span style="color:rgb(0,0,255)">11.7. 版本</span></a></p>
<p><a target="_blank" href="#versions.ops" rel="nofollow"><span style="color:rgb(0,0,255)">11.7.1. Hbase的操作(包含版本操作)</span></a></p>
<p><a target="_blank" href="#d613e2965" rel="nofollow"><span style="color:rgb(0,0,255)">11.7.2. 现有的限制</span></a></p>
<p><a target="_blank" href="#architecture" rel="nofollow"><span style="color:rgb(0,0,255)">12. 架构</span></a></p>
<p><a target="_blank" href="#client" rel="nofollow"><span style="color:rgb(0,0,255)">12.1. 客户端</span></a></p>
<p><a target="_blank" href="#client.connections" rel="nofollow"><span style="color:rgb(0,0,255)">12.1.1. 连接</span></a></p>
<p><a target="_blank" href="#client.writebuffer" rel="nofollow"><span style="color:rgb(0,0,255)">12.1.2. 写缓冲和批量操作 </span></a></p>
<p><a target="_blank" href="#client.filter" rel="nofollow"><span style="color:rgb(0,0,255)">12.1.3. Filters</span></a></p>
<p><a target="_blank" href="#daemons" rel="nofollow"><span style="color:rgb(0,0,255)">12.2. Daemons</span></a></p>
<p><a target="_blank" href="#master" rel="nofollow"><span style="color:rgb(0,0,255)">12.2.1. Master</span></a></p>
<p><a target="_blank" href="#regionserver.arch" rel="nofollow"><span style="color:rgb(0,0,255)">12.2.2. RegionServer</span></a></p>
<p><a target="_blank" href="#regions.arch" rel="nofollow"><span style="color:rgb(0,0,255)">12.3. Regions</span></a></p>
<p><a target="_blank" href="#arch.regions.size" rel="nofollow"><span style="color:rgb(0,0,255)">12.3.1. Region大小</span></a></p>
<p><a target="_blank" href="#d613e3126" rel="nofollow"><span style="color:rgb(0,0,255)">12.3.2. Region Splits</span></a></p>
<p><a target="_blank" href="#d613e3133" rel="nofollow"><span style="color:rgb(0,0,255)">12.3.3. Region负载均衡</span></a></p>
<p><a target="_blank" href="#store" rel="nofollow"><span style="color:rgb(0,0,255)">12.3.4. Store</span></a></p>
<p><a target="_blank" href="#wal" rel="nofollow"><span style="color:rgb(0,0,255)">12.4. Write Ahead Log (WAL)</span></a></p>
<p><a target="_blank" href="#purpose.wal" rel="nofollow"><span style="color:rgb(0,0,255)">12.4.1. 目的</span></a></p>
<p><a target="_blank" href="#wal_flush" rel="nofollow"><span style="color:rgb(0,0,255)">12.4.2. WAL Flushing</span></a></p>
<p><a target="_blank" href="#wal_splitting" rel="nofollow"><span style="color:rgb(0,0,255)">12.4.3. WAL Splitting</span></a></p>
<p><a target="_blank" href="#performance" rel="nofollow"><span style="color:rgb(0,0,255)">13. 性能调优</span></a></p>
<p><a target="_blank" href="#jvm" rel="nofollow"><span style="color:rgb(0,0,255)">13.1. Java</span></a></p>
<p><a target="_blank" href="#gc" rel="nofollow"><span style="color:rgb(0,0,255)">13.1.1. 垃圾收集和HBase</span></a></p>
<p><a target="_blank" href="#perf.configurations" rel="nofollow"><span style="color:rgb(0,0,255)">13.2. 配置</span></a></p>
<p><a target="_blank" href="#perf.number.of.regions" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.1. Regions的数目</span></a></p>
<p><a target="_blank" href="#perf.compactions.and.splits" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.2. 管理压缩</span></a></p>
<p><a target="_blank" href="#perf.compression" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.3. 压缩</span></a></p>
<p><a target="_blank" href="#perf.handlers" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.4. hbase.regionserver.handler.count</span></a></p>
<p><a target="_blank" href="#perf.hfile.block.cache.size" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.5. hfile.block.cache.size</span></a></p>
<p><a target="_blank" href="#perf.rs.memstore.upperlimit" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.6. hbase.regionserver.global.memstore.upperLimit</span></a></p>
<p><a target="_blank" href="#perf.rs.memstore.lowerlimit" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.7. hbase.regionserver.global.memstore.lowerLimit</span></a></p>
<p><a target="_blank" href="#perf.hstore.blockingstorefiles" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.8. hbase.hstore.blockingStoreFiles</span></a></p>
<p><a target="_blank" href="#perf.hregion.memstore.block.multiplier" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.9. hbase.hregion.memstore.block.multiplier</span></a></p>
<p><a target="_blank" href="#perf.number.of.cfs" rel="nofollow"><span style="color:rgb(0,0,255)">13.3. Column Families的数目</span></a></p>
<p><a target="_blank" href="#perf.one.region" rel="nofollow"><span style="color:rgb(0,0,255)">13.4. 数据聚集</span></a></p>
<p><a target="_blank" href="#perf.batch.loading" rel="nofollow"><span style="color:rgb(0,0,255)">13.5. 批量Loading</span></a></p>
<p><a target="_blank" href="#precreate.regions" rel="nofollow"><span style="color:rgb(0,0,255)">13.5.1. Table创建: 预创建Regions </span></a></p>
<p><a target="_blank" href="#d613e3446" rel="nofollow"><span style="color:rgb(0,0,255)">13.6. HBase客户端</span></a></p>
<p><a target="_blank" href="#perf.hbase.client.autoflush" rel="nofollow"><span style="color:rgb(0,0,255)">13.6.1. AutoFlush</span></a></p>
<p><a target="_blank" href="#perf.hbase.client.caching" rel="nofollow"><span style="color:rgb(0,0,255)">13.6.2. Scan Caching</span></a></p>
<p><a target="_blank" href="#perf.hbase.client.selection" rel="nofollow"><span style="color:rgb(0,0,255)">13.6.3. Scan 属性选择</span></a></p>
<p><a target="_blank" href="#perf.hbase.client.scannerclose" rel="nofollow"><span style="color:rgb(0,0,255)">13.6.4. 关闭 ResultScanners</span></a></p>
<p><a target="_blank" href="#perf.hbase.client.blockcache" rel="nofollow"><span style="color:rgb(0,0,255)">13.6.5. 块缓存</span></a></p>
<p><a target="_blank" href="#perf.hbase.client.rowkeyonly" rel="nofollow"><span style="color:rgb(0,0,255)">13.6.6. Row Keys的负载优化</span></a></p>
<p><a target="_blank" href="#blooms" rel="nofollow"><span style="color:rgb(0,0,255)">14. Bloom Filters</span></a></p>
<p><a target="_blank" href="#bloom.config" rel="nofollow"><span style="color:rgb(0,0,255)">14.1. 配置</span></a></p>
<p><a target="_blank" href="#d613e3574" rel="nofollow"><span style="color:rgb(0,0,255)">14.1.1. HColumnDescriptor 配置</span></a></p>
<p><a target="_blank" href="#d613e3593" rel="nofollow"><span style="color:rgb(0,0,255)">14.1.2. io.hfile.bloom.enabled 全局关闭开关</span></a></p>
<p><a target="_blank" href="#d613e3609" rel="nofollow"><span style="color:rgb(0,0,255)">14.1.3. io.hfile.bloom.error.rate</span></a></p>
<p><a target="_blank" href="#d613e3617" rel="nofollow"><span style="color:rgb(0,0,255)">14.1.4. io.hfile.bloom.max.fold</span></a></p>
<p><a target="_blank" href="#bloom_footprint" rel="nofollow"><span style="color:rgb(0,0,255)">14.2. Bloom StoreFile footprint</span></a></p>
<p><a target="_blank" href="#d613e3645" rel="nofollow"><span style="color:rgb(0,0,255)">14.2.1. StoreFile中的BloomFilter， FileInfo数据结构</span></a></p>
<p><a target="_blank" href="#d613e3672" rel="nofollow"><span style="color:rgb(0,0,255)">14.2.2. 在 StoreFile 元数据中的BloomFilter entries</span></a></p>
<p><a target="_blank" href="#trouble" rel="nofollow"><span style="color:rgb(0,0,255)">15. Hbase的故障排除和Debug</span></a></p>
<p><a target="_blank" href="#trouble.general" rel="nofollow"><span style="color:rgb(0,0,255)">15.1. 一般准则</span></a></p>
<p><a target="_blank" href="#trouble.log" rel="nofollow"><span style="color:rgb(0,0,255)">15.2. Logs</span></a></p>
<p><a target="_blank" href="#trouble.log.locations" rel="nofollow"><span style="color:rgb(0,0,255)">15.2.1. Log 位置</span></a></p>
<p><a target="_blank" href="#trouble.tools" rel="nofollow"><span style="color:rgb(0,0,255)">15.3. 工具</span></a></p>
<p><a target="_blank" href="#trouble.tools.searchhadoop" rel="nofollow"><span style="color:rgb(0,0,255)">15.3.1. search-hadoop.com</span></a></p>
<p><a target="_blank" href="#trouble.tools.tail" rel="nofollow"><span style="color:rgb(0,0,255)">15.3.2. tail</span></a></p>
<p><a target="_blank" href="#trouble.tools.top" rel="nofollow"><span style="color:rgb(0,0,255)">15.3.3. top</span></a></p>
<p><a target="_blank" href="#trouble.tools.jps" rel="nofollow"><span style="color:rgb(0,0,255)">15.3.4. jps</span></a></p>
<p><a target="_blank" href="#trouble.tools.jstack" rel="nofollow"><span style="color:rgb(0,0,255)">15.3.5. jstack</span></a></p>
<p><a target="_blank" href="#trouble.tools.opentsdb" rel="nofollow"><span style="color:rgb(0,0,255)">15.3.6. OpenTSDB</span></a></p>
<p><a target="_blank" href="#trouble.tools.clustersshtop" rel="nofollow"><span style="color:rgb(0,0,255)">15.3.7. clusterssh+top</span></a></p>
<p><a target="_blank" href="#trouble.client" rel="nofollow"><span style="color:rgb(0,0,255)">15.4. 客户端</span></a></p>
<p><a target="_blank" href="#trouble.client.scantimeout" rel="nofollow"><span style="color:rgb(0,0,255)">15.4.1. ScannerTimeoutException</span></a></p>
<p><a target="_blank" href="#trouble.rs" rel="nofollow"><span style="color:rgb(0,0,255)">15.5. RegionServer</span></a></p>
<p><a target="_blank" href="#trouble.rs.startup" rel="nofollow"><span style="color:rgb(0,0,255)">15.5.1. 启动错误</span></a></p>
<p><a target="_blank" href="#trouble.rs.runtime" rel="nofollow"><span style="color:rgb(0,0,255)">15.5.2. 运行时错误</span></a></p>
<p><a target="_blank" href="#trouble.rs.shutdown" rel="nofollow"><span style="color:rgb(0,0,255)">15.5.3. 终止错误</span></a></p>
<p><a target="_blank" href="#trouble.master" rel="nofollow"><span style="color:rgb(0,0,255)">15.6. Master</span></a></p>
<p><a target="_blank" href="#trouble.master.startup" rel="nofollow"><span style="color:rgb(0,0,255)">15.6.1. 启动错误</span></a></p>
<p><a target="_blank" href="#trouble.master.startup" rel="nofollow"><span style="color:rgb(0,0,255)">15.6.2. 终止错误</span></a></p>
<p><a target="_blank" href="#tools" rel="nofollow"><span style="color:rgb(0,0,255)">A. 工具</span></a></p>
<p><a target="_blank" href="#hbck" rel="nofollow"><span style="color:rgb(0,0,255)">A.1. HBase hbck</span></a></p>
<p><a target="_blank" href="#d613e4032" rel="nofollow"><span style="color:rgb(0,0,255)">A.2. HFile 工具</span></a></p>
<p><a target="_blank" href="#wal_tools" rel="nofollow"><span style="color:rgb(0,0,255)">A.3. WAL Tools</span></a></p>
<p><a target="_blank" href="#hlog_tool" rel="nofollow"><span style="color:rgb(0,0,255)">A.3.1. HLog 工具</span></a></p>
<p><a target="_blank" href="#compression.tool" rel="nofollow"><span style="color:rgb(0,0,255)">A.4. 压缩工具</span></a></p>
<p><a target="_blank" href="#decommission" rel="nofollow"><span style="color:rgb(0,0,255)">A.5. Node下线</span></a></p>
<p><a target="_blank" href="#rolling" rel="nofollow"><span style="color:rgb(0,0,255)">A.5.1. 依次重启</span></a></p>
<p><a target="_blank" href="#compression" rel="nofollow"><span style="color:rgb(0,0,255)">B. HBase中的压缩</span></a></p>
<p><a target="_blank" href="#compression.test" rel="nofollow"><span style="color:rgb(0,0,255)">B.1. 测试压缩工具</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.codecs" rel="nofollow"><span style="color:rgb(0,0,255)">B.2. hbase.regionserver.codecs </span></a></p>
<p><a target="_blank" href="#lzo.compression" rel="nofollow"><span style="color:rgb(0,0,255)">B.3. LZO </span></a></p>
<p><a target="_blank" href="#gzip.compression" rel="nofollow"><span style="color:rgb(0,0,255)">B.4. GZIP </span></a></p>
<p><a target="_blank" href="#faq" rel="nofollow"><span style="color:rgb(0,0,255)">C. FAQ</span></a></p>
<p><a target="_blank" href="#d613e4393" rel="nofollow"><span style="color:rgb(0,0,255)">D. YCSB: 雅虎云服务 测试 和Hbase</span></a></p>
<p><a target="_blank" href="#book_index" rel="nofollow"><span style="color:rgb(0,0,255)">Index</span></a></p>
<p>List of Tables</p>
<p>11.1. <a target="_blank" href="#d613e2561" rel="nofollow"><span style="color:rgb(0,0,255)">表 webtable</span></a></p>
<p>11.2. <a target="_blank" href="#d613e2642" rel="nofollow"><span style="color:rgb(0,0,255)">ColumnFamily anchor</span></a></p>
<p>11.3. <a target="_blank" href="#d613e2681" rel="nofollow"><span style="color:rgb(0,0,255)">ColumnFamily contents</span></a></p>
<p><a target="_blank" name="preface"></a><span style="color:rgb(153,0,0)">序</span></p>
<p>这本书是 <a target="_blank" href="http://hbase.apache.org/" rel="nofollow"><span style="color:rgb(0,0,255)">HBase</span></a> 的官方指南。版本为 0.90.4.可以在Hbase官网上找到它。也可以在 <a target="_blank" href="http://hbase.apache.org/docs/current/api/index.html" rel="nofollow"><span style="color:rgb(0,0,255)">javadoc</span></a>, <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE" rel="nofollow"><span style="color:rgb(0,0,255)">JIRA</span></a> 和 <a target="_blank" href="http://wiki.apache.org/hadoop/Hbase" rel="nofollow"><span style="color:rgb(0,0,255)">wiki</span></a> 找到更多的资料。</p>
<p>此书正在编辑中。 可以向 HBase 官方提供补丁<a target="_blank" href="https://issues.apache.org/jira/browse/HBASE" rel="nofollow"><span style="color:rgb(0,0,255)">JIRA</span></a>.</p>
<p>这个版本系译者水平限制，没有理解清楚或不需要翻译的地方保留英文原文。</p>
<p><a target="_blank" name="headsup"></a><span style="color:rgb(153,0,0)">最前面的话</span></p>
<p>若这是你第一次踏入分布式计算的精彩世界，你会感到这是一个有趣的年代。分布式计算是很难的，做一个分布式系统需要很多软硬件和网络的技能。你的集群可以会因为各式各样的错误发生故障。比如Hbase本身的Bug,错误的配置(包括操作系统)，硬件的故障(网卡和磁盘甚至内存) 如果你一直在写单机程序的话，你需要重新开始学习。这里就是一个好的起点: <a target="_blank" href="http://en.wikipedia.org/wiki/Fallacies_of_Distributed_Computing" rel="nofollow"><span style="color:rgb(0,0,255)">分布式计算的谬论</span></a>.</p>
<p><a target="_blank" name="getting_started"></a><span style="color:rgb(153,0,0)">Chapter 1. 入门</span></p>
<p>Table of Contents</p>
<p><a target="_blank" href="#d613e75" rel="nofollow"><span style="color:rgb(0,0,255)">1.1. 介绍</span></a></p>
<p><a target="_blank" href="#quickstart" rel="nofollow"><span style="color:rgb(0,0,255)">1.2. 快速开始</span></a></p>
<p><a target="_blank" href="#d613e91" rel="nofollow"><span style="color:rgb(0,0,255)">1.2.1. 下载解压最新版本</span></a></p>
<p><a target="_blank" href="#start_hbase" rel="nofollow"><span style="color:rgb(0,0,255)">1.2.2. 启动 HBase</span></a></p>
<p><a target="_blank" href="#shell_exercises" rel="nofollow"><span style="color:rgb(0,0,255)">1.2.3. Shell 练习</span></a></p>
<p><a target="_blank" href="#stopping" rel="nofollow"><span style="color:rgb(0,0,255)">1.2.4. 停止 HBase</span></a></p>
<p><a target="_blank" href="#d613e242" rel="nofollow"><span style="color:rgb(0,0,255)">1.2.5. 下一步该做什么</span></a></p>
<p><a target="_blank" href="#notsoquick" rel="nofollow"><span style="color:rgb(0,0,255)">1.3. 慢速开始(相对快速开始)</span></a></p>
<p><a target="_blank" href="#requirements" rel="nofollow"><span style="color:rgb(0,0,255)">1.3.1. 需要的软件</span></a></p>
<p><a target="_blank" href="#standalone_dist" rel="nofollow"><span style="color:rgb(0,0,255)">1.3.2. HBase运行模式:单机和分布式</span></a></p>
<p><a target="_blank" href="#example_config" rel="nofollow"><span style="color:rgb(0,0,255)">1.3.3. 配置例子</span></a></p>
<p><a target="_blank" name="d613e75"></a><span style="color:rgb(153,0,0)">1.1. 介绍</span></p>
<p><a target="_blank" href="#quickstart" rel="nofollow" title="1.2. 快速开始"><span style="color:rgb(0,0,255)">Section 1.2, “快速开始”</span></a>会介绍如何运行一个单机版的Hbase.他运行在本地磁盘上。 <a target="_blank" href="#notsoquick" rel="nofollow" title="1.3. 慢速开始(相对快速开始)"><span style="color:rgb(0,0,255)">Section 1.3, “慢速开始(相对快速开始)”</span></a> 会介绍如何运行一个分布式的Hbase。他运行在HDFS上</p>
<p><a target="_blank" name="quickstart"></a><span style="color:rgb(153,0,0)">1.2. 快速开始</span></p>
<p>本指南介绍了在单机安装Hbase的方法。会引导你通过shell创建一个表，插入一行，然后删除它，最后停止Hbase。只要10分钟就可以完成以下的操作。</p>
<p><a target="_blank" name="d613e91"></a><span style="color:rgb(153,0,0)">1.2.1. 下载解压最新版本</span></p>
<p>选择一个 <a target="_blank" href="http://www.apache.org/dyn/closer.cgi/hbase/" rel="nofollow"><span style="color:rgb(0,0,255)">Apache 下载镜像</span></a>，下载 HBase Releases. 点击 <span style="color:rgb(0,122,0)">stable</span>目录，然后下载后缀为 <span style="color:rgb(0,122,0)">.tar.gz</span> 的文件; 例如 <span style="color:rgb(0,122,0)">hbase-0.90.4.tar.gz</span>.</p>
<p>解压缩，然后进入到那个要解压的目录.</p>
<p>$ tar xfz hbase-0.90.4.tar.gz</p>
<p>$ cd hbase-0.90.4</p>
<p>现在你已经可以启动Hbase了。但是你可能需要先编辑 <span style="color:rgb(0,122,0)">conf/hbase-site.xml</span> 去配置hbase.rootdir，来选择Hbase将数据写到哪个目录 .</p>
<p> </p>
<p>&lt;?xml version="1.0"?&gt;</p>
<p>&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</p>
<p>&lt;configuration&gt;</p>
<p>&lt;property&gt;</p>
<p>&lt;name&gt;hbase.rootdir&lt;/name&gt;</p>
<p>&lt;value&gt;file:///DIRECTORY/hbase&lt;/value&gt;</p>
<p>&lt;/property&gt;</p>
<p>&lt;/configuration&gt;</p>
<p> </p>
<p>将 DIRECTORY 替换成你期望写文件的目录. 默认 hbase.rootdir 是指向 <span style="color:rgb(0,122,0)">/tmp/hbase-${user.name}</span> ，也就说你会在重启后丢失数据(重启的时候操作系统会清理<span style="color:rgb(0,122,0)">/tmp</span>目录)</p>
<p><a target="_blank" name="start_hbase"></a><span style="color:rgb(153,0,0)">1.2.2. 启动 HBase</span></p>
<p>现在启动Hbase:</p>
<p>$ ./bin/start-hbase.sh</p>
<p>starting Master, logging to logs/hbase-user-master-example.org.out</p>
<p>现在你运行的是单机模式的Hbaes。所以的服务都运行在一个JVM上，包括Hbase和Zookeeper。Hbase的日志放在<span style="color:rgb(0,122,0)">logs</span>目录,当你启动出问题的时候，可以检查这个日志。</p>
<p><span style="color:rgb(153,0,0)">是否安装了 java ?</span></p>
<p>你需要确认安装了Oracle的1.6 版本的java.如果你在命令行键入java有反应说明你安装了Java。如果没有装，你需要先安装，然后编辑<span style="color:rgb(0,122,0)">conf/hbase-env.sh</span>，将其中的JAVA_HOME指向到你Java的安装目录。</p>
<p><a target="_blank" name="shell_exercises"></a><span style="color:rgb(153,0,0)">1.2.3. Shell 练习</span></p>
<p>用shell连接你的Hbase</p>
<p>$ ./bin/hbase shell</p>
<p>HBase Shell; enter 'help&lt;RETURN&gt;' for list of supported commands.</p>
<p>Type "exit&lt;RETURN&gt;" to leave the HBase Shell</p>
<p>Version: 0.90.0, r1001068, Fri Sep 24 13:55:42 PDT 2010</p>
<p> </p>
<p>hbase(main):001:0&gt;</p>
<p>输入 help 然后 &lt;RETURN&gt; 可以看到一列shell命令。这里的帮助很详细，要注意的是表名，行和列需要加引号。</p>
<p>创建一个名为 test 的表，这个表只有一个 column family 为 cf。可以列出所有的表来检查创建情况，然后插入些值。</p>
<p>hbase(main):003:0&gt; create 'test', 'cf'</p>
<p>0 row(s) in 1.2200 seconds</p>
<p>hbase(main):003:0&gt; list 'table'</p>
<p>test</p>
<p>1 row(s) in 0.0550 seconds</p>
<p>hbase(main):004:0&gt; put 'test', 'row1', 'cf:a', 'value1'</p>
<p>0 row(s) in 0.0560 seconds</p>
<p>hbase(main):005:0&gt; put 'test', 'row2', 'cf:b', 'value2'</p>
<p>0 row(s) in 0.0370 seconds</p>
<p>hbase(main):006:0&gt; put 'test', 'row3', 'cf:c', 'value3'</p>
<p>0 row(s) in 0.0450 seconds</p>
<p>以上我们分别插入了3行。第一个行key为row1, 列为 cf:a， 值是 value1。Hbase中的列是由 column family前缀和列的名字组成的，以冒号间隔。例如这一行的列名就是a.</p>
<p>检查插入情况.</p>
<p>Scan这个表，操作如下</p>
<p>hbase(main):007:0&gt; scan 'test'</p>
<p>ROW        COLUMN+CELL</p>
<p>row1       column=cf:a, timestamp=1288380727188, value=value1</p>
<p>row2       column=cf:b, timestamp=1288380738440, value=value2</p>
<p>row3       column=cf:c, timestamp=1288380747365, value=value3</p>
<p>3 row(s) in 0.0590 seconds</p>
<p>Get一行，操作如下</p>
<p>hbase(main):008:0&gt; get 'test', 'row1'</p>
<p>COLUMN      CELL</p>
<p>cf:a        timestamp=1288380727188, value=value1</p>
<p>1 row(s) in 0.0400 seconds</p>
<p>disable 再 drop 这张表，可以清除你刚刚的操作</p>
<p>hbase(main):012:0&gt; disable 'test'</p>
<p>0 row(s) in 1.0930 seconds</p>
<p>hbase(main):013:0&gt; drop 'test'</p>
<p>0 row(s) in 0.0770 seconds</p>
<p>关闭shell</p>
<p>hbase(main):014:0&gt; exit</p>
<p><a target="_blank" name="stopping"></a><span style="color:rgb(153,0,0)">1.2.4. 停止 HBase</span></p>
<p>运行停止脚本来停止HBase.</p>
<p>$ ./bin/stop-hbase.sh</p>
<p>stopping hbase...............</p>
<p><a target="_blank" name="d613e242"></a><span style="color:rgb(153,0,0)">1.2.5. 下一步该做什么</span></p>
<p>以上步骤仅仅适用于实验和测试。接下来你可以看 <a target="_blank" href="#notsoquick" rel="nofollow" title="1.3. 慢速开始(相对快速开始)"><span style="color:rgb(0,0,255)">Section 1.3, “慢速开始(相对快速开始)”</span></a> ，我们会介绍不同的Hbase运行模式，运行分布式Hbase中需要的软件 和如何配置。</p>
<p><a target="_blank" name="notsoquick"></a><span style="color:rgb(153,0,0)">1.3. 慢速开始(相对快速开始)</span></p>
<p><a target="_blank" name="requirements"></a><span style="color:rgb(153,0,0)">1.3.1. 需要的软件</span></p>
<p>Hbase有如下需要，请仔细阅读本章节以确保所有的需要都被满足。如果需求没有能满足，就有可能遇到莫名其妙的错误甚至丢失数据。</p>
<p><a target="_blank" name="java"></a><span style="color:rgb(153,0,0)">1.3.1.1. java</span></p>
<p>和Hadoop一样，Hbase需要Oracle版本的<a target="_blank" href="http://www.java.com/download/" rel="nofollow"><span style="color:rgb(0,0,255)">Java6</span></a>.除了那个有问题的u18版本其他的都可以用，最好用最新的。</p>
<p><a target="_blank" name="hadoop"></a><span style="color:rgb(153,0,0)">1.3.1.2. </span><a target="_blank" href="http://hadoop.apache.org/" rel="nofollow"><span style="color:rgb(0,0,255)">hadoop</span></a><a target="_blank" name="d613e269"></a></p>
<p>该版本的Hbase只可以运行在<a target="_blank" href="http://hadoop.apache.org/common/releases.html" rel="nofollow"><span style="color:rgb(0,0,255)">Hadoop 0.20.x</span></a>，不可以运行于hadoop 0.21.x (0.22.x也不行). HBase运行在没有持久同步功能的HDFS上会丢失数据。 Hadoop 0.20.2 和 Hadoop 0.20.203.0就没有这个功能。现在只有 <a target="_blank" href="http://svn.apache.org/viewvc/hadoop/common/branches/branch-0.20-append/" rel="nofollow"><span style="color:rgb(0,0,255)">branch-0.20-append</span></a> 补丁有这个功能[<a target="_blank" name="d613e280"></a><a target="_blank" href="#ftn.d613e280" rel="nofollow"><span style="color:rgb(0,0,255)">1</span></a>]. 现在官方的发行版都没有这个功能，所以你要自己打这个补丁。推荐看 Michael Noll 写的详细的说明, <a target="_blank" href="http://www.michael-noll.com/blog/2011/04/14/building-an-hadoop-0-20-x-version-for-hbase-0-90-2/" rel="nofollow"><span style="color:rgb(0,0,255)">Building an Hadoop 0.20.x version for HBase 0.90.2</span></a>.</p>
<p>你还可以用 Cloudera's <a target="_blank" href="http://archive.cloudera.com/docs/" rel="nofollow"><span style="color:rgb(0,0,255)">CDH3</span></a>. CDH 打了这个补丁 (CDH3 betas 就可以满足; b2, b3, or b4).</p>
<p>因为Hbase建立在Hadoop之上，所以他用到了hadoop.jar,这个Jar在 <span style="color:rgb(0,122,0)">lib</span> 里面。这个jar是hbase自己打了branch-0.20-append 补丁的hadoop.jar. Hadoop使用的hadoop.jar和Hbase使用的 必须 一致。所以你需要将 Hbase <span style="color:rgb(0,122,0)">lib</span> 目录下的hadoop.jar替换成Hadoop里面的那个，防止版本冲突。比方说CDH的版本没有HDFS-724而branch-0.20-append里面有，这个HDFS-724补丁修改了RPC协议。如果不替换，就会有版本冲突，继而造成严重的出错，Hadoop会看起来挂了。</p>
<p><span style="color:rgb(153,0,0)">我可以用Hbase里面的支持</span><span style="color:rgb(153,0,0)">sync</span><span style="color:rgb(153,0,0)">的hadoop.jar替代Hadoop里面的那个吗?</span></p>
<p>你可以这么干。详细可以参见这个<a target="_blank" href="http://www.apacheserver.net/Using-Hadoop-bundled-in-lib-directory-HBase-at1136240.htm" rel="nofollow"><span style="color:rgb(0,0,255)">邮件列表</span></a>.</p>
<p><span style="color:rgb(153,0,0)">Hadoop 安全性</span></p>
<p>HBase运行在Hadoop 0.20.x上，就可以使用其中的安全特性 -- 只要你用这两个版本0.20S 和CDH3B3，然后把hadoop.jar替换掉就可以了.</p>
<p><a target="_blank" name="ssh"></a><span style="color:rgb(153,0,0)">1.3.1.3. ssh</span></p>
<p>必须安装ssh ， sshd 也必须运行，这样Hadoop的脚本才可以远程操控其他的Hadoop和Hbase进程。ssh之间必须都打通，不用密码都可以登录，详细方法可以Google一下 ("ssh passwordless login").</p>
<p><a target="_blank" name="dns"></a><span style="color:rgb(153,0,0)">1.3.1.4. DNS</span></p>
<p>HBase使用本地 hostname 才获得IP地址. 正反向的DNS都是可以的.</p>
<p>如果你的机器有多个接口，Hbase会使用hostname指向的主接口.</p>
<p>如果还不够，你可以设置 hbase.regionserver.dns.interface 来指定主接口。当然你的整个集群的配置文件都必须一致，每个主机都使用相同的网络接口</p>
<p>还有一种方法是设置 hbase.regionserver.dns.nameserver来指定nameserver，不使用系统带的.</p>
<p><a target="_blank" name="ntp"></a><span style="color:rgb(153,0,0)">1.3.1.5. NTP</span></p>
<p>集群的时钟要保证基本的一致。稍有不一致是可以容忍的，但是很大的不一致会造成奇怪的行为。 运行 <a target="_blank" href="http://en.wikipedia.org/wiki/Network_Time_Protocol" rel="nofollow"><span style="color:rgb(0,0,255)">NTP</span></a> 或者其他什么东西来同步你的时间.</p>
<p>如果你查询的时候或者是遇到奇怪的故障，可以检查一下系统时间是否正确!</p>
<p><a target="_blank" name="ulimit"></a><span style="color:rgb(153,0,0)">1.3.1.6.  ulimit<a target="_blank" name="d613e365"></a> 和 nproc<a target="_blank" name="d613e371"></a></span></p>
<p>HBase是数据库，会在同一时间使用很多的文件句柄。大多数linux系统使用的默认值1024是不能满足的，会导致<a target="_blank" href="#A6" rel="nofollow"><span style="color:rgb(0,0,255)">FAQ: Why do I see "java.io.IOException...(Too many open files)" in my logs?</span></a>异常。还可能会发生这样的异常</p>
<p>2010-04-06 03:04:37,542 INFO org.apache.hadoop.hdfs.DFSClient: Exception increateBlockOutputStream java.io.EOFException</p>
<p>2010-04-06 03:04:37,542 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-6935524980745310745_1391901</p>
<p> </p>
<p>所以你需要修改你的最大文件句柄限制。可以设置到10k. 你还需要修改 hbase 用户的 nproc，如果过低会造成 OutOfMemoryError异常。 [<a target="_blank" name="d613e389"></a><a target="_blank" href="#ftn.d613e389" rel="nofollow"><span style="color:rgb(0,0,255)">2</span></a>] [<a target="_blank" name="d613e396"></a><a target="_blank" href="#ftn.d613e396" rel="nofollow"><span style="color:rgb(0,0,255)">3</span></a>].</p>
<p>需要澄清的，这两个设置是针对操作系统的，不是Hbase本身的。有一个常见的错误是Hbase运行的用户，和设置最大值的用户不是一个用户。在Hbase启动的时候，第一行日志会现在ulimit信息，所以你最好检查一下。 [<a target="_blank" name="d613e408"></a><a target="_blank" href="#ftn.d613e408" rel="nofollow"><span style="color:rgb(0,0,255)">4</span></a>]</p>
<p><a target="_blank" name="ulimit_ubuntu"></a><span style="color:rgb(153,0,0)">1.3.1.6.1. 在Ubuntu上设置</span><span style="color:rgb(153,0,0)">ulimit</span></p>
<p>如果你使用的是Ubuntu,你可以这样设置:</p>
<p>在文件 <span style="color:rgb(0,122,0)">/etc/security/limits.conf</span> 添加一行，如:</p>
<p>hadoop  -       nofile  32768</p>
<p>可以把 hadoop 替换成你运行Hbase和Hadoop的用户。如果你用两个用户，你就需要配两个。还有配nproc hard 和 soft limits. 如:</p>
<p>hadoop soft/hard nproc 32000</p>
<p>.</p>
<p>在 <span style="color:rgb(0,122,0)">/etc/pam.d/common-session</span> 加上这一行:</p>
<p>session required  pam_limits.so</p>
<p>否则在 <span style="color:rgb(0,122,0)">/etc/security/limits.conf</span>上的配置不会生效.</p>
<p>还有注销再登录，这些配置才能生效!</p>
<p><a target="_blank" name="dfs.datanode.max.xcievers"></a><span style="color:rgb(153,0,0)">1.3.1.7. dfs.datanode.max.xcievers<a target="_blank" name="d613e451"></a></span></p>
<p>一个 Hadoop HDFS Datanode 有一个同时处理文件的上限. 这个参数叫 xcievers (Hadoop的作者把这个单词拼错了). 在你加载之前，先确认下你有没有配置这个文件<span style="color:rgb(0,122,0)">conf/hdfs-site.xml</span>里面的xceivers参数，至少要有4096:</p>
<p>&lt;property&gt;</p>
<p>&lt;name&gt;dfs.datanode.max.xcievers&lt;/name&gt;</p>
<p>&lt;value&gt;4096&lt;/value&gt;</p>
<p>&lt;/property&gt;</p>
<p> </p>
<p>对于HDFS修改配置要记得重启.</p>
<p>如果没有这一项配置，你可能会遇到奇怪的失败。你会在Datanode的日志中看到xcievers exceeded，但是运行起来会报 missing blocks错误。例如: 10/12/08 20:10:31 INFO hdfs.DFSClient: Could not obtain block blk_XXXXXXXXXXXXXXXXXXXXXX_YYYYYYYY from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry... [<a target="_blank" name="d613e474"></a><a target="_blank" href="#ftn.d613e474" rel="nofollow"><span style="color:rgb(0,0,255)">5</span></a>]</p>
<p><a target="_blank" name="windows"></a><span style="color:rgb(153,0,0)">1.3.1.8. Windows</span></p>
<p>HBase没有怎么在Windows下测试过。所以不推荐在Windows下运行.</p>
<p>如果你实在是想运行，需要安装<a target="_blank" href="http://cygwin.com/" rel="nofollow"><span style="color:rgb(0,0,255)">Cygwin</span></a> 还虚拟一个unix环境.详情请看 <a target="_blank" href="http://hbase.apache.org/cygwin.html" rel="nofollow"><span style="color:rgb(0,0,255)">Windows 安装指导</span></a> . 或者 <a target="_blank" href="http://search-hadoop.com/?q=hbase+windows&amp;fc_project=HBase&amp;fc_type=mail+_hash_+dev" rel="nofollow"><span style="color:rgb(0,0,255)">搜索邮件列表</span></a>找找最近的关于windows的注意点</p>
<p><a target="_blank" name="standalone_dist"></a><span style="color:rgb(153,0,0)">1.3.2. HBase运行模式:单机和分布式</span></p>
<p>HBase有两个运行模式: <a target="_blank" href="#standalone" rel="nofollow" title="1.3.2.1. 单机模式"><span style="color:rgb(0,0,255)">Section 1.3.2.1, “单机模式”</span></a> 和 <a target="_blank" href="#distributed" rel="nofollow" title="1.3.2.2. 分布式模式"><span style="color:rgb(0,0,255)">Section 1.3.2.2, “分布式模式”</span></a>. 默认是单机模式，如果要分布式模式你需要编辑 <span style="color:rgb(0,122,0)">conf</span> 文件夹中的配置文件.</p>
<p>不管是什么模式，你都需要编辑 conf/hbase-env.sh来告知Hbase java的安装路径.在这个文件里你还可以设置Hbase的运行环境，诸如 heapsize和其他 JVM有关的选项, 还有Log文件地址，等等. 设置 JAVA_HOME指向 java安装的路径.</p>
<p><a target="_blank" name="standalone"></a><span style="color:rgb(153,0,0)">1.3.2.1. 单机模式</span></p>
<p>这是默认的模式，在 <a target="_blank" href="#quickstart" rel="nofollow" title="1.2. 快速开始"><span style="color:rgb(0,0,255)">Section 1.2, “快速开始”</span></a> 一章中介绍的就是这个模式. 在单机模式中，Hbase使用本地文件系统，而不是HDFS ，所以的服务和zooKeeper都运作在一个JVM中。zookeep监听一个端口，这样客户端就可以连接Hbase了。</p>
<p><a target="_blank" name="distributed"></a><span style="color:rgb(153,0,0)">1.3.2.2. 分布式模式</span></p>
<p>分布式模式分两种。伪分布式模式是把进程运行在一台机器上，但不是一个JVM.而完全分布式模式就是把整个服务被分布在各个节点上了 [<a target="_blank" name="d613e543"></a><a target="_blank" href="#ftn.d613e543" rel="nofollow"><span style="color:rgb(0,0,255)">6</span></a>].</p>
<p>分布式模式需要使用 Hadoop Distributed File System (HDFS).可以参见 <a target="_blank" href="#overview_description" rel="nofollow"><span style="color:rgb(0,0,255)">HDFS需求和指导</span></a>来获得关于安装HDFS的指导。在操作Hbase之前，你要确认HDFS可以正常运作。</p>
<p>在我们安装之后，你需要确认你的伪分布式模式或者 完全分布式模式的配置是否正确。这两个模式可以使用同一个验证脚本<a target="_blank" href="#confirm" rel="nofollow" title="1.3.2.3. 运行和确认你的安装"><span style="color:rgb(0,0,255)">Section 1.3.2.3, “运行和确认你的安装”</span></a>。</p>
<p><a target="_blank" name="pseudo"></a><span style="color:rgb(153,0,0)">1.3.2.2.1. 伪分布式模式</span></p>
<p>伪分布式模式是一个相对简单的分布式模式。这个模式是用来测试的。不能把这个模式用于生产环节，也不能用于测试性能。</p>
<p>你确认HDFS安装成功之后，就可以先编辑 <span style="color:rgb(0,122,0)">conf/hbase-site.xml</span>。在这个文件你可以加入自己的配置，这个配置会覆盖 <a target="_blank" href="#hbase_default_configurations" rel="nofollow" title="3.1.1. HBase 默认配置"><span style="color:rgb(0,0,255)">Section 3.1.1, “HBase 默认配置”</span></a> and <a target="_blank" href="#hdfs_client_conf" rel="nofollow" title="1.3.2.2.2.3. HDFS客户端配置"><span style="color:rgb(0,0,255)">Section 1.3.2.2.2.3, “HDFS客户端配置”</span></a>. 运行Hbase需要设置hbase.rootdir 属性.该属性是指Hbase在HDFS中使用的目录的位置。例如，要想 <span style="color:rgb(0,122,0)">/hbase</span> 目录，让namenode 监听locahost的9000端口，只有一份数据拷贝(HDFS默认是3份拷贝)。可以在 <span style="color:rgb(0,122,0)">hbase-site.xml</span> 写上如下内容</p>
<p>&lt;configuration&gt;</p>
<p>...</p>
<p>&lt;property&gt;</p>
<p>&lt;name&gt;hbase.rootdir&lt;/name&gt;</p>
<p>&lt;value&gt;hdfs://localhost:9000/hbase&lt;/value&gt;</p>
<p>&lt;description&gt;The directory shared by RegionServers.</p>
<p>&lt;/description&gt;</p>
<p>&lt;/property&gt;</p>
<p>&lt;property&gt;</p>
<p>&lt;name&gt;dfs.replication&lt;/name&gt;</p>
<p>&lt;value&gt;1&lt;/value&gt;</p>
<p>&lt;description&gt;The replication count for HLog &amp; HFile storage. Should not be greater than HDFS datanode count.</p>
<p>&lt;/description&gt;</p>
<p>&lt;/property&gt;</p>
<p>...</p>
<p>&lt;/configuration&gt;</p>
<p><span style="color:rgb(153,0,0)">Note</span></p>
<p>让Hbase自己创建 hbase.rootdir 目录，如果你自己建这个目录，会有一个warning，Hbase会试图在里面进行migration操作，但是缺少必须的文件。</p>
<p><span style="color:rgb(153,0,0)">Note</span></p>
<p>上面我们绑定到 localhost. 也就是说除了本机，其他机器连不上Hbase。所以你需要设置成别的，才能使用它。</p>
<p>现在可以跳到 <a target="_blank" href="#confirm" rel="nofollow" title="1.3.2.3. 运行和确认你的安装"><span style="color:rgb(0,0,255)">Section 1.3.2.3, “运行和确认你的安装”</span></a> 来运行和确认你的伪分布式模式安装了。 [<a target="_blank" name="d613e606"></a><a target="_blank" href="#ftn.d613e606" rel="nofollow"><span style="color:rgb(0,0,255)">7</span></a>]</p>
<p><a target="_blank" name="fully_dist"></a><span style="color:rgb(153,0,0)">1.3.2.2.2. 完全分布式模式</span></p>
<p>要想运行完全分布式模式，你要进行如下配置，先在 <span style="color:rgb(0,122,0)">hbase-site.xml</span>, 加一个属性 hbase.cluster.distributed 设置为 true 然后把 hbase.rootdir 设置为HDFS的NameNode的位置。例如，你的namenode运行在namenode.example.org，端口是9000 你期望的目录是 <span style="color:rgb(0,122,0)">/hbase</span>,使用如下的配置</p>
<p>&lt;configuration&gt;</p>
<p>...</p>
<p>&lt;property&gt;</p>
<p>&lt;name&gt;hbase.rootdir&lt;/name&gt;</p>
<p>&lt;value&gt;hdfs://namenode.example.org:9000/hbase&lt;/value&gt;</p>
<p>&lt;description&gt;The directory shared by RegionServers.</p>
<p>&lt;/description&gt;</p>
<p>&lt;/property&gt;</p>
<p>&lt;property&gt;</p>
<p>&lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</p>
<p>&lt;value&gt;true&lt;/value&gt;</p>
<p>&lt;description&gt;The mode the cluster will be in. Possible values are</p>
<p>false: standalone and pseudo-distributed setups with managed Zookeeper</p>
<p>true: fully-distributed with unmanaged Zookeeper Quorum (see hbase-env.sh)</p>
<p>&lt;/description&gt;</p>
<p>&lt;/property&gt;</p>
<p>...</p>
<p>&lt;/configuration&gt;</p>
<p><a target="_blank" name="regionserver"></a><span style="color:rgb(153,0,0)">1.3.2.2.2.1. </span><span style="color:rgb(0,122,0)">regionservers</span></p>
<p>完全分布式模式的还需要修改<span style="color:rgb(0,122,0)">conf/regionservers</span>. 在 <a target="_blank" href="#regionservers" rel="nofollow" title="1.3.3.1.2. regionservers"><span style="color:rgb(0,0,255)">Section 1.3.3.1.2, “</span><span style="color:rgb(0,122,0)">regionservers</span><span style="color:rgb(0,0,255)">”</span></a> 列出了你希望运行的全部 HRegionServer，一行写一个host (就像Hadoop里面的 <span style="color:rgb(0,122,0)">slaves</span> 一样). 列在这里的server会随着集群的启动而启动，集群的停止而停止.</p>
<p><a target="_blank" name="zookeeper"></a><span style="color:rgb(153,0,0)">1.3.2.2.2.2. ZooKeeper<a target="_blank" name="d613e654"></a></span></p>
<p>一个分布式运行的Hbase依赖一个zookeeper集群。所有的节点和客户端都必须能够访问zookeeper。默认的情况下Hbase会管理一个zookeep集群。这个集群会随着Hbase的启动而启动。当然，你也可以自己管理一个zookeeper集群，但需要配置Hbase。你需要修改<span style="color:rgb(0,122,0)">conf/hbase-env.sh</span>里面的HBASE_MANAGES_ZK 来切换。这个值默认是true的，作用是让Hbase启动的时候同时也启动zookeeper.</p>
<p>当Hbase管理zookeeper的时候，你可以通过修改<span style="color:rgb(0,122,0)">zoo.cfg</span>来配置zookeeper，一个更加简单的方法是在 <span style="color:rgb(0,122,0)">conf/hbase-site.xml</span>里面修改zookeeper的配置。Zookeep的配置是作为property写在 <span style="color:rgb(0,122,0)">hbase-site.xml</span>里面的。option的名字是 hbase.zookeeper.property. 打个比方， clientPort 配置在xml里面的名字是 hbase.zookeeper.property.clientPort. 所有的默认值都是Hbase决定的，包括zookeeper, 参见 <a target="_blank" href="#hbase_default_configurations" rel="nofollow" title="3.1.1. HBase 默认配置"><span style="color:rgb(0,0,255)">Section 3.1.1, “HBase 默认配置”</span></a>. 可以查找 hbase.zookeeper.property 前缀，找到关于zookeeper的配置。 [<a target="_blank" name="d613e690"></a><a target="_blank" href="#ftn.d613e690" rel="nofollow"><span style="color:rgb(0,0,255)">8</span></a>]</p>
<p>对于zookeepr的配置，你至少要在 <span style="color:rgb(0,122,0)">hbase-site.xml</span>中列出zookeepr的ensemble servers，具体的字段是 hbase.zookeeper.quorum. 该这个字段的默认值是 localhost，这个值对于分布式应用显然是不可以的. (远程连接无法使用).</p>
<p><a target="_blank" name="how_many_zks"></a><span style="color:rgb(153,0,0)">我需要运行几个zookeeper?</span></p>
<p>你运行一个zookeeper也是可以的，但是在生产环境中，你最好部署3，5，7个节点。部署的越多，可靠性就越高，当然只能部署奇数个，偶数个是不可以的。你需要给每个zookeeper 1G左右的内存，如果可能的话，最好有独立的磁盘。 (独立磁盘可以确保zookeeper是高性能的。).如果你的集群负载很重，不要把Zookeeper和RegionServer运行在同一台机器上面。就像DataNodes 和 TaskTrackers一样</p>
<p>打个比方，Hbase管理着的ZooKeeper集群在节点 rs{1,2,3,4,5}.example.com, 监听2222 端口(默认是2181)，并确保<span style="color:rgb(0,122,0)">conf/hbase-env.sh</span>文件中 HBASE_MANAGE_ZK的值是 true ，再编辑 <span style="color:rgb(0,122,0)">conf/hbase-site.xml</span> 设置 hbase.zookeeper.property.clientPort 和 hbase.zookeeper.quorum。你还可以设置 hbase.zookeeper.property.dataDir属性来把ZooKeeper保存数据的目录地址改掉。默认值是 <span style="color:rgb(0,122,0)">/tmp</span> ，这里在重启的时候会被操作系统删掉，可以把它修改到 <span style="color:rgb(0,122,0)">/user/local/zookeeper</span>.</p>
<p>&lt;configuration&gt;</p>
<p>...</p>
<p>&lt;property&gt;</p>
<p>&lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;</p>
<p>&lt;value&gt;2222&lt;/value&gt;</p>
<p>&lt;description&gt;Property from ZooKeeper's config zoo.cfg.</p>
<p>The port at which the clients will connect.</p>
<p>&lt;/description&gt;</p>
<p>&lt;/property&gt;</p>
<p>&lt;property&gt;</p>
<p>&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</p>
<p>&lt;value&gt;rs1.example.com,rs2.example.com,rs3.example.com,rs4.example.com,rs5.example.com&lt;/value&gt;</p>
<p>&lt;description&gt;Comma separated list of servers in the ZooKeeper Quorum.</p>
<p>For example, "host1.mydomain.com,host2.mydomain.com,host3.mydomain.com".</p>
<p>By default this is set to localhost for local and pseudo-distributed modes</p>
<p>of operation. For a fully-distributed setup, this should be set to a full</p>
<p>list of ZooKeeper quorum servers. If HBASE_MANAGES_ZK is set in hbase-env.sh</p>
<p>this is the list of servers which we will start/stop ZooKeeper on.</p>
<p>&lt;/description&gt;</p>
<p>&lt;/property&gt;</p>
<p>&lt;property&gt;</p>
<p>&lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;</p>
<p>&lt;value&gt;/usr/local/zookeeper&lt;/value&gt;</p>
<p>&lt;description&gt;Property from ZooKeeper's config zoo.cfg.</p>
<p>The directory where the snapshot is stored.</p>
<p>&lt;/description&gt;</p>
<p>&lt;/property&gt;</p>
<p>...</p>
<p>&lt;/configuration&gt;</p>
<p><a target="_blank" name="d613e752"></a><span style="color:rgb(153,0,0)">1.3.2.2.2.2.1. 使用现有的ZooKeeper例子</span></p>
<p>让Hbase使用一个现有的不被Hbase托管的Zookeep集群，需要设置 <span style="color:rgb(0,122,0)">conf/hbase-env.sh</span>文件中的HBASE_MANAGES_ZK 属性为 false</p>
<p>...</p>
<p># Tell HBase whether it should manage it's own instance of Zookeeper or not.</p>
<p>export HBASE_MANAGES_ZK=false</p>
<p>接下来，指明Zookeeper的host和端口。可以在 <span style="color:rgb(0,122,0)">hbase-site.xml</span>中设置, 也可以在Hbase的<span style="color:rgb(0,122,0)">CLASSPATH</span>下面加一个<span style="color:rgb(0,122,0)">zoo.cfg</span>配置文件。 HBase 会优先加载 <span style="color:rgb(0,122,0)">zoo.cfg</span> 里面的配置，把<span style="color:rgb(0,122,0)">hbase-site.xml</span>里面的覆盖掉.</p>
<p>当Hbase托管ZooKeeper的时候，Zookeeper集群的启动是Hbase启动脚本的一部分。但现在，你需要自己去运行。你可以这样做</p>
<p>${HBASE_HOME}/bin/hbase-daemons.sh {start,stop} zookeeper</p>
<p>你可以用这条命令启动ZooKeeper而不启动Hbase. HBASE_MANAGES_ZK 的值是 false，如果你想在Hbase重启的时候不重启ZooKeeper,你可以这样做</p>
<p>对于独立Zoopkeeper的问题，你可以在 <a target="_blank" href="http://hadoop.apache.org/zookeeper/docs/current/zookeeperStarted.html" rel="nofollow"><span style="color:rgb(0,0,255)">Zookeeper启动</span></a>得到帮助.</p>
<p><a target="_blank" name="hdfs_client_conf"></a><span style="color:rgb(153,0,0)">1.3.2.2.2.3. HDFS客户端配置</span></p>
<p>如果你希望Hadoop集群上做HDFS 客户端配置 ，例如你的HDFS客户端的配置和服务端的不一样。按照如下的方法配置，HBase就能看到你的配置信息:</p>
<p>· 在<span style="color:rgb(0,122,0)">hbase-env.sh</span>里将HBASE_CLASSPATH环境变量加上HADOOP_CONF_DIR 。</p>
<p>· 在<span style="color:rgb(0,122,0)">${HBASE_HOME}/conf</span>下面加一个 <span style="color:rgb(0,122,0)">hdfs-site.xml</span> (或者 <span style="color:rgb(0,122,0)">hadoop-site.xml</span>) ，最好是软连接</p>
<p>· 如果你的HDFS客户端的配置不多的话，你可以把这些加到 <span style="color:rgb(0,122,0)">hbase-site.xml</span>上面.</p>
<p>例如HDFS的配置 dfs.replication.你希望复制5份，而不是默认的3份。如果你不照上面的做的话，Hbase只会复制3份。</p>
<p><a target="_blank" name="confirm"></a><span style="color:rgb(153,0,0)">1.3.2.3. 运行和确认你的安装</span></p>
<p>首先确认你的HDFS是运行着的。你可以运行HADOOP_HOME中的 <span style="color:rgb(0,122,0)">bin/start-hdfs.sh</span> 来启动HDFS.你可以通过put命令来测试放一个文件，然后有get命令来读这个文件。通常情况下Hbase是不会运行mapreduce的。所以比不需要检查这些。</p>
<p>如果你自己管理ZooKeeper集群，你需要确认它是运行着的。如果是Hbase托管，ZoopKeeper会随Hbase启动。</p>
<p>用如下命令启动Hbase:</p>
<p>bin/start-hbase.sh</p>
<p>这个脚本在HBASE_HOME目录里面。</p>
<p>你现在已经启动Hbase了。Hbase把log记在 <span style="color:rgb(0,122,0)">logs</span> 子目录里面. 当Hbase启动出问题的时候，可以看看Log.</p>
<p>Hbase也有一个界面，上面会列出重要的属性。默认是在Master的60010端口上H (HBase RegionServers 会默认绑定 60020端口，在端口60030上有一个展示信息的界面 ).如果Master运行在 master.example.org，端口是默认的话，你可以用浏览器在 <span style="color:rgb(0,122,0)">http://master.example.org:60010</span>看到主界面. .</p>
<p>一旦Hbase启动，参见<a target="_blank" href="#shell_exercises" rel="nofollow" title="1.2.3. Shell 练习"><span style="color:rgb(0,0,255)">Section 1.2.3, “Shell 练习”</span></a>可以看到如何建表，插入数据，scan你的表，还有disable这个表，最后把它删掉。</p>
<p>可以在Hbase Shell停止Hbase</p>
<p>$ ./bin/stop-hbase.sh</p>
<p>stopping hbase...............</p>
<p>停止操作需要一些时间，你的集群越大，停的时间可能会越长。如果你正在运行一个分布式的操作，要确认在Hbase彻底停止之前，Hadoop不能停.</p>
<p><a target="_blank" name="example_config"></a><span style="color:rgb(153,0,0)">1.3.3. 配置例子</span></p>
<p><a target="_blank" name="d613e896"></a><span style="color:rgb(153,0,0)">1.3.3.1. 简单的分布式Hbase安装</span></p>
<p>这里是一个10节点的Hbase的简单示例，这里的配置都是基本的，节点名为 example0, example1... 一直到 example9 . HBase Master 和 HDFS namenode 运作在同一个节点 example0上. RegionServers 运行在节点 example1-example9. 一个 3-节点 ZooKeeper 集群运行在example1, example2, 和 example3，端口保持默认. ZooKeeper 的数据保存在目录 <span style="color:rgb(0,122,0)">/export/zookeeper</span>. 下面我们展示主要的配置文件-- <span style="color:rgb(0,122,0)">hbase-site.xml</span>, <span style="color:rgb(0,122,0)">regionservers</span>, 和 <span style="color:rgb(0,122,0)">hbase-env.sh</span> -- 这些文件可以在 <span style="color:rgb(0,122,0)">conf</span>目录找到.</p>
<p><a target="_blank" name="hbase_site"></a><span style="color:rgb(153,0,0)">1.3.3.1.1. </span><span style="color:rgb(0,122,0)">hbase-site.xml</span></p>
<p> </p>
<p>&lt;?xml version="1.0"?&gt;</p>
<p>&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</p>
<p>&lt;configuration&gt;</p>
<p>&lt;property&gt;</p>
<p>&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</p>
<p>&lt;value&gt;example1,example2,example3&lt;/value&gt;</p>
<p>&lt;description&gt;The directory shared by RegionServers.</p>
<p>&lt;/description&gt;</p>
<p>&lt;/property&gt;</p>
<p>&lt;property&gt;</p>
<p>&lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;</p>
<p>&lt;value&gt;/export/zookeeper&lt;/value&gt;</p>
<p>&lt;description&gt;Property from ZooKeeper's config zoo.cfg.</p>
<p>The directory where the snapshot is stored.</p>
<p>&lt;/description&gt;</p>
<p>&lt;/property&gt;</p>
<p>&lt;property&gt;</p>
<p>&lt;name&gt;hbase.rootdir&lt;/name&gt;</p>
<p>&lt;value&gt;hdfs://example0:9000/hbase&lt;/value&gt;</p>
<p>&lt;description&gt;The directory shared by RegionServers.</p>
<p>&lt;/description&gt;</p>
<p>&lt;/property&gt;</p>
<p>&lt;property&gt;</p>
<p>&lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</p>
<p>&lt;value&gt;true&lt;/value&gt;</p>
<p>&lt;description&gt;The mode the cluster will be in. Possible values are</p>
<p>false: standalone and pseudo-distributed setups with managed Zookeeper</p>
<p>true: fully-distributed with unmanaged Zookeeper Quorum (see hbase-env.sh)</p>
<p>&lt;/description&gt;</p>
<p>&lt;/property&gt;</p>
<p>&lt;/configuration&gt;</p>
<p> </p>
<p> </p>
<p><a target="_blank" name="regionservers"></a><span style="color:rgb(153,0,0)">1.3.3.1.2. </span><span style="color:rgb(0,122,0)">regionservers</span></p>
<p>这个文件把RegionServer的节点列了下来。在这个例子里面我们让所有的节点都运行RegionServer,除了第一个节点 example1，它要运行 HBase Master 和 HDFS namenode</p>
<p>example1</p>
<p>example3</p>
<p>example4</p>
<p>example5</p>
<p>example6</p>
<p>example7</p>
<p>example8</p>
<p>example9</p>
<p> </p>
<p><a target="_blank" name="hbase_env"></a><span style="color:rgb(153,0,0)">1.3.3.1.3. </span><span style="color:rgb(0,122,0)">hbase-env.sh</span></p>
<p>下面我们用diff 命令来展示 <span style="color:rgb(0,122,0)">hbase-env.sh</span> 文件相比默认变化的部分. 我们把Hbase的堆内存设置为4G而不是默认的1G.</p>
<p> </p>
<p>$ git diff hbase-env.sh</p>
<p>diff --git a/conf/hbase-env.sh b/conf/hbase-env.sh</p>
<p>index e70ebc6..96f8c27 100644</p>
<p>--- a/conf/hbase-env.sh</p>
<p>+++ b/conf/hbase-env.sh</p>
<p>@@ -31,7 +31,7 @@ export JAVA_HOME=/usr/lib//jvm/java-6-sun/</p>
<p># export HBASE_CLASSPATH=</p>
<p> </p>
<p># The maximum amount of heap to use, in MB. Default is 1000.</p>
<p>-# export HBASE_HEAPSIZE=1000</p>
<p>+export HBASE_HEAPSIZE=4096</p>
<p> </p>
<p># Extra Java runtime options.</p>
<p># Below are what we set by default.  May only work with SUN JVM.</p>
<p> </p>
<p> </p>
<p>你可以使用 rsync 来同步 <span style="color:rgb(0,122,0)">conf</span> 文件夹到你的整个集群.</p>
<p> </p>
<p></p>
<p>[<a target="_blank" name="ftn.d613e280"></a><a target="_blank" href="#d613e280" rel="nofollow"><span style="color:rgb(0,0,255)">1</span></a>] See <a target="_blank" href="http://svn.apache.org/viewvc/hadoop/common/branches/branch-0.20-append/CHANGES.txt" rel="nofollow"><span style="color:rgb(0,0,255)">CHANGES.txt</span></a> in branch-0.20-append to see list of patches involved adding append on the Hadoop 0.20 branch.</p>
<p>[<a target="_blank" name="ftn.d613e389"></a><a target="_blank" href="#d613e389" rel="nofollow"><span style="color:rgb(0,0,255)">2</span></a>] See Jack Levin's <a><span style="color:rgb(0,0,255)">major hdfs issues</span></a> note up on the user list.</p>
<p>[<a target="_blank" name="ftn.d613e396"></a><a target="_blank" href="#d613e396" rel="nofollow"><span style="color:rgb(0,0,255)">3</span></a>] 这样的需求对于数据库应用来说是很常见的，例如Oracle。 Setting Shell Limits for the Oracle User in <a target="_blank" href="http://www.akadia.com/services/ora_linux_install_10g.html" rel="nofollow"><span style="color:rgb(0,0,255)">Short Guide to install Oracle 10 on Linux</span></a>.</p>
<p>[<a target="_blank" name="ftn.d613e408"></a><a target="_blank" href="#d613e408" rel="nofollow"><span style="color:rgb(0,0,255)">4</span></a>] A useful read setting config on you hadoop cluster is Aaron Kimballs' Configuration Parameters: What can you just ignore?</p>
<p>[<a target="_blank" name="ftn.d613e474"></a><a target="_blank" href="#d613e474" rel="nofollow"><span style="color:rgb(0,0,255)">5</span></a>] 参见 <a target="_blank" href="http://ccgtech.blogspot.com/2010/02/hadoop-hdfs-deceived-by-xciever.html" rel="nofollow"><span style="color:rgb(0,0,255)">Hadoop HDFS: Deceived by Xciever</span></a> for an informative rant on xceivering.</p>
<p>[<a target="_blank" name="ftn.d613e543"></a><a target="_blank" href="#d613e543" rel="nofollow"><span style="color:rgb(0,0,255)">6</span></a>] 这两个命名法来自于Hadoop.</p>
<p>[<a target="_blank" name="ftn.d613e606"></a><a target="_blank" href="#d613e606" rel="nofollow"><span style="color:rgb(0,0,255)">7</span></a>] See <a target="_blank" href="http://hbase.apache.org/pseudo-distributed.html" rel="nofollow"><span style="color:rgb(0,0,255)">Pseudo-distributed mode extras</span></a> for notes on how to start extra Masters and RegionServers when running pseudo-distributed.</p>
<p>[<a target="_blank" name="ftn.d613e690"></a><a target="_blank" href="#d613e690" rel="nofollow"><span style="color:rgb(0,0,255)">8</span></a>] For the full list of ZooKeeper configurations, see ZooKeeper's <span style="color:rgb(0,122,0)">zoo.cfg</span>. HBase does not ship with a <span style="color:rgb(0,122,0)">zoo.cfg</span> so you will need to browse the <span style="color:rgb(0,122,0)">conf</span> directory in an appropriate ZooKeeper download.</p>
<p><a target="_blank" name="upgrading"></a><span style="color:rgb(153,0,0)">Chapter 2. 升级</span></p>
<p>Table of Contents</p>
<p><a target="_blank" href="#upgrade0.90" rel="nofollow"><span style="color:rgb(0,0,255)">2.1. 从HBase 0.20.x or 0.89.x 升级到 HBase 0.90.x </span></a></p>
<p>参见 <a target="_blank" href="#requirements" rel="nofollow" title="1.3.1. 需要的软件"><span style="color:rgb(0,0,255)">Section 1.3.1, “需要的软件”</span></a>, 需要特别注意有关Hadoop 版本的信息.</p>
<p><a target="_blank" name="upgrade0.90"></a><span style="color:rgb(153,0,0)">2.1. 从HBase 0.20.x or 0.89.x 升级到 HBase 0.90.x</span></p>
<p>0.90.x 版本的HBase可以在 HBase 0.20.x 或者 HBase 0.89.x的数据上启动. 不需要转换数据文件， HBase 0.89.x 和 0.90.x 的region目录名是不一样的 -- 老版本用md5 hash 而不是jenkins hash 来命名region-- 这就意味着，一旦启动，再也不能回退到 HBase 0.20.x.</p>
<p>在升级的时候，一定要将<span style="color:rgb(0,122,0)">hbase-default.xml</span> 从你的 <span style="color:rgb(0,122,0)">conf</span>目录删掉。 0.20.x 版本的配置对于 0.90.x HBase不是最佳的. <span style="color:rgb(0,122,0)">hbase-default.xml</span> 现在已经被打包在 HBase jar 里面了. 如果你想看看这个文件内容，你可以在src目录下 <span style="color:rgb(0,122,0)">src/main/resources/hbase-default.xml</span> 或者在 <a target="_blank" href="#hbase_default_configurations" rel="nofollow" title="3.1.1. HBase 默认配置"><span style="color:rgb(0,0,255)">Section 3.1.1, “HBase 默认配置”</span></a>看到.</p>
<p>最后，如果从0.20.x升级，需要在shell里检查 .META. schema . 过去，我们推荐用户使用16KB的 MEMSTORE_FLUSHSIZE. 在shell中运行 hbase&gt; scan '-ROOT-'. 会显示当前的.META. schema. 检查 MEMSTORE_FLUSHSIZE 的大小. 看看是不是 16KB (16384)? 如果是的话，你需要修改它(默认的值是 64MB (67108864)) 运行脚本 <span style="color:rgb(0,122,0)">bin/set_meta_memstore_size.rb</span>. 这个脚本会修改 .META. schema. 如果不运行的话，集群会比较慢[<a target="_blank" name="d613e1033"></a><a target="_blank" href="#ftn.d613e1033" rel="nofollow"><span style="color:rgb(0,0,255)">9</span></a>] .</p>
<p> </p>
<p></p>
<p>[<a target="_blank" name="ftn.d613e1033"></a><a target="_blank" href="#d613e1033" rel="nofollow"><span style="color:rgb(0,0,255)">9</span></a>] 参见 <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE-3499" rel="nofollow"><span style="color:rgb(0,0,255)">HBASE-3499 Users upgrading to 0.90.0 need to have their .META. table updated with the right MEMSTORE_SIZE</span></a></p>
<p><a target="_blank" name="configuration"></a><span style="color:rgb(153,0,0)">Chapter 3. 配置</span></p>
<p>Table of Contents</p>
<p><a target="_blank" href="#hbase.site" rel="nofollow"><span style="color:rgb(0,0,255)">3.1. </span><span style="color:rgb(0,122,0)">hbase-site.xml</span><span style="color:rgb(0,0,255)"> 和 </span><span style="color:rgb(0,122,0)">hbase-default.xml</span></a></p>
<p><a target="_blank" href="#hbase_default_configurations" rel="nofollow"><span style="color:rgb(0,0,255)">3.1.1. HBase 默认配置</span></a></p>
<p><a target="_blank" href="#hbase.env.sh" rel="nofollow"><span style="color:rgb(0,0,255)">3.2. </span><span style="color:rgb(0,122,0)">hbase-env.sh</span></a></p>
<p><a target="_blank" href="#log4j" rel="nofollow"><span style="color:rgb(0,0,255)">3.3. </span><span style="color:rgb(0,122,0)">log4j.properties</span></a></p>
<p><a target="_blank" href="#important_configurations" rel="nofollow"><span style="color:rgb(0,0,255)">3.4. 重要的配置</span></a></p>
<p><a target="_blank" href="#required_configuration" rel="nofollow"><span style="color:rgb(0,0,255)">3.5. 必须的配置 </span></a></p>
<p><a target="_blank" href="#recommended_configurations" rel="nofollow"><span style="color:rgb(0,0,255)">3.6. 推荐的配置</span></a></p>
<p><a target="_blank" href="#zookeeper.session.timeout" rel="nofollow"><span style="color:rgb(0,0,255)">3.6.1. zookeeper.session.timeout</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.handler.count" rel="nofollow"><span style="color:rgb(0,0,255)">3.6.2. hbase.regionserver.handler.count</span></a></p>
<p><a target="_blank" href="#big_memory" rel="nofollow"><span style="color:rgb(0,0,255)">3.6.3. 大内存机器的配置 </span></a></p>
<p><a target="_blank" href="#lzo" rel="nofollow"><span style="color:rgb(0,0,255)">3.6.4. LZO 压缩</span></a></p>
<p><a target="_blank" href="#bigger.regions" rel="nofollow"><span style="color:rgb(0,0,255)">3.6.5. 更大的 Regions</span></a></p>
<p><a target="_blank" href="#disable.splitting" rel="nofollow"><span style="color:rgb(0,0,255)">3.6.6. 管理 Splitting</span></a></p>
<p><a target="_blank" href="#client_dependencies" rel="nofollow"><span style="color:rgb(0,0,255)">3.7. 连接Hbase集群的客户端配置和依赖</span></a></p>
<p><a target="_blank" href="#d613e2045" rel="nofollow"><span style="color:rgb(0,0,255)">3.7.1. Java客户端配置</span></a></p>
<p>Hbase的配置系统和Hadoop一样。在<span style="color:rgb(0,122,0)">conf/hbase-env.sh</span>配置系统的部署信息和环境变量。 -- 这个配置会被启动shell使用 -- 然后在XML文件里配置信息，覆盖默认的配置。告知Hbase使用什么目录地址，ZooKeeper的位置等等信息。 [<a target="_blank" name="d613e1048"></a><a target="_blank" href="#ftn.d613e1048" rel="nofollow"><span style="color:rgb(0,0,255)">10</span></a>] .</p>
<p>当你使用分布式模式的时间，当你编辑完一个文件之后，记得要把这个文件复制到整个集群的<span style="color:rgb(0,122,0)">conf</span> 目录下。Hbase不会帮你做这些，你得用 rsync.</p>
<p><a target="_blank" name="hbase.site"></a><span style="color:rgb(153,0,0)">3.1. </span><span style="color:rgb(0,122,0)">hbase-site.xml</span><span style="color:rgb(153,0,0)"> 和 </span><span style="color:rgb(0,122,0)">hbase-default.xml</span></p>
<p>正如Hadoop放置HDFS的配置文件<span style="color:rgb(0,122,0)">hdfs-site.xml</span>，Hbase的配置文件是 <span style="color:rgb(0,122,0)">conf/hbase-site.xml</span>. 你可以在 <a target="_blank" href="#hbase_default_configurations" rel="nofollow" title="3.1.1. HBase 默认配置"><span style="color:rgb(0,0,255)">Section 3.1.1, “HBase 默认配置”</span></a>找到配置的属性列表。你也可以看有代码里面的<span style="color:rgb(0,122,0)">hbase-default.xml</span>文件，他在<span style="color:rgb(0,122,0)">src/main/resources</span>目录下。</p>
<p>不是所有的配置都在 <span style="color:rgb(0,122,0)">hbase-default.xml</span>出现.只要改了代码，配置就有可能改变，所以唯一了解这些被改过的配置的办法是读源代码本身。</p>
<p>要注意的是，要重启集群才能是配置生效。</p>
<p><a target="_blank" name="hbase_default_configurations"></a><span style="color:rgb(153,0,0)">3.1.1. HBase 默认配置</span></p>
<p><a target="_blank" name="hbase.default.configuration"></a><span style="color:rgb(153,0,0)">HBase 默认配置</span></p>
<p>该文档是用hbase默认配置文件生成的，文件源是 <span style="color:rgb(0,122,0)">hbase-default.xml</span>(因翻译需要，被译者修改成中文注释).</p>
<p><a target="_blank" name="hbase.rootdir"></a>hbase.rootdir</p>
<p>这个目录是region server的共享目录，用来持久化Hbase。URL需要是'完全正确'的，还要包含文件系统的scheme。例如，要表示hdfs中的'/hbase'目录，namenode 运行在namenode.example.org的9090端口。则需要设置为hdfs://namenode.example.org:9000/hbase。默认情况下Hbase是写到/tmp的。不改这个配置，数据会在重启的时候丢失。</p>
<p>默认: file:///tmp/hbase-${user.name}/hbase</p>
<p><a target="_blank" name="hbase.master.port"></a>hbase.master.port</p>
<p>Hbase的Master的端口.</p>
<p>默认: 60000</p>
<p><a target="_blank" name="hbase.cluster.distributed"></a>hbase.cluster.distributed</p>
<p>Hbase的运行模式。false是单机模式，true是分布式模式。若为false,Hbase和Zookeeper会运行在同一个JVM里面。</p>
<p>默认: false</p>
<p><a target="_blank" name="hbase.tmp.dir"></a>hbase.tmp.dir</p>
<p>本地文件系统的临时文件夹。可以修改到一个更为持久的目录上。(/tmp会在重启时清楚)</p>
<p>默认: /tmp/hbase-${user.name}</p>
<p><a target="_blank" name="hbase.master.info.port"></a>hbase.master.info.port</p>
<p>HBase Master web 界面端口. 设置为-1 意味着你不想让他运行。</p>
<p>默认: 60010</p>
<p><a target="_blank" name="hbase.master.info.bindAddress"></a>hbase.master.info.bindAddress</p>
<p>HBase Master web 界面绑定的端口</p>
<p>默认: 0.0.0.0</p>
<p><a target="_blank" name="hbase.client.write.buffer"></a>hbase.client.write.buffer</p>
<p>HTable客户端的写缓冲的默认大小。这个值越大，需要消耗的内存越大。因为缓冲在客户端和服务端都有实例，所以需要消耗客户端和服务端两个地方的内存。得到的好处是，可以减少RPC的次数。可以这样估算服务器端被占用的内存： hbase.client.write.buffer * hbase.regionserver.handler.count</p>
<p>默认: 2097152</p>
<p><a target="_blank" name="hbase.regionserver.port"></a>hbase.regionserver.port</p>
<p>HBase RegionServer绑定的端口</p>
<p>默认: 60020</p>
<p><a target="_blank" name="hbase.regionserver.info.port"></a>hbase.regionserver.info.port</p>
<p>HBase RegionServer web 界面绑定的端口设置为 -1 意味这你不想与运行 RegionServer 界面.</p>
<p>默认: 60030</p>
<p><a target="_blank" name="hbase.regionserver.info.port.auto"></a>hbase.regionserver.info.port.auto</p>
<p>Master或RegionServer是否要动态搜一个可以用的端口来绑定界面。当hbase.regionserver.info.port已经被占用的时候，可以搜一个空闲的端口绑定。这个功能在测试的时候很有用。默认关闭。</p>
<p>默认: false</p>
<p><a target="_blank" name="hbase.regionserver.info.bindAddress"></a>hbase.regionserver.info.bindAddress</p>
<p>HBase RegionServer web 界面的IP地址</p>
<p>默认: 0.0.0.0</p>
<p><a target="_blank" name="hbase.regionserver.class"></a>hbase.regionserver.class</p>
<p>RegionServer 使用的接口。客户端打开代理来连接region server的时候会使用到。</p>
<p>默认: org.apache.hadoop.hbase.ipc.HRegionInterface</p>
<p><a target="_blank" name="hbase.client.pause"></a>hbase.client.pause</p>
<p>通常的客户端暂停时间。最多的用法是客户端在重试前的等待时间。比如失败的get操作和region查询操作等都很可能用到。</p>
<p>默认: 1000</p>
<p><a target="_blank" name="hbase.client.retries.number"></a>hbase.client.retries.number</p>
<p>最大重试次数。例如 region查询，Get操作，Update操作等等都可能发生错误，需要重试。这是最大重试错误的值。</p>
<p>默认: 10</p>
<p><a target="_blank" name="hbase.client.scanner.caching"></a>hbase.client.scanner.caching</p>
<p>当调用Scanner的next方法，而值又不在缓存里的时候，从服务端一次获取的行数。越大的值意味着Scanner会快一些，但是会占用更多的内存。当缓冲被占满的时候，next方法调用会越来越慢。慢到一定程度，可能会导致超时。例如超过了hbase.regionserver.lease.period。</p>
<p>默认: 1</p>
<p><a target="_blank" name="hbase.client.keyvalue.maxsize"></a>hbase.client.keyvalue.maxsize</p>
<p>一个KeyValue实例的最大size.这个是用来设置存储文件中的单个entry的大小上界。因为一个KeyValue是不能分割的，所以可以避免因为数据过大导致region不可分割。明智的做法是把它设为可以被最大region size整除的数。如果设置为0或者更小，就会禁用这个检查。默认10MB。</p>
<p>默认: 10485760</p>
<p><a target="_blank" name="hbase.regionserver.lease.period"></a>hbase.regionserver.lease.period</p>
<p>客户端租用HRegion server 期限，即超时阀值。单位是毫秒。默认情况下，客户端必须在这个时间内发一条信息，否则视为死掉。</p>
<p>默认: 60000</p>
<p>hbase.regionserver.handler.count</p>
<p>RegionServers受理的RPC Server实例数量。对于Master来说，这个属性是Master受理的handler数量</p>
<p>默认: 10</p>
<p><a target="_blank" name="hbase.regionserver.msginterval"></a>hbase.regionserver.msginterval</p>
<p>RegionServer 发消息给 Master 时间间隔，单位是毫秒</p>
<p>默认: 3000</p>
<p><a target="_blank" name="hbase.regionserver.optionallogflushinter"></a>hbase.regionserver.optionallogflushinterval</p>
<p>将Hlog同步到HDFS的间隔。如果Hlog没有积累到一定的数量，到了时间，也会触发同步。默认是1秒，单位毫秒。</p>
<p>默认: 1000</p>
<p><a target="_blank" name="hbase.regionserver.regionSplitLimit"></a>hbase.regionserver.regionSplitLimit</p>
<p>region的数量到了这个值后就不会在分裂了。这不是一个region数量的硬性限制。但是起到了一定指导性的作用，到了这个值就该停止分裂了。默认是MAX_INT.就是说不阻止分裂。</p>
<p>默认: 2147483647</p>
<p><a target="_blank" name="hbase.regionserver.logroll.period"></a>hbase.regionserver.logroll.period</p>
<p>提交commit log的间隔，不管有没有写足够的值。</p>
<p>默认: 3600000</p>
<p><a target="_blank" name="hbase.regionserver.hlog.reader.impl"></a>hbase.regionserver.hlog.reader.impl</p>
<p>HLog file reader 的实现.</p>
<p>默认: org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader</p>
<p><a target="_blank" name="hbase.regionserver.hlog.writer.impl"></a>hbase.regionserver.hlog.writer.impl</p>
<p>HLog file writer 的实现.</p>
<p>默认: org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter</p>
<p><a target="_blank" name="hbase.regionserver.thread.splitcompactch"></a>hbase.regionserver.thread.splitcompactcheckfrequency</p>
<p>region server 多久执行一次split/compaction 检查.</p>
<p>默认: 20000</p>
<p><a target="_blank" name="hbase.regionserver.nbreservationblocks"></a>hbase.regionserver.nbreservationblocks</p>
<p>储备的内存block的数量(译者注:就像石油储备一样)。当发生out of memory 异常的时候，我们可以用这些内存在RegionServer停止之前做清理操作。</p>
<p>默认: 4</p>
<p><a target="_blank" name="hbase.zookeeper.dns.interface"></a>hbase.zookeeper.dns.interface</p>
<p>当使用DNS的时候，Zookeeper用来上报的IP地址的网络接口名字。</p>
<p>默认: default</p>
<p><a target="_blank" name="hbase.zookeeper.dns.nameserver"></a>hbase.zookeeper.dns.nameserver</p>
<p>当使用DNS的时候，Zookeepr使用的DNS的域名或者IP 地址，Zookeeper用它来确定和master用来进行通讯的域名.</p>
<p>默认: default</p>
<p><a target="_blank" name="hbase.regionserver.dns.interface"></a>hbase.regionserver.dns.interface</p>
<p>当使用DNS的时候，RegionServer用来上报的IP地址的网络接口名字。</p>
<p>默认: default</p>
<p><a target="_blank" name="hbase.regionserver.dns.nameserver"></a>hbase.regionserver.dns.nameserver</p>
<p>当使用DNS的时候，RegionServer使用的DNS的域名或者IP 地址，RegionServer用它来确定和master用来进行通讯的域名.</p>
<p>默认: default</p>
<p><a target="_blank" name="hbase.master.dns.interface"></a>hbase.master.dns.interface</p>
<p>当使用DNS的时候，Master用来上报的IP地址的网络接口名字。</p>
<p>默认: default</p>
<p><a target="_blank" name="hbase.master.dns.nameserver"></a>hbase.master.dns.nameserver</p>
<p>当使用DNS的时候，RegionServer使用的DNS的域名或者IP 地址，Master用它来确定用来进行通讯的域名.</p>
<p>默认: default</p>
<p><a target="_blank" name="hbase.balancer.period%0A____"></a>hbase.balancer.period</p>
<p>Master执行region balancer的间隔。</p>
<p>默认: 300000</p>
<p><a target="_blank" name="hbase.regions.slop"></a>hbase.regions.slop</p>
<p>当任一regionserver有average + (average * slop)个region是会执行Rebalance</p>
<p>默认: 0</p>
<p><a target="_blank" name="hbase.master.logcleaner.ttl"></a>hbase.master.logcleaner.ttl</p>
<p>Hlog存在于.oldlogdir 文件夹的最长时间, 超过了就会被 Master 的线程清理掉.</p>
<p>默认: 600000</p>
<p><a target="_blank" name="hbase.master.logcleaner.plugins"></a>hbase.master.logcleaner.plugins</p>
<p>LogsCleaner服务会执行的一组LogCleanerDelegat。值用逗号间隔的文本表示。这些WAL/HLog cleaners会按顺序调用。可以把先调用的放在前面。你可以实现自己的LogCleanerDelegat，加到Classpath下，然后在这里写下类的全称。一般都是加在默认值的前面。</p>
<p>默认: org.apache.hadoop.hbase.master.TimeToLiveLogCleaner</p>
<p><a target="_blank" name="hbase.regionserver.global.memstore.upper"></a>hbase.regionserver.global.memstore.upperLimit</p>
<p>单个region server的全部memtores的最大值。超过这个值，一个新的update操作会被挂起，强制执行flush操作。</p>
<p>默认: 0.4</p>
<p><a target="_blank" name="hbase.regionserver.global.memstore.lower"></a>hbase.regionserver.global.memstore.lowerLimit</p>
<p>当强制执行flush操作的时候，当低于这个值的时候，flush会停止。默认是堆大小的 35% . 如果这个值和 hbase.regionserver.global.memstore.upperLimit 相同就意味着当update操作因为内存限制被挂起时，会尽量少的执行flush(译者注:一旦执行flush，值就会比下限要低，不再执行)</p>
<p>默认: 0.35</p>
<p><a target="_blank" name="hbase.server.thread.wakefrequency"></a>hbase.server.thread.wakefrequency</p>
<p>service工作的sleep间隔，单位毫秒。可以作为service线程的sleep间隔，比如log roller.</p>
<p>默认: 10000</p>
<p><a target="_blank" name="hbase.hregion.memstore.flush.size"></a>hbase.hregion.memstore.flush.size</p>
<p>当memstore的大小超过这个值的时候，会flush到磁盘。这个值被一个线程每隔hbase.server.thread.wakefrequency检查一下。</p>
<p>默认: 67108864</p>
<p><a target="_blank" name="hbase.hregion.preclose.flush.size"></a>hbase.hregion.preclose.flush.size</p>
<p>当一个region中的memstore的大小大于这个值的时候，我们又触发了close.会先运行“pre-flush”操作，清理这个需要关闭的memstore，然后将这个region下线。当一个region下线了，我们无法再进行任何写操作。如果一个memstore很大的时候，flush操作会消耗很多时间。"pre-flush"操作意味着在region下线之前，会先把memstore清空。这样在最终执行close操作的时候，flush操作会很快。</p>
<p>默认: 5242880</p>
<p><a target="_blank" name="hbase.hregion.memstore.block.multiplier"></a>hbase.hregion.memstore.block.multiplier</p>
<p>如果memstore有hbase.hregion.memstore.block.multiplier倍数的hbase.hregion.flush.size的大小，就会阻塞update操作。这是为了预防在update高峰期会导致的失控。如果不设上界，flush的时候会花很长的时间来合并或者分割，最坏的情况就是引发out of memory异常。(译者注:内存操作的速度和磁盘不匹配，需要等一等。原文似乎有误)</p>
<p>默认: 2</p>
<p><a target="_blank" name="hbase.hregion.memstore.mslab.enabled"></a>hbase.hregion.memstore.mslab.enabled</p>
<p>体验特性：启用memStore分配本地缓冲区。这个特性是为了防止在大量写负载的时候堆的碎片过多。这可以减少GC操作的频率。(GC有可能会Stop the world)(译者注：实现的原理相当于预分配内存，而不是每一个值都要从堆里分配)</p>
<p>默认: false</p>
<p><a target="_blank" name="hbase.hregion.max.filesize"></a>hbase.hregion.max.filesize</p>
<p>最大HStoreFile大小。若某个Column families的HStoreFile增长达到这个值，这个Hegion会被切割成两个。 Default: 256M.</p>
<p>默认: 268435456</p>
<p><a target="_blank" name="hbase.hstore.compactionThreshold"></a>hbase.hstore.compactionThreshold</p>
<p>当一个HStore含有多于这个值的HStoreFiles(每一个memstore flush产生一个HStoreFile)的时候，会执行一个合并操作，把这HStoreFiles写成一个。这个值越大，需要合并的时间就越长。</p>
<p>默认: 3</p>
<p><a target="_blank" name="hbase.hstore.blockingStoreFiles"></a>hbase.hstore.blockingStoreFiles</p>
<p>当一个HStore含有多于这个值的HStoreFiles(每一个memstore flush产生一个HStoreFile)的时候，会执行一个合并操作，update会阻塞直到合并完成，直到超过了hbase.hstore.blockingWaitTime的值</p>
<p>默认: 7</p>
<p><a target="_blank" name="hbase.hstore.blockingWaitTime"></a>hbase.hstore.blockingWaitTime</p>
<p>hbase.hstore.blockingStoreFiles所限制的StoreFile数量会导致update阻塞，这个时间是来限制阻塞时间的。当超过了这个时间，HRegion会停止阻塞update操作，不过合并还有没有完成。默认为90s.</p>
<p>默认: 90000</p>
<p><a target="_blank" name="hbase.hstore.compaction.max"></a>hbase.hstore.compaction.max</p>
<p>每个“小”合并的HStoreFiles最大数量。</p>
<p>默认: 10</p>
<p><a target="_blank" name="hbase.hregion.majorcompaction"></a>hbase.hregion.majorcompaction</p>
<p>一个Region中的所有HStoreFile的major compactions的时间间隔。默认是1天。设置为0就是禁用这个功能。</p>
<p>默认: 86400000</p>
<p><a target="_blank" name="hbase.mapreduce.hfileoutputformat.blocks"></a>hbase.mapreduce.hfileoutputformat.blocksize</p>
<p>MapReduce中HFileOutputFormat可以写 storefiles/hfiles. 这个值是hfile的blocksize的最小值。通常在Hbase写Hfile的时候，bloocksize是由table schema(HColumnDescriptor)决定的，但是在mapreduce写的时候，我们无法获取schema中blocksize。这个值越小，你的索引就越大，你随机访问需要获取的数据就越小。如果你的cell都很小，而且你需要更快的随机访问，可以把这个值调低。</p>
<p>默认: 65536</p>
<p><a target="_blank" name="hfile.block.cache.size"></a>hfile.block.cache.size</p>
<p>分配给HFile/StoreFile的block cache占最大堆(-Xmx setting)的比例。默认是20%，设置为0就是不分配。</p>
<p>默认: 0.2</p>
<p><a target="_blank" name="hbase.hash.type"></a>hbase.hash.type</p>
<p>哈希函数使用的哈希算法。可以选择两个值:: murmur (MurmurHash) 和 jenkins (JenkinsHash). 这个哈希是给 bloom filters用的.</p>
<p>默认: murmur</p>
<p><a target="_blank" name="hbase.master.keytab.file"></a>hbase.master.keytab.file</p>
<p>HMaster server验证登录使用的kerberos keytab 文件路径。(译者注：Hbase使用Kerberos实现安全)</p>
<p>默认:</p>
<p><a target="_blank" name="hbase.master.kerberos.principal"></a>hbase.master.kerberos.principal</p>
<p>例如. "hbase/_HOST@EXAMPLE.COM ". HMaster运行需要使用 kerberos principal name. principal name 可以在: user/hostname@DOMAIN 中获取. 如果 "_HOST" 被用做hostname portion，需要使用实际运行的hostname来替代它。</p>
<p>默认:</p>
<p><a target="_blank" name="hbase.regionserver.keytab.file"></a>hbase.regionserver.keytab.file</p>
<p>HRegionServer验证登录使用的kerberos keytab 文件路径。</p>
<p>默认:</p>
<p><a target="_blank" name="hbase.regionserver.kerberos.principal"></a>hbase.regionserver.kerberos.principal</p>
<p>例如. "hbase/_HOST@EXAMPLE.COM ". HRegionServer运行需要使用 kerberos principal name. principal name 可以在: user/hostname@DOMAIN 中获取. 如果 "_HOST" 被用做hostname portion，需要使用实际运行的hostname来替代它。在这个文件中必须要有一个entry来描述 hbase.regionserver.keytab.file</p>
<p>默认:</p>
<p>zookeeper.session.timeout</p>
<p>ZooKeeper 会话超时.Hbase把这个值传递改zk集群，向他推荐一个会话的最大超时时间。详见http://hadoop.apache.org/zookeeper/docs/current/zookeeperProgrammers.html#ch_zkSessions "The client sends a requested timeout, the server responds with the timeout that it can give the client. "。单位是毫秒</p>
<p>默认: 180000</p>
<p><a target="_blank" name="zookeeper.znode.parent"></a>zookeeper.znode.parent</p>
<p>ZooKeeper中的Hbase的根ZNode。所有的Hbase的ZooKeeper会用这个目录配置相对路径。默认情况下，所有的Hbase的ZooKeeper文件路径是用相对路径，所以他们会都去这个目录下面。</p>
<p>默认: /hbase</p>
<p><a target="_blank" name="zookeeper.znode.rootserver"></a>zookeeper.znode.rootserver</p>
<p>ZNode 保存的 根region的路径. 这个值是由Master来写，client和regionserver 来读的。如果设为一个相对地址，父目录就是 ${zookeeper.znode.parent}.默认情形下，意味着根region的路径存储在/hbase/root-region-server.</p>
<p>默认: root-region-server</p>
<p><a target="_blank" name="hbase.zookeeper.quorum"></a>hbase.zookeeper.quorum</p>
<p>Zookeeper集群的地址列表，用逗号分割。例如："host1.mydomain.com,host2.mydomain.com,host3.mydomain.com".默认是localhost,是给伪分布式用的。要修改才能在完全分布式的情况下使用。如果在hbase-env.sh设置了HBASE_MANAGES_ZK，这些ZooKeeper节点就会和Hbase一起启动。</p>
<p>默认: localhost</p>
<p><a target="_blank" name="hbase.zookeeper.peerport"></a>hbase.zookeeper.peerport</p>
<p>ZooKeeper节点使用的端口。详细参见：http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper</p>
<p>默认: 2888</p>
<p><a target="_blank" name="hbase.zookeeper.leaderport"></a>hbase.zookeeper.leaderport</p>
<p>ZooKeeper用来选择Leader的端口，详细参见：http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper</p>
<p>默认: 3888</p>
<p><a target="_blank" name="hbase.zookeeper.property.initLimit"></a>hbase.zookeeper.property.initLimit</p>
<p>ZooKeeper的zoo.conf中的配置。初始化synchronization阶段的ticks数量限制</p>
<p>默认: 10</p>
<p><a target="_blank" name="hbase.zookeeper.property.syncLimit"></a>hbase.zookeeper.property.syncLimit</p>
<p>ZooKeeper的zoo.conf中的配置。发送一个请求到获得承认之间的ticks的数量限制</p>
<p>默认: 5</p>
<p><a target="_blank" name="hbase.zookeeper.property.dataDir"></a>hbase.zookeeper.property.dataDir</p>
<p>ZooKeeper的zoo.conf中的配置。快照的存储位置</p>
<p>默认: ${hbase.tmp.dir}/zookeeper</p>
<p><a target="_blank" name="hbase.zookeeper.property.clientPort"></a>hbase.zookeeper.property.clientPort</p>
<p>ZooKeeper的zoo.conf中的配置。客户端连接的端口</p>
<p>默认: 2181</p>
<p><a target="_blank" name="hbase.zookeeper.property.maxClientCnxns"></a>hbase.zookeeper.property.maxClientCnxns</p>
<p>ZooKeeper的zoo.conf中的配置。 ZooKeeper集群中的单个节点接受的单个Client(以IP区分)的请求的并发数。这个值可以调高一点，防止在单机和伪分布式模式中出问题。</p>
<p>默认: 2000</p>
<p><a target="_blank" name="hbase.rest.port"></a>hbase.rest.port</p>
<p>HBase REST server的端口</p>
<p>默认: 8080</p>
<p><a target="_blank" name="hbase.rest.readonly"></a>hbase.rest.readonly</p>
<p>定义REST server的运行模式。可以设置成如下的值： false: 所有的HTTP请求都是被允许的 - GET/PUT/POST/DELETE. true:只有GET请求是被允许的</p>
<p>默认: false</p>
<p><a target="_blank" name="hbase.env.sh"></a><span style="color:rgb(153,0,0)">3.2. </span><span style="color:rgb(0,122,0)">hbase-env.sh</span></p>
<p>在这个文件里面设置HBase环境变量。比如可以配置JVM启动的堆大小或者GC的参数。你还可在这里配置Hbase的参数，如Log位置，niceness(译者注:优先级)，ssh参数还有pid文件的位置等等。打开文件<span style="color:rgb(0,122,0)">conf/hbase-env.sh</span>细读其中的内容。每个选项都是有详尽的注释的。你可以在此添加自己的环境变量。</p>
<p>这个文件的改动系统Hbase重启才能生效。</p>
<p><a target="_blank" name="log4j"></a><span style="color:rgb(153,0,0)">3.3. </span><span style="color:rgb(0,122,0)">log4j.properties</span></p>
<p>编辑这个文件可以改变Hbase的日志的级别，轮滚策略等等。</p>
<p>这个文件的改动系统Hbase重启才能生效。日志级别的更改会影响到HBase UI</p>
<p><a target="_blank" name="important_configurations"></a><span style="color:rgb(153,0,0)">3.4. 重要的配置</span></p>
<p>下面我们会列举重要 的配置. 这个章节讲述必须的配置和那些值得一看的配置。(译者注:淘宝的博客也有本章节的内容，<a target="_blank" href="http://rdc.taobao.com/team/jm/archives/975" rel="nofollow"><span style="color:rgb(0,0,255)">HBase性能调优</span></a>，很详尽)。</p>
<p><a target="_blank" name="required_configuration"></a><span style="color:rgb(153,0,0)">3.5. 必须的配置</span></p>
<p>参见 <a target="_blank" href="#requirements" rel="nofollow" title="1.3.1. 需要的软件"><span style="color:rgb(0,0,255)">Section 1.3.1, “需要的软件”</span></a>. 这里列举了运行Hbase至少两个必须的配置: i.e. <a target="_blank" href="#ulimit" rel="nofollow" title="1.3.1.6.  ulimit 和 nproc"><span style="color:rgb(0,0,255)">Section 1.3.1.6, “ ulimit 和 nproc ”</span></a> 和 <a target="_blank" href="#dfs.datanode.max.xcievers" rel="nofollow" title="1.3.1.7. dfs.datanode.max.xcievers"><span style="color:rgb(0,0,255)">Section 1.3.1.7, “dfs.datanode.max.xcievers”</span></a>.</p>
<p><a target="_blank" name="recommended_configurations"></a><span style="color:rgb(153,0,0)">3.6. 推荐的配置</span></p>
<p><a target="_blank" name="zookeeper.session.timeout"></a><span style="color:rgb(153,0,0)">3.6.1. </span><span style="color:rgb(153,0,0)">zookeeper.session.timeout</span></p>
<p>这个默认值是3分钟。这意味着一旦一个server宕掉了，Master至少需要3分钟才能察觉到宕机，开始恢复。你可能希望将这个超时调短，这样Master就能更快的察觉到了。在你调这个值之前，你需要确认你的JVM的GC参数，否则一个长时间的GC操作就可能导致超时。（当一个RegionServer在运行一个长时间的GC的时候，你可能想要重启并恢复它）.</p>
<p>要想改变这个配置，可以编辑 <span style="color:rgb(0,122,0)">hbase-site.xml</span>, 将配置部署到全部集群，然后重启。</p>
<p>我们之所以把这个值调的很高，是因为我们不想一天到晚在论坛里回答新手的问题。“为什么我在执行一个大规模数据导入的时候Region Server死掉啦”，通常这样的问题是因为长时间的GC操作引起的，他们的JVM没有调优。我们是这样想的，如果一个人对Hbase不很熟悉，不能期望他知道所有，打击他的自信心。等到他逐渐熟悉了，他就可以自己调这个参数了。</p>
<p><a target="_blank" name="hbase.regionserver.handler.count"></a><span style="color:rgb(153,0,0)">3.6.2. </span><span style="color:rgb(153,0,0)">hbase.regionserver.handler.count</span></p>
<p>这个设置决定了处理用户请求的线程数量。默认是10，这个值设的比较小，主要是为了预防用户用一个比较大的写缓冲，然后还有很多客户端并发，这样region servers会垮掉。有经验的做法是，当请求内容很大(上MB，如大puts, 使用缓存的scans)的时候，把这个值放低。请求内容较小的时候(gets, 小puts, ICVs, deletes)，把这个值放大。</p>
<p>当客户端的请求内容很小的时候，把这个值设置的和最大客户端数量一样是很安全的。一个典型的例子就是一个给网站服务的集群，put操作一般不会缓冲,绝大多数的操作是get操作。</p>
<p>把这个值放大的危险之处在于，把所有的Put操作缓冲意味着对内存有很大的压力，甚至会导致OutOfMemory.一个运行在内存不足的机器的RegionServer会频繁的触发GC操作，渐渐就能感受到停顿。(因为所有请求内容所占用的内存不管GC执行几遍也是不能回收的)。一段时间后，集群也会受到影响，因为所有的指向这个region的请求都会变慢。这样就会拖累集群，加剧了这个问题。</p>
<p><a target="_blank" name="big_memory"></a><span style="color:rgb(153,0,0)">3.6.3. 大内存机器的配置</span></p>
<p>Hbase有一个合理的保守的配置，这样可以运作在所有的机器上。如果你有台大内存的集群-Hbase有8G或者更大的heap,接下来的配置可能会帮助你 TODO.(译者注:原文到此为止，汗)</p>
<p><a target="_blank" name="lzo"></a><span style="color:rgb(153,0,0)">3.6.4. LZO 压缩<a target="_blank" name="d613e1936"></a></span></p>
<p>你可以考虑使用Lzo压缩，这个可以无缝集成，并且在大多数情况下可以提供性能。</p>
<p>Hbase是Apache的协议，而LZO是GPL的协议。Hbase不能自带LZO，因此LZO需要在安装Hbase之前安装。参见 <a target="_blank" href="http://wiki.apache.org/hadoop/UsingLzoCompression" rel="nofollow"><span style="color:rgb(0,0,255)">使用 LZO 压缩</span></a>介绍了如何在Hbase中使用LZO</p>
<p>一个常见的问题是，用户在一开始使用LZO的时候会很好，但是数月过去，管理员在给集群添加集群的时候，他们忘记了LZO的事情。在0.90.0版本之后，我们会运行失败，但也有可能不。请你要阅读这一段[<a target="_blank" name="d613e1948"></a><a target="_blank" href="#ftn.d613e1948" rel="nofollow"><span style="color:rgb(0,0,255)">11</span></a>].</p>
<p>还要在本书的尾部参见 <a target="_blank" href="#compression" rel="nofollow" title="Appendix B. HBase中的压缩"><span style="color:rgb(0,0,255)">Appendix B, </span><span style="color:rgb(0,0,255)">HBase中的压缩</span></a> .</p>
<p><a target="_blank" name="bigger.regions"></a><span style="color:rgb(153,0,0)">3.6.5. 更大的 Regions</span></p>
<p>更大的Region可以使你集群上的Region的总数量较少。一般来言，更少的Region可以使你的集群运行更加流畅。(你可以自己随时手工将大Region切割，这样单个热点Region就会被分布在集群的更多节点上)。默认情况下单个Region是256MB.你可以设置为1G。有些人使用更大的，4G甚至更多。可以调整<span style="color:rgb(0,122,0)">hbase-site.xml</span>中的 hbase.hregion.max.filesize属性.</p>
<p><a target="_blank" name="disable.splitting"></a><span style="color:rgb(153,0,0)">3.6.6. 管理 Splitting</span></p>
<p>除了让Hbase自动切割你的Region,你也可以手动切割。 [<a target="_blank" name="d613e1974"></a><a target="_blank" href="#ftn.d613e1974" rel="nofollow"><span style="color:rgb(0,0,255)">12</span></a>] 随着数据量的增大，splite会被持续执行。如果你需要知道你现在有几个region,比如长时间的debug或者做调优，你需要手动切割。通过跟踪日志来了解region级的问题是很难的，因为他在不停的切割和重命名。data offlineing bug和未知量的region会让你没有办法。如果一个 HLog 或者 StoreFile由于一个奇怪的bug，Hbase没有执行它。等到一天之后，你才发现这个问题，你可以确保现在的regions和那个时候的一样，这样你就可以restore或者replay这些数据。你还可以调优你的合并算法。如果数据是均匀的，随着数据增长，很容易导致split / compaction疯狂的运行。因为所有的region都是差不多大的。用手的切割，你就可以交错执行定时的合并和切割操作，降低IO负载。</p>
<p>为什么我关闭自动split呢？因为自动的splite是配置文件中的 hbase.hregion.max.filesize决定的. 你把它设置成ILong.MAX_VALUE是不推荐的做法，要是你忘记了手工切割怎么办.推荐的做法是设置成100GB，一旦到达这样的值，至少需要一个小时执行 major compactions。</p>
<p>那什么是最佳的在pre-splite regions的数量呢。这个决定于你的应用程序了。你可以先从低的开始，比如每个server10个pre-splite regions.然后花时间观察数据增长。有太少的region至少比出错好，你可以之后再rolling split.一个更复杂的答案是这个值是取决于你的region中的最大的storefile。随着数据的增大，这个也会跟着增大。 你可以当这个文件足够大的时候，用一个定时的操作使用Store的合并选择算法(compact selection algorithm)来仅合并这一个HStore。如果你不这样做，这个算法会启动一个 major compactions，很多region会受到影响，你的集群会疯狂的运行。需要注意的是，这样的疯狂合并操作是数据增长造成的，而不是手动分割操作决定的。</p>
<p>如果你 pre-split 导致 regions 很小,你可以通过配置HConstants.MAJOR_COMPACTION_PERIOD把你的major compaction参数调大</p>
<p>如果你的数据变得太大，可以使用org.apache.hadoop.hbase.util.RegionSplitter 脚本来执行针对全部集群的一个网络IO安全的rolling split操作。</p>
<p><a target="_blank" name="client_dependencies"></a><span style="color:rgb(153,0,0)">3.7. 连接Hbase集群的客户端配置和依赖</span></p>
<p>因为Hbase的Master有可能转移，所有客户端需要访问ZooKeeper来获得现在的位置。ZooKeeper会保存这些值。因此客户端必须知道Zookeeper集群的地址，否则做不了任何事情。通常这个地址存在 <span style="color:rgb(0,122,0)">hbase-site.xml</span> 里面，客户端可以从CLASSPATH取出这个文件.</p>
<p>如果你是使用一个IDE来运行Hbase客户端，你需要将<span style="color:rgb(0,122,0)">conf/</span>放入你的 classpath,这样 <span style="color:rgb(0,122,0)">hbase-site.xml</span>就可以找到了，(或者把hbase-site.xml放到 <span style="color:rgb(0,122,0)">src/test/resources</span>，这样测试的时候可以使用).</p>
<p>Hbase客户端最小化的依赖是 hbase, hadoop, log4j, commons-logging, commons-lang, 和 ZooKeeper ，这些jars 需要能在 CLASSPATH 中找到。</p>
<p>下面是一个基本的客户端 <span style="color:rgb(0,122,0)">hbase-site.xml</span> 例子：</p>
<p>&lt;?xml version="1.0"?&gt;</p>
<p>&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</p>
<p>&lt;configuration&gt;</p>
<p>&lt;property&gt;</p>
<p>&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</p>
<p>&lt;value&gt;example1,example2,example3&lt;/value&gt;</p>
<p>&lt;description&gt;The directory shared by region servers.</p>
<p>&lt;/description&gt;</p>
<p>&lt;/property&gt;</p>
<p>&lt;/configuration&gt;</p>
<p><a target="_blank" name="d613e2045"></a><span style="color:rgb(153,0,0)">3.7.1. Java客户端配置</span></p>
<p><span style="color:rgb(153,0,0)">Java是如何读到</span><span style="color:rgb(0,122,0)">hbase-site.xml</span><span style="color:rgb(153,0,0)"> 的内容的</span></p>
<p>Java客户端使用的配置信息是被映射在一个<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HBaseConfiguration" rel="nofollow"><span style="color:rgb(0,0,255)">HBaseConfiguration</span></a> 实例中. HBaseConfiguration有一个工厂方法, HBaseConfiguration.create();,运行这个方法的时候，他会去CLASSPATH,下找<span style="color:rgb(0,122,0)">hbase-site.xml</span>，读他发现的第一个配置文件的内容。 (这个方法还会去找<span style="color:rgb(0,122,0)">hbase-default.xml</span> ; <span style="color:rgb(0,122,0)">hbase.X.X.X.jar</span>里面也会有一个an hbase-default.xml). 不使用任何<span style="color:rgb(0,122,0)">hbase-site.xml</span>文件直接通过Java代码注入配置信息也是可以的。例如，你可以用编程的方式设置ZooKeeper信息，只要这样做:</p>
<p>Configuration config = HBaseConfiguration.create();</p>
<p>config.set("hbase.zookeeper.quorum", "localhost");  // Here we are running zookeeper locally</p>
<p>如果有多ZooKeeper实例，你可以使用逗号列表。(就像在<span style="color:rgb(0,122,0)">hbase-site.xml</span> 文件中做得一样). 这个 Configuration 实例会被传递到 <a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html" rel="nofollow"><span style="color:rgb(0,0,255)">HTable</span></a>, 之类的实例里面去.</p>
<p> </p>
<p></p>
<p>[<a target="_blank" name="ftn.d613e1048"></a><a target="_blank" href="#d613e1048" rel="nofollow"><span style="color:rgb(0,0,255)">10</span></a>] Be careful editing XML. Make sure you close all elements. Run your file through xmllint or similar to ensure well-formedness of your document after an edit session.</p>
<p>[<a target="_blank" name="ftn.d613e1948"></a><a target="_blank" href="#d613e1948" rel="nofollow"><span style="color:rgb(0,0,255)">11</span></a>] 参见 <a target="_blank" href="#hbase.regionserver.codecs" rel="nofollow" title="B.2.  hbase.regionserver.codecs"><span style="color:rgb(0,0,255)">Section B.2, “ hbase.regionserver.codecs ”</span></a> 可以看到关于LZO安装的具体信息，帮助你放在安装失败。</p>
<p>[<a target="_blank" name="ftn.d613e1974"></a><a target="_blank" href="#d613e1974" rel="nofollow"><span style="color:rgb(0,0,255)">12</span></a>] What follows is taken from the javadoc at the head of the org.apache.hadoop.hbase.util.RegionSplitter tool added to HBase post-0.90.0 release.</p>
<p><a target="_blank" name="shell"></a><span style="color:rgb(153,0,0)">Chapter 4. The HBase Shell</span></p>
<p>Table of Contents</p>
<p><a target="_blank" href="#scripting" rel="nofollow"><span style="color:rgb(0,0,255)">4.1. 使用脚本</span></a></p>
<p><a target="_blank" href="#shell_tricks" rel="nofollow"><span style="color:rgb(0,0,255)">4.2. Shell 技巧</span></a></p>
<p><a target="_blank" href="#d613e2127" rel="nofollow"><span style="color:rgb(0,0,255)">4.2.1. </span><span style="color:rgb(0,122,0)">irbrc</span></a></p>
<p><a target="_blank" href="#d613e2145" rel="nofollow"><span style="color:rgb(0,0,255)">4.2.2. LOG 时间转换</span></a></p>
<p><a target="_blank" href="#d613e2163" rel="nofollow"><span style="color:rgb(0,0,255)">4.2.3. Debug</span></a></p>
<p>Hbase Shell is 在<a target="_blank" href="http://jruby.org/" rel="nofollow"><span style="color:rgb(0,0,255)">(J)Ruby</span></a>的IRB的基础上加上了HBase的命令。任何你可以在IRB里做的事情都可在在Hbase Shell中做。</p>
<p>你可以这样来运行HBase Shell:</p>
<p>$ ./bin/hbase shell</p>
<p>输入 help 就会返回Shell的命令列表和选项。可以看看在Help文档尾部的关于如何输入变量和选项。尤其要注意的是表名，行，列名必须要加引号。</p>
<p>参见 <a target="_blank" href="#shell_exercises" rel="nofollow" title="1.2.3. Shell 练习"><span style="color:rgb(0,0,255)">Section 1.2.3, “Shell 练习”</span></a>可以看到Shell的基本使用例子。</p>
<p><a target="_blank" name="scripting"></a><span style="color:rgb(153,0,0)">4.1. 使用脚本</span></p>
<p>如果要使用脚本，可以看Hbase的<span style="color:rgb(0,122,0)">bin</span> 目录.在里面找到后缀为 <span style="color:rgb(0,122,0)">*.rb</span>的脚本.要想运行这个脚本，要这样</p>
<p>$ ./bin/hbase org.jruby.Main PATH_TO_SCRIPT</p>
<p>就可以了</p>
<p><a target="_blank" name="shell_tricks"></a><span style="color:rgb(153,0,0)">4.2. Shell 技巧</span></p>
<p><a target="_blank" name="d613e2127"></a><span style="color:rgb(153,0,0)">4.2.1. </span><span style="color:rgb(0,122,0)">irbrc</span></p>
<p>可以在你自己的Home目录下创建一个<span style="color:rgb(0,122,0)">.irbrc</span>文件. 在这个文件里加入自定义的命令。有一个有用的命令就是记录命令历史，这样你就可以把你的命令保存起来。</p>
<p>$ more .irbrc</p>
<p>require 'irb/ext/save-history'</p>
<p>IRB.conf[:SAVE_HISTORY] = 100</p>
<p>IRB.conf[:HISTORY_FILE] = "#{ENV['HOME']}/.irb-save-history"</p>
<p>可以参见 ruby 关于 <span style="color:rgb(0,122,0)">.irbrc</span> 的文档来学习更多的关于IRB的配置方法。</p>
<p><a target="_blank" name="d613e2145"></a><span style="color:rgb(153,0,0)">4.2.2. LOG 时间转换</span></p>
<p>可以将日期'08/08/16 20:56:29'从hbase log 转换成一个 timestamp, 操作如下:</p>
<p>hbase(main):021:0&gt; import java.text.SimpleDateFormat</p>
<p>hbase(main):022:0&gt; import java.text.ParsePosition</p>
<p>hbase(main):023:0&gt; SimpleDateFormat.new("yy/MM/dd HH:mm:ss").parse("08/08/16 20:56:29", ParsePosition.new(0)).getTime() =&gt; 1218920189000</p>
<p>也可以逆过来操作。</p>
<p>hbase(main):021:0&gt; import java.util.Date</p>
<p>hbase(main):022:0&gt; Date.new(1218920189000).toString() =&gt; "Sat Aug 16 20:56:29 UTC 2008"</p>
<p>要想把日期格式和Hbase log格式完全相同，可以参见文档 <a target="_blank" href="http://download.oracle.com/javase/6/docs/api/java/text/SimpleDateFormat.html" rel="nofollow"><span style="color:rgb(0,0,255)">SimpleDateFormat</span></a>.</p>
<p><a target="_blank" name="d613e2163"></a><span style="color:rgb(153,0,0)">4.2.3. Debug</span></p>
<p><a target="_blank" name="d613e2166"></a><span style="color:rgb(153,0,0)">4.2.3.1. Shell 切换成debug 模式</span></p>
<p>你可以将shell切换成debug模式。这样可以看到更多的信息。 -- 例如可以看到命令异常的stack trace:</p>
<p>hbase&gt; debug &lt;RETURN&gt;</p>
<p><a target="_blank" name="d613e2174"></a><span style="color:rgb(153,0,0)">4.2.3.2. DEBUG log level</span></p>
<p>想要在shell中看到 DEBUG 级别的 logging ，可以在启动的时候加上 -d 参数.</p>
<p>$ ./bin/hbase shell -d</p>
<p><a target="_blank" name="build"></a><span style="color:rgb(153,0,0)">Chapter 5. 构建 HBase</span></p>
<p>Table of Contents</p>
<p><a target="_blank" href="#mvn_repo" rel="nofollow"><span style="color:rgb(0,0,255)">5.1. 将一个 HBase release 加入到 Apache's Maven Repository</span></a></p>
<p><a target="_blank" name="mvn_repo"></a><span style="color:rgb(153,0,0)">5.1. 将一个 HBase release 加入到 Apache's Maven Repository</span></p>
<p>可以参考 <a target="_blank" href="http://www.apache.org/dev/publishing-maven-artifacts.html" rel="nofollow"><span style="color:rgb(0,0,255)">发布 Maven Artifacts</span></a>的信息.要想让所有的组件正确运行，关键在于配置好mvn release plugin。确保你在运行mvn release:perform之前使用的是正确的分支版本。这点非常的重要，要手写${HBASE_HOME}下的release.properties文件，然后执行release:perform.。你需要编辑它，这样才能将他指向一个正确的SVN地址。(译者注：可以使用cloudera)</p>
<p>如果你出现了如下的问题，是因为你需要在pom.xml里编辑版本然后加上 -SNAPSHOT 。</p>
<p>[INFO] Scanning for projects...</p>
<p>[INFO] Searching repository for plugin with prefix: 'release'.</p>
<p>[INFO] ------------------------------------------------------------------------</p>
<p>[INFO] Building HBase</p>
<p>[INFO]    task-segment: [release:prepare] (aggregator-style)</p>
<p>[INFO] ------------------------------------------------------------------------</p>
<p>[INFO] [release:prepare {execution: default-cli}]</p>
<p>[INFO] ------------------------------------------------------------------------</p>
<p>[ERROR] BUILD FAILURE</p>
<p>[INFO] ------------------------------------------------------------------------</p>
<p>[INFO] You don't have a SNAPSHOT project in the reactor projects list.</p>
<p>[INFO] ------------------------------------------------------------------------</p>
<p>[INFO] For more information, run Maven with the -e switch</p>
<p>[INFO] ------------------------------------------------------------------------</p>
<p>[INFO] Total time: 3 seconds</p>
<p>[INFO] Finished at: Sat Mar 26 18:11:07 PDT 2011</p>
<p>[INFO] Final Memory: 35M/423M</p>
<p>[INFO] -----------------------------------------------------------------------</p>
<p><span style="color:rgb(153,0,0)">Chapter 6. Developers</span></p>
<p>Table of Contents</p>
<p><a target="_blank" href="#ides" rel="nofollow"><span style="color:rgb(0,0,255)">6.1. IDEs</span></a></p>
<p><a target="_blank" href="#eclipse" rel="nofollow"><span style="color:rgb(0,0,255)">6.1.1. Eclipse</span></a></p>
<p><a target="_blank" href="#unit.tests" rel="nofollow"><span style="color:rgb(0,0,255)">6.2. 单元测试</span></a></p>
<p><a target="_blank" href="#mockito" rel="nofollow"><span style="color:rgb(0,0,255)">6.2.1. Mocito</span></a></p>
<p><a target="_blank" name="ides"></a><span style="color:rgb(153,0,0)">6.1. IDEs</span></p>
<p><a target="_blank" name="eclipse"></a><span style="color:rgb(153,0,0)">6.1.1. Eclipse</span></p>
<p>参见 <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE-3678" rel="nofollow"><span style="color:rgb(0,0,255)">HBASE-3678 Add Eclipse-based Apache Formatter to HBase Wiki</span></a>可以看到一个eclipse的格式化文件，可以帮你把编码转换成符合Hbase的格式。这个issue还包含有使用这个formatter的指导。</p>
<p><a target="_blank" name="unit.tests"></a><span style="color:rgb(153,0,0)">6.2. 单元测试</span></p>
<p>我们在Hbase中使用<a target="_blank" href="http://junit.org/" rel="nofollow"><span style="color:rgb(0,0,255)">JUnit</span></a> 4. 如果你希望跑一个最小化的HDFS, ZooKeeper, HBase, 或者 MapReduce 测试,可以checkoutHBaseTestingUtility. Alex Baranau of Sematext 阐述了怎么使用它 <a target="_blank" href="http://blog.sematext.com/2010/08/30/hbase-case-study-using-hbasetestingutility-for-local-testing-development/" rel="nofollow"><span style="color:rgb(0,0,255)">HBase Case-Study: Using HBaseTestingUtility for Local Testing and Development</span></a> (2010).</p>
<p><a target="_blank" name="mockito"></a><span style="color:rgb(153,0,0)">6.2.1. Mocito</span></p>
<p>有些时候你不需要运行一个完全的running server单元测试。比如一些操作org.apache.hadoop.hbase.Server 实例的方法或者使用 org.apache.hadoop.hbase.master.MasterServices 接口而不是 org.apache.hadoop.hbase.master.HMaster类的应用. 这些情况下，你可以不必使用 mocked Server 实例. 比如:</p>
<p>(<span style="font-family:宋体">译者注</span><span style="font-family:Courier New">:</span><span style="font-family:宋体">原文到此为止</span><span style="font-family:Courier New">)</span></p>
<p> </p>
<p><a target="_blank" name="mapreduce"></a><span style="color:rgb(153,0,0)">Chapter 7. HBase 和 MapReduce</span></p>
<p>Table of Contents</p>
<p><a target="_blank" href="#splitter" rel="nofollow"><span style="color:rgb(0,0,255)">7.1. 默认 HBase MapReduce 分割器(Splitter)</span></a></p>
<p><a target="_blank" href="#mapreduce.example" rel="nofollow"><span style="color:rgb(0,0,255)">7.2. HBase Input MapReduce 例子</span></a></p>
<p><a target="_blank" href="#mapreduce.htable.access" rel="nofollow"><span style="color:rgb(0,0,255)">7.3. 在一个MapReduce Job中访问其他的HBase Tables</span></a></p>
<p><a target="_blank" href="#mapreduce.specex" rel="nofollow"><span style="color:rgb(0,0,255)">7.4. 预测执行</span></a></p>
<p>关于 <a target="_blank" href="#package_description" rel="nofollow"><span style="color:rgb(0,0,255)">HBase 和 MapReduce</span></a>详见 javadocs. 下面是一些附加的帮助文档.</p>
<p><a target="_blank" name="splitter"></a><span style="color:rgb(153,0,0)">7.1. 默认 HBase MapReduce 分割器(Splitter)</span></p>
<p>当 MapReduce job的HBase table 使用<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableInputFormat.html" rel="nofollow"><span style="color:rgb(0,0,255)">TableInputFormat</span></a>为数据源格式的时候,他的splitter会给这个table的每个region一个map。因此，如果一个table有100个region，就有100个map-tasks，不论需要scan多少个column families 。</p>
<p><a target="_blank" name="mapreduce.example"></a><span style="color:rgb(153,0,0)">7.2. HBase Input MapReduce 例子</span></p>
<p>要想使HBase作为MapReduce的source,Job需要使用<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.html" rel="nofollow"><span style="color:rgb(0,0,255)">TableMapReduceUtil</span></a>来配置，如下所示...</p>
<p>Job job = ...;</p>
<p>Scan scan = new Scan();</p>
<p>scan.setCaching(500);  // 1 is the default in Scan, which will be bad for MapReduce jobs</p>
<p>scan.setCacheBlocks(false);</p>
<p>// Now set other scan attrs</p>
<p>...</p>
<p> </p>
<p>TableMapReduceUtil.initTableMapperJob(</p>
<p>tableName,    // input HBase table name</p>
<p>scan,  // Scan instance to control CF and attribute selection</p>
<p>MyMapper.class, // mapper</p>
<p>Text.class, // reducer key</p>
<p>LongWritable.class, // reducer value</p>
<p>job // job instance</p>
<p>);</p>
<p>...mapper需要继承于<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableMapper.html" rel="nofollow"><span style="color:rgb(0,0,255)">TableMapper</span></a>...</p>
<p>public class MyMapper extends TableMapper&lt;Text, LongWritable&gt; {</p>
<p>public void map(ImmutableBytesWritable row, Result value, Context context)</p>
<p>throws InterruptedException, IOException {</p>
<p>// process data for the row from the Result instance.</p>
<p><a target="_blank" name="mapreduce.htable.access"></a><span style="color:rgb(153,0,0)">7.3. 在一个MapReduce Job中访问其他的HBase Tables</span></p>
<p>尽管现有的框架允许一个HBase table作为一个MapReduce job的输入，其他的Hbase table可以同时作为普通的表被访问。例如在一个MapReduce的job中，可以在Mapper的setup方法中创建HTable实例。</p>
<p>public class MyMapper extends TableMapper&lt;Text, LongWritable&gt; {</p>
<p>private HTable myOtherTable;</p>
<p> </p>
<p>@Override</p>
<p>public void setup(Context context) {</p>
<p>myOtherTable = new HTable("myOtherTable");</p>
<p>}</p>
<p><a target="_blank" name="mapreduce.specex"></a><span style="color:rgb(153,0,0)">7.4. 预测执行</span></p>
<p>通常建议关掉针对HBase的MapReduce job的预测执行(speculative execution)功能。这个功能也可以用每个Job的配置来完成。对于整个集群，使用预测执行意味着双倍的运算量。这可不是你所希望的。</p>
<p><a target="_blank" name="schema"></a><span style="color:rgb(153,0,0)">Chapter 8. HBase 的 Schema 设计</span></p>
<p>Table of Contents</p>
<p><a target="_blank" href="#schema.creation" rel="nofollow"><span style="color:rgb(0,0,255)">8.1. Schema 创建 </span></a></p>
<p><a target="_blank" href="#number.of.cfs" rel="nofollow"><span style="color:rgb(0,0,255)">8.2. column families的数量 </span></a></p>
<p><a target="_blank" href="#timeseries" rel="nofollow"><span style="color:rgb(0,0,255)">8.3. 单调递增Row Keys/时序数据(log) </span></a></p>
<p><a target="_blank" href="#keysize" rel="nofollow"><span style="color:rgb(0,0,255)">8.4. 尽量最小化row和column的大小</span></a></p>
<p><a target="_blank" href="#schema.versions" rel="nofollow"><span style="color:rgb(0,0,255)">8.5. 版本的时间 </span></a></p>
<p>有一个关于NSQL数据库的优点和确定的介绍， <a target="_blank" href="http://ianvarley.com/UT/MR/Varley_MastersReport_Full_2009-08-07.pdf" rel="nofollow"><span style="color:rgb(0,0,255)">No Relation: The Mixed Blessings of Non-Relational Databases</span></a>. 推荐看一看.</p>
<p><a target="_blank" name="schema.creation"></a><span style="color:rgb(153,0,0)">8.1.  Schema 创建</span></p>
<p>可以使用<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HBaseAdmin.html" rel="nofollow"><span style="color:rgb(0,0,255)">HBaseAdmin</span></a>或者<a target="_blank" href="#shell" rel="nofollow" title="Chapter 4. The HBase Shell"><span style="color:rgb(0,0,255)">Chapter 4, </span><span style="color:rgb(0,0,255)">The HBase Shell</span></a> 来创建和编辑Hbase的schemas</p>
<p><a target="_blank" name="number.of.cfs"></a><span style="color:rgb(153,0,0)">8.2.  column families的数量</span></p>
<p>现在Hbase并不能很好的处理两个或者三个以上的column families，所以尽量让你的column families数量少一些。目前，flush和compaction操作是针对一个Region。所以当一个column family操作大量数据的时候会引发一个flush。那些不相关的column families也有进行flush操作，尽管他们没有操作多少数据。Compaction操作现在是根据一个column family下的全部文件的数量触发的，而不是根据文件大小触发的。当很多的column families在flush和compaction时,会造成很多没用的I/O负载(要想解决这个问题，需要将flush和compaction操作只针对一个column family)</p>
<p>尽量在你的应用中使用一个Column family。只有你的所有查询操作只访问一个column family的时候，可以引入第二个和第三个column family.例如，你有两个column family,但你查询的时候总是访问其中的一个，从来不会两个一起访问。</p>
<p><a target="_blank" name="timeseries"></a><span style="color:rgb(153,0,0)">8.3.  单调递增Row Keys/时序数据(log)</span></p>
<p>在Tom White的Hadoop: The Definitive Guide一书中，有一个章节描述了一个值得注意的问题：在一个集群中，一个导入数据的进程一动不动，所以的client都在等待一个region(就是一个节点)，过了一会后，变成了下一个region...如果使用了单调递增或者时序的key就会造成这样的问题。详情可以参见IKai画的漫画<a target="_blank" href="http://ikaisays.com/2011/01/25/app-engine-datastore-tip-monotonically-increasing-values-are-bad/" rel="nofollow"><span style="color:rgb(0,0,255)">monotonically increasing values are bad</span></a>。使用了顺序的key会将本没有顺序的数据变得有顺序，把负载压在一台机器上。所以要尽量避免时间戳或者(e.g. 1, 2, 3)这样的key。</p>
<p>如果你需要导入时间顺序的文件(如log)到Hbase中，可以学习<a target="_blank" href="http://opentsdb.net/" rel="nofollow"><span style="color:rgb(0,0,255)">OpenTSDB</span></a>的做法。他有一个页面来描述他的<a target="_blank" href="http://www.yankay.com/wp-cont/hbase/%20http:/opentsdb.net/schema.html" rel="nofollow"><span style="color:rgb(0,0,255)">schema</span></a>.OpenTSDB的Key的格式是[metric_type][event_timestamp]，乍一看，似乎违背了不将timestamp做key的建议，但是他并没有将timestamp作为key的一个关键位置，有成百上千的metric_type就足够将压力分散到各个region了。</p>
<p><a target="_blank" name="keysize"></a><span style="color:rgb(153,0,0)">8.4. 尽量最小化row和column的大小</span></p>
<p>在Hbase中，值是作为一个cell保存在系统的中的，要定位一个cell,需要row,column name和timestamp.通常情况下，如果你的row和column的名字要是太大(甚至比value的大小还要大)的话，你可能会遇到一些有趣的情况。例如Marc Limotte 在 <a target="_blank" href="#comment-13005272" rel="nofollow"><span style="color:rgb(0,0,255)">HBASE-3551</span></a>(recommended!)尾部提到的现象。在Hbase的存储文件<a target="_blank" href="#hfile" rel="nofollow" title="12.3.4.2. StoreFile (HFile)"><span style="color:rgb(0,0,255)">Section 12.3.4.2, “StoreFile (HFile)”</span></a>中，有一个索引用来方便value的随机访问，但是访问一个cell的坐标要是太大的话，会占用很大的内存，这个索引会被用尽。所以要想解决，可以设置一个更大的block size，当然也可以使用更小的column name `</p>
<p><a target="_blank" name="schema.versions"></a><span style="color:rgb(153,0,0)">8.5.  版本的时间</span></p>
<p>行的版本的数量是<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HColumnDescriptor.html" rel="nofollow"><span style="color:rgb(0,0,255)">HColumnDescriptor</span></a>设置的，每个column family可以单独设置，默认是3.这个设置是很重要的，在<a target="_blank" href="#datamodel" rel="nofollow" title="Chapter 11. 数据模型"><span style="color:rgb(0,0,255)">Chapter 11, </span><span style="color:rgb(0,0,255)">数据模型</span></a>有描述，因为Hbase是不会去覆盖一个值的，他只会在后面在追加写，用timestamp来区分、过早的版本会在执行major compaction的时候删除。这个版本的值可以根据具体的应用增加减少。</p>
<p><a target="_blank" name="hbase_metrics"></a><span style="color:rgb(153,0,0)">Chapter 9. Metrics</span></p>
<p>Table of Contents</p>
<p><a target="_blank" href="#metric_setup" rel="nofollow"><span style="color:rgb(0,0,255)">9.1. Metric 安装</span></a></p>
<p><a target="_blank" href="#rs_metrics" rel="nofollow"><span style="color:rgb(0,0,255)">9.2. RegionServer Metrics</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.blockCacheCount" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.1. hbase.regionserver.blockCacheCount</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.blockCacheFree" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.2. hbase.regionserver.blockCacheFree</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.blockCacheHitRatio" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.3. hbase.regionserver.blockCacheHitRatio</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.blockCacheSize" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.4. hbase.regionserver.blockCacheSize</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.compactionQueueSize" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.5. hbase.regionserver.compactionQueueSize</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.fsReadLatency_avg_time" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.6. hbase.regionserver.fsReadLatency_avg_time</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.fsReadLatency_num_ops" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.7. hbase.regionserver.fsReadLatency_num_ops</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.fsSyncLatency_avg_time" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.8. hbase.regionserver.fsSyncLatency_avg_time</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.fsSyncLatency_num_ops" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.9. hbase.regionserver.fsSyncLatency_num_ops</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.fsWriteLatency_avg_time" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.10. hbase.regionserver.fsWriteLatency_avg_time</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.fsWriteLatency_num_ops" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.11. hbase.regionserver.fsWriteLatency_num_ops</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.memstoreSizeMB" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.12. hbase.regionserver.memstoreSizeMB</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.regions" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.13. hbase.regionserver.regions</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.requests" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.14. hbase.regionserver.requests</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.storeFileIndexSizeMB" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.15. hbase.regionserver.storeFileIndexSizeMB</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.stores" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.16. hbase.regionserver.stores</span></a></p>
<p><a target="_blank" href="#hbase.regionserver.storeFiles" rel="nofollow"><span style="color:rgb(0,0,255)">9.2.17. hbase.regionserver.storeFiles</span></a></p>
<p><a target="_blank" name="metric_setup"></a><span style="color:rgb(153,0,0)">9.1. Metric 安装</span></p>
<p>参见 <a target="_blank" href="http://hbase.apache.org/metrics.html" rel="nofollow"><span style="color:rgb(0,0,255)">Metrics</span></a> 可以获得一个enable Metrics emission的指导。</p>
<p><a target="_blank" name="rs_metrics"></a><span style="color:rgb(153,0,0)">9.2. RegionServer Metrics</span></p>
<p><a target="_blank" name="hbase.regionserver.blockCacheCount"></a><span style="color:rgb(153,0,0)">9.2.1. </span><span style="color:rgb(153,0,0)">hbase.regionserver.blockCacheCount</span></p>
<p>内存中的Block cache item数量。这个是存储文件(HFiles)的缓存中的数量。</p>
<p><a target="_blank" name="hbase.regionserver.blockCacheFree"></a><span style="color:rgb(153,0,0)">9.2.2. </span><span style="color:rgb(153,0,0)">hbase.regionserver.blockCacheFree</span></p>
<p>内存中的Block cache memory 剩余 (单位 bytes).</p>
<p><a target="_blank" name="hbase.regionserver.blockCacheHitRatio"></a><span style="color:rgb(153,0,0)">9.2.3. </span><span style="color:rgb(153,0,0)">hbase.regionserver.blockCacheHitRatio</span></p>
<p>Block cache 命中率(0 到 100). TODO: 描述当cacheBlocks=false时对这个值得影响</p>
<p><a target="_blank" name="hbase.regionserver.blockCacheSize"></a><span style="color:rgb(153,0,0)">9.2.4. </span><span style="color:rgb(153,0,0)">hbase.regionserver.blockCacheSize</span></p>
<p>内存中的Block cache 大小 (单位 bytes)</p>
<p><a target="_blank" name="hbase.regionserver.compactionQueueSize"></a><span style="color:rgb(153,0,0)">9.2.5. </span><span style="color:rgb(153,0,0)">hbase.regionserver.compactionQueueSize</span></p>
<p>compaction队列的大小. 这个值是需要进行compaction的region数目</p>
<p><a target="_blank" name="hbase.regionserver.fsReadLatency_avg_tim"></a><span style="color:rgb(153,0,0)">9.2.6. </span><span style="color:rgb(153,0,0)">hbase.regionserver.fsReadLatency_avg_time</span></p>
<p>文件系统延迟 (ms). 这个值是平均读HDFS的延迟时间</p>
<p><a target="_blank" name="hbase.regionserver.fsReadLatency_num_ops"></a><span style="color:rgb(153,0,0)">9.2.7. </span><span style="color:rgb(153,0,0)">hbase.regionserver.fsReadLatency_num_ops</span></p>
<p>TODO</p>
<p><a target="_blank" name="hbase.regionserver.fsSyncLatency_avg_tim"></a><span style="color:rgb(153,0,0)">9.2.8. </span><span style="color:rgb(153,0,0)">hbase.regionserver.fsSyncLatency_avg_time</span></p>
<p>文件系统同步延迟(ms)</p>
<p><a target="_blank" name="hbase.regionserver.fsSyncLatency_num_ops"></a><span style="color:rgb(153,0,0)">9.2.9. </span><span style="color:rgb(153,0,0)">hbase.regionserver.fsSyncLatency_num_ops</span></p>
<p>TODO</p>
<p><a target="_blank" name="hbase.regionserver.fsWriteLatency_avg_ti"></a><span style="color:rgb(153,0,0)">9.2.10. </span><span style="color:rgb(153,0,0)">hbase.regionserver.fsWriteLatency_avg_time</span></p>
<p>文件系统写延迟(ms)</p>
<p><a target="_blank" name="hbase.regionserver.fsWriteLatency_num_op"></a><span style="color:rgb(153,0,0)">9.2.11. </span><span style="color:rgb(153,0,0)">hbase.regionserver.fsWriteLatency_num_ops</span></p>
<p>TODO</p>
<p><a target="_blank" name="hbase.regionserver.memstoreSizeMB"></a><span style="color:rgb(153,0,0)">9.2.12. </span><span style="color:rgb(153,0,0)">hbase.regionserver.memstoreSizeMB</span></p>
<p>所有的RegionServer的memstore大小 (MB)</p>
<p><a target="_blank" name="hbase.regionserver.regions"></a><span style="color:rgb(153,0,0)">9.2.13. </span><span style="color:rgb(153,0,0)">hbase.regionserver.regions</span></p>
<p>RegionServer服务的regions数量</p>
<p><a target="_blank" name="hbase.regionserver.requests"></a><span style="color:rgb(153,0,0)">9.2.14. </span><span style="color:rgb(153,0,0)">hbase.regionserver.requests</span></p>
<p>读写请求的全部数量。请求是指RegionServer的RPC数量，因此一次Get一个情况，一个带缓存的Scan也是一个请求。一个批量load是一个Hfile一个请求。</p>
<p><a target="_blank" name="hbase.regionserver.storeFileIndexSizeMB"></a><span style="color:rgb(153,0,0)">9.2.15. </span><span style="color:rgb(153,0,0)">hbase.regionserver.storeFileIndexSizeMB</span></p>
<p>当前RegionServer的storefile索引的总大小(MB)</p>
<p><a target="_blank" name="hbase.regionserver.stores"></a><span style="color:rgb(153,0,0)">9.2.16. </span><span style="color:rgb(153,0,0)">hbase.regionserver.stores</span></p>
<p>RegionServer打开的stores数量。一个stores对应一个column family。例如，一个表有3个region在这个RegionServer上，对应一个 column family就会有3个store.</p>
<p><a target="_blank" name="hbase.regionserver.storeFiles"></a><span style="color:rgb(153,0,0)">9.2.17. </span><span style="color:rgb(153,0,0)">hbase.regionserver.storeFiles</span></p>
<p>RegionServer打开的存储文件(HFile)数量。这个值一定大于等于store的数量。</p>
<p><a target="_blank" name="cluster_replication"></a><span style="color:rgb(153,0,0)">Chapter 10. 跨集群复制</span></p>
<p>参见 <a target="_blank" href="http://hbase.apache.org/replication.html" rel="nofollow"><span style="color:rgb(0,0,255)">跨集群复制</span></a>.</p>
<p><a target="_blank" name="datamodel"></a><span style="color:rgb(153,0,0)">Chapter 11. 数据模型</span></p>
<p>Table of Contents</p>
<p><a target="_blank" href="#conceptual.view" rel="nofollow"><span style="color:rgb(0,0,255)">11.1. 概念视图</span></a></p>
<p><a target="_blank" href="#physical.view" rel="nofollow"><span style="color:rgb(0,0,255)">11.2. 物理视图</span></a></p>
<p><a target="_blank" href="#table" rel="nofollow"><span style="color:rgb(0,0,255)">11.3. 表</span></a></p>
<p><a target="_blank" href="#row" rel="nofollow"><span style="color:rgb(0,0,255)">11.4. 行</span></a></p>
<p><a target="_blank" href="#columnfamily" rel="nofollow"><span style="color:rgb(0,0,255)">11.5. Column Family</span></a></p>
<p><a target="_blank" href="#cells" rel="nofollow"><span style="color:rgb(0,0,255)">11.6. Cells</span></a></p>
<p><a target="_blank" href="#versions" rel="nofollow"><span style="color:rgb(0,0,255)">11.7. 版本</span></a></p>
<p><a target="_blank" href="#versions.ops" rel="nofollow"><span style="color:rgb(0,0,255)">11.7.1. Hbase的操作(包含版本操作)</span></a></p>
<p><a target="_blank" href="#d613e2965" rel="nofollow"><span style="color:rgb(0,0,255)">11.7.2. 现有的限制</span></a></p>
<p>简单来说，应用程序是以表的方式在Hbase存储数据的。表是由行和列构成的，所以的列是从属于某一个column family的。行和列的交叉点称之为cell,cell是版本化的。cell的内容是不可分割的字节数组。</p>
<p>表的row key也是一段字节数组，所以任何东西都可以保存进去，不论是字符串或者数字。Hbase的表是按key排序的，排序方式之针对字节的。所以的表都必须要有主键-key.</p>
<p><a target="_blank" name="conceptual.view"></a><span style="color:rgb(153,0,0)">11.1. 概念视图</span></p>
<p>下面是根据<a target="_blank" href="http://labs.google.com/papers/bigtable.html" rel="nofollow"><span style="color:rgb(0,0,255)">BigTable</span></a> 论文稍加修改的例子。有一个名为webtable的表，包含两个column family：contents和anchor.在这个例子里面，anchor有两个列 (anchor:cssnsi.com, anchor:my.look.ca)，contents仅有一列(contents:html)</p>
<p><span style="color:rgb(153,0,0)">列名</span></p>
<p>一个列名是有它的column family前缀和qualifier连接而成。例如列contents:html是column family contents加冒号(:)加 qualifier html组成的。</p>
<p><a target="_blank" name="d613e2561"></a><span style="color:rgb(153,0,0)">Table 11.1. 表 webtable</span></p>
<table>
<tbody>
<tr>
<td valign="center">
<p>Row Key</p>
</td>
<td valign="center">
<p>Time Stamp</p>
</td>
<td valign="center">
<p>ColumnFamily contents</p>
</td>
<td valign="center">
<p>ColumnFamily anchor</p>
</td>
</tr>
<tr>
<td valign="center">
<p>"com.cnn.www"</p>
</td>
<td valign="center">
<p>t9</p>
</td>
<td valign="center">
<p> </p>
</td>
<td valign="center">
<p>anchor:cnnsi.com = "CNN"</p>
</td>
</tr>
<tr>
<td valign="center">
<p>"com.cnn.www"</p>
</td>
<td valign="center">
<p>t8</p>
</td>
<td valign="center">
<p> </p>
</td>
<td valign="center">
<p>anchor:my.look.ca = "CNN.com"</p>
</td>
</tr>
<tr>
<td valign="center">
<p>"com.cnn.www"</p>
</td>
<td valign="center">
<p>t6</p>
</td>
<td valign="center">
<p>contents:html = "&lt;html&gt;..."</p>
</td>
<td valign="center">
<p> </p>
</td>
</tr>
<tr>
<td valign="center">
<p>"com.cnn.www"</p>
</td>
<td valign="center">
<p>t5</p>
</td>
<td valign="center">
<p>contents:html = "&lt;html&gt;..."</p>
</td>
<td valign="center">
<p> </p>
</td>
</tr>
<tr>
<td valign="center">
<p>"com.cnn.www"</p>
</td>
<td valign="center">
<p>t3</p>
</td>
<td valign="center">
<p>contents:html = "&lt;html&gt;..."</p>
</td>
<td valign="center">
<p> </p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p><a target="_blank" name="physical.view"></a><span style="color:rgb(153,0,0)">11.2. 物理视图</span></p>
<p>尽管在概念视图里，表可以被看成是一个稀疏的行的集合。但在物理上，它的是区分column family 存储的。新的columns可以不经过声明直接加入一个column family.</p>
<p><a target="_blank" name="d613e2642"></a><span style="color:rgb(153,0,0)">Table 11.2. ColumnFamily anchor</span></p>
<table>
<tbody>
<tr>
<td valign="center">
<p>Row Key</p>
</td>
<td valign="center">
<p>Time Stamp</p>
</td>
<td valign="center">
<p>Column Family anchor</p>
</td>
</tr>
<tr>
<td valign="center">
<p>"com.cnn.www"</p>
</td>
<td valign="center">
<p>t9</p>
</td>
<td valign="center">
<p>anchor:cnnsi.com = "CNN"</p>
</td>
</tr>
<tr>
<td valign="center">
<p>"com.cnn.www"</p>
</td>
<td valign="center">
<p>t8</p>
</td>
<td valign="center">
<p>anchor:my.look.ca = "CNN.com"</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p><a target="_blank" name="d613e2681"></a><span style="color:rgb(153,0,0)">Table 11.3. ColumnFamily contents</span></p>
<table>
<tbody>
<tr>
<td valign="center">
<p>Row Key</p>
</td>
<td valign="center">
<p>Time Stamp</p>
</td>
<td valign="center">
<p>ColumnFamily "contents:"</p>
</td>
</tr>
<tr>
<td valign="center">
<p>"com.cnn.www"</p>
</td>
<td valign="center">
<p>t6</p>
</td>
<td valign="center">
<p>contents:html = "&lt;html&gt;..."</p>
</td>
</tr>
<tr>
<td valign="center">
<p>"com.cnn.www"</p>
</td>
<td valign="center">
<p>t5</p>
</td>
<td valign="center">
<p>contents:html = "&lt;html&gt;..."</p>
</td>
</tr>
<tr>
<td valign="center">
<p>"com.cnn.www"</p>
</td>
<td valign="center">
<p>t3</p>
</td>
<td valign="center">
<p>contents:html = "&lt;html&gt;..."</p>
</td>
</tr>
</tbody>
</table>
<p><br>
值得注意的是在上面的概念视图中空白cell在物理上是不存储的，因为根本没有必要存储。因此若一个请求为要获取t8时间的contents:html，他的结果就是空。相似的，若请求为获取t9时间的anchor:my.look.ca，结果也是空。但是，如果不指明时间，将会返回最新时间的行，每个最新的都会返回。例如，如果请求为获取row key为"com.cnn.www"，没有指明时间戳的话，活动的结果是t6下的contents:html，t9下的anchor:cnnsi.com和t8下anchor:my.look.ca。</p>
<p><a target="_blank" name="table"></a><span style="color:rgb(153,0,0)">11.3. 表</span></p>
<p>表是在schema声明的时候定义的。</p>
<p><a target="_blank" name="row"></a><span style="color:rgb(153,0,0)">11.4. 行</span></p>
<p>row key是不可分割的字节数组。行是按字典排序由低到高存储在表中的。一个空的数组是用来标识表空间的起始或者结尾。</p>
<p><a target="_blank" name="columnfamily"></a><span style="color:rgb(153,0,0)">11.5. Column Family<a target="_blank" name="d613e2767"></a></span></p>
<p>在Hbase是column family一些列的集合。一个column family所有列成员是有着相同的前缀。比如，列courses:history 和 courses:math都是 column family courses的成员.冒号(:)是column family的分隔符，用来区分前缀和列名。column 前缀必须是可打印的字符，剩下的部分(称为qualify),可以又任意字节数组组成。column family必须在表建立的时候声明。column就不需要了，随时可以新建。</p>
<p>在物理上，一个的column family成员在文件系统上都是存储在一起。因为存储优化都是针对column family级别的，这就意味着，一个colimn family的所有成员的是用相同的方式访问的。</p>
<p><a target="_blank" name="cells"></a><span style="color:rgb(153,0,0)">11.6. Cells<a target="_blank" name="d613e2790"></a></span></p>
<p>A {row, column, version} 元组就是一个Hbase中的一个 cell。Cell的内容是不可分割的字节数组。</p>
<p><a target="_blank" name="versions"></a><span style="color:rgb(153,0,0)">11.7. 版本<a target="_blank" name="d613e2804"></a></span></p>
<p>一个 {row, column, version} 元组是Hbase中的一个cell .但是有可能会有很多的cell的row和column是相同的，可以使用version来区分不同的cell.</p>
<p>rows和column key是用字节数组表示的，version则是用一个长整型表示。这个long的值使用 java.util.Date.getTime() 或者 System.currentTimeMillis()产生的。这就意味着他的含义是“当前时间和1970-01-01 UTC的时间差，单位毫秒。”</p>
<p>在Hbase中，版本是按倒序排列的，因此当读取这个文件的时候，最先找到的是最近的版本。</p>
<p>有些人不是很理解Hbase的 cell 意思。一个常见的问题是:</p>
<p>· 如果有多个包含版本写操作同时发起，Hbase会保存全部还是会保持最新的一个？[<a target="_blank" name="d613e2836"></a><a target="_blank" href="#ftn.d613e2836" rel="nofollow"><span style="color:rgb(0,0,255)">13</span></a>]</p>
<p>· 可以发起包含版本的写操作，但是他们的版本顺序和操作顺序相反吗?[<a target="_blank" name="d613e2842"></a><a target="_blank" href="#ftn.d613e2842" rel="nofollow"><span style="color:rgb(0,0,255)">14</span></a>]</p>
<p>下面我们介绍下在Hbase中版本是如何工作的。[<a target="_blank" name="d613e2847"></a><a target="_blank" href="#ftn.d613e2847" rel="nofollow"><span style="color:rgb(0,0,255)">15</span></a>].</p>
<p><a target="_blank" name="versions.ops"></a><span style="color:rgb(153,0,0)">11.7.1. Hbase的操作(包含版本操作)</span></p>
<p>在这一章我们来仔细看看在Hbase的各个主要操作中版本起到了什么作用。</p>
<p><a target="_blank" name="d613e2865"></a><span style="color:rgb(153,0,0)">11.7.1.1. Get/Scan</span></p>
<p>Gets实在Scan的基础上实现的。可以详细参见下面的讨论 <a target="_blank" href="http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/Get.html" rel="nofollow"><span style="color:rgb(0,0,255)">Get</span></a> 同样可以用 <a target="_blank" href="http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/Scan.html" rel="nofollow"><span style="color:rgb(0,0,255)">Scan</span></a>来描述.</p>
<p>默认情况下，如果你没有指定版本，当你使用Get操作的时候，会返回最近版本的Cell(该Cell可能是最新写入的，但不能保证)。默认的操作可以这样修改:</p>
<p>· 如果想要返回返回两个以上的把版本,参见<a target="_blank" href="#setMaxVersions()" rel="nofollow"><span style="color:rgb(0,0,255)">Get.setMaxVersions()</span></a></p>
<p>· 如果想要返回的版本不只是最近的，参见 <a target="_blank" href="http://www.yankay.com/wp-cont/hbase/???" rel="nofollow"><span style="color:rgb(0,0,255)">Get.setTimeRange()</span></a></p>
<p>要向查询的最新版本要小于或等于给定的这个值，这就意味着给定的'最近'的值可以是某一个时间点。可以使用0到你想要的时间来设置，还要把max versions设置为1.</p>
<p><a target="_blank" name="default_get_example"></a><span style="color:rgb(153,0,0)">11.7.1.2. 默认 Get 例子</span></p>
<p>下面的Get操作会只获得最新的一个版本。</p>
<p>Get get = new Get(Bytes.toBytes("row1"));</p>
<p>Result r = htable.get(get);</p>
<p>byte[] b = r.getValue(Bytes.toBytes("cf"), Bytes.toBytes("attr"));  // returns current version of value</p>
<p><a target="_blank" name="versioned_get_example"></a><span style="color:rgb(153,0,0)">11.7.1.3. 含有的版本的Get例子</span></p>
<p>下面的Get操作会获得最近的3个版本。</p>
<p>Get get = new Get(Bytes.toBytes("row1"));</p>
<p>get.setMaxVersions(3);  // will return last 3 versions of row</p>
<p>Result r = htable.get(get);</p>
<p>byte[] b = r.getValue(Bytes.toBytes("cf"), Bytes.toBytes("attr"));  // returns current version of value</p>
<p>List&lt;KeyValue&gt; kv = r.getColumn(Bytes.toBytes("cf"), Bytes.toBytes("attr"));  // returns all versions of this column</p>
<p> </p>
<p><a target="_blank" name="put_operation"></a><span style="color:rgb(153,0,0)">11.7.1.4. Put</span></p>
<p>一个Put操作会给一个cell,创建一个版本，默认使用当前时间戳，当然你也可以自己设置时间戳。这就意味着你可以把时间设置在过去或者未来，或者随意使用一个Long值。</p>
<p>要想覆盖一个现有的值，就意味着你的row,column和版本必须完全相等。</p>
<p><a target="_blank" name="implicit_version_example"></a><span style="color:rgb(153,0,0)">11.7.1.4.1. 不指明版本的例子</span></p>
<p>下面的Put操作不指明版本，所以Hbase会用当前时间作为版本。</p>
<p>Put put = new Put(Bytes.toBytes(row));</p>
<p>put.add(Bytes.toBytes("cf"), Bytes.toBytes("attr1"), Bytes.toBytes( data));</p>
<p>htable.put(put);</p>
<p> </p>
<p><a target="_blank" name="explicit_version_example"></a><span style="color:rgb(153,0,0)">11.7.1.4.2. 指明版本的例子</span></p>
<p>下面的Put操作，指明了版本。</p>
<p>Put put = new Put( Bytes.toBytes(row ));</p>
<p>long explicitTimeInMs = 555;  // just an example</p>
<p>put.add(Bytes.toBytes("cf"), Bytes.toBytes("attr1"), explicitTimeInMs, Bytes.toBytes(data));</p>
<p>htable.put(put);</p>
<p> </p>
<p><a target="_blank" name="d613e2936"></a><span style="color:rgb(153,0,0)">11.7.1.5. Delete</span></p>
<p>当你进行delete操作的是，有两种方式来确定要删除的版本。</p>
<p>· 删除所有比当前早的版本。</p>
<p>· 删除指定的版本。</p>
<p>一个删除操作可以删除一行，也可以是一个column family，或者仅仅删除一个column。你也可以删除指明的一个版本。若你没有指明，默认情况下是删除比当前时间早的版本。</p>
<p>删除操作的实现是创建一个删除标记。例如，我们想要删除一个版本，或者默认是currentTimeMillis。就意味着“删除比这个版本更早的所有版本”.Hbase不会去改那些数据，数据不会立即从文件中删除。他使用删除标记来屏蔽掉这些值。[<a target="_blank" name="d613e2961"></a><a target="_blank" href="#ftn.d613e2961" rel="nofollow"><span style="color:rgb(0,0,255)">16</span></a>]若你知道的版本比数据中的版本晚，就意味着这一行中的所有数据都会被删除。</p>
<p><a target="_blank" name="d613e2965"></a><span style="color:rgb(153,0,0)">11.7.2. 现有的限制</span></p>
<p>关于版本还有一些bug(或者称之为未实现的功能)，计划在下个版本实现。</p>
<p><a target="_blank" name="d613e2970"></a><span style="color:rgb(153,0,0)">11.7.2.1. 删除标记误删Puts</span></p>
<p>删除标记操作可能会标记之后put的数据。[<a target="_blank" name="d613e2975"></a><a target="_blank" href="#ftn.d613e2975" rel="nofollow"><span style="color:rgb(0,0,255)">17</span></a>].需要值得注意的是，当写下一个删除标记后，只有下一个major compaction操作发起之后，这个删除标记才会消失。设想一下，当你写下一个删除标记-“删除所有&lt;= 时间T的数据”。但之后，你又执行了一个Put操作，版本&lt;= T。这样就算这个Put发生在删除之后，他的数据也算是打上了删除标记。这个Put并不会失败，但是你需要注意的是这个操作没有任何作用。只有一个major compaction执行只有，一切才会恢复正常。如果你的Put操作一直使用升序的版本，这个错误就不会发生。但是也有可能出现这样的情况，你删除之后，</p>
<p><a target="_blank" name="d613e2980"></a><span style="color:rgb(153,0,0)">11.7.2.2. Major compactions 改变查询的结果</span></p>
<p>“设想一下，你一个cell有三个版本t1,t2和t3。你的maximun-version设置是2.当你请求获取全部版本的时候，只会返回两个，t2和t3。如果你将t2和t3删除，就会返回t1。但是如果在删除之前，发生了major compaction操作，那么什么值都不好返回了。[<a target="_blank" name="d613e2986"></a><a target="_blank" href="#ftn.d613e2986" rel="nofollow"><span style="color:rgb(0,0,255)">18</span></a>]”</p>
<p> </p>
<p></p>
<p>[<a target="_blank" name="ftn.d613e2836"></a><a target="_blank" href="#d613e2836" rel="nofollow"><span style="color:rgb(0,0,255)">13</span></a>] 目前，只有最新的那个是可以获取到的。.</p>
<p>[<a target="_blank" name="ftn.d613e2842"></a><a target="_blank" href="#d613e2842" rel="nofollow"><span style="color:rgb(0,0,255)">14</span></a>] 可以</p>
<p>[<a target="_blank" name="ftn.d613e2847"></a><a target="_blank" href="#d613e2847" rel="nofollow"><span style="color:rgb(0,0,255)">15</span></a>] See <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE-2406" rel="nofollow"><span style="color:rgb(0,0,255)">HBASE-2406</span></a> for discussion of HBase versions. <a target="_blank" href="http://outerthought.org/blog/417-ot.html" rel="nofollow"><span style="color:rgb(0,0,255)">Bending time in HBase</span></a> makes for a good read on the version, or time, dimension in HBase. It has more detail on versioning than is provided here. As of this writing, the limiitation Overwriting values at existing timestamps mentioned in the article no longer holds in HBase. This section is basically a synopsis of this article by Bruno Dumon.</p>
<p>[<a target="_blank" name="ftn.d613e2961"></a><a target="_blank" href="#d613e2961" rel="nofollow"><span style="color:rgb(0,0,255)">16</span></a>] 当Hbase执行一次major compaction,标记删除的数据会被实际的删除，删除标记也会被删除。</p>
<p>[<a target="_blank" name="ftn.d613e2975"></a><a target="_blank" href="#d613e2975" rel="nofollow"><span style="color:rgb(0,0,255)">17</span></a>] <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE-2256" rel="nofollow"><span style="color:rgb(0,0,255)">HBASE-2256</span></a></p>
<p>[<a target="_blank" name="ftn.d613e2986"></a><a target="_blank" href="#d613e2986" rel="nofollow"><span style="color:rgb(0,0,255)">18</span></a>] See Garbage Collection in <a target="_blank" href="http://outerthought.org/blog/417-ot.html" rel="nofollow"><span style="color:rgb(0,0,255)">Bending time in HBase</span></a></p>
<p><a target="_blank" name="architecture"></a><span style="color:rgb(153,0,0)">Chapter 12. 架构</span></p>
<p>Table of Contents</p>
<p><a target="_blank" href="#client" rel="nofollow"><span style="color:rgb(0,0,255)">12.1. 客户端</span></a></p>
<p><a target="_blank" href="#client.connections" rel="nofollow"><span style="color:rgb(0,0,255)">12.1.1. 连接</span></a></p>
<p><a target="_blank" href="#client.writebuffer" rel="nofollow"><span style="color:rgb(0,0,255)">12.1.2. 写缓冲和批量操作 </span></a></p>
<p><a target="_blank" href="#client.filter" rel="nofollow"><span style="color:rgb(0,0,255)">12.1.3. Filters</span></a></p>
<p><a target="_blank" href="#daemons" rel="nofollow"><span style="color:rgb(0,0,255)">12.2. Daemons</span></a></p>
<p><a target="_blank" href="#master" rel="nofollow"><span style="color:rgb(0,0,255)">12.2.1. Master</span></a></p>
<p><a target="_blank" href="#regionserver.arch" rel="nofollow"><span style="color:rgb(0,0,255)">12.2.2. RegionServer</span></a></p>
<p><a target="_blank" href="#regions.arch" rel="nofollow"><span style="color:rgb(0,0,255)">12.3. Regions</span></a></p>
<p><a target="_blank" href="#arch.regions.size" rel="nofollow"><span style="color:rgb(0,0,255)">12.3.1. Region大小</span></a></p>
<p><a target="_blank" href="#d613e3126" rel="nofollow"><span style="color:rgb(0,0,255)">12.3.2. Region Splits</span></a></p>
<p><a target="_blank" href="#d613e3133" rel="nofollow"><span style="color:rgb(0,0,255)">12.3.3. Region负载均衡</span></a></p>
<p><a target="_blank" href="#store" rel="nofollow"><span style="color:rgb(0,0,255)">12.3.4. Store</span></a></p>
<p><a target="_blank" href="#wal" rel="nofollow"><span style="color:rgb(0,0,255)">12.4. Write Ahead Log (WAL)</span></a></p>
<p><a target="_blank" href="#purpose.wal" rel="nofollow"><span style="color:rgb(0,0,255)">12.4.1. 目的</span></a></p>
<p><a target="_blank" href="#wal_flush" rel="nofollow"><span style="color:rgb(0,0,255)">12.4.2. WAL Flushing</span></a></p>
<p><a target="_blank" href="#wal_splitting" rel="nofollow"><span style="color:rgb(0,0,255)">12.4.3. WAL Splitting</span></a></p>
<p><a target="_blank" name="client"></a><span style="color:rgb(153,0,0)">12.1. 客户端</span></p>
<p>Hbase客户端的 <a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html" rel="nofollow"><span style="color:rgb(0,0,255)">HTable</span></a>类负责寻找相应的RegionServers来处理行。他是先查询 .META. 和 -ROOT 目录表。然后再确定region的位置。定位到所需要的区域后，客户端会直接 去访问相应的region(不经过master)，发起读写请求。这些信息会缓存在客户端，这样就不用每发起一个请求就去查一下。如果一个region已经废弃(原因可能是master load balance或者RegionServer死了)，客户端就会重新进行这个步骤，决定要去访问的新的地址。</p>
<p>管理集群操作是经由<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HBaseAdmin.html" rel="nofollow"><span style="color:rgb(0,0,255)">HBaseAdmin</span></a>发起的</p>
<p><a target="_blank" name="client.connections"></a><span style="color:rgb(153,0,0)">12.1.1. 连接</span></p>
<p>关于连接的配置信息，参见<a target="_blank" href="#client_dependencies" rel="nofollow" title="3.7. 连接Hbase集群的客户端配置和依赖"><span style="color:rgb(0,0,255)">Section 3.7, “连接Hbase集群的客户端配置和依赖”</span></a>.</p>
<p><a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html" rel="nofollow"><span style="color:rgb(0,0,255)">HTable</span></a>不是线程安全的。建议使用同一个<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HBaseConfiguration" rel="nofollow"><span style="color:rgb(0,0,255)">HBaseConfiguration</span></a>实例来创建HTable实例。这样可以共享ZooKeeper和socket实例。例如，最好这样做：</p>
<p>HBaseConfiguration conf = HBaseConfiguration.create();</p>
<p>HTable table1 = new HTable(conf, "myTable");</p>
<p>HTable table2 = new HTable(conf, "myTable");</p>
<p>而不是这样：</p>
<p>HBaseConfiguration conf1 = HBaseConfiguration.create();</p>
<p>HTable table1 = new HTable(conf1, "myTable");</p>
<p>HBaseConfiguration conf2 = HBaseConfiguration.create();</p>
<p>HTable table2 = new HTable(conf2, "myTable");</p>
<p>如果你想知道的更多的关于Hbase客户端connection的知识，可以参照： <a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HConnectionManager.html" rel="nofollow"><span style="color:rgb(0,0,255)">HConnectionManager</span></a>.</p>
<p><a target="_blank" name="client.writebuffer"></a><span style="color:rgb(153,0,0)">12.1.2. 写缓冲和批量操作</span></p>
<p>若关闭了<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html" rel="nofollow"><span style="color:rgb(0,0,255)">HTable</span></a>中的 <a target="_blank" href="#perf.hbase.client.autoflush" rel="nofollow" title="13.6.1. AutoFlush"><span style="color:rgb(0,0,255)">Section 13.6.1, “AutoFlush”</span></a>，Put操作会在写缓冲填满的时候向RegionServer发起请求。默认情况下，写缓冲是2MB.在Htable被废弃之前，要调用close(), flushCommits()操作，这样写缓冲就不会丢失。</p>
<p>要想更好的细粒度控制 Put或Delete的批量操作，可以参考Htable中的<a target="_blank" href="#batch%28java.util.List%29" rel="nofollow"><span style="color:rgb(0,0,255)">batch</span></a> 方法.</p>
<p><a target="_blank" name="client.filter"></a><span style="color:rgb(153,0,0)">12.1.3. Filters</span></p>
<p><a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Get.html" rel="nofollow"><span style="color:rgb(0,0,255)">Get</span></a> 和 <a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html" rel="nofollow"><span style="color:rgb(0,0,255)">Scan</span></a>实例可以使用 <a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/Filter.html" rel="nofollow"><span style="color:rgb(0,0,255)">filters</span></a>，这个过滤操作是运行在RegionServer上的。</p>
<p><a target="_blank" name="daemons"></a><span style="color:rgb(153,0,0)">12.2. Daemons</span></p>
<p><a target="_blank" name="master"></a><span style="color:rgb(153,0,0)">12.2.1. Master</span></p>
<p><a target="_blank" name="regionserver.arch"></a><span style="color:rgb(153,0,0)">12.2.2. RegionServer</span></p>
<p><a target="_blank" name="regions.arch"></a><span style="color:rgb(153,0,0)">12.3. Regions</span></p>
<p>本章节都是再讲Regions.</p>
<p><span style="color:rgb(153,0,0)">Note</span></p>
<p>Regions是由每个Column Family的Store组成。</p>
<p><a target="_blank" name="arch.regions.size"></a><span style="color:rgb(153,0,0)">12.3.1. Region大小</span></p>
<p>Region的大小是一个棘手的问题，需要考量如下几个因素。</p>
<p>· Regions是可用性和分布式的最基本单位</p>
<p>· HBase通过将region切分在许多机器上实现分布式。也就是说，你如果有16GB的数据，只分了2个region， 你却有20台机器，有18台就浪费了。</p>
<p>· region数目太多就会造成性能下降，现在比以前好多了。但是对于同样大小的数据，700个region比3000个要好。</p>
<p>· region数目太少就会妨碍可扩展性，降低并行能力。有的时候导致压力不够分散。这就是为什么，你向一个10节点的Hbase集群导入200MB的数据，大部分的节点是idle的。</p>
<p>· RegionServer中1个region和10个region索引需要的内存量没有太多的差别。</p>
<p>最好是使用默认的配置，可以把热的表配小一点(或者受到split热点的region把压力分散到集群中)。如果你的cell的大小比较大(100KB或更大)，就可以把region的大小调到1GB。</p>
<p><a target="_blank" name="d613e3126"></a><span style="color:rgb(153,0,0)">12.3.2. Region Splits</span></p>
<p>RegionServer的Splits操作是不可见的，因为Master不会参与其中。RegionServer切割region的步骤是，先将该region下线，然后切割，将其子region加入到元信息中，再将他们加入到原本的RegionServer中，最后汇报Master.参见<a target="_blank" href="#disable.splitting" rel="nofollow" title="3.6.6. 管理 Splitting"><span style="color:rgb(0,0,255)">Section 3.6.6, “管理 Splitting”</span></a>来手动管理切割操作。</p>
<p><a target="_blank" name="d613e3133"></a><span style="color:rgb(153,0,0)">12.3.3. Region负载均衡</span></p>
<p>当没有任何region在进行转换的时候，Hbase会定期执行一个load balance。他会将移动region进行集群的负载均衡。可以配置运行时间间隔。</p>
<p><a target="_blank" name="store"></a><span style="color:rgb(153,0,0)">12.3.4. Store</span></p>
<p>一个Store包含了一个MemStore和若干个StoreFile(HFile).一个Store可以定位到一个column family中的一个region.</p>
<p><a target="_blank" name="store.memstore"></a><span style="color:rgb(153,0,0)">12.3.4.1. MemStore</span></p>
<p>MemStores是Store中的内存Store,可以进行修改操作。修改的内容是KeyValues。当flush的是，现有的memstore会生成快照，然后清空。在执行快照的时候，Hbase会继续接收修改操作，保存在memstore外面，直到快照完成。</p>
<p><a target="_blank" name="hfile"></a><span style="color:rgb(153,0,0)">12.3.4.2. StoreFile (HFile)</span></p>
<p><a target="_blank" name="d613e3151"></a><span style="color:rgb(153,0,0)">12.3.4.2.1. HFile Format</span></p>
<p>hfile文件格式是基于<a target="_blank" href="http://labs.google.com/papers/bigtable.html" rel="nofollow"><span style="color:rgb(0,0,255)">BigTable [2006]</span></a>论文中的SSTable。构建在Hadoop的<a target="_blank" href="http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/io/file/tfile/TFile.html" rel="nofollow"><span style="color:rgb(0,0,255)">tfile</span></a>上面(直接使用了tfile的单元测试和压缩工具)。 Schubert Zhang's的博客<a target="_blank" href="http://cloudepr.blogspot.com/2009/09/hfile-block-indexed-file-format-to.html" rel="nofollow"><span style="color:rgb(0,0,255)">HFile: A Block-Indexed File Format to Store Sorted Key-Value Pairs</span></a>详细介绍了Hbases的hfile。Matteo Bertozzi也做了详细的介绍<a target="_blank" href="http://th30z.blogspot.com/2011/02/hbase-io-hfile.html?spref=tw" rel="nofollow"><span style="color:rgb(0,0,255)">HBase I/O: HFile</span></a>。</p>
<p><a target="_blank" name="hfile_tool"></a><span style="color:rgb(153,0,0)">12.3.4.2.2. HFile工具</span></p>
<p>要想看到hfile内容的文本化版本，你可以使用org.apache.hadoop.hbase.io.hfile.HFile 工具。可以这样用：</p>
<p>$ ${HBASE_HOME}/bin/hbase org.apache.hadoop.hbase.io.hfile.HFile</p>
<p>例如，你想看文件 <span style="color:rgb(0,122,0)">hdfs://10.81.47.41:9000/hbase/TEST/1418428042/DSMP/4759508618286845475</span>的内容, 就执行如下的命令:</p>
<p>$ ${HBASE_HOME}/bin/hbase org.apache.hadoop.hbase.io.hfile.HFile -v -f hdfs://10.81.47.41:9000/hbase/TEST/1418428042/DSMP/4759508618286845475</p>
<p>如果你没有输入-v,就仅仅能看到一个hfile的汇总信息。其他功能的用法可以看HFile的文档。</p>
<p><a target="_blank" name="compaction"></a><span style="color:rgb(153,0,0)">12.3.4.3. 压缩</span></p>
<p>有两种类型的压缩:minor和major。minor压缩通常会将数个小的相邻的文件合并成一个大的。Minor不会删除打上删除标记的数据，也不会删除过期的数据，Major压缩会删除过期的数据。有些时候minor压缩就会将一个store中的全部文件压缩，实际上这个时候他本身就是一个major压缩。对于一个minor压缩是如何压缩的，可以参见<a target="_blank" href="#836" rel="nofollow"><span style="color:rgb(0,0,255)">ascii diagram in the Store source code.</span></a></p>
<p>在执行一个major压缩之后，一个store只会有一个sotrefile,通常情况下这样可以提供性能。注意：major压缩将会将store中的数据全部重写，在一个负载很大的系统中，这个操作是很伤的。所以在大型系统中，通常会自己<a target="_blank" href="#disable.splitting" rel="nofollow" title="3.6.6. 管理 Splitting"><span style="color:rgb(0,0,255)">Section 3.6.6, “管理 Splitting”</span></a>。</p>
<p><a target="_blank" name="wal"></a><span style="color:rgb(153,0,0)">12.4. Write Ahead Log (WAL)</span></p>
<p><a target="_blank" name="purpose.wal"></a><span style="color:rgb(153,0,0)">12.4.1. 目的</span></p>
<p>每个RegionServer会将更新(Puts, Deletes) 先记录到Write Ahead Log中(WAL)，然后将其更新在<a target="_blank" href="#store" rel="nofollow" title="12.3.4. Store"><span style="color:rgb(0,0,255)">Section 12.3.4, “Store”</span></a>的<a target="_blank" href="#store.memstore" rel="nofollow" title="12.3.4.1. MemStore"><span style="color:rgb(0,0,255)">Section 12.3.4.1, “MemStore”</span></a>里面。这样就保证了Hbase的写的可靠性。如果没有WAL,当RegionServer宕掉的时候，MemStore还没有flush，StoreFile还没有保存，数据就会丢失。<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/regionserver/wal/HLog.html" rel="nofollow"><span style="color:rgb(0,0,255)">HLog</span></a> 是Hbase的一个WAL实现，一个RegionServer有一个HLog实例。</p>
<p>WAL 保存在HDFS 的 <span style="color:rgb(0,122,0)">/hbase/.logs/</span> 里面，每个region一个文件。</p>
<p>要想知道更多的信息，可以访问维基百科 <a target="_blank" href="http://en.wikipedia.org/wiki/Write-ahead_logging" rel="nofollow"><span style="color:rgb(0,0,255)">Write-Ahead Log</span></a> 的文章.</p>
<p><a target="_blank" name="wal_flush"></a><span style="color:rgb(153,0,0)">12.4.2. WAL Flushing</span></p>
<p>TODO (describe).</p>
<p><a target="_blank" name="wal_splitting"></a><span style="color:rgb(153,0,0)">12.4.3. WAL Splitting</span></p>
<p><a target="_blank" name="d613e3239"></a><span style="color:rgb(153,0,0)">12.4.3.1. 当RegionServer宕掉的时候，如何恢复</span></p>
<p>TODO</p>
<p><a target="_blank" name="d613e3244"></a><span style="color:rgb(153,0,0)">12.4.3.2. hbase.hlog.split.skip.errors</span></p>
<p>默认设置为 true,在split执行中发生的任何错误会被记录，有问题的WAL会被移动到Hbase rootdir目录下的<span style="color:rgb(0,122,0)">.corrupt</span>目录，接着进行处理。如果设置为 false，异常会被抛出，split会记录错误。[<a target="_blank" name="d613e3262"></a><a target="_blank" href="#ftn.d613e3262" rel="nofollow"><span style="color:rgb(0,0,255)">19</span></a>]</p>
<p><a target="_blank" name="d613e3268"></a><span style="color:rgb(153,0,0)">12.4.3.3. 如果处理一个发生在当RegionServers' WALs 分割时候的EOFExceptions异常</span></p>
<p>如果我们在分割日志的时候发生EOF,就是hbase.hlog.split.skip.errors设置为 false，我们也会进行处理。一个EOF会发生在一行一行读取Log，但是Log中最后一行似乎只写了一半就停止了。如果在处理过程中发生了EOF，我们还会继续处理，除非这个文件是要处理的最后一个文件。[<a target="_blank" name="d613e3279"></a><a target="_blank" href="#ftn.d613e3279" rel="nofollow"><span style="color:rgb(0,0,255)">20</span></a>]</p>
<p> </p>
<p></p>
<p>[<a target="_blank" name="ftn.d613e3262"></a><a target="_blank" href="#d613e3262" rel="nofollow"><span style="color:rgb(0,0,255)">19</span></a>] See <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE-2958" rel="nofollow"><span style="color:rgb(0,0,255)">HBASE-2958 When hbase.hlog.split.skip.errors is set to false, we fail the split but thats it</span></a>. We need to do more than just fail split if this flag is set.</p>
<p>[<a target="_blank" name="ftn.d613e3279"></a><a target="_blank" href="#d613e3279" rel="nofollow"><span style="color:rgb(0,0,255)">20</span></a>] 要想知道背景知识, 参见 <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE-2643" rel="nofollow"><span style="color:rgb(0,0,255)">HBASE-2643 Figure how to deal with eof splitting logs</span></a></p>
<p><a target="_blank" name="performance"></a><span style="color:rgb(153,0,0)">Chapter 13. 性能调优</span></p>
<p>Table of Contents</p>
<p><a target="_blank" href="#jvm" rel="nofollow"><span style="color:rgb(0,0,255)">13.1. Java</span></a></p>
<p><a target="_blank" href="#gc" rel="nofollow"><span style="color:rgb(0,0,255)">13.1.1. 垃圾收集和HBase</span></a></p>
<p><a target="_blank" href="#perf.configurations" rel="nofollow"><span style="color:rgb(0,0,255)">13.2. 配置</span></a></p>
<p><a target="_blank" href="#perf.number.of.regions" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.1. Regions的数目</span></a></p>
<p><a target="_blank" href="#perf.compactions.and.splits" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.2. 管理压缩</span></a></p>
<p><a target="_blank" href="#perf.compression" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.3. 压缩</span></a></p>
<p><a target="_blank" href="#perf.handlers" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.4. hbase.regionserver.handler.count</span></a></p>
<p><a target="_blank" href="#perf.hfile.block.cache.size" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.5. hfile.block.cache.size</span></a></p>
<p><a target="_blank" href="#perf.rs.memstore.upperlimit" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.6. hbase.regionserver.global.memstore.upperLimit</span></a></p>
<p><a target="_blank" href="#perf.rs.memstore.lowerlimit" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.7. hbase.regionserver.global.memstore.lowerLimit</span></a></p>
<p><a target="_blank" href="#perf.hstore.blockingstorefiles" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.8. hbase.hstore.blockingStoreFiles</span></a></p>
<p><a target="_blank" href="#perf.hregion.memstore.block.multiplier" rel="nofollow"><span style="color:rgb(0,0,255)">13.2.9. hbase.hregion.memstore.block.multiplier</span></a></p>
<p><a target="_blank" href="#perf.number.of.cfs" rel="nofollow"><span style="color:rgb(0,0,255)">13.3. Column Families的数目</span></a></p>
<p><a target="_blank" href="#perf.one.region" rel="nofollow"><span style="color:rgb(0,0,255)">13.4. 数据聚集</span></a></p>
<p><a target="_blank" href="#perf.batch.loading" rel="nofollow"><span style="color:rgb(0,0,255)">13.5. 批量Loading</span></a></p>
<p><a target="_blank" href="#precreate.regions" rel="nofollow"><span style="color:rgb(0,0,255)">13.5.1. Table创建: 预创建Regions </span></a></p>
<p><a target="_blank" href="#d613e3446" rel="nofollow"><span style="color:rgb(0,0,255)">13.6. HBase客户端</span></a></p>
<p><a target="_blank" href="#perf.hbase.client.autoflush" rel="nofollow"><span style="color:rgb(0,0,255)">13.6.1. AutoFlush</span></a></p>
<p><a target="_blank" href="#perf.hbase.client.caching" rel="nofollow"><span style="color:rgb(0,0,255)">13.6.2. Scan Caching</span></a></p>
<p><a target="_blank" href="#perf.hbase.client.selection" rel="nofollow"><span style="color:rgb(0,0,255)">13.6.3. Scan 属性选择</span></a></p>
<p><a target="_blank" href="#perf.hbase.client.scannerclose" rel="nofollow"><span style="color:rgb(0,0,255)">13.6.4. 关闭 ResultScanners</span></a></p>
<p><a target="_blank" href="#perf.hbase.client.blockcache" rel="nofollow"><span style="color:rgb(0,0,255)">13.6.5. 块缓存</span></a></p>
<p><a target="_blank" href="#perf.hbase.client.rowkeyonly" rel="nofollow"><span style="color:rgb(0,0,255)">13.6.6. Row Keys的负载优化</span></a></p>
<p>可以从 <a target="_blank" href="http://wiki.apache.org/hadoop/PerformanceTuning" rel="nofollow"><span style="color:rgb(0,0,255)">wiki Performance Tuning</span></a>看起。这个文档讲了一些主要的影响性能的方面:RAM, 压缩, JVM 设置, 等等。然后，可以看看下面的补充内容。</p>
<p><a target="_blank" name="rpc.logging"></a><span style="color:rgb(153,0,0)">打开RPC-level日志</span></p>
<p>在RegionServer打开RPC-level的日志对于深度的优化是有好处的。一旦打开，日志将喷涌而出。所以不建议长时间打开，只能看一小段时间。要想启用RPC-level的职责，可以使用RegionServer UI点击Log Level。将 org.apache.hadoop.ipc 的日志级别设为DEBUG。然后tail RegionServer的日志，进行分析。</p>
<p>要想关闭，只要把日志级别设为INFO就可以了.</p>
<p><a target="_blank" name="jvm"></a><span style="color:rgb(153,0,0)">13.1. Java</span></p>
<p><a target="_blank" name="gc"></a><span style="color:rgb(153,0,0)">13.1.1. 垃圾收集和HBase</span></p>
<p><a target="_blank" name="gcpause"></a><span style="color:rgb(153,0,0)">13.1.1.1. 长时间GC停顿</span></p>
<p>在这个PPT <a target="_blank" href="http://www.slideshare.net/cloudera/hbase-hug-presentation" rel="nofollow"><span style="color:rgb(0,0,255)">Avoiding Full GCs with MemStore-Local Allocation Buffers</span></a>, Todd Lipcon描述列在Hbase中常见的两种stop-the-world的GC操作，尤其是在loading的时候。一种是CMS失败的模式(译者注:CMS是一种GC的算法)，另一种是老一代的堆碎片导致的。要想定位第一种，只要将CMS执行的时间提前就可以了，加入-XX:CMSInitiatingOccupancyFraction参数，把值调低。可以先从60%和70%开始(这个值调的越低，触发的GC次数就越多，消耗的CPU时间就越长)。要想定位第二种错误，Todd加入了一个实验性的功能，在Hbase 0.90.x中这个是要明确指定的(在0.92.x中，这个是默认项)，将你的Configuration中的hbase.hregion.memstore.mslab.enabled设置为true。详细信息，可以看这个PPT.</p>
<p><a target="_blank" name="perf.configurations"></a><span style="color:rgb(153,0,0)">13.2. 配置</span></p>
<p>参见<a target="_blank" href="#recommended_configurations" rel="nofollow" title="3.6. 推荐的配置"><span style="color:rgb(0,0,255)">Section 3.6, “推荐的配置”</span></a>.</p>
<p><a target="_blank" name="perf.number.of.regions"></a><span style="color:rgb(153,0,0)">13.2.1. Regions的数目</span></p>
<p>Hbase中region的数目可以根据<a target="_blank" href="#bigger.regions" rel="nofollow" title="3.6.5. 更大的 Regions"><span style="color:rgb(0,0,255)">Section 3.6.5, “更大的 Regions”</span></a>调整.也可以参见 <a target="_blank" href="#arch.regions.size" rel="nofollow" title="12.3.1. Region大小"><span style="color:rgb(0,0,255)">Section 12.3.1, “Region大小”</span></a></p>
<p><a target="_blank" name="perf.compactions.and.splits"></a><span style="color:rgb(153,0,0)">13.2.2. 管理压缩</span></p>
<p>对于大型的系统，你需要考虑管理<a target="_blank" href="#disable.splitting" rel="nofollow" title="3.6.6. 管理 Splitting"><span style="color:rgb(0,0,255)">压缩和分割</span></a></p>
<p><a target="_blank" name="perf.compression"></a><span style="color:rgb(153,0,0)">13.2.3. 压缩</span></p>
<p>生产环境中的系统需要在column family的定义中使用<a target="_blank" href="#lzo" rel="nofollow" title="3.6.4. LZO 压缩"><span style="color:rgb(0,0,255)">Section 3.6.4, “LZO 压缩”</span></a>之类的压缩。</p>
<p><a target="_blank" name="perf.handlers"></a><span style="color:rgb(153,0,0)">13.2.4. </span><span style="color:rgb(153,0,0)">hbase.regionserver.handler.count</span></p>
<p>参见<a target="_blank" href="#hbase.regionserver.handler.count" rel="nofollow" title="hbase.regionserver.handler.count"><span style="color:rgb(0,0,255)">hbase.regionserver.handler.count</span></a>.这个参数的本质是设置一个RegsionServer可以同时处理多少请求。 如果定的太高，吞吐量反而会降低;如果定的太低，请求会被阻塞，得不到响应。你可以<a target="_blank" href="#rpc.logging" rel="nofollow" title="打开RPC-level日志"><span style="color:rgb(0,0,255)">打开RPC-level日志</span></a>读Log，来决定对于你的集群什么值是合适的。(请求队列也是会消耗内存的)</p>
<p><a target="_blank" name="perf.hfile.block.cache.size"></a><span style="color:rgb(153,0,0)">13.2.5. </span><span style="color:rgb(153,0,0)">hfile.block.cache.size</span></p>
<p>参见 <a target="_blank" href="#hfile.block.cache.size" rel="nofollow" title="hfile.block.cache.size"><span style="color:rgb(0,0,255)">hfile.block.cache.size</span></a>. 对于RegionServer进程的内存设置。</p>
<p><a target="_blank" name="perf.rs.memstore.upperlimit"></a><span style="color:rgb(153,0,0)">13.2.6. </span><span style="color:rgb(153,0,0)">hbase.regionserver.global.memstore.upperLimit</span></p>
<p>参见 <a target="_blank" href="#hbase.regionserver.global.memstore.upperLimit" rel="nofollow" title="hbase.regionserver.global.memstore.upperLimit"><span style="color:rgb(0,0,255)">hbase.regionserver.global.memstore.upperLimit</span></a>. 这个内存设置是根据RegionServer的需要来设定。</p>
<p><a target="_blank" name="perf.rs.memstore.lowerlimit"></a><span style="color:rgb(153,0,0)">13.2.7. </span><span style="color:rgb(153,0,0)">hbase.regionserver.global.memstore.lowerLimit</span></p>
<p>参见 <a target="_blank" href="#hbase.regionserver.global.memstore.lowerLimit" rel="nofollow" title="hbase.regionserver.global.memstore.lowerLimit"><span style="color:rgb(0,0,255)">hbase.regionserver.global.memstore.lowerLimit</span></a>. 这个内存设置是根据RegionServer的需要来设定。</p>
<p><a target="_blank" name="perf.hstore.blockingstorefiles"></a><span style="color:rgb(153,0,0)">13.2.8. </span><span style="color:rgb(153,0,0)">hbase.hstore.blockingStoreFiles</span></p>
<p>参见<a target="_blank" href="#hbase.hstore.blockingStoreFiles" rel="nofollow" title="hbase.hstore.blockingStoreFiles"><span style="color:rgb(0,0,255)">hbase.hstore.blockingStoreFiles</span></a>. 如果在RegionServer的Log中block,提高这个值是有帮助的。</p>
<p><a target="_blank" name="perf.hregion.memstore.block.multiplier"></a><span style="color:rgb(153,0,0)">13.2.9. </span><span style="color:rgb(153,0,0)">hbase.hregion.memstore.block.multiplier</span></p>
<p>参见 <a target="_blank" href="#hbase.hregion.memstore.block.multiplier" rel="nofollow" title="hbase.hregion.memstore.block.multiplier"><span style="color:rgb(0,0,255)">hbase.hregion.memstore.block.multiplier</span></a>. 如果有足够的RAM，提高这个值。</p>
<p><a target="_blank" name="perf.number.of.cfs"></a><span style="color:rgb(153,0,0)">13.3. Column Families的数目</span></p>
<p>参见 <a target="_blank" href="#number.of.cfs" rel="nofollow" title="8.2.  column families的数量"><span style="color:rgb(0,0,255)">Section 8.2, “ column families的数量 ”</span></a>.</p>
<p><a target="_blank" name="perf.one.region"></a><span style="color:rgb(153,0,0)">13.4. 数据聚集</span></p>
<p>如果你的数据总是往一个region写。你可以再看看<a target="_blank" href="#timeseries" rel="nofollow" title="8.3.  单调递增Row Keys/时序数据(log)"><span style="color:rgb(0,0,255)">处理时序数据</span></a> 这一章.</p>
<p><a target="_blank" name="perf.batch.loading"></a><span style="color:rgb(153,0,0)">13.5. 批量Loading</span></p>
<p>如果可以的话，尽量使用批量导入工具，参见 <a target="_blank" href="http://hbase.apache.org/bulk-loads.html" rel="nofollow"><span style="color:rgb(0,0,255)">Bulk Loads</span></a>.否则就要详细看看下面的内容。</p>
<p><a target="_blank" name="precreate.regions"></a><span style="color:rgb(153,0,0)">13.5.1.  Table创建: 预创建Regions</span></p>
<p>默认情况下Hbase创建Table会新建一个region。执行批量导入，意味着所有的client会写入这个region，直到这个region足够大，以至于分裂。一个有效的提高批量导入的性能的方式，是预创建空的region。最好稍保守一点，因为过多的region会实实在在的降低性能。下面是一个预创建region的例子。 (注意：这个例子里需要根据应用的key进行调整。):</p>
<p>public static boolean createTable(HBaseAdmin admin, HTableDescriptor table, byte[][] splits)</p>
<p>throws IOException {</p>
<p>try {</p>
<p>admin.createTable( table, splits );</p>
<p>return true;</p>
<p>} catch (TableExistsException e) {</p>
<p>logger.info("table " + table.getNameAsString() + " already exists");</p>
<p>// the table already exists...</p>
<p>return false;</p>
<p>}</p>
<p>}</p>
<p> </p>
<p>public static byte[][] getHexSplits(String startKey, String endKey, int numRegions) {</p>
<p>byte[][] splits = new byte[numRegions-1][];</p>
<p>BigInteger lowestKey = new BigInteger(startKey, 16);</p>
<p>BigInteger highestKey = new BigInteger(endKey, 16);</p>
<p>BigInteger range = highestKey.subtract(lowestKey);</p>
<p>BigInteger regionIncrement = range.divide(BigInteger.valueOf(numRegions));</p>
<p>lowestKey = lowestKey.add(regionIncrement);</p>
<p>for(int i=0; i &lt; numRegions-1;i++) {</p>
<p>BigInteger key = lowestKey.add(regionIncrement.multiply(BigInteger.valueOf(i)));</p>
<p>byte[] b = String.format("%016x", key).getBytes();</p>
<p>splits[i] = b;</p>
<p>}</p>
<p>return splits;</p>
<p>}</p>
<p><a target="_blank" name="d613e3446"></a><span style="color:rgb(153,0,0)">13.6. HBase客户端</span></p>
<p><a target="_blank" name="perf.hbase.client.autoflush"></a><span style="color:rgb(153,0,0)">13.6.1. AutoFlush</span></p>
<p>当你进行大量的Put的时候，要确认你的<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html" rel="nofollow"><span style="color:rgb(0,0,255)">HTable</span></a>的setAutoFlush是关闭着的。否则的话，每执行一个Put就要想RegionServer发一个请求。通过 htable.add(Put) 和 htable.add( &lt;List&gt; Put)来将Put添加到写缓冲中。如果 autoFlush = false，要等到写缓冲都填满的时候才会发起请求。要想显式的发起请求，可以调用flushCommits。在HTable实例上进行的close操作也会发起flushCommits</p>
<p><a target="_blank" name="perf.hbase.client.caching"></a><span style="color:rgb(153,0,0)">13.6.2. Scan Caching</span></p>
<p>如果Hbase的输入源是一个MapReduce Job，要确保输入的<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html" rel="nofollow"><span style="color:rgb(0,0,255)">Scan</span></a>的setCaching值要比默认值0要大。使用默认值就意味着map-task每一行都会去请求一下region-server。可以把这个值设为500，这样就可以一次传输500行。当然这也是需要权衡的，过大的值会同时消耗客户端和服务端很大的内存，不是越大越好。</p>
<p><a target="_blank" name="perf.hbase.client.selection"></a><span style="color:rgb(153,0,0)">13.6.3. Scan 属性选择</span></p>
<p>当Scan用来处理大量的行的时候(尤其是作为MapReduce的输入)，要注意的是选择了什么字段。如果调用了 scan.addFamily，这个column family的所有属性都会返回。如果只是想过滤其中的一小部分，就指定那几个column，否则就会造成很大浪费，影响性能。</p>
<p><a target="_blank" name="perf.hbase.client.scannerclose"></a><span style="color:rgb(153,0,0)">13.6.4. 关闭 ResultScanners</span></p>
<p>这与其说是提高性能，倒不如说是避免发生性能问题。如果你忘记了关闭<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/ResultScanner.html" rel="nofollow"><span style="color:rgb(0,0,255)">ResultScanners</span></a>，会导致RegionServer出现问题。所以一定要把ResultScanner包含在try/catch 块中...</p>
<p>Scan scan = new Scan();</p>
<p>// set attrs...</p>
<p>ResultScanner rs = htable.getScanner(scan);</p>
<p>try {</p>
<p>for (Result r = rs.next(); r != null; r = rs.next()) {</p>
<p>// process result...</p>
<p>} finally {</p>
<p>rs.close();  // always close the ResultScanner!</p>
<p>}</p>
<p>htable.close();</p>
<p><a target="_blank" name="perf.hbase.client.blockcache"></a><span style="color:rgb(153,0,0)">13.6.5. 块缓存</span></p>
<p><a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html" rel="nofollow"><span style="color:rgb(0,0,255)">Scan</span></a>实例可以在RegionServer中使用块缓存，可以由setCacheBlocks方法控制。如果Scan是MapReduce的输入源，要将这个值设置为 false。对于经常读到的行，就建议使用块缓冲。</p>
<p><a target="_blank" name="perf.hbase.client.rowkeyonly"></a><span style="color:rgb(153,0,0)">13.6.6. Row Keys的负载优化</span></p>
<p>当<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html" rel="nofollow"><span style="color:rgb(0,0,255)">scan</span></a>一个表的时候，如果仅仅需要row key（不需要no families, qualifiers, values 和 timestamps）,在加入FilterList的时候，要使用Scanner的setFilter方法的时候，要填上MUST_PASS_ALL操作参数(译者注：相当于And操作符)。一个FilterList要包含一个 <a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/FirstKeyOnlyFilter.html" rel="nofollow"><span style="color:rgb(0,0,255)">FirstKeyOnlyFilter</span></a> 和一个 <a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/KeyOnlyFilter.html" rel="nofollow"><span style="color:rgb(0,0,255)">KeyOnlyFilter</span></a>.通过这样的filter组合，就算在最坏的情况下，RegionServer只会从磁盘读一个值，同时最小化客户端的网络带宽占用。</p>
<p><a target="_blank" name="blooms"></a><span style="color:rgb(153,0,0)">Chapter 14. Bloom Filters</span></p>
<p>Table of Contents</p>
<p><a target="_blank" href="#bloom.config" rel="nofollow"><span style="color:rgb(0,0,255)">14.1. 配置</span></a></p>
<p><a target="_blank" href="#d613e3574" rel="nofollow"><span style="color:rgb(0,0,255)">14.1.1. HColumnDescriptor 配置</span></a></p>
<p><a target="_blank" href="#d613e3593" rel="nofollow"><span style="color:rgb(0,0,255)">14.1.2. io.hfile.bloom.enabled 全局关闭开关</span></a></p>
<p><a target="_blank" href="#d613e3609" rel="nofollow"><span style="color:rgb(0,0,255)">14.1.3. io.hfile.bloom.error.rate</span></a></p>
<p><a target="_blank" href="#d613e3617" rel="nofollow"><span style="color:rgb(0,0,255)">14.1.4. io.hfile.bloom.max.fold</span></a></p>
<p><a target="_blank" href="#bloom_footprint" rel="nofollow"><span style="color:rgb(0,0,255)">14.2. Bloom StoreFile footprint</span></a></p>
<p><a target="_blank" href="#d613e3645" rel="nofollow"><span style="color:rgb(0,0,255)">14.2.1. StoreFile中的BloomFilter， FileInfo数据结构</span></a></p>
<p><a target="_blank" href="#d613e3672" rel="nofollow"><span style="color:rgb(0,0,255)">14.2.2. 在 StoreFile 元数据中的BloomFilter entries</span></a></p>
<p>Bloom filters 是在 <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE-1200" rel="nofollow"><span style="color:rgb(0,0,255)">HBase-1200 Add bloomfilters</span></a>上面开发的.[<a target="_blank" name="d613e3547"></a><a target="_blank" href="#ftn.d613e3547" rel="nofollow"><span style="color:rgb(0,0,255)">21</span></a>][<a target="_blank" name="d613e3559"></a><a target="_blank" href="#ftn.d613e3559" rel="nofollow"><span style="color:rgb(0,0,255)">22</span></a>] （译者注:Bloom Filter是一个算法，可以用来快速确认一个Row Key或者值是否在一个Hfile里面。）</p>
<p><a target="_blank" name="bloom.config"></a><span style="color:rgb(153,0,0)">14.1. 配置</span></p>
<p>可以在column family的选项的配置Blooms.可以通过Hbase Shell，也可以用Java代码操作 org.apache.hadoop.hbase.HColumnDescriptor.</p>
<p><a target="_blank" name="d613e3574"></a><span style="color:rgb(153,0,0)">14.1.1. </span><span style="color:rgb(153,0,0)">HColumnDescriptor</span><span style="color:rgb(153,0,0)"> 配置</span></p>
<p>使用 HColumnDescriptor.setBloomFilterType(NONE | ROW | ROWCOL)来控制每个column family的Blooms这种。默认值是 NONE ，如果值是ROW，就会在插入的时候去Hash这个row，加入到Bloom中去。如果值是ROWCOL，就Hash这个row,column family和column family qualifer。(译者注，ROW是哈希row key)</p>
<p><a target="_blank" name="d613e3593"></a><span style="color:rgb(153,0,0)">14.1.2. </span><span style="color:rgb(153,0,0)">io.hfile.bloom.enabled</span><span style="color:rgb(153,0,0)"> 全局关闭开关</span></p>
<p>当有些东西出错的时候，Configuration中的io.hfile.bloom.enabled是一个关闭的开关。 默认是 true.</p>
<p><a target="_blank" name="d613e3609"></a><span style="color:rgb(153,0,0)">14.1.3. </span><span style="color:rgb(153,0,0)">io.hfile.bloom.error.rate</span></p>
<p>io.hfile.bloom.error.rate = 平均错误率。默认是 1%.减少一半(如 .5%)，就意味着每个bloom entry加一个bit.</p>
<p><a target="_blank" name="d613e3617"></a><span style="color:rgb(153,0,0)">14.1.4. </span><span style="color:rgb(153,0,0)">io.hfile.bloom.max.fold</span></p>
<p>io.hfile.bloom.max.fold = 保证最低的fold率。大多数人不该修改这个值，默认是7，就是说可以折叠到原本大小的1/128。参见 Development Process中的文档 <a target="_blank" href="https://issues.apache.org/jira/secure/attachment/12444007/Bloom_Filters_in_HBase.pdf" rel="nofollow"><span style="color:rgb(0,0,255)">BloomFilters in HBase</span></a>获得更多关于这个配置的信息。</p>
<p><a target="_blank" name="bloom_footprint"></a><span style="color:rgb(153,0,0)">14.2. Bloom StoreFile footprint</span></p>
<p>Bloom filters在StoreFile加入了一个entry.包括一般的 FileInfo 数据结构和两个额外entries到StoreFile的元数据部分中。</p>
<p><a target="_blank" name="d613e3645"></a><span style="color:rgb(153,0,0)">14.2.1. </span><span style="color:rgb(153,0,0)">StoreFile</span><span style="color:rgb(153,0,0)">中的BloomFilter， </span><span style="color:rgb(153,0,0)">FileInfo</span><span style="color:rgb(153,0,0)">数据结构</span></p>
<p><a target="_blank" name="d613e3653"></a><span style="color:rgb(153,0,0)">14.2.1.1. BLOOM_FILTER_TYPE</span></p>
<p>FileInfo有一个 BLOOM_FILTER_TYPE entry，可以被设置为 NONE, ROW 或者 ROWCOL.</p>
<p><a target="_blank" name="d613e3672"></a><span style="color:rgb(153,0,0)">14.2.2.  在 </span><span style="color:rgb(153,0,0)">StoreFile</span><span style="color:rgb(153,0,0)"> 元数据中的BloomFilter entries</span></p>
<p><a target="_blank" name="d613e3678"></a><span style="color:rgb(153,0,0)">14.2.2.1. BLOOM_FILTER_META</span></p>
<p>BLOOM_FILTER_META保存了Bloom的大小，使用的Hash算法等信息。他的大小的很小。 StoreFile.Reader加载的时候会缓存进去。</p>
<p><a target="_blank" name="d613e3689"></a><span style="color:rgb(153,0,0)">14.2.2.2. BLOOM_FILTER_DATA</span></p>
<p>BLOOM_FILTER_DATA是实际的bloomfiter数据。按需获取，保存在LRU缓存中(如果缓存是开启的，默认开启)。</p>
<p> </p>
<p></p>
<p>[<a target="_blank" name="ftn.d613e3547"></a><a target="_blank" href="#d613e3547" rel="nofollow"><span style="color:rgb(0,0,255)">21</span></a>] For description of the development process -- why static blooms rather than dynamic -- and for an overview of the unique properties that pertain to blooms in HBase, as well as possible future directions, see the Development Process section of the document <a target="_blank" href="https://issues.apache.org/jira/secure/attachment/12444007/Bloom_Filters_in_HBase.pdf" rel="nofollow"><span style="color:rgb(0,0,255)">BloomFilters in HBase</span></a> attached to <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE-1200" rel="nofollow"><span style="color:rgb(0,0,255)">HBase-1200</span></a>.</p>
<p>[<a target="_blank" name="ftn.d613e3559"></a><a target="_blank" href="#d613e3559" rel="nofollow"><span style="color:rgb(0,0,255)">22</span></a>] The bloom filters described here are actually version two of blooms in HBase. In versions up to 0.19.x, HBase had a dynamic bloom option based on work done by the <a target="_blank" href="http://www.one-lab.org/" rel="nofollow"><span style="color:rgb(0,0,255)">European Commission One-Lab Project 034819</span></a>. The core of the HBase bloom work was later pulled up into Hadoop to implement org.apache.hadoop.io.BloomMapFile. Version 1 of HBase blooms never worked that well. Version 2 is a rewrite from scratch though again it starts with the one-lab work.</p>
<p><a target="_blank" name="trouble"></a><span style="color:rgb(153,0,0)">Chapter 15. Hbase的故障排除和Debug</span></p>
<p>Table of Contents</p>
<p><a target="_blank" href="#trouble.general" rel="nofollow"><span style="color:rgb(0,0,255)">15.1. 一般准则</span></a></p>
<p><a target="_blank" href="#trouble.log" rel="nofollow"><span style="color:rgb(0,0,255)">15.2. Logs</span></a></p>
<p><a target="_blank" href="#trouble.log.locations" rel="nofollow"><span style="color:rgb(0,0,255)">15.2.1. Log 位置</span></a></p>
<p><a target="_blank" href="#trouble.tools" rel="nofollow"><span style="color:rgb(0,0,255)">15.3. 工具</span></a></p>
<p><a target="_blank" href="#trouble.tools.searchhadoop" rel="nofollow"><span style="color:rgb(0,0,255)">15.3.1. search-hadoop.com</span></a></p>
<p><a target="_blank" href="#trouble.tools.tail" rel="nofollow"><span style="color:rgb(0,0,255)">15.3.2. tail</span></a></p>
<p><a target="_blank" href="#trouble.tools.top" rel="nofollow"><span style="color:rgb(0,0,255)">15.3.3. top</span></a></p>
<p><a target="_blank" href="#trouble.tools.jps" rel="nofollow"><span style="color:rgb(0,0,255)">15.3.4. jps</span></a></p>
<p><a target="_blank" href="#trouble.tools.jstack" rel="nofollow"><span style="color:rgb(0,0,255)">15.3.5. jstack</span></a></p>
<p><a target="_blank" href="#trouble.tools.opentsdb" rel="nofollow"><span style="color:rgb(0,0,255)">15.3.6. OpenTSDB</span></a></p>
<p><a target="_blank" href="#trouble.tools.clustersshtop" rel="nofollow"><span style="color:rgb(0,0,255)">15.3.7. clusterssh+top</span></a></p>
<p><a target="_blank" href="#trouble.client" rel="nofollow"><span style="color:rgb(0,0,255)">15.4. 客户端</span></a></p>
<p><a target="_blank" href="#trouble.client.scantimeout" rel="nofollow"><span style="color:rgb(0,0,255)">15.4.1. ScannerTimeoutException</span></a></p>
<p><a target="_blank" href="#trouble.rs" rel="nofollow"><span style="color:rgb(0,0,255)">15.5. RegionServer</span></a></p>
<p><a target="_blank" href="#trouble.rs.startup" rel="nofollow"><span style="color:rgb(0,0,255)">15.5.1. 启动错误</span></a></p>
<p><a target="_blank" href="#trouble.rs.runtime" rel="nofollow"><span style="color:rgb(0,0,255)">15.5.2. 运行时错误</span></a></p>
<p><a target="_blank" href="#trouble.rs.shutdown" rel="nofollow"><span style="color:rgb(0,0,255)">15.5.3. 终止错误</span></a></p>
<p><a target="_blank" href="#trouble.master" rel="nofollow"><span style="color:rgb(0,0,255)">15.6. Master</span></a></p>
<p><a target="_blank" href="#trouble.master.startup" rel="nofollow"><span style="color:rgb(0,0,255)">15.6.1. 启动错误</span></a></p>
<p><a target="_blank" href="#trouble.master.startup" rel="nofollow"><span style="color:rgb(0,0,255)">15.6.2. 终止错误</span></a></p>
<p><a target="_blank" name="trouble.general"></a><span style="color:rgb(153,0,0)">15.1. 一般准则</span></p>
<p>首先可以看看master的log。通常情况下，他总是一行一行的重复信息。如果不是这样，说明有问题，可以Google或是用<a target="_blank" href="http://search-hadoop.com/" rel="nofollow"><span style="color:rgb(0,0,255)">search-hadoop.com</span></a>来搜索遇到的exception。</p>
<p>一个错误通常不是单独出现在Hbase中的，通常是某一个地方发生了异常，然后对其他的地方发生影响。到处都是exception和stack straces。遇到这样的错误，最好的办法是查日志，找到最初的异常。例如Region会在abort的时候打印一下信息。Grep这个Dump就有可能找到最初的异常信息。</p>
<p>RegionServer的自杀是很“正常”的。当一些事情发生错误的，他们就会自杀。如果ulimit和xcievers(最重要的两个设定，详见<a target="_blank" href="#ulimit" rel="nofollow" title="1.3.1.6.  ulimit 和 nproc"><span style="color:rgb(0,0,255)">Section 1.3.1.6, “ ulimit 和 nproc ”</span></a>)没有修改，HDFS将无法运转正常，在HBase看来，HDFS死掉了。假想一下，你的MySQL突然无法访问它的文件系统，他会怎么做。同样的事情会发生在Hbase和HDFS上。还有一个造成RegionServer切腹(译者注:竟然用日文词)自杀的常见的原因是，他们执行了一个长时间的GC操作，这个时间超过了ZooKeeper的session timeout。关于GC停顿的详细信息，参见Todd Lipcon的 <a target="_blank" href="http://www.cloudera.com/blog/2011/02/avoiding-full-gcs-in-hbase-with-memstore-local-allocation-buffers-part-1/" rel="nofollow"><span style="color:rgb(0,0,255)">3 part blog post</span></a> by Todd Lipcon 和上面的 <a target="_blank" href="#gcpause" rel="nofollow" title="13.1.1.1. 长时间GC停顿"><span style="color:rgb(0,0,255)">Section 13.1.1.1, “长时间GC停顿”</span></a>.</p>
<p><a target="_blank" name="trouble.log"></a><span style="color:rgb(153,0,0)">15.2. Logs</span></p>
<p>重要日志的位置( &lt;user&gt;是启动服务的用户，&lt;hostname&gt; 是机器的名字)</p>
<p>NameNode: <span style="color:rgb(0,122,0)">$HADOOP_HOME/logs/hadoop-&lt;user&gt;-namenode-&lt;hostname&gt;.log</span></p>
<p>DataNode: <span style="color:rgb(0,122,0)">$HADOOP_HOME/logs/hadoop-&lt;user&gt;-datanode-&lt;hostname&gt;.log</span></p>
<p>JobTracker: <span style="color:rgb(0,122,0)">$HADOOP_HOME/logs/hadoop-&lt;user&gt;-jobtracker-&lt;hostname&gt;.log</span></p>
<p>TaskTracker: <span style="color:rgb(0,122,0)">$HADOOP_HOME/logs/hadoop-&lt;user&gt;-jobtracker-&lt;hostname&gt;.log</span></p>
<p>HMaster: <span style="color:rgb(0,122,0)">$HBASE_HOME/logs/hbase-&lt;user&gt;-master-&lt;hostname&gt;.log</span></p>
<p>RegionServer: <span style="color:rgb(0,122,0)">$HBASE_HOME/logs/hbase-&lt;user&gt;-regionserver-&lt;hostname&gt;.log</span></p>
<p>ZooKeeper: <span style="color:rgb(0,122,0)">TODO</span></p>
<p><a target="_blank" name="trouble.log.locations"></a><span style="color:rgb(153,0,0)">15.2.1. Log 位置</span></p>
<p>对于单节点模式，Log都会在一台机器上，但是对于生产环境，都会运行在一个集群上。</p>
<p><a target="_blank" name="trouble.log.locations.namenode"></a><span style="color:rgb(153,0,0)">15.2.1.1. NameNode</span></p>
<p>NameNode的日志在NameNode server上。HBase Master 通常也运行在NameNode server上，ZooKeeper通常也是这样。</p>
<p>对于小一点的机器，JobTracker也通常运行在NameNode server上面。</p>
<p><a target="_blank" name="trouble.log.locations.datanode"></a><span style="color:rgb(153,0,0)">15.2.1.2. DataNode</span></p>
<p>每一台DataNode server有一个HDFS的日志，Region有一个Hbase日志。</p>
<p>每个DataNode server还有一份TaskTracker的日志，来记录MapReduce的Task信息。</p>
<p><a target="_blank" name="trouble.tools"></a><span style="color:rgb(153,0,0)">15.3. 工具</span></p>
<p><a target="_blank" name="trouble.tools.searchhadoop"></a><span style="color:rgb(153,0,0)">15.3.1. search-hadoop.com</span></p>
<p><a target="_blank" href="http://search-hadoop.com/" rel="nofollow"><span style="color:rgb(0,0,255)">search-hadoop.com</span></a>将所有的 mailing lists 和 <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE" rel="nofollow"><span style="color:rgb(0,0,255)">JIRA</span></a>建立了索引。用它来找Hadoop/HBase的问题很方便。</p>
<p><a target="_blank" name="trouble.tools.tail"></a><span style="color:rgb(153,0,0)">15.3.2. tail</span></p>
<p>tail是一个命令行工具，可以用来看日志的尾巴。加入的"-f"参数后，就会在数据更新的时候自己刷新。用它来看日志很方便。例如，一个机器需要花很多时间来启动或关闭，你可以tail他的master log(也可以是region server的log)。</p>
<p><a target="_blank" name="trouble.tools.top"></a><span style="color:rgb(153,0,0)">15.3.3. top</span></p>
<p>top是一个很重要的工具来看你的机器各个进程的资源占用情况。下面是一个生产环境的例子：</p>
<p>top - 14:46:59 up 39 days, 11:55,  1 user,  load average: 3.75, 3.57, 3.84</p>
<p>Tasks: 309 total,   1 running, 308 sleeping,   0 stopped,   0 zombie</p>
<p>Cpu(s):  4.5%us,  1.6%sy,  0.0%ni, 91.7%id,  1.4%wa,  0.1%hi,  0.6%si,  0.0%st</p>
<p>Mem:  24414432k total, 24296956k used,   117476k free,     7196k buffers</p>
<p>Swap: 16008732k total, 14348k used, 15994384k free, 11106908k cached</p>
<p> </p>
<p>PID USER   PR  NI  VIRT  RES  SHR S %CPU %MEM TIME+  COMMAND</p>
<p>15558 hadoop 18  -2 3292m 2.4g 3556 S   79 10.4   6523:52 java</p>
<p>13268 hadoop 18  -2 8967m 8.2g 4104 S   21 35.1   5170:30 java</p>
<p>8895 hadoop 18  -2 1581m 497m 3420 S   11  2.1   4002:32 java</p>
<p>…</p>
<p> </p>
<p>这里你可以看到系统的load average在最近5分钟是3.75，意思就是说这5分钟里面平均有3.75个线程在CPU时间的等待队列里面。通常来说，最完美的情况是这个值和CPU和核数相等，比这个值低意味着资源闲置，比这个值高就是过载了。这是一个重要的概念，要想理解的更多，可以看这篇文章 <a target="_blank" href="http://www.linuxjournal.com/article/9001" rel="nofollow"><span style="color:rgb(0,0,255)">http://www.linuxjournal.com/article/9001</span></a>.</p>
<p>处理负载，我们可以看到系统已经几乎使用了他的全部RAM，其中大部分都是用于OS cache(这是一件好事).Swap只使用了一点点KB,这正是我们期望的，如果数值很高的话，就意味着在进行交换，这对Java程序的性能是致命的。另一种检测交换的方法是看Load average是否过高(load average过高还可能是磁盘损坏或者其它什么原因导致的)。</p>
<p>默认情况下进程列表不是很有用，我们可以看到3个Java进程使用了111%的CPU。要想知道哪个进程是什么，可以输入"c"，每一行就会扩展信息。输入“1”可以显示CPU的每个核的具体状况。</p>
<p><a target="_blank" name="trouble.tools.jps"></a><span style="color:rgb(153,0,0)">15.3.4. jps</span></p>
<p>jps是JDK集成的一个工具，可以用来看当前用户的Java进程id。(如果是root,可以看到所有用户的id)，例如:</p>
<p>hadoop@sv4borg12:~$ jps</p>
<p>1322 TaskTracker</p>
<p>17789 HRegionServer</p>
<p>27862 Child</p>
<p>1158 DataNode</p>
<p>25115 HQuorumPeer</p>
<p>2950 Jps</p>
<p>19750 ThriftServer</p>
<p>18776 jmx</p>
<p> </p>
<p>按顺序看</p>
<p>· Hadoop TaskTracker,管理本地的Task</p>
<p>· HBase RegionServer,提供region的服务</p>
<p>· Child, 一个 MapReduce task,无法看出详细类型</p>
<p>· Hadoop DataNode, 管理blocks</p>
<p>· HQuorumPeer, ZooKeeper集群的成员</p>
<p>· Jps, 就是这个进程</p>
<p>· ThriftServer, 当thrif启动后，就会有这个进程</p>
<p>· jmx, 这个是本地监控平台的进程。你可以不用这个。</p>
<p>你可以看到这个进程启动是全部命令行信息。</p>
<p>hadoop@sv4borg12:~$ ps aux | grep HRegionServer</p>
<p>hadoop   17789  155 35.2 9067824 8604364 ?     S&lt;l  Mar04 9855:48 /usr/java/jdk1.6.0_14/bin/java -Xmx8000m -XX:+DoEscapeAnalysis -XX:+AggressiveOpts -XX:+UseConcMarkSweepGC -XX:NewSize=64m -XX:MaxNewSize=64m -XX:CMSInitiatingOccupancyFraction=88 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:/export1/hadoop/logs/gc-hbase.log -Dcom.sun.management.jmxremote.port=10102 -Dcom.sun.management.jmxremote.authenticate=true -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.password.file=/home/hadoop/hbase/conf/jmxremote.password -Dcom.sun.management.jmxremote -Dhbase.log.dir=/export1/hadoop/logs -Dhbase.log.file=hbase-hadoop-regionserver-sv4borg12.log -Dhbase.home.dir=/home/hadoop/hbase -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,DRFA -Djava.library.path=/home/hadoop/hbase/lib/native/Linux-amd64-64 -classpath /home/hadoop/hbase/bin/../conf:[many jars]:/home/hadoop/hadoop/conf org.apache.hadoop.hbase.regionserver.HRegionServer start</p>
<p> </p>
<p><a target="_blank" name="trouble.tools.jstack"></a><span style="color:rgb(153,0,0)">15.3.5. jstack</span></p>
<p>jstack 是一个最重要(除了看Log)的java工具，可以看到具体的Java进程的在做什么。可以先用Jps看到进程的Id,然后就可以用jstack。他会按线程的创建顺序显示线程的列表，还有这个线程在做什么。下面是例子：</p>
<p>这个主线程是一个RegionServer正在等master返回什么信息。</p>
<p>"regionserver60020" prio=10 tid=0x0000000040ab4000 nid=0x45cf waiting on condition [0x00007f16b6a96000..0x00007f16b6a96a70]</p>
<p>java.lang.Thread.State: TIMED_WAITING (parking)</p>
<p>at sun.misc.Unsafe.park(Native Method)</p>
<p>- parking to wait for  &lt;0x00007f16cd5c2f30&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)</p>
<p>at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)</p>
<p>at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1963)</p>
<p>at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:395)</p>
<p>at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:647)</p>
<p>at java.lang.Thread.run(Thread.java:619)</p>
<p> </p>
<p>The MemStore flusher thread that is currently flushing to a file:</p>
<p>"regionserver60020.cacheFlusher" daemon prio=10 tid=0x0000000040f4e000 nid=0x45eb in Object.wait() [0x00007f16b5b86000..0x00007f16b5b87af0]</p>
<p>java.lang.Thread.State: WAITING (on object monitor)</p>
<p>at java.lang.Object.wait(Native Method)</p>
<p>at java.lang.Object.wait(Object.java:485)</p>
<p>at org.apache.hadoop.ipc.Client.call(Client.java:803)</p>
<p>- locked &lt;0x00007f16cb14b3a8&gt; (a org.apache.hadoop.ipc.Client$Call)</p>
<p>at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:221)</p>
<p>at $Proxy1.complete(Unknown Source)</p>
<p>at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)</p>
<p>at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)</p>
<p>at java.lang.reflect.Method.invoke(Method.java:597)</p>
<p>at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)</p>
<p>at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)</p>
<p>at $Proxy1.complete(Unknown Source)</p>
<p>at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.closeInternal(DFSClient.java:3390)</p>
<p>- locked &lt;0x00007f16cb14b470&gt; (a org.apache.hadoop.hdfs.DFSClient$DFSOutputStream)</p>
<p>at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.close(DFSClient.java:3304)</p>
<p>at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:61)</p>
<p>at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:86)</p>
<p>at org.apache.hadoop.hbase.io.hfile.HFile$Writer.close(HFile.java:650)</p>
<p>at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.close(StoreFile.java:853)</p>
<p>at org.apache.hadoop.hbase.regionserver.Store.internalFlushCache(Store.java:467)</p>
<p>- locked &lt;0x00007f16d00e6f08&gt; (a java.lang.Object)</p>
<p>at org.apache.hadoop.hbase.regionserver.Store.flushCache(Store.java:427)</p>
<p>at org.apache.hadoop.hbase.regionserver.Store.access$100(Store.java:80)</p>
<p>at org.apache.hadoop.hbase.regionserver.Store$StoreFlusherImpl.flushCache(Store.java:1359)</p>
<p>at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:907)</p>
<p>at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:834)</p>
<p>at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:786)</p>
<p>at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:250)</p>
<p>at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:224)</p>
<p>at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.run(MemStoreFlusher.java:146)</p>
<p> </p>
<p>一个处理线程是在等一些东西(例如put, delete, scan...):</p>
<p>"IPC Server handler 16 on 60020" daemon prio=10 tid=0x00007f16b011d800 nid=0x4a5e waiting on condition [0x00007f16afefd000..0x00007f16afefd9f0]</p>
<p>java.lang.Thread.State: WAITING (parking)</p>
<p>at sun.misc.Unsafe.park(Native Method)</p>
<p>- parking to wait for  &lt;0x00007f16cd3f8dd8&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)</p>
<p>at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)</p>
<p>at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)</p>
<p>at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)</p>
<p>at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1013)</p>
<p> </p>
<p>有一个线程正在忙，在递增一个counter(这个阶段是正在创建一个scanner来读最新的值):</p>
<p>"IPC Server handler 66 on 60020" daemon prio=10 tid=0x00007f16b006e800 nid=0x4a90 runnable [0x00007f16acb77000..0x00007f16acb77cf0]</p>
<p>java.lang.Thread.State: RUNNABLE</p>
<p>at org.apache.hadoop.hbase.regionserver.KeyValueHeap.&lt;init&gt;(KeyValueHeap.java:56)</p>
<p>at org.apache.hadoop.hbase.regionserver.StoreScanner.&lt;init&gt;(StoreScanner.java:79)</p>
<p>at org.apache.hadoop.hbase.regionserver.Store.getScanner(Store.java:1202)</p>
<p>at org.apache.hadoop.hbase.regionserver.HRegion$RegionScanner.&lt;init&gt;(HRegion.java:2209)</p>
<p>at org.apache.hadoop.hbase.regionserver.HRegion.instantiateInternalScanner(HRegion.java:1063)</p>
<p>at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1055)</p>
<p>at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1039)</p>
<p>at org.apache.hadoop.hbase.regionserver.HRegion.getLastIncrement(HRegion.java:2875)</p>
<p>at org.apache.hadoop.hbase.regionserver.HRegion.incrementColumnValue(HRegion.java:2978)</p>
<p>at org.apache.hadoop.hbase.regionserver.HRegionServer.incrementColumnValue(HRegionServer.java:2433)</p>
<p>at sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)</p>
<p>at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)</p>
<p>at java.lang.reflect.Method.invoke(Method.java:597)</p>
<p>at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:560)</p>
<p>at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1027)</p>
<p> </p>
<p>还有一个线程在从HDFS获取数据。</p>
<p> </p>
<p>"IPC Client (47) connection to sv4borg9/10.4.24.40:9000 from hadoop" daemon prio=10 tid=0x00007f16a02d0000 nid=0x4fa3 runnable [0x00007f16b517d000..0x00007f16b517dbf0]</p>
<p>java.lang.Thread.State: RUNNABLE</p>
<p>at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)</p>
<p>at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:215)</p>
<p>at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)</p>
<p>at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)</p>
<p>- locked &lt;0x00007f17d5b68c00&gt; (a sun.nio.ch.Util$1)</p>
<p>- locked &lt;0x00007f17d5b68be8&gt; (a java.util.Collections$UnmodifiableSet)</p>
<p>- locked &lt;0x00007f1877959b50&gt; (a sun.nio.ch.EPollSelectorImpl)</p>
<p>at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)</p>
<p>at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:332)</p>
<p>at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)</p>
<p>at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)</p>
<p>at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)</p>
<p>at java.io.FilterInputStream.read(FilterInputStream.java:116)</p>
<p>at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:304)</p>
<p>at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)</p>
<p>at java.io.BufferedInputStream.read(BufferedInputStream.java:237)</p>
<p>- locked &lt;0x00007f1808539178&gt; (a java.io.BufferedInputStream)</p>
<p>at java.io.DataInputStream.readInt(DataInputStream.java:370)</p>
<p>at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:569)</p>
<p>at org.apache.hadoop.ipc.Client$Connection.run(Client.java:477)</p>
<p> </p>
<p>这里是一个RegionServer死了，master正在试着恢复。</p>
<p>"LeaseChecker" daemon prio=10 tid=0x00000000407ef800 nid=0x76cd waiting on condition [0x00007f6d0eae2000..0x00007f6d0eae2a70]</p>
<p>--</p>
<p>java.lang.Thread.State: WAITING (on object monitor)</p>
<p>at java.lang.Object.wait(Native Method)</p>
<p>at java.lang.Object.wait(Object.java:485)</p>
<p>at org.apache.hadoop.ipc.Client.call(Client.java:726)</p>
<p>- locked &lt;0x00007f6d1cd28f80&gt; (a org.apache.hadoop.ipc.Client$Call)</p>
<p>at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)</p>
<p>at $Proxy1.recoverBlock(Unknown Source)</p>
<p>at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:2636)</p>
<p>at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.&lt;init&gt;(DFSClient.java:2832)</p>
<p>at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:529)</p>
<p>at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:186)</p>
<p>at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:530)</p>
<p>at org.apache.hadoop.hbase.util.FSUtils.recoverFileLease(FSUtils.java:619)</p>
<p>at org.apache.hadoop.hbase.regionserver.wal.HLog.splitLog(HLog.java:1322)</p>
<p>at org.apache.hadoop.hbase.regionserver.wal.HLog.splitLog(HLog.java:1210)</p>
<p>at org.apache.hadoop.hbase.master.HMaster.splitLogAfterStartup(HMaster.java:648)</p>
<p>at org.apache.hadoop.hbase.master.HMaster.joinCluster(HMaster.java:572)</p>
<p>at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:503)</p>
<p> </p>
<p><a target="_blank" name="trouble.tools.opentsdb"></a><span style="color:rgb(153,0,0)">15.3.6. OpenTSDB</span></p>
<p><a target="_blank" href="http://opentsdb.net/" rel="nofollow"><span style="color:rgb(0,0,255)">OpenTSDB</span></a>是一个Ganglia的很好的替代品，因为他使用Hbase来存储所有的时序而不需要采样。使用OpenTSDB来监控你的Hbase是一个很好的实践</p>
<p>这里有一个例子，集群正在同时进行上百个compaction，严重影响了IO性能。(TODO: 在这里插入compactionQueueSize的图片)(译者注:囧)</p>
<p>给集群构建一个图表监控是一个很好的实践。包括集群和每台机器。这样就可以快速定位到问题。例如，在StumbleUpon，每个机器有一个图表监控，包括OS和Hbase，涵盖所有的重要的信息。你也可以登录到机器上，获取更多的信息。</p>
<p><a target="_blank" name="trouble.tools.clustersshtop"></a><span style="color:rgb(153,0,0)">15.3.7. clusterssh+top</span></p>
<p>clusterssh+top,感觉是一个穷人用的监控系统，但是他确实很有效，当你只有几台机器的是，很好设置。启动clusterssh后，你就会每台机器有个终端，还有一个终端，你在这个终端的操作都会反应到其他的每一个终端上。 这就意味着，你在一天机器执行“top”,集群中的所有机器都会给你全部的top信息。你还可以这样tail全部的log，等等。</p>
<p><a target="_blank" name="trouble.client"></a><span style="color:rgb(153,0,0)">15.4. 客户端</span></p>
<p><a target="_blank" name="trouble.client.scantimeout"></a><span style="color:rgb(153,0,0)">15.4.1. ScannerTimeoutException</span></p>
<p>当从客户端到RegionServer的RPC请求超时。例如如果Scan.setCacheing的值设置为500，RPC请求就要去获取500行的数据，每500次.next()操作获取一次。因为数据是以大块的形式传到客户端的，就可能造成超时。将这个 serCacheing的值调小是一个解决办法，但是这个值要是设的太小就会影响性能。</p>
<p><a target="_blank" name="trouble.rs"></a><span style="color:rgb(153,0,0)">15.5. RegionServer</span></p>
<p><a target="_blank" name="trouble.rs.startup"></a><span style="color:rgb(153,0,0)">15.5.1. 启动错误</span></p>
<p><a target="_blank" name="trouble.rs.startup.compression"></a><span style="color:rgb(153,0,0)">15.5.1.1. 压缩链接错误</span></p>
<p>因为LZO压缩算法需要在集群中的每台机器都要安装，这是一个启动失败的常见错误。如果你获得了如下信息</p>
<p>11/02/20 01:32:15 ERROR lzo.GPLNativeCodeLoader: Could not load native gpl library</p>
<p>java.lang.UnsatisfiedLinkError: no gplcompression in java.library.path</p>
<p>at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1734)</p>
<p>at java.lang.Runtime.loadLibrary0(Runtime.java:823)</p>
<p>at java.lang.System.loadLibrary(System.java:1028)</p>
<p> </p>
<p>就意味着你的压缩库出现了问题。参见配置章节的 <a target="_blank" href="#lzo" rel="nofollow" title="3.6.4. LZO 压缩"><span style="color:rgb(0,0,255)">LZO compression configuration</span></a>.</p>
<p><a target="_blank" name="trouble.rs.runtime"></a><span style="color:rgb(153,0,0)">15.5.2. 运行时错误</span></p>
<p><a target="_blank" name="trouble.rs.runtime.filehandles"></a><span style="color:rgb(153,0,0)">15.5.2.1. java.io.IOException...(Too many open files)</span></p>
<p>参见快速入门的章节<a target="_blank" href="#ulimit" rel="nofollow" title="1.3.1.6.  ulimit 和 nproc"><span style="color:rgb(0,0,255)">ulimit and nproc configuration</span></a>.</p>
<p><a target="_blank" name="trouble.rs.runtime.xceivers"></a><span style="color:rgb(153,0,0)">15.5.2.2. xceiverCount 258 exceeds the limit of concurrent xcievers 256</span></p>
<p>这个时常会出现在DataNode的日志中。</p>
<p>参见快速入门章节的 <a target="_blank" href="#dfs.datanode.max.xcievers" rel="nofollow" title="1.3.1.7. dfs.datanode.max.xcievers"><span style="color:rgb(0,0,255)">xceivers configuration</span></a>.</p>
<p><a target="_blank" name="trouble.rs.runtime.oom-nt"></a><span style="color:rgb(153,0,0)">15.5.2.3. 系统不稳定,DataNode或者其他系统进程有 "java.lang.OutOfMemoryError: unable to create new native thread in exceptions"的错误</span></p>
<p>参见快速入门章节的 <a target="_blank" href="#ulimit" rel="nofollow" title="1.3.1.6.  ulimit 和 nproc"><span style="color:rgb(0,0,255)">ulimit and nproc configuration</span></a>.</p>
<p><a target="_blank" name="trouble.rs.runtime.gc"></a><span style="color:rgb(153,0,0)">15.5.2.4. DFS不稳定或者RegionServer租期超时</span></p>
<p>如果你收到了如下的消息</p>
<p>2009-02-24 10:01:33,516 WARN org.apache.hadoop.hbase.util.Sleeper: We slept xxx ms, ten times longer than scheduled: 10000</p>
<p>2009-02-24 10:01:33,516 WARN org.apache.hadoop.hbase.util.Sleeper: We slept xxx ms, ten times longer than scheduled: 15000</p>
<p>2009-02-24 10:01:36,472 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: unable to report to master for xxx milliseconds - retrying</p>
<p> </p>
<p>或者看到了全GC压缩操作，你可能正在执行一个全GC。</p>
<p><a target="_blank" name="trouble.rs.runtime.nolivenodes"></a><span style="color:rgb(153,0,0)">15.5.2.5. "No live nodes contain current block" and/or YouAreDeadException</span></p>
<p>这个错误有可能是OS的文件句柄溢出，也可能是网络故障导致节点无法访问。</p>
<p>参见快速入门章节 <a target="_blank" href="#ulimit" rel="nofollow" title="1.3.1.6.  ulimit 和 nproc"><span style="color:rgb(0,0,255)">ulimit and nproc configuration</span></a>，检查你的网络。</p>
<p><a target="_blank" name="trouble.rs.shutdown"></a><span style="color:rgb(153,0,0)">15.5.3. 终止错误</span></p>
<p><a target="_blank" name="trouble.master"></a><span style="color:rgb(153,0,0)">15.6. Master</span></p>
<p><span style="color:rgb(153,0,0)">15.6.1. 启动错误</span></p>
<p><a target="_blank" name="trouble.master.startup"></a><span style="color:rgb(153,0,0)">15.6.2. 终止错误</span></p>
<p><a target="_blank" name="tools"></a>三、 <a target="_blank" name="d613e4032"></a>HBase Coprocessor的分析</p>
<p> </p>
<p><a target="_blank" href="http://blog.nosqlfan.com/tags/hbase" rel="nofollow" title="查看 hbase 的全部文章"><span style="color:rgb(0,0,255)">hbase</span></a> Coprocessor是很多人对hbase-0.92的重大期待之一。它让离线分析和在线应用很好地结合在了一起，另外也极大地拓展了hbase的应用丰富性，不再是简单的k-v类应用。hbase <a target="_blank" href="http://blog.nosqlfan.com/tags/coprocessor" rel="nofollow" title="查看 coprocessor 的全部文章"><span style="color:rgb(0,0,255)">coprocessor</span></a>的设计来源于hbase-2000和hbase-2001两个issue。那么几年过去了，hbase coprocessor究竟发展到什么程度，可以将它们用于哪些地方呢？下文主要内容来源于Trend Micro Hadoop Group的成员，同时也是hbase coprocessor的作者，不愿意看底下啰嗦废话的同学可以直接跳到最后面的总结看。</p>
<p><a target="_blank" href="https://blogs.apache.org/hbase/entry/coprocessor_introduction" rel="nofollow"><span style="color:rgb(0,0,255)">https://blogs.apache.org/hbase/entry/coprocessor_introduction</span></a></p>
<p>hbase coprocessor随着0.92的release而完整地release出来了，它的设计来源于google bigtable的coprocessor(Jeff Dean的一篇演讲)。coprocessor其实是一个类似mapreduce的分析组件，不过它极大简化了mapreduce模型，只是将请求独立地在各个region中并行地运行，并且提供了一套框架能够让用户非常灵活地编写自定义的coprocessor。hbase的coprocessor与google的coprocessor最大的区别是，hbase的coprocessor是一套在regionserver和master进程内的框架，可以在运行期动态执行用户的代码，而google的coprocessor则是拥有自己独立的进程和地址空间。看起来似乎hbase的coprocessor更加高效，但其实并非如此，拥有独立的地址空间的好处是可以通过与计算资源的绑定更高效地使用硬件，比如通过cgroup的方式绑定到独立的cpu上去工作。<br>
现在hbase的coprocessor有两种完全不同的实现，分别是observer模式与endpoint模式，它们分别对应2000和2001两个issue。我们可以将observer模式看成数据库中的触发器，而endpoint可以看成是存储过程。</p>
<p>关于coprocessor我们可以从类继承关系上看到，如下图所示：</p>
<p> </p>
<p>共有三个Observer对象，即MasterObserver，RegionObserver和WALObserver。它们的工作原理类似于钩子函数，在真实的函数实现前加入pre()，实现后加入post()方法，来实现对操作进行一些嵌入式的改变。效率上的影响仅仅取决于嵌入的钩子函数本身的影响。如下图所示：</p>
<p> </p>
<p>比如下面这段代码就实现了在get之前做权限检查：</p>
<p>publicclassAccessControlCoprocessorextends BaseRegionObserver {</p>
<p>@Override</p>
<p>public void preGet(final ObserverContext c,</p>
<p>final Get get, final List result) throws IOException</p>
<p>throws IOException {</p>
<p> </p>
<p>// check permissions..</p>
<p>if (!permissionGranted()) {</p>
<p>thrownewAccessDeniedException("User is not allowed to access.");</p>
<p>}</p>
<p>}</p>
<p> </p>
<p>// override prePut(), preDelete(), etc.</p>
<p>}</p>
<p>在hbase的社区中，己经有很多人提出了各种基于Observer的实现方法，来做一些有意义的事。比如可以通过regionObserver实现刚才说的权限，还有故障隔离，优先级等工作。通过MasterObserver则可以实现对ddl操作的监控。通过WALObserver则可以实现二级索引、replication等工作。不过遗憾的是，很少有想法实现了，主要原因还是大家都比较忙，而相应的需求在现阶段还不强烈，所以留待后面来做。由于Observer框架的灵活性和扩展性，用户可以方便地自定义各种符合自己需求的实现。</p>
<p>BaseEndpoint类则是直接实现了Coprocessor接口，它实际上是client-side的实现，即客户端包装了一个HTable的实现，将类似于getMin()的操作包装起来，内部则通过并行scan等操作来实现。这就很类似一个简单的mapreduce，map就是在目标region server上的那些region，而reduce则是客户端。这个方法对于习惯于编写map reduce代码的人来说非常直观，可以很容易地实现sum，min等接口。由于这一层包装，可以屏蔽掉很多开发上的细节，让开发应用的人专注于开发应用，将底层实现交给mapreduce programmer。</p>
<p>一个简单的Endpoint例子如下：</p>
<p>public T getMin(ColumnInterpreter ci, Scan scan)</p>
<p>throws IOException {</p>
<p>T min = null;</p>
<p>T temp;</p>
<p>InternalScanner scanner = ((RegionCoprocessorEnvironment) getEnvironment())</p>
<p>.getRegion().getScanner(scan);</p>
<p>List results = new ArrayList();</p>
<p>byte[] colFamily = scan.getFamilies()[0];</p>
<p>byte[] qualifier = scan.getFamilyMap().get(colFamily).pollFirst();</p>
<p>try {</p>
<p>boolean hasMoreRows = false;</p>
<p>do {</p>
<p>hasMoreRows = scanner.next(results);</p>
<p>for (KeyValue kv : results) {</p>
<p>temp = ci.getValue(colFamily, qualifier, kv);</p>
<p>min = (min == null || ci.compare(temp, min) &lt; 0) ? temp : min;</p>
<p>}</p>
<p>results.clear();</p>
<p>} while (hasMoreRows);</p>
<p>} finally {</p>
<p>scanner.close();</p>
<p>}</p>
<p>log.info("Minimum from this region is "</p>
<p>+ ((RegionCoprocessorEnvironment) getEnvironment()).getRegion()</p>
<p>.getRegionNameAsString() + ": " + min);</p>
<p>return min;</p>
<p>}</p>
<p>Coprocessor可以让用户随时加载自己实现的代码，而不需要重启系统。它可以通过配置来加载，也可以通过shell或java程序来加载。</p>
<p>总结：</p>
<p>· hbase coprocessor是脱胎于google bigtable coprocessor，区别是hbase coprocessor并非独立进程，而是在原来进程中嵌入框架</p>
<p>· hbase coprocessor的实现分为observer与endpoint，其中observer类似于触发器，主要在服务端工作，而endpoint类似于存储过程，主要在client端工作</p>
<p>· observer可以实现权限管理、优先级设置、监控、ddl控制、二级索引等功能，而endpoint可以实现min、mas、avg、sum等功能</p>
<p>· coprocessor可以动态加载</p>
<p>· coprocessor的性能取决于想要加载的方法的性能，不过为了有一个直观的了解，我们仍然近期打算对hbase coprocessor的一些典型场景做性能测试。</p>
<p>四、 HBase在淘宝的应用和优化小结</p>
<p> </p>
<h3> 1 前言</h3>
<p><a target="_blank" href="http://blog.nosqlfan.com/tags/hbase" rel="nofollow" title="查看 hbase 的全部文章"><span style="color:rgb(0,0,255)">hbase</span></a>是从<a target="_blank" href="http://blog.nosqlfan.com/tags/hadoop" rel="nofollow" title="查看 hadoop 的全部文章"><span style="color:rgb(0,0,255)">hadoop</span></a>中分离出来的apache顶级开源项目。由于它很好地用java实现了google的bigtable系统大部分特性，因此在数据量猛增的今天非常受到欢迎。对于淘宝而言，随着市场规模的扩大，产品与技术的发展，业务数据量越来越大，对海量数据的高效插入和读取变得越来越重要。由于淘宝拥有也许是国内最大的单一hadoop集群(云梯)，因此对hadoop系列的产品有比较深入的了解，也就自然希望使用hbase来做这样一种海量数据读写服务。本篇文章将对淘宝最近一年来在online应用上使用和优化hbase的情况做一次小结。</p>
<p>2 原因</p>
<p>为什么要使用hbase？</p>
<p>淘宝在2011年之前所有的后端持久化存储基本上都是在mysql上进行的(不排除少量oracle/bdb/tair/mongdb等)，mysql由于开源，并且生态系统良好，本身拥有分库分表等多种解决方案，因此很长一段时间内都满足淘宝大量业务的需求。</p>
<p>但是由于业务的多样化发展，有越来越多的业务系统的需求开始发生了变化。一般来说有以下几类变化：</p>
<p>· a) 数据量变得越来越多，事实上现在淘宝几乎任何一个与用户相关的在线业务的数据量都在亿级别，每日系统调用次数从亿到百亿都有，且历史数据不能轻易删除。这需要有一个海量分布式文件系统，能对TB级甚至PB级别的数据提供在线服务</p>
<p>· b) 数据量的增长很快且不一定能准确预计，大多数应用系统从上线起在一段时间内数据量都呈很快的上升趋势，因此从成本的角度考虑对系统水平扩展能力有比较强烈的需求，且不希望存在单点制约</p>
<p>· c) 只需要简单的kv读取，没有复杂的join等需求。但对系统的并发能力以及吞吐量、响应延时有非常高的需求，并且希望系统能够保持强一致性</p>
<p>· d) 通常系统的写入非常频繁，尤其是大量系统依赖于实时的日志分析</p>
<p>· e) 希望能够快速读取批量数据</p>
<p>· f ) schema灵活多变，可能经常更新列属性或新增列</p>
<p>· g) 希望能够方便使用，有良好且语义清晰的java接口</p>
<p>以上需求综合在一起，我们认为hbase是一种比较适合的选择。首先它的数据由hdfs天然地做了数据冗余，云梯三年的稳定运行，数据100%可靠己经证明了hdfs集群的安全性，以及服务于海量数据的能力。其次hbase本身的数据读写服务没有单点的限制，服务能力可以随服务器的增长而线性增长，达到几十上百台的规模。LSM-Tree模式的设计让hbase的写入性能非常良好，单次写入通常在1-3ms内即可响应完成，且性能不随数据量的增长而下降。region（相当于数据库的分表）可以ms级动态的切分和移动，保证了负载均衡性。由于hbase上的数据模型是按rowkey排序存储的，而读取时会一次读取连续的整块数据做为cache，因此良好的rowkey设计可以让批量读取变得十分容易，甚至只需要１次io就能获取几十上百条用户想要的数据。最后，淘宝大部分工程师是java背景的同学，因此hbase的api对于他们来说非常容易上手，培训成本相对较低。</p>
<p>当然也必须指出，在大数据量的背景下银弹是不存在的，hbase本身也有不适合的场景。比如，索引只支持主索引（或看成主组合索引），又比如服务是单点的，单台机器宕机后在master恢复它期间它所负责的部分数据将无法服务等。这就要求在选型上需要对自己的应用系统有足够了解。</p>
<p>3 应用情况</p>
<p>我们从2011年3月开始研究hbase如何用于在线服务。尽管之前在一淘搜索中己经有了几十节点的离线服务。这是因为hbase早期版本的目标就是一个海量数据中的离线服务。2009年9月发布的0.20.0版本是一个里程碑，online应用正式成为了hbase的目标，为此hbase引入了zookeeper来做为backupmaster以及regionserver的管理。2011年1月0.90.0版本是另一个里程碑，基本上我们今天看到的各大网站，如facebook/ebay/yahoo内所使用于生产的hbase都是基于这一个版本(fb所采用的0.89版本结构与0.90.x相近)。bloomfilter等诸多属性加入了进来，性能也有极大提升。基于此，淘宝也选用了0.90.x分支作为线上版本的基础。</p>
<p>第一个上线的应用是数据魔方中的prom。prom原先是基于redis构建的，因为数据量持续增大以及需求的变化，因此我们用hbase重构了它的存储层。准确的说prom更适合0.92版本的hbase，因为它不仅需要高速的在线读写，更需要count/group by等复杂应用。但由于当时0.92版本尚未成熟，因此我们自己单独实现了coprocessor。prom的数据导入是来源于云梯，因此我们每天晚上花半个小时将数据从云梯上写入hbase所在的hdfs，然后在web层做了一个client转发。经过一个月的数据比对，确认了速度比之redis并未有明显下降，以及数据的准确性，因此得以顺利上线。</p>
<p>第二个上线的应用是TimeTunnel，TimeTunnel是一个高效的、可靠的、可扩展的实时数据传输平台，广泛应用于实时日志收集、数据实时监控、广告效果实时反馈、数据库实时同步等领域。它与prom相比的特点是增加了在线写。动态的数据增加使hbase上compact/balance/split/recovery等诸多特性受到了极大的挑战。TT的写入量大约一天20TB，读的量约为此的1.5倍，我们为此准备了20台regionserver的集群，当然底层的hdfs是公用的，数量更为庞大（下文会提到）。每天TT会为不同的业务在hbase上建不同的表，然后往该表上写入数据，即使我们将region的大小上限设为1GB，最大的几个业务也会达到数千个region这样的规模，可以说每一分钟都会有数次split。在TT的上线过程中，我们修复了hbase很多关于split方面的bug，有好几个commit到了hbase社区，同时也将社区一些最新的patch打在了我们的版本上。split相关的bug应该说是hbase中会导致数据丢失最大的风险之一，这一点对于每个想使用hbase的开发者来说必须牢记。hbase由于采用了LSM-Tree模型，从架构原理上来说数据几乎没有丢失的可能，但是在实际使用中不小心谨慎就有丢失风险。原因后面会单独强调。TT在预发过程中我们分别因为Meta表损坏以及split方面的bug曾经丢失过数据，因此也单独写了meta表恢复工具，确保今后不发生类似问题(hbase-0.90.5以后的版本都增加了类似工具)。另外，由于我们存放TT的机房并不稳定，发生过很多次宕机事故，甚至发生过假死现象。因此我们也着手修改了一些patch，以提高宕机恢复时间，以及增强了监控的强度。</p>
<p>CTU以及会员中心项目是两个对在线要求比较高的项目，在这两个项目中我们特别对hbase的慢响应问题进行了研究。hbase的慢响应现在一般归纳为四类原因：网络原因、gc问题、命中率以及client的反序列化问题。我们现在对它们做了一些解决方案(后面会有介绍)，以更好地对慢响应有控制力。</p>
<p>和Facebook类似，我们也使用了hbase做为实时计算类项目的存储层。目前对内部己经上线了部分实时项目，比如实时页面点击系统，galaxy实时交易推荐以及直播间等内部项目，用户则是散布到公司内各部门的运营小二们。与facebook的puma不同的是淘宝使用了多种方式做实时计算层，比如galaxy是使用类似affa的actor模式处理交易数据，同时关联商品表等维度表计算排行(TopN)，而实时页面点击系统则是基于twitter开源的storm进行开发，后台通过TT获取实时的日志数据，计算流将中间结果以及动态维表持久化到hbase上，比如我们将rowkey设计为url+userid，并读出实时的数据，从而实现实时计算各个维度上的uv。</p>
<p>最后要特别提一下历史交易订单项目。这个项目实际上也是一个重构项目，目的是从以前的solr+bdb的方案上迁移到hbase上来。由于它关系到己买到页面，用户使用频率非常高，重要程度接近核心应用，对数据丢失以及服务中断是零容忍。它对compact做了优化，避免大数据量的compact在服务时间内发生。新增了定制的filter来实现分页查询，rowkey上对应用进行了巧妙的设计以避免了冗余数据的传输以及90%以上的读转化成了顺序读。目前该集群存储了超过百亿的订单数据以及数千亿的索引数据，线上故障率为0。</p>
<p>随着业务的发展，目前我们定制的hbase集群己经应用到了线上超过二十个应用，数百台服务器上。包括淘宝首页的商品实时推荐、广泛用于卖家的实时量子统计等应用，并且还有继续增多以及向核心应用靠近的趋势。</p>
<p>4 部署、运维和监控</p>
<p>Facebook之前曾经透露过Facebook的hbase架构，可以说是非常不错的。如他们将message服务的hbase集群按用户分为数个集群，每个集群100台服务器，拥有一台namenode以及分为５个机架，每个机架上一台zookeeper。可以说对于大数据量的服务这是一种优良的架构。对于淘宝来说，由于数据量远没有那么大，应用也没有那么核心，因此我们采用公用hdfs以及zookeeper集群的架构。每个hdfs集群尽量不超过100台规模（这是为了尽量限制namenode单点问题）。在其上架设数个hbase集群，每个集群一个master以及一个backupmaster。公用hdfs的好处是可以尽量减少compact的影响，以及均摊掉硬盘的成本，因为总有集群对磁盘空间要求高，也总有集群对磁盘空间要求低，混合在一起用从成本上是比较合算的。zookeeper集群公用，每个hbase集群在zk上分属不同的根节点。通过zk的权限机制来保证hbase集群的相互独立。zk的公用原因则仅仅是为了运维方便。</p>
<p>由于是在线应用，运维和监控就变得更加重要，由于之前的经验接近0，因此很难招到专门的hbase运维人员。我们的开发团队和运维团队从一开始就很重视该问题，很早就开始自行培养。以下讲一些我们的运维和监控经验。</p>
<p>我们定制的hbase很重要的一部分功能就是增加监控。hbase本身可以发送ganglia监控数据，只是监控项远远不够，并且ganglia的展示方式并不直观和突出。因此一方面我们在代码中侵入式地增加了很多监控点，比如compact/split/balance/flush队列以及各个阶段的耗时、读写各个阶段的响应时间、读写次数、region的open/close，以及具体到表和region级别的读写次数等等。仍然将它们通过socket的方式发送到ganglia中，ganglia会把它们记录到rrd文件中，rrd文件的特点是历史数据的精度会越来越低，因此我们自己编写程序从rrd中读出相应的数据并持久化到其它地方，然后自己用js实现了一套监控界面，将我们关心的数据以趋势图、饼图等各种方式重点汇总和显示出来，并且可以无精度损失地查看任意历史数据。在显示的同时会把部分非常重要的数据，如读写次数、响应时间等写入数据库，实现波动报警等自定义的报警。经过以上措施，保证了我们总是能先于用户发现集群的问题并及时修复。我们利用redis高效的排序算法实时地将每个region的读写次数进行排序，能够在高负载的情况下找到具体请求次数排名较高的那些region，并把它们移到空闲的regionserver上去。在高峰期我们能对上百台机器的数十万个region进行实时排序。</p>
<p>为了隔离应用的影响，我们在代码层面实现了可以检查不同client过来的连接，并且切断某些client的连接，以在发生故障时，将故障隔离在某个应用内部而不扩大化。mapreduce的应用也会控制在低峰期运行，比如在白天我们会关闭jobtracker等。</p>
<p>此外，为了保障服务从结果上的可用，我们也会定期跑读写测试、建表测试、hbck等命令。hbck是一个非常有用的工具，不过要注意它也是一个很重的工操作，因此尽量减少hbck的调用次数，尽量不要并行运行hbck服务。在0.90.4以前的hbck会有一些机率使hbase宕机。另外为了确保hdfs的安全性，需要定期运行fsck等以检查hdfs的状态，如block的replica数量等。<br>
我们会每天根踪所有线上服务器的日志，将错误日志全部找出来并且邮件给开发人员，以查明每一次error以上的问题原因和fix。直至错误降低为0。另外每一次的hbck结果如果有问题也会邮件给开发人员以处理掉。尽管并不是每一次error都会引发问题，甚至大部分error都只是分布式系统中的正常现象，但明白它们问题的原因是非常重要的。</p>
<p>5 测试与发布</p>
<p>因为是未知的系统，我们从一开始就非常注重测试。测试从一开始就分为性能测试和功能测试。性能测试主要是注意基准测试，分很多场景，比如不同混合读写比例，不同k/v大小，不同列族数，不同命中率，是否做presharding等等。每次运行都会持续数小时以得到准确的结果。因此我们写了一套自动化系统，从web上选择不同的场景，后台会自动将测试参数传到各台服务器上去执行。由于是测试分布式系统，因此client也必须是分布式的。</p>
<p>我们判断测试是否准确的依据是同一个场景跑多次，是否数据，以及运行曲线达到99%以上的重合度，这个工作非常烦琐，以至于消耗了很多时间，但后来的事实证明它非常有意义。因为我们对它建立了100%的信任，这非常重要，比如后期我们的改进哪怕只提高2%的性能也能被准确捕捉到，又比如某次代码修改使compact队列曲线有了一些起伏而被我们看到，从而找出了程序的bug，等等。</p>
<p>功能测试上则主要是接口测试和异常测试。接口测试一般作用不是很明显，因为hbase本身的单元测试己经使这部分被覆盖到了。但异常测试非常重要，我们绝大部分bug修改都是在异常测试中发现的，这帮助我们去掉了很多生产环境中可能存在的不稳定因素，我们也提交了十几个相应的patch到社区，并受到了重视和commit。分布式系统设计的难点和复杂度都在异常处理上，我们必须认为系统在通讯的任何时候都是不可靠的。某些难以复现的问题我们会通过查看代码大体定位到问题以后，在代码层面强行抛出异常来复现它。事实证明这非常有用。</p>
<p>为了方便和快速定位问题，我们设计了一套日志收集和处理的程序，以方便地从每台服务器上抓取相应的日志并按一定规律汇总。这非常重要，避免浪费大量的时间到登录不同的服务器以寻找一个bug的线索。</p>
<p>由于hbase社区在不停发展，以及线上或测试环境发现的新的bug，我们需要制定一套有规律的发布模式。它既要避免频繁的发布引起的不稳定，又要避免长期不发布导致生产版本离开发版本越来越远或是隐藏的bug爆发。我们强行规定每两周从内部trunk上release一个版本，该版本必须通过所有的测试包括回归测试，并且在release后在一个小型的集群上24小时不受甘扰不停地运行。每个月会有一次发布，发布时采用最新release的版本，并且将现有的集群按重要性分级发布，以确保重要应用不受新版本的潜在bug影响。事实证明自从我们引入这套发布机制后，由发布带来的不稳定因素大大下降了，并且线上版本也能保持不落后太多。</p>
<p>6 改进和优化</p>
<p>Facebook是一家非常值得尊敬的公司，他们毫无保留地对外公布了对hbase的所有改造，并且将他们内部实际使用的版本开源到了社区。facebook线上应用的一个重要特点是他们关闭了split，以降低split带来的风险。与facebook不同，淘宝的业务数据量相对没有如此庞大，并且由于应用类型非常丰富，我们并们并没有要求用户强行选择关闭split，而是尽量去修改split中可能存在的bug。到目前为止，虽然我们并不能说完全解决了这个问题，但是从0.90.2中暴露出来的诸多跟split以及宕机相关的可能引发的bug我们的测试环境上己经被修复到接近了0，也为社区提交了10数个稳定性相关的patch，比较重要的有以下几个：</p>
<p>· <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE-4562" rel="nofollow"><span style="color:rgb(0,0,255)">https://issues.apache.org/jira/browse/HBASE-4562</span></a></p>
<p>· <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE-4563" rel="nofollow"><span style="color:rgb(0,0,255)">https://issues.apache.org/jira/browse/HBASE-4563</span></a></p>
<p>· <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE-5152" rel="nofollow"><span style="color:rgb(0,0,255)">https://issues.apache.org/jira/browse/HBASE-5152</span></a></p>
<p>· <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE-5100" rel="nofollow"><span style="color:rgb(0,0,255)">https://issues.apache.org/jira/browse/HBASE-5100</span></a></p>
<p>· <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE-4880" rel="nofollow"><span style="color:rgb(0,0,255)">https://issues.apache.org/jira/browse/HBASE-4880</span></a></p>
<p>· <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE-4878" rel="nofollow"><span style="color:rgb(0,0,255)">https://issues.apache.org/jira/browse/HBASE-4878</span></a></p>
<p>· <a target="_blank" href="https://issues.apache.org/jira/browse/HBASE-4899" rel="nofollow"><span style="color:rgb(0,0,255)">https://issues.apache.org/jira/browse/HBASE-4899</span></a></p>
<p>还有其它一些，我们主要将patch提交到0.92版本，社区会有commitor帮助我们backport回0.90版本。所以社区从0.90.2一直到0.90.6一共发布了5个bugfix版本后，0.90.6版本其实己经比较稳定了。建议生产环境可以考虑这个版本。</p>
<p>split这是一个很重的事务，它有一个严重的问题就是会修改meta表（当然宕机恢复时也有这个问题）。如果在此期间发生异常，很有可能meta表、rs内存、master内存以及hdfs上的文件会发生不一致，导致之后region重新分配时发生错误。其中一个错误就是有可能同一个region被两个以上的regionserver所服务，那么就可能出现这一个region所服务的数据会随机分别写到多台rs上，读取的时候也会分别读取，导致数据丢失。想要恢复原状，必须删除掉其中一个rs上的region，这就导致了不得不主动删掉数据，从而引发数据丢失。</p>
<p>前面说到慢响应的问题归纳为网络原因、gc问题、命中率以及client的反序列化问题。网络原因一般是网络不稳定引起的，不过也有可能是tcp参数设置问题，必须保证尽量减少包的延迟，如nodelay需要设置为true等，这些问题我们通过tcpdump等一系列工具专门定位过，证明tcp参数对包的组装确实会造成慢连接。gc要根据应用的类型来，一般在读比较多的应用中新生代不能设置得太小。命中率极大影响了响应的时间，我们会尽量将version数设为１以增加缓存的容量，良好的balance也能帮助充分应用好每台机器的命中率。我们为此设计了表级别的balance。</p>
<p>由于hbase服务是单点的，即宕机一台，则该台机器所服务的数据在恢复前是无法读写的。宕机恢复速度决定了我们服务的可用率。为此主要做了几点优化。首先是将zk的宕机发现时间尽量缩短到1分钟，其次改进了master恢复日志为并行恢复，大大提高了master恢复日志的速度，然后我们修改了openhandler中可能出现的一些超时异常，以及死锁，去掉了日志中可能发生的open…too long等异常。原生的hbase在宕机恢复时有可能发生10几分钟甚至半小时无法重启的问题己经被修复掉了。另外，hdfs层面我们将socket.timeout时间以及重试时间也缩短了，以降低datanode宕机引起的长时间block现象。</p>
<p>hbase本身读写层面的优化我们目前并没有做太多的工作，唯一打的patch是region增加时写性能严重下降的问题。因为由于hbase本身良好的性能，我们通过大量测试找到了各种应用场景中比较优良的参数并应用于生产环境后，都基本满足需求。不过这是我们接下来的重要工作。</p>
<p>7 将来计划</p>
<p>我们目前维护着淘宝内基于社区0.90.x而定制的hbase版本。接下来除继续fix它的bug外，会维护基于0.92.x修改的版本。之所以这样，是因为0.92.x和0.90.x的兼容性并不是非常好，而且0.92.x修改掉的代码非常多，粗略统计会超过30%。0.92中有我们非常看重的一些特性。</p>
<p>· 0.92版本改进了hfile为hfileV2，v2版本的特点是将索引以及bloomfilter进行了大幅改造，以支持单个大hfile文件。现有的HFile在文件大到一定程度时，index会占用大量的内存，并且加载文件的速度会因此下降非常多。而如果HFile不增大的话，region就无法扩大，从而导致region数量非常多。这是我们想尽量避免的事。</p>
<p>· 0.92版本改进了通讯层协议，在通讯层中增加了length，这非常重要，它让我们可以写出nio的客户端，使反序列化不再成为影响client性能的地方。</p>
<p>· 0.92版本增加了coprocessor特性，这支持了少量想要在rs上进行count等的应用。</p>
<p>· 还有其它很多优化，比如改进了balance算法、改进了compact算法、改进了scan算法、compact变为CF级别、动态做ddl等等特性。</p>
<p>除了0.92版本外，0.94版本以及最新的trunk(0.96)也有很多不错的特性，0.94是一个性能优化版本。它做了很多革命性工作，比如去掉root表，比如HLog进行压缩，replication上支持多个slave集群，等等。<br>
我们自己也有一些优化，比如自行实现的二级索引、backup策略等都会在内部版本上实现。</p>
<p>另外值得一提的是hdfs层面的优化也非常重要，hadoop-1.0.0以及cloudera-3u3的改进对hbase非常有帮助，比如本地化读、checksum的改进、datanode的keepalive设置、namenode的HA策略等。我们有一支优秀的hdfs团队来支持我们的hdfs层面工作，比如定位以及fix一些hdfs层面的bug,帮助提供一些hdfs上参数的建议，以及帮助实现namenode的HA等。最新的测试表明，3u3的checksum+本地化读可以将随机读性能提升至少一倍。</p>
<p>我们正在做的一件有意义的事是实时监控和调整regionserver的负载，能够动态地将负载不足的集群上的服务器挪到负载较高的集群中，而整个过程对用户完全透明。</p>
<p>总的来说，我们的策略是尽量和社区合作，以推动hbase在整个apache生态链以及业界的发展，使其能更稳定地部署到更多的应用中去，以降低使用门槛以及使用成本。</p>
<p> </p>
<p> </p>
<p>五、 HBase运维实战：disable table失败的处理</p>
<p> </p>
<p>相信每一个维护<a target="_blank" href="http://blog.nosqlfan.com/tags/hbase" rel="nofollow" title="查看 hbase 的全部文章"><span style="color:rgb(0,0,255)">hbase</span></a>集群的<a target="_blank" href="http://blog.nosqlfan.com/tags/%C3%A8%C2%BF%C2%90%C3%A7%C2%BB%C2%B4" rel="nofollow" title="查看 运维 的全部文章"><span style="color:rgb(0,0,255)">运维</span></a>人员一定碰到过disable失败，陷入无穷的”Region has been PENDING_CLOSE for too long…”状态，此时没有什么好的办法处理。经常需要重启集群。</p>
<p>这个问题产生的原因非常讨厌，经过一段时间的分析和验证，得到了根本原因。要理解它，必须从disable的原理说起：</p>
<p>· disable线程是一个DisableTableHandler类，我们看它的handleDisableTable()方法，在while循环中先获取table的regions列表，然后调用BulkDisabler的bulkAssign()方法，等待bulkAssign()返回为true时则结束</p>
<p>· 在bulkAssign()方法中启动线程池，然后等待线程池超时，超时时间由hbase.bulk.assignment.waiton.empty.rit 控制</p>
<p>· 在每个线程中，先从regions collection中得到regions列表，然后通知rs来处理该region，并且把该region放入RIT列表中，表示该region正在进行处理</p>
<p>· rs处理完region以后，将该region状态在zk上置为closing，此时master得到通知</p>
<p>· master将这个region从RIT列表中删除，并从regions列表中删除。</p>
<p> </p>
<p>注意以上最后一步，当master把它从RIT中删除以后，还有短暂的时间这个region还在regions列表中，此时另一个线程拿到了这个region，并且此时这个region不处于RIT状态保护，于是另一个线程开始重复以上过程，而前一个线程己经把它从collection中删除了，于是后一个线程再也无法完成closing事件。直到RIT超时（默认30秒）。</p>
<p> </p>
<p>六、 Hadoop HBase 单机环境简单配置教程</p>
<p> </p>
<p>Hadoop是Apache的一个项目,它是一个实现了MapReduce计算模型的可以运用于大型集群并行计算的分布式并行计算编程框架,当然分布式计算离不开分布式存储,Hadoop框架包含了分布式存储系统HDFS(Hadoop Distributed File System),其存储和数据结构很类似Google的GFS.<br>
HBase是Hadoop的子项目,它是基于Hadoop HDFS分布存储系统的一个Google BigTable开源实现(最近看了BigTable的Paper,很受鼓舞和启发),它在存储数据结构上并非关系型,而是疏松分布式的,持久并按多维排序并索引的map型,下次我把介绍BigTable和HBase的文章转载过来.<br>
Google BigTable的paper: <a target="_blank" href="http://labs.google.com/papers/bigtable-osdi06.pdf" rel="nofollow"><span style="color:rgb(0,0,255)">http://labs.google.com/papers/bigtable-osdi06.pdf</span></a></p>
<p>在初接触Hadoop和Hbase的时候,大多数技术人员只希望通过简单的方法初步搭起框架环境,但我找了好多安装手册都是上来就部署集群分布环境(尽管做Hadoop就是为了这个目的),搭建集群环境的时候要设置ssh协议访问权限,要生成访问公钥,并且slaves配置上的小错误也会导致整个部署问题重重,所以我在部署成功后记录下最简单运行的standalone模式的安装配置过程,希望初学者在需要的时候能找到这个小小的guide,以后有时间我会再把集群配置的方法写出来.</p>
<p>开始:<br>
1.在Apache/Hadoop项目的网站(<a target="_blank" href="http://hadoop.apache.org/" rel="nofollow"><span style="color:rgb(0,0,255)">hadoop.apache.org</span></a>)下载<a target="_blank" href="http://blog.nosqlfan.com/tags/hadoop" rel="nofollow" title="查看 hadoop 的全部文章"><span style="color:rgb(0,0,255)">hadoop</span></a>以及<a target="_blank" href="http://blog.nosqlfan.com/tags/hbase" rel="nofollow" title="查看 hbase 的全部文章"><span style="color:rgb(0,0,255)">hbase</span></a>的发行包,此处两个发行包的大版本号一定要一致,譬如都是0.18版本:<br>
hadoop-0.18.2.tar.gz<br>
hbase-0.18.1.tar.gz</p>
<p>2.使用root身份登录目标服务器系统(Suse10 Linux),首先安装java虚拟机,这个比较简单,随便找个绿色的解压就可以了,在这个例子里面我使用IBM WAS6.1附带的jdk,它的home目录是/opt/IBM/WebSphere/AppServer/java,我们只需要配置系统的环境变量就可以了.<br>
编辑全局环境变量文件/etc/profile,在文件后面添加</p>
<p>export JAVA_HOME=/opt/IBM/WebSphere/AppServer/java</p>
<p>export PATH=$JAVA_HOME:$PATH</p>
<p>保存profile文件后使用</p>
<p>source /etc/profile</p>
<p>命令重新加载profile,然后随便在一个目录下面运行</p>
<p>java -version</p>
<p>查看javahome环境变量和path变量是否被正确加载.<br>
另外到 /etc/hosts 文件中查看主机映射是否存在,例如 127.0.0.1 localhost 或者什么其他的名字,在这里默认配置本机为localhost,如果需要做分布式的话,本机要做namenode,所以要把所有的datanode的host添加到这里面.</p>
<p>3.创建hadoop用户,</p>
<p>useradd hadoop</p>
<p>可以用</p>
<p>passwd hadoop</p>
<p>修改hadoop用户的登录密码.</p>
<p>4.创建hadoop用户的home目录,如果打算在别处安装hadoop/hbase的话可以不这样做,这里我们默认将hadoop/hbase安装在/home/${username}目录下.</p>
<p>cd /home</p>
<p>mkdir hadoop</p>
<p>将目录用户指派给hadoop</p>
<p>chown hadoop hadoop</p>
<p>改变目录权限,这里我们配大一些,其实只要644就足够了:</p>
<p>chmod 755 hadoop</p>
<p>5.使用hadoop用户登录系统,将下载的两个发行包文件传到/home/hadoop目录下面,然后给它们加上执行权限:</p>
<p>chmod a+x hadoop-0.18.2.tar.gz</p>
<p>chmod a+x hbase-0.18.1.tar.gz</p>
<p>6.解压hadoop:</p>
<p>tar zxvf hadoop-0.18.2.tar.gz</p>
<p>这样做会在/home/hadoop目录下解压hadoop发行包并创建到/home/hadoop/hadoop-0.18.2目录中,这里可以详细设计目录结构并创建link文件来方便日后升级等工作,这里我们先简单放在这里.</p>
<p>7.修改hadoop环境脚本:<br>
修改文件/home/hadoop/hadoop-0.18.2/conf/hadoop-env.sh,在其中加入JAVA_HOME变量:</p>
<p>export JAVA_HOME=/opt/IBM/WebSphere/AppServer/java</p>
<p>HADOOP_HOME变量我们可以不设置,默认的情况是指定HADOOP_HOME为运行启动脚本当前目录的父目录.</p>
<p>8.修改hadoop启动配置:<br>
参照默认配置文件/home/hadoop/hadoop-0.18.2/conf/hadoop-default.xml 修改用户配置文件/home/hadoop/hadoop-0.18.2/conf/hadoop-site.xml,hadoop启动的时候会加载默认配置文件,然后读取用户配置文件并使用用户配置文件中的属性替换默认配置文件中的值,这里最简单的情况我们只需要修改如下几项即可,如果需要做分布的话也是要在这个文件里面进行配置.将要修改的配置项简单的放到hadoop-site.xml文件的中去:</p>
<p>fs.default.name</p>
<p>hdfs://localhost:9000/</p>
<p>mapred.job.tracker</p>
<p>localhost:9001</p>
<p>9.格式化nodename及启动hdfs守护进程:</p>
<p>/home/hadoop/hadoop-0.18.2/bin/hadoop namenode -format</p>
<p>/home/hadoop/hadoop-0.18.2/bin/start-all.sh</p>
<p>使用shart-all.sh可以方便的启动所有的hdfs守护进程,如果想关闭这些守护进程可以使用stop-all.sh脚本.<br>
启动过程中需要输入登录密码.<br>
启动成功后可以用以下简单方法测试hdfs:</p>
<p>/home/hadoop/hadoop-0.18.2/bin/hadoop dfs -mkdir dir4test</p>
<p>/home/hadoop/hadoop-0.18.2/bin/hadoop dfs -ls</p>
<p>/home/hadoop/hadoop-0.18.2/bin/hadoop dfs -put /home/hadoop/file4test.zip file4test_temp.zip</p>
<p>相当于linux系统下的mkdir ls cp命令.<br>
用浏览器访问 http://localhost:50030/ 和 http://localhost:50070/ 可以查看hdfs拓扑结构和job进程还有hdfs文件系统结构.</p>
<p>10.解压hbase发行包:</p>
<p>tar zxvf hbase-0.18.1.tar.gz</p>
<p>11.修改hbase环境脚本:<br>
修改文件/home/hadoop/hbase-0.18.1/conf/hbase-env.sh,在其中加入JAVA_HOME变量:</p>
<p>export JAVA_HOME=/opt/IBM/WebSphere/AppServer/java</p>
<p>简单启动暂时不需要在用户配置文件/home/hadoop/hbase-0.18.1/conf/hbase-site.xml添加任何替代属性.</p>
<p>12.启动hbase:</p>
<p>/home/hadoop/hbase-0.18.1/bin/start-hbase.sh</p>
<p>成功启动hbase的守护进程.<br>
启动hbase hql shell:</p>
<p>/home/hadoop/hbase-0.18.1/bin/hbase shell</p>
<p>在hql shell中可以进行hbase数据操作,如果需要帮助信息可以键入:</p>
<p>hbase&gt;help</p>
<p>简单测试hbase:<br>
在hbase shell下:</p>
<p>hbase&gt;create 't1','f1','f3'</p>
<p>hbase&gt;list</p>
<p>使用浏览器访问 http://localhost:60010/ 可以查看当前hbase信息.</p>
<p>启动hbase REST服务:</p>
<p>/home/hadoop/hbase-0.18.1/bin/hbase rest start</p>
<p>成功启动hbase REST服务后就可以通过对uri: http://localhost:60050/api/ 的通用REST操作(GET/POST/PUT/DELETE)实现对hbase的REST形式数据操作.</p>
<p>To be continue… </p>
<p>七、 Cassandra 和 HBase 中使用的 BigTable 模型</p>
<p> </p>
<p>众所周知，<a target="_blank" href="http://blog.nosqlfan.com/tags/bigtable" rel="nofollow" title="查看 BigTable 的全部文章"><span style="color:rgb(0,0,255)">BigTable</span></a>是NoSQL数据库的王者，其论文更是NoSQL理论的基石，但遗憾的是BigTable不开源，于是有了开源的BigTable版本这一说法，其中的佼佼者包括今天提到的两位：<a target="_blank" href="http://blog.nosqlfan.com/tags/cassandra" rel="nofollow" title="查看 Cassandra 的全部文章"><span style="color:rgb(0,0,255)">Cassandra</span></a>和HBase。</p>
<p>本文为翻译文章，翻译均为意译，仅挑选重点部分进行大意翻译。详尽的意思及全文翻译请看原文。</p>
<p>英文原文链接：<a target="_blank" href="http://horicky.blogspot.com/2010/10/bigtable-model-with-cassandra-and-hbase.html" rel="nofollow"><span style="color:rgb(0,0,255)">http://horicky.blogspot.com/2010/10/bigtable-model-with-cassandra-and-hbase.html</span></a></p>
<p>中文原文链接：<a target="_blank" href="http://lgone.com/html/y2010/812.html" rel="nofollow"><span style="color:rgb(0,0,255)">http://lgone.com/html/y2010/812.html</span></a></p>
<p>本文主要对Cassandra和HBase特性和实现中对BigTable理论的应用。</p>
<p>1.Fundamentally Distributed（<a target="_blank" href="http://blog.nosqlfan.com/tags/%C3%A5%C2%88%C2%86%C3%A5%C2%B8%C2%83%C3%A5%C2%BC%C2%8F" rel="nofollow" title="查看 分布式 的全部文章"><span style="color:rgb(0,0,255)">分布式</span></a>存储）</p>
<p>项目从最初规划上，就是为海量数据服务的，当然分布式存储的思想也是扎根于其血脉中。分布式系统主要需要考虑两个方面：partitioning（分区存储，也可以理解为通常说的Sharding）、replication（数据复制，主要是将数据复制成多份以提高可用性）。</p>
<p> </p>
<p>2.Column Oriented（<a target="_blank" href="http://blog.nosqlfan.com/tags/%C3%A5%C2%88%C2%97%C3%A5%C2%BC%C2%8F%C3%A5%C2%AD%C2%98%C3%A5%C2%82%C2%A8" rel="nofollow" title="查看 列式存储 的全部文章"><span style="color:rgb(0,0,255)">列式存储</span></a>）</p>
<p>和普通的RDBMS不一样，普通的RDBMS通常是行式存储的，一行数据是连续存在一段磁盘空间上的。而列式存储是将各个列分别进行连续的存储。也正是因此，它对于处理字段中的NULL字段，能够不占用过多的空间。同时能够支持灵活松散的列定义。也就是我们通常所说的schema-less。</p>
<p> </p>
<p>3.Sequential write（顺序写磁盘）</p>
<p>BigTable型系统的一个特点是其对写性能进行的优化。它的写都是通过先记一条操作日志，然后直接写在内存中的数据集合，然后其集合按条件或定时将数据flush到磁盘。这里涉及到的记操作日志或者数据flush到磁盘都会顺序的磁盘操作。故而避免了磁盘随机操作造成的无谓的磁盘寻道时间。</p>
<p>4.Merged read（读操作数据合并）</p>
<p>上面说到写操作是通过定时将数据直接flush到磁盘进行的，每次flush都会生成一个数据块，那可能造成一个数据在多个数据块中的情况，而在读的时候就需要将这多个版本中的值进行合并。其中在判断一个数据块是否包含指定值时使用了bloom-filter算法。</p>
<p>5.Periodic Data Compaction（定期数据合并）</p>
<p>同样是上面说到的，一个数据可能存在于多个数据块，如果我们不做处理，随着时间的推移，数据块会越来越多。所以BigTable型系统会进行定时的数据合并。在上面讲到的将内存中的数据直接flush到磁盘的过程中，flush之前进行了一次数据的排序操作，既是说存在磁盘中的块中的数据，都是顺序的，那么对一堆顺序的数据进行排重合并，其实和我们熟知的多路归并排序很相似。故而其定时数据合并的效率也是非常高的。</p>
<p> </p>
<p>接下来的部分是关于标题中的两个产品Cassandra和HBase在这些理论上的具体实践和修改。暂时就不翻译了。有兴趣的同学可以查看英文原文。 </p>
<p>八、 HBase 文件结构图</p>
<p> </p>
<p><a target="_blank" href="http://blog.nosqlfan.com/tags/hfile" rel="nofollow" title="查看 HFile 的全部文章"><span style="color:rgb(0,0,255)">HFile</span></a> 是 HBase 的数据文件结构，下图是对HFile 的数据组织结构描述，是理解 HBase 数据存储的绝佳教材。</p>
<p>图片来源及解释：<a target="_blank" href="http://th30z.blogspot.com/2011/02/hbase-io-hfile.html" rel="nofollow"><span style="color:rgb(0,0,255)">http://th30z.blogspot.com/2011/02/hbase-io-hfile.html</span></a></p>
<p> </p>
<p>相关文章两篇：</p>
<p>1.<a target="_blank" href="http://blog.nosqlfan.com/html/1217.html" rel="nofollow"><span style="color:rgb(0,0,255)">Hadoop 数据类型与文件结构剖析 Sequence, Map, Set, Array, BloomMap Files</span></a></p>
<p>2.<a target="_blank" href="http://blog.nosqlfan.com/html/1249.html" rel="nofollow"><span style="color:rgb(0,0,255)">图形化理解 HBase 数据写操作、压缩操作过程</span></a> </p>
<p>九、 图形化理解 HBase 数据写操作、压缩操作过程</p>
<p> </p>
<p>HBase 写数据的过程是：先写到内存中（memstore），当内存中的数据达到一定大小，将内存中的数据一次性<a target="_blank" href="http://blog.nosqlfan.com/tags/flush" rel="nofollow" title="查看 flush 的全部文章"><span style="color:rgb(0,0,255)">flush</span></a>到磁盘上形成数据文件。期间对每一次写操作，都会记一个持久化的日志。那些 flush 到磁盘上的文件，会定时进行<a target="_blank" href="http://blog.nosqlfan.com/tags/%C3%A5%C2%8E%C2%8B%C3%A7%C2%BC%C2%A9" rel="nofollow" title="查看 压缩 的全部文章"><span style="color:rgb(0,0,255)">压缩</span></a>。下图形像地说明这一系列过程：</p>
<p> </p>
<p>原文链接：<a target="_blank" href="http://goo.gl/jwKdj" rel="nofollow"><span style="color:rgb(0,0,255)">http://goo.gl/jwKdj</span></a></p>
<p>最近还有两篇相关的文章，讲述 Hadoop 及 HBase 的数据文件内部结构的，一并推荐在这里：</p>
<p>1.<a target="_blank" href="http://blog.nosqlfan.com/html/1217.html" rel="nofollow"><span style="color:rgb(0,0,255)">Hadoop 数据类型与文件结构剖析 Sequence, Map, Set, Array, BloomMap Files</span></a></p>
<p>2.<a target="_blank" href="http://blog.nosqlfan.com/html/1135.html" rel="nofollow"><span style="color:rgb(0,0,255)">HBase 文件结构图</span></a> </p>
<p>十、 Facebook为何选择了Hadoop和HBase</p>
<p>前段时间<a target="_blank" href="http://blog.nosqlfan.com/tags/facebook" rel="nofollow" title="查看 Facebook 的全部文章"><span style="color:rgb(0,0,255)">Facebook</span></a>的新版<a target="_blank" href="http://highscalability.com/blog/2010/11/16/facebooks-new-real-time-messaging-system-hbase-to-store-135.html" rel="nofollow"><span style="color:rgb(0,0,255)">消息系统</span></a>发布，Facebook对HBase的成功使用也使得超来超多的HBase案例得以出现，下文是Facebook的Hadoop工程师Dhruba Borthakur同学发表的Hadoop系列文章中的一篇，对Facebook选择Hadoop和HBase的原因做了一个说明。</p>
<p>原文链接：<a target="_blank" href="http://hadoopblog.blogspot.com/2011/05/realtime-hadoop-usage-at-facebook-part.html" rel="nofollow"><span style="color:rgb(0,0,255)">Realtime Hadoop usage at Facebook — Part 1</span></a></p>
<p>· 横向扩展性强。对Facebook这种海量数据存储场景来说，扩容几乎是家常便饭，HBase能够使数据扩容非常容易。</p>
<p>· 支持很高的写吞吐。Facebook的消息数据很庞大，每天的写量也很大。</p>
<p>· 在同一个数据同中心，能够保证有较强的一致性。Facebook用HBase来存储消息数据，业务上需要一个能够保证一致性的数据存储（这也是Facebook并没有采用Cassandra的原因之一["<span style="color:rgb(51,153,102)">We found Cassandra's eventual consistency model to be a difficult pattern to reconcile for our new Messages infrastructure</span>" from <a target="_blank" href="http://www.quora.com/Why-did-Facebook-pick-HBase-instead-of-Cassandra-for-the-new-messaging-platform" rel="nofollow"><span style="color:rgb(0,0,255)">quora</span></a>]）</p>
<p>· 有良好的随机读性能。消息系统的业务逻辑导致会有很多穿透缓存层的随机读操作。</p>
<p>· 高可用性，故障可恢复性。由于数据量大，分布的机器也可能很多，出故障或者进行一些日常升级工作会比较频繁，需要能够有很高可用性的系统。</p>
<p>· 错误隔离性。一个结点的错误不会影响到其它结点，磁盘故障只会对相应的小规模的数据产生影响。</p>
<p>· 提供原子性的read-modify-write操作。原子性的increment或者对比后修改的操作，对很多业务上的处理非常方便。</p>
<p>· 提供获取某个范围的数据的功能。比如像获取某人最近100条消息这样的功能，在消息系统里是很常见的需求。</p>
<p>当然，下面几个Hadoop和HBase不太擅长的方面也值得一说：</p>
<p>· 同一个数据中心网络割裂下的容灾性。同一个数据中心的网络出现问题了，导致各结点之间无法正常沟通，这种情况通常可以通过配置一些备用的网络设备来避免。</p>
<p>· 某个数据中心故障不会影响服务。这个情况更是少之又少。</p>
<p>· 在多个数据中心间的实时数据交换。这个不太现实，通常这一点是用Cache层来实现用户对无端数据的实时访问的。</p>
<p>十一、 关于HBase的一些零碎事</p>
<p> </p>
<p> </p>
<p>随着<a target="_blank" href="http://highscalability.com/blog/2010/11/16/facebooks-new-real-time-messaging-system-hbase-to-store-135.html" rel="nofollow"><span style="color:rgb(0,0,255)">Facebook使用HBase来构建实时消息系统</span></a>，基于Hadoop的面向列存储的HBase持续升温。</p>
<p>目前稳定版本的HBase0.90.2只能基于Hadoop0.20.x系列版本，暂不支持最新的0.21.x。而且官方版本的Hadoop0.20.2（或者0.203.0）缺少一个重要的特性，HDFS不支持sync模式的持久，这样HBase就有较大的丢失数据的风险。要在生产环境使用HBase，有两个选择，一是使用<a target="_blank" href="https://ccp.cloudera.com/display/SUPPORT/Downloads" rel="nofollow"><span style="color:rgb(0,0,255)">Cloudera的CDH3版本</span></a>，Cloudera就类似MySQL的Percona，对官方版本的Hadoop做了很多改进工作，而且经典的《Hadoop：The Definitive Guide》一书的作者Tom White就是Cloudera的一员，这也和《High performance MySQL》一书的作者主要来是Percona一样。另外一种选择，就是自行编译Hadoop branch-0.20-append源码分支，这里有<a target="_blank" href="http://www.michael-noll.com/blog/2011/04/14/building-an-hadoop-0-20-x-version-for-hbase-0-90-2/" rel="nofollow"><span style="color:rgb(0,0,255)">详细的说明</span></a>。</p>
<p>对于HBase这种类似BigTable的系统，其优化之一是消除了磁盘的随机写。付出的代价是将最新的数据保存在内存表中，对内存有较大的需求。如果内存表的数量较多，则每个内存表就会在较小的时候刷到磁盘，导致磁盘文件多而且小。范围读取数据的时候就会跨多个数据文件甚至多个节点。为提升读性能，系统都会设计有compaction操作。另外为了防止某些情况下数据文件过大（<a target="_blank" href="http://blog.nosqlfan.com/tags/hbase" rel="nofollow" title="查看 hbase 的全部文章"><span style="color:rgb(0,0,255)">hbase</span></a>.hregion.max.filesize，默认256M，太大的数据文件在compaction等操作是对内存的消耗更大），HBase也设计了split操作。Compaction和Split操作，对于在线应用的响应时间都容易造成波动，他们的策略需要根据应用的特性进行调整。建议在业务低峰期手工调整。</p>
<p>HBase的regionserver宕机超过一定时间后，HMaster会将其所管理的region重新分布到其他存活的regionserver，由于数据和日志都持久在HDFS中，因此该操作不会导致数据丢失。但是重新分配的region需要根据日志恢复原regionserver中的内存表，这会导致宕机的region在这段时间内无法对外提供服务。而一旦重分布，宕机的节点起来后就相当于一个新的regionserver加入集群，为了平衡，需要再次将某些region分布到该server。 因此这个超时建议根据情况进行调整，一般情况下，宕机重启后即可恢复，如果重启需要10分钟，region重分布加恢复的时间要超过5分钟，那么还不如等节点重启。Region Server的内存表memstore如何在节点间做到更高的可用，是HBase的一个较大的挑战。Oceanbase也是采用内存表保持最新的更新数据，和HBase不同的是，Oceanbase使用的是集中的UpdateServer，只需要全力做好UpdateServer的容灾切换即可对业务连续性做到最小影响。分布还是集中，哪些功能分布，哪些功能集中，各自取不同平衡，是目前大部分分布式数据库或者存储的一个主要区别。当然，像Cassandra这种全分布的，架构上看起来很完美，实际应用起来反而问题更多。</p>
<p>对于java应用，线上运维最大的挑战之一就是heap内存管理。GC的不同方式，以及使用内存表和cache对内存的消耗，可能导致局部阻塞应用或者stop the world全局阻塞或者OOM。因此HBase的很多参数设置都是针对这两种情况。HBase使用了较新的CMS GC（-XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode）。</p>
<p>默认触发GC的时机是当年老代内存达到90%的时候，这个百分比由 -XX:CMSInitiatingOccupancyFraction=N 这个参数来设置。concurrent mode failed发生在这样一个场景：<br>
当年老代内存达到90%的时候，CMS开始进行并发垃圾收集，于此同时，新生代还在迅速不断地晋升对象到年老代。当年老代CMS还未完成并发标记时，年老代满了，悲剧就发生了。CMS因为没内存可用不得不暂停mark，并触发一次全jvm的stop the world（挂起所有线程），然后采用单线程拷贝方式清理所有垃圾对象。这个过程会非常漫长。为了避免出现concurrent mode failed，我们应该让GC在未到90%时，就触发。</p>
<p>通过设置 -XX:CMSInitiatingOccupancyFraction=N</p>
<p>这个百分比， 可以简单的这么计算。如果你的 hfile.block.cache.size 和 hbase.regionserver.global.memstore.upperLimit 加起来有60%（默认），那么你可以设置 70-80，一般高10%左右差不多。</p>
<p>（以上CMS GC的说明引自<a target="_blank" href="http://kenwublog.com/hbase-performance-tuning" rel="nofollow"><span style="color:rgb(0,0,255)">HBase性能调优</span></a>）</p>
<p>目前关于HBase的书不多，《Hadoop： The Definitive Guide》第二版有一章，另外最权威的要算<a target="_blank" href="#start_hbase" rel="nofollow"><span style="color:rgb(0,0,255)">官方的这本电子书</span></a>了</p>
<p>十二、 HBase性能调优</p>
<p> </p>
<p>我们经常看到一些文章吹嘘某产品如何如何快，如何如何强，而自己测试时却不如描述的一些数据。其实原因可能在于你还不是真正理解其内部结构，对于其<a target="_blank" href="http://blog.nosqlfan.com/tags/%C3%A6%C2%80%C2%A7%C3%A8%C2%83%C2%BD" rel="nofollow" title="查看 性能 的全部文章"><span style="color:rgb(0,0,255)">性能</span></a><a target="_blank" href="http://blog.nosqlfan.com/tags/%C3%A8%C2%B0%C2%83%C3%A4%C2%BC%C2%98" rel="nofollow" title="查看 调优 的全部文章"><span style="color:rgb(0,0,255)">调优</span></a>方法不够了解。本文转自TaoBao的<a target="_blank" href="http://twitter.com/kenwu" rel="nofollow"><span style="color:rgb(0,0,255)">Ken Wu</span></a>同学的博客，是目前看到比较完整的HBase调优文章。</p>
<p>原文链接：<a target="_blank" href="http://kenwublog.com/hbase-performance-tuning" rel="nofollow"><span style="color:rgb(0,0,255)">HBase<span style="font-family:宋体">性能调优</span></span></a></p>
<p>因<a target="_blank" href="#performance" rel="nofollow"><span style="color:rgb(0,0,255)">官方<span style="font-family:Times New Roman">Book Performance Tuning</span></span></a>部分章节没有按配置项进行索引，不能达到快速查阅的效果。所以我以配置项驱动，重新整理了原文，并补充一些自己的理解，如有错误，欢迎指正。</p>
<h2>配置<a target="_blank" href="http://blog.nosqlfan.com/tags/%C3%A4%C2%BC%C2%98%C3%A5%C2%8C%C2%96" rel="nofollow" title="查看 优化 的全部文章"><span style="color:rgb(0,0,255)">优化</span></a></h2>
<p>zookeeper.session.timeout</p>
<p>默认值：3分钟（180000ms）</p>
<p>说明：RegionServer与Zookeeper间的连接超时时间。当超时时间到后，ReigonServer会被Zookeeper从RS集群清单中移除，HMaster收到移除通知后，会对这台server负责的regions重新balance，让其他存活的RegionServer接管.</p>
<p>调优：这个timeout决定了RegionServer是否能够及时的failover。设置成1分钟或更低，可以减少因等待超时而被延长的failover时间。</p>
<p>不过需要注意的是，对于一些Online应用，RegionServer从宕机到恢复时间本身就很短的（网络闪断，crash等故障，运维可快速介入），如果调低timeout时间，反而会得不偿失。因为当ReigonServer被正式从RS集群中移除时，HMaster就开始做balance了（让其他RS根据故障机器记录的WAL日志进行恢复）。当故障的RS在人工介入恢复后，这个balance动作是毫无意义的，反而会使负载不均匀，给RS带来更多负担。特别是那些固定分配regions的场景。</p>
<p><a target="_blank" href="http://blog.nosqlfan.com/tags/hbase" rel="nofollow" title="查看 hbase 的全部文章"><span style="color:rgb(0,0,255)">hbase</span></a>.regionserver.handler.count</p>
<p>默认值：10</p>
<p>说明：RegionServer的请求处理IO线程数。</p>
<p>调优：这个参数的调优与内存息息相关。</p>
<p>较少的IO线程，适用于处理单次请求内存消耗较高的Big PUT场景（大容量单次PUT或设置了较大cache的scan，均属于Big PUT）或ReigonServer的内存比较紧张的场景。<br>
较多的IO线程，适用于单次请求内存消耗低，TPS要求非常高的场景。设置该值的时候，以监控内存为主要参考。</p>
<p>这里需要注意的是如果server的region数量很少，大量的请求都落在一个region上，因快速充满memstore触发flush导致的读写锁会影响全局TPS，不是IO线程数越高越好。</p>
<p>压测时，开启<a target="_blank" href="#rpc.logging" rel="nofollow" title="Enabling RPC-level logging"><span style="color:rgb(0,0,255)">Enabling RPC-level logging</span></a>，可以同时监控每次请求的内存消耗和GC的状况，最后通过多次压测结果来合理调节IO线程数。</p>
<p>这里是一个案例 <a target="_blank" href="http://software.intel.com/en-us/articles/hadoop-and-hbase-optimization-for-read-intensive-search-applications/" rel="nofollow"><span style="color:rgb(0,0,255)">Hadoop and HBase Optimization for Read Intensive Search Applications</span></a>，作者在SSD的机器上设置IO线程数为100，仅供参考。</p>
<p>hbase.hregion.max.filesize</p>
<p>默认值：256M</p>
<p>说明：在当前ReigonServer上单个Reigon的最大存储空间，单个Region超过该值时，这个Region会被自动split成更小的region。</p>
<p>调优：小region对split和compaction友好，因为拆分region或compact小region里的storefile速度很快，内存占用低。缺点是split和compaction会很频繁。</p>
<p>特别是数量较多的小region不停地split, compaction，会导致集群响应时间波动很大，region数量太多不仅给管理上带来麻烦，甚至会引发一些Hbase的bug。<br>
一般512以下的都算小region。</p>
<p>大region，则不太适合经常split和compaction，因为做一次compact和split会产生较长时间的停顿，对应用的读写性能冲击非常大。此外，大region意味着较大的storefile，compaction时对内存也是一个挑战。<br>
当然，大region也有其用武之地。如果你的应用场景中，某个时间点的访问量较低，那么在此时做compact和split，既能顺利完成split和compaction，又能保证绝大多数时间平稳的读写性能。</p>
<p>既然split和compaction如此影响性能，有没有办法去掉？<br>
compaction是无法避免的，split倒是可以从自动调整为手动。<br>
只要通过将这个参数值调大到某个很难达到的值，比如100G，就可以间接禁用自动split（RegionServer不会对未到达100G的region做split）。<br>
再配合<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/util/RegionSplitter.html" rel="nofollow" title="class in org.apache.hadoop.hbase.util"><span style="color:rgb(0,0,255)">RegionSplitter</span></a>这个工具，在需要split时，手动split。<br>
手动split在灵活性和稳定性上比起自动split要高很多，相反，管理成本增加不多，比较推荐online实时系统使用。</p>
<p>内存方面，小region在设置memstore的大小值上比较灵活，大region则过大过小都不行，过大会导致flush时app的IO wait增高，过小则因store file过多影响读性能。</p>
<p>hbase.regionserver.global.memstore.upperLimit/lowerLimit</p>
<p>默认值：0.4/0.35</p>
<p>upperlimit<span style="font-family:宋体">说明</span>：hbase.hregion.memstore.flush.size 这个参数的作用是 当单个memstore达到指定值时，flush该memstore。但是，一台ReigonServer可能有成百上千个memstore，每个memstore也许未达到flush.size，jvm的heap就不够用了。该参数就是为了限制memstores占用的总内存。<br>
当ReigonServer内所有的memstore所占用的内存总和达到heap的40%时，HBase会强制block所有的更新并flush这些memstore以释放所有memstore占用的内存。</p>
<p>lowerLimit<span style="font-family:宋体">说明</span>： 同upperLimit，只不过当全局memstore的内存达到35%时，它不会flush所有的memstore，它会找一些内存占用较大的memstore，做个别flush，当然更新还是会被block。lowerLimit算是一个在全局flush导致性能暴跌前的补救措施。为什么说是性能暴跌？可以想象一下，如果memstore需要在一段较长的时间内做全量flush，且这段时间内无法接受任何读写请求，对HBase集群的性能影响是很大的。</p>
<p>调优：这是一个Heap内存保护参数，默认值已经能适用大多数场景。它的调整一般是为了配合某些专属优化，比如读密集型应用，将读缓存开大，降低该值，腾出更多内存给其他模块使用。<br>
这个参数会给使用者带来什么影响？</p>
<p>比如，10G内存，100个region，每个memstore 64M，假设每个region只有一个memstore，那么当100个memstore平均占用到50%左右时，就会达到lowerLimit的限制。假设此时，其他memstore同样有很多的写请求进来。在那些大的region未flush完，就可能又超过了upperlimit，则所有region都会被block，开始触发全局flush。</p>
<p>不过，除了你的内存非常小或你的应用场景里大多数都是读，我觉得不需要去调这个参数。</p>
<p>hfile.block.cache.size</p>
<p>默认值：0.2</p>
<p>说明：storefile的读缓存占用Heap的大小百分比，0.2表示20%。该值直接影响数据读的性能。</p>
<p>调优：当然是越大越好，如果读比写少，开到0.4-0.5也没问题。如果读写较均衡，0.3左右。如果写比读多，果断默认吧。设置这个值的时候，你同时要参考 hbase.regionserver.global.memstore.upperLimit ，该值是memstore占heap的最大百分比，两个参数一个影响读，一个影响写。如果两值加起来超过80-90%，会有OOM的风险，谨慎设置。</p>
<p>hbase.hstore.blockingStoreFiles</p>
<p>默认值：7</p>
<p>说明：在compaction时，如果一个Store（Coulmn Family）内有超过7个storefile需要合并，则block所有的写请求，进行flush，限制storefile数量增长过快。</p>
<p>调优：block写请求会影响当前region的性能，将值设为单个region可以支撑的最大store file数量会是个不错的选择，即允许comapction时，memstore继续生成storefile。最大storefile数量可通过region size/memstore size来计算。如果你将region size设为无限大，那么你需要预估一个region可能产生的最大storefile数。</p>
<p>hbase.hregion.memstore.block.multiplier</p>
<p>默认值：2</p>
<p>说明：当一个region里的memstore超过单个memstore.size两倍的大小时，block该region的所有请求，进行flush，释放内存。虽然我们设置了memstore的总大小，比如64M，但想象一下，在最后63.9M的时候，我Put了一个100M的数据，此时memstore的大小会瞬间暴涨到超过预期的memstore.size。这个参数的作用是当memstore的大小增至超过memstore.size时，block所有请求，遏制风险进一步扩大。</p>
<p>调优： 这个参数的默认值还是比较靠谱的。如果你预估你的正常应用场景（不包括异常）不会出现突发写或写的量可控，那么保持默认值即可。如果正常情况下，你的写请求量就会经常暴长到正常的几倍，那么你应该调大这个倍数并调整其他参数值，比如hfile.block.cache.size和hbase.regionserver.global.memstore.upperLimit/lowerLimit，以预留更多内存，防止HBase server OOM。</p>
<h2>其他</h2>
<p>启用<span style="font-family:Times New Roman">LZO</span><span style="font-family:宋体">压缩</span></p>
<p>LZO对比Hbase默认的GZip，前者性能较高，后者压缩比较高，具体参见 <a target="_blank" href="http://wiki.apache.org/hadoop/UsingLzoCompression" rel="nofollow"><span style="color:rgb(0,0,255)">Using LZO Compression</span></a>。对于想提高HBase读写性能的开发者，采用LZO是比较好的选择。对于非常在乎存储空间的开发者，则建议保持默认。</p>
<p>不要在一张表里定义太多的<span style="font-family:Times New Roman">Column Family</span></p>
<p>Hbase目前不能良好的处理超过包含2-3个CF的表。因为某个CF在flush发生时，它邻近的CF也会因关联效应被触发flush，最终导致系统产生更多IO。</p>
<p>批量导入</p>
<p>在批量导入数据到Hbase前，你可以通过预先创建regions，来平衡数据的负载。详见 <a target="_blank" href="#precreate.regions" rel="nofollow"><span style="color:rgb(0,0,255)">Table Creation: Pre-Creating Regions</span></a></p>
<p>避免<span style="font-family:Times New Roman">CMS concurrent mode failure</span></p>
<p>HBase使用CMS GC。默认触发GC的时机是当年老代内存达到90%的时候，这个百分比由 -XX:CMSInitiatingOccupancyFraction=N 这个参数来设置。concurrent mode failed发生在这样一个场景：</p>
<p>当年老代内存达到90%的时候，CMS开始进行并发垃圾收集，于此同时，新生代还在迅速不断地晋升对象到年老代。当年老代CMS还未完成并发标记时，年老代满了，悲剧就发生了。CMS因为没内存可用不得不暂停mark，并触发一次全jvm的stop the world（挂起所有线程），然后采用单线程拷贝方式清理所有垃圾对象。这个过程会非常漫长。为了避免出现concurrent mode failed，我们应该让GC在未到90%时，就触发。</p>
<p>通过设置 -XX:CMSInitiatingOccupancyFraction=N</p>
<p>这个百分比， 可以简单的这么计算。如果你的 hfile.block.cache.size 和 hbase.regionserver.global.memstore.upperLimit 加起来有60%（默认），那么你可以设置 70-80，一般高10%左右差不多。</p>
<h2>Hbase客户端优化</h2>
<p>AutoFlush</p>
<p>将<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html" rel="nofollow"><span style="color:rgb(0,0,255)">HTable</span></a>的setAutoFlush设为false，可以支持客户端批量更新。即当Put填满客户端flush缓存时，才发送到服务端。默认是true。</p>
<p>Scan Caching</p>
<p>scanner一次缓存多少数据来scan（从服务端一次抓多少数据回来scan）。<br>
默认值是 1，一次只取一条。</p>
<p>Scan Attribute Selection</p>
<p>scan时建议指定需要的Column Family，减少通信量，否则scan操作默认会返回整个row的所有数据（所有Coulmn Family）。</p>
<p>Close ResultScanners</p>
<p>通过scan取完数据后，记得要关闭ResultScanner，否则RegionServer可能会出现问题（对应的Server资源无法释放）。</p>
<p>Optimal Loading of Row Keys</p>
<p>当你scan一张表的时候，返回结果只需要row key（不需要CF, qualifier,values,timestaps）时，你可以在scan实例中添加一个filterList，并设置 MUST_PASS_ALL操作，filterList中add <a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/FirstKeyOnlyFilter.html" rel="nofollow"><span style="color:rgb(0,0,255)">FirstKeyOnlyFilter</span></a>或<a target="_blank" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/KeyOnlyFilter.html" rel="nofollow"><span style="color:rgb(0,0,255)">KeyOnlyFilter</span></a>。这样可以减少网络通信量。</p>
<p>Turn off WAL on Puts</p>
<p>当Put某些非重要数据时，你可以设置writeToWAL(false)，来进一步提高写性能。writeToWAL(false)会在Put时放弃写WAL log。风险是，当RegionServer宕机时，可能你刚才Put的那些数据会丢失，且无法恢复。</p>
<p>启用<span style="font-family:Times New Roman">Bloom Filter</span></p>
<p><a target="_blank" href="#blooms" rel="nofollow"><span style="color:rgb(0,0,255)">Bloom Filter</span></a>通过空间换时间，提高读操作性能</p>
<p>十三、 关于HFile的思考</p>
<p> </p>
<p> </p>
<p> </p>
<p>本文是一篇转载文章，原文作者郭鹏（@<a target="_blank" href="http://weibo.com/gpcuster/" rel="nofollow"><span style="color:rgb(0,0,255)">逖靖寒</span></a>），国内Cassandra领域的先驱者和实践者。资深软件开发工程师，擅长分布式应用程序的开发和使用，实践经验极其丰富。在本文中，作者推荐了<a target="_blank" href="http://blog.nosqlfan.com/tags/hfile" rel="nofollow" title="查看 HFile 的全部文章"><span style="color:rgb(0,0,255)">HFile</span></a>文件格式的经典论文，并对HFile的block size的应用进行了实例探讨。</p>
<p> </p>
<p>0.90.x版本的HBase中的文件是存储在HFile中的。</p>
<p>关于HFile文件的详细介绍，可以查看这篇文章：<a target="_blank" href="http://www.data-works.org/download/hfile.pdf" rel="nofollow"><span style="color:rgb(0,0,255)">hfile.pdf</span></a></p>
<p>这篇文章中介绍了以下五点内容：</p>
<p>· HFile的作用。</p>
<p>· HFile的格式。</p>
<p>· HFile的性能。</p>
<p>· HFile的使用注意事项。</p>
<p>· HFile的编程接口。</p>
<p>HFile中有一个很重要的参数，那就是block size。如果我们写入hfile中的某一个value的值大于block size会怎么样？</p>
<p>于是有如下的测试代码：</p>
<p>// create local file system</p>
<p>FileSystem fs = new RawLocalFileSystem();</p>
<p>fs.setConf(new Configuration());</p>
<p> </p>
<p>// block size = 1kb</p>
<p>HFile.Writer hwriter = new HFile.Writer(fs,</p>
<p>        new Path("hfile"), 1, (Compression.Algorithm) null, null);</p>
<p> </p>
<p>// create key &amp; value, the value is 8kb, larger than 1kb</p>
<p>byte[] key = "www.data-works.org".getBytes();</p>
<p>byte[] value = new byte[8 * 1024];</p>
<p>for (int i = 0; i &lt; 8 * 1024; i++) {</p>
<p>    value[i] = '0';</p>
<p>}</p>
<p> </p>
<p>// add values to hfile</p>
<p>for (int i = 0; i &lt; 10; i++) {</p>
<p>    hwriter.append(key, value);</p>
<p>}</p>
<p> </p>
<p>// close hfile</p>
<p>hwriter.close();</p>
<p>上面的代码可以看出来，每一个value的值都是8kb，已经超过了hfile预设的1kb的block size。</p>
<p>实际的写入情况是如果value大于block size，那么就按照实际的情况来写。</p>
<p>上面的测试用例执行完毕以后，整个hile文件只有1个data block。</p>
<p>这个hfile的读取代码如下：</p>
<p>// create local file system</p>
<p>FileSystem fs = new RawLocalFileSystem();</p>
<p>fs.initialize(URI.create("file:///"), new Configuration());</p>
<p>fs.setConf(new Configuration());</p>
<p>HFile.Reader hreader = new HFile.Reader(fs,</p>
<p>new Path("hfile"), null, false);</p>
<p> </p>
<p>// loadFileInfo</p>
<p>hreader.loadFileInfo();</p>
<p> </p>
<p>HFileScanner hscanner = hreader.getScanner(false, false);</p>
<p> </p>
<p>// seek to the start position of the hfile.</p>
<p>hscanner.seekTo();</p>
<p> </p>
<p>// print values.</p>
<p>int index = 1;</p>
<p>while (hscanner.next()) {</p>
<p>System.out.println("index: " + index++);</p>
<p>System.out.println("key: " + hscanner.getKeyString());</p>
<p>System.out.println("value: " + hscanner.getValueString());</p>
<p>}</p>
<p> </p>
<p>// close hfile.</p>
<p>hreader.close();</p>
<p>上面的代码将读取hfile，并将这个文件中的所有kv打印出来。</p>
<p>通过上面的测试可以看出：如果某一个key有非常非常多的value，那么查找这些value就无法通过索引去快速查找，而是需要通过遍历进行。</p>
<p>另外，JIRA上面的<a target="_blank" href="https://issues.apache.org/jira/browse/HBASE-3857" rel="nofollow"><span style="color:rgb(0,0,255)">HBASE-3857</span></a>也提出了一种新的HFile格式，HFile v2</p>
<p>他主要是针对现有HFile的两个主要缺陷提出来的：</p>
<p>· 暂用过多内存</p>
<p>· 启动加载时间缓慢</p>
<p>有兴趣的朋友可以详细了解一下。</p>
<p>十四、 HBase性能优化方法总结</p>
<p> </p>
<p>1. 表的设计</p>
<p>1.1 Pre-Creating Regions</p>
<p>默认情况下，在创建HBase表的时候会自动创建一个region分区，当导入数据的时候，所有的HBase客户端都向这一个region写数据，直到这个region足够大了才进行切分。一种可以加快批量写入速度的方法是通过预先创建一些空的regions，这样当数据写入HBase时，会按照region分区情况，在集群内做数据的负载均衡。</p>
<p>有关预分区，详情参见：<a target="_blank" href="#precreate.regions" rel="nofollow"><span style="color:rgb(0,0,255)">Table Creation: Pre-Creating Regions</span></a>，下面是一个例子：</p>
<table>
<tbody>
<tr>
<td valign="center">
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
<p>19</p>
<p>20</p>
<p>21</p>
<p>22</p>
<p>23</p>
<p>24</p>
<p>25</p>
<p>26</p>
</td>
<td valign="center">
<p>public static boolean createTable(HBaseAdmin admin, HTableDescriptor table, byte[][] splits) </p>
<p>throws IOException { </p>
<p>  try { </p>
<p>    admin.createTable(table, splits); </p>
<p>    return true; </p>
<p>  } catch (TableExistsException e) { </p>
<p>    logger.info("table " + table.getNameAsString() + " already exists"); </p>
<p>    // the table already exists... </p>
<p>    return false; </p>
<p>  } </p>
<p>} </p>
<p>  </p>
<p>public static byte[][] getHexSplits(String startKey, String endKey, int numRegions) { </p>
<p>  byte[][] splits = new byte[numRegions-1][]; </p>
<p>  BigInteger lowestKey = new BigInteger(startKey, 16); </p>
<p>  BigInteger highestKey = new BigInteger(endKey, 16); </p>
<p>  BigInteger range = highestKey.subtract(lowestKey); </p>
<p>  BigInteger regionIncrement = range.divide(BigInteger.valueOf(numRegions)); </p>
<p>  lowestKey = lowestKey.add(regionIncrement); </p>
<p>  for(int i=0; i &lt; numRegions-1;i++) { </p>
<p>    BigInteger key = lowestKey.add(regionIncrement.multiply(BigInteger.valueOf(i))); </p>
<p>    byte[] b = String.format("%016x", key).getBytes(); </p>
<p>    splits[i] = b; </p>
<p>  } </p>
<p>  return splits; </p>
<p>}</p>
</td>
</tr>
</tbody>
</table>
<p>1.2 Row Key</p>
<p>HBase中row key用来检索表中的记录，支持以下三种方式：</p>
<p>· 通过单个row key访问：即按照某个row key键值进行get操作；</p>
<p>· 通过row key的range进行scan：即通过设置startRowKey和endRowKey，在这个范围内进行扫描；</p>
<p>· 全表扫描：即直接扫描整张表中所有行记录。</p>
<p>在HBase中，row key可以是任意字符串，最大长度64KB，实际应用中一般为10~100bytes，存为byte[]字节数组，一般设计成定长的。</p>
<p>row key是按照字典序存储，因此，设计row key时，要充分利用这个排序特点，将经常一起读取的数据存储到一块，将最近可能会被访问的数据放在一块。</p>
<p>举个例子：如果最近写入HBase表中的数据是最可能被访问的，可以考虑将时间戳作为row key的一部分，由于是字典序排序，所以可以使用Long.MAX_VALUE – timestamp作为row key，这样能保证新写入的数据在读取时可以被快速命中。</p>
<p>1.3 Column Family</p>
<p>不要在一张表里定义太多的column family。目前Hbase并不能很好的处理超过2~3个column family的表。因为某个column family在flush的时候，它邻近的column family也会因关联效应被触发flush，最终导致系统产生更多的I/O。感兴趣的同学可以对自己的HBase集群进行实际测试，从得到的测试结果数据验证一下。</p>
<p>1.4 In Memory</p>
<p>创建表的时候，可以通过HColumnDescriptor.setInMemory(true)将表放到RegionServer的缓存中，保证在读取的时候被cache命中。</p>
<p>1.5 Max Version</p>
<p>创建表的时候，可以通过HColumnDescriptor.setMaxVersions(int maxVersions)设置表中数据的最大版本，如果只需要保存最新版本的数据，那么可以设置setMaxVersions(1)。</p>
<p>1.6 Time To Live</p>
<p>创建表的时候，可以通过HColumnDescriptor.setTimeToLive(int timeToLive)设置表中数据的存储生命期，过期数据将自动被删除，例如如果只需要存储最近两天的数据，那么可以设置setTimeToLive(2 * 24 * 60 * 60)。</p>
<p>1.7 Compact &amp; Split</p>
<p>在HBase中，数据在更新时首先写入WAL 日志(HLog)和内存(MemStore)中，MemStore中的数据是排序的，当MemStore累计到一定阈值时，就会创建一个新的MemStore，并且将老的MemStore添加到flush队列，由单独的线程flush到磁盘上，成为一个StoreFile。于此同时， 系统会在zookeeper中记录一个redo point，表示这个时刻之前的变更已经持久化了(minor compact)。</p>
<p>StoreFile是只读的，一旦创建后就不可以再修改。因此Hbase的更新其实是不断追加的操作。当一个Store中的StoreFile达到一定的阈值后，就会进行一次合并(major compact)，将对同一个key的修改合并到一起，形成一个大的StoreFile，当StoreFile的大小达到一定阈值后，又会对 StoreFile进行分割(split)，等分为两个StoreFile。</p>
<p>由于对表的更新是不断追加的，处理读请求时，需要访问Store中全部的StoreFile和MemStore，将它们按照row key进行合并，由于StoreFile和MemStore都是经过排序的，并且StoreFile带有内存中索引，通常合并过程还是比较快的。</p>
<p>实际应用中，可以考虑必要时手动进行major compact，将同一个row key的修改进行合并形成一个大的StoreFile。同时，可以将StoreFile设置大些，减少split的发生。</p>
<p>2. 写表操作</p>
<p>2.1 多HTable并发写</p>
<p>创建多个HTable客户端用于写操作，提高写数据的吞吐量，一个例子：</p>
<table>
<tbody>
<tr>
<td valign="center">
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
</td>
<td valign="center">
<p>static final Configuration conf = HBaseConfiguration.create(); </p>
<p>static final String table_log_name = “user_log”; </p>
<p>wTableLog = new HTable[tableN]; </p>
<p>for (int i = 0; i &lt; tableN; i++) { </p>
<p>    wTableLog[i] = new HTable(conf, table_log_name); </p>
<p>    wTableLog[i].setWriteBufferSize(5 * 1024 * 1024); //5MB </p>
<p>    wTableLog[i].setAutoFlush(false); </p>
<p>}</p>
</td>
</tr>
</tbody>
</table>
<p>2.2 HTable参数设置</p>
<p>2.2.1 Auto Flush</p>
<p>通过调用HTable.setAutoFlush(false)方法可以将HTable写客户端的自动flush关闭，这样可以批量写入数据到HBase，而不是有一条put就执行一次更新，只有当put填满客户端写缓存时，才实际向HBase服务端发起写请求。默认情况下auto flush是开启的。</p>
<p>2.2.2 Write Buffer</p>
<p>通过调用HTable.setWriteBufferSize(writeBufferSize)方法可以设置HTable客户端的写buffer大小，如果新设置的buffer小于当前写buffer中的数据时，buffer将会被flush到服务端。其中，writeBufferSize的单位是byte字节数，可以根据实际写入数据量的多少来设置该值。</p>
<p>2.2.3 WAL Flag</p>
<p>在HBae中，客户端向集群中的RegionServer提交数据时（Put/Delete操作），首先会先写WAL（Write Ahead Log）日志（即HLog，一个RegionServer上的所有Region共享一个HLog），只有当WAL日志写成功后，再接着写MemStore，然后客户端被通知提交数据成功；如果写WAL日志失败，客户端则被通知提交失败。这样做的好处是可以做到RegionServer宕机后的数据恢复。</p>
<p>因此，对于相对不太重要的数据，可以在Put/Delete操作时，通过调用Put.setWriteToWAL(false)或Delete.setWriteToWAL(false)函数，放弃写WAL日志，从而提高数据写入的性能。</p>
<p>值得注意的是：谨慎选择关闭WAL日志，因为这样的话，一旦RegionServer宕机，Put/Delete的数据将会无法根据WAL日志进行恢复。</p>
<p>2.3 批量写</p>
<p>通过调用HTable.put(Put)方法可以将一个指定的row key记录写入HBase，同样HBase提供了另一个方法：通过调用HTable.put(List&lt;Put&gt;)方法可以将指定的row key列表，批量写入多行记录，这样做的好处是批量执行，只需要一次网络I/O开销，这对于对数据实时性要求高，网络传输RTT高的情景下可能带来明显的性能提升。</p>
<p>2.4 多线程并发写</p>
<p>在客户端开启多个HTable写线程，每个写线程负责一个HTable对象的flush操作，这样结合定时flush和写buffer（writeBufferSize），可以既保证在数据量小的时候，数据可以在较短时间内被flush（如1秒内），同时又保证在数据量大的时候，写buffer一满就及时进行flush。下面给个具体的例子：</p>
<table>
<tbody>
<tr>
<td valign="center">
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
<p>19</p>
<p>20</p>
<p>21</p>
<p>22</p>
</td>
<td valign="center">
<p>for (int i = 0; i &lt; threadN; i++) { </p>
<p>    Thread th = new Thread() { </p>
<p>        public void run() { </p>
<p>            while (true) { </p>
<p>                try { </p>
<p>                    sleep(1000); //1 second </p>
<p>                } catch (InterruptedException e) { </p>
<p>                    e.printStackTrace(); </p>
<p>                } </p>
<p>                                synchronized (wTableLog[i]) { </p>
<p>                    try { </p>
<p>                        wTableLog[i].flushCommits(); </p>
<p>                    } catch (IOException e) { </p>
<p>                        e.printStackTrace(); </p>
<p>                    } </p>
<p>                } </p>
<p>            } </p>
<p>                } </p>
<p>    }; </p>
<p>    th.setDaemon(true); </p>
<p>    th.start(); </p>
<p>}</p>
</td>
</tr>
</tbody>
</table>
<p>3. 读表操作</p>
<p>3.1 多HTable并发读</p>
<p>创建多个HTable客户端用于读操作，提高读数据的吞吐量，一个例子：</p>
<table>
<tbody>
<tr>
<td valign="center">
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
</td>
<td valign="center">
<p>static final Configuration conf = HBaseConfiguration.create(); </p>
<p>static final String table_log_name = “user_log”; </p>
<p>rTableLog = new HTable[tableN]; </p>
<p>for (int i = 0; i &lt; tableN; i++) { </p>
<p>    rTableLog[i] = new HTable(conf, table_log_name); </p>
<p>    rTableLog[i].setScannerCaching(50); </p>
<p>}</p>
</td>
</tr>
</tbody>
</table>
<p>3.2 HTable参数设置</p>
<p>3.2.1 Scanner Caching</p>
<p>通过调用HTable.setScannerCaching(int scannerCaching)可以设置HBase scanner一次从服务端抓取的数据条数，默认情况下一次一条。通过将此值设置成一个合理的值，可以减少scan过程中next()的时间开销，代价是scanner需要通过客户端的内存来维持这些被cache的行记录。</p>
<p>3.2.2 Scan Attribute Selection</p>
<p>scan时指定需要的Column Family，可以减少网络传输数据量，否则默认scan操作会返回整行所有Column Family的数据。</p>
<p>3.2.3 Close ResultScanner</p>
<p>通过scan取完数据后，记得要关闭ResultScanner，否则RegionServer可能会出现问题（对应的Server资源无法释放）。</p>
<p>3.3 批量读</p>
<p>通过调用HTable.get(Get)方法可以根据一个指定的row key获取一行记录，同样HBase提供了另一个方法：通过调用HTable.get(List)方法可以根据一个指定的row key列表，批量获取多行记录，这样做的好处是批量执行，只需要一次网络I/O开销，这对于对数据实时性要求高而且网络传输RTT高的情景下可能带来明显的性能提升。</p>
<p>3.4 多线程并发读</p>
<p>在客户端开启多个HTable读线程，每个读线程负责通过HTable对象进行get操作。下面是一个多线程并发读取HBase，获取店铺一天内各分钟PV值的例子：</p>
<table>
<tbody>
<tr>
<td valign="center">
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
<p>19</p>
<p>20</p>
<p>21</p>
<p>22</p>
<p>23</p>
<p>24</p>
<p>25</p>
<p>26</p>
<p>27</p>
<p>28</p>
<p>29</p>
<p>30</p>
<p>31</p>
<p>32</p>
<p>33</p>
<p>34</p>
<p>35</p>
<p>36</p>
<p>37</p>
<p>38</p>
<p>39</p>
<p>40</p>
<p>41</p>
<p>42</p>
<p>43</p>
<p>44</p>
<p>45</p>
<p>46</p>
<p>47</p>
<p>48</p>
<p>49</p>
<p>50</p>
<p>51</p>
<p>52</p>
<p>53</p>
<p>54</p>
<p>55</p>
<p>56</p>
<p>57</p>
<p>58</p>
<p>59</p>
<p>60</p>
<p>61</p>
<p>62</p>
<p>63</p>
<p>64</p>
<p>65</p>
<p>66</p>
<p>67</p>
<p>68</p>
<p>69</p>
<p>70</p>
<p>71</p>
<p>72</p>
<p>73</p>
<p>74</p>
<p>75</p>
<p>76</p>
<p>77</p>
<p>78</p>
<p>79</p>
<p>80</p>
<p>81</p>
<p>82</p>
<p>83</p>
<p>84</p>
<p>85</p>
<p>86</p>
<p>87</p>
<p>88</p>
<p>89</p>
<p>90</p>
<p>91</p>
<p>92</p>
<p>93</p>
<p>94</p>
<p>95</p>
<p>96</p>
<p>97</p>
<p>98</p>
<p>99</p>
<p>100</p>
<p>101</p>
<p>102</p>
<p>103</p>
<p>104</p>
<p>105</p>
<p>106</p>
<p>107</p>
<p>108</p>
<p>109</p>
<p>110</p>
<p>111</p>
<p>112</p>
<p>113</p>
<p>114</p>
<p>115</p>
<p>116</p>
<p>117</p>
<p>118</p>
<p>119</p>
<p>120</p>
<p>121</p>
<p>122</p>
<p>123</p>
<p>124</p>
<p>125</p>
<p>126</p>
<p>127</p>
<p>128</p>
<p>129</p>
<p>130</p>
<p>131</p>
<p>132</p>
<p>133</p>
<p>134</p>
<p>135</p>
<p>136</p>
<p>137</p>
<p>138</p>
<p>139</p>
<p>140</p>
<p>141</p>
<p>142</p>
<p>143</p>
<p>144</p>
<p>145</p>
<p>146</p>
</td>
<td valign="center">
<p>public class DataReaderServer { </p>
<p>     //获取店铺一天内各分钟PV值的入口函数 </p>
<p>     public static ConcurrentHashMap getUnitMinutePV(long uid, long startStamp, long endStamp){ </p>
<p>         long min = startStamp; </p>
<p>         int count = (int)((endStamp - startStamp) / (60*1000)); </p>
<p>         List lst = new ArrayList(); </p>
<p>         for (int i = 0; i &lt;= count; i++) { </p>
<p>            min = startStamp + i * 60 * 1000; </p>
<p>            lst.add(uid + "_" + min); </p>
<p>         } </p>
<p>         return parallelBatchMinutePV(lst); </p>
<p>     } </p>
<p>      //多线程并发查询，获取分钟PV值 </p>
<p>private static ConcurrentHashMap parallelBatchMinutePV(List lstKeys){ </p>
<p>        ConcurrentHashMap hashRet = new ConcurrentHashMap(); </p>
<p>        int parallel = 3; </p>
<p>        List&lt;List&lt;String&gt;&gt; lstBatchKeys  = null; </p>
<p>        if (lstKeys.size() &lt; parallel ){ </p>
<p>            lstBatchKeys  = new ArrayList&lt;List&lt;String&gt;&gt;(1); </p>
<p>            lstBatchKeys.add(lstKeys); </p>
<p>        } </p>
<p>        else{ </p>
<p>            lstBatchKeys  = new ArrayList&lt;List&lt;String&gt;&gt;(parallel); </p>
<p>            for(int i = 0; i &lt; parallel; i++  ){ </p>
<p>                List lst = new ArrayList(); </p>
<p>                lstBatchKeys.add(lst); </p>
<p>            } </p>
<p>  </p>
<p>            for(int i = 0 ; i &lt; lstKeys.size() ; i ++ ){ </p>
<p>                lstBatchKeys.get(i%parallel).add(lstKeys.get(i)); </p>
<p>            } </p>
<p>        } </p>
<p>  </p>
<p>        List &gt;&gt; futures = new ArrayList &gt;&gt;(5); </p>
<p>  </p>
<p>        ThreadFactoryBuilder builder = new ThreadFactoryBuilder(); </p>
<p>        builder.setNameFormat("ParallelBatchQuery"); </p>
<p>        ThreadFactory factory = builder.build(); </p>
<p>        ThreadPoolExecutor executor = (ThreadPoolExecutor) Executors.newFixedThreadPool(lstBatchKeys.size(), factory); </p>
<p>  </p>
<p>        for(List keys : lstBatchKeys){ </p>
<p>            Callable&lt; ConcurrentHashMap &gt; callable = new BatchMinutePVCallable(keys); </p>
<p>            FutureTask&lt; ConcurrentHashMap &gt; future = (FutureTask&lt; ConcurrentHashMap &gt;) executor.submit(callable); </p>
<p>            futures.add(future); </p>
<p>        } </p>
<p>        executor.shutdown(); </p>
<p>  </p>
<p>        // Wait for all the tasks to finish </p>
<p>        try { </p>
<p>          boolean stillRunning = !executor.awaitTermination( </p>
<p>              5000000, TimeUnit.MILLISECONDS); </p>
<p>          if (stillRunning) { </p>
<p>            try { </p>
<p>                executor.shutdownNow(); </p>
<p>            } catch (Exception e) { </p>
<p>                // TODO Auto-generated catch block </p>
<p>                e.printStackTrace(); </p>
<p>            } </p>
<p>          } </p>
<p>        } catch (InterruptedException e) { </p>
<p>          try { </p>
<p>              Thread.currentThread().interrupt(); </p>
<p>          } catch (Exception e1) { </p>
<p>            // TODO Auto-generated catch block </p>
<p>            e1.printStackTrace(); </p>
<p>          } </p>
<p>        } </p>
<p>  </p>
<p>        // Look for any exception </p>
<p>        for (Future f : futures) { </p>
<p>          try { </p>
<p>              if(f.get() != null) </p>
<p>              { </p>
<p>                  hashRet.putAll((ConcurrentHashMap)f.get()); </p>
<p>              } </p>
<p>          } catch (InterruptedException e) { </p>
<p>            try { </p>
<p>                 Thread.currentThread().interrupt(); </p>
<p>            } catch (Exception e1) { </p>
<p>                // TODO Auto-generated catch block </p>
<p>                e1.printStackTrace(); </p>
<p>            } </p>
<p>          } catch (ExecutionException e) { </p>
<p>            e.printStackTrace(); </p>
<p>          } </p>
<p>        } </p>
<p>  </p>
<p>        return hashRet; </p>
<p>    } </p>
<p>     //一个线程批量查询，获取分钟PV值 </p>
<p>    protected static ConcurrentHashMap getBatchMinutePV(List lstKeys){ </p>
<p>        ConcurrentHashMap hashRet = null; </p>
<p>        List lstGet = new ArrayList(); </p>
<p>        String[] splitValue = null; </p>
<p>        for (String s : lstKeys) { </p>
<p>            splitValue = s.split("_"); </p>
<p>            long uid = Long.parseLong(splitValue[0]); </p>
<p>            long min = Long.parseLong(splitValue[1]); </p>
<p>            byte[] key = new byte[16]; </p>
<p>            Bytes.putLong(key, 0, uid); </p>
<p>            Bytes.putLong(key, 8, min); </p>
<p>            Get g = new Get(key); </p>
<p>            g.addFamily(fp); </p>
<p>            lstGet.add(g); </p>
<p>        } </p>
<p>        Result[] res = null; </p>
<p>        try { </p>
<p>            res = tableMinutePV[rand.nextInt(tableN)].get(lstGet); </p>
<p>        } catch (IOException e1) { </p>
<p>            logger.error("tableMinutePV exception, e=" + e1.getStackTrace()); </p>
<p>        } </p>
<p>  </p>
<p>        if (res != null &amp;&amp; res.length &gt; 0) { </p>
<p>            hashRet = new ConcurrentHashMap(res.length); </p>
<p>            for (Result re : res) { </p>
<p>                if (re != null &amp;&amp; !re.isEmpty()) { </p>
<p>                    try { </p>
<p>                        byte[] key = re.getRow(); </p>
<p>                        byte[] value = re.getValue(fp, cp); </p>
<p>                        if (key != null &amp;&amp; value != null) { </p>
<p>                            hashRet.put(String.valueOf(Bytes.toLong(key, </p>
<p>                                    Bytes.SIZEOF_LONG)), String.valueOf(Bytes </p>
<p>                                    .toLong(value))); </p>
<p>                        } </p>
<p>                    } catch (Exception e2) { </p>
<p>                        logger.error(e2.getStackTrace()); </p>
<p>                    } </p>
<p>                } </p>
<p>            } </p>
<p>        } </p>
<p>  </p>
<p>        return hashRet; </p>
<p>    } </p>
<p>} </p>
<p>//调用接口类，实现Callable接口 </p>
<p>class BatchMinutePVCallable implements Callable&gt;{ </p>
<p>     private List keys; </p>
<p>  </p>
<p>     public BatchMinutePVCallable(List lstKeys ) { </p>
<p>         this.keys = lstKeys; </p>
<p>     } </p>
<p>  </p>
<p>     public ConcurrentHashMap call() throws Exception { </p>
<p>         return DataReadServer.getBatchMinutePV(keys); </p>
<p>     } </p>
<p>}</p>
</td>
</tr>
</tbody>
</table>
<p>3.5 缓存查询结果</p>
<p>对于频繁查询HBase的应用场景，可以考虑在应用程序中做缓存，当有新的查询请求时，首先在缓存中查找，如果存在则直接返回，不再查询HBase；否则对HBase发起读请求查询，然后在应用程序中将查询结果缓存起来。至于缓存的替换策略，可以考虑LRU等常用的策略。</p>
<p>3.6 Blockcache</p>
<p>HBase上Regionserver的内存分为两个部分，一部分作为Memstore，主要用来写；另外一部分作为BlockCache，主要用于读。</p>
<p>写请求会先写入Memstore，Regionserver会给每个region提供一个Memstore，当Memstore满64MB以后，会启动 flush刷新到磁盘。当Memstore的总大小超过限制时（heapsize * hbase.regionserver.global.memstore.upperLimit * 0.9），会强行启动flush进程，从最大的Memstore开始flush直到低于限制。</p>
<p>读请求先到Memstore中查数据，查不到就到BlockCache中查，再查不到就会到磁盘上读，并把读的结果放入BlockCache。由于BlockCache采用的是LRU策略，因此BlockCache达到上限(heapsize * hfile.block.cache.size * 0.85)后，会启动淘汰机制，淘汰掉最老的一批数据。</p>
<p>一个Regionserver上有一个BlockCache和N个Memstore，它们的大小之和不能大于等于heapsize * 0.8，否则HBase不能启动。默认BlockCache为0.2，而Memstore为0.4。对于注重读响应时间的系统，可以将 BlockCache设大些，比如设置BlockCache=0.4，Memstore=0.39，以加大缓存的命中率。</p>
<p>有关BlockCache机制，请参考这里：HBase的Block cache，HBase的blockcache机制，hbase中的缓存的计算与使用。</p>
<p>4.数据计算</p>
<p>4.1 服务端计算</p>
<p>Coprocessor运行于HBase RegionServer服务端，各个Regions保持对与其相关的coprocessor实现类的引用，coprocessor类可以通过RegionServer上classpath中的本地jar或HDFS的classloader进行加载。</p>
<p>目前，已提供有几种coprocessor：</p>
<p>Coprocessor：提供对于region管理的钩子，例如region的open/close/split/flush/compact等；<br>
RegionObserver：提供用于从客户端监控表相关操作的钩子，例如表的get/put/scan/delete等；<br>
Endpoint：提供可以在region上执行任意函数的命令触发器。一个使用例子是RegionServer端的列聚合，这里有代码示例。<br>
以上只是有关coprocessor的一些基本介绍，本人没有对其实际使用的经验，对它的可用性和性能数据不得而知。感兴趣的同学可以尝试一下，欢迎讨论。</p>
<p>4.2 写端计算</p>
<p>4.2.1 计数</p>
<p>HBase本身可以看作是一个可以水平扩展的Key-Value存储系统，但是其本身的计算能力有限（Coprocessor可以提供一定的服务端计算），因此，使用HBase时，往往需要从写端或者读端进行计算，然后将最终的计算结果返回给调用者。举两个简单的例子：</p>
<p>PV计算：通过在HBase写端内存中，累加计数，维护PV值的更新，同时为了做到持久化，定期（如1秒）将PV计算结果同步到HBase中，这样查询端最多会有1秒钟的延迟，能看到秒级延迟的PV结果。<br>
分钟PV计算：与上面提到的PV计算方法相结合，每分钟将当前的累计PV值，按照rowkey + minute作为新的rowkey写入HBase中，然后在查询端通过scan得到当天各个分钟以前的累计PV值，然后顺次将前后两分钟的累计PV值相减，就得到了当前一分钟内的PV值，从而最终也就得到当天各个分钟内的PV值。</p>
<p>4.2.2 去重</p>
<p>对于UV的计算，就是个去重计算的例子。分两种情况：</p>
<p>如果内存可以容纳，那么可以在Hash表中维护所有已经存在的UV标识，每当新来一个标识时，通过快速查找Hash确定是否是一个新的UV，若是则UV值加1，否则UV值不变。另外，为了做到持久化或提供给查询接口使用，可以定期（如1秒）将UV计算结果同步到HBase中。<br>
如果内存不能容纳，可以考虑采用Bloom Filter来实现，从而尽可能的减少内存的占用情况。除了UV的计算外，判断URL是否存在也是个典型的应用场景。</p>
<p>4.3 读端计算</p>
<p>如果对于响应时间要求比较苛刻的情况（如单次http请求要在毫秒级时间内返回），个人觉得读端不宜做过多复杂的计算逻辑，尽量做到读端功能单一化：即从HBase RegionServer读到数据（scan或get方式）后，按照数据格式进行简单的拼接，直接返回给前端使用。当然，如果对于响应时间要求一般，或者业务特点需要，也可以在读端进行一些计算逻辑。</p>
<p>5.总结</p>
<p>作为一个Key-Value存储系统，HBase并不是万能的，它有自己独特的地方。因此，基于它来做应用时，我们往往需要从多方面进行优化改进（表设计、读表操作、写表操作、数据计算等），有时甚至还需要从系统级对HBase进行配置调优，更甚至可以对HBase本身进行优化。这属于不同的层次范畴。</p>
<p>总之，概括来讲，对系统进行优化时，首先定位到影响你的程序运行性能的瓶颈之处，然后有的放矢进行针对行的优化。如果优化后满足你的期望，那么就可以停止优化；否则继续寻找新的瓶颈之处，开始新的优化，直到满足性能要求。</p>
<p>以上就是从项目开发中总结的一点经验，如有不对之处，欢迎大家不吝赐教。</p>
<p>十五、 HBase 系统架构</p>
<p> </p>
<p><span style="color:rgb(75,75,75)">HBase<span style="font-family:宋体">是</span><span style="font-family:Verdana">Apache Hadoop</span><span style="font-family:宋体">的数据库，能够对大型数据提供随机、实时的读写访问。</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的目标是存储并处理大型的数据。</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">是一个开源的，分布式的，多版本的，面向列的存储模型。它存储的是松散型数据。</span></span></p>
<p><span style="color:rgb(75,75,75)">HBase<span style="font-family:宋体">特性：</span></span></p>
<p><span style="color:rgb(75,75,75)">1 <span style="font-family:宋体">高可靠性</span></span></p>
<p><span style="color:rgb(75,75,75)">2 <span style="font-family:宋体">高效性</span></span></p>
<p><span style="color:rgb(75,75,75)">3 <span style="font-family:宋体">面向列</span></span></p>
<p><span style="color:rgb(75,75,75)">4 <span style="font-family:宋体">可伸缩</span></span></p>
<p><span style="color:rgb(75,75,75)">5 <span style="font-family:宋体">可在廉价</span><span style="font-family:Verdana">PC Server</span><span style="font-family:宋体">搭建大规模结构化存储集群</span></span></p>
<p><span style="color:rgb(75,75,75)">HBase<span style="font-family:宋体">是</span><span style="font-family:Verdana">Google BigTable</span><span style="font-family:宋体">的开源实现</span></span><span style="color:rgb(75,75,75)">，其相互对应如下：</span></p>
<p><span style="color:rgb(75,75,75)">Google <span style="font-family:宋体">　　　　　　　　　　 </span><span style="font-family:Verdana">HBase</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">文件存储系统 　　　 <span style="font-family:Verdana"> GFS </span><span style="font-family:宋体">　　　　　　　　　　　 </span><span style="font-family:Verdana"> HDFS</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">海量数据处理 　　　 <span style="font-family:Verdana"> MapReduce Hadoop </span><span style="font-family:Verdana">MapReduce</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">协同服务管理　　　　<span style="font-family:Verdana">Chubby </span><span style="font-family:Verdana">Zookeeper</span></span></p>
<p><span style="color:rgb(75,75,75)"> </span></p>
<p><span style="color:rgb(75,75,75)">HBase<span style="font-family:宋体">关系图：</span></span></p>
<p><span style="color:rgb(75,75,75)"> </span></p>
<p><span style="color:rgb(75,75,75)">HBase<span style="font-family:宋体">位于结构化存储层，围绕</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">，各部件对</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的支持情况：</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Hadoop<span style="font-family:宋体">部件　　　　　　　　　　　　作用</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">HDFS<span style="font-family:宋体">　　　　　　　　　　　　　　高可靠的底层存储支持</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">MapReduce <span style="font-family:Verdana">  </span><span style="font-family:宋体">高性能的计算能力</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Zookeeper <span style="font-family:宋体">　　　　　　　　　　　稳定服务和</span><span style="font-family:Verdana">failover</span><span style="font-family:宋体">机制</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Pig&amp;Hive<span style="font-family:Verdana"> </span><span style="font-family:宋体">高层语言支持，便于数据统计</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Sqoop<span style="font-family:Verdana"> </span><span style="font-family:宋体">提供</span><span style="font-family:Verdana">RDBMS</span><span style="font-family:宋体">数据导入，便于传统数据库向</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">迁移</span></span></p>
<p><span style="color:rgb(75,75,75)">访问<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的接口</span></span></p>
<p><span style="color:rgb(75,75,75)">方式　　　　　　　　　　　　特点　　　　　　　　　　　　　　场合</span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Native Java API<span style="font-family:宋体">　　　　　　最常规和高效 　　　　　　　　　　 </span><span style="font-family:Verdana">Hadoop MapReduce Job</span><span style="font-family:宋体">并行处理</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">表数据</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">HBase Shell<span style="font-family:宋体">　　　　　　　 </span><span style="font-family:Verdana"> </span><span style="font-family:宋体">最简单接口 　　　　　　　　　　　</span><span style="font-family:Verdana"> HBase</span><span style="font-family:宋体">管理使用</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Thrift Gateway<span style="font-family:宋体">　　　　　　利用</span><span style="font-family:Verdana">Thrift</span><span style="font-family:宋体">序列化支持多种语言 　　 </span><span style="font-family:Verdana"> </span><span style="font-family:宋体">异构系统在线访问</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">表数据</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Rest Gateway<span style="font-family:Verdana"> </span><span style="font-family:宋体">解除语言限制 　　　　　　　　　　 </span><span style="font-family:Verdana">Rest</span><span style="font-family:宋体">风格</span><span style="font-family:Verdana">Http API</span><span style="font-family:宋体">访问</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Pig<span style="font-family:Verdana">Pig Latin</span><span style="font-family:宋体">六十编程语言处理数据 　　数据统计</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Hive<span style="font-family:Verdana"> </span><span style="font-family:宋体">简单，</span><span style="font-family:Verdana">SqlLike</span></span></p>
<p><span style="color:rgb(75,75,75)">HBase <span style="font-family:宋体">数据模型</span></span></p>
<p><span style="color:rgb(75,75,75)"> </span></p>
<p><span style="color:rgb(75,75,75)">组成部件说明：</span></p>
<p><span style="color:rgb(75,75,75)">Row Key<span style="font-family:宋体">：　　 　　</span><span style="font-family:Verdana">Table</span><span style="font-family:宋体">主键 行键 </span><span style="font-family:Verdana">Table</span><span style="font-family:宋体">中记录按照</span><span style="font-family:Verdana">Row Key</span><span style="font-family:宋体">排序</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Timestamp<span style="font-family:宋体">：</span><span style="font-family:Verdana">   </span><span style="font-family:宋体">　　每次对数据操作对应的时间戳，也即数据的</span><span style="font-family:Verdana">version number</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Column Family<span style="font-family:宋体">： 　列簇，一个</span><span style="font-family:Verdana">table</span><span style="font-family:宋体">在水平方向有一个或者多个列簇，列簇可由任意多个</span><span style="font-family:Verdana">Column</span><span style="font-family:宋体">组成，列簇支持动态扩展，无须预定义数量及类型，二进制存储，用户需自行进行类型转换</span></span></p>
<p><span style="color:rgb(75,75,75)">Table&amp;Region</span></p>
<p><span style="color:rgb(75,75,75)"> </span></p>
<p><span style="color:rgb(75,75,75)">1. Table<span style="font-family:宋体">随着记录增多不断变大，会自动分裂成多份</span><span style="font-family:Verdana">Splits</span><span style="font-family:宋体">，成为</span><span style="font-family:Verdana">Regions</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">2. <span style="font-family:宋体">一个</span><span style="font-family:Verdana">region</span><span style="font-family:宋体">由</span><span style="font-family:Verdana">[startkey</span><span style="font-family:宋体">，</span><span style="font-family:Verdana">endkey)</span><span style="font-family:宋体">表示</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">3. <span style="font-family:宋体">不同</span><span style="font-family:Verdana">region</span><span style="font-family:宋体">会被</span><span style="font-family:Verdana">Master</span><span style="font-family:宋体">分配给相应的</span><span style="font-family:Verdana">RegionServer</span><span style="font-family:宋体">进行管理</span></span></p>
<p><span style="color:rgb(75,75,75)">两张特殊表：<span style="font-family:Verdana">-ROOT- &amp; .META.</span></span></p>
<p><span style="color:rgb(75,75,75)"> </span></p>
<p><span style="color:rgb(75,75,75)">.META. <span style="font-family:宋体">　　记录用户表的</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">信息，同时，</span><span style="font-family:Verdana">.META.</span><span style="font-family:宋体">也可以有多个</span><span style="font-family:Verdana">region</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">-ROOT- <span style="font-family:Verdana">  </span><span style="font-family:宋体">记录</span><span style="font-family:Verdana">.META.</span><span style="font-family:宋体">表的</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">信息，但是，</span><span style="font-family:Verdana">-ROOT-</span><span style="font-family:宋体">只有一个</span><span style="font-family:Verdana">region</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Zookeeper<span style="font-family:宋体">中记录了</span><span style="font-family:Verdana">-ROOT-</span><span style="font-family:宋体">表的</span><span style="font-family:Verdana">location</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">客户端访问数据的流程：</span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Client -&gt; Zookeeper -&gt; -ROOT- -&gt; .META. -&gt; <span style="font-family:宋体">用户数据表</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">多次网络操作，不过<span style="font-family:Verdana">client</span><span style="font-family:宋体">端有</span><span style="font-family:Verdana">cache</span><span style="font-family:宋体">缓存</span></span></p>
<p><span style="color:rgb(75,75,75)">HBase <span style="font-family:宋体">系统架构图</span></span></p>
<p><span style="color:rgb(75,75,75)"> </span></p>
<p><span style="color:rgb(75,75,75)">组成部件说明</span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Client<span style="font-family:宋体">：</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">使用<span style="font-family:Verdana">HBase RPC</span><span style="font-family:宋体">机制与</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">进行通信</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Client<span style="font-family:宋体">与</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">进行通信进行管理类操作</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Client<span style="font-family:宋体">与</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">进行数据读写类操作</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Zookeeper<span style="font-family:宋体">：</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Zookeeper Quorum<span style="font-family:宋体">存储</span><span style="font-family:Verdana">-ROOT-</span><span style="font-family:宋体">表地址、</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">地址</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">HRegionServer<span style="font-family:宋体">把自己以</span><span style="font-family:Verdana">Ephedral</span><span style="font-family:宋体">方式注册到</span><span style="font-family:Verdana">Zookeeper</span><span style="font-family:宋体">中，</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">随时感知各个</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">的健康状况</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Zookeeper<span style="font-family:宋体">避免</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">单点问题</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">HMaster<span style="font-family:宋体">：</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">HMaster<span style="font-family:宋体">没有单点问题，</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">中可以启动多个</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">，通过</span><span style="font-family:Verdana">Zookeeper</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">Master Election</span><span style="font-family:宋体">机制保证总有一个</span><span style="font-family:Verdana">Master</span><span style="font-family:宋体">在运行</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">主要负责<span style="font-family:Verdana">Table</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">的管理工作：</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">1 <span style="font-family:宋体">管理用户对表的增删改查操作</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">2 <span style="font-family:宋体">管理</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">的负载均衡，调整</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">分布</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">3 Region Split<span style="font-family:宋体">后，负责新</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">的分布</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">4 <span style="font-family:宋体">在</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">停机后，负责失效</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">上</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">迁移</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">HRegionServer<span style="font-family:宋体">：</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">HBase<span style="font-family:宋体">中最核心的模块，主要负责响应用户</span><span style="font-family:Verdana">I/O</span><span style="font-family:宋体">请求，向</span><span style="font-family:Verdana">HDFS</span><span style="font-family:宋体">文件系统中读写数据</span></span></p>
<p><span style="color:rgb(75,75,75)"> </span></p>
<p><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">HRegionServer<span style="font-family:宋体">管理一些列</span><span style="font-family:Verdana">HRegion</span><span style="font-family:宋体">对象；</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">每个<span style="font-family:Verdana">HRegion</span><span style="font-family:宋体">对应</span><span style="font-family:Verdana">Table</span><span style="font-family:宋体">中一个</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">，</span><span style="font-family:Verdana">HRegion</span><span style="font-family:宋体">由多个</span><span style="font-family:Verdana">HStore</span><span style="font-family:宋体">组成；</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">每个<span style="font-family:Verdana">HStore</span><span style="font-family:宋体">对应</span><span style="font-family:Verdana">Table</span><span style="font-family:宋体">中一个</span><span style="font-family:Verdana">Column Family</span><span style="font-family:宋体">的存储；</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Column Family<span style="font-family:宋体">就是一个集中的存储单元，故将具有相同</span><span style="font-family:Verdana">IO</span><span style="font-family:宋体">特性的</span><span style="font-family:Verdana">Column</span><span style="font-family:宋体">放在一个</span><span style="font-family:Verdana">Column Family</span><span style="font-family:宋体">会更高效</span></span></p>
<p><span style="color:rgb(75,75,75)">HStore<span style="font-family:宋体">：</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">HBase<span style="font-family:宋体">存储的核心。由</span><span style="font-family:Verdana">MemStore</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">StoreFile</span><span style="font-family:宋体">组成。</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">MemStore<span style="font-family:宋体">是</span><span style="font-family:Verdana">Sorted Memory Buffer</span><span style="font-family:宋体">。用户写入数据的流程：</span></span></p>
<p><span style="color:rgb(75,75,75)"> </span></p>
<p><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Client<span style="font-family:宋体">写入 </span><span style="font-family:Verdana">-&gt; </span><span style="font-family:宋体">存入</span><span style="font-family:Verdana">MemStore</span><span style="font-family:宋体">，一直到</span><span style="font-family:Verdana">MemStore</span><span style="font-family:宋体">满 </span><span style="font-family:Verdana">-&gt; Flush</span><span style="font-family:宋体">成一个</span><span style="font-family:Verdana">StoreFile</span><span style="font-family:宋体">，直至增长到一定阈值 </span><span style="font-family:Verdana">-&gt; </span><span style="font-family:宋体">出发</span><span style="font-family:Verdana">Compact</span><span style="font-family:宋体">合并操作 </span><span style="font-family:Verdana">-&gt; </span><span style="font-family:宋体">多个</span><span style="font-family:Verdana">StoreFile</span><span style="font-family:宋体">合并成一个</span><span style="font-family:Verdana">StoreFile</span><span style="font-family:宋体">，同时进行版本合并和数据删除 </span><span style="font-family:Verdana">-&gt; </span><span style="font-family:宋体">当</span><span style="font-family:Verdana">StoreFiles Compact</span><span style="font-family:宋体">后，逐步形成越来越大的</span><span style="font-family:Verdana">StoreFile -&gt; </span><span style="font-family:宋体">单个</span><span style="font-family:Verdana">StoreFile</span><span style="font-family:宋体">大小超过一定阈值后，触发</span><span style="font-family:Verdana">Split</span><span style="font-family:宋体">操作，把当前</span><span style="font-family:Verdana">Region Split</span><span style="font-family:宋体">成</span><span style="font-family:Verdana">2</span><span style="font-family:宋体">个</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">，</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">会下线，新</span><span style="font-family:Verdana">Split</span><span style="font-family:宋体">出的</span><span style="font-family:Verdana">2</span><span style="font-family:宋体">个孩子</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">会被</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">分配到相应的</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">上，使得原先</span><span style="font-family:Verdana">1</span><span style="font-family:宋体">个</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">的压力得以分流到</span><span style="font-family:Verdana">2</span><span style="font-family:宋体">个</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">上</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">由此过程可知，<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">只是增加数据，有所得更新和删除操作，都是在</span><span style="font-family:Verdana">Compact</span><span style="font-family:宋体">阶段做的，所以，用户写操作只需要进入到内存即可立即返回，从而保证</span><span style="font-family:Verdana">I/O</span><span style="font-family:宋体">高性能。</span></span></p>
<p><span style="color:rgb(75,75,75)">HLog</span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">引入<span style="font-family:Verdana">HLog</span><span style="font-family:宋体">原因：</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">在分布式系统环境中，无法避免系统出错或者宕机，一旦<span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">以外退出，</span><span style="font-family:Verdana">MemStore</span><span style="font-family:宋体">中的内存数据就会丢失，引入</span><span style="font-family:Verdana">HLog</span><span style="font-family:宋体">就是防止这种情况</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">工作机制：</span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">每个<span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">中都会有一个</span><span style="font-family:Verdana">HLog</span><span style="font-family:宋体">对象，</span><span style="font-family:Verdana">HLog</span><span style="font-family:宋体">是一个实现</span><span style="font-family:Verdana">Write Ahead Log</span><span style="font-family:宋体">的类，每次用户操作写入</span><span style="font-family:Verdana">Memstore</span><span style="font-family:宋体">的同时，也会写一份数据到</span><span style="font-family:Verdana">HLog</span><span style="font-family:宋体">文件，</span><span style="font-family:Verdana">HLog</span><span style="font-family:宋体">文件定期会滚动出新，并删除旧的文件</span><span style="font-family:Verdana">(</span><span style="font-family:宋体">已持久化到</span><span style="font-family:Verdana">StoreFile</span><span style="font-family:宋体">中的数据</span><span style="font-family:Verdana">)</span><span style="font-family:宋体">。当</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">意外终止后，</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">会通过</span><span style="font-family:Verdana">Zookeeper</span><span style="font-family:宋体">感知，</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">首先处理遗留的</span><span style="font-family:Verdana">HLog</span><span style="font-family:宋体">文件，将不同</span><span style="font-family:Verdana">region</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">log</span><span style="font-family:宋体">数据拆分，分别放到相应</span><span style="font-family:Verdana">region</span><span style="font-family:宋体">目录下，然后再将失效的</span><span style="font-family:Verdana">region</span><span style="font-family:宋体">重新分配，领取到这些</span><span style="font-family:Verdana">region</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">在</span><span style="font-family:Verdana">Load Region</span><span style="font-family:宋体">的过程中，会发现有历史</span><span style="font-family:Verdana">HLog</span><span style="font-family:宋体">需要处理，因此会</span><span style="font-family:Verdana">Replay HLog</span><span style="font-family:宋体">中的数据到</span><span style="font-family:Verdana">MemStore</span><span style="font-family:宋体">中，然后</span><span style="font-family:Verdana">flush</span><span style="font-family:宋体">到</span><span style="font-family:Verdana">StoreFiles</span><span style="font-family:宋体">，完成数据恢复。</span></span></p>
<p><span style="color:rgb(75,75,75)">HBase<span style="font-family:宋体">存储格式</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">HBase<span style="font-family:宋体">中的所有数据文件都存储在</span><span style="font-family:Verdana">Hadoop HDFS</span><span style="font-family:宋体">文件系统上，格式主要有两种：</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">1 HFile HBase<span style="font-family:宋体">中</span><span style="font-family:Verdana">KeyValue</span><span style="font-family:宋体">数据的存储格式，</span><span style="font-family:Verdana">HFile</span><span style="font-family:宋体">是</span><span style="font-family:Verdana">Hadoop</span><span style="font-family:宋体">的二进制格式文件，实际上</span><span style="font-family:Verdana">StoreFile</span><span style="font-family:宋体">就是对</span><span style="font-family:Verdana">HFile</span><span style="font-family:宋体">做了轻量级包装，即</span><span style="font-family:Verdana">StoreFile</span><span style="font-family:宋体">底层就是</span><span style="font-family:Verdana">HFile</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">2 HLog File<span style="font-family:宋体">，</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">中</span><span style="font-family:Verdana">WAL</span><span style="font-family:宋体">（</span><span style="font-family:Verdana">Write Ahead Log</span><span style="font-family:宋体">） 的存储格式，物理上是</span><span style="font-family:Verdana">Hadoop</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">Sequence File</span></span></p>
<p><span style="color:rgb(75,75,75)">HFile</span></p>
<p><span style="color:rgb(75,75,75)"> </span></p>
<p><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">图片解释：</span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">HFile<span style="font-family:宋体">文件不定长，长度固定的块只有两个：</span><span style="font-family:Verdana">Trailer</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">FileInfo</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Trailer<span style="font-family:宋体">中指针指向其他数据块的起始点</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">File Info<span style="font-family:宋体">中记录了文件的一些</span><span style="font-family:Verdana">Meta</span><span style="font-family:宋体">信息，例如：</span><span style="font-family:Verdana">AVG_KEY_LEN, AVG_VALUE_LEN, LAST_KEY, COMPARATOR, MAX_SEQ_ID_KEY</span><span style="font-family:宋体">等</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Data Index<span style="font-family:宋体">和</span><span style="font-family:Verdana">Meta Index</span><span style="font-family:宋体">块记录了每个</span><span style="font-family:Verdana">Data</span><span style="font-family:宋体">块和</span><span style="font-family:Verdana">Meta</span><span style="font-family:宋体">块的起始点</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Data Block<span style="font-family:宋体">是</span><span style="font-family:Verdana">HBase I/O</span><span style="font-family:宋体">的基本单元，为了提高效率，</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">中有基于</span><span style="font-family:Verdana">LRU</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">Block Cache</span><span style="font-family:宋体">机制</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">每个<span style="font-family:Verdana">Data</span><span style="font-family:宋体">块的大小可以在创建一个</span><span style="font-family:Verdana">Table</span><span style="font-family:宋体">的时候通过参数指定，大号的</span><span style="font-family:Verdana">Block</span><span style="font-family:宋体">有利于顺序</span><span style="font-family:Verdana">Scan</span><span style="font-family:宋体">，小号</span><span style="font-family:Verdana">Block</span><span style="font-family:宋体">利于随机查询</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">每个<span style="font-family:Verdana">Data</span><span style="font-family:宋体">块除了开头的</span><span style="font-family:Verdana">Magic</span><span style="font-family:宋体">以外就是一个个</span><span style="font-family:Verdana">KeyValue</span><span style="font-family:宋体">对拼接而成</span><span style="font-family:Verdana">, Magic</span><span style="font-family:宋体">内容就是一些随机数字，目的是防止数据损坏</span></span></p>
<p><span style="color:rgb(75,75,75)">HFile<span style="font-family:宋体">里面的每个</span><span style="font-family:Verdana">KeyValue</span><span style="font-family:宋体">对就是一个简单的</span><span style="font-family:Verdana">byte</span><span style="font-family:宋体">数组。这个</span><span style="font-family:Verdana">byte</span><span style="font-family:宋体">数组里面包含了很多项，并且有固定的结构。</span></span></p>
<p><span style="color:rgb(75,75,75)"> </span></p>
<p><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">KeyLength<span style="font-family:宋体">和</span><span style="font-family:Verdana">ValueLength</span><span style="font-family:宋体">：两个固定的长度，分别代表</span><span style="font-family:Verdana">Key</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">Value</span><span style="font-family:宋体">的长度</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Key<span style="font-family:宋体">部分：</span><span style="font-family:Verdana">Row Length</span><span style="font-family:宋体">是固定长度的数值，表示</span><span style="font-family:Verdana">RowKey</span><span style="font-family:宋体">的长度，</span><span style="font-family:Verdana">Row </span><span style="font-family:宋体">就是</span><span style="font-family:Verdana">RowKey</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Column Family Length<span style="font-family:宋体">是固定长度的数值，表示</span><span style="font-family:Verdana">Family</span><span style="font-family:宋体">的长度</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">接着就是<span style="font-family:Verdana">Column Family</span><span style="font-family:宋体">，再接着是</span><span style="font-family:Verdana">Qualifier</span><span style="font-family:宋体">，然后是两个固定长度的数值，表示</span><span style="font-family:Verdana">Time Stamp</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">Key Type</span><span style="font-family:宋体">（</span><span style="font-family:Verdana">Put/Delete</span><span style="font-family:宋体">）</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">Value<span style="font-family:宋体">部分没有这么复杂的结构，就是纯粹的二进制数据</span></span></p>
<p><span style="color:rgb(75,75,75)">HLog File</span></p>
<p><span style="color:rgb(75,75,75)"> </span></p>
<p><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">HLog<span style="font-family:宋体">文件就是一个普通的</span><span style="font-family:Verdana">Hadoop Sequence File</span><span style="font-family:宋体">，</span><span style="font-family:Verdana">Sequence File </span><span style="font-family:宋体">的</span><span style="font-family:Verdana">Key</span><span style="font-family:宋体">是</span><span style="font-family:Verdana">HLogKey</span><span style="font-family:宋体">对象，</span><span style="font-family:Verdana">HLogKey</span><span style="font-family:宋体">中记录了写入数据的归属信息，除了</span><span style="font-family:Verdana">table</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">region</span><span style="font-family:宋体">名字外，同时还包括 </span><span style="font-family:Verdana">sequence number</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">timestamp</span><span style="font-family:宋体">，</span><span style="font-family:Verdana">timestamp</span><span style="font-family:宋体">是</span><span style="font-family:Verdana">“</span><span style="font-family:宋体">写入时间</span><span style="font-family:Verdana">”</span><span style="font-family:宋体">，</span><span style="font-family:Verdana">sequence number</span><span style="font-family:宋体">的起始值为</span><span style="font-family:Verdana">0</span><span style="font-family:宋体">，或者是最近一次存入文件系统中</span><span style="font-family:Verdana">sequence number</span><span style="font-family:宋体">。</span></span><span style="color:rgb(75,75,75)"><br>
</span><span style="color:rgb(75,75,75)">HLog Sequece File<span style="font-family:宋体">的</span><span style="font-family:Verdana">Value</span><span style="font-family:宋体">是</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">KeyValue</span><span style="font-family:宋体">对象，即对应</span><span style="font-family:Verdana">HFile</span><span style="font-family:宋体">中的</span><span style="font-family:Verdana">KeyValue</span></span></p>
<p> </p>
<p> </p>
<p>十六、 HBase Java客户端编程</p>
<p> </p>
<p>本文以HBase 0.90.2为例，介绍如何在Windows系统，Eclipse IDE集成环境下，使用Java语言，进行HBase客户端编程，包含建立表、删除表、插入记录、删除记录、各种方式下的查询操作等。 </p>
<h1>1. 准备工作</h1>
<p>1、下载后安装jdk包（这里使用的是jdk-6u10-rc2-bin-b32-windows-i586-p-12_sep_2008）；</p>
<p>2、下载eclipse，解压到本地（这里使用的是eclipse-java-helios-SR2-win32）；</p>
<p>3、下载HBase包，解压安装包到本地（这里使用的是hbase-0.90.2）。</p>
<h1>2. 搭建开发环境</h1>
<p>1、运行Eclipse，创建一个新的Java工程“HBaseClient”，右键项目根目录，选择“Properties”-&gt;“Java Build Path”-&gt;“Library”-&gt;“Add External JARs”，将HBase解压后根目录下的hbase-0.90.2.jar、hbase-0.90.2-tests.jar和lib子目录下所有jar包添加到本工程的Classpath下，如图1所示。</p>
<p></p>
<p>图1 Eclilse IDE下添加HBase的Jar包</p>
<p>2、按照步骤1中的操作，将自己所连接的HBase的配置文件hbase-site.xml添加到本工程的Classpath中，如下所示为配置文件的一个示例。</p>
<table>
<tbody>
<tr>
<td valign="center">
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
</td>
<td valign="center">
<p>&lt;configuration&gt; </p>
<p>&lt;property&gt; </p>
<p>&lt;name&gt;hbase.rootdir&lt;/name&gt; </p>
<p>&lt;value&gt;<a target="_blank" href="" rel="nofollow">hdfs://hostname:9000/hbase</a>&lt;/value&gt; </p>
<p>&lt;/property&gt; </p>
<p>&lt;property&gt; </p>
<p>&lt;name&gt;hbase.cluster.distributed&lt;/name&gt; </p>
<p>&lt;value&gt;true&lt;/value&gt; </p>
<p>&lt;/property&gt; </p>
<p>&lt;property&gt; </p>
<p>&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; </p>
<p>&lt;value&gt;*.*.*.*, *.*.*.*, *.*.*.*&lt;/value&gt; </p>
<p>&lt;/property&gt; </p>
<p>&lt;property skipInDoc="true"&gt; </p>
<p>&lt;name&gt;hbase.defaults.for.version&lt;/name&gt; </p>
<p>&lt;value&gt;0.90.2&lt;/value&gt; </p>
<p>&lt;/property&gt; </p>
<p>&lt;/configuration&gt;</p>
</td>
</tr>
</tbody>
</table>
<p>3、下面可以在Eclipse环境下进行HBase编程了。</p>
<h1>3. HBase基本操作代码示例</h1>
<h2>3.1 初始化配置</h2>
<table>
<tbody>
<tr>
<td valign="center">
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
</td>
<td valign="center">
<p>private static Configuration conf = null; </p>
<p>/** </p>
<p> * 初始化配置 </p>
<p> */</p>
<p>static { </p>
<p>    conf = HBaseConfiguration.create(); </p>
<p>}</p>
</td>
</tr>
</tbody>
</table>
<h2>3.2 创建表</h2>
<table>
<tbody>
<tr>
<td valign="center">
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
</td>
<td valign="center">
<p>/** </p>
<p> * 创建表操作 </p>
<p> * @throws IOException </p>
<p> */</p>
<p>public void createTable(String tablename, String[] cfs) throws IOException { </p>
<p>    HBaseAdmin admin = new HBaseAdmin(conf); </p>
<p>    if (admin.tableExists(tablename)) { </p>
<p>        System.out.println("表已经存在！"); </p>
<p>    } </p>
<p>    else { </p>
<p>        HTableDescriptor tableDesc = new HTableDescriptor(tablename); </p>
<p>        for (int i = 0; i &lt; cfs.length; i++) { </p>
<p>            tableDesc.addFamily(new HColumnDescriptor(cfs[i])); </p>
<p>        } </p>
<p>        admin.createTable(tableDesc); </p>
<p>        System.out.println("表创建成功！"); </p>
<p>    } </p>
<p>}</p>
</td>
</tr>
</tbody>
</table>
<h2>3.3 删除表</h2>
<table>
<tbody>
<tr>
<td valign="center">
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
</td>
<td valign="center">
<p>/** </p>
<p> * 删除表操作 </p>
<p> * @param tablename </p>
<p> * @throws IOException </p>
<p> */</p>
<p>public void deleteTable(String tablename) throws IOException { </p>
<p>    try { </p>
<p>        HBaseAdmin admin = new HBaseAdmin(conf); </p>
<p>        admin.disableTable(tablename); </p>
<p>        admin.deleteTable(tablename); </p>
<p>        System.out.println("表删除成功！"); </p>
<p>    } catch (MasterNotRunningException e) { </p>
<p>        e.printStackTrace(); </p>
<p>    } catch (ZooKeeperConnectionException e) { </p>
<p>        e.printStackTrace(); </p>
<p>    } </p>
<p>}</p>
</td>
</tr>
</tbody>
</table>
<h2>3.4 插入一行记录</h2>
<table>
<tbody>
<tr>
<td valign="center">
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
<p>19</p>
</td>
<td valign="center">
<p>/** </p>
<p> * 插入一行记录 </p>
<p> * @param tablename </p>
<p> * @param cfs </p>
<p> */</p>
<p>public void writeRow(String tablename, String[] cfs) { </p>
<p>    try { </p>
<p>        HTable table = new HTable(conf, tablename); </p>
<p>        Put put = new Put(Bytes.toBytes("rows1")); </p>
<p>        for (int j = 0; j &lt; cfs.length; j++) { </p>
<p>            put.add(Bytes.toBytes(cfs[j]), </p>
<p>                    Bytes.toBytes(String.valueOf(1)), </p>
<p>                    Bytes.toBytes("value_1")); </p>
<p>            table.put(put); </p>
<p>        } </p>
<p>    } catch (IOException e) { </p>
<p>        e.printStackTrace(); </p>
<p>    } </p>
<p>}</p>
</td>
</tr>
</tbody>
</table>
<h2>3.5 删除一行记录</h2>
<table>
<tbody>
<tr>
<td valign="center">
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
</td>
<td valign="center">
<p>/** </p>
<p> * 删除一行记录 </p>
<p> * @param tablename </p>
<p> * @param rowkey </p>
<p> * @throws IOException </p>
<p> */</p>
<p>public void deleteRow(String tablename, String rowkey) throws IOException { </p>
<p>    HTable table = new HTable(conf, tablename); </p>
<p>    List list = new ArrayList(); </p>
<p>    Delete d1 = new Delete(rowkey.getBytes()); </p>
<p>    list.add(d1); </p>
<p>    table.delete(list); </p>
<p>    System.out.println("删除行成功！"); </p>
<p>}</p>
</td>
</tr>
</tbody>
</table>
<h2>3.6 查找一行记录</h2>
<table>
<tbody>
<tr>
<td valign="center">
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
</td>
<td valign="center">
<p>/** </p>
<p> * 查找一行记录 </p>
<p> * @param tablename </p>
<p> * @param rowkey </p>
<p> */</p>
<p>public static void selectRow(String tablename, String rowKey) </p>
<p>        throws IOException { </p>
<p>    HTable table = new HTable(conf, tablename); </p>
<p>    Get g = new Get(rowKey.getBytes()); </p>
<p>    Result rs = table.get(g); </p>
<p>    for (KeyValue kv : rs.raw()) { </p>
<p>        System.out.print(new String(kv.getRow()) + "  "); </p>
<p>        System.out.print(new String(kv.getFamily()) + ":"); </p>
<p>        System.out.print(new String(kv.getQualifier()) + "  "); </p>
<p>        System.out.print(kv.getTimestamp() + "  "); </p>
<p>        System.out.println(new String(kv.getValue())); </p>
<p>    } </p>
<p>}</p>
</td>
</tr>
</tbody>
</table>
<h2>3.7 查询表中所有行</h2>
<table>
<tbody>
<tr>
<td valign="center">
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
<p>19</p>
<p>20</p>
<p>21</p>
<p>22</p>
<p>23</p>
</td>
<td valign="center">
<p>/** </p>
<p> * 查询表中所有行 </p>
<p> * @param tablename </p>
<p> */</p>
<p>public void scaner(String tablename) { </p>
<p>    try { </p>
<p>        HTable table = new HTable(conf, tablename); </p>
<p>        Scan s = new Scan(); </p>
<p>        ResultScanner rs = table.getScanner(s); </p>
<p>        for (Result r : rs) { </p>
<p>            KeyValue[] kv = r.raw(); </p>
<p>            for (int i = 0; i &lt; kv.length; i++) { </p>
<p>                System.out.print(new String(kv[i].getRow()) + "  "); </p>
<p>                System.out.print(new String(kv[i].getFamily()) + ":"); </p>
<p>                System.out.print(new String(kv[i].getQualifier()) + "  "); </p>
<p>                System.out.print(kv[i].getTimestamp() + "  "); </p>
<p>                System.out.println(new String(kv[i].getValue())); </p>
<p>            } </p>
<p>        } </p>
<p>    } catch (IOException e) { </p>
<p>        e.printStackTrace(); </p>
<p>    } </p>
<p>}</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p> </p>
<p>十七、 HBase如何合理设置客户端Write Buffer</p>
<p>HBase客户端API提供了Write Buffer的方式，即批量提交一批Put对象到HBase服务端。本文将结合HBase相关源码，对其进行深入介绍，分析如何在实际项目中合理设置和使用它。</p>
<p>什么时候需要Write Buffer？</p>
<p>默认情况下，一次Put操作即要与Region Server执行一次RPC操作，其执行过程可以被拆分为以下三个部分：</p>
<p>· T1：RTT(Round-Trip Time)，即网络往返时延，它指从客户端发送数据开始，到客户端收到来自服务端的确认，总共经历的时延，不包括数据传输的时间；</p>
<p>· T2：数据传输时间，即Put所操作的数据在客户端与服务端之间传输所消耗的时间开销，当数据量大的时候，T2的开销不容忽略；</p>
<p>· T3：服务端处理时间，对于Put操作，即写入WAL日志（如果设置了WAL标识为true）、更新MemStore等。</p>
<p>其中，T2和T3都是不可避免的时间开销，那么能不能减少T1呢？假设我们将多次Put操作打包起来一次性提交到服务端，则可以将T1部分的总时间从T1 * N降低为T1，其中T1为一次RTT时间，N为Put的记录条数。</p>
<p>正是出于上述考虑，HBase为用户提供了客户端缓存批量提交的方式（即Write Buffer）。假设RTT的时间较长，如1ms，则该种方式能够显著提高整个集群的写入性能。</p>
<p>那么，什么场景下适用于该种模式呢？下面简单分析一下：</p>
<p>· 如果Put提交的是小数据（如KB级别甚至更小）记录，那么T2很小，因此，通过该种模式减少T1的开销，能够明显提高写入性能。</p>
<p>· 如果Put提交的是大数据（如MB级别）记录，那么T2可能已经远大于T1，此时T1与T2相比可以被忽略，因此，使用该种模式并不能得到很好的性能提升，不建议通过增大Write Buffer大小来使用该种模式。</p>
<p>如何配置使用Write Buffer？</p>
<p>如果要启动Write Buffer模式，则调用HTable的以下API将auto flush设置为false：</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>void setAutoFlush(boolean autoFlush)</p>
</td>
</tr>
</tbody>
</table>
<p>默认配置下，Write Buffer大小为2MB，可以根据应用实际情况，通过以下任意方式进行自定义：</p>
<p>1）  调用HTable接口设置，仅对该HTable对象起作用：</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>void setWriteBufferSize(long writeBufferSize) throws IOException</p>
</td>
</tr>
</tbody>
</table>
<p>2）  在hbase-site.xml中配置，所有HTable都生效（下面设置为5MB）：</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>&lt;property&gt;</p>
<p>&lt;name&gt;hbase.client.write.buffer&lt;/name&gt;</p>
<p>&lt;value&gt;5242880&lt;/value&gt;</p>
<p>&lt;/property&gt;</p>
</td>
</tr>
</tbody>
</table>
<p>该种模式下向服务端提交的时机分为显式和隐式两种情况：</p>
<p>1）  显式提交：用户调用flushCommits()进行提交；</p>
<p>2）  隐式提交：当Write Buffer满了，客户端会自动执行提交；或者调用了HTable的close()方法时无条件执行提交操作。</p>
<p>如何确定每次flushCommits()时实际的RPC次数？</p>
<p>客户端提交后，所有的Put操作可能涉及不同的行，然后客户端负责将这些Put对象根据row key按照 region server分组，再按region server打包后提交到region server，每个region server做一次RPC请求。如下图所示：</p>
<p> </p>
<p>如何确定每次flushCommits()时提交的记录条数？</p>
<p>下面我们先从HBase存储原理层面“粗略”分析下HBase中的一条Put记录格式：</p>
<p>HBase中Put对象的大小主要由若干个KeyValue对的大小决定（Put继承自org/apache/hadoop/hbase/client/Mutation.java，具体见Mutation的代码所示），而KeyValue类中自带的字段占用约50~60 bytes（参考源码：org/apache/hadoop/hbase/KeyValue.java），那么客户端Put一行数据时，假设column qualifier个数为N，row key长度为L1 bytes，value总长度为L2 bytes，则该Put对象占用大小可按以下公式预估：</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>Put Size = ((50~60) + L1) * N + L2) bytes</p>
</td>
</tr>
</tbody>
</table>
<p>下面我们通过对HBase的源码分析来进一步验证以上理论估算值：</p>
<p>HBase客户端执行put操作后，会调用put.heapSize()累加当前客户端buffer中的数据，满足以下条件则调用flushCommits()将客户端数据提交到服务端：</p>
<p>1）每次put方法调用时可能传入的是一个List&lt;Put&gt;，此时每隔DOPUT_WB_CHECK条（默认为10条），检查当前缓存数据是否超过writeBufferSize，超过则强制执行刷新；</p>
<p>2）autoFlush被设置为true，此次put方法调用后执行一次刷新；</p>
<p>3）autoFlush被设置为false，但当前缓存数据已超过设定的writeBufferSize，则执行刷新。</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>         private void doPut(final List&lt;Put&gt; puts) throws IOException {</p>
<p>                   int n = 0;</p>
<p>                   for (Put put : puts) {</p>
<p>                            validatePut(put);</p>
<p>                            writeBuffer.add(put);</p>
<p>                            currentWriteBufferSize += put.heapSize();</p>
<p>                            // we need to periodically see if the writebuffer is full instead</p>
<p>                            // of waiting until the end of the List</p>
<p>                            n++;</p>
<p>                            if (n % DOPUT_WB_CHECK == 0</p>
<p>                                               &amp;&amp; currentWriteBufferSize &gt; writeBufferSize) {</p>
<p>                                     flushCommits();</p>
<p>                            }</p>
<p>                   }</p>
<p>                   if (autoFlush || currentWriteBufferSize &gt; writeBufferSize) {</p>
<p>                            flushCommits();</p>
<p>                   }</p>
<p>         }</p>
</td>
</tr>
</tbody>
</table>
<p>由上述代码可见，通过put.heapSize()累加客户端的缓存数据，作为判断的依据；那么，我们可以编写一个简单的程序生成Put对象，调用其heapSize()方法，就能得到一行数据实际占用的客户端缓存大小（该程序需要传递上述三个变量：N，L1，L2作为参数）：</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>import org.apache.hadoop.hbase.client.Put;</p>
<p>import org.apache.hadoop.hbase.util.Bytes;</p>
<p>public class PutHeapSize {</p>
<p>         /**</p>
<p>          * @param args</p>
<p>          */</p>
<p>         public static void main(String[] args) {</p>
<p>                   if (args.length != 3) {</p>
<p>                            System.out.println(“Invalid number of parameters: 3 parameters!”);</p>
<p>                            System.exit(1);</p>
<p>                   }</p>
<p>                   int N = Integer.parseInt(args[0]);</p>
<p>                   int L1 = Integer.parseInt(args[1]);</p>
<p>                   int L2 = Integer.parseInt(args[2]);</p>
<p>                   byte[] rowKey = new byte[L1];</p>
<p>                   byte[] value = null;</p>
<p>                   Put put = new Put(rowKey);</p>
<p>                   for (int i = 0; i &lt; N; i++) {</p>
<p>                            put.add(Bytes.toBytes(“cf”), Bytes.toBytes(“c” + i), value);</p>
<p>                   }</p>
<p>                   System.out.println(“Put Size: ” + (put.heapSize() + L2) + ” bytes”);</p>
<p>         }</p>
<p>}</p>
</td>
</tr>
</tbody>
</table>
<p>该程序可以用来预估当前设置的Write Buffer可以一次性批量提交的记录数：</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>Puts Per Commit = Write Buffer Size / Put Size</p>
</td>
</tr>
</tbody>
</table>
<p>更进一步地，如果知道业务中的每秒产生的数据量，就可知道客户端大概多长时间会隐式调用flushCommits()向服务端提交一次，同时也可反过来根据数据实时刷新频率调整Write Buffer大小。</p>
<p>Write Buffer有什么潜在的问题？</p>
<p>首先，Write Buffer存在于客户端的本地内存中，那么当客户端运行出现问题时，会导致在Write Buffer中未提交的数据丢失；由于HBase服务端还未收到这些数据，因此也无法通过WAL日志等方式进行数据恢复。</p>
<p>其次，Write Buffer方式本身会占用客户端和HBase服务端的内存开销，具体见下节的详细分析。</p>
<p>如何预估Write Buffer占用的内存？</p>
<p>客户端通过Write Buffer方式提交的话，会导致客户端和服务端均有一定的额外内存开销，Write Buffer Size越大，则占用的内存越大。客户端占用的内存开销可以粗略地使用以下公式预估：</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>hbase.client.write.buffer * number of HTable object for writing</p>
</td>
</tr>
</tbody>
</table>
<p>而对于服务端来说，可以使用以下公式预估占用的Region Server总内存开销：</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>hbase.client.write.buffer * hbase.regionserver.handler.count * number of region server</p>
</td>
</tr>
</tbody>
</table>
<p>其中，hbase.regionserver.handler.count为每个Region Server上配置的RPC Handler线程数。</p>
<p>十八、 HBase Block Cache实现机制分析</p>
<p> </p>
<h1> 1. 概述</h1>
<p>HBase上Regionserver的内存分为两个部分，一部分作为Memstore，主要用来写；另外一部分作为BlockCache，主要用于读。</p>
<p>· 写请求会先写入Memstore，Regionserver会给每个region提供一个Memstore，当Memstore满64MB以后，会启动 flush刷新到磁盘。当Memstore的总大小超过限制时（heapsize * hbase.regionserver.global.memstore.upperLimit * 0.9），会强行启动flush进程，从最大的Memstore开始flush直到低于限制。</p>
<p>· 读请求先到Memstore中查数据，查不到就到BlockCache中查，再查不到就会到磁盘上读，并把读的结果放入BlockCache。由于BlockCache采用的是LRU策略，因此BlockCache达到上限(heapsize * hfile.block.cache.size * 0.85)后，会启动淘汰机制，淘汰掉最老的一批数据。</p>
<p>一个Regionserver上有一个BlockCache和N个Memstore，它们的大小之和不能大于等于heapsize * 0.8，否则HBase不能正常启动。</p>
<p>默认配置下，BlockCache为0.2，而Memstore为0.4。在注重读响应时间的应用场景下，可以将 BlockCache设置大些，Memstore设置小些，以加大缓存的命中率。</p>
<p>HBase RegionServer包含三个级别的Block优先级队列：</p>
<p>· Single：如果一个Block第一次被访问，则放在这一优先级队列中；</p>
<p>· Multi：如果一个Block被多次访问，则从Single队列移到Multi队列中；</p>
<p>· InMemory：如果一个Block是inMemory的，则放到这个队列中。</p>
<p>以上将Cache分级思想的好处在于：</p>
<p>· 首先，通过inMemory类型Cache，可以有选择地将in-memory的column families放到RegionServer内存中，例如Meta元数据信息；</p>
<p>· 通过区分Single和Multi类型Cache，可以防止由于Scan操作带来的Cache频繁颠簸，将最少使用的Block加入到淘汰算法中。</p>
<p>默认配置下，对于整个BlockCache的内存，又按照以下百分比分配给Single、Multi、InMemory使用：0.25、0.50和0.25。</p>
<p>注意，其中InMemory队列用于保存HBase Meta表元数据信息，因此如果将数据量很大的用户表设置为InMemory的话，可能会导致Meta表缓存失效，进而对整个集群的性能产生影响。</p>
<p>2. 源码分析</p>
<p>下面是对HBase 0.94.1中相关源码（org.apache.hadoop.hbase.io.hfile.LruBlockCache）的分析过程。</p>
<p>2.1加入Block Cache</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>  /** Concurrent map (the cache) */</p>
<p>  private final ConcurrentHashMap&lt;BlockCacheKey,CachedBlock&gt; map;</p>
<p>  /**</p>
<p>   * Cache the block with the specified name and buffer.</p>
<p>   * &lt;p&gt;</p>
<p>   * It is assumed this will NEVER be called on an already cached block.  If</p>
<p>   * that is done, an exception will be thrown.</p>
<p>   * @param cacheKey block’s cache key</p>
<p>   * @param buf block buffer</p>
<p>   * @param inMemory if block is in-memory</p>
<p>   */</p>
<p>  public void cacheBlock(BlockCacheKey cacheKey, Cacheable buf, boolean inMemory) {</p>
<p>    CachedBlock cb = map.get(cacheKey);</p>
<p>    if(cb != null) {</p>
<p>      throw new RuntimeException(“Cached an already cached block”);</p>
<p>    }</p>
<p>    cb = new CachedBlock(cacheKey, buf, count.incrementAndGet(), inMemory);</p>
<p>    long newSize = updateSizeMetrics(cb, false);</p>
<p>    map.put(cacheKey, cb);</p>
<p>    elements.incrementAndGet();</p>
<p>    if(newSize &gt; acceptableSize() &amp;&amp; !evictionInProgress) {</p>
<p>      runEviction();</p>
<p>    }</p>
<p>  }</p>
<p>  /**</p>
<p>   * Cache the block with the specified name and buffer.</p>
<p>   * &lt;p&gt;</p>
<p>   * It is assumed this will NEVER be called on an already cached block.  If</p>
<p>   * that is done, it is assumed that you are reinserting the same exact</p>
<p>   * block due to a race condition and will update the buffer but not modify</p>
<p>   * the size of the cache.</p>
<p>   * @param cacheKey block’s cache key</p>
<p>   * @param buf block buffer</p>
<p>   */</p>
<p>  public void cacheBlock(BlockCacheKey cacheKey, Cacheable buf) {</p>
<p>    cacheBlock(cacheKey, buf, false);</p>
<p>  }</p>
</td>
</tr>
</tbody>
</table>
<p>1）  这里假设不会对同一个已经被缓存的BlockCacheKey重复放入cache操作；</p>
<p>2）  根据inMemory标志创建不同类别的CachedBlock对象：若inMemory为true则创建BlockPriority.MEMORY类型，否则创建BlockPriority.SINGLE；注意，这里只有这两种类型的Cache，因为BlockPriority.MULTI在Cache Block被重复访问时才进行创建，见CachedBlock的access方法代码：</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>  /**</p>
<p>   * Block has been accessed.  Update its local access time.</p>
<p>   */</p>
<p>  public void access(long accessTime) {</p>
<p>    this.accessTime = accessTime;</p>
<p>    if(this.priority == BlockPriority.SINGLE) {</p>
<p>      this.priority = BlockPriority.MULTI;</p>
<p>    }</p>
<p>  }</p>
</td>
</tr>
</tbody>
</table>
<p>3）  将BlockCacheKey和创建的CachedBlock对象加入到全局的ConcurrentHashMap map中，同时做一些更新计数操作；</p>
<p>4）  最后判断如果加入后的Block Size大于设定的临界值且当前没有淘汰线程运行，则调用runEviction()方法启动LRU淘汰过程：</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>  /** Eviction thread */</p>
<p>  private final EvictionThread evictionThread;</p>
<p>  /**</p>
<p>   * Multi-threaded call to run the eviction process.</p>
<p>   */</p>
<p>  private void runEviction() {</p>
<p>    if(evictionThread == null) {</p>
<p>      evict();</p>
<p>    } else {</p>
<p>      evictionThread.evict();</p>
<p>    }</p>
<p>  }</p>
</td>
</tr>
</tbody>
</table>
<p>其中，EvictionThread线程即是LRU淘汰的具体实现线程。下面将给出详细分析。</p>
<p>2.2淘汰Block Cache</p>
<p>EvictionThread线程主要用于与主线程的同步，从而完成Block Cache的LRU淘汰过程。</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>  /*</p>
<p>   * Eviction thread.  Sits in waiting state until an eviction is triggered</p>
<p>   * when the cache size grows above the acceptable level.&lt;p&gt;</p>
<p>   *</p>
<p>   * Thread is triggered into action by {@link LruBlockCache#runEviction()}</p>
<p>   */</p>
<p>  private static class EvictionThread extends HasThread {</p>
<p>    private WeakReference&lt;LruBlockCache&gt; cache;</p>
<p>    private boolean go = true;</p>
<p>    public EvictionThread(LruBlockCache cache) {</p>
<p>      super(Thread.currentThread().getName() + “.LruBlockCache.EvictionThread”);</p>
<p>      setDaemon(true);</p>
<p>      this.cache = new WeakReference&lt;LruBlockCache&gt;(cache);</p>
<p>    }</p>
<p>    @Override</p>
<p>    public void run() {</p>
<p>      while (this.go) {</p>
<p>        synchronized(this) {</p>
<p>          try {</p>
<p>            this.wait();</p>
<p>          } catch(InterruptedException e) {}</p>
<p>        }</p>
<p>        LruBlockCache cache = this.cache.get();</p>
<p>        if(cache == null) break;</p>
<p>        cache.evict();</p>
<p>      }</p>
<p>    }</p>
<p>    public void evict() {</p>
<p>      synchronized(this) {</p>
<p>        this.notify(); // FindBugs NN_NAKED_NOTIFY</p>
<p>      }</p>
<p>    }</p>
<p>    void shutdown() {</p>
<p>      this.go = false;</p>
<p>      interrupt();</p>
<p>    }</p>
<p>  }</p>
</td>
</tr>
</tbody>
</table>
<p>EvictionThread线程启动后，调用wait被阻塞住，直到EvictionThread线程的evict方法被主线程调用时执行notify（见上面的代码分析过程，通过主线程的runEviction方法触发调用），开始执行LruBlockCache的evict方法进行真正的淘汰过程，代码如下：</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>  /**</p>
<p>   * Eviction method.</p>
<p>   */</p>
<p>  void evict() {</p>
<p>    // Ensure only one eviction at a time</p>
<p>    if(!evictionLock.tryLock()) return;</p>
<p>    try {</p>
<p>      evictionInProgress = true;</p>
<p>      long currentSize = this.size.get();</p>
<p>      long bytesToFree = currentSize – minSize();</p>
<p>      if (LOG.isDebugEnabled()) {</p>
<p>        LOG.debug(“Block cache LRU eviction started; Attempting to free ” +</p>
<p>          StringUtils.byteDesc(bytesToFree) + ” of total=” +</p>
<p>          StringUtils.byteDesc(currentSize));</p>
<p>      }</p>
<p>      if(bytesToFree &lt;= 0) return;</p>
<p>      // Instantiate priority buckets</p>
<p>      BlockBucket bucketSingle = new BlockBucket(bytesToFree, blockSize,</p>
<p>          singleSize());</p>
<p>      BlockBucket bucketMulti = new BlockBucket(bytesToFree, blockSize,</p>
<p>          multiSize());</p>
<p>      BlockBucket bucketMemory = new BlockBucket(bytesToFree, blockSize,</p>
<p>          memorySize());</p>
<p>      // Scan entire map putting into appropriate buckets</p>
<p>      for(CachedBlock cachedBlock : map.values()) {</p>
<p>        switch(cachedBlock.getPriority()) {</p>
<p>          case SINGLE: {</p>
<p>            bucketSingle.add(cachedBlock);</p>
<p>            break;</p>
<p>          }</p>
<p>          case MULTI: {</p>
<p>            bucketMulti.add(cachedBlock);</p>
<p>            break;</p>
<p>          }</p>
<p>          case MEMORY: {</p>
<p>            bucketMemory.add(cachedBlock);</p>
<p>            break;</p>
<p>          }</p>
<p>        }</p>
<p>      }</p>
<p>      PriorityQueue&lt;BlockBucket&gt; bucketQueue =</p>
<p>        new PriorityQueue&lt;BlockBucket&gt;(3);</p>
<p>      bucketQueue.add(bucketSingle);</p>
<p>      bucketQueue.add(bucketMulti);</p>
<p>      bucketQueue.add(bucketMemory);</p>
<p>      int remainingBuckets = 3;</p>
<p>      long bytesFreed = 0;</p>
<p>      BlockBucket bucket;</p>
<p>      while((bucket = bucketQueue.poll()) != null) {</p>
<p>        long overflow = bucket.overflow();</p>
<p>        if(overflow &gt; 0) {</p>
<p>          long bucketBytesToFree = Math.min(overflow,</p>
<p>            (bytesToFree – bytesFreed) / remainingBuckets);</p>
<p>          bytesFreed += bucket.free(bucketBytesToFree);</p>
<p>        }</p>
<p>        remainingBuckets–;</p>
<p>      }</p>
<p>      if (LOG.isDebugEnabled()) {</p>
<p>        long single = bucketSingle.totalSize();</p>
<p>        long multi = bucketMulti.totalSize();</p>
<p>        long memory = bucketMemory.totalSize();</p>
<p>        LOG.debug(“Block cache LRU eviction completed; ” +</p>
<p>          “freed=” + StringUtils.byteDesc(bytesFreed) + “, ” +</p>
<p>          “total=” + StringUtils.byteDesc(this.size.get()) + “, ” +</p>
<p>          “single=” + StringUtils.byteDesc(single) + “, ” +</p>
<p>          “multi=” + StringUtils.byteDesc(multi) + “, ” +</p>
<p>          “memory=” + StringUtils.byteDesc(memory));</p>
<p>      }</p>
<p>    } finally {</p>
<p>      stats.evict();</p>
<p>      evictionInProgress = false;</p>
<p>      evictionLock.unlock();</p>
<p>    }</p>
<p>  }</p>
</td>
</tr>
</tbody>
</table>
<p>1）首先获取锁，保证同一时刻只有一个淘汰线程运行；</p>
<p>2）计算得到当前Block Cache总大小currentSize及需要被淘汰释放掉的大小bytesToFree，如果bytesToFree小于等于0则不进行后续操作；</p>
<p>3） 初始化创建三个BlockBucket队列，分别用于存放Single、Multi和InMemory类Block Cache，其中每个BlockBucket维护了一个CachedBlockQueue，按LRU淘汰算法维护该BlockBucket中的所有CachedBlock对象；</p>
<p>4） 遍历记录所有Block Cache的全局ConcurrentHashMap，加入到相应的BlockBucket队列中；</p>
<p>5） 将以上三个BlockBucket队列加入到一个优先级队列中，按照各个BlockBucket超出bucketSize的大小顺序排序（见BlockBucket的compareTo方法）；</p>
<p>6） 遍历优先级队列，对于每个BlockBucket，通过Math.min(overflow, (bytesToFree – bytesFreed) / remainingBuckets)计算出需要释放的空间大小，这样做可以保证尽可能平均地从三个BlockBucket中释放指定的空间；具体实现过程详见BlockBucket的free方法，从其CachedBlockQueue中取出即将被淘汰掉的CachedBlock对象：</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>    public long free(long toFree) {</p>
<p>      CachedBlock cb;</p>
<p>      long freedBytes = 0;</p>
<p>      while ((cb = queue.pollLast()) != null) {</p>
<p>        freedBytes += evictBlock(cb);</p>
<p>        if (freedBytes &gt;= toFree) {</p>
<p>          return freedBytes;</p>
<p>        }</p>
<p>      }</p>
<p>      return freedBytes;</p>
<p>    }</p>
</td>
</tr>
</tbody>
</table>
<p>7） 进一步调用了LruBlockCache的evictBlock方法，从全局ConcurrentHashMap中移除该CachedBlock对象，同时更新相关计数：</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>  protected long evictBlock(CachedBlock block) {</p>
<p>    map.remove(block.getCacheKey());</p>
<p>    updateSizeMetrics(block, true);</p>
<p>    elements.decrementAndGet();</p>
<p>    stats.evicted();</p>
<p>    return block.heapSize();</p>
<p>  }</p>
</td>
</tr>
</tbody>
</table>
<p>8） 释放锁，完成善后工作。</p>
<p>3. 总结</p>
<p>以上关于Block Cache的实现机制，核心思想是将Cache分级，这样的好处是避免Cache之间相互影响，尤其是对HBase来说像Meta表这样的Cache应该保证高优先级。</p>
<p> </p>
<p>十九、 HBase解决Region Server Compact过程占用大量网络出口带宽的问题</p>
<p> </p>
<p>HBase 0.92版本之后，Region Server的Compact过程根据待合并的文件大小分为small compaction和large compaction两种，由此可能导致在集群写入量大的时候Compact占用过多的网络出口带宽。本文将详细描述集群使用过程中遇到这一问题的排查过程及其解决方法。</p>
<h1>1. 发现问题</h1>
<p>HBase集群（版本为0.94.0）运行过程中，发现5台Region Server的网络出口带宽经常维持在100MB/s以上，接近到网卡的极限；同时Region Server的机器load负载也很高，高峰时候能够达到30~50。</p>
<h1>2. 排查问题</h1>
<p>1、集群实际运行过程中，观察到Region Server服务端的网卡，平均每台写入流量大概60MB/s（此时写入量已经很大了）；读出流量90MB/s，有时甚至突破100MB/s（注：每台机器都是千兆网卡）；</p>
<p>2、观察实际的写入数据量在每秒5w tps左右，单条记录平均大小为1KB，大概会占用50MB/s左右的网卡入口带宽请求量，和观察到的现象一致；</p>
<p>3、观察查询量在每秒6w qps左右，单条记录平均大小为1KB，大概会占用60MB/s左右的网卡出口带宽请求量，奇怪的是实际观察到有接近甚至超过100MB/s的网络出口带宽请求量，多出了40MB/s左右的网络出口带宽；</p>
<p>4、经分析排查确定导致上述过程的原因，可能是HBase服务端由于写入量过大频繁触发compaction过程，而compaction是需要读HBase数据的，因此占据了相当部分的网络出口带宽；</p>
<p>5、结合对相关源码org/apache/hadoop/hbase/regionserver/CompactSplitThread.java的分析，决定对HBase集群配置做出变更（具体见下一小节），主要目的是减少compaction的发生；</p>
<p>6、接下来，观察到Region Server的网络利用率明显降低，一般进出口带宽能维持在70MB/s以下。</p>
<h1>3. 解决问题</h1>
<p>HBase 0.92版本之后增加了关于compact的配置选项，compact分为small compaction和large compaction两个线程池执行（默认都是各有1个线程，具体源代码见：org/apache/hadoop/hbase/regionserver /CompactSplitThread.java），由于compact过程需要从HBase集群读取数据，因此实际运行中导致了compact占用大 量网络出口流量，解决方案为选择性地关闭small compaction或large compaction。有以下两种变更方式均可解决：</p>
<p>1<span style="font-family:宋体">）方案一</span></p>
<p>（1） 修改hbase.regionserver.thread.compaction.throttle为一个很大的值（如50GB），强制让所有compact都变为small compaction，减少compact的压力；</p>
<p>（2） 将small compaction和large compaction线程数均设置为1，减少compact的压力（可不配置，系统默认也会将其初始化为1）。</p>
<p>操作步骤：</p>
<p>准备hbase-site.xml文件，添加或修改如下选项：</p>
<p>&lt;property&gt;</p>
<p>    &lt;name&gt;hbase.regionserver.thread.compaction.throttle&lt;/name&gt;</p>
<p>    &lt;value&gt;53687091200&lt;/value&gt;</p>
<p>&lt;/property&gt;</p>
<p>&lt;property&gt;</p>
<p>    &lt;name&gt;hbase.regionserver.thread.compaction.small&lt;/name&gt;</p>
<p>    &lt;value&gt;1&lt;/value&gt;</p>
<p>&lt;/property&gt;</p>
<p>&lt;property&gt;</p>
<p>    &lt;name&gt;hbase.regionserver.thread.compaction.large&lt;/name&gt;</p>
<p>    &lt;value&gt;1&lt;/value&gt;</p>
<p>&lt;/property&gt;</p>
<p>重启集群使配置生效。</p>
<p>2）方案二</p>
<p>将small compaction线程数均设置为0，从而关闭small compaction，只剩下large compaction，也可减少compact的压力。</p>
<p>操作步骤：</p>
<p>准备hbase-site.xml文件，添加或修改如下选项：</p>
<p>&lt;property&gt;</p>
<p>    &lt;name&gt;hbase.regionserver.thread.compaction.small&lt;/name&gt;</p>
<p>    &lt;value&gt;0&lt;/value&gt;</p>
<p>&lt;/property&gt;</p>
<p>重启集群使配置生效。</p>
<p>二十、 HBase集群出现NotServingRegionException问题的排查及解决方法</p>
<p> </p>
<p>HBase集群在读写过程中，可能由于Region Split或Region Blance等导致Region的短暂下线，此时客户端与HBase集群进行RPC操作时会抛出NotServingRegionException异常，从而导致读写操作失败。这里根据实际项目经验，详细描述这一问题的发现及排查解决过程。</p>
<p>1. 发现问题</p>
<p>在对HBase集群进行压力测试过程中发现，当实际写入HBase和从HBase查询的量是平时的若干倍时（集群规模10~20台，每秒读写数据量在几十万条记录的量级），导致集群的读写出现一定程度的波动。具体如下：</p>
<p>1）写端抛出以下异常信息：</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 150 actions: NotServingRegionException: 150 times, servers with issues: my161208.cm6:60020,at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatchCallback(HConnectionManager.java:1600)at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatch(HConnectionManager.java:1376)at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:916)</p>
</td>
</tr>
</tbody>
</table>
<p>2）读端也抛出类似异常信息：</p>
<table>
<tbody>
<tr>
<td valign="top">
<p>org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=10, exceptions:Mon Oct 29 14:03:09 CST 2012, org.apache.hadoop.hbase.client.ScannerCallable@3740fb20, org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: xxxxxx,\x0FP\x8D\xC3\xDB1053223266:\x00\x00V6,1351490475989.bd68113129f07163dc25e78fba17ad6c. is closing</p>
</td>
</tr>
</tbody>
</table>
<p>以上异常，在压测期间周期性地出现，HBase集群由此出现了短暂的不可服务期。</p>
<p>2. 排查问题</p>
<p>通 过查看HBase Master运行日志，结合客户端抛出异常的时刻，发现当时HBase集群内正在进行Region的Split和不同机器之间的Region Balance，那么，为什么会周期性频繁触发以上过程呢？而且是发生在压测期间（数据量与平时相比大几倍）。下面结合表的设计来分析一下：</p>
<p>1） 由于表中rowkey有时间字段，因此每天都需要新创建Region，同时由于写入数据量大，进一步触发了HBase的Region Split操作，这一过程一般耗时较长（测试时从线上日志来看，平均为10秒左右，Region大小为4GB），且Region Split操作触发较为频繁；</p>
<p>2）同时由于Region Split操作导致Region分布不均匀，进而触发HBase自动做Region Balance操作，Region迁移过程中也会导致Region下线，这一过程耗时较长（测试时从线上日志来看，平均为20秒左右）。</p>
<p>3. 解决问题</p>
<p>首先，从客户端考虑，其实就是要保证Region下线不可服务期间，读写请求能够在集群恢复后继续，具体可以采取如下措施：</p>
<p>1） 对于写端，可以将未写入成功的记录，添加到一个客户端缓存中，隔一段时间后交给一个后台线程统一重新提交一次；也可以通过 setAutoFlush(flase, false)保证提交失败的记录不被抛弃，留在客户端writeBuffer中等待下次writeBuffer满了后再次尝试提交，直到提交成功为止。</p>
<p>2）对于读端，捕获异常后，可以采取休眠一段时间后进行重试等方式。</p>
<p>3）当然，还可以根据实际情况合理调整hbase.client.retries.number和hbase.client.pause配置选项。</p>
<p>然后，从服务端考虑，需要分别针对Region Split和Region Balance进行解决：</p>
<p>1） 由于建表时，我们已经考虑到了数据在不同Region Server上的均匀分布，而且预先在不同Region Server上创建并分配了相同数目的Region，那么考虑到为了集群能够在实际线上环境下提供稳定的服务，可以选择关掉HBase的Region自动 Balance功能，当然关掉后可以选择在每天读写压力小的时候（如凌晨后）触发执行一次Balance操作即可。</p>
<p>2）接下来，Region总是被创建，不能被复用的问题该如何解决呢？根本原因是rowkey中包含了timestamp字段，而每时每刻timestamp总是 向上增长的。但是，使用方确实需要能够根据timestamp字段进行顺序scan操作，因此，timestamp字段必须保留。据此，这里给出两种解决 思路：</p>
<p>· 一种常用方法是将表按照时间分表，例如按天进行分表，这样可以通过预先建表创建好Region分区，避免实际读写过程中频 繁触发Region Split等过程，但是这一方法的缺点是每天需要预先建好表，而这一DDL过程可能出现问题进而导致读写出现问题，同时跨天时读写端也需要做出适应，调整 为读写新创建的表。</p>
<p>· 其实，我们可以换一种思路，通过修改表的rowkey结构，将timestamp字段改成一个周期循环的 timestamp，如取timestamp % TS_MODE后的值，其中TS_MODE须大于等于表的TTL时间周期，这样才能保证数据不会被覆盖掉。经过这样改造后，即可实现Region的复用， 避免Region的无限上涨。对于读写端的变更也较小，读写端操作时只需将timestamp字段取模后作为rowkey进行读写，另外，读端需要考虑能 适应scan扫描时处理[startTsMode, endTsMode]和[endTsMode, startTsMode]两种情况。</p>
<p>4. 总结的话</p>
<p>以上仅是本人结合实际项目中遇到的问题进行了概括总结，仅供参考。欢迎讨论交流。</p>
<p>二十一、 hbase java编程实例</p>
<p> </p>
<p><span style="color:rgb(17,17,17)">HBase<span style="font-family:宋体">提供了</span><span style="font-family:Verdana">java api</span><span style="font-family:宋体">来对</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">进行一系列的管理涉及到对表的管理、数据的操作等。常用的</span><span style="font-family:Verdana">API</span><span style="font-family:宋体">操作有：</span></span></p>
<p><span style="color:rgb(17,17,17)">　　<span style="font-family:Verdana">1</span><span style="font-family:宋体">、 </span><span style="font-family:Verdana"> </span><span style="font-family:宋体">对表的创建、删除、显示以及修改等，可以用</span><span style="font-family:Verdana">HBaseAdmin</span><span style="font-family:宋体">，一旦创建了表，那么可以通过</span><span style="font-family:Verdana">HTable</span><span style="font-family:宋体">的实例来访问表，每次可以往表里增加数据。</span></span></p>
<p><span style="color:rgb(17,17,17)">　　<span style="font-family:Verdana">2</span><span style="font-family:宋体">、 </span><span style="font-family:Verdana"> </span><span style="font-family:宋体">插入数据</span></span></p>
<p><span style="color:rgb(17,17,17)">　　　　创建一个<span style="font-family:Verdana">Put</span><span style="font-family:宋体">对象，在这个</span><span style="font-family:Verdana">Put</span><span style="font-family:宋体">对象里可以指定要给哪个列增加数据，以及当前的时间戳等值，然后通过调用</span><span style="font-family:Verdana">HTable.put(Put)</span><span style="font-family:宋体">来提交操作，子猴在这里提请注意的是：在创建</span><span style="font-family:Verdana">Put</span><span style="font-family:宋体">对象的时候，你必须指定一个行</span><span style="font-family:Verdana">(Row)</span><span style="font-family:宋体">值，在构造</span><span style="font-family:Verdana">Put</span><span style="font-family:宋体">对象的时候作为参数传入。</span></span></p>
<p><span style="color:rgb(17,17,17)">　　<span style="font-family:Verdana">3</span><span style="font-family:宋体">、 </span><span style="font-family:Verdana"> </span><span style="font-family:宋体">获取数据</span></span></p>
<p><span style="color:rgb(17,17,17)">　　　　要获取数据，使用<span style="font-family:Verdana">Get</span><span style="font-family:宋体">对象，</span><span style="font-family:Verdana">Get</span><span style="font-family:宋体">对象同</span><span style="font-family:Verdana">Put</span><span style="font-family:宋体">对象一样有好几个构造函数，通常在构造的时候传入行值，表示取第几行的数据，通过</span><span style="font-family:Verdana">HTable.get(Get)</span><span style="font-family:宋体">来调用。</span></span></p>
<p><span style="color:rgb(17,17,17)">　　<span style="font-family:Verdana">4</span><span style="font-family:宋体">、 </span><span style="font-family:Verdana"> </span><span style="font-family:宋体">浏览每一行</span></span></p>
<p><span style="color:rgb(17,17,17)">　　　　通过<span style="font-family:Verdana">Scan</span><span style="font-family:宋体">可以对表中的行进行浏览，得到每一行的信息，比如列名，时间戳等，</span><span style="font-family:Verdana">Scan</span><span style="font-family:宋体">相当于一个游标，通过</span><span style="font-family:Verdana">next()</span><span style="font-family:宋体">来浏览下一个，通过调用</span><span style="font-family:Verdana">HTable.getScanner(Scan)</span><span style="font-family:宋体">来返回一个</span><span style="font-family:Verdana">ResultScanner</span><span style="font-family:宋体">对象。</span><span style="font-family:Verdana">HTable.get(Get)</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">HTable.getScanner(Scan)</span><span style="font-family:宋体">都是返回一个</span><span style="font-family:Verdana">Result</span><span style="font-family:宋体">。</span><span style="font-family:Verdana">Result</span><span style="font-family:宋体">是一个</span></span></p>
<p><span style="color:rgb(17,17,17)">KeyValue<span style="font-family:宋体">的链表。</span></span></p>
<p><span style="color:rgb(17,17,17)">　　<span style="font-family:Verdana">5</span><span style="font-family:宋体">、 </span><span style="font-family:Verdana"> </span><span style="font-family:宋体">删除</span></span></p>
<p><span style="color:rgb(17,17,17)">　　　　使用<span style="font-family:Verdana">Delete</span><span style="font-family:宋体">来删除记录，通过调用</span><span style="font-family:Verdana">HTable.delete(Delete)</span><span style="font-family:宋体">来执行删除操作。（注：删除这里有些特别，也就是删除并不是马上将数据从表中删除。）</span></span></p>
<p><span style="color:rgb(17,17,17)">　　<span style="font-family:Verdana">6</span><span style="font-family:宋体">、 </span><span style="font-family:Verdana"> </span><span style="font-family:宋体">锁</span></span></p>
<p><span style="color:rgb(17,17,17)">　　　　新增、获取、删除在操作过程中会对所操作的行加一个锁，而浏览却不会。</span></p>
<p><span style="color:rgb(17,17,17)">　　<span style="font-family:Verdana">7</span><span style="font-family:宋体">、 </span><span style="font-family:Verdana"> </span><span style="font-family:宋体">簇的访问</span></span></p>
<p><span style="color:rgb(17,17,17)">　　　　客户端代码通过<span style="font-family:Verdana">ZooKeeper</span><span style="font-family:宋体">来访问找到簇，也就是说</span><span style="font-family:Verdana">ZooKeeper quorum</span><span style="font-family:宋体">将被使用，那么相关的类（包）应该在客户端的类（</span><span style="font-family:Verdana">classes</span><span style="font-family:宋体">）目录下，即客户端一定要找到文件</span><span style="font-family:Verdana">hbase-site.xml</span><span style="font-family:宋体">。</span></span></p>
<p><span style="color:rgb(17,17,17)">　　以下是一个完整的代码示例，基于<span style="font-family:Verdana">hbase-0.90.3</span><span style="font-family:宋体">编写（</span><span style="font-family:Verdana">hbase</span><span style="font-family:宋体">的基本概念可参考我博客的</span></span><a target="_blank" href="http://www.cnblogs.com/flying5/archive/2011/09/15/2178064.html" rel="nofollow"><span style="color:rgb(0,102,204)">前一篇文章</span></a><span style="color:rgb(17,17,17)">）：</span></p>
<p><a target="_blank" href="http://www.cnblogs.com/flying5/archive/2011/09/16/2178069.html" rel="nofollow"><span style="color:rgb(0,102,204)">?</span></a></p>
<table>
<tbody>
<tr>
<td valign="center">
<p>import java.io.IOException; </p>
<p>import java.util.ArrayList; </p>
<p>import java.util.List; </p>
<p>  </p>
<p>import org.apache.hadoop.conf.Configuration; </p>
<p>import org.apache.hadoop.hbase.HBaseConfiguration; </p>
<p>import org.apache.hadoop.hbase.HColumnDescriptor; </p>
<p>import org.apache.hadoop.hbase.HTableDescriptor; </p>
<p>import org.apache.hadoop.hbase.KeyValue; </p>
<p>import org.apache.hadoop.hbase.MasterNotRunningException; </p>
<p>import org.apache.hadoop.hbase.ZooKeeperConnectionException; </p>
<p>import org.apache.hadoop.hbase.client.Delete; </p>
<p>import org.apache.hadoop.hbase.client.Get; </p>
<p>import org.apache.hadoop.hbase.client.HBaseAdmin; </p>
<p>import org.apache.hadoop.hbase.client.HTable; </p>
<p>import org.apache.hadoop.hbase.client.Result; </p>
<p>import org.apache.hadoop.hbase.client.ResultScanner; </p>
<p>import org.apache.hadoop.hbase.client.Scan; </p>
<p>import org.apache.hadoop.hbase.client.Put; </p>
<p>import org.apache.hadoop.hbase.util.Bytes; </p>
<p>  </p>
<p>public class HBaseTest { </p>
<p>     </p>
<p>    private static Configuration conf = null; </p>
<p>      </p>
<p>    /** </p>
<p>     * 初始化配置 </p>
<p>     */</p>
<p>    static { </p>
<p>        Configuration HBASE_CONFIG = new Configuration(); </p>
<p>        //与hbase/conf/hbase-site.xml中hbase.zookeeper.quorum配置的值相同   </p>
<p>        HBASE_CONFIG.set("hbase.zookeeper.quorum", "10.1.1.1"); </p>
<p>        //与hbase/conf/hbase-site.xml中hbase.zookeeper.property.clientPort配置的值相同  </p>
<p>        HBASE_CONFIG.set("hbase.zookeeper.property.clientPort", "2181"); </p>
<p>        conf = HBaseConfiguration.create(HBASE_CONFIG); </p>
<p>    } </p>
<p>     </p>
<p>    /** </p>
<p>     * 创建一张表 </p>
<p>     */</p>
<p>    public static void creatTable(String tableName, String[] familys) throws Exception { </p>
<p>        HBaseAdmin admin = new HBaseAdmin(conf); </p>
<p>        if (admin.tableExists(tableName)) { </p>
<p>            System.out.println("table already exists!"); </p>
<p>        } else { </p>
<p>            HTableDescriptor tableDesc = new HTableDescriptor(tableName); </p>
<p>            for(int i=0; i&lt;familys.length; i++){ </p>
<p>                tableDesc.addFamily(new HColumnDescriptor(familys[i])); </p>
<p>            } </p>
<p>            admin.createTable(tableDesc); </p>
<p>            System.out.println("create table " + tableName + " ok."); </p>
<p>        }   </p>
<p>    } </p>
<p>     </p>
<p>    /** </p>
<p>     * 删除表 </p>
<p>     */</p>
<p>    public static void deleteTable(String tableName) throws Exception { </p>
<p>       try { </p>
<p>           HBaseAdmin admin = new HBaseAdmin(conf); </p>
<p>           admin.disableTable(tableName); </p>
<p>           admin.deleteTable(tableName); </p>
<p>           System.out.println("delete table " + tableName + " ok."); </p>
<p>       } catch (MasterNotRunningException e) { </p>
<p>           e.printStackTrace(); </p>
<p>       } catch (ZooKeeperConnectionException e) { </p>
<p>           e.printStackTrace(); </p>
<p>       } </p>
<p>    } </p>
<p>      </p>
<p>    /** </p>
<p>     * 插入一行记录 </p>
<p>     */</p>
<p>    public static void addRecord (String tableName, String rowKey, String family, String qualifier, String value)  </p>
<p>            throws Exception{ </p>
<p>        try { </p>
<p>            HTable table = new HTable(conf, tableName); </p>
<p>            Put put = new Put(Bytes.toBytes(rowKey)); </p>
<p>            put.add(Bytes.toBytes(family),Bytes.toBytes(qualifier),Bytes.toBytes(value)); </p>
<p>            table.put(put); </p>
<p>            System.out.println("insert recored " + rowKey + " to table " + tableName +" ok."); </p>
<p>        } catch (IOException e) { </p>
<p>            e.printStackTrace(); </p>
<p>        } </p>
<p>    } </p>
<p>  </p>
<p>    /** </p>
<p>     * 删除一行记录 </p>
<p>     */</p>
<p>    public static void delRecord (String tableName, String rowKey) throws IOException{ </p>
<p>        HTable table = new HTable(conf, tableName); </p>
<p>        List list = new ArrayList(); </p>
<p>        Delete del = new Delete(rowKey.getBytes()); </p>
<p>        list.add(del); </p>
<p>        table.delete(list); </p>
<p>        System.out.println("del recored " + rowKey + " ok."); </p>
<p>    } </p>
<p>      </p>
<p>    /** </p>
<p>     * 查找一行记录 </p>
<p>     */</p>
<p>    public static void getOneRecord (String tableName, String rowKey) throws IOException{ </p>
<p>        HTable table = new HTable(conf, tableName); </p>
<p>        Get get = new Get(rowKey.getBytes()); </p>
<p>        Result rs = table.get(get); </p>
<p>        for(KeyValue kv : rs.raw()){ </p>
<p>            System.out.print(new String(kv.getRow()) + " " ); </p>
<p>            System.out.print(new String(kv.getFamily()) + ":" ); </p>
<p>            System.out.print(new String(kv.getQualifier()) + " " ); </p>
<p>            System.out.print(kv.getTimestamp() + " " ); </p>
<p>            System.out.println(new String(kv.getValue())); </p>
<p>        } </p>
<p>    } </p>
<p>      </p>
<p>    /** </p>
<p>     * 显示所有数据 </p>
<p>     */</p>
<p>    public static void getAllRecord (String tableName) { </p>
<p>        try{ </p>
<p>             HTable table = new HTable(conf, tableName); </p>
<p>             Scan s = new Scan(); </p>
<p>             ResultScanner ss = table.getScanner(s); </p>
<p>             for(Result r:ss){ </p>
<p>                 for(KeyValue kv : r.raw()){ </p>
<p>                    System.out.print(new String(kv.getRow()) + " "); </p>
<p>                    System.out.print(new String(kv.getFamily()) + ":"); </p>
<p>                    System.out.print(new String(kv.getQualifier()) + " "); </p>
<p>                    System.out.print(kv.getTimestamp() + " "); </p>
<p>                    System.out.println(new String(kv.getValue())); </p>
<p>                 } </p>
<p>             } </p>
<p>        } catch (IOException e){ </p>
<p>            e.printStackTrace(); </p>
<p>        } </p>
<p>    } </p>
<p>     </p>
<p>    public static void  main (String [] agrs) { </p>
<p>        try { </p>
<p>            String tablename = "scores"; </p>
<p>            String[] familys = {"grade", "course"}; </p>
<p>            HBaseTest.creatTable(tablename, familys); </p>
<p>              </p>
<p>            //add record zkb </p>
<p>            HBaseTest.addRecord(tablename,"zkb","grade","","5"); </p>
<p>            HBaseTest.addRecord(tablename,"zkb","course","","90"); </p>
<p>            HBaseTest.addRecord(tablename,"zkb","course","math","97"); </p>
<p>            HBaseTest.addRecord(tablename,"zkb","course","art","87"); </p>
<p>            //add record  baoniu </p>
<p>            HBaseTest.addRecord(tablename,"baoniu","grade","","4"); </p>
<p>            HBaseTest.addRecord(tablename,"baoniu","course","math","89"); </p>
<p>              </p>
<p>            System.out.println("===========get one record========"); </p>
<p>            HBaseTest.getOneRecord(tablename, "zkb"); </p>
<p>              </p>
<p>            System.out.println("===========show all record========"); </p>
<p>            HBaseTest.getAllRecord(tablename); </p>
<p>              </p>
<p>            System.out.println("===========del one record========"); </p>
<p>            HBaseTest.delRecord(tablename, "baoniu"); </p>
<p>            HBaseTest.getAllRecord(tablename); </p>
<p>              </p>
<p>            System.out.println("===========show all record========"); </p>
<p>            HBaseTest.getAllRecord(tablename); </p>
<p>        } catch (Exception e) { </p>
<p>            e.printStackTrace(); </p>
<p>        } </p>
<p>    } </p>
<p>}</p>
</td>
</tr>
</tbody>
</table>
<p><span style="color:rgb(17,17,17)">　　程序编译为一个<span style="font-family:Verdana">jar</span><span style="font-family:宋体">包</span><span style="font-family:Verdana">hbtest.jar,</span><span style="font-family:宋体">执行脚本：</span></span></p>
<p><a target="_blank" href="http://www.cnblogs.com/flying5/archive/2011/09/16/2178069.html" rel="nofollow"><span style="color:rgb(0,102,204)">?</span></a></p>
<table>
<tbody>
<tr>
<td valign="center">
<p>#!/bin/sh </p>
<p>  </p>
<p>source ~/.bash_profile </p>
<p>export HADOOP_CLASSPATH=/home/admin/hadoop/hadoop-core-0.20.2-CDH3B4.jar:/home/admin/hbase/hbase-0.90.3.jar:/home/admin/zookeeper/zookeeper-3.3.2.jar  </p>
<p>  </p>
<p>hadoop jar hbtest.jar</p>
</td>
</tr>
</tbody>
</table>
<p><span style="color:rgb(17,17,17)">　　输出结果是：</span></p>
<p><a target="_blank" href="http://www.cnblogs.com/flying5/archive/2011/09/16/2178069.html" rel="nofollow"><span style="color:rgb(0,102,204)">?</span></a></p>
<table>
<tbody>
<tr>
<td valign="center">
<p>create table scores ok. </p>
<p>11/09/16 00:45:39 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=10.1.1.1:2181 sessionTimeout=180000 watcher=hconnection </p>
<p>11/09/16 00:45:39 INFO zookeeper.ClientCnxn: Opening socket connection to server /10.1.1.1:2181</p>
<p>11/09/16 00:45:39 INFO zookeeper.ClientCnxn: Socket connection established to search041134.sqa.cm4.tbsite.net/10.1.1.1:2181, initiating session </p>
<p>11/09/16 00:45:39 INFO zookeeper.ClientCnxn: Session establishment complete on server search041134.sqa.cm4.tbsite.net/10.1.1.1:2181, sessionid = 0x132614b5411007f, negotiated timeout = 180000</p>
<p>insert recored zkb to table scores ok. </p>
<p>insert recored zkb to table scores ok. </p>
<p>insert recored zkb to table scores ok. </p>
<p>insert recored zkb to table scores ok. </p>
<p>insert recored baoniu to table scores ok. </p>
<p>insert recored baoniu to table scores ok. </p>
<p>===========get one record======== </p>
<p>zkb course: 1316105139153 90</p>
<p>zkb course:art 1316105139156 87</p>
<p>zkb course:math 1316105139154 97</p>
<p>zkb grade: 1316105139149 5</p>
<p>===========show all record======== </p>
<p>baoniu course:math 1316105139159 89</p>
<p>baoniu grade: 1316105139158 4</p>
<p>zkb course: 1316105139153 90</p>
<p>zkb course:art 1316105139156 87</p>
<p>zkb course:math 1316105139154 97</p>
<p>zkb grade: 1316105139149 5</p>
<p>===========del one record======== </p>
<p>del recored baoniu ok. </p>
<p>zkb course: 1316105139153 90</p>
<p>zkb course:art 1316105139156 87</p>
<p>zkb course:math 1316105139154 97</p>
<p>zkb grade: 1316105139149 5</p>
<p>===========show all record======== </p>
<p>zkb course: 1316105139153 90</p>
<p>zkb course:art 1316105139156 87</p>
<p>zkb course:math 1316105139154 97</p>
<p>zkb grade: 1316105139149 5</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p> </p>
<p> </p>
<p>二十二、 <a target="_blank" href="http://blog.csdn.net/karen_wang/article/details/6283729" rel="nofollow">java实现hbase表创建、数据插入、删除表 </a></p>
<p> </p>
<p><span style="color:rgb(51,51,51)">近日查看了相关资料后，梳理了一下用<span style="font-family:Arial">java</span><span style="font-family:宋体">实现</span><span style="font-family:Arial">hbase</span><span style="font-family:宋体">的表创建、数据插入、删除表，代码如下：</span></span></p>
<p><span style="color:rgb(51,51,51)">1<span style="font-family:宋体">、需要的</span><span style="font-family:Arial">jar</span><span style="font-family:宋体">包：</span></span></p>
<p><span style="color:rgb(51,51,51)">commons-codec-1.4.jar</span></p>
<p><span style="color:rgb(51,51,51)">commons-logging-1.0.4.jar</span></p>
<p><span style="color:rgb(51,51,51)">hadoop-0.20.2-core.jar</span></p>
<p><span style="color:rgb(51,51,51)">hbase-0.20.6.jar</span></p>
<p><span style="color:rgb(51,51,51)">log4j-1.2.15.jar</span></p>
<p><span style="color:rgb(51,51,51)">zookeeper-3.2.2.jar</span></p>
<p><span style="color:rgb(51,51,51)"> </span></p>
<p><span style="color:rgb(51,51,51)">2<span style="font-family:宋体">、代码：</span></span></p>
<p style="background:rgb(231,229,220)"><span style="color:rgb(51,51,51)">[java:nogutter]</span><span style="color:rgb(51,51,51)"> </span><a target="_blank" href="http://blog.csdn.net/karen_wang/article/details/6283729" rel="nofollow" title="view plain"><span style="color:rgb(0,0,255)">view plain</span></a><a target="_blank" href="http://blog.csdn.net/karen_wang/article/details/6283729" rel="nofollow" title="copy"><span style="color:rgb(0,0,255)">copy</span></a><a target="_blank" href="http://blog.csdn.net/karen_wang/article/details/6283729" rel="nofollow" title="print"><span style="color:rgb(0,0,255)">print</span></a><a target="_blank" href="http://blog.csdn.net/karen_wang/article/details/6283729" rel="nofollow" title="?"><span style="color:rgb(0,0,255)">?</span></a></p>
<p><span style="color:rgb(51,51,51)">1. </span><span style="color:rgb(51,51,51)">package</span><span style="color:rgb(51,51,51)"> org.myhbase;  </span></p>
<p><span style="color:rgb(51,51,51)">2. </span><span style="color:rgb(51,51,51)">  </span></p>
<p><span style="color:rgb(51,51,51)">3. </span><span style="color:rgb(51,51,51)">import</span><span style="color:rgb(51,51,51)"> java.io.IOException;  </span></p>
<p><span style="color:rgb(51,51,51)">4. </span><span style="color:rgb(51,51,51)">  </span></p>
<p><span style="color:rgb(51,51,51)">5. </span><span style="color:rgb(51,51,51)">import</span><span style="color:rgb(51,51,51)"> org.apache.hadoop.conf.Configuration;  </span></p>
<p><span style="color:rgb(51,51,51)">6. </span><span style="color:rgb(51,51,51)">import</span><span style="color:rgb(51,51,51)"> org.apache.hadoop.hbase.HBaseConfiguration;  </span></p>
<p><span style="color:rgb(51,51,51)">7. </span><span style="color:rgb(51,51,51)">import</span><span style="color:rgb(51,51,51)"> org.apache.hadoop.hbase.HColumnDescriptor;  </span></p>
<p><span style="color:rgb(51,51,51)">8. </span><span style="color:rgb(51,51,51)">import</span><span style="color:rgb(51,51,51)"> org.apache.hadoop.hbase.HTableDescriptor;  </span></p>
<p><span style="color:rgb(51,51,51)">9. </span><span style="color:rgb(51,51,51)">import</span><span style="color:rgb(51,51,51)"> org.apache.hadoop.hbase.KeyValue;  </span></p>
<p><span style="color:rgb(51,51,51)">10. </span><span style="color:rgb(51,51,51)">import</span><span style="color:rgb(51,51,51)"> org.apache.hadoop.hbase.client.HBaseAdmin;  </span></p>
<p><span style="color:rgb(51,51,51)">11. </span><span style="color:rgb(51,51,51)">import</span><span style="color:rgb(51,51,51)"> org.apache.hadoop.hbase.client.HTable;  </span></p>
<p><span style="color:rgb(51,51,51)">12. </span><span style="color:rgb(51,51,51)">import</span><span style="color:rgb(51,51,51)"> org.apache.hadoop.hbase.client.Result;  </span></p>
<p><span style="color:rgb(51,51,51)">13. </span><span style="color:rgb(51,51,51)">import</span><span style="color:rgb(51,51,51)"> org.apache.hadoop.hbase.client.ResultScanner;  </span></p>
<p><span style="color:rgb(51,51,51)">14. </span><span style="color:rgb(51,51,51)">import</span><span style="color:rgb(51,51,51)"> org.apache.hadoop.hbase.client.Scan;  </span></p>
<p><span style="color:rgb(51,51,51)">15. </span><span style="color:rgb(51,51,51)">import</span><span style="color:rgb(51,51,51)"> org.apache.hadoop.hbase.io.BatchUpdate;  </span></p>
<p><span style="color:rgb(51,51,51)">16. </span><span style="color:rgb(51,51,51)">  </span></p>
<p><span style="color:rgb(51,51,51)">17. </span><span style="color:rgb(51,51,51)">public</span><span style="color:rgb(51,51,51)"> </span><span style="color:rgb(51,51,51)">class</span><span style="color:rgb(51,51,51)"> HBaseBasic02 {  </span></p>
<p><span style="color:rgb(51,51,51)">18. </span><span style="color:rgb(51,51,51)">    </span><span style="color:rgb(51,51,51)">static</span><span style="color:rgb(51,51,51)"> HBaseConfiguration hbaseConfig=</span><span style="color:rgb(51,51,51)">null</span><span style="color:rgb(51,51,51)">;  </span></p>
<p><span style="color:rgb(51,51,51)">19. </span><span style="color:rgb(51,51,51)">    </span><span style="color:rgb(51,51,51)">static</span><span style="color:rgb(51,51,51)">{  </span></p>
<p><span style="color:rgb(51,51,51)">20. </span><span style="color:rgb(51,51,51)">        Configuration config=</span><span style="color:rgb(51,51,51)">new</span><span style="color:rgb(51,51,51)"> Configuration();  </span></p>
<p><span style="color:rgb(51,51,51)">21. </span><span style="color:rgb(51,51,51)">        config.set(</span><span style="color:rgb(51,51,51)">"hbase.zookeeper.quorum"</span><span style="color:rgb(51,51,51)">,</span><span style="color:rgb(51,51,51)">"192.168.10.149,192.168.10.44,192.168.10.49"</span><span style="color:rgb(51,51,51)">);  </span></p>
<p><span style="color:rgb(51,51,51)">22. </span><span style="color:rgb(51,51,51)">        config.set(</span><span style="color:rgb(51,51,51)">"hbase.zookeeper.property.clientPort"</span><span style="color:rgb(51,51,51)">, </span><span style="color:rgb(51,51,51)">"2181"</span><span style="color:rgb(51,51,51)">);  </span></p>
<p><span style="color:rgb(51,51,51)">23. </span><span style="color:rgb(51,51,51)">        hbaseConfig=</span><span style="color:rgb(51,51,51)">new</span><span style="color:rgb(51,51,51)"> HBaseConfiguration(config);  </span></p>
<p><span style="color:rgb(51,51,51)">24. </span><span style="color:rgb(51,51,51)">    }  </span></p>
<p><span style="color:rgb(51,51,51)">25. </span><span style="color:rgb(51,51,51)">      </span></p>
<p><span style="color:rgb(51,51,51)">26. </span><span style="color:rgb(51,51,51)">    </span><span style="color:rgb(51,51,51)">/**</span><span style="color:rgb(51,51,51)"> </span></p>
<p><span style="color:rgb(51,51,51)">27. </span><span style="color:rgb(51,51,51)">     * <span style="font-family:宋体">创建一张表</span></span><span style="color:rgb(51,51,51)"> </span></p>
<p><span style="color:rgb(51,51,51)">28. </span><span style="color:rgb(51,51,51)">     * @throws IOException </span><span style="color:rgb(51,51,51)"> </span></p>
<p><span style="color:rgb(51,51,51)">29. </span><span style="color:rgb(51,51,51)">     */</span><span style="color:rgb(51,51,51)">  </span></p>
<p><span style="color:rgb(51,51,51)">30. </span><span style="color:rgb(51,51,51)">    </span><span style="color:rgb(51,51,51)">public</span><span style="color:rgb(51,51,51)"> </span><span style="color:rgb(51,51,51)">static</span><span style="color:rgb(51,51,51)"> </span><span style="color:rgb(51,51,51)">void</span><span style="color:rgb(51,51,51)"> createTable(String tablename) </span><span style="color:rgb(51,51,51)">throws</span><span style="color:rgb(51,51,51)"> IOException{  </span></p>
<p><span style="color:rgb(51,51,51)">31. </span><span style="color:rgb(51,51,51)">        HBaseAdmin admin = </span><span style="color:rgb(51,51,51)">new</span><span style="color:rgb(51,51,51)"> HBaseAdmin(hbaseConfig);  </span></p>
<p><span style="color:rgb(51,51,51)">32. </span><span style="color:rgb(51,51,51)">        </span><span style="color:rgb(51,51,51)">if</span><span style="color:rgb(51,51,51)">(admin.tableExists(tablename)){  </span></p>
<p><span style="color:rgb(51,51,51)">33. </span><span style="color:rgb(51,51,51)">            System.out.println(</span><span style="color:rgb(51,51,51)">"table Exists!!!"</span><span style="color:rgb(51,51,51)">);  </span></p>
<p><span style="color:rgb(51,51,51)">34. </span><span style="color:rgb(51,51,51)">        }</span><span style="color:rgb(51,51,51)">else</span><span style="color:rgb(51,51,51)">{  </span></p>
<p><span style="color:rgb(51,51,51)">35. </span><span style="color:rgb(51,51,51)">            HTableDescriptor tableDesc = </span><span style="color:rgb(51,51,51)">new</span><span style="color:rgb(51,51,51)"> HTableDescriptor(tablename);  </span></p>
<p><span style="color:rgb(51,51,51)">36. </span><span style="color:rgb(51,51,51)">            tableDesc.addFamily(</span><span style="color:rgb(51,51,51)">new</span><span style="color:rgb(51,51,51)"> HColumnDescriptor(</span><span style="color:rgb(51,51,51)">"name:"</span><span style="color:rgb(51,51,51)">));  </span></p>
<p><span style="color:rgb(51,51,51)">37. </span><span style="color:rgb(51,51,51)">            admin.createTable(tableDesc);  </span></p>
<p><span style="color:rgb(51,51,51)">38. </span><span style="color:rgb(51,51,51)">            System.out.println(</span><span style="color:rgb(51,51,51)">"create table ok."</span><span style="color:rgb(51,51,51)">);  </span></p>
<p><span style="color:rgb(51,51,51)">39. </span><span style="color:rgb(51,51,51)">        }  </span></p>
<p><span style="color:rgb(51,51,51)">40. </span><span style="color:rgb(51,51,51)">    }  </span></p>
<p><span style="color:rgb(51,51,51)">41. </span><span style="color:rgb(51,51,51)">      </span></p>
<p><span style="color:rgb(51,51,51)">42. </span><span style="color:rgb(51,51,51)">    </span><span style="color:rgb(51,51,51)">/**</span><span style="color:rgb(51,51,51)"> </span></p>
<p><span style="color:rgb(51,51,51)">43. </span><span style="color:rgb(51,51,51)">     * <span style="font-family:宋体">删除一张表</span></span><span style="color:rgb(51,51,51)"> </span></p>
<p><span style="color:rgb(51,51,51)">44. </span><span style="color:rgb(51,51,51)">     * @throws IOException </span><span style="color:rgb(51,51,51)"> </span></p>
<p><span style="color:rgb(51,51,51)">45. </span><span style="color:rgb(51,51,51)">     */</span><span style="color:rgb(51,51,51)">  </span></p>
<p><span style="color:rgb(51,51,51)">46. </span><span style="color:rgb(51,51,51)">    </span><span style="color:rgb(51,51,51)">public</span><span style="color:rgb(51,51,51)"> </span><span style="color:rgb(51,51,51)">static</span><span style="color:rgb(51,51,51)"> </span><span style="color:rgb(51,51,51)">void</span><span style="color:rgb(51,51,51)"> dropTable(String tablename) </span><span style="color:rgb(51,51,51)">throws</span><span style="color:rgb(51,51,51)"> IOException{  </span></p>
<p><span style="color:rgb(51,51,51)">47. </span><span style="color:rgb(51,51,51)">        HBaseAdmin admin = </span><span style="color:rgb(51,51,51)">new</span><span style="color:rgb(51,51,51)"> HBaseAdmin(hbaseConfig);  </span></p>
<p><span style="color:rgb(51,51,51)">48. </span><span style="color:rgb(51,51,51)">        admin.disableTable(tablename);  </span></p>
<p><span style="color:rgb(51,51,51)">49. </span><span style="color:rgb(51,51,51)">        admin.deleteTable(tablename);  </span></p>
<p><span style="color:rgb(51,51,51)">50. </span><span style="color:rgb(51,51,51)">        System.out.println(</span><span style="color:rgb(51,51,51)">"drop table ok."</span><span style="color:rgb(51,51,51)">);  </span></p>
<p><span style="color:rgb(51,51,51)">51. </span><span style="color:rgb(51,51,51)">    }  </span></p>
<p><span style="color:rgb(51,51,51)">52. </span><span style="color:rgb(51,51,51)">      </span></p>
<p><span style="color:rgb(51,51,51)">53. </span><span style="color:rgb(51,51,51)">      </span></p>
<p><span style="color:rgb(51,51,51)">54. </span><span style="color:rgb(51,51,51)">    </span><span style="color:rgb(51,51,51)">/**</span><span style="color:rgb(51,51,51)"> </span></p>
<p><span style="color:rgb(51,51,51)">55. </span><span style="color:rgb(51,51,51)">     * <span style="font-family:宋体">添加一条数据</span></span><span style="color:rgb(51,51,51)"> </span></p>
<p><span style="color:rgb(51,51,51)">56. </span><span style="color:rgb(51,51,51)">     * @throws IOException </span><span style="color:rgb(51,51,51)"> </span></p>
<p><span style="color:rgb(51,51,51)">57. </span><span style="color:rgb(51,51,51)">     */</span><span style="color:rgb(51,51,51)">  </span></p>
<p><span style="color:rgb(51,51,51)">58. </span><span style="color:rgb(51,51,51)">    </span><span style="color:rgb(51,51,51)">public</span><span style="color:rgb(51,51,51)"> </span><span style="color:rgb(51,51,51)">static</span><span style="color:rgb(51,51,51)"> </span><span style="color:rgb(51,51,51)">void</span><span style="color:rgb(51,51,51)"> addData(String tablename) </span><span style="color:rgb(51,51,51)">throws</span><span style="color:rgb(51,51,51)"> IOException{  </span></p>
<p><span style="color:rgb(51,51,51)">59. </span><span style="color:rgb(51,51,51)">        HTable table=</span><span style="color:rgb(51,51,51)">new</span><span style="color:rgb(51,51,51)"> HTable(hbaseConfig,tablename);  </span></p>
<p><span style="color:rgb(51,51,51)">60. </span><span style="color:rgb(51,51,51)">        BatchUpdate update=</span><span style="color:rgb(51,51,51)">new</span><span style="color:rgb(51,51,51)"> BatchUpdate(</span><span style="color:rgb(51,51,51)">"Huangyi"</span><span style="color:rgb(51,51,51)">);  </span></p>
<p><span style="color:rgb(51,51,51)">61. </span><span style="color:rgb(51,51,51)">        update.put(</span><span style="color:rgb(51,51,51)">"name:java"</span><span style="color:rgb(51,51,51)">,</span><span style="color:rgb(51,51,51)">"http://www.sun.com"</span><span style="color:rgb(51,51,51)">.getBytes());  </span></p>
<p><span style="color:rgb(51,51,51)">62. </span><span style="color:rgb(51,51,51)">        table.commit(update);  </span></p>
<p><span style="color:rgb(51,51,51)">63. </span><span style="color:rgb(51,51,51)">        System.out.println(</span><span style="color:rgb(51,51,51)">"add data ok."</span><span style="color:rgb(51,51,51)">);  </span></p>
<p><span style="color:rgb(51,51,51)">64. </span><span style="color:rgb(51,51,51)">    }  </span></p>
<p><span style="color:rgb(51,51,51)">65. </span><span style="color:rgb(51,51,51)">      </span></p>
<p><span style="color:rgb(51,51,51)">66. </span><span style="color:rgb(51,51,51)">      </span></p>
<p><span style="color:rgb(51,51,51)">67. </span><span style="color:rgb(51,51,51)">    </span><span style="color:rgb(51,51,51)">/**</span><span style="color:rgb(51,51,51)"> </span></p>
<p><span style="color:rgb(51,51,51)">68. </span><span style="color:rgb(51,51,51)">     * <span style="font-family:宋体">显示所有数据</span></span><span style="color:rgb(51,51,51)"> </span></p>
<p><span style="color:rgb(51,51,51)">69. </span><span style="color:rgb(51,51,51)">     * @throws IOException </span><span style="color:rgb(51,51,51)"> </span></p>
<p><span style="color:rgb(51,51,51)">70. </span><span style="color:rgb(51,51,51)">     */</span><span style="color:rgb(51,51,51)">  </span></p>
<p><span style="color:rgb(51,51,51)">71. </span><span style="color:rgb(51,51,51)">    </span><span style="color:rgb(51,51,51)">public</span><span style="color:rgb(51,51,51)"> </span><span style="color:rgb(51,51,51)">static</span><span style="color:rgb(51,51,51)"> </span><span style="color:rgb(51,51,51)">void</span><span style="color:rgb(51,51,51)"> getAllData(String tablename) </span><span style="color:rgb(51,51,51)">throws</span><span style="color:rgb(51,51,51)"> IOException{  </span></p>
<p><span style="color:rgb(51,51,51)">72. </span><span style="color:rgb(51,51,51)">        HTable table=</span><span style="color:rgb(51,51,51)">new</span><span style="color:rgb(51,51,51)"> HTable(hbaseConfig,tablename);  </span></p>
<p><span style="color:rgb(51,51,51)">73. </span><span style="color:rgb(51,51,51)">        Scan s=</span><span style="color:rgb(51,51,51)">new</span><span style="color:rgb(51,51,51)"> Scan();  </span></p>
<p><span style="color:rgb(51,51,51)">74. </span><span style="color:rgb(51,51,51)">        ResultScanner rs=table.getScanner(s);  </span></p>
<p><span style="color:rgb(51,51,51)">75. </span><span style="color:rgb(51,51,51)">        </span><span style="color:rgb(51,51,51)">for</span><span style="color:rgb(51,51,51)">(Result r:rs){  </span></p>
<p><span style="color:rgb(51,51,51)">76. </span><span style="color:rgb(51,51,51)">            </span><span style="color:rgb(51,51,51)">for</span><span style="color:rgb(51,51,51)">(KeyValue kv:r.raw()){  </span></p>
<p><span style="color:rgb(51,51,51)">77. </span><span style="color:rgb(51,51,51)">                System.out.println(</span><span style="color:rgb(51,51,51)">"rowkey : "</span><span style="color:rgb(51,51,51)">+</span><span style="color:rgb(51,51,51)">new</span><span style="color:rgb(51,51,51)"> String(kv.getRow()));  </span></p>
<p><span style="color:rgb(51,51,51)">78. </span><span style="color:rgb(51,51,51)">                System.out.println(</span><span style="color:rgb(51,51,51)">new</span><span style="color:rgb(51,51,51)"> String(kv.getColumn())+</span><span style="color:rgb(51,51,51)">" = "</span><span style="color:rgb(51,51,51)">+</span><span style="color:rgb(51,51,51)">new</span><span style="color:rgb(51,51,51)"> String(kv.getValue()));  </span></p>
<p><span style="color:rgb(51,51,51)">79. </span><span style="color:rgb(51,51,51)">            }  </span></p>
<p><span style="color:rgb(51,51,51)">80. </span><span style="color:rgb(51,51,51)">        }  </span></p>
<p><span style="color:rgb(51,51,51)">81. </span><span style="color:rgb(51,51,51)">    }  </span></p>
<p><span style="color:rgb(51,51,51)">82. </span><span style="color:rgb(51,51,51)">      </span></p>
<p><span style="color:rgb(51,51,51)">83. </span><span style="color:rgb(51,51,51)">    </span><span style="color:rgb(51,51,51)">public</span><span style="color:rgb(51,51,51)"> </span><span style="color:rgb(51,51,51)">static</span><span style="color:rgb(51,51,51)"> </span><span style="color:rgb(51,51,51)">void</span><span style="color:rgb(51,51,51)"> main(String [] args) </span><span style="color:rgb(51,51,51)">throws</span><span style="color:rgb(51,51,51)"> IOException{  </span></p>
<p><span style="color:rgb(51,51,51)">84. </span><span style="color:rgb(51,51,51)">            String tablename=</span><span style="color:rgb(51,51,51)">"table_1"</span><span style="color:rgb(51,51,51)">;  </span></p>
<p><span style="color:rgb(51,51,51)">85. </span><span style="color:rgb(51,51,51)">            HBaseBasic02.createTable(tablename);  </span></p>
<p><span style="color:rgb(51,51,51)">86. </span><span style="color:rgb(51,51,51)">            HBaseBasic02.addData(tablename);  </span></p>
<p><span style="color:rgb(51,51,51)">87. </span><span style="color:rgb(51,51,51)">            HBaseBasic02.getAllData(tablename);  </span></p>
<p><span style="color:rgb(51,51,51)">88. </span><span style="color:rgb(51,51,51)">            HBaseBasic02.dropTable(tablename);  </span></p>
<p><span style="color:rgb(51,51,51)">89. </span><span style="color:rgb(51,51,51)">    }  </span></p>
<p><span style="color:rgb(51,51,51)">90. </span><span style="color:rgb(51,51,51)">      </span></p>
<p><span style="color:rgb(51,51,51)">91. </span><span style="color:rgb(51,51,51)">      </span></p>
<p><span style="color:rgb(51,51,51)">92. </span><span style="color:rgb(51,51,51)">}  </span></p>
<p>二十三、 Java操作Hbase进行建表、删表以及对数据进行增删改查，条件查询</p>
<p> </p>
<p>1、搭建环境</p>
<p>  新建JAVA项目，添加的包有:</p>
<p>   有关Hadoop的hadoop-core-0.20.204.0.jar</p>
<p>   有关Hbase的hbase-0.90.4.jar、hbase-0.90.4-tests.jar以及Hbase资源包中lib目录下的所有jar包</p>
<p> </p>
<p>2、主要程序</p>
<p> </p>
<p>Java代码  <a target="_blank" href="" rel="nofollow" title="收藏这段代码"></a></p>
<p>1. package com.wujintao.hbase.test;   </p>
<p>2.   </p>
<p>3. import java.io.IOException;   </p>
<p>4. import java.util.ArrayList;   </p>
<p>5. import java.util.List;   </p>
<p>6.   </p>
<p>7. import org.apache.hadoop.conf.Configuration;   </p>
<p>8. import org.apache.hadoop.hbase.HBaseConfiguration;   </p>
<p>9. import org.apache.hadoop.hbase.HColumnDescriptor;   </p>
<p>10. import org.apache.hadoop.hbase.HTableDescriptor;   </p>
<p>11. import org.apache.hadoop.hbase.KeyValue;   </p>
<p>12. import org.apache.hadoop.hbase.MasterNotRunningException;   </p>
<p>13. import org.apache.hadoop.hbase.ZooKeeperConnectionException;   </p>
<p>14. import org.apache.hadoop.hbase.client.Delete;   </p>
<p>15. import org.apache.hadoop.hbase.client.Get;   </p>
<p>16. import org.apache.hadoop.hbase.client.HBaseAdmin;   </p>
<p>17. import org.apache.hadoop.hbase.client.HTable;   </p>
<p>18. import org.apache.hadoop.hbase.client.HTablePool;   </p>
<p>19. import org.apache.hadoop.hbase.client.Put;   </p>
<p>20. import org.apache.hadoop.hbase.client.Result;   </p>
<p>21. import org.apache.hadoop.hbase.client.ResultScanner;   </p>
<p>22. import org.apache.hadoop.hbase.client.Scan;   </p>
<p>23. import org.apache.hadoop.hbase.filter.Filter;   </p>
<p>24. import org.apache.hadoop.hbase.filter.FilterList;   </p>
<p>25. import org.apache.hadoop.hbase.filter.SingleColumnValueFilter;   </p>
<p>26. import org.apache.hadoop.hbase.filter.CompareFilter.CompareOp;   </p>
<p>27. import org.apache.hadoop.hbase.util.Bytes;   </p>
<p>28.   </p>
<p>29. public class JinTaoTest {   </p>
<p>30.   </p>
<p>31.     public static Configuration configuration;   </p>
<p>32.     static {   </p>
<p>33.         configuration = HBaseConfiguration.create();   </p>
<p>34.         configuration.set("hbase.zookeeper.property.clientPort", "2181");   </p>
<p>35.         configuration.set("hbase.zookeeper.quorum", "192.168.1.100");   </p>
<p>36.         configuration.set("hbase.master", "192.168.1.100:600000");   </p>
<p>37.     }   </p>
<p>38.   </p>
<p>39.     public static void main(String[] args) {   </p>
<p>40.         // createTable("wujintao");   </p>
<p>41.         // insertData("wujintao");   </p>
<p>42.         // QueryAll("wujintao");   </p>
<p>43.         // QueryByCondition1("wujintao");   </p>
<p>44.         // QueryByCondition2("wujintao");   </p>
<p>45.         //QueryByCondition3("wujintao");   </p>
<p>46.         //deleteRow("wujintao","abcdef");   </p>
<p>47.         deleteByCondition("wujintao","abcdef");   </p>
<p>48.     }   </p>
<p>49.   </p>
<p>50.     /**  </p>
<p>51.      * 创建表  </p>
<p>52.      * @param tableName  </p>
<p>53.      */  </p>
<p>54.     public static void createTable(String tableName) {   </p>
<p>55.         System.out.println("start create table ......");   </p>
<p>56.         try {   </p>
<p>57.             HBaseAdmin hBaseAdmin = new HBaseAdmin(configuration);   </p>
<p>58.             if (hBaseAdmin.tableExists(tableName)) {// 如果存在要创建的表，那么先删除，再创建   </p>
<p>59.                 hBaseAdmin.disableTable(tableName);   </p>
<p>60.                 hBaseAdmin.deleteTable(tableName);   </p>
<p>61.                 System.out.println(tableName + " is exist,detele....");   </p>
<p>62.             }   </p>
<p>63.             HTableDescriptor tableDescriptor = new HTableDescriptor(tableName);   </p>
<p>64.             tableDescriptor.addFamily(new HColumnDescriptor("column1"));   </p>
<p>65.             tableDescriptor.addFamily(new HColumnDescriptor("column2"));   </p>
<p>66.             tableDescriptor.addFamily(new HColumnDescriptor("column3"));   </p>
<p>67.             hBaseAdmin.createTable(tableDescriptor);   </p>
<p>68.         } catch (MasterNotRunningException e) {   </p>
<p>69.             e.printStackTrace();   </p>
<p>70.         } catch (ZooKeeperConnectionException e) {   </p>
<p>71.             e.printStackTrace();   </p>
<p>72.         } catch (IOException e) {   </p>
<p>73.             e.printStackTrace();   </p>
<p>74.         }   </p>
<p>75.         System.out.println("end create table ......");   </p>
<p>76.     }   </p>
<p>77.   </p>
<p>78.     /**  </p>
<p>79.      * 插入数据  </p>
<p>80.      * @param tableName  </p>
<p>81.      */  </p>
<p>82.     public static void insertData(String tableName) {   </p>
<p>83.         System.out.println("start insert data ......");   </p>
<p>84.         HTablePool pool = new HTablePool(configuration, <span style="color:rgb(192,0,0)">1000</span>);   </p>
<p>85.         HTable table = (HTable) pool.getTable(tableName);   </p>
<p>86.         Put put = new Put("112233bbbcccc".getBytes());// 一个PUT代表一行数据，再NEW一个PUT表示第二行数据,每行一个唯一的ROWKEY，此处rowkey为put构造方法中传入的值   </p>
<p>87.         put.add("column1".getBytes(), null, "aaa".getBytes());// 本行数据的第一列   </p>
<p>88.         put.add("column2".getBytes(), null, "bbb".getBytes());// 本行数据的第三列   </p>
<p>89.         put.add("column3".getBytes(), null, "ccc".getBytes());// 本行数据的第三列   </p>
<p>90.         try {   </p>
<p>91.             table.put(put);   </p>
<p>92.         } catch (IOException e) {   </p>
<p>93.             e.printStackTrace();   </p>
<p>94.         }   </p>
<p>95.         System.out.println("end insert data ......");   </p>
<p>96.     }   </p>
<p>97.   </p>
<p>98.     /**  </p>
<p>99.      * 删除一张表  </p>
<p>100.      * @param tableName  </p>
<p>101.      */  </p>
<p>102.     public static void dropTable(String tableName) {   </p>
<p>103.         try {   </p>
<p>104.             HBaseAdmin admin = new HBaseAdmin(configuration);   </p>
<p>105.             admin.disableTable(tableName);   </p>
<p>106.             admin.deleteTable(tableName);   </p>
<p>107.         } catch (MasterNotRunningException e) {   </p>
<p>108.             e.printStackTrace();   </p>
<p>109.         } catch (ZooKeeperConnectionException e) {   </p>
<p>110.             e.printStackTrace();   </p>
<p>111.         } catch (IOException e) {   </p>
<p>112.             e.printStackTrace();   </p>
<p>113.         }   </p>
<p>114.   </p>
<p>115.     }   </p>
<p>116.     /**  </p>
<p>117.      * 根据 rowkey删除一条记录  </p>
<p>118.      * @param tablename  </p>
<p>119.      * @param rowkey  </p>
<p>120.      */  </p>
<p>121.      public static void deleteRow(String tablename, String rowkey)  {   </p>
<p>122.         try {   </p>
<p>123.             HTable table = new HTable(configuration, tablename);   </p>
<p>124.             List list = new ArrayList();   </p>
<p>125.             Delete d1 = new Delete(rowkey.getBytes());   </p>
<p>126.             list.add(d1);   </p>
<p>127.                </p>
<p>128.             table.delete(list);   </p>
<p>129.             System.out.println("删除行成功!");   </p>
<p>130.                </p>
<p>131.         } catch (IOException e) {   </p>
<p>132.             e.printStackTrace();   </p>
<p>133.         }   </p>
<p>134.            </p>
<p>135.   </p>
<p>136.     }   </p>
<p>137.   </p>
<p>138.      /**  </p>
<p>139.       * 组合条件删除  </p>
<p>140.       * @param tablename  </p>
<p>141.       * @param rowkey  </p>
<p>142.       */  </p>
<p>143.      public static void deleteByCondition(String tablename, String rowkey)  {   </p>
<p>144.             //目前还没有发现有效的API能够实现 根据非rowkey的条件删除 这个功能能，还有清空表全部数据的API操作   </p>
<p>145.   </p>
<p>146.     }   </p>
<p>147.   </p>
<p>148.   </p>
<p>149.     /**  </p>
<p>150.      * 查询所有数据  </p>
<p>151.      * @param tableName  </p>
<p>152.      */  </p>
<p>153.     public static void QueryAll(String tableName) {   </p>
<p>154.         HTablePool pool = new HTablePool(configuration, <span style="color:rgb(192,0,0)">1000</span>);   </p>
<p>155.         HTable table = (HTable) pool.getTable(tableName);   </p>
<p>156.         try {   </p>
<p>157.             ResultScanner rs = table.getScanner(new Scan());   </p>
<p>158.             for (Result r : rs) {   </p>
<p>159.                 System.out.println("获得到rowkey:" + new String(r.getRow()));   </p>
<p>160.                 for (KeyValue keyValue : r.raw()) {   </p>
<p>161.                     System.out.println("列：" + new String(keyValue.getFamily())   </p>
<p>162.                             + "====值:" + new String(keyValue.getValue()));   </p>
<p>163.                 }   </p>
<p>164.             }   </p>
<p>165.         } catch (IOException e) {   </p>
<p>166.             e.printStackTrace();   </p>
<p>167.         }   </p>
<p>168.     }   </p>
<p>169.   </p>
<p>170.     /**  </p>
<p>171.      * 单条件查询,根据rowkey查询唯一一条记录  </p>
<p>172.      * @param tableName  </p>
<p>173.      */  </p>
<p>174.     public static void QueryByCondition1(String tableName) {   </p>
<p>175.   </p>
<p>176.         HTablePool pool = new HTablePool(configuration, <span style="color:rgb(192,0,0)">1000</span>);   </p>
<p>177.         HTable table = (HTable) pool.getTable(tableName);   </p>
<p>178.         try {   </p>
<p>179.             Get scan = new Get("abcdef".getBytes());// 根据rowkey查询   </p>
<p>180.             Result r = table.get(scan);   </p>
<p>181.             System.out.println("获得到rowkey:" + new String(r.getRow()));   </p>
<p>182.             for (KeyValue keyValue : r.raw()) {   </p>
<p>183.                 System.out.println("列：" + new String(keyValue.getFamily())   </p>
<p>184.                         + "====值:" + new String(keyValue.getValue()));   </p>
<p>185.             }   </p>
<p>186.         } catch (IOException e) {   </p>
<p>187.             e.printStackTrace();   </p>
<p>188.         }   </p>
<p>189.     }   </p>
<p>190.   </p>
<p>191.     /**  </p>
<p>192.      * 单条件按查询，查询多条记录  </p>
<p>193.      * @param tableName  </p>
<p>194.      */  </p>
<p>195.     public static void QueryByCondition2(String tableName) {   </p>
<p>196.   </p>
<p>197.         try {   </p>
<p>198.             HTablePool pool = new HTablePool(configuration, <span style="color:rgb(192,0,0)">1000</span>);   </p>
<p>199.             HTable table = (HTable) pool.getTable(tableName);   </p>
<p>200.             Filter filter = new SingleColumnValueFilter(Bytes   </p>
<p>201.                     .toBytes("column1"), null, CompareOp.EQUAL, Bytes   </p>
<p>202.                     .toBytes("aaa")); // 当列column1的值为aaa时进行查询   </p>
<p>203.             Scan s = new Scan();   </p>
<p>204.             s.setFilter(filter);   </p>
<p>205.             ResultScanner rs = table.getScanner(s);   </p>
<p>206.             for (Result r : rs) {   </p>
<p>207.                 System.out.println("获得到rowkey:" + new String(r.getRow()));   </p>
<p>208.                 for (KeyValue keyValue : r.raw()) {   </p>
<p>209.                     System.out.println("列：" + new String(keyValue.getFamily())   </p>
<p>210.                             + "====值:" + new String(keyValue.getValue()));   </p>
<p>211.                 }   </p>
<p>212.             }   </p>
<p>213.         } catch (Exception e) {   </p>
<p>214.             e.printStackTrace();   </p>
<p>215.         }   </p>
<p>216.   </p>
<p>217.     }   </p>
<p>218.   </p>
<p>219.     /**  </p>
<p>220.      * 组合条件查询  </p>
<p>221.      * @param tableName  </p>
<p>222.      */  </p>
<p>223.     public static void QueryByCondition3(String tableName) {   </p>
<p>224.   </p>
<p>225.         try {   </p>
<p>226.             HTablePool pool = new HTablePool(configuration, <span style="color:rgb(192,0,0)">1000</span>);   </p>
<p>227.             HTable table = (HTable) pool.getTable(tableName);   </p>
<p>228.   </p>
<p>229.             List&lt;Filter&gt; filters = new ArrayList&lt;Filter&gt;();   </p>
<p>230.   </p>
<p>231.             Filter filter1 = new SingleColumnValueFilter(Bytes   </p>
<p>232.                     .toBytes("column1"), null, CompareOp.EQUAL, Bytes   </p>
<p>233.                     .toBytes("aaa"));   </p>
<p>234.             filters.add(filter1);   </p>
<p>235.   </p>
<p>236.             Filter filter2 = new SingleColumnValueFilter(Bytes   </p>
<p>237.                     .toBytes("column2"), null, CompareOp.EQUAL, Bytes   </p>
<p>238.                     .toBytes("bbb"));   </p>
<p>239.             filters.add(filter2);   </p>
<p>240.   </p>
<p>241.             Filter filter3 = new SingleColumnValueFilter(Bytes   </p>
<p>242.                     .toBytes("column3"), null, CompareOp.EQUAL, Bytes   </p>
<p>243.                     .toBytes("ccc"));   </p>
<p>244.             filters.add(filter3);   </p>
<p>245.   </p>
<p>246.             FilterList filterList1 = new FilterList(filters);   </p>
<p>247.   </p>
<p>248.             Scan scan = new Scan();   </p>
<p>249.             scan.setFilter(filterList1);   </p>
<p>250.             ResultScanner rs = table.getScanner(scan);   </p>
<p>251.             for (Result r : rs) {   </p>
<p>252.                 System.out.println("获得到rowkey:" + new String(r.getRow()));   </p>
<p>253.                 for (KeyValue keyValue : r.raw()) {   </p>
<p>254.                     System.out.println("列：" + new String(keyValue.getFamily())   </p>
<p>255.                             + "====值:" + new String(keyValue.getValue()));   </p>
<p>256.                 }   </p>
<p>257.             }   </p>
<p>258.             rs.close();   </p>
<p>259.   </p>
<p>260.         } catch (Exception e) {   </p>
<p>261.             e.printStackTrace();   </p>
<p>262.         }   </p>
<p>263.   </p>
<p>264.     }   </p>
<p>265.   </p>
<p>266. }  </p>
<p>package com.wujintao.hbase.test;</p>
<p> </p>
<p>import java.io.IOException;</p>
<p>import java.util.ArrayList;</p>
<p>import java.util.List;</p>
<p> </p>
<p>import org.apache.hadoop.conf.Configuration;</p>
<p>import org.apache.hadoop.hbase.HBaseConfiguration;</p>
<p>import org.apache.hadoop.hbase.HColumnDescriptor;</p>
<p>import org.apache.hadoop.hbase.HTableDescriptor;</p>
<p>import org.apache.hadoop.hbase.KeyValue;</p>
<p>import org.apache.hadoop.hbase.MasterNotRunningException;</p>
<p>import org.apache.hadoop.hbase.ZooKeeperConnectionException;</p>
<p>import org.apache.hadoop.hbase.client.Delete;</p>
<p>import org.apache.hadoop.hbase.client.Get;</p>
<p>import org.apache.hadoop.hbase.client.HBaseAdmin;</p>
<p>import org.apache.hadoop.hbase.client.HTable;</p>
<p>import org.apache.hadoop.hbase.client.HTablePool;</p>
<p>import org.apache.hadoop.hbase.client.Put;</p>
<p>import org.apache.hadoop.hbase.client.Result;</p>
<p>import org.apache.hadoop.hbase.client.ResultScanner;</p>
<p>import org.apache.hadoop.hbase.client.Scan;</p>
<p>import org.apache.hadoop.hbase.filter.Filter;</p>
<p>import org.apache.hadoop.hbase.filter.FilterList;</p>
<p>import org.apache.hadoop.hbase.filter.SingleColumnValueFilter;</p>
<p>import org.apache.hadoop.hbase.filter.CompareFilter.CompareOp;</p>
<p>import org.apache.hadoop.hbase.util.Bytes;</p>
<p> </p>
<p>public class JinTaoTest {</p>
<p> </p>
<p>public static Configuration configuration;</p>
<p>static {</p>
<p>configuration = HBaseConfiguration.create();</p>
<p>configuration.set("hbase.zookeeper.property.clientPort", "2181");</p>
<p>configuration.set("hbase.zookeeper.quorum", "192.168.1.100");</p>
<p>configuration.set("hbase.master", "192.168.1.100:600000");</p>
<p>}</p>
<p> </p>
<p>public static void main(String[] args) {</p>
<p>// createTable("wujintao");</p>
<p>// insertData("wujintao");</p>
<p>// QueryAll("wujintao");</p>
<p>// QueryByCondition1("wujintao");</p>
<p>// QueryByCondition2("wujintao");</p>
<p>//QueryByCondition3("wujintao");</p>
<p>//deleteRow("wujintao","abcdef");</p>
<p>deleteByCondition("wujintao","abcdef");</p>
<p>}</p>
<p> </p>
<p>/**</p>
<p> * 创建表</p>
<p> * @param tableName</p>
<p> */</p>
<p>public static void createTable(String tableName) {</p>
<p>System.out.println("start create table ......");</p>
<p>try {</p>
<p>HBaseAdmin hBaseAdmin = new HBaseAdmin(configuration);</p>
<p>if (hBaseAdmin.tableExists(tableName)) {// 如果存在要创建的表，那么先删除，再创建</p>
<p>hBaseAdmin.disableTable(tableName);</p>
<p>hBaseAdmin.deleteTable(tableName);</p>
<p>System.out.println(tableName + " is exist,detele....");</p>
<p>}</p>
<p>HTableDescriptor tableDescriptor = new HTableDescriptor(tableName);</p>
<p>tableDescriptor.addFamily(new HColumnDescriptor("column1"));</p>
<p>tableDescriptor.addFamily(new HColumnDescriptor("column2"));</p>
<p>tableDescriptor.addFamily(new HColumnDescriptor("column3"));</p>
<p>hBaseAdmin.createTable(tableDescriptor);</p>
<p>} catch (MasterNotRunningException e) {</p>
<p>e.printStackTrace();</p>
<p>} catch (ZooKeeperConnectionException e) {</p>
<p>e.printStackTrace();</p>
<p>} catch (IOException e) {</p>
<p>e.printStackTrace();</p>
<p>}</p>
<p>System.out.println("end create table ......");</p>
<p>}</p>
<p> </p>
<p>/**</p>
<p> * 插入数据</p>
<p> * @param tableName</p>
<p> */</p>
<p>public static void insertData(String tableName) {</p>
<p>System.out.println("start insert data ......");</p>
<p>HTablePool pool = new HTablePool(configuration, 1000);</p>
<p>HTable table = (HTable) pool.getTable(tableName);</p>
<p>Put put = new Put("112233bbbcccc".getBytes());// 一个PUT代表一行数据，再NEW一个PUT表示第二行数据,每行一个唯一的ROWKEY，此处rowkey为put构造方法中传入的值</p>
<p>put.add("column1".getBytes(), null, "aaa".getBytes());// 本行数据的第一列</p>
<p>put.add("column2".getBytes(), null, "bbb".getBytes());// 本行数据的第三列</p>
<p>put.add("column3".getBytes(), null, "ccc".getBytes());// 本行数据的第三列</p>
<p>try {</p>
<p>table.put(put);</p>
<p>} catch (IOException e) {</p>
<p>e.printStackTrace();</p>
<p>}</p>
<p>System.out.println("end insert data ......");</p>
<p>}</p>
<p> </p>
<p>/**</p>
<p> * 删除一张表</p>
<p> * @param tableName</p>
<p> */</p>
<p>public static void dropTable(String tableName) {</p>
<p>try {</p>
<p>HBaseAdmin admin = new HBaseAdmin(configuration);</p>
<p>admin.disableTable(tableName);</p>
<p>admin.deleteTable(tableName);</p>
<p>} catch (MasterNotRunningException e) {</p>
<p>e.printStackTrace();</p>
<p>} catch (ZooKeeperConnectionException e) {</p>
<p>e.printStackTrace();</p>
<p>} catch (IOException e) {</p>
<p>e.printStackTrace();</p>
<p>}</p>
<p> </p>
<p>}</p>
<p>/**</p>
<p> * 根据 rowkey删除一条记录</p>
<p> * @param tablename</p>
<p> * @param rowkey</p>
<p> */</p>
<p> public static void deleteRow(String tablename, String rowkey)  {</p>
<p>try {</p>
<p>HTable table = new HTable(configuration, tablename);</p>
<p>List list = new ArrayList();</p>
<p>Delete d1 = new Delete(rowkey.getBytes());</p>
<p>list.add(d1);</p>
<p></p>
<p>table.delete(list);</p>
<p>System.out.println("删除行成功!");</p>
<p></p>
<p>} catch (IOException e) {</p>
<p>e.printStackTrace();</p>
<p>}</p>
<p></p>
<p> </p>
<p>}</p>
<p> </p>
<p> /**</p>
<p>  * 组合条件删除</p>
<p>  * @param tablename</p>
<p>  * @param rowkey</p>
<p>  */</p>
<p> public static void deleteByCondition(String tablename, String rowkey)  {</p>
<p>//目前还没有发现有效的API能够实现 根据非rowkey的条件删除 这个功能能，还有清空表全部数据的API操作</p>
<p> </p>
<p>}</p>
<p> </p>
<p> </p>
<p>/**</p>
<p> * 查询所有数据</p>
<p> * @param tableName</p>
<p> */</p>
<p>public static void QueryAll(String tableName) {</p>
<p>HTablePool pool = new HTablePool(configuration, 1000);</p>
<p>HTable table = (HTable) pool.getTable(tableName);</p>
<p>try {</p>
<p>ResultScanner rs = table.getScanner(new Scan());</p>
<p>for (Result r : rs) {</p>
<p>System.out.println("获得到rowkey:" + new String(r.getRow()));</p>
<p>for (KeyValue keyValue : r.raw()) {</p>
<p>System.out.println("列：" + new String(keyValue.getFamily())</p>
<p>+ "====值:" + new String(keyValue.getValue()));</p>
<p>}</p>
<p>}</p>
<p>} catch (IOException e) {</p>
<p>e.printStackTrace();</p>
<p>}</p>
<p>}</p>
<p> </p>
<p>/**</p>
<p> * 单条件查询,根据rowkey查询唯一一条记录</p>
<p> * @param tableName</p>
<p> */</p>
<p>public static void QueryByCondition1(String tableName) {</p>
<p> </p>
<p>HTablePool pool = new HTablePool(configuration, 1000);</p>
<p>HTable table = (HTable) pool.getTable(tableName);</p>
<p>try {</p>
<p>Get scan = new Get("abcdef".getBytes());// 根据rowkey查询</p>
<p>Result r = table.get(scan);</p>
<p>System.out.println("获得到rowkey:" + new String(r.getRow()));</p>
<p>for (KeyValue keyValue : r.raw()) {</p>
<p>System.out.println("列：" + new String(keyValue.getFamily())</p>
<p>+ "====值:" + new String(keyValue.getValue()));</p>
<p>}</p>
<p>} catch (IOException e) {</p>
<p>e.printStackTrace();</p>
<p>}</p>
<p>}</p>
<p> </p>
<p>/**</p>
<p> * 单条件按查询，查询多条记录</p>
<p> * @param tableName</p>
<p> */</p>
<p>public static void QueryByCondition2(String tableName) {</p>
<p> </p>
<p>try {</p>
<p>HTablePool pool = new HTablePool(configuration, 1000);</p>
<p>HTable table = (HTable) pool.getTable(tableName);</p>
<p>Filter filter = new SingleColumnValueFilter(Bytes</p>
<p>.toBytes("column1"), null, CompareOp.EQUAL, Bytes</p>
<p>.toBytes("aaa")); // 当列column1的值为aaa时进行查询</p>
<p>Scan s = new Scan();</p>
<p>s.setFilter(filter);</p>
<p>ResultScanner rs = table.getScanner(s);</p>
<p>for (Result r : rs) {</p>
<p>System.out.println("获得到rowkey:" + new String(r.getRow()));</p>
<p>for (KeyValue keyValue : r.raw()) {</p>
<p>System.out.println("列：" + new String(keyValue.getFamily())</p>
<p>+ "====值:" + new String(keyValue.getValue()));</p>
<p>}</p>
<p>}</p>
<p>} catch (Exception e) {</p>
<p>e.printStackTrace();</p>
<p>}</p>
<p> </p>
<p>}</p>
<p> </p>
<p>/**</p>
<p> * 组合条件查询</p>
<p> * @param tableName</p>
<p> */</p>
<p>public static void QueryByCondition3(String tableName) {</p>
<p> </p>
<p>try {</p>
<p>HTablePool pool = new HTablePool(configuration, 1000);</p>
<p>HTable table = (HTable) pool.getTable(tableName);</p>
<p> </p>
<p>List&lt;Filter&gt; filters = new ArrayList&lt;Filter&gt;();</p>
<p> </p>
<p>Filter filter1 = new SingleColumnValueFilter(Bytes</p>
<p>.toBytes("column1"), null, CompareOp.EQUAL, Bytes</p>
<p>.toBytes("aaa"));</p>
<p>filters.add(filter1);</p>
<p> </p>
<p>Filter filter2 = new SingleColumnValueFilter(Bytes</p>
<p>.toBytes("column2"), null, CompareOp.EQUAL, Bytes</p>
<p>.toBytes("bbb"));</p>
<p>filters.add(filter2);</p>
<p> </p>
<p>Filter filter3 = new SingleColumnValueFilter(Bytes</p>
<p>.toBytes("column3"), null, CompareOp.EQUAL, Bytes</p>
<p>.toBytes("ccc"));</p>
<p>filters.add(filter3);</p>
<p> </p>
<p>FilterList filterList1 = new FilterList(filters);</p>
<p> </p>
<p>Scan scan = new Scan();</p>
<p>scan.setFilter(filterList1);</p>
<p>ResultScanner rs = table.getScanner(scan);</p>
<p>for (Result r : rs) {</p>
<p>System.out.println("获得到rowkey:" + new String(r.getRow()));</p>
<p>for (KeyValue keyValue : r.raw()) {</p>
<p>System.out.println("列：" + new String(keyValue.getFamily())</p>
<p>+ "====值:" + new String(keyValue.getValue()));</p>
<p>}</p>
<p>}</p>
<p>rs.close();</p>
<p> </p>
<p>} catch (Exception e) {</p>
<p>e.printStackTrace();</p>
<p>}</p>
<p> </p>
<p>}</p>
<p> </p>
<p>}</p>
<p> 注意：可能大家没看到更新数据的操作，其实更新的操作跟添加完全一致，只不过是添加呢rowkey不存在，更新呢rowkey已经存在，并且timstamp相同的情况下，还有就是目前好像还没办法实现hbase数据的分页查询，不知道有没有人知道怎么做</p>
<p> </p>
<p>HBase性能优化建议：</p>
<p> 针对前面的代码，有很多不足之处，在此我就不修改上面的代码了，只是提出建议的地方，大家自己加上</p>
<p>   1)配置</p>
<p>  当你调用create方法时将会加载两个配置文件:hbase-default.xml and hbase-site.xml,利用的是当前的java类路径， 代码中configuration设置的这些配置将会覆盖hbase-default.xml和hbase-site.xml中相同的配置,如果两个配置文件都存在并且都设置好了相应参上面的属性下面的属性即可</p>
<p> </p>
<p> 2)关于建表</p>
<p>   </p>
<p>public void createTable(HTableDescriptor desc)</p>
<p> </p>
<p>HTableDescriptor 代表的是表的schema, 提供的方法中比较有用的有</p>
<p>setMaxFileSize，指定最大的region size</p>
<p>setMemStoreFlushSize 指定memstore flush到HDFS上的文件大小</p>
<p>增加family通过 addFamily方法</p>
<p>  </p>
<p>public void addFamily(final HColumnDescriptor family)</p>
<p> </p>
<p>HColumnDescriptor 代表的是column的schema，提供的方法比较常用的有</p>
<p>setTimeToLive:指定最大的TTL,单位是ms,过期数据会被自动删除。</p>
<p>setInMemory:指定是否放在内存中，对小表有用，可用于提高效率。默认关闭</p>
<p>setBloomFilter:指定是否使用BloomFilter,可提高随机查询效率。默认关闭</p>
<p>setCompressionType:设定数据压缩类型。默认无压缩。</p>
<p>setMaxVersions:指定数据最大保存的版本个数。默认为3。</p>
<p> </p>
<p>注意的是，一般我们不去setInMemory为true,默认是关闭的</p>
<p>3)关于入库</p>
<p>   官方建议</p>
<p> table.setAutoFlush(false); //数据入库之前先设置此项为false</p>
<p> table.setflushCommits();//入库完成后，手动刷入数据</p>
<p>注意：</p>
<p>  在入库过程中，put.setWriteToWAL(true/flase);</p>
<p>  关于这一项如果不希望大量数据在存储过程中丢失，建议设置为true,如果仅是在测试演练阶段，为了节省入库时间建议设置为false</p>
<p>4)关于获取表实例</p>
<p>HTablePool pool = new HTablePool(configuration, Integer.MAX_VALUE);</p>
<p>HTable table = (HTable) pool.getTable(tableName);</p>
<p>建议用表连接池的方式获取表，具体池有什么作用，我想用过数据库连接池的同学都知道，我就不再重复</p>
<p>不建议使用new HTable(configuration,tableName);的方式获取表</p>
<p>5)关于查询</p>
<p> 建议每个查询语句都放入try catch语句块，并且finally中要进行关闭ResultScanner实例以及将不使用的表重新放入到HTablePool中的操作，具体做法如下</p>
<p>Java代码  <a target="_blank" href="" rel="nofollow" title="收藏这段代码"></a></p>
<p>1. public static void QueryAll(String tableName) {   </p>
<p>2.         HTablePool pool = new HTablePool(configuration, Integer.MAX_VALUE);   </p>
<p>3.         HTable table = null;   </p>
<p>4.         ResultScanner rs = null;   </p>
<p>5.         try {   </p>
<p>6.             Scan scan = new Scan();   </p>
<p>7.             table = (HTable) pool.getTable(tableName);   </p>
<p>8.             rs = table.getScanner(scan);   </p>
<p>9.             for (Result r : rs) {   </p>
<p>10.                 System.out.println("获得到rowkey:" + new String(r.getRow()));   </p>
<p>11.                 for (KeyValue keyValue : r.raw()) {   </p>
<p>12.                     System.out.println("列：" + new String(keyValue.getFamily())   </p>
<p>13.                             + "====值:" + new String(keyValue.getValue()));   </p>
<p>14.                 }   </p>
<p>15.             }   </p>
<p>16.         } catch (IOException e) {   </p>
<p>17.             e.printStackTrace();   </p>
<p>18.         }finally{   </p>
<p>19.             rs.close();// 最后还得关闭   </p>
<p>20.             pool.putTable(table); //实际应用过程中，pool获取实例的方式应该抽取为单例模式的，不应在每个方法都重新获取一次(单例明白？就是抽取到专门获取pool的逻辑类中，具体逻辑为如果pool存在着直接使用，如果不存在则new)   </p>
<p>21.         }   </p>
<p>22.     }  </p>
<p>public static void QueryAll(String tableName) {</p>
<p>HTablePool pool = new HTablePool(configuration, Integer.MAX_VALUE);</p>
<p>HTable table = null;</p>
<p>ResultScanner rs = null;</p>
<p>try {</p>
<p>Scan scan = new Scan();</p>
<p>table = (HTable) pool.getTable(tableName);</p>
<p>rs = table.getScanner(scan);</p>
<p>for (Result r : rs) {</p>
<p>System.out.println("获得到rowkey:" + new String(r.getRow()));</p>
<p>for (KeyValue keyValue : r.raw()) {</p>
<p>System.out.println("列：" + new String(keyValue.getFamily())</p>
<p>+ "====值:" + new String(keyValue.getValue()));</p>
<p>}</p>
<p>}</p>
<p>} catch (IOException e) {</p>
<p>e.printStackTrace();</p>
<p>}finally{</p>
<p>rs.close();// 最后还得关闭</p>
<p>pool.putTable(table); //实际应用过程中，pool获取实例的方式应该抽取为单例模式的，不应在每个方法都重新获取一次(单例明白？就是抽取到专门获取pool的逻辑类中，具体逻辑为如果pool存在着直接使用，如果不存在则new)</p>
<p>}</p>
<p>}</p>
<p> </p>
<p> 所以，以上代码有缺陷的地方，感兴趣的同学可以针对优化建议作出相应修改</p>
<p>二十四、 基于Hbase存储的分布式消息(IM)系统-JABase</p>
<p> </p>
<p> </p>
<p> <span style="color:rgb(64,64,64)">前段日子看了在<span style="font-family:Verdana">highscalability.com</span><span style="font-family:宋体">上一篇</span></span><a target="_blank" href="http://highscalability.com/blog/2010/11/16/facebooks-new-real-time-messaging-system-hbase-to-store-135.html" rel="nofollow"><span style="color:rgb(0,0,255)">介绍<span style="font-family:Verdana">facebook</span><span style="font-family:宋体">消息系统的文章</span></span></a><span style="color:rgb(64,64,64)">，一夜之后被无数个网站无数次的转载，现如今<span style="font-family:Verdana">facebook</span><span style="font-family:宋体">的任何一个话题都会引起很多人的关注，但我对只对这文章里面没有说明的部分比较感兴趣，系统里是怎么获得即时消息的？</span><span style="font-family:Verdana">PHP</span><span style="font-family:宋体">监听器？开启很多个监听器服务？推模式？拉模式？跟</span><span style="font-family:Verdana">Twitter</span><span style="font-family:宋体">一样采用消息中间件？对此有了些疑问，期待日后有人能给出明确解答。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)"> </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    <span style="font-family:宋体">这个叫</span><span style="font-family:Verdana">JABase</span><span style="font-family:宋体">的 东东 能给我一些启示，</span><span style="font-family:Verdana">JABase</span><span style="font-family:宋体">是应用在分布式</span><span style="font-family:Verdana">IM</span><span style="font-family:宋体">系统中的中间件，可以支持大规模的集群环境的伸缩性架构，并采用</span><span style="font-family:Verdana">Java</span><span style="font-family:宋体">语言来实现的，</span><span style="font-family:Verdana">JABase</span><span style="font-family:宋体">是介于分布式数据存储</span><span style="font-family:Verdana">(HBase/HDFS)</span><span style="font-family:宋体">和即时消息收发</span><span style="font-family:Verdana">(Erlbase/XMPP Server)</span><span style="font-family:宋体">的一个中介体，</span><span style="font-family:Verdana">JABase</span><span style="font-family:宋体">将</span><span style="font-family:Verdana">XMPP Server</span><span style="font-family:宋体">中的收</span><span style="font-family:Verdana">/</span><span style="font-family:宋体">发消息存放在</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">中，这点与</span><span style="font-family:Verdana">facebook</span><span style="font-family:宋体">消息系统文章中提到的极为相似。另外提一下，</span><span style="font-family:Verdana">JABase</span><span style="font-family:宋体">给出的方案中的</span><span style="font-family:Verdana">IM</span><span style="font-family:宋体">消息服务器</span><span style="font-family:Verdana">(XMPP Server) Erlbase</span><span style="font-family:宋体">是采用 </span><span style="font-family:Verdana">Erlang </span><span style="font-family:宋体">语言编写，有点像</span><span style="font-family:Verdana">Twitter</span><span style="font-family:宋体">。</span></span></p>
<p><span style="color:rgb(64,64,64)">整个系统架构由<span style="font-family:Verdana">HBase/HDFS</span><span style="font-family:宋体">、</span><span style="font-family:Verdana">JABase</span><span style="font-family:宋体">、</span><span style="font-family:Verdana">ErlBase </span><span style="font-family:宋体">这</span><span style="font-family:Verdana">3</span><span style="font-family:宋体">大部分组成，整体架构如图所示：</span></span></p>
<p><span style="color:rgb(64,64,64)"> </span></p>
<p><span style="color:rgb(64,64,64)">除了需要安装<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">HDFS</span><span style="font-family:宋体">一些主要部件以外，还需要有以下一些组件支持：</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">   – ejabberd-2.0.3.tar.gz    (Erlang)</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">   – erlbase-1.0.tar.gz         (Erlang)</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">   – jabase-1.0.tar.gz           (Java)</span></p>
<p><span style="color:rgb(64,64,64)">对<span style="font-family:Verdana">JABase</span><span style="font-family:宋体">项目的了解，结合目前采用的架构引发出</span><span style="font-family:Verdana">2</span><span style="font-family:宋体">个的设想：</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    1<span style="font-family:宋体">、</span><span style="font-family:Verdana">XMPP</span><span style="font-family:宋体">与</span><span style="font-family:Verdana">MQ </span><span style="font-family:宋体">可扩展性的比较，有时间需要坐下来跟大家讨论一下。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    2<span style="font-family:宋体">、</span><span style="font-family:Verdana">MQ</span><span style="font-family:宋体">的性能扩展 </span><span style="font-family:Verdana">a)</span><span style="font-family:宋体">前端集成缓存 </span><span style="font-family:Verdana">b)</span><span style="font-family:宋体">后端消息存储，看看这么加才对我们有真正的帮助。</span></span></p>
<p> </p>
<p> </p>
<p>二十五、 HBase入门篇</p>
<p> <span style="color:rgb(64,64,64)">HBase<span style="font-family:宋体">是什么？ </span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">HBase<span style="font-family:宋体">是</span><span style="font-family:Verdana">Apache Hadoop</span><span style="font-family:宋体">中的一个子项目，</span><span style="font-family:Verdana">Hbase</span><span style="font-family:宋体">依托于</span><span style="font-family:Verdana">Hadoop</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">HDFS</span><span style="font-family:宋体">作为最基本存储基础单元，通过使用</span><span style="font-family:Verdana">hadoop</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">DFS</span><span style="font-family:宋体">工具就可以看到这些这些数据 存储文件夹的结构</span><span style="font-family:Verdana">,</span><span style="font-family:宋体">还可以通过</span><span style="font-family:Verdana">Map/Reduce</span><span style="font-family:宋体">的框架</span><span style="font-family:Verdana">(</span><span style="font-family:宋体">算法</span><span style="font-family:Verdana">)</span><span style="font-family:宋体">对</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">进行操作，如右侧的图所示：</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">HBase<span style="font-family:宋体">在产品中还包含了</span><span style="font-family:Verdana">Jetty</span><span style="font-family:宋体">，在</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">启动时采用嵌入式的方式来启动</span><span style="font-family:Verdana">Jetty</span><span style="font-family:宋体">，因此可以通过</span><span style="font-family:Verdana">web</span><span style="font-family:宋体">界面对</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">进行管理和查看当前运行的一些状态，非常轻巧。</span></span></p>
<p><span style="color:rgb(64,64,64)">为什么采用<span style="font-family:Verdana">HBase</span></span><span style="color:rgb(64,64,64)">？</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">HBase <span style="font-family:宋体">不同于一般的关系数据库</span><span style="font-family:Verdana">,</span><span style="font-family:宋体">它是一个适合于非结构化数据存储的数据库</span><span style="font-family:Verdana">.</span><span style="font-family:宋体">所谓非结构化数据存储就是说</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">是基于列的而不是基于行的模式，这样方面读写你的大数据内容。</span></span></p>
<p><span style="color:rgb(64,64,64)">HBase<span style="font-family:宋体">是介于</span><span style="font-family:Verdana">Map Entry(key &amp; value)</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">DB Row</span><span style="font-family:宋体">之间的一种数据存储方式。就点有点类似于现在流行的</span><span style="font-family:Verdana">Memcache</span><span style="font-family:宋体">，但不仅仅是简单的一个</span><span style="font-family:Verdana">key</span><span style="font-family:宋体">对应一个 </span><span style="font-family:Verdana">value</span><span style="font-family:宋体">，你很可能需要存储多个属性的数据结构，但没有传统数据库表中那么多的关联关系，这就是所谓的松散数据。</span></span></p>
<p><span style="color:rgb(64,64,64)">简单来说，你在<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">中的表创建的可以看做是一张很大的表，而这个表的属性可以根据需求去动态增加，在</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">中没有表与表之间关联查询。你只需要 告诉你的数据存储到</span><span style="font-family:Verdana">Hbase</span><span style="font-family:宋体">的那个</span><span style="font-family:Verdana">column families </span><span style="font-family:宋体">就可以了，不需要指定它的具体类型：</span><span style="font-family:Verdana">char,varchar,int,tinyint,text</span><span style="font-family:宋体">等等。但是你需要注意</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">中不包含事务此类的功 能。</span></span></p>
<p><span style="color:rgb(64,64,64)">Apache HBase <span style="font-family:宋体">和</span><span style="font-family:Verdana">Google Bigtable </span><span style="font-family:宋体">有非常相似的地方，一个数据行拥有一个可选择的键和任意数量的列。表是疏松的存储的，因此用户可以给行定义各种不同的列，对于这样的功能在大项目中非常实用，可以简化设计和升级的成本。</span></span></p>
<p><span style="color:rgb(64,64,64)">如何运行<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">？</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">从 <span style="font-family:Verdana">Apache</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的镜像网站上下载一个稳定版本的</span><span style="font-family:Verdana">HBase http://mirrors.devlib.org/apache/hbase/stable/hbase-0.20.6.tar.gz</span><span style="font-family:宋体">， 下载完成后，对其进行解压缩。确定你的机器中已经正确的安装了</span><span style="font-family:Verdana">Java SDK</span><span style="font-family:宋体">、</span><span style="font-family:Verdana">SSH</span><span style="font-family:宋体">，否则将无法正常运行。</span></span></p>
<p><span style="color:rgb(64,64,64)">$ cd /work/hbase</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">进入此目录</span></p>
<p><span style="color:rgb(64,64,64)">$ vim conf/hbase-env.sh</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">export JAVA_HOME=/JDK_PATH</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">编辑 <span style="font-family:Verdana">conf/hbase-env.sh </span><span style="font-family:宋体">文件</span><span style="font-family:Verdana">,</span><span style="font-family:宋体">将</span><span style="font-family:Verdana">JAVA_HOME</span><span style="font-family:宋体">修改为你的</span><span style="font-family:Verdana">JDK</span><span style="font-family:宋体">安装目录</span></span></p>
<p><span style="color:rgb(64,64,64)">$ vim conf/regionservers</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">输入你的所有<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">服务器名</span><span style="font-family:Verdana">,localhost,</span><span style="font-family:宋体">或者是</span><span style="font-family:Verdana">ip</span><span style="font-family:宋体">地址</span></span></p>
<p><span style="color:rgb(64,64,64)">$ bin/start-hbase.sh</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">启动<span style="font-family:Verdana">hbase, </span><span style="font-family:宋体">中间需要你输入两次密码，也可以进行设置不需要输入密码，启动成功，如图所示：</span></span><span style="color:rgb(64,64,64)"><br>
</span></p>
<p><span style="color:rgb(64,64,64)">$ bin/hbase rest start</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">启动<span style="font-family:Verdana">hbase REST</span><span style="font-family:宋体">服务后就可以通过对</span><span style="font-family:Verdana">uri: http://localhost:60050/api/ </span><span style="font-family:宋体">的通用</span><span style="font-family:Verdana">REST</span><span style="font-family:宋体">操作</span><span style="font-family:Verdana">(GET/POST/PUT/DELETE)</span><span style="font-family:宋体">实现对</span><span style="font-family:Verdana">hbase</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">REST</span><span style="font-family:宋体">形式数据操作</span><span style="font-family:Verdana">.</span></span></p>
<p><span style="color:rgb(64,64,64)">也可以输入以下指令进入<span style="font-family:Verdana">HQL</span><span style="font-family:宋体">指令模式</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">$ bin/hbase shell</span></p>
<p><span style="color:rgb(64,64,64)">$ bin/stop-hbase.sh</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">关闭<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">服务</span></span></p>
<p><span style="color:rgb(64,64,64)">启动时存在的问题</span></p>
<p><span style="color:rgb(64,64,64)">由于<span style="font-family:Verdana">linux</span><span style="font-family:宋体">系统的主机名配置不正确，在运行</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">服务器中可能存在的问题，如图所示：</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">2010-11-05 11:10:20,189 ERROR org.apache.hadoop.hbase.master.HMaster: Can not start master</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">java.net.UnknownHostException: ubuntu-server216: ubuntu-server216</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">表示你的主机名不正确，你可以先查看一下 <span style="font-family:Verdana">/etc/hosts/</span><span style="font-family:宋体">中名称是什么，再用 </span><span style="font-family:Verdana">hostname </span><span style="font-family:宋体">命令进行修改， </span><span style="font-family:Verdana">hostname you_server_name</span></span></p>
<p><span style="color:rgb(64,64,64)">查看运行状态</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">1<span style="font-family:宋体">、如果你需要对</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的日志进行监控你可以查看 </span><span style="font-family:Verdana">hbase.x.x./logs/</span><span style="font-family:宋体">下的日志文件，可以使用</span><span style="font-family:Verdana">tail -f </span><span style="font-family:宋体">来查看。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">2<span style="font-family:宋体">、通过 </span><span style="font-family:Verdana">web</span><span style="font-family:宋体">方式查看运行在 </span><span style="font-family:Verdana">HBase </span><span style="font-family:宋体">下的</span><span style="font-family:Verdana">zookeeper  http://localhost:60010/zk.jsp</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">3<span style="font-family:宋体">、如果你需要查看当前的运行状态可以通过</span><span style="font-family:Verdana">web</span><span style="font-family:宋体">的方式对</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">服务器进行查看，如图所示：</span></span><span style="color:rgb(64,64,64)"><br>
</span></p>
<p><span style="color:rgb(255,255,255); background:rgb(0,0,0); color:rgb(255,255,255)">扩展阅读<span style="font-family:Verdana">1</span><span style="font-family:宋体">：</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    Apach <span style="font-family:宋体">的 </span><span style="font-family:Verdana">Hadoop</span><span style="font-family:宋体">的项目中包含了那些产品，如图所示：</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)">Pig </span><span style="color:rgb(64,64,64)">是在<span style="font-family:Verdana">MapReduce</span><span style="font-family:宋体">上构建的查询语言</span><span style="font-family:Verdana">(SQL-like),</span><span style="font-family:宋体">适用于大量并行计算。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)">Chukwa </span><span style="color:rgb(64,64,64)">是基于<span style="font-family:Verdana">Hadoop</span><span style="font-family:宋体">集群中监控系统，简单来说就是一个</span><span style="font-family:Verdana">“</span><span style="font-family:宋体">看门狗</span><span style="font-family:Verdana">” (WatchDog)</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)">Hive </span><span style="color:rgb(64,64,64)">是<span style="font-family:Verdana">DataWareHouse </span><span style="font-family:宋体">和 </span><span style="font-family:Verdana">Map Reduce</span><span style="font-family:宋体">交集，适用于</span><span style="font-family:Verdana">ETL</span><span style="font-family:宋体">方面的工作。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)">HBase</span><span style="color:rgb(64,64,64)"> 是一个面向列的分布式数据库。</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)">Map Reduce</span><span style="color:rgb(64,64,64)"> 是<span style="font-family:Verdana">Google</span><span style="font-family:宋体">提出的一种算法，用于超大型数据集的并行运算。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)">HDFS </span><span style="color:rgb(64,64,64)">可以支持千万级的大型分布式文件系统。</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)">Zookeeper  </span><span style="color:rgb(64,64,64)">提供的功能包括：配置维护、名字服务、分布式同步、组服务等，用于分布式系统的可靠协调系统。</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)">Avro </span><span style="color:rgb(64,64,64)">是一个数据序列化系统，设计用于支持大批量数据交换的应用。</span></p>
<p><span style="color:rgb(255,255,255); background:rgb(0,0,0); color:rgb(255,255,255)">扩展阅读<span style="font-family:Verdana">2</span><span style="font-family:宋体">：</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    <span style="font-family:宋体">什么是列存储？列存储不同于传统的关系型数据库，其数据在表中是按行存储的，列方式所带来的重要好处之一就是，由于查询中的选择规则是通过列来定义的，因 此整个数据库是自动索引化的。按列存储每个字段的数据聚集存储，在查询只需要少数几个字段的时候，能大大减少读取的数据量，一个字段的数据聚集存储，那就 更容易为这种聚集存储设计更好的压缩</span><span style="font-family:Verdana">/</span><span style="font-family:宋体">解压算法。这张图讲述了传统的行存储和列存储的区别：</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)"> </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(255,255,255); background:rgb(0,0,0); color:rgb(255,255,255)">扩展阅读<span style="font-family:Verdana">3</span><span style="font-family:宋体">：</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    <span style="font-family:宋体">对系统海量的</span><span style="font-family:Verdana">Log4J</span><span style="font-family:宋体">日志可以存放在一个集中式的机器上，在此机器上安装 </span><span style="font-family:Verdana">splunk </span><span style="font-family:宋体">可以方便对所有日志查看，安装方法可以参考：</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><a target="_blank" href="http://www.splunk.com/base/Documentation/latest/Installation/InstallonLinux" rel="nofollow"><span style="color:rgb(0,0,255)">http://www.splunk.com/base/Documentation/latest/Installation/InstallonLinux</span></a></p>
<p>二十六、 HBase入门篇2-Java操作HBase例子</p>
<p> </p>
<p><span style="color:rgb(64,64,64)">本篇文章讲述用<span style="font-family:Verdana">HBase Shell</span><span style="font-family:宋体">命令 和 </span><span style="font-family:Verdana">HBase Java API </span><span style="font-family:宋体">对</span><span style="font-family:Verdana">HBase </span><span style="font-family:宋体">服务器 进行操作。在此之前需要对</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的总体上有个大概的了解。比如说</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">服务器内部由哪些主要部件构成？</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的内部工作原理是什么？我想学习任何一项知识、技术的态度不能只是知道如何使用，对产品的内部构建一点都不去关心，那样出了问题，很难让你很快的找到答案，甚至我们希望最后能对该项技术的领悟出自己的心得，为我所用，借鉴该项技术其中的设计思想创造出自己的解决方案，更灵活的去应对多变的计算场景与架构设计。以我目前的对</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的了解还不够深入，将来不断的学习，我会把我所知道的点滴分享到这个</span><span style="font-family:Verdana">Blog</span><span style="font-family:宋体">上。</span></span></p>
<p><span style="color:rgb(64,64,64)">     <span style="font-family:宋体">先来看一下读取一行记录</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">是如何进行工作的，首先</span><span style="font-family:Verdana">HBase Client</span><span style="font-family:宋体">端会连接</span><span style="font-family:Verdana">Zookeeper Qurom</span></span><span style="color:rgb(64,64,64)">(<span style="font-family:宋体">从下面的代码也能看出来，例如：</span><span style="font-family:Verdana">HBASE_CONFIG.set("hbase.zookeeper.quorum", "192.168.50.216") </span></span><span style="color:rgb(64,64,64)">)<span style="font-family:宋体">。通过</span><span style="font-family:Verdana">Zookeeper</span><span style="font-family:宋体">组件</span><span style="font-family:Verdana">Client</span><span style="font-family:宋体">能获知哪个</span><span style="font-family:Verdana">Server</span><span style="font-family:宋体">管理</span><span style="font-family:Verdana">-ROOT- Region</span><span style="font-family:宋体">。那么</span><span style="font-family:Verdana">Client</span><span style="font-family:宋体">就去访问管理</span><span style="font-family:Verdana">-ROOT-</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">Server</span><span style="font-family:宋体">，在</span><span style="font-family:Verdana">META</span><span style="font-family:宋体">中记录了</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">中所有表信息，</span><span style="font-family:Verdana">(</span><span style="font-family:宋体">你可以使用</span><span style="font-family:Verdana">  scan '.META.' </span><span style="font-family:宋体">命令列出你创建的所有表的详细信息</span><span style="font-family:Verdana">),</span><span style="font-family:宋体">从而获取</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">分布的信息。一旦</span><span style="font-family:Verdana">Client</span><span style="font-family:宋体">获取了这一行的位置信息，比如这一行属于哪个</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">，</span><span style="font-family:Verdana">Client</span><span style="font-family:宋体">将会缓存这个信息并直接访问</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">。久而久之</span><span style="font-family:Verdana">Client</span><span style="font-family:宋体">缓存的信息渐渐增多，即使不访问</span><span style="font-family:Verdana">.META.</span><span style="font-family:宋体">表也能知道去访问哪个</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">。</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">中包含两种基本类型的文件，一种用于存储</span><span style="font-family:Verdana">WAL</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">log</span><span style="font-family:宋体">，另一种用于存储具体的数据，这些数据都通过</span><span style="font-family:Verdana">DFS Client</span><span style="font-family:宋体">和分布式的文件系统</span><span style="font-family:Verdana">HDFS</span><span style="font-family:宋体">进行交互实现存储。</span></span></p>
<p><span style="color:rgb(64,64,64)">如图所示：</span></p>
<p><a target="_blank" href="http://niaklq.bay.livefilestore.com/y1pX0l7uDaGqyf11KWFupkIkan9-yVosEZOno4HK8qpCdO8NIfbtwrYtckBTf73hsoDphtQ34WLC36HmqWLsHUrkFpMpuflRs_t/HBase-Architecture-1.jpg?psid=1" rel="nofollow"><span style="color:rgb(0,0,0)"><br>
</span><span style="color:rgb(0,0,0)"><br>
</span></a></p>
<p><a target="_blank" href="http://niaklq.bay.livefilestore.com/y1pX0l7uDaGqyf11KWFupkIkan9-yVosEZOno4HK8qpCdO8NIfbtwrYtckBTf73hsoDphtQ34WLC36HmqWLsHUrkFpMpuflRs_t/HBase-Architecture-1.jpg?psid=1" rel="nofollow"><span style="color:rgb(0,0,255)">查看大图请点击这里</span><span style="color:rgb(0,0,0)"><br>
</span></a></p>
<p><span style="color:rgb(64,64,64)">再来看看<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的一些内存实现原理： </span><span style="font-family:Verdana">   </span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    * HMaster— HBase<span style="font-family:宋体">中仅有一个</span><span style="font-family:Verdana">Master server</span><span style="font-family:宋体">。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    * HRegionServer—<span style="font-family:宋体">负责多个</span><span style="font-family:Verdana">HRegion</span><span style="font-family:宋体">使之能向</span><span style="font-family:Verdana">client</span><span style="font-family:宋体">端提供服务，在</span><span style="font-family:Verdana">HBase cluster</span><span style="font-family:宋体">中会存在多个</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    * ServerManager—<span style="font-family:宋体">负责管理</span><span style="font-family:Verdana">Region server</span><span style="font-family:宋体">信息，如每个</span><span style="font-family:Verdana">Region server</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">HServerInfo(</span><span style="font-family:宋体">这个对象包含</span><span style="font-family:Verdana">HServerAddress</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">startCode),</span><span style="font-family:宋体">已</span><span style="font-family:Verdana">load Region</span><span style="font-family:宋体">个数，死亡的</span><span style="font-family:Verdana">Region server</span><span style="font-family:宋体">列表</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    * RegionManager—<span style="font-family:宋体">负责将</span><span style="font-family:Verdana">region</span><span style="font-family:宋体">分配到</span><span style="font-family:Verdana">region server</span><span style="font-family:宋体">的具体工作，还监视</span><span style="font-family:Verdana">root</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">meta </span><span style="font-family:宋体">这</span><span style="font-family:Verdana">2</span><span style="font-family:宋体">个系统级的</span><span style="font-family:Verdana">region</span><span style="font-family:宋体">状态。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    * RootScanner—<span style="font-family:宋体">定期扫描</span><span style="font-family:Verdana">root region</span><span style="font-family:宋体">，以发现没有分配的</span><span style="font-family:Verdana">meta region</span><span style="font-family:宋体">。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    * MetaScanner—<span style="font-family:宋体">定期扫描</span><span style="font-family:Verdana">meta region,</span><span style="font-family:宋体">以发现没有分配的</span><span style="font-family:Verdana">user region</span><span style="font-family:宋体">。</span></span></p>
<p><span style="color:rgb(64,64,64)">HBase<span style="font-family:宋体">基本命令</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">下面我们再看看看<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的一些基本操作命令，我列出了几个常用的</span><span style="font-family:Verdana">HBase Shell</span><span style="font-family:宋体">命令，如下：</span></span></p>
<table>
<tbody>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">名称</span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">命令表达式</span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">创建表</span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">create '<span style="font-family:宋体">表名称</span><span style="font-family:Verdana">', '</span><span style="font-family:宋体">列名称</span><span style="font-family:Verdana">1','</span><span style="font-family:宋体">列名称</span><span style="font-family:Verdana">2','</span><span style="font-family:宋体">列名称</span><span style="font-family:Verdana">N'</span></span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">添加记录<span style="font-family:Verdana">      </span></span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">put '<span style="font-family:宋体">表名称</span><span style="font-family:Verdana">', '</span><span style="font-family:宋体">行名称</span><span style="font-family:Verdana">', '</span><span style="font-family:宋体">列名称</span><span style="font-family:Verdana">:', '</span><span style="font-family:宋体">值</span><span style="font-family:Verdana">'</span></span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">查看记录</span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">get '<span style="font-family:宋体">表名称</span><span style="font-family:Verdana">', '</span><span style="font-family:宋体">行名称</span><span style="font-family:Verdana">'</span></span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">查看表中的记录总数</span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">count  '<span style="font-family:宋体">表名称</span><span style="font-family:Verdana">'</span></span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">删除记录</span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">delete  '<span style="font-family:宋体">表名</span><span style="font-family:Verdana">' ,'</span><span style="font-family:宋体">行名称</span><span style="font-family:Verdana">' , '</span><span style="font-family:宋体">列名称</span><span style="font-family:Verdana">'</span></span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">删除一张表</span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">先要屏蔽该表，才能对该表进行删除，第一步 <span style="font-family:Verdana">disable '</span><span style="font-family:宋体">表名称</span><span style="font-family:Verdana">' </span><span style="font-family:宋体">第二步</span><span style="font-family:Verdana">  drop '</span><span style="font-family:宋体">表名称</span><span style="font-family:Verdana">'</span></span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">查看所有记录</span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">scan "<span style="font-family:宋体">表名称</span><span style="font-family:Verdana">"  </span></span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">查看某个表某个列中所有数据</span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">scan "<span style="font-family:宋体">表名称</span><span style="font-family:Verdana">" , ['</span><span style="font-family:宋体">列名称</span><span style="font-family:Verdana">:']</span></span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">更新记录<span style="font-family:Verdana"> </span></span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">就是重写一遍进行覆盖</span></p>
</td>
</tr>
</tbody>
</table>
<p><span style="color:rgb(64,64,64)">  <span style="font-family:宋体">如果你是一个新手队</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的一些命令还不算非常熟悉的话，你可以进入 </span><span style="font-family:Verdana">hbase </span><span style="font-family:宋体">的</span><span style="font-family:Verdana">shell </span><span style="font-family:宋体">模式中你可以输入 </span><span style="font-family:Verdana">help </span><span style="font-family:宋体">命令查看到你可以执行的命令和对该命令的说明，例如对</span><span style="font-family:Verdana">scan</span><span style="font-family:宋体">这个命令，</span><span style="font-family:Verdana">help</span><span style="font-family:宋体">中不仅仅提到有这个命令，还详细的说明了</span><span style="font-family:Verdana">scan</span><span style="font-family:宋体">命令中可以使用的参数和作用，例如，根据列名称查询的方法和带</span><span style="font-family:Verdana">LIMIT </span><span style="font-family:宋体">、</span><span style="font-family:Verdana">STARTROW</span><span style="font-family:宋体">的使用方法：</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">scan   Scan a table; pass table name and optionally a dictionary of scanner specifications.  Scanner specifications may include one or more of  the following: LIMIT, STARTROW, STOPROW, TIMESTAMP, or COLUMNS.  If no columns are specified, all columns will be scanned.  To scan all members of a column family, leave the qualifier empty as in  'col_family:'.  Examples:</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            hbase&gt; scan '.META.'</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            hbase&gt; scan '.META.', {COLUMNS =&gt; 'info:regioninfo'}</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            hbase&gt; scan 't1', {COLUMNS =&gt; ['c1', 'c2'], LIMIT =&gt; 10, STARTROW =&gt; 'xyz'}</span></p>
<p><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">使用<span style="font-family:Verdana">Java API</span><span style="font-family:宋体">对</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">服务器进行操作</span></span></p>
<p><span style="color:rgb(64,64,64)">需要下列<span style="font-family:Verdana">jar</span><span style="font-family:宋体">包</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     hbase-0.20.6.jar</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     hadoop-core-0.20.1.jar</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     commons-logging-1.1.1.jar</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     zookeeper-3.3.0.jar</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     log4j-1.2.91.jar</span></p>
<p><span style="color:rgb(64,64,64)">import org.apache.hadoop.conf.Configuration;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.HBaseConfiguration;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.HColumnDescriptor;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.HTableDescriptor;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.KeyValue;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.client.HBaseAdmin;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.client.HTable;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.client.Result;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.client.ResultScanner;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.client.Scan;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.io.BatchUpdate;</span></p>
<p><span style="color:rgb(64,64,64)">@SuppressWarnings("deprecation")</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">public class HBaseTestCase {</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    static HBaseConfiguration cfg = null;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    static {</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        Configuration HBASE_CONFIG = new Configuration();</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        HBASE_CONFIG.set("hbase.zookeeper.quorum", "192.168.50.216");</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        HBASE_CONFIG.set("hbase.zookeeper.property.clientPort", "2181");</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        cfg = new HBaseConfiguration(HBASE_CONFIG);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    /**</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     * <span style="font-family:宋体">创建一张表</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     */</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    public static void creatTable(String tablename) throws Exception {</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        HBaseAdmin admin = new HBaseAdmin(cfg);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        if (admin.tableExists(tablename)) {</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            System.out.println("table   Exists!!!");</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        else{</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            HTableDescriptor tableDesc = new HTableDescriptor(tablename);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            tableDesc.addFamily(new HColumnDescriptor("name:"));</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            admin.createTable(tableDesc);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            System.out.println("create table ok .");</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">         </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    /**</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     * <span style="font-family:宋体">添加一条数据</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     */</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    public static void addData (String tablename) throws Exception{</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">         HTable table = new HTable(cfg, tablename);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">             BatchUpdate update = new BatchUpdate("Huangyi");  </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">             update.put("name:java", "http://www.javabloger.com".getBytes());  </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">             table.commit(update);  </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">         System.out.println("add data ok .");</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    /**</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     * <span style="font-family:宋体">显示所有数据</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     */</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    public static void getAllData (String tablename) throws Exception{</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">         HTable table = new HTable(cfg, tablename);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">         Scan s = new Scan();</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">         ResultScanner ss = table.getScanner(s);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">         for(Result r:ss){</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">             for(KeyValue kv:r.raw()){</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">                System.out.print(new String(kv.getColumn()));</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">                System.out.println(new String(kv.getValue()    ));</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">             }</span></p>
<p><span style="color:rgb(64,64,64)">         }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    public static void  main (String [] agrs) {</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        try {</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">                String tablename="tablename";</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">                HBaseTestCase.creatTable(tablename);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">                HBaseTestCase.addData(tablename);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">                HBaseTestCase.getAllData(tablename);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            } </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        catch (Exception e) {</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            e.printStackTrace();</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">}</span></p>
<p>二十七、 HBase入门篇3</p>
<p> </p>
<p><span style="color:rgb(64,64,64)">前两篇文件分别说到了我在学习<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">中的</span></span><a target="_blank" href="http://www.javabloger.com/article/category/hbase" rel="nofollow"><span style="color:rgb(0,0,255)">一些入门经验</span></a><span style="color:rgb(64,64,64)">，而《<span style="font-family:Verdana">HBase </span><span style="font-family:宋体">入门</span><span style="font-family:Verdana">3</span><span style="font-family:宋体">》这篇文章浅显的从几个方面谈谈</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的一些优化技巧，只能作为我学习笔记的一部分，因为学多了怕忘，留给自己以后看看。</span></span></p>
<p><span style="color:rgb(64,64,64)">1 <span style="font-family:宋体">修改 </span><span style="font-family:Verdana">linux </span><span style="font-family:宋体">系统参数 </span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    Linux<span style="font-family:宋体">系统最大可打开文件数一般默认的参数值是</span><span style="font-family:Verdana">1024,</span><span style="font-family:宋体">如果你不进行修改并发量上来的时候会出现</span><span style="font-family:Verdana">“Too Many Open Files”</span><span style="font-family:宋体">的错误，导致整个</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">不可运行，你可以用</span><span style="font-family:Verdana">ulimit -n </span><span style="font-family:宋体">命令进行修改，或者修改</span><span style="font-family:Verdana">/etc/security/limits.conf </span><span style="font-family:宋体">和</span><span style="font-family:Verdana">/proc/sys/fs/file-max  </span><span style="font-family:宋体">的参数，具体如何修改可以去</span><span style="font-family:Verdana">Google </span><span style="font-family:宋体">关键字 </span><span style="font-family:Verdana">“linux limits.conf ”</span></span></p>
<p><span style="color:rgb(64,64,64)">2JVM <span style="font-family:宋体">配置</span><span style="font-family:Verdana">  </span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">修改 <span style="font-family:Verdana">hbase-env.sh </span><span style="font-family:宋体">文件中的配置参数，根据你的机器硬件和当前操作系统的</span><span style="font-family:Verdana">JVM(32/64</span><span style="font-family:宋体">位</span><span style="font-family:Verdana">)</span><span style="font-family:宋体">配置适当的参数</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    HBASE_HEAPSIZE 4000   HBase<span style="font-family:宋体">使用的 </span><span style="font-family:Verdana">JVM </span><span style="font-family:宋体">堆的大小</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    HBASE_OPTS  "</span><span style="color:rgb(64,64,64)">‐</span><span style="color:rgb(64,64,64)">server </span><span style="color:rgb(64,64,64)">‐</span><span style="color:rgb(64,64,64)">XX:+UseConcMarkSweepGC"JVM GC <span style="font-family:宋体">选项</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    HBASE_MANAGES_ZKfalse   <span style="font-family:宋体">是否使用</span><span style="font-family:Verdana">Zookeeper</span><span style="font-family:宋体">进行分布式管理</span></span></p>
<p><span style="color:rgb(64,64,64)">3 HBase<span style="font-family:宋体">持久化</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">重启操作系统后<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">中数据全无，你可以不做任何修改的情况下，创建一张表，写一条数据进行，然后将机器重启，重启后你再进入</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">shell</span><span style="font-family:宋体">中使用 </span><span style="font-family:Verdana">list </span><span style="font-family:宋体">命令查看当前所存在的表，一个都没有了。是不是很杯具？没有关系你可以在</span><span style="font-family:Verdana">hbase/conf/hbase-default.xml</span><span style="font-family:宋体">中设置</span><span style="font-family:Verdana">hbase.rootdir</span><span style="font-family:宋体">的值，来设置文件的保存位置指定一个文件夹 ，例如：</span><span style="font-family:Verdana">&lt;value&gt;file:///you/hbase-data/path&lt;/value&gt;</span><span style="font-family:宋体">，你建立的</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">中的表和数据就直接写到了你的磁盘上，如图所示：</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">同样你也可以指定你的分布式文件系统<span style="font-family:Verdana">HDFS</span><span style="font-family:宋体">的路径例如</span><span style="font-family:Verdana">: hdfs://NAMENODE_SERVER:PORT/HBASE_ROOTDIR</span><span style="font-family:宋体">，这样就写到了你的分布式文件系统上了。</span></span></p>
<p><span style="color:rgb(64,64,64)">4<span style="font-family:宋体">配置</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">运行参数 </span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">其次就需要对<span style="font-family:Verdana">hbase/conf/hbase-default.xml </span><span style="font-family:宋体">文件进行配置，以下是我认为比较重要的配置参数</span></span></p>
<p><span style="color:rgb(255,255,255); background:rgb(0,0,0); color:rgb(255,255,255)">hbase.client.write.buffer  </span><span style="color:rgb(64,64,64)">  </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">描述：这个参数可以设置写入数据缓冲区的大小，当客户端和服务器端传输数据，服务器为了提高系统运行性能开辟一个写的缓冲区来处理它， 这个参数设置如果设置的大了，将会对系统的内存有一定的要求，直接影响系统的性能。</span></p>
<p><span style="color:rgb(255,255,255); background:rgb(0,0,0); color:rgb(255,255,255)">hbase.master.meta.thread.rescanfrequency  </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">描述：多长时间 <span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">对系统表 </span><span style="font-family:Verdana">root </span><span style="font-family:宋体">和 </span><span style="font-family:Verdana">meta </span><span style="font-family:宋体">扫描一次，这个参数可以设置的长一些，降低系统的能耗。</span></span></p>
<p><span style="color:rgb(255,255,255); background:rgb(0,0,0); color:rgb(255,255,255)">hbase.regionserver.handler.count  </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">描述：由于<span style="font-family:Verdana">HBase/Hadoop</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">Server</span><span style="font-family:宋体">是采用</span><span style="font-family:Verdana">Multiplexed, non-blocking I/O</span><span style="font-family:宋体">方式而设计的，所以它可以透过一个</span><span style="font-family:Verdana">Thread</span><span style="font-family:宋体">来完成处理，但是由于处理</span><span style="font-family:Verdana">Client</span><span style="font-family:宋体">端所呼叫的方法是</span><span style="font-family:Verdana">Blocking I/O</span><span style="font-family:宋体">，所以它的设计会将</span><span style="font-family:Verdana">Client</span><span style="font-family:宋体">所传递过来的物件先放置在</span><span style="font-family:Verdana">Queue</span><span style="font-family:宋体">，并在启动</span><span style="font-family:Verdana">Server</span><span style="font-family:宋体">时就先产生一堆</span><span style="font-family:Verdana">Handler(Thread)</span><span style="font-family:宋体">，该</span><span style="font-family:Verdana">Handler</span><span style="font-family:宋体">会透过</span><span style="font-family:Verdana">Polling</span><span style="font-family:宋体">的方式来取得该物件并执行对应的方法，默认为</span><span style="font-family:Verdana">25</span><span style="font-family:宋体">，根据实际场景可以设置大一些。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)"> </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(255,255,255); background:rgb(0,0,0); color:rgb(255,255,255)">hbase.regionserver.thread.splitcompactcheckfrequency </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">描述：这个参数是表示多久去<span style="font-family:Verdana">RegionServer</span><span style="font-family:宋体">服务器运行一次</span><span style="font-family:Verdana">split/compaction</span><span style="font-family:宋体">的时间间隔，当然</span><span style="font-family:Verdana">split</span><span style="font-family:宋体">之前会先进行一个</span><span style="font-family:Verdana">compact</span><span style="font-family:宋体">操作</span><span style="font-family:Verdana">.</span><span style="font-family:宋体">这个</span><span style="font-family:Verdana">compact</span><span style="font-family:宋体">操作可能是</span><span style="font-family:Verdana">minor compact</span><span style="font-family:宋体">也可能是</span><span style="font-family:Verdana">major compact.compact</span><span style="font-family:宋体">后</span><span style="font-family:Verdana">,</span><span style="font-family:宋体">会从所有的</span><span style="font-family:Verdana">Store</span><span style="font-family:宋体">下的所有</span><span style="font-family:Verdana">StoreFile</span><span style="font-family:宋体">文件最大的那个取</span><span style="font-family:Verdana">midkey.</span><span style="font-family:宋体">这个</span><span style="font-family:Verdana">midkey</span><span style="font-family:宋体">可能并不处于全部数据的</span><span style="font-family:Verdana">mid</span><span style="font-family:宋体">中</span><span style="font-family:Verdana">.</span><span style="font-family:宋体">一个</span><span style="font-family:Verdana">row-key</span><span style="font-family:宋体">的下面的数据可能会跨不同的</span><span style="font-family:Verdana">HRegion</span><span style="font-family:宋体">。</span></span></p>
<p><span style="color:rgb(255,255,255); background:rgb(0,0,0); color:rgb(255,255,255)">hbase.hregion.max.filesize</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">描述：<span style="font-family:Verdana">HRegion</span><span style="font-family:宋体">中的</span><span style="font-family:Verdana">HStoreFile</span><span style="font-family:宋体">最大值，任何表中的列族一旦超过这个大小将会被切分，而</span><span style="font-family:Verdana">HStroeFile</span><span style="font-family:宋体">的默认大小是</span><span style="font-family:Verdana">256M</span><span style="font-family:宋体">。</span></span></p>
<p><span style="color:rgb(255,255,255); background:rgb(0,0,0); color:rgb(255,255,255)">hfile.block.cache.size   </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">描述：指定 <span style="font-family:Verdana">HFile/StoreFile </span><span style="font-family:宋体">缓存在</span><span style="font-family:Verdana">JVM</span><span style="font-family:宋体">堆中分配的百分比，默认值是</span><span style="font-family:Verdana">0.2</span><span style="font-family:宋体">，意思就是</span><span style="font-family:Verdana">20%</span><span style="font-family:宋体">，而如果你设置成</span><span style="font-family:Verdana">0</span><span style="font-family:宋体">，就表示对该选项屏蔽。</span></span></p>
<p><span style="color:rgb(255,255,255); background:rgb(0,0,0); color:rgb(255,255,255)">hbase.zookeeper.property.maxClientCnxns     </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">描述： 这项配置的选项就是从<span style="font-family:Verdana">zookeeper</span><span style="font-family:宋体">中来的，表示</span><span style="font-family:Verdana">ZooKeeper</span><span style="font-family:宋体">客户端同时访问的并发连接数，</span><span style="font-family:Verdana">ZooKeeper</span><span style="font-family:宋体">对于</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">来说就是一个入口这个参数的值可以适当放大些。</span></span></p>
<p><span style="color:rgb(255,255,255); background:rgb(0,0,0); color:rgb(255,255,255)">hbase.regionserver.global.memstore.upperLimit</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">描述：在<span style="font-family:Verdana">Region Server</span><span style="font-family:宋体">中所有</span><span style="font-family:Verdana">memstores</span><span style="font-family:宋体">占用堆的大小参数配置，默认值是</span><span style="font-family:Verdana">0.4</span><span style="font-family:宋体">，表示</span><span style="font-family:Verdana">40%</span><span style="font-family:宋体">，如果设置为</span><span style="font-family:Verdana">0</span><span style="font-family:宋体">，就是对选项进行屏蔽。</span></span></p>
<p><span style="color:rgb(255,255,255); background:rgb(0,0,0); color:rgb(255,255,255)">hbase.hregion.memstore.flush.size </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">描述：<span style="font-family:Verdana">Memstore</span><span style="font-family:宋体">中缓存的内容超过配置的范围后将会写到磁盘上，例如：删除操作是先写入</span><span style="font-family:Verdana">MemStore</span><span style="font-family:宋体">里做个标记，指示那个</span><span style="font-family:Verdana">value, column </span><span style="font-family:宋体">或 </span><span style="font-family:Verdana">family</span><span style="font-family:宋体">等下是要删除的，</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">会定期对存储文件做一个</span><span style="font-family:Verdana">major compaction</span><span style="font-family:宋体">，在那时</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">会把</span><span style="font-family:Verdana">MemStore</span><span style="font-family:宋体">刷入一个新的</span><span style="font-family:Verdana">HFile</span><span style="font-family:宋体">存储文件中。如果在一定时间范围内没有做</span><span style="font-family:Verdana">major compaction</span><span style="font-family:宋体">，而</span><span style="font-family:Verdana">Memstore</span><span style="font-family:宋体">中超出的范围就写入磁盘上了。</span></span></p>
<p><span style="color:rgb(64,64,64)">5 HBase<span style="font-family:宋体">中</span><span style="font-family:Verdana">log4j</span><span style="font-family:宋体">的日志 </span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">HBase<span style="font-family:宋体">中日志输出等级默认状态下是把</span><span style="font-family:Verdana">debug</span><span style="font-family:宋体">、 </span><span style="font-family:Verdana">info </span><span style="font-family:宋体">级别的日志打开的，可以根据自己的需要调整</span><span style="font-family:Verdana">log</span><span style="font-family:宋体">级别，</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">log4j</span><span style="font-family:宋体">日志配置文件在 </span><span style="font-family:Verdana">hbase\conf\log4j.properties </span><span style="font-family:宋体">目录下</span></span></p>
<p>二十八、 HBase入门篇4–存储</p>
<p>   <span style="color:rgb(64,64,64)">前几篇文章讲述了 </span><a target="_blank" href="http://www.javabloger.com/article/apache-hbase-shell-and-install-key-value.html" rel="nofollow"><span style="color:rgb(0,0,255)">HBase<span style="font-family:宋体">的安装</span></span></a><span style="color:rgb(64,64,64)">、</span><a target="_blank" href="http://www.javabloger.com/article/apache-hbase-shell-and-java-api-html.html" rel="nofollow"><span style="color:rgb(0,0,255)">Hbase<span style="font-family:宋体">命令和</span><span style="font-family:Verdana">API</span><span style="font-family:宋体">的使用</span></span></a><span style="color:rgb(64,64,64)">、</span><a target="_blank" href="http://www.javabloger.com/article/hbase-performance-hbase-optimized.html" rel="nofollow"><span style="color:rgb(0,0,255)">HBase<span style="font-family:宋体">简单的优化技巧</span></span></a><span style="color:rgb(64,64,64)">，《<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">入门篇</span><span style="font-family:Verdana">4</span><span style="font-family:宋体">》</span></span><a target="_blank" href="http://www.javabloger.com/article/apache-hbase-hadoop.html" rel="nofollow"><span style="color:rgb(0,0,255)">这篇文章</span></a><span style="color:rgb(64,64,64)">是讲述把<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的数据放在</span><span style="font-family:Verdana">HDFS</span><span style="font-family:宋体">上的点滴过程。目前对与</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">我是一个绝对的新手，如果在文章中有任何我理解有错误的地方请各位指正，谢谢。</span></span></p>
<p><span style="color:rgb(64,64,64)">Ok<span style="font-family:宋体">，进行正题 </span><span style="font-family:Verdana">………</span></span></p>
<p><span style="color:rgb(64,64,64)">   <span style="font-family:宋体">在</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">中创建的一张表可以分布在多个</span><span style="font-family:Verdana">Hregion</span><span style="font-family:宋体">，也就说一张表可以被拆分成多块，每一块称我们呼为一个</span><span style="font-family:Verdana">Hregion</span><span style="font-family:宋体">。每个</span><span style="font-family:Verdana">Hregion</span><span style="font-family:宋体">会保 存一个表里面某段连续的数据，用户创建的那个大表中的每个</span><span style="font-family:Verdana">Hregion</span><span style="font-family:宋体">块是由</span><span style="font-family:Verdana">Hregion</span><span style="font-family:宋体">服务器提供维护，访问</span><span style="font-family:Verdana">Hregion</span><span style="font-family:宋体">块是要通过 </span><span style="font-family:Verdana">Hregion</span><span style="font-family:宋体">服务器，而一个</span><span style="font-family:Verdana">Hregion</span><span style="font-family:宋体">块对应一个</span><span style="font-family:Verdana">Hregion</span><span style="font-family:宋体">服务器，一张完整的表可以保存在多个</span><span style="font-family:Verdana">Hregion </span><span style="font-family:宋体">上。</span><span style="font-family:Verdana">HRegion Server </span><span style="font-family:宋体">与</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">的对应关系是一对多的关系。每一个</span><span style="font-family:Verdana">HRegion</span><span style="font-family:宋体">在物理上会被分为三个部分：</span><span style="font-family:Verdana">Hmemcache(</span><span style="font-family:宋体">缓存</span><span style="font-family:Verdana">)</span><span style="font-family:宋体">、</span><span style="font-family:Verdana">Hlog(</span><span style="font-family:宋体">日志</span><span style="font-family:Verdana">)</span><span style="font-family:宋体">、</span><span style="font-family:Verdana">HStore(</span><span style="font-family:宋体">持久层</span><span style="font-family:Verdana">)</span><span style="font-family:宋体">。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">上述这些关系在我脑海中的样子，如图所示：</span></p>
<p><span style="color:rgb(64,64,64)">1.HRegionServer<span style="font-family:宋体">、</span><span style="font-family:Verdana">HRegion</span><span style="font-family:宋体">、</span><span style="font-family:Verdana">Hmemcache</span><span style="font-family:宋体">、</span><span style="font-family:Verdana">Hlog</span><span style="font-family:宋体">、</span><span style="font-family:Verdana">HStore</span><span style="font-family:宋体">之间的关系，如图所示：</span></span></p>
<p><span style="color:rgb(64,64,64)"> </span></p>
<p><span style="color:rgb(64,64,64)">2.HBase<span style="font-family:宋体">表中的数据与</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">的分布关系，如图所示：</span></span></p>
<p><span style="color:rgb(64,64,64)"> </span></p>
<p><span style="color:rgb(64,64,64)"> </span></p>
<p><span style="color:rgb(64,64,64)">HBase<span style="font-family:宋体">读数据</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">HBase<span style="font-family:宋体">读取数据优先读取</span><span style="font-family:Verdana">HMemcache</span><span style="font-family:宋体">中的内容，如果未取到再去读取</span><span style="font-family:Verdana">Hstore</span><span style="font-family:宋体">中的数据，提高数据读取的性能。</span></span></p>
<p><span style="color:rgb(64,64,64)">HBase<span style="font-family:宋体">写数据</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">HBase<span style="font-family:宋体">写入数据会写到</span><span style="font-family:Verdana">HMemcache</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">Hlog</span><span style="font-family:宋体">中，</span><span style="font-family:Verdana">HMemcache</span><span style="font-family:宋体">建立缓存，</span><span style="font-family:Verdana">Hlog</span><span style="font-family:宋体">同步</span><span style="font-family:Verdana">Hmemcache</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">Hstore</span><span style="font-family:宋体">的事务日志，发起</span><span style="font-family:Verdana">Flush Cache</span><span style="font-family:宋体">时，数据持久化到</span><span style="font-family:Verdana">Hstore</span><span style="font-family:宋体">中，并清空</span><span style="font-family:Verdana">HMemecache</span><span style="font-family:宋体">。</span></span></p>
<p><span style="color:rgb(64,64,64)">    <span style="font-family:宋体">客户端访问这些数据的时候通过</span><span style="font-family:Verdana">Hmaster </span><span style="font-family:宋体">，每个 </span><span style="font-family:Verdana">Hregion </span><span style="font-family:宋体">服务器都会和</span><span style="font-family:Verdana">Hmaster </span><span style="font-family:宋体">服务器保持一个长连接，</span><span style="font-family:Verdana">Hmaster </span><span style="font-family:宋体">是</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">分布式系统中的管理者，他的主要任务就是要告诉每个</span><span style="font-family:Verdana">Hregion </span><span style="font-family:宋体">服务器它要维护哪些</span><span style="font-family:Verdana">Hregion</span><span style="font-family:宋体">。用户的这些都数据可以保存在</span><span style="font-family:Verdana">Hadoop </span><span style="font-family:宋体">分布式文件系统上。 如果主服务器</span><span style="font-family:Verdana">Hmaster</span><span style="font-family:宋体">死机，那么整个系统都会无效。下面我会考虑如何解决</span><span style="font-family:Verdana">Hmaster</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">SPFO</span><span style="font-family:宋体">的问题，这个问题有点类似</span><span style="font-family:Verdana">Hadoop</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">SPFO </span><span style="font-family:宋体">问题一样只有一个</span><span style="font-family:Verdana">NameNode</span><span style="font-family:宋体">维护全局的</span><span style="font-family:Verdana">DataNode</span><span style="font-family:宋体">，</span><span style="font-family:Verdana">HDFS</span><span style="font-family:宋体">一旦死机全部挂了，也有人说采用</span><span style="font-family:Verdana">Heartbeat</span><span style="font-family:宋体">来解决这个问题，但我总想找出 其他的解决方案，多点时间，总有办法的。</span></span></p>
<p><span style="color:rgb(64,64,64)">昨天在<span style="font-family:Verdana">hadoop-0.21.0</span><span style="font-family:宋体">、</span><span style="font-family:Verdana">hbase-0.20.6</span><span style="font-family:宋体">的环境中折腾了很久，一直报错，错误信息如下：</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">Exception in thread "main" java.io.IOException: Call to localhost/serv6:9000 failed on local exception: java.io.EOFException</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">10/11/10 15:34:34 ERROR master.HMaster: Can not start master</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">java.lang.reflect.InvocationTargetException</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        at org.apache.hadoop.hbase.master.HMaster.doMain(HMaster.java:1233)</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:1274)</span></p>
<p><span style="color:rgb(64,64,64)">死活连接不上<span style="font-family:Verdana">HDFS</span><span style="font-family:宋体">，也无法连接</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">，郁闷啊。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">我想想啊，慢慢想，我眼前一亮<span style="font-family:Verdana">  java.io.EOFException </span><span style="font-family:宋体">这个异常，是不是有可能是</span><span style="font-family:Verdana">RPC </span><span style="font-family:宋体">协定格式不一致导致的？也就是说服务器端和客户端的版本不一致的问题？换了一个</span><span style="font-family:Verdana">HDFS</span><span style="font-family:宋体">的服务器端以后，一切都好了，果然是版本的问题，最后采用 </span><span style="font-family:Verdana">hadoop-0.20.2 </span><span style="font-family:宋体">搭配</span><span style="font-family:Verdana">hbase-0.20.6 </span><span style="font-family:宋体">比较稳当。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">最后的效果如图所示：</span></p>
<p><span style="color:rgb(64,64,64)"> </span></p>
<p><a target="_blank" href="http://farm5.static.flickr.com/4065/5165595387_d17a1bbbe4_b.jpg" rel="nofollow"><span style="color:rgb(0,0,255)">查看大图请点击这里</span></a><span style="color:rgb(64,64,64)">， 上图的一些文字说明：</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">   1.hadoop<span style="font-family:宋体">版本是</span><span style="font-family:Verdana">0.20.2 ,</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">   2.hbase<span style="font-family:宋体">版本是</span><span style="font-family:Verdana">0.20.6,</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">   3.<span style="font-family:宋体">在</span><span style="font-family:Verdana">hbase</span><span style="font-family:宋体">中创建了一张表 </span><span style="font-family:Verdana">tab1</span><span style="font-family:宋体">，退出</span><span style="font-family:Verdana">hbase shell</span><span style="font-family:宋体">环境</span><span style="font-family:Verdana">,</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">   4.<span style="font-family:宋体">用</span><span style="font-family:Verdana">hadoop</span><span style="font-family:宋体">命令查看，文件系统中的文件果然多了一个刚刚创建的</span><span style="font-family:Verdana">tab1</span><span style="font-family:宋体">目录</span><span style="font-family:Verdana">,</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">以上这张图片说明<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">在分布式文件系统</span><span style="font-family:Verdana">Apache HDFS</span><span style="font-family:宋体">中运行了。</span></span></p>
<p>二十九、 HBase入门5(集群) -压力分载与失效转发</p>
<p> </p>
<p> <span style="color:rgb(64,64,64)">在</span><a target="_blank" href="http://www.javabloger.com/article/apache-hbase-shell-and-java-api-html.html" rel="nofollow"><span style="color:rgb(0,0,255)">上一篇</span></a><a target="_blank" href="http://www.javabloger.com/article/category/hbase" rel="nofollow"><span style="color:rgb(0,0,255)">关于<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的文章</span></span></a><span style="color:rgb(64,64,64)">中曾经讲述过<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">在分布式中的架构，这篇文章将会讲述</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">在分布式环境中是如何排除单点故障的</span><span style="font-family:Verdana">(SPFO)</span><span style="font-family:宋体">，做一个小实验讲述</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">在分布式环境中的高可用性，亲眼看到一些现象，延伸一些思考的话题。</span></span></p>
<p><span style="color:rgb(64,64,64)">先来回顾一下<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">主要部件：</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">   1.HBaseMaster  </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">   2.HRegionServer </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">   3.HBase Client</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">   4.HBase Thrift Server</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">   5.HBase REST Server</span></p>
<p><span style="color:rgb(64,64,64)">HBaseMaster</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    HMaster <span style="font-family:宋体">负责给</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">分配区域</span><span style="font-family:Verdana">,</span><span style="font-family:宋体">并且负责对集群环境中的</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">进行负载均衡，</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">还负责监控集群环境中的</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">的运行状况，如果某一台</span><span style="font-family:Verdana">HReginServer down</span><span style="font-family:宋体">机，</span><span style="font-family:Verdana">HBaseMaster</span><span style="font-family:宋体">将会把不可用的</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">来提供服务的</span><span style="font-family:Verdana">HLog</span><span style="font-family:宋体">和表进行重新分配转交给其他</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">来提供，</span><span style="font-family:Verdana">HBaseMaster</span><span style="font-family:宋体">还负责对数据和表进行管理，处理表结构和表中数据的变更，因为在 </span><span style="font-family:Verdana">META </span><span style="font-family:宋体">系统表中存储了所有的相关表信息。并且</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">实现了</span><span style="font-family:Verdana">ZooKeeper</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">Watcher</span><span style="font-family:宋体">接口可以和</span><span style="font-family:Verdana">zookeeper</span><span style="font-family:宋体">集群交互。</span></span></p>
<p><span style="color:rgb(64,64,64)">HRegionServer</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    HReginServer<span style="font-family:宋体">负责处理用户的读和写的操作。</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">通过与</span><span style="font-family:Verdana">HBaseMaster</span><span style="font-family:宋体">通信获取自己需要服务的数据表，并向</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">反馈自己的运行状况。当一个写的请求到来的时候，它首先会写到一个叫做</span><span style="font-family:Verdana">HLog</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">write-ahead log</span><span style="font-family:宋体">中。</span><span style="font-family:Verdana">HLog</span><span style="font-family:宋体">被缓存在内存中，称为</span><span style="font-family:Verdana">Memcache</span><span style="font-family:宋体">，每一个</span><span style="font-family:Verdana">HStore</span><span style="font-family:宋体">只能有一个</span><span style="font-family:Verdana">Memcache</span><span style="font-family:宋体">。当</span><span style="font-family:Verdana">Memcache</span><span style="font-family:宋体">到达配置的大小以后，将会创建一个</span><span style="font-family:Verdana">MapFile</span><span style="font-family:宋体">，将其写到磁盘中去。这将减少</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">的内存压力。当一起读取的请求到来的时候，</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">会先在</span><span style="font-family:Verdana">Memcache</span><span style="font-family:宋体">中寻找该数据，当找不到的时候，才会去在</span><span style="font-family:Verdana">MapFiles </span><span style="font-family:宋体">中寻找。</span></span></p>
<p><span style="color:rgb(64,64,64)">HBase Client</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    HBase Client<span style="font-family:宋体">负责寻找提供需求数据的</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">。在这个过程中，</span><span style="font-family:Verdana">HBase Client</span><span style="font-family:宋体">将首先与</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">通信，找到</span><span style="font-family:Verdana">ROOT</span><span style="font-family:宋体">区域。这个操作是</span><span style="font-family:Verdana">Client</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">Master</span><span style="font-family:宋体">之间仅有的通信操作。一旦</span><span style="font-family:Verdana">ROOT</span><span style="font-family:宋体">区域被找到以后，</span><span style="font-family:Verdana">Client</span><span style="font-family:宋体">就可以通过扫描</span><span style="font-family:Verdana">ROOT</span><span style="font-family:宋体">区域找到相应的</span><span style="font-family:Verdana">META</span><span style="font-family:宋体">区域去定位实际提供数据的</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">。当定位到提供数据的</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">以后，</span><span style="font-family:Verdana">Client</span><span style="font-family:宋体">就可以通过这个</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">找到需要的数据了。这些信息将会被</span><span style="font-family:Verdana">Client</span><span style="font-family:宋体">缓存起来，当下次请求的时候，就不需要走上面的这个流程了。</span></span></p>
<p><span style="color:rgb(64,64,64)">HBase<span style="font-family:宋体">服务接口</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    HBase Thrift Server<span style="font-family:宋体">和</span><span style="font-family:Verdana">HBase REST Server</span><span style="font-family:宋体">是通过非</span><span style="font-family:Verdana">Java</span><span style="font-family:宋体">程序对</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">进行访问的一种途径。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)"> </span></p>
<p><span style="color:rgb(64,64,64)">进入正题</span></p>
<p><span style="color:rgb(64,64,64)">先来看一个<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">集群的模拟环境，此环境中一共有</span><span style="font-family:Verdana">4</span><span style="font-family:宋体">台机器，分别包含 </span><span style="font-family:Verdana">zookeeper</span><span style="font-family:宋体">、</span><span style="font-family:Verdana">HBaseMaster</span><span style="font-family:宋体">、</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">、</span><span style="font-family:Verdana">HDSF 4</span><span style="font-family:宋体">个服务，为了展示失效转发的效果</span><span style="font-family:Verdana">HBaseMaster</span><span style="font-family:宋体">、</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">各有</span><span style="font-family:Verdana">2</span><span style="font-family:宋体">台，只是在一台机器上即运行了</span><span style="font-family:Verdana">HBaseMaster</span><span style="font-family:宋体">，也运行了</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">注意，<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的集群环境中</span><span style="font-family:Verdana">HBaseMaster</span><span style="font-family:宋体">只有失效转发没有压力分载的功能，而</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">即提供失效转发也提供压力分载。</span></span></p>
<p><span style="color:rgb(64,64,64)">服务器清单如下：</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    1<span style="font-family:宋体">、</span></span><span style="color:rgb(64,64,64)">zookeeper               </span><span style="color:rgb(64,64,64)">192.168.20.214</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    2<span style="font-family:宋体">、</span></span><span style="color:rgb(64,64,64)">HBaseMaster         </span><span style="color:rgb(64,64,64)">192.168.20.213/192.168.20.215</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    3<span style="font-family:宋体">、</span></span><span style="color:rgb(64,64,64)">HReginServer         </span><span style="color:rgb(64,64,64)">192.168.20.213/192.168.20.215</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    4<span style="font-family:宋体">、</span></span><span style="color:rgb(64,64,64)">HDSF                         </span><span style="color:rgb(64,64,64)">192.168.20.212</span></p>
<p><span style="color:rgb(64,64,64)">整个模拟环境的架构如图所示：</span><span style="color:rgb(64,64,64)"><br>
</span></p>
<p><span style="color:rgb(64,64,64)">注意，这里只是做了一个模拟环境，因为这个环境的重点是<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">，所以</span><span style="font-family:Verdana">zookeeper</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">HDFS</span><span style="font-family:宋体">服务都是单台。 </span></span></p>
<p><span style="color:rgb(64,64,64)">虽然说在整个<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的集群环境中只能有一个</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">，可是在集群环境中</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">可以启动多个，但真正使用到的</span><span style="font-family:Verdana">HMaster Server</span><span style="font-family:宋体">只有一个，他不</span><span style="font-family:Verdana">down</span><span style="font-family:宋体">掉的时候，其他启动的</span><span style="font-family:Verdana">HMaster Server</span><span style="font-family:宋体">并不会工作，直到与</span><span style="font-family:Verdana">ZooKeeper</span><span style="font-family:宋体">服务器判断与当前运行的</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">通讯超时，认为这个正在运行的</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">服务器</span><span style="font-family:Verdana">down</span><span style="font-family:宋体">掉了，</span><span style="font-family:Verdana">Zookeeper</span><span style="font-family:宋体">才会去连接下一台</span><span style="font-family:Verdana">HMaster Server</span><span style="font-family:宋体">。</span></span></p>
<p><span style="color:rgb(64,64,64)">简单来说<span style="font-family:Verdana">,</span><span style="font-family:宋体">如果运行中</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">服务器</span><span style="font-family:Verdana">down</span><span style="font-family:宋体">掉了，那么</span><span style="font-family:Verdana">zookeeper</span><span style="font-family:宋体">会从列表中选择下一个</span><span style="font-family:Verdana">HMaster </span><span style="font-family:宋体">服务器进行访问，让他接管</span><span style="font-family:Verdana">down</span><span style="font-family:宋体">掉的</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">任务，换而言之，用</span><span style="font-family:Verdana">Java</span><span style="font-family:宋体">客户端对</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">进行操作是通过</span><span style="font-family:Verdana">ZooKeeper</span><span style="font-family:宋体">的，也就是说如果</span><span style="font-family:Verdana">zookeeper</span><span style="font-family:宋体">集群中的节点全挂了 那么</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的集群也挂了。本身</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">并不存储中的任何数据 真正的数据是保存在</span><span style="font-family:Verdana">HDFS</span><span style="font-family:宋体">上，所以</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的数据是一致的，但是</span><span style="font-family:Verdana">HDFS</span><span style="font-family:宋体">文件系统挂了，</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的集群也挂。</span></span></p>
<p><span style="color:rgb(64,64,64)">在一台<span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">失败后，客户端对</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">集群环境访问时，客户端先会通过</span><span style="font-family:Verdana">zookeeper</span><span style="font-family:宋体">识别到</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">运行异常，直到确认多次后，才连接到下一个</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">，此时，备份的</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">服务才生效，在</span><span style="font-family:Verdana">IDE</span><span style="font-family:宋体">环境中的效果，如图所示：</span></span></p>
<p><span style="color:rgb(64,64,64)"> </span></p>
<p><span style="color:rgb(64,64,64)">上图中能看见抛出的一些异常和<span style="font-family:Verdana">name:javahttp://www.javabloger.com</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">name:javahttp://www.javabloger.com1</span><span style="font-family:宋体">的结果集，因为我在</span><span style="font-family:Verdana">serv215</span><span style="font-family:宋体">机器上用</span><span style="font-family:Verdana">killall java</span><span style="font-family:宋体">命令把 </span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">都关掉，并且立刻用</span><span style="font-family:Verdana">Java</span><span style="font-family:宋体">客户端对</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的集群环境进行访问有异常抛出，但是</span><span style="font-family:Verdana">retry</span><span style="font-family:宋体">到一定次数后查询出结果，前面已经说了访问</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">是通过</span><span style="font-family:Verdana">zookeeper</span><span style="font-family:宋体">再和真正的数据打交道，也就是说</span><span style="font-family:Verdana">zookeeper</span><span style="font-family:宋体">接管了一个</span><span style="font-family:Verdana">standby </span><span style="font-family:宋体">的 </span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">，让原先</span><span style="font-family:Verdana">Standby</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">接替了失效的</span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">任务，而被接管的</span><span style="font-family:Verdana">HBaseMaster</span><span style="font-family:宋体">再对</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">的任务进行分配，当 </span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">失败后</span><span style="font-family:Verdana">zookeeper</span><span style="font-family:宋体">会通知 </span><span style="font-family:Verdana">HMaster</span><span style="font-family:宋体">对</span><span style="font-family:Verdana">HReginServer</span><span style="font-family:宋体">的任务进行分配。这样充分的说明了</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">做到了实效转发的功能。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">如图所示：</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)"> </span></p>
<p><span style="color:rgb(64,64,64)">口水：</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">1<span style="font-family:宋体">、</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的失效转发的效率比较慢了，不指望能在</span><span style="font-family:Verdana">1-2</span><span style="font-family:宋体">秒切换和恢复完毕，也许是我暂时没有发现有什么参数可以提高失效转发和恢复过程的速度，将来会继续关注这个问题。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">2<span style="font-family:宋体">、在官方网站上看见</span><span style="font-family:Verdana">HBase0.89.20100924</span><span style="font-family:宋体">的版本有篇讲述关于数据同步的文章，我尝试了一下在一台机器上可以运行所谓的</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">虚拟集群环境，但是切换到多台机器的分布式环境中，单点失效转发的速度很慢比</span><span style="font-family:Verdana">HBase0.20.6</span><span style="font-family:宋体">还要慢，我又检查了是否存在网络的问题，目前尚未找到正确的答案，对与</span><span style="font-family:Verdana">HBase0.89.20100924 </span><span style="font-family:宋体">新版中的数据同步的原理，如图所示：</span><span style="font-family:Verdana">(</span></span><a target="_blank" href="http://hbase.apache.org/docs/r0.89.20100924/replication.html" rel="nofollow"><span style="color:rgb(0,0,255)">更多信息</span></a><span style="color:rgb(64,64,64)">)</span></p>
<p><a target="_blank" href="http://a7l8ig.bay.livefilestore.com/y1px9fq45qmsHJTelsmQB80Of4YrmrbGMPJDSOPc7VxjxU6UZb2x4bnl1_xPdbSV7fPna8iuCubQx0ctnuVXSDG3kz-x15J_pAG/replication_overview.png?psid=1" rel="nofollow"><span style="color:rgb(0,0,0)"><br>
</span></a></p>
<p><span style="color:rgb(64,64,64)">可以留言或者发邮件与我交流，我的联系方式是<span style="font-family:Verdana">:njthnet  # gmail.com</span></span></p>
<p>三十、 HBase入门篇2-Java操作HBase例子</p>
<p>   <span style="color:rgb(64,64,64)">   <span style="font-family:宋体">本篇文章讲述用</span><span style="font-family:Verdana">HBase Shell</span><span style="font-family:宋体">命令 和 </span><span style="font-family:Verdana">HBase Java API </span><span style="font-family:宋体">对</span><span style="font-family:Verdana">HBase </span><span style="font-family:宋体">服务器 进行操作。在此之前需要对</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的总体上有个大概的了解。比如说</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">服务器内部由哪些主要部件构成？</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的内部工作原理是什么？我想学习任何一项知识、技术的态度不能只是知道如何使用，对产品的内部构建一点都不去关心，那样出了问题，很难让你很快的找到答案，甚至我们希望最后能对该项技术的领悟出自己的心得，为我所用，借鉴该项技术其中的设计思想创造出自己的解决方案，更灵活的去应对多变的计算场景与架构设计。以我目前的对</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的了解还不够深入，将来不断的学习，我会把我所知道的点滴分享到这个</span><span style="font-family:Verdana">Blog</span><span style="font-family:宋体">上。</span></span></p>
<p><span style="color:rgb(64,64,64)">     <span style="font-family:宋体">先来看一下读取一行记录</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">是如何进行工作的，首先</span><span style="font-family:Verdana">HBase Client</span><span style="font-family:宋体">端会连接</span><span style="font-family:Verdana">Zookeeper Qurom</span></span><span style="color:rgb(64,64,64)">(<span style="font-family:宋体">从下面的代码也能看出来，例如：</span><span style="font-family:Verdana">HBASE_CONFIG.set("hbase.zookeeper.quorum", "192.168.50.216") </span></span><span style="color:rgb(64,64,64)">)<span style="font-family:宋体">。通过</span><span style="font-family:Verdana">Zookeeper</span><span style="font-family:宋体">组件</span><span style="font-family:Verdana">Client</span><span style="font-family:宋体">能获知哪个</span><span style="font-family:Verdana">Server</span><span style="font-family:宋体">管理</span><span style="font-family:Verdana">-ROOT- Region</span><span style="font-family:宋体">。那么</span><span style="font-family:Verdana">Client</span><span style="font-family:宋体">就去访问管理</span><span style="font-family:Verdana">-ROOT-</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">Server</span><span style="font-family:宋体">，在</span><span style="font-family:Verdana">META</span><span style="font-family:宋体">中记录了</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">中所有表信息，</span><span style="font-family:Verdana">(</span><span style="font-family:宋体">你可以使用</span><span style="font-family:Verdana">  scan '.META.' </span><span style="font-family:宋体">命令列出你创建的所有表的详细信息</span><span style="font-family:Verdana">),</span><span style="font-family:宋体">从而获取</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">分布的信息。一旦</span><span style="font-family:Verdana">Client</span><span style="font-family:宋体">获取了这一行的位置信息，比如这一行属于哪个</span><span style="font-family:Verdana">Region</span><span style="font-family:宋体">，</span><span style="font-family:Verdana">Client</span><span style="font-family:宋体">将会缓存这个信息并直接访问</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">。久而久之</span><span style="font-family:Verdana">Client</span><span style="font-family:宋体">缓存的信息渐渐增多，即使不访问</span><span style="font-family:Verdana">.META.</span><span style="font-family:宋体">表也能知道去访问哪个</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">。</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">中包含两种基本类型的文件，一种用于存储</span><span style="font-family:Verdana">WAL</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">log</span><span style="font-family:宋体">，另一种用于存储具体的数据，这些数据都通过</span><span style="font-family:Verdana">DFS Client</span><span style="font-family:宋体">和分布式的文件系统</span><span style="font-family:Verdana">HDFS</span><span style="font-family:宋体">进行交互实现存储。</span></span></p>
<p><span style="color:rgb(64,64,64)">如图所示：</span></p>
<p><a target="_blank" href="http://niaklq.bay.livefilestore.com/y1pX0l7uDaGqyf11KWFupkIkan9-yVosEZOno4HK8qpCdO8NIfbtwrYtckBTf73hsoDphtQ34WLC36HmqWLsHUrkFpMpuflRs_t/HBase-Architecture-1.jpg?psid=1" rel="nofollow"><span style="color:rgb(0,0,0)"><br>
</span><span style="color:rgb(0,0,0)"><br>
</span></a></p>
<p><a target="_blank" href="http://niaklq.bay.livefilestore.com/y1pX0l7uDaGqyf11KWFupkIkan9-yVosEZOno4HK8qpCdO8NIfbtwrYtckBTf73hsoDphtQ34WLC36HmqWLsHUrkFpMpuflRs_t/HBase-Architecture-1.jpg?psid=1" rel="nofollow"><span style="color:rgb(0,0,255)">查看大图请点击这里</span><span style="color:rgb(0,0,0)"><br>
</span></a></p>
<p><span style="color:rgb(64,64,64)">再来看看<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的一些内存实现原理： </span><span style="font-family:Verdana">   </span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    * HMaster— HBase<span style="font-family:宋体">中仅有一个</span><span style="font-family:Verdana">Master server</span><span style="font-family:宋体">。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    * HRegionServer—<span style="font-family:宋体">负责多个</span><span style="font-family:Verdana">HRegion</span><span style="font-family:宋体">使之能向</span><span style="font-family:Verdana">client</span><span style="font-family:宋体">端提供服务，在</span><span style="font-family:Verdana">HBase cluster</span><span style="font-family:宋体">中会存在多个</span><span style="font-family:Verdana">HRegionServer</span><span style="font-family:宋体">。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    * ServerManager—<span style="font-family:宋体">负责管理</span><span style="font-family:Verdana">Region server</span><span style="font-family:宋体">信息，如每个</span><span style="font-family:Verdana">Region server</span><span style="font-family:宋体">的</span><span style="font-family:Verdana">HServerInfo(</span><span style="font-family:宋体">这个对象包含</span><span style="font-family:Verdana">HServerAddress</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">startCode),</span><span style="font-family:宋体">已</span><span style="font-family:Verdana">load Region</span><span style="font-family:宋体">个数，死亡的</span><span style="font-family:Verdana">Region server</span><span style="font-family:宋体">列表</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    * RegionManager—<span style="font-family:宋体">负责将</span><span style="font-family:Verdana">region</span><span style="font-family:宋体">分配到</span><span style="font-family:Verdana">region server</span><span style="font-family:宋体">的具体工作，还监视</span><span style="font-family:Verdana">root</span><span style="font-family:宋体">和</span><span style="font-family:Verdana">meta </span><span style="font-family:宋体">这</span><span style="font-family:Verdana">2</span><span style="font-family:宋体">个系统级的</span><span style="font-family:Verdana">region</span><span style="font-family:宋体">状态。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    * RootScanner—<span style="font-family:宋体">定期扫描</span><span style="font-family:Verdana">root region</span><span style="font-family:宋体">，以发现没有分配的</span><span style="font-family:Verdana">meta region</span><span style="font-family:宋体">。</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    * MetaScanner—<span style="font-family:宋体">定期扫描</span><span style="font-family:Verdana">meta region,</span><span style="font-family:宋体">以发现没有分配的</span><span style="font-family:Verdana">user region</span><span style="font-family:宋体">。</span></span></p>
<p><span style="color:rgb(64,64,64)">HBase<span style="font-family:宋体">基本命令</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">下面我们再看看看<span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的一些基本操作命令，我列出了几个常用的</span><span style="font-family:Verdana">HBase Shell</span><span style="font-family:宋体">命令，如下：</span></span></p>
<table>
<tbody>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">名称</span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">命令表达式</span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">创建表</span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">create '<span style="font-family:宋体">表名称</span><span style="font-family:Verdana">', '</span><span style="font-family:宋体">列名称</span><span style="font-family:Verdana">1','</span><span style="font-family:宋体">列名称</span><span style="font-family:Verdana">2','</span><span style="font-family:宋体">列名称</span><span style="font-family:Verdana">N'</span></span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">添加记录<span style="font-family:Verdana">      </span></span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">put '<span style="font-family:宋体">表名称</span><span style="font-family:Verdana">', '</span><span style="font-family:宋体">行名称</span><span style="font-family:Verdana">', '</span><span style="font-family:宋体">列名称</span><span style="font-family:Verdana">:', '</span><span style="font-family:宋体">值</span><span style="font-family:Verdana">'</span></span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">查看记录</span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">get '<span style="font-family:宋体">表名称</span><span style="font-family:Verdana">', '</span><span style="font-family:宋体">行名称</span><span style="font-family:Verdana">'</span></span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">查看表中的记录总数</span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">count  '<span style="font-family:宋体">表名称</span><span style="font-family:Verdana">'</span></span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">删除记录</span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">delete  '<span style="font-family:宋体">表名</span><span style="font-family:Verdana">' ,'</span><span style="font-family:宋体">行名称</span><span style="font-family:Verdana">' , '</span><span style="font-family:宋体">列名称</span><span style="font-family:Verdana">'</span></span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">删除一张表</span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">先要屏蔽该表，才能对该表进行删除，第一步 <span style="font-family:Verdana">disable '</span><span style="font-family:宋体">表名称</span><span style="font-family:Verdana">' </span><span style="font-family:宋体">第二步</span><span style="font-family:Verdana">  drop '</span><span style="font-family:宋体">表名称</span><span style="font-family:Verdana">'</span></span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">查看所有记录</span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">scan "<span style="font-family:宋体">表名称</span><span style="font-family:Verdana">"  </span></span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">查看某个表某个列中所有数据</span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">scan "<span style="font-family:宋体">表名称</span><span style="font-family:Verdana">" , ['</span><span style="font-family:宋体">列名称</span><span style="font-family:Verdana">:']</span></span></p>
</td>
</tr>
<tr>
<td valign="center">
<p><span style="color:rgb(64,64,64)">更新记录<span style="font-family:Verdana"> </span></span></p>
</td>
<td valign="center">
<p><span style="color:rgb(64,64,64)">就是重写一遍进行覆盖</span></p>
</td>
</tr>
</tbody>
</table>
<p><span style="color:rgb(64,64,64)">  <span style="font-family:宋体">如果你是一个新手队</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">的一些命令还不算非常熟悉的话，你可以进入 </span><span style="font-family:Verdana">hbase </span><span style="font-family:宋体">的</span><span style="font-family:Verdana">shell </span><span style="font-family:宋体">模式中你可以输入 </span><span style="font-family:Verdana">help </span><span style="font-family:宋体">命令查看到你可以执行的命令和对该命令的说明，例如对</span><span style="font-family:Verdana">scan</span><span style="font-family:宋体">这个命令，</span><span style="font-family:Verdana">help</span><span style="font-family:宋体">中不仅仅提到有这个命令，还详细的说明了</span><span style="font-family:Verdana">scan</span><span style="font-family:宋体">命令中可以使用的参数和作用，例如，根据列名称查询的方法和带</span><span style="font-family:Verdana">LIMIT </span><span style="font-family:宋体">、</span><span style="font-family:Verdana">STARTROW</span><span style="font-family:宋体">的使用方法：</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">scan   Scan a table; pass table name and optionally a dictionary of scanner specifications.  Scanner specifications may include one or more of  the following: LIMIT, STARTROW, STOPROW, TIMESTAMP, or COLUMNS.  If no columns are specified, all columns will be scanned.  To scan all members of a column family, leave the qualifier empty as in  'col_family:'.  Examples:</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            hbase&gt; scan '.META.'</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            hbase&gt; scan '.META.', {COLUMNS =&gt; 'info:regioninfo'}</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            hbase&gt; scan 't1', {COLUMNS =&gt; ['c1', 'c2'], LIMIT =&gt; 10, STARTROW =&gt; 'xyz'}</span></p>
<p><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">使用<span style="font-family:Verdana">Java API</span><span style="font-family:宋体">对</span><span style="font-family:Verdana">HBase</span><span style="font-family:宋体">服务器进行操作</span></span></p>
<p><span style="color:rgb(64,64,64)">需要下列<span style="font-family:Verdana">jar</span><span style="font-family:宋体">包</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     hbase-0.20.6.jar</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     hadoop-core-0.20.1.jar</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     commons-logging-1.1.1.jar</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     zookeeper-3.3.0.jar</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     log4j-1.2.91.jar</span></p>
<p><span style="color:rgb(64,64,64)">import org.apache.hadoop.conf.Configuration;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.HBaseConfiguration;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.HColumnDescriptor;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.HTableDescriptor;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.KeyValue;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.client.HBaseAdmin;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.client.HTable;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.client.Result;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.client.ResultScanner;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.client.Scan;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">import org.apache.hadoop.hbase.io.BatchUpdate;</span></p>
<p><span style="color:rgb(64,64,64)">@SuppressWarnings("deprecation")</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">public class HBaseTestCase {</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    static HBaseConfiguration cfg = null;</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    static {</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        Configuration HBASE_CONFIG = new Configuration();</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        HBASE_CONFIG.set("hbase.zookeeper.quorum", "192.168.50.216");</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        HBASE_CONFIG.set("hbase.zookeeper.property.clientPort", "2181");</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        cfg = new HBaseConfiguration(HBASE_CONFIG);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    /**</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     * <span style="font-family:宋体">创建一张表</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     */</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    public static void creatTable(String tablename) throws Exception {</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        HBaseAdmin admin = new HBaseAdmin(cfg);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        if (admin.tableExists(tablename)) {</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            System.out.println("table   Exists!!!");</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        else{</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            HTableDescriptor tableDesc = new HTableDescriptor(tablename);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            tableDesc.addFamily(new HColumnDescriptor("name:"));</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            admin.createTable(tableDesc);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            System.out.println("create table ok .");</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">         </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    /**</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     * <span style="font-family:宋体">添加一条数据</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     */</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    public static void addData (String tablename) throws Exception{</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">         HTable table = new HTable(cfg, tablename);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">             BatchUpdate update = new BatchUpdate("Huangyi");  </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">             update.put("name:java", "http://www.javabloger.com".getBytes());  </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">             table.commit(update);  </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">         System.out.println("add data ok .");</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    /**</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     * <span style="font-family:宋体">显示所有数据</span></span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">     */</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    public static void getAllData (String tablename) throws Exception{</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">         HTable table = new HTable(cfg, tablename);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">         Scan s = new Scan();</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">         ResultScanner ss = table.getScanner(s);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">         for(Result r:ss){</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">             for(KeyValue kv:r.raw()){</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">                System.out.print(new String(kv.getColumn()));</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">                System.out.println(new String(kv.getValue()    ));</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">             }</span></p>
<p><span style="color:rgb(64,64,64)">         }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    public static void  main (String [] agrs) {</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        try {</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">                String tablename="tablename";</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">                HBaseTestCase.creatTable(tablename);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">                HBaseTestCase.addData(tablename);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">                HBaseTestCase.getAllData(tablename);</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            } </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        catch (Exception e) {</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">            e.printStackTrace();</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">        </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    }</span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">    </span><span style="color:rgb(64,64,64)"><br>
</span><span style="color:rgb(64,64,64)">}</span></p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
            </div>
                </div>