---
layout:     post
title:      Hadoop v1.1.2安装配置 
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <div class="iteye-blog-content-contain" style="font-size:14px;">
<p><span style="color:#323e32;font-family:simsun;background-color:#9caec1;"> </span></p>
<div style="color:#323e32;font-family:simsun;background-color:#9caec1;">
<ol style="border:0px;"><li style="border:0px;">下载Hadoop最新版：<span style="line-height:21px;font-family:'Times new roman', serif;">wget</span> <a style="color:#318b92;" href="http://mirror.bjtu.edu.cn/apache/hadoop/common/hadoop-1.0.0/hadoop-1.0.0-bin.tar.gz" rel="nofollow">http://mirror.bjtu.edu.cn/apache/hadoop/common/hadoop-1.1.2/hadoop-1.1.2-bin.tar.gz</a>
</li>
<li style="border:0px;">解压：tar -xzf hadoop-1.1.2-bin.tar.gz</li>
<li style="border:0px;">进入Hadoop目录</li>
<li style="border:0px;">编辑hadoop_home/etc/hadoop/hadoop-env.sh文件（在旧版本中在conf目录下），加入JAVA_HOME环境变量定义：export JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-i386</li>
</ol><div>由于我们希望Hadoop运行在伪分布式环境下，这样可以模拟真实环境。需要进行如下配置：</div>
</div>
<div style="color:#323e32;font-family:simsun;background-color:#9caec1;">编辑hadoop/conf目录下</div>
<div style="color:#323e32;font-family:simsun;background-color:#9caec1;">/core-site.xml文件：</div>
<div style="color:#323e32;font-family:simsun;background-color:#9caec1;">
<div>&lt;configuration&gt;</div>
<div>     &lt;property&gt;</div>
<div>         &lt;name&gt;fs.default.name&lt;/name&gt;</div>
<div>         &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</div>
<div>     &lt;/property&gt;</div>
<div>&lt;/configuration&gt;</div>
</div>
<div style="color:#323e32;font-family:simsun;background-color:#9caec1;"><span>hdfs-site.xml文件：</span></div>
<div style="color:#323e32;font-family:simsun;background-color:#9caec1;">
<div><span>&lt;configuration&gt;</span></div>
<div>     &lt;property&gt;</div>
<div>         &lt;name&gt;dfs.replication&lt;/name&gt;</div>
<div>         &lt;value&gt;1&lt;/value&gt;</div>
<div>     &lt;/property&gt;</div>
<div>&lt;/configuration&gt;</div>
<div>mapred-site.xml文件：</div>
<div>
<div>&lt;configuration&gt;</div>
<div>     &lt;property&gt;</div>
<div>         &lt;name&gt;mapred.job.tracker&lt;/name&gt;</div>
<div>         &lt;value&gt;localhost:9001&lt;/value&gt;</div>
<div>     &lt;/property&gt;</div>
<div>&lt;/configuration&gt;</div>
</div>
<div>接下来配置SSH：</div>
<div>
<div>ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa </div>
<div>cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</div>
</div>
<div>然后是准备HDFS系统：</div>
<div>bin/hadoop namenode -format</div>
<div>下面启动Hadoop（注意缺省情况下sbin目录下文件全不是可执行文件，需要chmod 777 *）：</div>
<div>sbin/start-all.sh</div>
<div>此时可以通过http://localhost:50070和http://localhost:50030来验证安装是否正确，如果可以显示网页，就证明安装是正确的。</div>
<div>Hadoop的停止命令：sbin/stop-all.sh</div>
</div>
</div>            </div>
                </div>