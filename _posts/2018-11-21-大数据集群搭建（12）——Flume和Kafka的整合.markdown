---
layout:     post
title:      大数据集群搭建（12）——Flume和Kafka的整合
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p style="margin-left:0pt;"><strong><strong>Flume和Kafka的整合</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>1.配置flume，在flume的conf目录下新建文件（flume_kafka.conf）并配置。</strong></strong></p>

<blockquote>
<p style="margin-left:0pt;"><strong><strong> ########################################################</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>##主要作用是监听目录中的新增数据，采集到数据之后，输出到kafka</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>##    注意：Flume agent的运行，主要就是配置source channel sink</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>##  下面的a1就是agent的代号，source叫r1 channel叫c1 sink叫k1</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>#########################################################</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sources = r1</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sinks = k1</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.channels = c1</strong></strong></p>

<p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;"><strong><strong>#具体定义source</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sources.r1.type = </strong></strong><strong><span style="color:#df402a;"><strong>spooldir</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><strong>#先创建此目录，保证里面空的</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sources.r1.</strong></strong><strong><span style="color:#df402a;"><strong>spoolDir</strong></span></strong><strong><strong> = </strong></strong><strong><span style="color:#df402a;"><strong>/logs</strong></span></strong></p>

<p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;"><strong><strong>#sink到kafka里面</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sinks.k1.channel = c1</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sinks.k1.type =org.apache.flume.sink.kafka.KafkaSink</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>#设置Kafka的Topic</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sinks.k1.kafka.topic = </strong></strong><strong><span style="color:#df402a;"><strong>test3</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><strong>#设置Kafka的broker地址和端口号</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sinks.k1.kafka.bootstrap.servers = </strong></strong><strong><span style="color:#df402a;"><strong>master:9092,slaver1:9092,slaver2:9092</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><strong>#配置批量提交的数量</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sinks.k1.kafka.flumeBatchSize = 20</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sinks.k1.kafka.producer.acks = 1</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sinks.k1.kafka.producer.linger.ms = 1</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sinks.ki.kafka.producer.compression.type= snappy</strong></strong></p>

<p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;"><strong><strong>#对于channel的配置描述 使用文件做数据的临时缓存 这种的安全性要高</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.channels.c1.type = file</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.channels.c1.checkpointDir = /home/uplooking/data/flume/checkpoint</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.channels.c1.dataDirs = /home/uplooking/data/flume/data</strong></strong></p>

<p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;"><strong><strong>#通过channel c1将source r1和sink k1关联起来</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sources.r1.channels = c1</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sinks.k1.channel = c1</strong></strong></p>
</blockquote>

<p style="margin-left:0pt;"><strong><strong>2.启动</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>2.1.启动Zookeeper(3台)</strong></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#df402a;"><strong>[root@master bin]# ./zkServer.sh start</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><strong>2.2.再启动kafka(3台)</strong></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#df402a;"><strong>./bin/kafka-server-start.sh -daemon config/server.properties &amp;</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><strong>2.3.如果没有主题创建主题</strong></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#df402a;"><strong>./bin/kafka-topics.sh --create --zookeeper master:2181,slaver1:2181,slaver2:2181 --replication-factor 3 --partitions 3 --topic 主题名</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><strong>2.4.启动一个该主题的消费者</strong></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#df402a;"><strong>./bin/kafka-console-consumer.sh --bootstrap-server master:9092, slaver1:9092, slaver2:9092 --from-beginning --topic 主题名</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><strong>2.5.启动flume</strong></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#df402a;"><strong>bin/flume-ng agent -n a1 -c conf -f conf/文件名 -Dflume.root.logger=INFO,console</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><strong>2.6.向flume监听目录里面添加内容，观察消费者</strong></strong></p>

<p style="margin-left:0pt;"> </p>            </div>
                </div>