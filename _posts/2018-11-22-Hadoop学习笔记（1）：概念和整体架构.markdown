---
layout:     post
title:      Hadoop学习笔记（1）：概念和整体架构
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>http://www.cnblogs.com/kubixuesheng/p/5525306.html<br></p>
<p><br></p>
<p></p>
<h1 class="postTitle" style="border-bottom:1px solid rgb(221,221,221);font-size:14px;font-family:Verdana, Arial, Helvetica, sans-serif;">
<a id="cb_post_title_url" class="postTitle2" href="http://www.cnblogs.com/kubixuesheng/p/5525306.html" rel="nofollow" style="text-decoration:none;color:rgb(0,0,0);line-height:1.5;">Hadoop学习笔记（1）：概念和整体架构</a></h1>
<div class="clear" style="clear:both;font-family:Verdana, Arial, Helvetica, sans-serif;font-size:13px;">
</div>
<div class="postBody" style="color:rgb(17,17,17);font-size:13px;line-height:1.8;font-family:Verdana, Arial, Helvetica, sans-serif;">
<div id="cnblogs_post_body">
<p style="color:#000080;font-size:12px;">
<br></p>
<ul><li style="list-style:disc inside;">Hadoop简介和历史</li><li style="list-style:disc inside;">Hadoop架构体系</li><li style="list-style:disc inside;">Master和Slave节点</li><li style="list-style:disc inside;">数据分析面临的问题和Hadoop思想</li></ul><p> </p>
<p>　　由于工作原因，必须学习和深入一下Hadoop，特此记录笔记。</p>
<p> </p>
<p>　　<span><span style="background-color:rgb(255,255,0);">什么是hadoop？</span></span></p>
<p>　　Apache Hadoop是一款支持<span style="color:rgb(255,0,0);">数据密集型分布式应用</span>并以Apache 2.0许可协议发布的<span style="color:rgb(255,0,0);">开源软件框架</span>。它支持在商品硬件构建的大型集群上运行的应用程序。<span><span style="color:rgb(255,0,0);">Hadoop是根据Google公司发表的MapReduce和Google档案系统的论文自行实作而成。</span></span></p>
<p><span><span style="color:rgb(255,0,0);">　　</span></span>Hadoop框架透明地为应用提供可靠性和数据移动。它实现了名为<span style="color:rgb(255,0,0);">MapReduce的编程范式：应用程序被分割成许多小部分，而每个部分都能在集群中的任意节点上执行或重新执行。</span>此外，Hadoop还提供了分布式文件系统，用以存储所有计算节点的数据，这为整个集群带来了非常高的带宽。MapReduce和分布式文件系统的设计，使得整个框架能够自动处理节点故障。它使应用程序与成千上万的独立计算的电脑和PB级的数据。<span style="line-height:1.5;">　　</span></p>
<p>　</p>
<p>　　<span><span style="background-color:rgb(255,255,0);">hadoop历史</span></span></p>
<p>　　Hadoop由 Apache Software Foundation 于 2005 年秋天作为Lucene的子项目Nutch的一部分正式引入。它受到最先由 Google Lab 开发的 Map/Reduce 和 Google File System(GFS) 的启发。</p>
<p>　　2006 年 3 月份，Map/Reduce 和 Nutch Distributed File System (NDFS) 分别被纳入称为 Hadoop 的项目中。Hadoop 是最受欢迎的在 Internet 上对搜索关键字进行内容分类的工具，但它也可以解决许多要求极大伸缩性的问题。例如，如果您要 grep 一个 10TB 的巨型文件，会出现什么情况？在传统的系统上，这将需要很长的时间。但是
 Hadoop 在设计时就考虑到这些问题，采用并行执行机制，因此能大大提高效率。</p>
<ul><li style="list-style:disc inside;">Hadoop Common：在0.20及以前的版本中，包含HDFS、MapReduce和其他项目公共内容，从0.21开始HDFS和MapReduce被分离为独立的子项目，其余内容为Hadoop Common</li><li style="list-style:disc inside;">HDFS：Hadoop分布式文件系统（Distributed File System）－HDFS（Hadoop Distributed File System）</li><li style="list-style:disc inside;">MapReduce：并行计算框架，0.20前使用org.apache.hadoop.mapred旧接口，0.20版本开始引入org.apache.hadoop.mapreduce的新API</li><li style="list-style:disc inside;">Apache HBase：分布式NoSQL列数据库，类似谷歌公司BigTable。</li><li style="list-style:disc inside;">Apache Hive：构建于hadoop之上的数据仓库，通过一种类SQL语言HiveQL为用户提供数据的归纳、查询和分析等功能。Hive最初由Facebook贡献。</li><li style="list-style:disc inside;">Apache Mahout：机器学习算法软件包。</li><li style="list-style:disc inside;">Apache Sqoop：结构化数据（如关系数据库）与Apache Hadoop之间的数据转换工具。</li><li style="list-style:disc inside;">Apache ZooKeeper：分布式锁设施，提供类似Google Chubby的功能，由Facebook贡献。</li><li style="list-style:disc inside;">Apache Avro：新的数据序列化格式与传输工具，将逐步取代Hadoop原有的IPC机制。</li></ul><p> </p>
<p>　　<span style="background-color:rgb(255,255,0);"><span>hadoop平台子项目</span></span><span style="line-height:1.5;"><br></span></p>
<p><img src="http://images2015.cnblogs.com/blog/682679/201606/682679-20160620210009647-1359402318.png" alt="" style="border:0px;width:637px;"></p>
<p>　<span>　</span>现在普遍认为整个Apache Hadoop“平台”包括Hadoop内核、MapReduce、Hadoop分布式文件系统（HDFS）以及一些相关项目，有Apache Hive和Apache HBase等等。Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，则MapReduce为海量的数据提供了计算。</p>
<p>　　如图，最下面一层就是hadoop的核心代码，核心代码之上实现了两个最核心的功能：MapReduce和HDFS，这是hadoop的两大支柱！因为hadoop是Java写的，为了方便其他对Java语言不熟悉的程序员，在这之上又有Pig，这是一个轻量级的语言，用户可以使用Pig用于数据分析和处理，系统会自动把它转化为MapReduce程序。</p>
<p>　　还有一个Hive，很重要！这是一个传统的SQL到MapReduce的映射器，面向传统的数据库工程师。但是不支持全部SQL。还有一个子项目叫HBase，一个非关系数据库，NoSQL数据库，数据是列存储的，提高响应速度，减少IO量，可以做成分布式集群。</p>
<p>　　ZooKeeper负责服务器节点和进程间的通信，是一个协调工具，因为Hadoop的几乎每个子项目都是用动物做logo，故这个协调软件叫动物园管理员。</p>
<p> </p>
<p>　　<span style="background-color:rgb(255,255,0);"><span>Hadoop架构</span></span></p>
<p><img src="http://images2015.cnblogs.com/blog/682679/201606/682679-20160620211821944-76440873.png" alt="" style="border:0px;width:637px;"></p>
<p>　　如图，两个服务器机柜，每个圆柱代表一个物理机，各个物理节点通过网线连接，连接到交换机，然后客户端通过互联网来访问。其中各个物理机上都运行着Hadoop的一些后台进程。</p>
<p> </p>
<p>　　<span style="background-color:rgb(255,255,0);color:rgb(255,0,0);"><span>Namenode</span></span></p>
<p>　　<img src="http://images2015.cnblogs.com/blog/682679/201606/682679-20160620222533678-1005831470.png" alt="" style="border:0px;"></p>
<p>　　也叫名称节点，是HDFS的守护程序（一个核心程序），对整个分布式文件系统进行总控制，会纪录所有的元数据分布存储的状态信息，比如文件是如何分割成数据块的，以及这些数据块被存储到哪些节点上，还有对内存和I/O进行集中管理，用户首先会访问Namenode，通过该总控节点获取文件分布的状态信息，找到文件分布到了哪些数据节点，然后在和这些节点打交道，把文件拿到。故这是一个核心节点。</p>
<p>　　<span style="color:rgb(255,0,0);">不过这是个单点，发生故障将使集群崩溃。</span></p>
<p> </p>
<p>　　<span style="background-color:rgb(255,255,0);color:rgb(255,0,0);"><span>Secondary Namenode</span></span></p>
<p><span>　　<img src="http://images2015.cnblogs.com/blog/682679/201606/682679-20160620223707053-1682118655.png" alt="" style="border:0px;"></span></p>
<p>　　在Hadoop中，有一些命名不好的模块，Secondary NameNode是其中之一。从它的名字上看，它给人的感觉就像是NameNode的备份，比如有人叫它第二名称节点，仿佛给人感觉还有后续……但它实际上却不完全是。</p>
<p>　　最好翻译为<span><span style="color:rgb(255,0,0);">辅助名称节点，或者检查点节点</span></span>，它是<span style="color:rgb(255,0,0);"><span>监控HDFS状态的辅助后台程序</span></span>，可以保存名称节点的副本，故每个集群都有一个，它与NameNode进行通讯，定期保存HDFS元数据快照。<span style="color:rgb(255,0,0);">NameNode故障可以作为备用NameNode使用，目前还不能自动切换。但是功能绝不仅限于此。所谓后备也不是它的主要功能。后续详细解释。</span></p>
<p>　　</p>
<p><span>　　</span><span style="color:rgb(255,0,0);"><span><span style="background-color:rgb(255,255,0);">DataNode</span></span></span></p>
<p>　　<img src="http://images2015.cnblogs.com/blog/682679/201606/682679-20160620223933990-828799821.png" alt="" style="border:0px;"></p>
<p>　　叫数据节点，<span style="color:rgb(255,0,0);"><span>每台从服务器节点都运行一个</span></span>，负责把HDFS数据块读、写到本地文件系统。<span style="color:rgb(255,0,0);"><span>这三个东西组成了Hadoop平台其中一个支柱——HDFS体系。</span></span></p>
<p> </p>
<p><span style="color:rgb(255,0,0);"><span>　　再看另一个支柱——MapReduce，有两个后台进程。</span></span></p>
<p><span>　　</span><span style="color:rgb(255,0,0);"><span><span style="background-color:rgb(255,255,0);">JobTracker</span></span></span></p>
<p> </p>
<p><span><span><span><span>　　<span><img src="http://images2015.cnblogs.com/blog/682679/201606/682679-20160620223707053-1682118655.png" alt="" style="border:0px;"></span></span></span></span></span></p>
<p>　　叫作业跟踪器，运行到主节点（Namenode）上的一个很重要的进程，是MapReduce体系的调度器。用于处理作业（用户提交的代码）的后台程序，决定有哪些文件参与作业的处理，然后把作业切割成为一个个的小task，并把它们分配到所需要的数据所在的子节点。</p>
<p>　　Hadoop的原则就是就近运行，数据和程序要在同一个物理节点里，数据在哪里，程序就跑去哪里运行。这个工作是JobTracker做的，监控task，还会重启失败的task（于不同的节点），<span><span style="color:rgb(255,0,0);">每个集群只有唯一一个JobTracker，类似单点的nn，位于Master节点（稍后解释Master节点和slave节点）</span></span>。</p>
<p><span>　　</span></p>
<p><span>　　</span><span style="background-color:rgb(255,255,0);color:rgb(255,0,0);"><span>TaskTracker</span></span></p>
<p><span><span><span><span>　　<span><span><span><span><span><img src="http://images2015.cnblogs.com/blog/682679/201606/682679-20160620223707053-1682118655.png" alt="" style="border:0px;"></span></span></span></span></span></span></span></span></span></p>
<p>　　叫任务跟踪器，MapReduce体系的最后一个后台进程，位于每个slave节点上，与datanode结合（代码与数据一起的原则），管理各自节点上的task（由jobtracker分配），<span style="color:rgb(255,0,0);"><span>每个节点只有一个tasktracker，但一个tasktracker可以启动多个JVM</span></span>，用于并行执行map或reduce任务，它与jobtracker交互通信，可以告知jobtracker子任务完成情况。</p>
<p> </p>
<p>　　<span><span style="background-color:rgb(255,255,0);">Master与Slave</span></span></p>
<p>　　Master节点：运行了Namenode、或者Secondary Namenode、或者Jobtracker的节点。还有浏览器（用于观看管理界面），等其它Hadoop工具。<span><span style="color:rgb(255,0,0);">Master不是唯一的！</span></span></p>
<p>　　Slave节点：运行Tasktracker、Datanode的机器。</p>
<p> </p>
<p>　　<span style="background-color:rgb(255,255,0);"><span>数据分析者面临的问题和Hadoop的思想</span></span></p>
<p><span style="line-height:1.5;">　　目前需要我们处理的数据日趋庞大，无论是入库和查询，都出现性能瓶颈，</span>用户的应用和分析结果呈整合趋势，对实时性和响应时间要求越来越高。使用的模型越来越复杂，计算量指数级上升。</p>
<p>　　故，人们希望出现一种技术或者工具来解决性能瓶颈，在可见未来不容易出现新瓶颈，并且学习成本尽量低，使得过去所拥有的技能可以平稳过渡。比如SQL、R等，还有转移平台的成本能否控制最低，比如平台软硬件成本，再开发成本，技能再培养成本，维护成本等。</p>
<p>　　而Hadoop就能解决如上问题——分而治之，化繁为简。</p>
<p> </p>
</div>
<div id="MySignature">辛苦的劳动，转载请注明出处，如果真心帮到了您，为鼓励更多的写作，您可以选择博客右侧的打赏功能。</div>
</div>
<br><p></p>
            </div>
                </div>