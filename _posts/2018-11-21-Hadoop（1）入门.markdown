---
layout:     post
title:      Hadoop（1）入门
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p></p><div class="toc"><div class="toc">
<ul>
<li><a href="#%E4%B8%80-%E4%BB%8Ehadoop%E6%A1%86%E6%9E%B6%E8%AE%A8%E8%AE%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81" rel="nofollow" target="_blank">一 从Hadoop框架讨论大数据生态</a><ul>
<li><a href="#11-hadoop%E6%98%AF%E4%BB%80%E4%B9%88" rel="nofollow" target="_blank">1 Hadoop是什么</a></li>
<li><a href="#12-hadoop" rel="nofollow" target="_blank">2 Hadoop</a></li>
<li><a href="#13-hadoop%E4%B8%89%E5%A4%A7%E5%8F%91%E8%A1%8C%E7%89%88%E6%9C%AC" rel="nofollow" target="_blank">3 Hadoop三大发行版本</a></li>
<li><a href="#14-hadoop%E7%9A%84%E4%BC%98%E5%8A%BF" rel="nofollow" target="_blank">4 Hadoop的优势</a></li>
<li><a href="#15-hadoop%E7%BB%84%E6%88%90" rel="nofollow" target="_blank">5 Hadoop组成</a></li>
<li><a href="#16-%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E7%94%9F%E6%80%81%E4%BD%93%E7%B3%BB" rel="nofollow" target="_blank">6  大数据技术生态体系</a></li>
</ul>
</li>
<li><a href="#%E4%BA%8C-hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F" rel="nofollow" target="_blank">二 Hadoop运行模式</a><ul>
<li><a href="#2-1-%E6%9C%AC%E5%9C%B0%E8%BF%90%E8%A1%8Chadoop-%E6%A1%88%E4%BE%8B" rel="nofollow" target="_blank">2-1 本地运行Hadoop 案例</a></li>
<li><a href="#2-2-%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8Chadoop%E6%A1%88%E4%BE%8B" rel="nofollow" target="_blank">2-2 伪分布式运行Hadoop案例</a><ul>
<li><a href="#1-%E5%90%AF%E5%8A%A8hdfs%E5%B9%B6%E8%BF%90%E8%A1%8Cmapreduce%E7%A8%8B%E5%BA%8F" rel="nofollow" target="_blank">1 启动HDFS并运行MapReduce程序</a></li>
<li><a href="#2-yarn%E4%B8%8A%E8%BF%90%E8%A1%8Cmapreduce-%E7%A8%8B%E5%BA%8F" rel="nofollow" target="_blank">2  YARN上运行MapReduce 程序</a></li>
<li><a href="#3-%E4%BF%AE%E6%94%B9%E6%9C%AC%E5%9C%B0%E4%B8%B4%E6%97%B6%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E7%9B%AE%E5%BD%95" rel="nofollow" target="_blank">3 修改本地临时文件存储目录</a></li>
<li><a href="#4-hadoop%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E" rel="nofollow" target="_blank">4 Hadoop配置文件说明</a></li>
<li><a href="#5-%E5%8E%86%E5%8F%B2%E6%9C%8D%E5%8A%A1%E9%85%8D%E7%BD%AE%E5%90%AF%E5%8A%A8%E6%9F%A5%E7%9C%8B" rel="nofollow" target="_blank">5 历史服务配置启动查看</a></li>
<li><a href="#6-%E6%97%A5%E5%BF%97%E7%9A%84%E8%81%9A%E9%9B%86" rel="nofollow" target="_blank">6 日志的聚集</a></li>
</ul>
</li>
<li><a href="#2-3-%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2hadoop" rel="nofollow" target="_blank">2-3 完全分布式部署Hadoop</a><ul>
<li><a href="#1-scp" rel="nofollow" target="_blank">1 scp</a></li>
<li><a href="#2-ssh%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95" rel="nofollow" target="_blank">2 SSH无密码登录</a></li>
<li><a href="#3-rsync" rel="nofollow" target="_blank">3 rsync</a></li>
<li><a href="#4-xsync%E8%84%9A%E6%9C%AC" rel="nofollow" target="_blank">4 xsync脚本</a></li>
<li><a href="#5xcall%E8%84%9A%E6%9C%AC" rel="nofollow" target="_blank">5xcall脚本</a></li>
<li><a href="#6-%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4" rel="nofollow" target="_blank">6 配置集群</a></li>
<li><a href="#7-%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8%E6%B5%8B%E8%AF%95" rel="nofollow" target="_blank">7 集群启动测试</a></li>
<li><a href="#8-hadoop%E5%90%AF%E5%8A%A8%E5%81%9C%E6%AD%A2%E6%96%B9%E5%BC%8F" rel="nofollow" target="_blank">8 Hadoop启动停止方式</a></li>
<li><a href="#9-%E9%9B%86%E7%BE%A4%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5%E8%AE%BE%E7%BD%AE" rel="nofollow" target="_blank">9 集群时间同步设置</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E4%B8%89-hadoop%E7%BC%96%E8%AF%91%E6%BA%90%E7%A0%81" rel="nofollow" target="_blank">三 Hadoop编译源码</a><ul>
<li><a href="#1-%E5%89%8D%E6%9C%9F%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C" rel="nofollow" target="_blank">1 前期准备工作</a></li>
<li><a href="#2-jar%E5%8C%85%E5%AE%89%E8%A3%85" rel="nofollow" target="_blank">2 jar包安装</a></li>
</ul>
</li>
</ul>
</div>
</div>




<h1 id="一-从hadoop框架讨论大数据生态">一 、从Hadoop框架讨论大数据生态</h1>



<h2 id="11-hadoop是什么">1.1 Hadoop是什么</h2>

<ul>
<li>1）Hadoop是一个由Apache基金会所开发的分布式系统基础架构</li>
<li>2）主要解决，海量数据的存储和海量数据的分析计算问题。</li>
<li>3）广义上来说，HADOOP通常是指一个更广泛的概念——HADOOP生态圈</li>
</ul>



<h2 id="12-hadoop">1.2 Hadoop</h2>

<ul>
<li>1）Lucene–Doug Cutting开创的开源软件，用java书写代码，实现与Google类似的全文搜索功能，它提供了全文检索引擎的架构，包括完整的查询引擎和索引引擎 </li>
<li>2）2001年年底成为apache基金会的一个子项目</li>
<li>3）对于大数量的场景，Lucene面对与Google同样的困难</li>
<li>4）学习和模仿Google解决这些问题的办法 ：微型版Nutch</li>
<li>5）可以说Google是hadoop的思想之源(Google在大数据方面的三篇论文) <br>
GFS —&gt;HDFS <br>
Map-Reduce —&gt;MR <br>
BigTable —&gt;Hbase</li>
<li>6）2003-2004年，Google公开了部分GFS和Mapreduce思想的细节，以此为基础Doug Cutting等人用了2年业余时间实现了DFS和Mapreduce机制，使Nutch性能飙升 </li>
<li>7）2005 年Hadoop 作为 Lucene的子项目 Nutch的一部分正式引入Apache基金会。2006 年 3 月份，Map-Reduce和Nutch Distributed File System (NDFS) 分别被纳入称为 Hadoop 的项目中 </li>
<li>8）名字来源于Doug Cutting儿子的玩具大象 <br>
<div align="left"> <br>
<img src="https://img-blog.csdn.net/20171123094239673" width="100" height="100" alt="LOGO"> <br>
</div></li>
<li>9）Hadoop就此诞生并迅速发展，标志这云计算时代来临</li>
</ul>

<h2 id="13-hadoop三大发行版本">1.3 Hadoop三大发行版本</h2>

<p><strong>Hadoop 三大发行版本: Apache、Cloudera、Hortonworks</strong></p>

<ul>
<li>Apache版本最原始（最基础）的版本，对于入门学习最好。</li>
<li>Cloudera在大型互联网企业中用的较多。</li>
<li><p>Hortonworks文档较好。</p></li>
<li><p><strong>Cloudera Hadoop</strong>  <br>
    （1）2008年成立的Cloudera是最早将Hadoop商用的公司，为合作伙伴提供Hadoop的商用解决方案，主要是包括支持、咨询服务、培训。 <br>
    （2）2009年Hadoop的创始人Doug Cutting也加盟Cloudera公司。Cloudera产品主要为CDH，Cloudera Manager，Cloudera Support <br>
    （3）CDH是Cloudera的Hadoop发行版，完全开源，比Apache Hadoop在兼容性，安全性，稳定性上有所增强。 <br>
    （4）Cloudera Manager是集群的软件分发及管理监控平台，可以在几个小时内部署好一个Hadoop集群，并对集群的节点及服务进行实时监控。Cloudera Support即是对Hadoop的技术支持。 <br>
    （5）Cloudera的标价为每年每个节点4000美元。Cloudera开发并贡献了可实时处理大数据的Impala项目。</p></li>
<li><strong>Hortonworks Hadoop</strong> <br>
    （1）2011年成立的Hortonworks是雅虎与硅谷风投公司Benchmark Capital合资组建。 <br>
    （2）公司成立之初就吸纳了大约25名至30名专门研究Hadoop的雅虎工程师，上述工程师均在2005年开始协助雅虎开发Hadoop，贡献了Hadoop80%的代码。 <br>
    （3）雅虎工程副总裁、雅虎Hadoop开发团队负责人Eric Baldeschwieler出任Hortonworks的首席执行官。 <br>
    （4）Hortonworks的主打产品是Hortonworks Data Platform（HDP），也同样是100%开源的产品，HDP除常见的项目外还包括了Ambari，一款开源的安装和管理系统。 <br>
    （5）HCatalog，一个元数据管理系统，HCatalog现已集成到Facebook开源的Hive中。Hortonworks的Stinger开创性的极大的优化了Hive项目。Hortonworks为入门提供了一个非常好的，易于使用的沙盒。 <br>
    （6）Hortonworks开发了很多增强特性并提交至核心主干，这使得Apache Hadoop能够在包括Window Server和Windows Azure在内的microsoft Windows平台上本地运行。定价以集群为基础，每10个节点每年为12500美元。</li>
</ul>



<h2 id="14-hadoop的优势">1.4 Hadoop的优势</h2>

<ul>
<li>1）<strong>高可靠性</strong>：因为Hadoop假设计算元素和存储会出现故障，因为它维护多个工作数据副本，在出现故障时可以对失败的节点重新分布处理。</li>
<li>2）<strong>高扩展性</strong>：在集群间分配任务数据，可方便的扩展数以千计的节点。</li>
<li>3）<strong>高效性</strong>：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。</li>
<li>4）<strong>高容错性</strong>：自动保存多份副本数据，并且能够自动将失败的任务重新分配。</li>
</ul>



<h2 id="15-hadoop组成">1.5 Hadoop组成</h2>

<ol>
<li><strong>Hadoop HDFS</strong>：一个高可靠、高吞吐量的分布式文件系统。</li>
<li><strong>Hadoop MapReduce</strong>：一个分布式的离线并行计算框架。</li>
<li><strong>Hadoop YARN</strong>：作业调度与集群资源管理的框架。</li>
<li><p><strong>Hadoop Common</strong>：支持其他模块的工具模块。 <br>
<img src="https://img-blog.csdn.net/20171123100701629" alt="hadoop组成" title=""></p>

<ul><li><p><strong>HDFS架构概述</strong> <br>
1）NameNode（nn）：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。 <br>
2）DataNode(dn)：在本地文件系统存储文件块数据，以及块数据的校验和。 <br>
3）Secondary NameNode(2nn)：用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</p></li>
<li><p><strong>Yarn架构概述</strong> <br>
1）ResourceManager(rm)：处理客户端请求、启动/监控ApplicationMaster、监控NodeManager、资源分配与调度； <br>
2）NodeManager(nm)：单个节点上的资源管理、处理来自ResourceManager的命令、处理来自ApplicationMaster的命令； <br>
3）ApplicationMaster：数据切分、为应用程序申请资源，并分配给内部任务、任务监控与容错。 <br>
4）Container：对任务运行环境的抽象，封装了CPU、内存等多维资源以及环境变量、启动命令等任务运行相关的信息。</p></li>
<li><p><strong>MapReduce架构概述</strong> <br>
MapReduce将计算过程分为两个阶段：Map和Reduce <br>
1）Map阶段并行处理输入数据 <br>
2）Reduce阶段对Map结果进行汇总</p>

<div align="left">
<img src="https://img-blog.csdn.net/20171123103203856" width="600" height="400" alt="MapReduce">
</div>

<p><em>上图简单的阐明了map和reduce的两个过程或者作用，虽然不够严谨，但是足以提供一个大概的认知，map过程是一个蔬菜到制成食物前的准备工作，reduce将准备好的材料合并进而制作出食物的过程</em></p></li></ul></li>
</ol>

<h2 id="16-大数据技术生态体系">1.6  大数据技术生态体系</h2>

<p><img src="https://img-blog.csdn.net/20171123111950498" alt="大数据生态体系" title=""></p>

<p><em>图中涉及的技术名词解释如下：</em></p>

<ul>
<li>1）<strong>Sqoop</strong>：sqoop是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle 等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。</li>
<li>2）<strong>Flume</strong>：Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。</li>
<li>3）<strong>Kafka</strong>：Kafka是一种高吞吐量的分布式发布订阅消息系统，有如下特性： <br>
（1）通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。 <br>
（2）高吞吐量：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息 <br>
（3）支持通过Kafka服务器和消费机集群来分区消息。 <br>
（4）支持Hadoop并行数据加载。</li>
<li>4）<strong>Storm</strong>：Storm为分布式实时计算提供了一组通用原语，可被用于“流处理”之中，实时处理消息并更新数据库。这是管理队列及工作者集群的另一种方式。 Storm也可被用于“连续计算”（continuous computation），对数据流做连续查询，在计算时就将结果以流的形式输出给用户。</li>
<li>5）<strong>Spark</strong>：Spark是当前最流行的开源大数据内存计算框架。可以基于Hadoop上存储的大数据进行计算。</li>
<li>6）<strong>Oozie</strong>：Oozie是一个管理Hdoop作业（job）的工作流程调度管理系统。Oozie协调作业就是通过时间（频率）和有效数据触发当前的Oozie工作流程。</li>
<li>7）<strong>Hbase</strong>：HBase是一个分布式的、面向列的开源数据库。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。</li>
<li>8）<strong>Hive</strong>：hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</li>
<li>9）<strong>R语言</strong>：R是用于统计分析、绘图的语言和操作环境。R是属于GNU系统的一个自由、免费、源代码开放的软件，它是一个用于统计计算和统计制图的优秀工具。</li>
<li>10）<strong>Mahout</strong>: <br>
Apache Mahout是个可扩展的机器学习和数据挖掘库，当前Mahout支持主要的4个用例： <br>
推荐挖掘：搜集用户动作并以此给用户推荐可能喜欢的事物。 <br>
聚集：收集文件并进行相关文件分组。 <br>
分类：从现有的分类文档中学习，寻找文档中的相似特征，并为无标签的文档进行正确的归类。 <br>
频繁项集挖掘：将一组项分组，并识别哪些个别项会经常一起出现。</li>
<li>11）<strong>ZooKeeper</strong>：Zookeeper是Google的Chubby一个开源的实现。它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、 分布式同步、组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。</li>
</ul>

<h1 id="二-hadoop运行模式">二、 Hadoop运行模式</h1>

<ul>
<li>1）官方网址 <br>
（1）官方网站： <br>
<a href="http://hadoop.apache.org/" rel="nofollow" target="_blank">http://hadoop.apache.org/</a> <br>
（2）各个版本归档库地址 <br>
<a href="https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/" rel="nofollow" target="_blank">https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/</a> <br>
（3）hadoop2.7.2版本详情介绍 <br>
<a href="http://hadoop.apache.org/docs/r2.7.2/" rel="nofollow" target="_blank">http://hadoop.apache.org/docs/r2.7.2/</a></li>
<li>2）Hadoop运行模式 <br>
（1）本地模式（默认模式）： <br>
不需要启用单独进程，直接可以运行，测试和开发时使用。 <br>
（2）伪分布式模式： <br>
等同于完全分布式，只有一个节点。 <br>
（3）完全分布式模式： <br>
多个节点一起运行。</li>
</ul>



<h2 id="2-1-本地运行hadoop-案例">2-1 本地运行Hadoop 案例</h2>

<p>1）创建在hadoop-2.7.2文件下面创建一个input文件夹 <br>
    <code>[admin@linux01 hadoop-2.7.2]$mkdir input</code> <br>
2）将hadoop的xml配置文件复制到input <br>
    <code>[admin@linux01 hadoop-2.7.2]$cp etc/hadoop/*.xml input</code> <br>
3）执行share目录下的mapreduce程序 <br>
<code>[admin@linux01 hadoop-2.7.2]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output 'dfs[a-z.]+'</code> <br>
4）查看输出结果 <br>
<code>[admin@linux01 hadoop-2.7.2]$ cat output/*</code></p>



<h2 id="2-2-伪分布式运行hadoop案例">2-2 伪分布式运行Hadoop案例</h2>



<h3 id="1-启动hdfs并运行mapreduce程序">1、 启动HDFS并运行MapReduce程序</h3>

<ul>
<li>1）分析： <br>
<ul><li>（1）准备1台客户机</li>
<li>（2）安装jdk</li>
<li>（3）配置环境变量</li>
<li>（4）安装hadoop</li>
<li>（5）配置环境变量</li>
<li>（6）配置集群</li>
<li>（7）启动、测试集群增、删、查</li>
<li>（8）执行wordcount案例</li></ul></li>
<li><p>2）执行步骤 <br>
需要配置hadoop文件如下</p>

<ul><li><p>（1）配置集群</p>

<ul><li>（a）配置：hadoop-env.sh <br>
Linux系统中获取jdk的安装路径： <br>
<code>[root@ linux01 ~]# echo $JAVA_HOME/opt/module/jdk1.7.0_79</code> <br>
修改JAVA_HOME 路径： <br>
<code>export JAVA_HOME=/opt/module/jdk1.7.0_79</code></li>
<li><p>（b）配置：core-site.xml</p>

<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>hdfs://linux01:9000<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-comment">&lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre></li>
<li><p>（c）配置：hdfs-site.xml  </p>

<pre class="prettyprint"><code class="language-xml hljs ">    <span class="hljs-comment">&lt;!-- 指定HDFS副本的数量 --&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre></li></ul></li>
<li>（2）启动集群 <br>
<ul><li>（a）格式化namenode（第一次启动时格式化，以后就不要总格式化） <br>
bin/hdfs namenode -format</li>
<li>（b）启动namenode <br>
sbin/hadoop-daemon.sh start namenode</li>
<li>（c）启动datanode <br>
sbin/hadoop-daemon.sh start datanode</li></ul></li>
<li><p>（3）查看集群</p>

<ul><li>（a）查看是否启动成功 <br>
<code>[root@linux01 ~]# jps <br>
13586 NameNode <br>
13668 DataNode <br>
13786 Jps</code></li>
<li><p>（b）查看产生的log日志 <br>
当前目录：/opt/module/hadoop-2.7.2/logs <br>
<code>[root@linux01 logs]# ls <br>
hadoop-root-datanode-hadoop.atguigu.com.log <br>
hadoop-root-datanode-hadoop.atguigu.com.out <br>
hadoop-root-namenode-hadoop.atguigu.com.log <br>
hadoop-root-namenode-hadoop.atguigu.com.out <br>
SecurityAuth-root.audit</code></p>

<p><code>[root@linux01 logs]# cat hadoop-root-datanode-hadoop.atguigu.com.log</code></p></li>
<li>（c）web端查看HDFS文件系统 <br>
<a href="http://192.168.1.101:50070/dfshealth.html#tab-overview" rel="nofollow" target="_blank">http://192.168.1.101:50070/dfshealth.html#tab-overview</a> <br>
注意：如果不能查看，看如下帖子处理 <br>
<a href="http://www.cnblogs.com/zlslch/p/6604189.html" rel="nofollow" target="_blank">http://www.cnblogs.com/zlslch/p/6604189.html</a></li></ul></li>
<li>（4）操作集群 <br>
<ul><li>（a）在hdfs文件系统上创建一个input文件夹 <br>
<code>[admin@linux01 hadoop-2.7.2]$ bin/hdfs dfs -mkdir -p /user/atguigu/mapreduce/wordcount/input</code></li>
<li>（b）将测试文件内容上传到文件系统上 <br>
<code>bin/hdfs dfs -put wcinput/wc.input  /user/atguigu/mapreduce/wordcount/input/</code></li>
<li>（c）查看上传的文件是否正确 <br>
<code>bin/hdfs dfs -ls  /user/atguigu/mapreduce/wordcount/input/</code> <br>
<code>bin/hdfs dfs -cat  /user/atguigu/mapreduce/wordcount/input/wc.input</code></li>
<li>（d）运行mapreduce程序 <br>
<code>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/mapreduce/wordcount/input/ /user/atguigu/mapreduce/wordcount/output</code></li>
<li>（e）查看输出结果 <br>
命令行查看： <br>
<code>bin/hdfs dfs -cat /user/atguigu/mapreduce/wordcount/output/*</code> <br>
浏览器查看 <br>
<img src="https://img-blog.csdn.net/20171123140753045" alt="hdfs" title=""></li>
<li>（f）将测试文件内容下载到本地 <br>
<code>hadoop fs -get /user/atguigu/mapreduce/wordcount/output/part-r-00000 ./wcoutput/</code></li>
<li>（g）删除输出结果 <br>
<code>hdfs dfs -rmr /user/atguigu/mapreduce/wordcount/output</code></li></ul></li></ul></li>
</ul>

<h3 id="2-yarn上运行mapreduce-程序">2、  YARN上运行MapReduce 程序</h3>

<ul>
<li>1）分析： <br>
<ul><li>（1）准备1台客户机</li>
<li>（2）安装jdk</li>
<li>（3）配置环境变量</li>
<li>（4）安装hadoop</li>
<li>（5）配置环境变量</li>
<li>（6）配置集群yarn上运行</li>
<li>（7）启动、测试集群增、删、查</li>
<li>（8）在yarn上执行wordcount案例</li></ul></li>
<li><p>2）执行步骤</p>

<ul><li><p>（1）配置集群</p>

<ul><li>（a）配置yarn-env.sh <br>
配置一下JAVA_HOME <br>
<code>export JAVA_HOME=/opt/module/jdk1.7.0_79</code></li>
<li><p>（b）配置yarn-site.xml</p>

<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-comment">&lt;!-- reducer获取数据的方式 --&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
 <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
 <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>

<span class="hljs-comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>linux01<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre></li>
<li><p>（c）配置：mapred-env.sh <br>
配置一下JAVA_HOME <br>
<code>export JAVA_HOME=/opt/module/jdk1.7.0_79</code></p></li>
<li>（d）配置： (对mapred-site.xml.template重新命名为) mapred-site.xml <br>
<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-comment">&lt;!-- 指定mr运行在yarn上 --&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre></li></ul></li>
<li><p>（2）启动集群</p>

<ul><li>（a）启动resourcemanager <br>
<code>sbin/yarn-daemon.sh start resourcemanager</code></li>
<li>（b）启动nodemanager <br>
<code>sbin/yarn-daemon.sh start nodemanager</code></li></ul></li>
<li>（3）集群操作 <br>
<ul><li>（a）yarn的浏览器页面查看 <br>
<a href="http://192.168.1.101:8088/cluster" rel="nofollow" target="_blank">http://192.168.1.101:8088/cluster</a> <br>
<img src="https://img-blog.csdn.net/20171123141538866" alt="yarn" title=""></li>
<li>（b）删除文件系统上的output文件 <br>
<code>bin/hdfs dfs -rm -R /user/atguigu/mapreduce/wordcount/output</code></li>
<li>（c）执行mapreduce程序 <br>
<code>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/mapreduce/wordcount/input  /user/atguigu/mapreduce/wordcount/output</code></li>
<li>（d）查看运行结果 <br>
<code>bin/hdfs dfs -cat /user/atguigu/mapreduce/wordcount/output/*</code> <br>
<img src="https://img-blog.csdn.net/20171123141644311" alt="yarn2" title=""></li></ul></li></ul></li>
</ul>

<h3 id="3-修改本地临时文件存储目录">3、 修改本地临时文件存储目录</h3>

<ul>
<li>1）停止进程 <br>
<code>[atguigu@hadoop101 hadoop-2.7.2]$ sbin/yarn-daemon.sh stop nodemanager</code> <br>
<code>[atguigu@hadoop101 hadoop-2.7.2]$ sbin/yarn-daemon.sh stop resourcemanager</code> <br>
<code>[atguigu@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh stop datanode</code> <br>
<code>[atguigu@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh stop namenode</code></li>
<li><p>2）修改hadoop.tmp.dir <br>
[core-site.xml]</p>

<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-comment">&lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre></li>
<li>3）将/opt/module/hadoop-2.7.2路径中的logs文件夹删除掉 <br>
<code>[admin@linux01 hadoop-2.7.2]$ rm -rf logs/</code></li>
<li>4）进入到tmp目录将tmp目录中hadoop-atguigu目录删除掉 <br>
<code>[admin@linux01 tmp]$ rm -rf hadoop-atguigu/</code></li>
<li>5）格式化NameNode <br>
<code>[atguigu@hadoop101 hadoop-2.7.2]$ hadoop namenode -format</code></li>
<li>6）启动所有进程 <br>
<code>[admin@linux01 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode</code> <br>
<code>[admin@linux01 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start datanode</code> <br>
<code>[admin@linux01 hadoop-2.7.2]$ sbin/yarn-daemon.sh start resourcemanager</code> <br>
<code>[admin@linux01 hadoop-2.7.2]$ sbin/yarn-daemon.sh start nodemanager</code></li>
<li>7）查看/opt/module/hadoop-2.7.2/data/tmp这个目录下的内容。</li>
</ul>



<h3 id="4-hadoop配置文件说明">4、 Hadoop配置文件说明</h3>

<p>Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。</p>

<ul>
<li>（1）默认配置文件：存放在hadoop相应的jar包中 <br>
<code>[core-default.xml] <br>
        hadoop-common-2.7.2.jar/ core-default.xml</code> <br>
<code>[hdfs-default.xml] <br>
        hadoop-hdfs-2.7.2.jar/ hdfs-default.xml</code> <br>
<code>[yarn-default.xml] <br>
        hadoop-yarn-common-2.7.2.jar/ yarn-default.xml</code> <br>
<code>[core-default.xml] <br>
        hadoop-mapreduce-client-core-2.7.2.jar/ core-default.xml</code></li>
<li>（2）自定义配置文件：存放在$HADOOP_HOME/etc/hadoop <br>
    core-site.xml <br>
    hdfs-site.xml <br>
    yarn-site.xml <br>
    mapred-site.xml</li>
</ul>



<h3 id="5-历史服务配置启动查看">5、 历史服务配置启动查看</h3>

<ul>
<li>1）配置mapred-site.xml</li>
</ul>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.jobhistory.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>linux01:10020<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>linux01:19888<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>

<ul>
<li>2）查看启动历史服务器文件目录： <br>
<code>[root@linux01 hadoop-2.7.2]# ls sbin/ |grep mr <br>
mr-jobhistory-daemon.sh</code></li>
<li>3）启动历史服务器 <br>
<code>sbin/mr-jobhistory-daemon.sh start historyserver</code></li>
<li>4）查看历史服务器是否启动 <br>
    <code>jps</code></li>
<li>5）查看jobhistory <br>
<a href="http://192.168.1.101:19888/jobhistory" rel="nofollow" target="_blank">http://192.168.1.101:19888/jobhistory</a></li>
</ul>



<h3 id="6-日志的聚集">6、 日志的聚集</h3>

<p>日志聚集概念：应用运行完成以后，将日志信息上传到HDFS系统上。 <br>
开启日志聚集功能步骤：</p>

<ul>
<li>（1）配置yarn-site.xml</li>
</ul>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-comment">&lt;!-- 日志聚集功能使能 --&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.log-aggregation-enable<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-comment">&lt;!-- 日志保留时间设置7天 --&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>604800<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>

<ul>
<li>（2）关闭nodemanager 、resourcemanager和historymanager <br>
<code>sbin/yarn-daemon.sh stop resourcemanager</code> <br>
<code>sbin/yarn-daemon.sh stop nodemanager</code> <br>
<code>sbin/mr-jobhistory-daemon.sh stop historyserver</code></li>
<li>（3）启动nodemanager 、resourcemanager和historymanager <br>
<code>sbin/yarn-daemon.sh start resourcemanager</code> <br>
<code>sbin/yarn-daemon.sh start nodemanager</code> <br>
<code>sbin/mr-jobhistory-daemon.sh start historyserver</code></li>
<li>（4）删除hdfs上已经存在的hdfs文件 <br>
<code>bin/hdfs dfs -rm -R /user/atguigu/mapreduce/wordcount/output</code></li>
<li>（5）执行wordcount程序 <br>
<code>hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/mapreduce/wordcount/input /user/atguigu/mapreduce/wordcount/output</code> <br>
    （6）查看日志 <br>
<a href="http://192.168.1.101:19888/jobhistory" rel="nofollow" target="_blank">http://192.168.1.101:19888/jobhistory</a> <br>
<img src="https://img-blog.csdn.net/20171123144433648" alt="jobhistory1" title=""> <br>
<img src="https://img-blog.csdn.net/20171123144503927" alt="jobhistory2" title=""> <br>
<img src="https://img-blog.csdn.net/20171123144624578" alt="jobhistory3" title=""></li>
</ul>

<h2 id="2-3-完全分布式部署hadoop">2-3 完全分布式部署Hadoop</h2>

<p>分析： <br>
    1）准备3台客户机（关闭防火墙、静态ip、主机名称） <br>
    2）安装jdk <br>
    3）配置环境变量 <br>
    4）安装hadoop <br>
    5）配置环境变量 <br>
    6）安装ssh <br>
    7）配置集群 <br>
    8）启动测试集群</p>



<h3 id="1-scp">1、 scp</h3>

<ul>
<li>1）scp可以实现服务器与服务器之间的数据拷贝。</li>
<li>2）案例实操 <br>
（1）将linux01中/opt/module和/opt/software文件拷贝到linux02、linux03和linux04上。 <br>
<code>[root@linux01 /]# scp -r /opt/module/  root@linux02:/opt</code> <br>
<code>[root@linux01 /]# scp -r /opt/software/  root@linux02:/opt</code> <br>
<code>[root@linux01 /]# scp -r /opt/module/  root@linux03:/opt</code> <br>
<code>[root@linux01 /]# scp -r /opt/software/  root@linux03:/opt</code> <br>
<code>[root@linux01 /]# scp -r /opt/module/  root@linux04:/opt</code> <br>
<code>[root@linux01 /]# scp -r /opt/software/  root@linux05:/opt</code> <br>
（2）将192.168.1.102服务器上的文件拷贝到当前用户下。 <br>
<code>[root@linux01 opt]# scp  root@linux02:/etc/profile  /opt/tmp/</code> <br>
（3）实现两台远程机器之间的文件传输（hadoop103主机文件拷贝到hadoop104主机上） <br>
    <code>[admin@linux02 test]$ scp atguigu@linux03:/opt/test/haha atguigu@linux04:/opt/test/</code></li>
</ul>



<h3 id="2-ssh无密码登录">2、 SSH无密码登录</h3>

<ul>
<li>1）配置ssh <br>
<ul><li>（1）基本语法 <br>
ssh 另一台电脑的ip地址</li>
<li>（2）ssh连接时出现Host key verification failed的解决方法 <br>
<code>[root@linux02 opt]# ssh 192.168.1.103 <br>
The authenticity of host '192.168.1.103 (192.168.1.103)' can't be established. <br>
RSA key fingerprint is cf:1e:de:d7:d0:4c:2d:98:60:b4:fd:ae:b1:2d:ad:06. <br>
Are you sure you want to continue connecting (yes/no)?  <br>
Host key verification failed.</code> <br>
（3）解决方案如下：直接输入yes</li></ul></li>
<li>2）无密钥配置 <br>
<ul><li>（1）进入到我的home目录 <br>
<code>cd  ~/.ssh</code></li>
<li>（2）生成公钥和私钥： <br>
<code>ssh-keygen -t rsa</code> <br>
然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）</li>
<li>（3）将公钥拷贝到要免密登录的目标机器上 <br>
<code>ssh-copy-id linux03</code> <br>
<code>ssh-copy-id linux04</code></li></ul></li>
</ul>

<p><img src="https://img-blog.csdn.net/20171123161213188" alt="免密登录原理" title=""></p>

<ul>
<li>3）.ssh文件夹下的文件功能解释 <br>
<ul><li>（1）~/.ssh/known_hosts    ：记录ssh访问过计算机的公钥(public key)</li>
<li>（2）id_rsa ：生成的私钥</li>
<li>（3）id_rsa.pub ：生成的公钥</li>
<li>（4）authorized_keys    ：存放授权过得无秘登录服务器公钥</li></ul></li>
</ul>

<h3 id="3-rsync">3、 rsync</h3>

<p>rsync远程同步工具，主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。 <br>
rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。</p>

<ul>
<li>（1）查看rsync使用说明 <br>
man rsync | more</li>
<li>（2）基本语法 <br>
<code>rsync -rvl     $pdir/$fname         $user@linux$host:$pdir</code> <br>
<code>命令 命令参数 要拷贝的文件路径/名称   目的用户@主机:目的路径</code> <br>
选项 <br>
-r 递归 <br>
-v 显示复制过程 <br>
-l 拷贝符号连接</li>
<li>（3）案例实操 <br>
    把本机/opt/tmp目录同步到hadoop103服务器的root用户下的/opt/tmp目录 <br>
    <code>rsync -rvl /opt/tmp/*  root@linux03:/opt/tmp</code></li>
</ul>



<h3 id="4-xsync脚本">4、 xsync脚本</h3>

<p>（1）在/usr/local/bin目录下创建xsync文件，文件内容如下:</p>



<pre class="prettyprint"><code class="language-shell hljs bash"><span class="hljs-shebang">#!/bin/bash</span>
<span class="hljs-comment">#1 获取输入参数个数，如果没有参数，直接退出</span>
pcount=<span class="hljs-variable">$#</span>
<span class="hljs-keyword">if</span>((pcount==<span class="hljs-number">0</span>)); <span class="hljs-keyword">then</span>
<span class="hljs-built_in">echo</span> no args;
<span class="hljs-keyword">exit</span>;
<span class="hljs-keyword">fi</span>

<span class="hljs-comment">#2 获取文件名称</span>
p1=<span class="hljs-variable">$1</span>
fname=`basename <span class="hljs-variable">$p1</span>`
<span class="hljs-built_in">echo</span> fname=<span class="hljs-variable">$fname</span>

<span class="hljs-comment">#3 获取上级目录到绝对路径</span>
pdir=`<span class="hljs-built_in">cd</span> -P $(dirname <span class="hljs-variable">$p1</span>); <span class="hljs-built_in">pwd</span>`
<span class="hljs-built_in">echo</span> pdir=<span class="hljs-variable">$pdir</span>

<span class="hljs-comment">#4 获取当前用户名称</span>
user=`whoami`

<span class="hljs-comment">#5 循环</span>
<span class="hljs-keyword">for</span>((host=<span class="hljs-number">2</span>; host&lt;<span class="hljs-number">4</span>; host++)); <span class="hljs-keyword">do</span>
        <span class="hljs-comment">#echo $pdir/$fname $user@linux0$host:$pdir</span>
        <span class="hljs-built_in">echo</span> --------------- linux0<span class="hljs-variable">$host</span> ----------------
        rsync -rvl <span class="hljs-variable">$pdir</span>/<span class="hljs-variable">$fname</span> <span class="hljs-variable">$user</span>@linux0<span class="hljs-variable">$host</span>:<span class="hljs-variable">$pdir</span>
<span class="hljs-keyword">done</span>                                                                                                                                                      </code></pre>

<p>（2）修改脚本 xsync 具有执行权限 <br>
        [root@linux01 bin]# chmod a+x xsync <br>
（3）调用脚本形式：xsync 文件名称</p>



<h3 id="5xcall脚本">5、xcall脚本</h3>

<p>（1）在/usr/local/bin目录下创建xcall文件，文件内容如下：</p>



<pre class="prettyprint"><code class="language-shell hljs bash"><span class="hljs-shebang">#!/bin/bash</span>
pcount=<span class="hljs-variable">$#</span>
<span class="hljs-keyword">if</span>((pcount==<span class="hljs-number">0</span>));<span class="hljs-keyword">then</span>
        <span class="hljs-built_in">echo</span> no args;
        <span class="hljs-keyword">exit</span>;
<span class="hljs-keyword">fi</span>

<span class="hljs-keyword">for</span>((host=<span class="hljs-number">1</span>; host&lt;=<span class="hljs-number">3</span>; host++)); <span class="hljs-keyword">do</span>
        <span class="hljs-built_in">echo</span> ----------linux<span class="hljs-variable">$host</span>---------
        ssh linux0<span class="hljs-variable">$host</span> <span class="hljs-variable">$@</span>
<span class="hljs-keyword">done</span></code></pre>

<p>（2）修改脚本 xcall 具有执行权限 <br>
        [root@linux01 bin]# chmod a+x xcall <br>
（3）调用脚本形式： xcall 操作命令 <br>
[root@linux01 ~]# xcall rm -rf /opt/tmp/profile </p>



<h3 id="6-配置集群">6、 配置集群</h3>

<p>1）集群部署规划</p>

<table>
<thead>
<tr>
  <th>配置</th>
  <th align="center">linux01</th>
  <th align="center">linux02</th>
  <th align="center">linux03</th>
</tr>
</thead>
<tbody><tr>
  <td>NameNode</td>
  <td align="center">√</td>
  <td align="center"></td>
  <td align="center"></td>
</tr>
<tr>
  <td>DateNode</td>
  <td align="center">√</td>
  <td align="center">√</td>
  <td align="center">√</td>
</tr>
<tr>
  <td>SeconderayNameNode</td>
  <td align="center"></td>
  <td align="center"></td>
  <td align="center">√</td>
</tr>
<tr>
  <td>ResourceManager</td>
  <td align="center"></td>
  <td align="center">√</td>
  <td align="center"></td>
</tr>
<tr>
  <td>NodeManager</td>
  <td align="center">√</td>
  <td align="center">√</td>
  <td align="center">√</td>
</tr>
</tbody></table>


<p>2）配置文件 <br>
（1）<strong>core-site.xml</strong></p>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>hdfs://linux01:9000<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>

    <span class="hljs-comment">&lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>

<p>（2）<strong>Hdfs</strong></p>

<ul>
<li><strong>hadoop-env.sh</strong> <br>
<code>export JAVA_HOME=/opt/module/jdk1.7.0_79</code></li>
<li><strong>hdfs-site.xml</strong></li>
</ul>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span> 
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>3<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>

    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>linux03:50090<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>

<ul>
<li><strong>slaves</strong></li>
</ul>



<pre class="prettyprint"><code class="language-xml hljs ">linux01
linux02
linux03</code></pre>

<p>（3）<strong>yarn</strong></p>

<ul>
<li><strong>yarn-env.sh</strong> <br>
<code>export JAVA_HOME=/opt/module/jdk1.7.0_79</code></li>
<li><strong>yarn-site.xml</strong></li>
</ul>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>

    <span class="hljs-comment">&lt;!-- reducer获取数据的方式 --&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>

    <span class="hljs-comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>linux02<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>

<p>（4）<strong>mapreduce</strong></p>

<ul>
<li><strong>mapred-env.sh</strong> <br>
<code>export JAVA_HOME=/opt/module/jdk1.7.0_79</code></li>
<li><strong>mapred-site.xml</strong></li>
</ul>



<pre class="prettyprint"><code class="language-xml hljs "><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
    <span class="hljs-comment">&lt;!-- 指定mr运行在yarn上 --&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>

<p>3）在集群上分发配置好的hadoop <br>
<code>xsync /opt/modules/hadoop-2.7.2</code></p>



<h3 id="7-集群启动测试">7、 集群启动测试</h3>

<p>1）启动集群</p>

<ul>
<li>（0）如果集群是第一次启动，需要格式化namenode <br>
    <code>[root@linux01 hadoop-2.7.2]# bin/hdfs namenode -format</code></li>
<li>（1）启动HDFS：</li>
</ul>



<pre class="prettyprint"><code class=" hljs ruby">[root<span class="hljs-variable">@linux01</span> hadoop-<span class="hljs-number">2.7</span>.<span class="hljs-number">2</span>]<span class="hljs-comment"># sbin/start-dfs.sh</span>
[root<span class="hljs-variable">@linux01</span> hadoop-<span class="hljs-number">2.7</span>.<span class="hljs-number">2</span>]<span class="hljs-comment"># jps</span>
<span class="hljs-number">4166</span> <span class="hljs-constant">NameNode</span>
<span class="hljs-number">4482</span> <span class="hljs-constant">Jps</span>
<span class="hljs-number">4263</span> <span class="hljs-constant">DataNode</span></code></pre>



<pre class="prettyprint"><code class=" hljs ruby">[root<span class="hljs-variable">@linux02</span>桌面]<span class="hljs-comment"># jps</span>
<span class="hljs-number">3218</span> <span class="hljs-constant">DataNode</span>
<span class="hljs-number">3288</span> <span class="hljs-constant">Jps</span></code></pre>



<pre class="prettyprint"><code class=" hljs ruby">[root<span class="hljs-variable">@linux03</span> 桌面]<span class="hljs-comment"># jps</span>
<span class="hljs-number">3221</span> <span class="hljs-constant">DataNode</span>
<span class="hljs-number">3283</span> <span class="hljs-constant">SecondaryNameNode</span>
<span class="hljs-number">3364</span> <span class="hljs-constant">Jps</span></code></pre>

<ul>
<li>（2）启动yarn <br>
<code>sbin/start-yarn.sh</code> <br>
<em>注意：Namenode和ResourceManger如果不是同一台机器，不能在NameNode上启动 yarn，应该在ResouceManager所在的机器上启动yarn。</em></li>
</ul>

<p>2）集群基本测试</p>

<ul>
<li>（1）上传文件到集群 <br>
上传小文件 <br>
<code>bin/hdfs dfs -mkdir -p /user/admin/tmp/conf</code> <br>
<code>bin/hdfs dfs -put etc/hadoop/*-site.xml /user/admin/tmp/conf</code> <br>
上传大文件 <br>
<code>[admin@linux01 hadoop-2.7.2]$ bin/hadoop fs -put /opt/software/hadoop-2.7.2.tar.gz  /user/admin/input</code></li>
<li>（2）上传文件后查看文件存放在什么位置 <br>
文件存储路径</li>
</ul>



<pre class="prettyprint"><code class=" hljs ruby">[admin<span class="hljs-variable">@linux01subdir0</span>]<span class="hljs-variable">$ </span>pwd
/opt/<span class="hljs-class"><span class="hljs-keyword">module</span>/<span class="hljs-title">hadoop</span>-2.7.2/<span class="hljs-title">data</span>/<span class="hljs-title">tmp</span>/<span class="hljs-title">dfs</span>/<span class="hljs-title">data</span>/<span class="hljs-title">current</span>/<span class="hljs-title">BP</span>-938951106-192.168.10.107-1495462844069/<span class="hljs-title">current</span>/<span class="hljs-title">finalized</span>/<span class="hljs-title">subdir0</span>/<span class="hljs-title">subdir0</span>`</span></code></pre>

<pre><code>查看文件内容
</code></pre>



<pre class="prettyprint"><code class=" hljs ruby">[admin<span class="hljs-variable">@linux01</span> subdir<span class="hljs-number">0</span>]<span class="hljs-variable">$ </span>cat blk_1073741825
hadoop
hello
world</code></pre>

<ul>
<li>（3）拼接</li>
</ul>



<pre class="prettyprint"><code class=" hljs lasso"><span class="hljs-attribute">-rw</span><span class="hljs-attribute">-rw</span><span class="hljs-attribute">-r</span><span class="hljs-subst">--</span><span class="hljs-built_in">.</span> <span class="hljs-number">1</span> admin admin <span class="hljs-number">134217728</span> <span class="hljs-number">5</span>月  <span class="hljs-number">23</span> <span class="hljs-number">16</span>:<span class="hljs-number">01</span> blk_1073741836
<span class="hljs-attribute">-rw</span><span class="hljs-attribute">-rw</span><span class="hljs-attribute">-r</span><span class="hljs-subst">--</span><span class="hljs-built_in">.</span> <span class="hljs-number">1</span> admin admin <span class="hljs-number">1048583</span> <span class="hljs-number">5</span>月  <span class="hljs-number">23</span> <span class="hljs-number">16</span>:<span class="hljs-number">01</span> blk_1073741836_1012<span class="hljs-built_in">.</span>meta
<span class="hljs-attribute">-rw</span><span class="hljs-attribute">-rw</span><span class="hljs-attribute">-r</span><span class="hljs-subst">--</span><span class="hljs-built_in">.</span> <span class="hljs-number">1</span> admin admin <span class="hljs-number">63439959</span> <span class="hljs-number">5</span>月  <span class="hljs-number">23</span> <span class="hljs-number">16</span>:<span class="hljs-number">01</span> blk_1073741837
<span class="hljs-attribute">-rw</span><span class="hljs-attribute">-rw</span><span class="hljs-attribute">-r</span><span class="hljs-subst">--</span><span class="hljs-built_in">.</span> <span class="hljs-number">1</span> admin admin <span class="hljs-number">495635</span> <span class="hljs-number">5</span>月  <span class="hljs-number">23</span> <span class="hljs-number">16</span>:<span class="hljs-number">01</span> blk_1073741837_1013<span class="hljs-built_in">.</span>meta
<span class="hljs-preprocessor">[</span>admin@linux01 subdir0<span class="hljs-preprocessor">]</span><span class="hljs-markup">$ cat blk_1073741836&gt;&gt;tmp.file
</span><span class="hljs-preprocessor">[</span>admin@linux01 subdir0<span class="hljs-preprocessor">]</span><span class="hljs-markup">$ cat blk_1073741837&gt;&gt;tmp.file
</span><span class="hljs-preprocessor">[</span>admin@linux01 subdir0<span class="hljs-preprocessor">]</span><span class="hljs-markup">$ tar -zxvf tmp.file</span></code></pre>

<ul>
<li>（4）下载 <br>
<code>[admin@linux01 hadoop-2.7.2]$ bin/hadoop fs -get /user/atguigu/input/hadoop-2.7.2.tar.gz</code></li>
</ul>

<p>3）性能测试集群 <br>
    写海量数据 <br>
    读海量数据</p>



<h3 id="8-hadoop启动停止方式">8、 Hadoop启动停止方式</h3>

<p>1）各个服务组件逐一启动</p>

<ul>
<li>（1）分别启动hdfs组件 <br>
    <code>hadoop-daemon.sh  start|stop  namenode|datanode|secondarynamenode</code></li>
<li>（2）启动yarn <br>
    <code>yarn-daemon.sh  start|stop  resourcemanager|nodemanager</code></li>
</ul>

<p>2）各个模块分开启动（配置ssh是前提）常用</p>

<ul>
<li>（1）整体启动/停止hdfs <br>
<code>start-dfs.sh</code> <br>
<code>stop-dfs.sh</code></li>
<li>（2）整体启动/停止yarn <br>
    <code>start-yarn.sh</code> <br>
    <code>stop-yarn.sh</code></li>
</ul>

<p>3）全部启动（不建议使用） <br>
    <code>start-all.sh</code> <br>
    <code>stop-all.sh</code></p>



<h3 id="9-集群时间同步设置">9、 集群时间同步设置</h3>

<p>时间同步的方式：找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步，比如，每隔十分钟，同步一次时间。 <br>
配置时间同步实操： <br>
1）时间服务器配置（必须root用户）</p>

<ul>
<li>（1）检查ntp是否安装</li>
</ul>



<pre class="prettyprint"><code class=" hljs avrasm">[root@linux01 桌面]<span class="hljs-preprocessor"># rpm -qa|grep ntp</span>
ntp-<span class="hljs-number">4.2</span><span class="hljs-number">.6</span>p5-<span class="hljs-number">10.</span>el6<span class="hljs-preprocessor">.centos</span><span class="hljs-preprocessor">.x</span>86_64
fontpackages-filesystem-<span class="hljs-number">1.41</span>-<span class="hljs-number">1.1</span><span class="hljs-preprocessor">.el</span>6<span class="hljs-preprocessor">.noarch</span>
ntpdate-<span class="hljs-number">4.2</span><span class="hljs-number">.6</span>p5-<span class="hljs-number">10.</span>el6<span class="hljs-preprocessor">.centos</span><span class="hljs-preprocessor">.x</span>86_64</code></pre>

<ul>
<li><p>（2）修改ntp配置文件 <br>
<code>[root@linux01 桌面]# vi /etc/ntp.conf</code> <br>
修改内容如下</p>

<ul><li>a）修改1 <br>
<code>#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</code>为 <br>
<code>restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</code></li>
<li><p>b）修改2</p>

<pre class="prettyprint"><code class=" hljs avrasm">server <span class="hljs-number">0.</span>centos<span class="hljs-preprocessor">.pool</span><span class="hljs-preprocessor">.ntp</span><span class="hljs-preprocessor">.org</span> iburst
server <span class="hljs-number">1.</span>centos<span class="hljs-preprocessor">.pool</span><span class="hljs-preprocessor">.ntp</span><span class="hljs-preprocessor">.org</span> iburst
server <span class="hljs-number">2.</span>centos<span class="hljs-preprocessor">.pool</span><span class="hljs-preprocessor">.ntp</span><span class="hljs-preprocessor">.org</span> iburst
server <span class="hljs-number">3.</span>centos<span class="hljs-preprocessor">.pool</span><span class="hljs-preprocessor">.ntp</span><span class="hljs-preprocessor">.org</span> iburst</code></pre>

<p>为</p>

<pre class="prettyprint"><code class=" hljs vala">
<span class="hljs-preprocessor">#server 0.centos.pool.ntp.org iburst</span>


<span class="hljs-preprocessor">#server 1.centos.pool.ntp.org iburst</span>


<span class="hljs-preprocessor">#server 2.centos.pool.ntp.org iburst</span>


<span class="hljs-preprocessor">#server 3.centos.pool.ntp.org iburst</span>
</code></pre></li>
<li><p>c）添加3</p>

<pre class="prettyprint"><code class=" hljs nginx"><span class="hljs-title">server</span> <span class="hljs-number">127.127.1.0</span>
fudge <span class="hljs-number">127.127.1.0</span> stratum <span class="hljs-number">10</span></code></pre></li></ul></li>
<li><p>（3）修改/etc/sysconfig/ntpd 文件 <br>
<code>[root@linux01 桌面]# vim /etc/sysconfig/ntpd</code> <br>
增加内容如下 <br>
<code>SYNC_HWCLOCK=yes</code></p></li>
<li>（4）重新启动ntpd</li>
</ul>



<pre class="prettyprint"><code class=" hljs ruby">[root<span class="hljs-variable">@hadoop102</span> 桌面]<span class="hljs-comment"># service ntpd status</span>
ntpd 已停
[root<span class="hljs-variable">@hadoop102</span> 桌面]<span class="hljs-comment"># service ntpd start</span>
正在启动 ntpd：                                            [确定]</code></pre>

<ul>
<li>（5）执行： <br>
    <code>[root@linux01 桌面]# chkconfig ntpd on</code></li>
</ul>

<p>2）其他机器配置（必须root用户）</p>

<ul>
<li>（1）在其他机器配置10分钟与时间服务器同步一次 <br>
    <code>[root@linux01 hadoop-2.7.2]# crontab -e</code> <br>
    编写脚本 <br>
    <code>*/10 * * * * /usr/sbin/ntpdate linux01</code>   </li>
<li>（2）修改任意机器时间 <br>
    <code>[root@linux02 hadoop]# date -s "2017-9-11 11:11:11"</code></li>
<li>（3）十分钟后查看机器是否与时间服务器同步 <br>
    <code>[root@linux02 hadoop]# date</code></li>
</ul>



<h1 id="三-hadoop编译源码">三、 Hadoop编译源码</h1>



<h2 id="1-前期准备工作">1、 前期准备工作</h2>

<p>1）CentOS联网 </p>



<pre class="prettyprint"><code class="language-shell hljs makefile">[root@linux01 桌面]<span class="hljs-comment"># vi /etc/sysconfig/network-scripts/ifcfg-eth0 </span>
<span class="hljs-constant">DEVICE</span>=eth0
<span class="hljs-constant">HWADDR</span>=00:0c:29:ca:6e:ec
<span class="hljs-constant">TYPE</span>=Ethernet
<span class="hljs-constant">UUID</span>=9e008bf7-44f6-4e72-8ead-71b8ea7a9b5b
<span class="hljs-constant">ONBOOT</span>=yes
<span class="hljs-constant">NM_CONTROLLED</span>=yes
<span class="hljs-constant">BOOTPROTO</span>=dhcp
[root@hadoop101 桌面]<span class="hljs-comment"># service network restart</span></code></pre>

<p><em>注意：采用root角色编译，减少文件夹权限出现问题</em> <br>
2）jar包准备(hadoop源码、JDK7 、 maven、 ant 、protobuf)</p>

<ul>
<li>（1）hadoop-2.7.2-src.tar.gz</li>
<li>（2）jdk-7u79-linux-x64.gz</li>
<li>（3）apache-ant-1.9.9-bin.tar.gz</li>
<li>（4）apache-maven-3.0.5-bin.tar.gz</li>
<li>（5）protobuf-2.5.0.tar.gz</li>
</ul>



<h2 id="2-jar包安装">2、 jar包安装</h2>

<p><em>注意：所有操作必须在root用户下完成</em> <br>
1）JDK解压、配置环境变量 JAVA_HOME和PATH，验证java-version(如下都需要验证是否配置成功) <br>
<code>[root@linux01 software] # tar -zxf jdk-7u79-linux-x64.gz -C /opt/module/</code> <br>
<code>[root@linux01 software]# vi /etc/profile</code></p>



<pre class="prettyprint"><code class="language-shell hljs bash"><span class="hljs-comment">#JAVA_HOME</span>
<span class="hljs-keyword">export</span> JAVA_HOME=/opt/module/jdk1.<span class="hljs-number">7.0</span>_79
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$JAVA_HOME</span>/bin</code></pre>

<p><code>[root@linux01 software]#source /etc/profile</code> <br>
验证命令：java -version <br>
2）Maven解压、配置  MAVEN_HOME和PATH。 <br>
<code>[root@linux01 software]# tar -zxvf apache-maven-3.0.5-bin.tar.gz -C /opt/module/</code> <br>
<code>[root@linux01 apache-maven-3.0.5]#  vi /etc/profile</code></p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-comment">#MAVEN_HOME</span>
<span class="hljs-keyword">export</span> MAVEN_HOME=/opt/module/apache-maven-<span class="hljs-number">3.0</span>.<span class="hljs-number">5</span>
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$MAVEN_HOME</span>/bin</code></pre>

<p><code>[root@linux01 software]#source /etc/profile</code> <br>
验证命令：mvn -version <br>
3）ant解压、配置  ANT _HOME和PATH。 <br>
<code>[root@linux01 software]# tar -zxvf apache-ant-1.9.9-bin.tar.gz -C /opt/module/</code> <br>
<code>[root@linux01 apache-ant-1.9.9]# vi /etc/profile</code></p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-comment">#ANT_HOME</span>
<span class="hljs-keyword">export</span> ANT_HOME=/opt/module/apache-ant-<span class="hljs-number">1.9</span>.<span class="hljs-number">9</span>
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$ANT_HOME</span>/bin</code></pre>

<p><code>[root@linux01 software]#source /etc/profile</code> <br>
验证命令：ant -version <br>
4）安装  glibc-headers 和  g++  命令如下:  <br>
<code>[root@linux01 apache-ant-1.9.9]# yum install glibc-headers</code> <br>
<code>[root@linux01 apache-ant-1.9.9]# yum install gcc-c++</code> <br>
5）安装make和cmake <br>
<code>[root@linux01 apache-ant-1.9.9]# yum install make</code> <br>
<code>[root@linux01 apache-ant-1.9.9]# yum install cmake</code> <br>
6）解压protobuf ，进入到解压后protobuf主目录，/opt/module/protobuf-2.5.0 <br>
然后相继执行命令： <br>
<code>[root@linux01 software]# tar -zxvf protobuf-2.5.0.tar.gz -C /opt/module/</code> <br>
<code>[root@linux01  opt]# cd /opt/module/protobuf-2.5.0/</code> <br>
<code>[root@linux01 protobuf-2.5.0]#./configure</code> <br>
<code>[root@linux01 protobuf-2.5.0]# make</code> <br>
<code>[root@linux01 protobuf-2.5.0]# make check</code> <br>
<code>[root@linux01 protobuf-2.5.0]# make install</code> <br>
<code>[root@linux01 protobuf-2.5.0]# ldconfig</code> <br>
<code>[root@linux01 hadoop-dist]# vi /etc/profile</code></p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-comment">#LD_LIBRARY_PATH</span>
<span class="hljs-keyword">export</span> LD_LIBRARY_PATH=/opt/module/protobuf-<span class="hljs-number">2.5</span>.<span class="hljs-number">0</span>
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$LD_LIBRARY_PATH</span></code></pre>

<p>[root@hadoop101 software]#source /etc/profile <br>
验证命令：protoc –version <br>
7）安装openssl库 <br>
<code>[root@linux01 software]#yum install openssl-devel</code> <br>
8）安装 ncurses-devel库： <br>
<code>[root@linux01 software]#yum install ncurses-devel</code> <br>
到此，编译工具安装基本完成。</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>