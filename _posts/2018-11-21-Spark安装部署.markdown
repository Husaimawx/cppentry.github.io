---
layout:     post
title:      Spark安装部署
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-github-gist">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h2 id="spark集群搭建">Spark集群搭建</h2>



<h5 id="1spark安装包下载">1、Spark安装包下载</h5>

<p><a href="http://spark.apache.org/downloads.html" rel="nofollow">http://spark.apache.org/downloads.html</a></p>



<h5 id="2spark安装部署">2、Spark安装部署</h5>



<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor">#上传安装包到指定路径</span>
[root@master Spark]<span class="hljs-preprocessor"># pwd</span>
/opt/app/Spark
[root@master Spark]<span class="hljs-preprocessor"># rz</span>

<span class="hljs-preprocessor">#安装包解压，删除，重命名操作</span>
[root@master Spark]<span class="hljs-preprocessor"># tar -zxvf spark-2.2.2-bin-hadoop2.7.tgz</span>
[root@master Spark]<span class="hljs-preprocessor"># mv spark-2.2.2-bin-hadoop2.7 spark-2.2.2</span>
[root@master Spark]<span class="hljs-preprocessor"># rm -rf spark-2.2.2-bin-hadoop2.7.tgz </span>

<span class="hljs-preprocessor">#查看配置信息</span>
[root@master Spark]<span class="hljs-preprocessor"># cd spark-2.2.2/conf/</span>
[root@master conf]<span class="hljs-preprocessor"># ls</span>
docker<span class="hljs-preprocessor">.properties</span><span class="hljs-preprocessor">.template</span>  metrics<span class="hljs-preprocessor">.properties</span><span class="hljs-preprocessor">.template</span>   spark-env<span class="hljs-preprocessor">.sh</span><span class="hljs-preprocessor">.template</span>
fairscheduler<span class="hljs-preprocessor">.xml</span><span class="hljs-preprocessor">.template</span>  slaves<span class="hljs-preprocessor">.template</span>
log4j<span class="hljs-preprocessor">.properties</span><span class="hljs-preprocessor">.template</span>   spark-defaults<span class="hljs-preprocessor">.conf</span><span class="hljs-preprocessor">.template</span>

<span class="hljs-preprocessor">#修改文件名</span>
[root@master conf]<span class="hljs-preprocessor"># cp spark-env.sh.template spark-env.sh</span>
[root@master conf]<span class="hljs-preprocessor"># cp slaves.template slaves</span>

<span class="hljs-preprocessor">#编辑配置文件</span>
[root@master conf]<span class="hljs-preprocessor"># vim spark-env.sh</span>
<span class="hljs-preprocessor">#添加内容</span>
SPARK_MASTER_HOST=master
SPARK_MASTER_PORT=<span class="hljs-number">7077</span>
[root@master conf]<span class="hljs-preprocessor"># vim slaves</span>
<span class="hljs-preprocessor">#添加内容</span>
slave1
slave2</code></pre>



<h5 id="3高可用ha配置">3、高可用HA配置</h5>



<pre class="prettyprint"><code class=" hljs coffeescript">[root<span class="hljs-property">@master</span> conf]<span class="hljs-comment"># vim spark-env.sh</span>
<span class="hljs-comment">#注释或删掉以下内容</span>
SPARK_MASTER_HOST=master
SPARK_MASTER_PORT=<span class="hljs-number">7077</span>
<span class="hljs-comment">#添加内容</span>
<span class="hljs-reserved">export</span> SPARK_DAEMON_JAVA_OPTS=<span class="hljs-string">"-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=master:2181,slave1:2181,slave2,slave3 -Dspark.deploy.zookeeper.dir=/spark"</span></code></pre>



<h5 id="4启动spark集群">4、启动Spark集群</h5>



<pre class="prettyprint"><code class=" hljs ruby"><span class="hljs-comment">#在master节点上启动start-all.sh</span>
[root<span class="hljs-variable">@master</span> ~]<span class="hljs-comment"># /opt/app/Spark/spark-2.2.2/sbin/start-all.sh </span>
<span class="hljs-comment">#HA集群：在slave1节点上使用start-master.sh</span>
[root<span class="hljs-variable">@slave1</span> ~]<span class="hljs-comment"># /opt/app/Spark/spark-2.2.2/sbin/start-master.sh </span></code></pre>



<h5 id="5执行spark程序格式">5、执行Spark程序格式</h5>

<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor">#执行spark的案例程序格式</span>
[root@master bin]<span class="hljs-preprocessor"># ./spark-submit \</span>
--master spark://master:<span class="hljs-number">7077</span>,slave1:<span class="hljs-number">7077</span> \ 
--class org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.spark</span><span class="hljs-preprocessor">.examples</span><span class="hljs-preprocessor">.SparkPi</span> \ 
/opt/app/Spark/spark-<span class="hljs-number">2.2</span><span class="hljs-number">.2</span>/examples/jars/spark-examples_2<span class="hljs-number">.11</span>-<span class="hljs-number">2.2</span><span class="hljs-number">.2</span><span class="hljs-preprocessor">.jar</span>  <span class="hljs-number">10000</span></code></pre>

<pre class="prettyprint"><code class=" hljs haml">#执行自定义的spark程序格式
[root@slave1 ~]# /opt/Apps/Spark/spark-2.2.2/bin/spark-submit \
-<span class="ruby">-master <span class="hljs-symbol">spark:</span>/<span class="hljs-regexp">/master:7077 \
</span></span>-<span class="ruby">-total-executor-cores <span class="hljs-number">4</span> \
</span>-<span class="ruby">-executor-memory <span class="hljs-number">512</span>m \
</span>-<span class="ruby">-<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">com</span>.<span class="hljs-title">zhiyou100</span>.<span class="hljs-title">spark</span>.<span class="hljs-title">ScalaWordCount</span> \</span>
</span>ScalaWordCount.jar hdfs://master:9000/wc.txt hdfs://master:9000/spark/wc/scala/out4</code></pre>

<h5 id="6spark-shell">6、Spark Shell</h5>



<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor">#在不指定集群的时候（master），可以正常启动shell，但是这种模式只是启动了本地模式。没有与集群建立连接</span>
[root@master ~]<span class="hljs-preprocessor"># /opt/app/Spark/spark-2.2.2/bin/spark-shell</span>

<span class="hljs-preprocessor">#在spark集群上运行</span>
[root@slave1 ~]<span class="hljs-preprocessor"># /opt/app/Spark/spark-2.2.2/bin/spark-shell --master spark://master:7077 --total-executor-cores 2 --executor-memory 512m</span>

<span class="hljs-preprocessor">#在Shell中可以直接编写Spark代码。SparkContext类会默认初始化为sc对象。</span>
scala&gt; sc<span class="hljs-preprocessor">.textFile</span>(<span class="hljs-string">"hdfs://master:9000/wc.txt"</span>)<span class="hljs-preprocessor">.flatMap</span>(_<span class="hljs-preprocessor">.split</span>(<span class="hljs-string">" "</span>))<span class="hljs-preprocessor">.map</span>((_,<span class="hljs-number">1</span>))<span class="hljs-preprocessor">.reduceByKey</span>(_+_)<span class="hljs-preprocessor">.saveAsTextFile</span>(<span class="hljs-string">"hdfs://master:9000/out"</span>)

</code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>