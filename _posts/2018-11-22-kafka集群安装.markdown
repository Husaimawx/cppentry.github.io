---
layout:     post
title:      kafka集群安装
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/singgel/article/details/79790138				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p><span style="color:#393939;">kafka：</span><a href="https://mirrors.cnnic.cn/apache/kafka/" rel="nofollow"><span style="color:#003884;">https://mirrors.cnnic.cn/apache/kafka/</span></a></p>

<p><span style="color:#393939;">1.前提需要java环境和zookeeper的支持</span></p>

<p><span style="color:#393939;">2.创建持久化目录（根目录）</span></p>

<p><span style="color:#0000ff;">mkdir</span> /kafkaLogs</p>

<p>3.修改kafka的配置文件（config）目录</p>

<p>vim server.properties</p>

<p>1.修改broker.id</p>

<p>2.修改kafka监听地址</p>

<p>3.修改持久化目录</p>

<p>4.修改zk地址</p>

<p>5.添加启用删除topic配置</p>

<p>6.关闭自动创建topic</p>

<table style="width:0px;"><tbody><tr><td style="border-color:#a7a7a7;">
			<p><span style="color:#000000;">############################# Server Basics #############################</span></p>

			<p> </p>

			<p><span style="color:#000000;"># The id of the broker. This must be set to a unique integer for each broker.</span></p>

			<p><span style="color:#000000;">broker.id=0</span></p>

			<p><span style="color:#000000;">advertised.host.name=192.168.1.123</span></p>

			<p> </p>

			<p><span style="color:#000000;">############################# Socket Server Settings #############################</span></p>

			<p> </p>

			<p><span style="color:#000000;"># The address the socket server listens on. It will get the value returned from </span></p>

			<p><span style="color:#000000;"># java.net.InetAddress.getCanonicalHostName() if not configured.</span></p>

			<p><span style="color:#000000;"># FORMAT:</span></p>

			<p><span style="color:#000000;"># listeners = listener_name://host_name:port</span></p>

			<p><span style="color:#000000;"># EXAMPLE:</span></p>

			<p><span style="color:#000000;"># listeners = PLAINTEXT://your.host.name:9092</span></p>

			<p><span style="color:#000000;">#listeners=PLAINTEXT://:9092</span></p>

			<p> </p>

			<p><span style="color:#000000;"># Hostname and port the broker will advertise to producers and consumers. If not set, </span></p>

			<p><span style="color:#000000;"># it uses the value for "listeners" if configured. Otherwise, it will use the value</span></p>

			<p><span style="color:#000000;"># returned from java.net.InetAddress.getCanonicalHostName().</span></p>

			<p><span style="color:#000000;">#advertised.listeners=PLAINTEXT://your.host.name:9092</span></p>

			<p> </p>

			<p><span style="color:#000000;"># Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details</span></p>

			<p><span style="color:#000000;">#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL</span></p>

			<p> </p>

			<p><span style="color:#000000;"># The number of threads that the server uses for receiving requests from the network and sending responses to the network</span></p>

			<p><span style="color:#000000;">num.network.threads=3</span></p>

			<p> </p>

			<p><span style="color:#000000;"># The number of threads that the server uses for processing requests, which may include disk I/O</span></p>

			<p><span style="color:#000000;">num.io.threads=8</span></p>

			<p> </p>

			<p><span style="color:#000000;"># The send buffer (SO_SNDBUF) used by the socket server</span></p>

			<p><span style="color:#000000;">socket.send.buffer.bytes=102400</span></p>

			<p> </p>

			<p><span style="color:#000000;"># The receive buffer (SO_RCVBUF) used by the socket server</span></p>

			<p><span style="color:#000000;">socket.receive.buffer.bytes=102400</span></p>

			<p> </p>

			<p><span style="color:#000000;"># The maximum size of a request that the socket server will accept (protection against OOM)</span></p>

			<p><span style="color:#000000;">socket.request.max.bytes=104857600</span></p>

			<p> </p>

			<p> </p>

			<p><span style="color:#000000;">############################# Log Basics #############################</span></p>

			<p> </p>

			<p><span style="color:#000000;"># A comma separated list of directories under which to store log files</span></p>

			<p><span style="color:#000000;">log.dirs=/kafkaLogs</span></p>

			<p> </p>

			<p><span style="color:#000000;"># The default number of log partitions per topic. More partitions allow greater</span></p>

			<p><span style="color:#000000;"># parallelism for consumption, but this will also result in more files across</span></p>

			<p><span style="color:#000000;"># the brokers.</span></p>

			<p><span style="color:#000000;">num.partitions=1</span></p>

			<p> </p>

			<p><span style="color:#000000;"># The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.</span></p>

			<p><span style="color:#000000;"># This value is recommended to be increased for installations with data dirs located in RAID array.</span></p>

			<p><span style="color:#000000;">num.recovery.threads.per.data.dir=1</span></p>

			<p> </p>

			<p><span style="color:#000000;">############################# Internal Topic Settings #############################</span></p>

			<p><span style="color:#000000;"># The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"</span></p>

			<p><span style="color:#000000;"># For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.</span></p>

			<p><span style="color:#000000;">offsets.topic.replication.factor=1</span></p>

			<p><span style="color:#000000;">transaction.state.log.replication.factor=1</span></p>

			<p><span style="color:#000000;">transaction.state.log.min.isr=1</span></p>

			<p> </p>

			<p><span style="color:#000000;">############################# Log Flush Policy #############################</span></p>

			<p> </p>

			<p><span style="color:#000000;"># Messages are immediately written to the filesystem but by default we only fsync() to sync</span></p>

			<p><span style="color:#000000;"># the OS cache lazily. The following configurations control the flush of data to disk.</span></p>

			<p><span style="color:#000000;"># There are a few important trade-offs here:</span></p>

			<p><span style="color:#000000;"># 1. Durability: Unflushed data may be lost if you are not using replication.</span></p>

			<p><span style="color:#000000;"># 2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.</span></p>

			<p><span style="color:#000000;"># 3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.</span></p>

			<p><span style="color:#000000;"># The settings below allow one to configure the flush policy to flush data after a period of time or</span></p>

			<p><span style="color:#000000;"># every N messages (or both). This can be done globally and overridden on a per-topic basis.</span></p>

			<p> </p>

			<p><span style="color:#000000;"># The number of messages to accept before forcing a flush of data to disk</span></p>

			<p><span style="color:#000000;">#log.flush.interval.messages=10000</span></p>

			<p> </p>

			<p><span style="color:#000000;"># The maximum amount of time a message can sit in a log before we force a flush</span></p>

			<p><span style="color:#000000;">#log.flush.interval.ms=1000</span></p>

			<p> </p>

			<p><span style="color:#000000;">############################# Log Retention Policy #############################</span></p>

			<p> </p>

			<p><span style="color:#000000;"># The following configurations control the disposal of log segments. The policy can</span></p>

			<p><span style="color:#000000;"># be set to delete segments after a period of time, or after a given size has accumulated.</span></p>

			<p><span style="color:#000000;"># A segment will be deleted whenever *either* of these criteria are met. Deletion always happens</span></p>

			<p><span style="color:#000000;"># from the end of the log.</span></p>

			<p> </p>

			<p><span style="color:#000000;"># The minimum age of a log file to be eligible for deletion due to age</span></p>

			<p><span style="color:#000000;">log.retention.hours=168</span></p>

			<p> </p>

			<p><span style="color:#000000;"># A size-based retention policy for logs. Segments are pruned from the log unless the remaining</span></p>

			<p><span style="color:#000000;"># segments drop below log.retention.bytes. Functions independently of log.retention.hours.</span></p>

			<p><span style="color:#000000;">#log.retention.bytes=1073741824</span></p>

			<p> </p>

			<p><span style="color:#000000;"># The maximum size of a log segment file. When this size is reached a new log segment will be created.</span></p>

			<p><span style="color:#000000;">log.segment.bytes=1073741824</span></p>

			<p> </p>

			<p><span style="color:#000000;"># The interval at which log segments are checked to see if they can be deleted according</span></p>

			<p><span style="color:#000000;"># to the retention policies</span></p>

			<p><span style="color:#000000;">log.retention.check.interval.ms=300000</span></p>

			<p> </p>

			<p><span style="color:#000000;">############################# Zookeeper #############################</span></p>

			<p> </p>

			<p><span style="color:#000000;"># Zookeeper connection string (see zookeeper docs for details).</span></p>

			<p><span style="color:#000000;"># This is a comma separated host:port pairs, each corresponding to a zk</span></p>

			<p><span style="color:#000000;"># server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".</span></p>

			<p><span style="color:#000000;"># You can also append an optional chroot string to the urls to specify the</span></p>

			<p><span style="color:#000000;"># root directory for all kafka znodes.</span></p>

			<p><span style="color:#000000;">zookeeper.connect=192.168.1.123:2181,192.168.1.131:2181,192.168.1.148:2181</span></p>

			<p> </p>

			<p><span style="color:#000000;"># Timeout in ms for connecting to zookeeper</span></p>

			<p><span style="color:#000000;">zookeeper.connection.timeout.ms=6000</span></p>

			<p> </p>

			<p> </p>

			<p><span style="color:#000000;">############################# Group Coordinator Settings #############################</span></p>

			<p> </p>

			<p><span style="color:#000000;"># The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.</span></p>

			<p><span style="color:#000000;"># The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.</span></p>

			<p><span style="color:#000000;"># The default value for this is 3 seconds.</span></p>

			<p><span style="color:#000000;"># We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.</span></p>

			<p><span style="color:#000000;"># However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.</span></p>

			<p><span style="color:#000000;">group.initial.rebalance.delay.ms=0</span></p>

			<p> </p>

			<p><span style="color:#000000;">###########删除topic#############################</span></p>

			<p><span style="color:#000000;">delete.topic.enable=true</span></p>

			<p> </p>

			<p><span style="color:#000000;">#########关闭自动创建topic###################</span></p>

			<p><span style="color:#000000;">auto.create.topics.enable=false</span></p>

			<p> </p>
			</td>
		</tr></tbody></table><p><span style="color:#393939;">4.复制该配置到集群中的其他机器</span></p>

<p><span style="color:#0000ff;">scp</span> -rp kafka_2.<span style="color:#800080;">11</span>-<span style="color:#800080;">0.9</span>.<span style="color:#800080;">0.1</span> root@<span style="color:#800080;">***</span>:/usr/local/</p>

<p><span style="color:#393939;">5.修改集群中其他机器的broker.id</span></p>

<p>vim server.properties</p>

<table style="width:0px;"><tbody><tr><td style="border-color:#a7a7a7;">
			<p><span style="color:#000000;">broker.id=0</span></p>

			<p> </p>
			</td>
		</tr></tbody></table><p><span style="color:#393939;">6.启动kafka的相关命令：</span></p>

<p><span style="color:#393939;">主机启动kafka：</span></p>

<p>JMX_PORT=<span style="color:#800080;">9997</span> bin/kafka-server-start.<span style="color:#0000ff;">sh</span> -daemon config/server.properties &amp;</p>

<p><span style="color:#393939;">停止kafka：</span></p>

<p>/usr/local/kafka_2.<span style="color:#800080;">11</span>-<span style="color:#800080;">0.9</span>.<span style="color:#800080;">0.1</span>/bin/kafka-server-stop.<span style="color:#0000ff;">sh</span></p>

<p>7.设置脚本，定期清理logs下的日志（kafka的根目录）</p>

<p>cd /usr/local/kafka_2.<span style="color:#800080;">11</span>-<span style="color:#800080;">0.9</span>.<span style="color:#800080;">0.1</span>/</p>

<p>vim clean_kafkalog.<span style="color:#0000ff;">sh</span></p>

<table style="width:0px;"><tbody><tr><td style="border-color:#a7a7a7;">
			<p><span style="color:#000000;">#!/bin/bash</span></p>

			<p><span style="color:#000000;">###Description:This script is used to </span><span style="color:#0000ff;">clear</span><span style="color:#000000;"> kafka logs, not message </span><span style="color:#0000ff;">file</span><span style="color:#000000;">.</span></p>

			<p><span style="color:#000000;">###Written by: jkzhao - jkzhao@wisedu.com </span></p>

			<p><span style="color:#000000;">###History: </span><span style="color:#800080;">2016</span><span style="color:#000000;">-</span><span style="color:#800080;">04</span><span style="color:#000000;">-</span><span style="color:#800080;">18</span><span style="color:#000000;"> First release.</span></p>

			<p> </p>

			<p><span style="color:#000000;"># log </span><span style="color:#0000ff;">file</span><span style="color:#000000;"> </span><span style="color:#0000ff;">dir</span><span style="color:#000000;">.</span></p>

			<p><span style="color:#000000;">logDir=/usr/local/kafka_2.</span><span style="color:#800080;">11</span><span style="color:#000000;">-</span><span style="color:#800080;">0.9</span><span style="color:#000000;">.</span><span style="color:#800080;">0.1</span><span style="color:#000000;">/logs</span></p>

			<p> </p>

			<p><span style="color:#000000;"># Reserved </span><span style="color:#800080;">7</span><span style="color:#000000;"> files.</span></p>

			<p><span style="color:#000000;">COUNT=</span><span style="color:#800080;">7</span></p>

			<p> </p>

			<p><span style="color:#0000ff;">ls</span><span style="color:#000000;"> -t $logDir/server.log* | </span><span style="color:#0000ff;">tail</span><span style="color:#000000;"> -n +$[$COUNT+</span><span style="color:#800080;">1</span><span style="color:#000000;">] | </span><span style="color:#0000ff;">xargs</span><span style="color:#000000;"> </span><span style="color:#0000ff;">rm</span><span style="color:#000000;"> -f</span></p>

			<p><span style="color:#0000ff;">ls</span><span style="color:#000000;"> -t $logDir/controller.log* | </span><span style="color:#0000ff;">tail</span><span style="color:#000000;"> -n +$[$COUNT+</span><span style="color:#800080;">1</span><span style="color:#000000;">] | </span><span style="color:#0000ff;">xargs</span><span style="color:#000000;"> </span><span style="color:#0000ff;">rm</span><span style="color:#000000;"> -f</span></p>

			<p><span style="color:#0000ff;">ls</span><span style="color:#000000;"> -t $logDir/state-change.log* | </span><span style="color:#0000ff;">tail</span><span style="color:#000000;"> -n +$[$COUNT+</span><span style="color:#800080;">1</span><span style="color:#000000;">] | </span><span style="color:#0000ff;">xargs</span><span style="color:#000000;"> </span><span style="color:#0000ff;">rm</span><span style="color:#000000;"> -f</span></p>

			<p><span style="color:#0000ff;">ls</span><span style="color:#000000;"> -t $logDir/log-cleaner.log* | </span><span style="color:#0000ff;">tail</span><span style="color:#000000;"> -n +$[$COUNT+</span><span style="color:#800080;">1</span><span style="color:#000000;">] | </span><span style="color:#0000ff;">xargs</span><span style="color:#000000;"> </span><span style="color:#0000ff;">rm</span><span style="color:#000000;"> –f</span></p>
			</td>
		</tr></tbody></table><p><span style="color:#0000ff;">chmod</span> +x clean_kafkalog.<span style="color:#0000ff;">sh</span></p>

<p><span style="color:#333333;">周期性任务策略：每周日的0点0分去执行这个脚本：</span></p>

<p>crontab -e <span style="color:#800080;">0</span> <span style="color:#800080;">0</span> * * <span style="color:#800080;">0</span> /usr/local/kafka_2.<span style="color:#800080;">11</span>-<span style="color:#800080;">0.9</span>.<span style="color:#800080;">0.1</span>/clean_kafkalog.<span style="color:#0000ff;">sh</span></p>

<p> </p>            </div>
                </div>