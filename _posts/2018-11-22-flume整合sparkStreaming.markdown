---
layout:     post
title:      flume整合sparkStreaming
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <div style="white-space:pre-wrap;text-align:left;line-height:1.75;font-size:14px;"><span style="color:rgb(51,51,51);background-color:rgb(249,249,249);">(1)、如何实现sparkStreaming读取flume中的数据</span></div><p></p><div style="white-space:pre-wrap;text-align:left;line-height:1.75;font-size:14px;"><span style="color:rgb(51,51,51);background-color:rgb(249,249,249);">推模式：Flume将数据Push推给Spark Streaming 拉模式：Spark Streaming从flume 中Poll拉取数据</span></div><div style="white-space:pre-wrap;text-align:left;line-height:1.75;font-size:14px;"><span style="color:rgb(51,51,51);background-color:rgb(249,249,249);">(2)、在实际开发的时候是如何保证数据不丢失的</span></div><p></p><div style="white-space:pre-wrap;text-align:left;line-height:1.75;font-size:14px;"><span style="color:rgb(51,51,51);background-color:rgb(249,249,249);">flume那边采用的channel是将数据落地到磁盘中，保证数据源端安全性（可以在补充一下，flume在这里的channel可以设置为memory内存中，提高数据接收处理的效率，但是由于数据在内存中，安全机制保证不了，故选择channel为磁盘存储。整个流程运行有一点的延迟性） sparkStreaming通过拉模式整合的时候，使用了FlumeUtils这样一个类，该类是需要依赖一个额外的jar包（spark-streaming-flume_2.10） 要想保证数据不丢失，数据的准确性，可以在构建StreamingConext的时候，利用StreamingContext.getOrCreate（checkpoint, creatingFunc: () =&gt; StreamingContext）来创建一个StreamingContext,使用StreamingContext.getOrCreate来创建StreamingContext对象，传入的第一个参数是checkpoint的存放目录，第二参数是生成StreamingContext对象的用户自定义函数。如果checkpoint的存放目录存在，则从这个目录中生成StreamingContext对象；如果不存在，才会调用第二个函数来生成新的StreamingContext对象。在creatingFunc函数中，除了生成一个新的StreamingContext操作，还需要完成各种操作，然后调用ssc.checkpoint(checkpointDirectory)来初始化checkpoint功能，最后再返回StreamingContext对象。</span></div><div style="white-space:pre-wrap;text-align:left;line-height:1.75;font-size:14px;"><span style="color:rgb(51,51,51);background-color:rgb(249,249,249);">这样，在StreamingContext.getOrCreate之后，就可以直接调用start()函数来启动（或者是从中断点继续运行）流式应用了。如果有其他在启动或继续运行都要做的工作，可以在start()调用前执行。 流失计算中使用checkpoint的作用：</span></div><div style="white-space:pre-wrap;text-align:left;line-height:1.75;font-size:14px;"><span style="color:rgb(51,51,51);background-color:rgb(249,249,249);">保存元数据，包括流式应用的配置、流式没崩溃之前定义的各种操作、未完成所有操作的batch。元数据被存储到容忍失败的存储</span><a href="https://www.2cto.com/os/" rel="nofollow"><span style="color:rgb(31,58,135);background-color:rgb(249,249,249);">系统</span></a><span style="color:rgb(51,51,51);background-color:rgb(249,249,249);">上，如HDFS。这种ckeckpoint主要针对driver失败后的修复。 保存流式数据，也是存储到容忍失败的存储系统上，如HDFS。这种ckeckpoint主要针对window operation、有状态的操作。无论是driver失败了，还是worker失败了，这种checkpoint都够快速恢复，而不需要将很长的历史数据都重新计算一遍（以便得到当前的状态）。 设置流式数据checkpoint的周期</span></div><div style="white-space:pre-wrap;text-align:left;line-height:1.75;font-size:14px;"><span style="color:rgb(51,51,51);background-color:rgb(249,249,249);">对于一个需要做checkpoint的DStream结构，可以通过调用DStream.checkpoint(checkpointInterval)来设置ckeckpoint的周期，经验上一般将这个checkpoint周期设置成batch周期的5至10倍。 使用write ahead logs功能</span></div><div style="white-space:pre-wrap;text-align:left;line-height:1.75;font-size:14px;"><span style="color:rgb(51,51,51);background-color:rgb(249,249,249);">这是一个可选功能，建议加上。这个功能将使得输入数据写入之前配置的checkpoint目录。这样有状态的数据可以从上一个checkpoint开始计算。开启的方法是把spark.streaming.receiver.writeAheadLogs.enable这个property设置为true。另外，由于输入RDD的默认StorageLevel是MEMORY_AND_DISK_2，即数据会在两台worker上做replication。实际上，Spark Streaming模式下，任何从网络输入数据的Receiver（如kafka、flume、socket）都会在两台机器上做数据备份。如果开启了write ahead logs的功能，建议把StorageLevel改成MEMORY_AND_DISK_SER。修改的方法是，在创建RDD时由参数传入。 使用以上的checkpoint机制，确实可以保证数据0丢失。但是一个前提条件是，数据发送端必须要有缓存功能，这样才能保证在spark应用重启期间，数据发送端不会因为spark streaming服务不可用而把数据丢弃。而flume具备这种特性，同样kafka也具备。</span></div><div style="white-space:pre-wrap;text-align:left;line-height:1.75;font-size:14px;"><span style="color:rgb(51,51,51);background-color:rgb(249,249,249);">(3)Spark Streaming的数据可靠性</span></div><p></p><div style="white-space:pre-wrap;text-align:left;line-height:1.75;font-size:14px;"><span style="color:rgb(51,51,51);background-color:rgb(249,249,249);">有了checkpoint机制、write ahead log机制、Receiver缓存机器、可靠的Receiver（即数据接收并备份成功后会发送ack），可以保证无论是worker失效还是driver失效，都是数据0丢失。原因是：如果没有Receiver服务的worker失效了，RDD数据可以依赖血统来重新计算；如果Receiver所在worker失败了，由于Reciever是可靠的，并有write ahead log机制，则收到的数据可以保证不丢；如果driver失败了，可以从checkpoint中恢复数据重新构建。</span></div>            </div>
                </div>