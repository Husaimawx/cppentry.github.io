---
layout:     post
title:      flume ng高可用部署
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>一、flume简介 <br>
    flume是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单的处理，并写到各类数据接受方（可定制）的能力。Flume1.x版本的统称为Flume-ng。 <br>
    数据处理： <br>
        Flume提供了从console（控制台）、RPC（Thrift-RPC）、text、tail、syslog（syslog日志系统），支持TCP和UDP等2两种模式，exec（命令执行）等数据源上收集数据的能力。 <br>
        Flume NG采用的是三层架构: Agent层，Collector层，和Store层，每一层均可水平拓展。其中Agent包含Source，Channel和Sink，三者组建了一个Agent。三者的作用： <br>
        Source：用来消费（收集）数据源到Channel组件中。 <br>
        Channel：中转临时存储，保存所有Source组件信息。 <br>
        Sink：从Channel中读取，读取成功后会删除Channel中的信息。</p>

<p>二、单点FlumeNG搭建、运行。 <br>
    这里我用的是Flume-1.6.0版本。 <br>
    安装解压flume安装包，命令如下所示：</p>



<pre class="prettyprint"><code class=" hljs lasso">    tar <span class="hljs-attribute">-zxvf</span> apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.6</span><span class="hljs-number">.0</span><span class="hljs-attribute">-bin</span><span class="hljs-built_in">.</span>tar<span class="hljs-built_in">.</span>gz  </code></pre>

<p>配置环境变量： <br>
    <img src="https://img-blog.csdn.net/20170914163957889?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzgyOTg4Njk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>flume单节点配置文件设置如下： <br>
flume-hdfs.conf <br>
<img src="https://img-blog.csdn.net/20170914164150167?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzgyOTg4Njk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>复制flume-env.sh</p>

<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-keyword">cp</span> flume-env<span class="hljs-preprocessor">.sh</span><span class="hljs-preprocessor">.template</span> flume-env<span class="hljs-preprocessor">.sh</span></code></pre>

<p>加入jdk配置：</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-keyword">export</span> JAVA_HOME=/usr/local/jdk1.<span class="hljs-number">7.0</span>_79</code></pre>

<p>注意： 配置中的目录需提前创建</p>

<p>运行： <br>
启动命令如下：</p>



<pre class="prettyprint"><code class=" hljs lasso">flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-subst">--</span>conf conf <span class="hljs-subst">--</span>conf<span class="hljs-attribute">-file</span> /home/hadoop/flume<span class="hljs-subst">-</span><span class="hljs-number">1.6</span><span class="hljs-number">.0</span>/conf/flume<span class="hljs-attribute">-hdfs</span><span class="hljs-built_in">.</span>conf <span class="hljs-subst">--</span>name agent1 <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>INFO,console <span class="hljs-subst">&gt;</span> /home/hadoop/flume<span class="hljs-subst">-</span><span class="hljs-number">1.6</span><span class="hljs-number">.0</span>/logs/flume<span class="hljs-attribute">-hdfs</span><span class="hljs-built_in">.</span><span class="hljs-keyword">log</span> <span class="hljs-number">2</span><span class="hljs-subst">&gt;&amp;</span><span class="hljs-number">1</span> <span class="hljs-subst">&amp;</span></code></pre>

<p>注：命令中的agent1表示配置文件中的Agent的Name，flume-hdfs.conf要写准确的文件路径。</p>

<p>单节点flume效果预览： <br>
<img src="https://img-blog.csdn.net/20170914164817288?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzgyOTg4Njk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>hadoopweb页面可以查看已上传并重命名的文件： <br>
<img src="https://img-blog.csdn.net/20170914165135996?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzgyOTg4Njk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>三、高可用的Flume NG搭建 <br>
    架构图： <br>
    <img src="https://img-blog.csdn.net/20170914165329842?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzgyOTg4Njk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>Flume的存储可以支持很多种，这里只列举了HDFS和Kafka。比如：存储一定时间的日志，并给Storm系统提供实时日志流。</p>

<p>3台机器构建集群。Flume的Agent和Collector分布如下：</p>



<pre class="prettyprint"><code class=" hljs vbscript">名称            HOST          角色
Agent1        db1           Web <span class="hljs-built_in">Server</span>
Agent2        db2           Web <span class="hljs-built_in">Server</span>
Agent3        db3           Web <span class="hljs-built_in">Server</span>
Collector1    db1           AgentMstr1
Collector2    db3           AgentMstr1</code></pre>

<p>Agent1、Agent2、Agent3，分别位于db1-db3三台机器上，配置相同，如下所示： <br>
flume-client.properties <br>
<img src="https://img-blog.csdn.net/20170914170041551?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzgyOTg4Njk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>接下来再配置Collector1和Collector2，分别位于db1和db3两台机器，绑定IP的不同， <br>
db1（master）flume-server.properties配置如下： <br>
<img src="https://img-blog.csdn.net/20170914170320371?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzgyOTg4Njk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>db3（slave）的配置如下： <br>
<img src="https://img-blog.csdn.net/20170914170508870?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzgyOTg4Njk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>其中的属性描述： <br>
agent.channels.ch1.type ：Agent的channel类型 <br>
a1.sinks.k1.type = hdfs  ：  Sink类型 <br>
a1.sinks.k1.hdfs.path = hdfs://bi/flume/logdfs  ： Sink类型 <br>
a1.sinks.k1.hdfs.fileType = DataStream  ：  流数据的文件类型 <br>
a1.sinks.k1.hdfs.writeFotmat=TEXT   ：  数据写入格式 <br>
a1.sinks.k1.hdfs.rollInterval=1   ：  hdfs sink 间隔多长将临时文件滚动成最终目标文件，单位是秒；如果设置为0，则表示不根据时间来滚动文件 <br>
agent.sinks.k1.hdfs.rollCount  ： 当events数据达到该数量时候，将临时文件滚动成目标文件；如果设置成0，则表示不根据events数据来滚动文件</p>

<p>flume集群启动： <br>
在   Collector各节点上启动命令如下：</p>



<pre class="prettyprint"><code class=" hljs lasso">flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-subst">--</span>conf conf <span class="hljs-subst">--</span>conf<span class="hljs-attribute">-file</span> /home/hadoop/flume<span class="hljs-subst">-</span><span class="hljs-number">1.6</span><span class="hljs-number">.0</span>/conf/flume<span class="hljs-attribute">-server</span><span class="hljs-built_in">.</span>properties <span class="hljs-subst">--</span>name a1 <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>INFO,console <span class="hljs-subst">&gt;</span> /home/hadoop/flume<span class="hljs-subst">-</span><span class="hljs-number">1.6</span><span class="hljs-number">.0</span>/logs/flume<span class="hljs-attribute">-server</span><span class="hljs-built_in">.</span><span class="hljs-keyword">log</span> <span class="hljs-number">2</span><span class="hljs-subst">&gt;&amp;</span><span class="hljs-number">1</span> <span class="hljs-subst">&amp;</span></code></pre>

<p>注：命令中的a1 表示配置中的Agent的Name，如配置文件中的a1。配置文件填准确的地址</p>

<p>在Agent各节点上启动命令：</p>



<pre class="prettyprint"><code class=" hljs lasso">flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-subst">--</span>conf conf <span class="hljs-subst">--</span>conf<span class="hljs-attribute">-file</span> /home/hadoop/flume<span class="hljs-subst">-</span><span class="hljs-number">1.6</span><span class="hljs-number">.0</span>/conf/flume<span class="hljs-attribute">-client</span><span class="hljs-built_in">.</span>properties <span class="hljs-subst">--</span>name agent1 <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>INFO,console <span class="hljs-subst">&gt;</span> /home/hadoop/flume<span class="hljs-subst">-</span><span class="hljs-number">1.6</span><span class="hljs-number">.0</span>/logs/flume<span class="hljs-attribute">-client</span><span class="hljs-built_in">.</span><span class="hljs-keyword">log</span> <span class="hljs-number">2</span><span class="hljs-subst">&gt;&amp;</span><span class="hljs-number">1</span> <span class="hljs-subst">&amp;</span></code></pre>

<p>注：命令中的agent1表示配置文件中的Agent的Name。</p>

<p>FlumeNG集群的HA测试： <br>
    场景如下:我在Agent1节点上传文件，由于配置Collector1的权重比Collector2大，所以Collector1优先采集并上传到存储系统。然后我们kill掉Collector1，再重新编辑该文件，此时由Collector2负责日志采集上传工作，之后，我们手动启动Collector1节点的Flume服务，再次在Agent1编辑该文件，发现Collector2恢复优先级别的采集工作。</p>

<p>四、总结</p>

<pre><code>在配置高可用的Flume NG时，在Agent中需要绑定对应的Collector1和Collector2的IP和Port，另外，在配置Collector节点时，需要修改当前FLume节点的配置文件中的bind和IP port。
</code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>