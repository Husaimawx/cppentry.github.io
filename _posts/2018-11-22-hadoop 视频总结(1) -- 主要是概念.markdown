---
layout:     post
title:      hadoop 视频总结(1) -- 主要是概念
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/xfg0218/article/details/51766158				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p></p>
<p>1、概念：</p>
<p>      HDFS : Hadoop   DIstributed   File    Sysytem   分布式分拣储存系统</p>
<p>      MapReduce ： 并行计算框架</p>
<p><br></p>
<p><br></p>
<p>2、HDFS 与MapReduce 结构</p>
<p>      HDFS: 主从结构：</p>
<p>                   <span> </span>主节点，只有一个： namenode  </p>
<p>                        从节点可有多个：datenode</p>
<p>                     </p>
<p>                  namenode负责:  接受用户请求操作请阿牛</p>
<p>                                                 维护文件系统的目录结构</p>
<p>                                                管理文件与block之间的关系，block与datenode之间的关系</p>
<p>                    datenode 负责:</p>
<p>                                              储存文件</p>
<p>       ·<span> </span>     把文件分成block储存在磁盘上</p>
<p> <span> </span>    为保证数据的安全，文件会有多个副本</p>
<p>  </p>
<p>           MapReduce：主从结构：</p>
<p>                          主节点:只有一个：JobTracker</p>
<p>                           从节点，可有多个：TaskTracker</p>
<p>  </p>
<p>                      JobTracker 负责：接受客户提交的计算任务</p>
<p>                                                        把计算任务分给TaskTracker执行</p>
<p> ·<span> </span>监控TaskTracker的执行任务</p>
<p>                      TaskTracker负责：</p>
<p> <span> </span>         执行JobTracker的分配的计算任务</p>
<p><br></p>
<p>                               </p>
<p>3、Hadoop 的特点：</p>
<p>           3-1）、扩容能力：使用reliably储存和处理千兆字节的数据(PB)</p>
<p>           3-2）、成本低:可以运行在普通的计算机上</p>
<p>           3-3）、高效率：能运算分配到不同的额计算机上</p>
<p>           3-4）、可靠性：hadoop维护数据的多副本，任务失败之后自动重新部署，计算任务。</p>
<p><br></p>
<p>4、 1.* hadoop  结构</p>
<p>           <img src="https://img-blog.csdn.net/20160627182233143?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
<p><br></p>
<p>      HBase :  是实时分布式从数据库：</p>
<p>                        1）、把数据库放在HDFS文件中，有多台电脑同时进行运行，效率非常高。</p>
<p>                        2）、18亿条数据，根据条件查询数据，用时1.6S 。</p>
<p>                        3）、就是一个实时的分布式的数据库，原因在于HDFS的分布式。</p>
<p><br></p>
<p>   </p>
<p>                 </p>
<p>        ETL  :  <span>(E)</span>提起    ----- &gt;  (T) 转换  ---- &gt;  (L) 加载   </p>
<p>       在数据库中提取数据，并进行一系列的对数据的清理筛选，将合格的数据进行转换一定格式的数据进行储存<span></span>，将格式化的数据储存到HDFS上，以供计算框架进行计算与筛选以及挖掘。</p>
<p>         TSV   格式：每行数据的每列之间以【制表符\t】进行分割。</p>
<p>         CSV 格式 ： 每行数据的每列之间以【逗号】进行分割。</p>
<p><br></p>
<p>        Sqoop ： 数据库ETL 工具 ：</p>
<p>                            强关系型数据库的数据与HDFS(HDFS文件、Hbase中的表、Hive 中的表) 上的数据进行相互导入</p>
<p>      </p>
<p>         Flume :  日志收集工具,主要处理日志的信息</p>
<p>         </p>
<p>         </p>
<p>             hadoop   1*    的组成</p>
<p>             <img src="https://img-blog.csdn.net/20160628123010519?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
<p><br></p>
<p><br></p>
<p><br></p>
<p>               NameNode :   数据元服务器</p>
<p>              JobTracker  :   任务调度员</p>
<p>              DateNode  :   块储存</p>
<p>               TaskTracker  :   执行任务</p>
<p> </p>
<p><br></p>
<p>             分布式的系统与框架的结构来说，一般分为两大块：</p>
<p>                   第一部分：管理层，用于管理应用层的</p>
<p>                   第二部分：应用层(工作的)</p>
<p><br></p>
<p>              HDFS 分布式系统:</p>
<p>                           NameNode ：  属于管理层，用于管理数据的属性，属性包含：路径，权限，文件名字，文件的块先和</p>
<p>                           SeccondaryNameNode :  也属于管理者，辅助NameNode进行管理</p>
<p>                           DateNode : 属于应用层，用户进行数据的储存，被NameNode 进行管理，要定时的向NameNode 进行工作汇报，执行NameNode分配分发的任务。</p>
<p><br></p>
<p>              MapRecude 分布式系统 ：</p>
<p>                           JobTracker : 属于管理层，管理集群资源和对任务进行资源的调度，监控人去的执行。</p>
<p>                           TaskTracker : 属于应用层，执行JobTracker 分配分发的任务，并向JobTracker汇报工作情况。</p>
<p><br></p>
<p><br></p>
<p>5、    2.*   的hadoop  的结构如下：</p>
<p>              <img src="https://img-blog.csdn.net/20160628121816988?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
<p><br></p>
<p><br></p>
<p>            hadoop     1.*    的版本与 hadoop   2.*   的版本相比，只是多了一个Yarn框架，主要负责集群管理的任务。</p>
<p>             Yarn :  对每台机器的资源管理，对每台机器的服务，每个人应用进行调度，以及资源的，包括CPU,内存，银盘的调度。</p>
<p>             </p>
<p>            </p>
<p>              <strong><span style="font-size:14px;">各个节点的理解：</span></strong></p>
<p>                <img src="https://img-blog.csdn.net/20160628135650376?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
<p><br></p>
<p>               </p>
<p>                   NameNode   主节点 ： 储存文件的元数据，例如文件的路径，权限，以及每个文件快的列表以及所在快的DateNode .</p>
<p>                   DateNode :  在本地文件系统中储存文件快的数据，以及块的校验和</p>
<p>                   Secondary  NameNode : 用来监控HDFS状态的辅助后台程序，每个一段时间获取HDFS元数据的额快照。</p>
<p>                   JobTracker : 负责接受用户提交的作业，负责启动，跟踪任务执行。‘</p>
<p>                   TaskTracker : 负责执行由JobTracker 分配的任务，管理各个任务在每个节点上的执行情况。</p>
<p><br></p>
<p><br></p>
<p>              <strong><span style="font-size:18px;">   NameNode  : 储存文件的元数据：</span></strong></p>
<p><strong><span style="font-size:18px;">                       1）、文件的额名字</span></strong></p>
<p><strong><span style="font-size:18px;">                       2）、文件的目录结构</span></strong></p>
<p><strong><span style="font-size:18px;">                       3）、文件的属性(权限、副本数、生成的时间) </span></strong></p>
<p><strong><span style="font-size:18px;">                       4）、文件  --   &gt;   Block   ----- &gt;   DateNode   上</span></strong></p>
<p><br></p>
<p><br></p>
<p><span style="font-size:18px;">6、  <strong>HDFS   的结构图：</strong></span></p>
<p><span style="font-size:18px;"><strong><br></strong></span></p>
<p>            1）、理解一图：</p>
<p><img src="https://img-blog.csdn.net/20160628140445528?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
<p><br></p>
<p><br></p>
<p>         2）、理解二图：</p>
<p><br></p>
<p>            <img src="https://img-blog.csdn.net/20160628141744488?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
<p><br></p>
<p><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">           1）NameNode、DataNode和Client</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">                   NameNode可以看作是分布式文件系统中的管理者，主要负责管理文件系统的命名空间、</span></p>
<p><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">                   集群配置信息和存储块的复制等。NameNode会将</span><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">文件系统的Meta-data存储在内存中，</span></p>
<p><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">                  这些信息主要包括了文件信息、每一个文件对应的文件块的信息和每一个文件块在DataNode的信息等。</span></p>
<p><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">                  DataNode是文件存储的基本单元，它将Block存储在本地文件系统中，保存了Block的Meta-data，</span></p>
<p><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">                 同时周期性地将所有存在的Block信息发送给NameNode。</span></p>
<p><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">                 Client就是需要获取分布式文件系统文件的应用程序。</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">           2）文件写入</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">             Client向NameNode发起文件写入的请求。</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">             NameNode根据文件大小和文件块配置情况，返回给Client它所管理部分DataNode的信息。</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">             Client将文件划分为多个Block，根据DataNode的地址信息，按顺序写入到每一个DataNode块中。</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">          3）文件读取</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">            Client向NameNode发起文件读取的请求。</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">            NameNode返回文件存储的DataNode的信息。</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">            Client读取文件信息。</span><br></p>
<p><br></p>
<p><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">通信方式介绍：</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">在hadoop系统中，master/slaves/client的对应关系是：</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">master---namenode；</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">slaves---datanode；</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">client---dfsclient；</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">那究竟是通过什么样的方式进行通信的呢，在这里从大体介绍一下：</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">简单地讲：</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">client和namenode之间是通过rpc通信；</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">datanode和namenode之间是通过rpc通信；</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">client和datanode之间是通过简单的socket通信。</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">随便拔一下DFSClient的代码，可以看到它有一个成员变量public final ClientProtocolnamenode;</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;">而再拔一下DataNode的代码，可以看到它也有一个成员变量public DatanodeProtocolnamenode</span><br></p>
<p><br></p>
<p><br></p>
<p><strong><span style="font-size:18px;">7、MapReduce  结构图 ：  </span></strong></p>
<p><strong><span style="font-size:18px;">       1）、MapReduce 系统的架构图：</span></strong></p>
<p>            <img src="https://img-blog.csdn.net/20160628145404549?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
<p><br></p>
<p>           HearBeat  ：   心跳的意思</p>
<p>            实现的思路：客户端请求时贤惠发送到JobTracker 中，再有JobTracker 通过心跳的方式，每个一段时间通信一次，</p>
<p>            分配到TaskTrackker 中，同事TaskTracker 也会心跳的方式去请求JobTracker ，也会返回结果。</p>
<p>               </p>
<p><br></p>
<p><br></p>
<p>       <strong><span style="font-size:18px;">     2、MapRecude 思想原理图</span></strong></p>
<p><br></p>
<p>             <img src="https://img-blog.csdn.net/20160628145636396?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p>
<p>             </p>
<p><span style="font-size:14px;"><strong>8、hadoop 的启动顺序与关闭顺序</strong></span></p>
<p>  </p>
<p>                 1）、启动顺序<br>
                          HDFS:   namenode   -- &gt;  datanode   ---&gt;    Secondarynamenode   <br>
                          MapReduce : JobTracker   --- &gt;  TaskTracker  <br><br><br><br><br>
           2）、关闭顺序<br>
             MapReduce :  JobTracker  ---&gt;  TaskTracker <br>
             HDFS: namenode --&gt;  datenode -- &gt; secondarynamenode</p>
<p> </p>
<p><br></p>
<p><span style="font-size:14px;"><strong>9、读文件的流程</strong></span></p>
<p><br></p>
<p>           首先客户端会请求文件下心痛，文件系统会去找namenode上的checksum节点，在全中查找最近的datenode获取block<br>
       的数据。</p>
<p><br></p>
<p><br></p>
<p><br></p>
<p><br></p>
<p><br></p>
<p><br></p>
<p><br></p>
<p><br></p>
            </div>
                </div>