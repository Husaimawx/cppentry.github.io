---
layout:     post
title:      Flume学习总结
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/Suubyy/article/details/80517613				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p><strong>- Flume定义</strong></p>

<ol>
<li>Flume是分布式，高可用，基于流式计算的，用于收集、聚合、移动大量日志数据的框架。</li>
</ol>

<hr>

<p><strong>- Flume模型</strong> <br>
 <img src="https://img-blog.csdn.net/20180530232114224?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1dWJ5eQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<ol>
<li>Source用于采集数据源的数据，然后封装成Event传输给Channel管道，期间也可以设置过滤器</li>
<li>Chanel接受来自Source传输过来的Event数据</li>
<li>Sink在Channel中拉取Event数据并将数输出，将数据写入存储设备上。</li>
<li>Event：有可以选的Header和载有数据的ByteAarry组成，Header是容纳了Key-value字符串对的无序集合，key在集合内是唯一的。Header可以在上线文路由中扩展。</li>
</ol>

<hr>

<p><strong>- Flume优点</strong></p>

<ol>
<li>可以和任何中央数据库集中式集成</li>
<li>起到缓冲的作用，减轻存储设备的压力</li>
<li>提供了数据流的路线</li>
<li>事物基于channel，保证了数据的可靠性</li>
<li>高效收集日志</li>
<li>支持水平拓展支持多级跳跃。</li>
</ol>

<hr>

<p><strong>- Flume的使用</strong></p>

<ol>
<li>下载Flume：<a href="http://archive.cloudera.com/cdh5/cdh/5/flume-ng-1.6.0-cdh5.7.0.tar.gz" rel="nofollow">http://archive.cloudera.com/cdh5/cdh/5/flume-ng-1.6.0-cdh5.7.0.tar.gz</a></li>
<li>解压</li>
<li><p>配置<code>${FLUME_HOME}/conf/flume-env.sh</code> 配置Java环境 <br>
<img src="https://img-blog.csdn.net/20180531211904320?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1dWJ5eQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p></li>
<li><p>运行Flume，在${FLUME_HOME}/bin 下运行</p>

<pre class="prettyprint"><code class=" hljs vala">./flume-ng agent -n a1 -c conf -f ../conf/example.conf -Dflume.root.logger=INFO,console

<span class="hljs-preprocessor">#agent 必须写的没有疑问</span>


<span class="hljs-preprocessor"># -n a1 ：指定agent的名字</span>


<span class="hljs-preprocessor"># -c conf 指定配置目录</span>


<span class="hljs-preprocessor"># -f 执行agent具体的的配置文件</span>


<span class="hljs-preprocessor"># Dflume.root.logger=INFO,console：接收数据打印到控制台</span>


<span class="hljs-preprocessor"># example.conf：配置文件。需要自己根据flume的语法创建</span>
</code></pre>

<pre class="prettyprint"><code class=" hljs avrasm">
<span class="hljs-preprocessor">#example.conf，基础的测试案例</span>

a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span> <span class="hljs-preprocessor">#设置source名字</span>
a1<span class="hljs-preprocessor">.sinks</span> = k1 <span class="hljs-preprocessor">#设置sink名字，可以有多个，用逗号隔开</span>
a1<span class="hljs-preprocessor">.channels</span> = c1 <span class="hljs-preprocessor">#设置channel名字，可以有多个，用逗号隔开</span>

a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = netcat <span class="hljs-preprocessor">#设置source监控的数据类型</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.bind</span> = hadoop001 <span class="hljs-preprocessor">#设置source监控的地址</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.port</span> = <span class="hljs-number">44444</span> <span class="hljs-preprocessor">#设置source的监控端口</span>


a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = memory <span class="hljs-preprocessor">#设置channel的类型</span>


a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1 <span class="hljs-preprocessor">#设置source与channel的连接</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1 <span class="hljs-preprocessor">#设置sink与channel的连接</span></code></pre></li>
<li><p>在source监控的地址的机器上运行<code>telnet xx.xxx.xxx.xxx  44444</code>,然后随便数据数据就可以在Flume的agent的机器的控制台上出现输入的数据 <br>
<img src="https://img-blog.csdn.net/20180531214020975?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1dWJ5eQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
<img src="https://img-blog.csdn.net/20180531213941263?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1dWJ5eQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p></li>
</ol>

<hr>

<p><strong>- Flume的三大组件</strong></p>

<ol>
<li><p>Source，其中红框里的最常用也是最重要的 <br>
<img src="https://img-blog.csdn.net/20180531222925391?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1dWJ5eQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<ol><li><p>Exec Soufce，通过linux的指令来监控数据，以下是基本配置，想看详细配置请点击该链接<a href="http://flume.apache.org/FlumeUserGuide.html#exec-source" rel="nofollow">http://flume.apache.org/FlumeUserGuide.html#exec-source</a></p>

<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span> <span class="hljs-preprocessor">#定义source的名字，多个用逗号隔开</span>
a1<span class="hljs-preprocessor">.channels</span> = c1 <span class="hljs-preprocessor">#定义channel的名字，多个用逗号隔开</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = exec <span class="hljs-preprocessor">#定义source的类型</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.command</span> = tail -F /var/log/secure <span class="hljs-preprocessor">#利用指令监控日志</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1</code></pre>

<table>
<thead>
<tr>
  <th>属性名</th>
  <th align="center">默认值</th>
  <th align="right">属性名解释</th>
</tr>
</thead>
<tbody><tr>
  <td><strong>channels</strong></td>
  <td align="center">无</td>
  <td align="right">连接channel</td>
</tr>
<tr>
  <td><strong>type</strong></td>
  <td align="center">无</td>
  <td align="right">该组件的类型名称，该值必须是exec</td>
</tr>
<tr>
  <td><strong>command</strong></td>
  <td align="center">无</td>
  <td align="right">执行的命令，例如：tail -F /var/log/secure</td>
</tr>
<tr>
  <td>shell</td>
  <td align="center">无</td>
  <td align="right">用于运行命令的shell调用</td>
</tr>
<tr>
  <td>restartThrottle</td>
  <td align="center">10000</td>
  <td align="right">在尝试重新启动之前等待的时间(以millis为单位)</td>
</tr>
<tr>
  <td>restart</td>
  <td align="center">false</td>
  <td align="right">如果执行的cmd死了，是否应该重新启动它</td>
</tr>
<tr>
  <td>logStdErr</td>
  <td align="center">false</td>
  <td align="right">是否记录命令的标准输出</td>
</tr>
<tr>
  <td>batchSize</td>
  <td align="center">20</td>
  <td align="right">每次读取和发送给channel的最大行数</td>
</tr>
<tr>
  <td>batchTimeout</td>
  <td align="center">3000</td>
  <td align="right">如果没有达到缓冲区的大小，等待多久将数据push到channel里</td>
</tr>
<tr>
  <td>selector.type</td>
  <td align="center">replicating</td>
  <td align="right">复制或多路复用。复制就是把一个完整的事件发送到不同的channel中，多路复用就是根据不同的条件将同一个事件拆分成多个条目发送到channel中</td>
</tr>
<tr>
  <td>selector.*</td>
  <td align="center">无</td>
  <td align="right">取决于selector.type的值</td>
</tr>
<tr>
  <td>interceptors</td>
  <td align="center">无</td>
  <td align="right">空格分隔的列表的拦截器</td>
</tr>
<tr>
  <td>interceptors.*</td>
  <td align="center"></td>
  <td align="right"></td>
</tr>
</tbody></table>
</li>
<li><p>SpoolDirectorySource：这个源支持从磁盘中某文件夹获取文件数据。不同于其他异步源，这个源能够避免重启或者发送失败后数据丢失。flume可以监控文件夹，当出现新文件时会读取该文件并获取数据。当一个给定的文件被全部读入到通道中时，该文件会被重命名以标志已经完成。同时，该源需要一个清理进程来定期移除完成的文件，一下是最基本的配置，想看详细配置请点击该链接<a href="http://flume.apache.org/FlumeUserGuide.html#spooling-directory-source" rel="nofollow">http://flume.apache.org/FlumeUserGuide.html#spooling-directory-source</a></p>

<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.channels</span> = ch-<span class="hljs-number">1</span>
a1<span class="hljs-preprocessor">.sources</span> = src-<span class="hljs-number">1</span>

a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.src</span>-<span class="hljs-number">1.</span>type = spooldir
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.src</span>-<span class="hljs-number">1.</span>channels = ch-<span class="hljs-number">1</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.src</span>-<span class="hljs-number">1.</span>spoolDir = /var/log/apache/flumeSpool
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.src</span>-<span class="hljs-number">1.</span>fileHeader = true</code></pre>

<table>
<thead>
<tr>
  <th>属性名</th>
  <th align="center">默认值</th>
  <th align="right">属性名解释</th>
</tr>
</thead>
<tbody><tr>
  <td><strong>channels</strong></td>
  <td align="center">无</td>
  <td align="right">连接channel</td>
</tr>
<tr>
  <td><strong>type</strong></td>
  <td align="center">无</td>
  <td align="right">该组件的类型名称，必须是spooldir</td>
</tr>
<tr>
  <td><strong>spoolDir</strong></td>
  <td align="center">无</td>
  <td align="right">自己定义的spooldir的文件目录</td>
</tr>
<tr>
  <td>fileSuffix</td>
  <td align="center">.COMPLETED</td>
  <td align="right">文件读取完毕以后给完成文件添加的标记后缀</td>
</tr>
<tr>
  <td>deletePolicy</td>
  <td align="center">never</td>
  <td align="right">是否删除读取完毕的文件，默认是”never”，就是不删除，目前只支持”never”和“IMMEDIATE”；</td>
</tr>
<tr>
  <td>fileHeader</td>
  <td align="center">false</td>
  <td align="right">是否在event的Header中添加文件名，boolean类型</td>
</tr>
<tr>
  <td>fileHeaderKey</td>
  <td align="center">file</td>
  <td align="right">这是event的Header中的key,value是文件名</td>
</tr>
<tr>
  <td>basenameHeader</td>
  <td align="center">false</td>
  <td align="right">是否添加一个存储文件的basename的Header</td>
</tr>
<tr>
  <td>basenameHeaderKey</td>
  <td align="center">basename</td>
  <td align="right">将文件的basename添加到事件头时使用的头文件键。</td>
</tr>
<tr>
  <td>includePattern</td>
  <td align="center">^.*$</td>
  <td align="right">指定要包含哪些文件的正则表达式。它可以与ignorePattern一起使用。如果一个文件同时匹配ignorePattern和includePattern regex，该文件将被忽略。</td>
</tr>
<tr>
  <td>ignorePattern</td>
  <td align="center">^$</td>
  <td align="right">正则表达式指定被忽略的文件，如果一个文件同时匹配ignorePattern和includePattern regex，该文件将被忽略。</td>
</tr>
<tr>
  <td>trackerDir</td>
  <td align="center">.flumespool</td>
  <td align="right">目录来存储与文件处理相关的元数据。如果该路径不是绝对路径，则将指定spoolDir。</td>
</tr>
<tr>
  <td>pollDelay</td>
  <td align="center">500</td>
  <td align="right">轮询新文件的时候使用的延迟时间</td>
</tr>
<tr>
  <td>recursiveDirectorySearch</td>
  <td align="center">false</td>
  <td align="right">是否监视要读取的新文件的子目录</td>
</tr>
<tr>
  <td>maxBackoff</td>
  <td align="center">4000</td>
  <td align="right">如果通道满了以后，连续尝试向通道里写入数据的最大的等待时间，毫秒为单位</td>
</tr>
<tr>
  <td>batchSize</td>
  <td align="center">100</td>
  <td align="right">批量向channle传输event的大小</td>
</tr>
<tr>
  <td>inputCharset</td>
  <td align="center">UTF-8</td>
  <td align="right">编码方式，默认是”UTF-8”</td>
</tr>
<tr>
  <td>decodeErrorPolicy</td>
  <td align="center">FAIL</td>
  <td align="right">FAIL:抛出异常并解析文件失败。REPLACE:将不可解析字符替换为“替换字符”字符，通常是Unicode U+FFFD。IGNORE:删除不可解析的字符序列。</td>
</tr>
<tr>
  <td>deserializer</td>
  <td align="center">LINE</td>
  <td align="right">指定用于将文件解析为事件的反序列化器。默认情况下，将每一行解析为一个事件。指定的类必须实现eventdeserizer.builder。</td>
</tr>
<tr>
  <td>selector.type</td>
  <td align="center">replicating</td>
  <td align="right">复制或多路复用。复制就是把一个完整的事件发送到不同的channel中，多路复用就是根据不同的条件将同一个事件拆分成多个条目发送到channel中</td>
</tr>
<tr>
  <td>selector.*</td>
  <td align="center">无</td>
  <td align="right">取决于selector.type的值</td>
</tr>
<tr>
  <td>interceptors</td>
  <td align="center">无</td>
  <td align="right">空格分隔的列表的拦截器</td>
</tr>
<tr>
  <td>interceptors.*</td>
  <td align="center"></td>
  <td align="right"></td>
</tr>
</tbody></table>
</li>
<li><p>Kafka Source：是一个从Kafka的 Topic中读取消息的Apache Kafka消费者。 如果您有多个Kafka source运行，您可以使用相同的Consumer Group配置它们，因此每个将读取topic中一组唯一的分区。以下是基本配置，想看详细配置请点击该链接<a href="http://flume.apache.org/FlumeUserGuide.html#kafka-source" rel="nofollow">http://flume.apache.org/FlumeUserGuide.html#kafka-source</a></p>

<pre class="prettyprint"><code class=" hljs avrasm">tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.type</span> = org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.flume</span><span class="hljs-preprocessor">.source</span><span class="hljs-preprocessor">.kafka</span><span class="hljs-preprocessor">.KafkaSource</span> <span class="hljs-preprocessor">#指定source的类型为kafka</span>
tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.channels</span> = channel1
tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.batchSize</span> = <span class="hljs-number">5000</span> <span class="hljs-preprocessor">#在一个批处理中写入通道的最大消息数</span>
tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.batchDurationMillis</span> = <span class="hljs-number">2000</span> <span class="hljs-preprocessor">#在将批处理写入通道之前的最大时间(以ms为单位)</span>
tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.kafka</span><span class="hljs-preprocessor">.bootstrap</span><span class="hljs-preprocessor">.servers</span> = localhost:<span class="hljs-number">9092</span> <span class="hljs-preprocessor">#kafka地址</span>
tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.kafka</span><span class="hljs-preprocessor">.topics</span> = test1, test2 <span class="hljs-preprocessor">#指定消费哪些主题，多个用逗号隔开</span>
tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.kafka</span><span class="hljs-preprocessor">.consumer</span><span class="hljs-preprocessor">.group</span><span class="hljs-preprocessor">.id</span> = custom<span class="hljs-preprocessor">.g</span><span class="hljs-preprocessor">.id</span> </code></pre>

<pre class="prettyprint"><code class=" hljs avrasm">tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.type</span> = org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.flume</span><span class="hljs-preprocessor">.source</span><span class="hljs-preprocessor">.kafka</span><span class="hljs-preprocessor">.KafkaSource</span> <span class="hljs-preprocessor">#指定source的类型为kafka</span>
tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.channels</span> = channel1
tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.kafka</span><span class="hljs-preprocessor">.bootstrap</span><span class="hljs-preprocessor">.servers</span> = localhost:<span class="hljs-number">9092</span> <span class="hljs-preprocessor">#kafka地址</span>
tier1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.kafka</span><span class="hljs-preprocessor">.topics</span><span class="hljs-preprocessor">.regex</span> = ^topic[<span class="hljs-number">0</span>-<span class="hljs-number">9</span>]$ <span class="hljs-preprocessor">#正则匹配消费哪些主题</span>

<span class="hljs-preprocessor"># the default kafka.consumer.group.id=flume is used</span>
</code></pre>

<table>
<thead>
<tr>
  <th>属性名</th>
  <th align="center">默认值</th>
  <th align="right">属性名解释</th>
</tr>
</thead>
<tbody><tr>
  <td><strong>channels</strong></td>
  <td align="center">无</td>
  <td align="right">连接channel</td>
</tr>
<tr>
  <td><strong>type</strong></td>
  <td align="center">无</td>
  <td align="right">该组件的类型名称，必须是org.apache.flume.source.kafka.KafkaSource</td>
</tr>
<tr>
  <td><strong>kafka.bootstrap.servers</strong></td>
  <td align="center">无</td>
  <td align="right">kafka集群的地址，如localhost:9092</td>
</tr>
<tr>
  <td><strong>kafka.topics</strong></td>
  <td align="center">无</td>
  <td align="right">Kafka集群的主题，多个用逗号隔开</td>
</tr>
<tr>
  <td><strong>kafka.topics.regex</strong></td>
  <td align="center">无</td>
  <td align="right">正则匹配的主题集，他比kafka.topics优先级高，如果kafka.topics存在，那么就会覆盖kafka.topics的值</td>
</tr>
<tr>
  <td>kafka.consumer.group.id</td>
  <td align="center">flume</td>
  <td align="right">消费者群体的唯一标识。在多个源或代理中设置相同的id表明它们属于同一个消费者组</td>
</tr>
<tr>
  <td>batchSize</td>
  <td align="center">1000</td>
  <td align="right">一个批次向channel中写入的最大的消息的数量</td>
</tr>
<tr>
  <td>batchDurationMillis</td>
  <td align="center">1000</td>
  <td align="right">在将批处理写入通道之前的最大时间(以ms为单位)</td>
</tr>
<tr>
  <td>backoffSleepIncrement</td>
  <td align="center">1000</td>
  <td align="right">当Kafka主题为空时触发的初始和增量等待时间。这个值尽可能的低</td>
</tr>
<tr>
  <td>maxBackoffSleep</td>
  <td align="center">5000</td>
  <td align="right">当Kafka主题看起来为空时触发的最大等待时间，这个值尽可能的低</td>
</tr>
<tr>
  <td>useFlumeEventFormat</td>
  <td align="center">false</td>
  <td align="right">默认情况下，事件作为字节从Kafka主题直接带到事件主体中。设置为true以Avro二进制格式读取事件。与KafkaSink上的相同属性或Kafka通道上的parseAsFlumeEvent属性一起使用，这将保留在生产端发送的所有Flume头。</td>
</tr>
<tr>
  <td>setTopicHeader</td>
  <td align="center">true</td>
  <td align="right">当设置为true时，将检索到的消息的主题存储到一个header中，由topicHeader属性定义。</td>
</tr>
<tr>
  <td>topicHeader</td>
  <td align="center">topic</td>
  <td align="right">如果setTopicHeader属性设置为true，则定义用于存储接收消息的主题的标题的名称。如果与Kafka Sink topicHeader属性结合，应该要小心，以免在循环中将消息发送回相同的主题。</td>
</tr>
<tr>
  <td>migrateZookeeperOffsets</td>
  <td align="center">true</td>
  <td align="right"></td>
</tr>
</tbody></table>
</li>
<li><p>Syslog Sources：读取Syslog数据转转换成Event。</p>

<ol><li><p>Syslog TCP Source：通过单个监听端口来接受数据转换成Event</p>

<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span>   <span class="hljs-preprocessor">#source名称</span>
a1<span class="hljs-preprocessor">.channels</span> = c1   <span class="hljs-preprocessor">#channel的名称</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = syslogtcp   <span class="hljs-preprocessor">#source类型为syslogtcp</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.port</span> = <span class="hljs-number">5140</span>  <span class="hljs-preprocessor">#source监控的端口号</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.host</span> = localhost   <span class="hljs-preprocessor">#监控的机器地址</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1  <span class="hljs-preprocessor">#定义source与channel的连接</span></code></pre>

<table>
<thead>
<tr>
  <th>属性名</th>
  <th align="center">默认值</th>
  <th align="right">属性名解释</th>
</tr>
</thead>
<tbody><tr>
  <td><strong>channels</strong></td>
  <td align="center">无</td>
  <td align="right">连接channel</td>
</tr>
<tr>
  <td><strong>type</strong></td>
  <td align="center">无</td>
  <td align="right">该组件的类型名称，必须是syslogtcp</td>
</tr>
<tr>
  <td><strong>host</strong></td>
  <td align="center">无</td>
  <td align="right">主机名或IP地址</td>
</tr>
<tr>
  <td><strong>port</strong></td>
  <td align="center">无</td>
  <td align="right">监听的端口号</td>
</tr>
<tr>
  <td>eventSize</td>
  <td align="center">2500</td>
  <td align="right">单个事件行的最大大小，以字节为单位</td>
</tr>
<tr>
  <td>selector.type</td>
  <td align="center">replicating</td>
  <td align="right">复制或多路复用。复制就是把一个完整的事件发送到不同的channel中，多路复用就是根据不同的条件将同一个事件拆分成多个条目发送到channel中</td>
</tr>
<tr>
  <td>selector.*</td>
  <td align="center">无</td>
  <td align="right">取决于selector.type的值</td>
</tr>
<tr>
  <td>interceptors</td>
  <td align="center">无</td>
  <td align="right">空格分隔的列表的拦截器</td>
</tr>
<tr>
  <td>interceptors.*</td>
  <td align="center"></td>
  <td align="right"></td>
</tr>
</tbody></table>
</li>
<li><p>Multiport  Syslog TCP Source：通过监听多个端口开始先数据转换成Event</p>

<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span>  <span class="hljs-preprocessor">#定义的source</span>
a1<span class="hljs-preprocessor">.channels</span> = c1 <span class="hljs-preprocessor">#定义channel</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = multiport_syslogtcp  <span class="hljs-preprocessor">#指定source类型为多端口监控</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.host</span> = <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span> <span class="hljs-preprocessor">#指定监控端口的所在的机器</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.ports</span> = <span class="hljs-number">10001</span> <span class="hljs-number">10002</span> <span class="hljs-number">10003</span>  <span class="hljs-preprocessor">#监控多个端口用空格开</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.portHeader</span> = port  <span class="hljs-preprocessor">#监控的是端口</span></code></pre>

<table>
<thead>
<tr>
  <th>属性名</th>
  <th align="center">默认值</th>
  <th align="right">属性名解释</th>
</tr>
</thead>
<tbody><tr>
  <td><strong>channels</strong></td>
  <td align="center">无</td>
  <td align="right">连接channel</td>
</tr>
<tr>
  <td><strong>type</strong></td>
  <td align="center">无</td>
  <td align="right">该组件的类型名称，必须是multiport_syslogtcp</td>
</tr>
<tr>
  <td><strong>host</strong></td>
  <td align="center">无</td>
  <td align="right">主机名或IP地址</td>
</tr>
<tr>
  <td><strong>ports</strong></td>
  <td align="center">无</td>
  <td align="right">监听的端口号，多个用空格隔开</td>
</tr>
<tr>
  <td>portHeader</td>
  <td align="center">无</td>
  <td align="right">如果指定，端口号将使用这里指定的头名存储在每个事件的头中。这允许拦截器和通道选择器根据传入的端口自定义路由逻辑。</td>
</tr>
<tr>
  <td>eventSize</td>
  <td align="center">2500</td>
  <td align="right">单个事件行的最大大小，以字节为单位</td>
</tr>
<tr>
  <td>charset.default</td>
  <td align="center">UTF-8</td>
  <td align="right">将syslog事件解析为字符串时使用的默认字符集。</td>
</tr>
<tr>
  <td>charset.port.《port》</td>
  <td align="center">无</td>
  <td align="right">设置对应端口的字符集</td>
</tr>
<tr>
  <td>batchSize</td>
  <td align="center">100</td>
  <td align="right">尝试处理每个请求循环的最大事件数。使用默认值通常是可以的。</td>
</tr>
<tr>
  <td>readBufferSize</td>
  <td align="center">1024</td>
  <td align="right">内部Mina读取缓冲区的大小。提供性能调优。使用默认值通常是可以的。</td>
</tr>
<tr>
  <td>selector.type</td>
  <td align="center">replicating</td>
  <td align="right">复制或多路复用。复制就是把一个完整的事件发送到不同的channel中，多路复用就是根据不同的条件将同一个事件拆分成多个条目发送到channel中</td>
</tr>
<tr>
  <td>selector.*</td>
  <td align="center">无</td>
  <td align="right">取决于selector.type的值</td>
</tr>
<tr>
  <td>interceptors</td>
  <td align="center">无</td>
  <td align="right">空格分隔的列表的拦截器</td>
</tr>
<tr>
  <td>interceptors.*</td>
  <td align="center"></td>
  <td align="right"></td>
</tr>
</tbody></table>
</li>
<li><p>Syslog UDP Source¶：通过监听UDP协议的端口来实现数据转换成Event，以下是具体的必须配置项，如果想查看更加详细的配置请点击该链接<a href="http://flume.apache.org/FlumeUserGuide.html#syslog-udp-source" rel="nofollow">http://flume.apache.org/FlumeUserGuide.html#syslog-udp-source</a></p>

<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span>
a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = syslogudp <span class="hljs-preprocessor">#指定source类型为syslogUdp</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.port</span> = <span class="hljs-number">5140</span>  <span class="hljs-preprocessor">#指定监控的端口</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.host</span> = localhost
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1</code></pre>

<table>
<thead>
<tr>
  <th>属性名</th>
  <th align="center">默认值</th>
  <th align="right">属性名解释</th>
</tr>
</thead>
<tbody><tr>
  <td><strong>channels</strong></td>
  <td align="center">无</td>
  <td align="right">连接channel</td>
</tr>
<tr>
  <td><strong>type</strong></td>
  <td align="center">无</td>
  <td align="right">该组件的类型名称，必须是syslogudp</td>
</tr>
<tr>
  <td><strong>host</strong></td>
  <td align="center">无</td>
  <td align="right">主机名或IP地址</td>
</tr>
<tr>
  <td><strong>port</strong></td>
  <td align="center">无</td>
  <td align="right">监听的端口号</td>
</tr>
<tr>
  <td>selector.type</td>
  <td align="center">replicating</td>
  <td align="right">复制或多路复用。复制就是把一个完整的事件发送到不同的channel中，多路复用就是根据不同的条件将同一个事件拆分成多个条目发送到channel中</td>
</tr>
<tr>
  <td>selector.*</td>
  <td align="center">无</td>
  <td align="right">取决于selector.type的值</td>
</tr>
<tr>
  <td>interceptors</td>
  <td align="center">无</td>
  <td align="right">空格分隔的列表的拦截器</td>
</tr>
<tr>
  <td>interceptors.*</td>
  <td align="center"></td>
  <td align="right"></td>
</tr>
</tbody></table>
</li></ol></li>
<li><p>HTTP Source：用于接受Http的Post或者Get请求，但是Get请求一般用在实验环境中，以下是最基本的配置，如果想查看更加详细的配置请点击该链接<a href="http://flume.apache.org/FlumeUserGuide.html#http-source" rel="nofollow">http://flume.apache.org/FlumeUserGuide.html#http-source</a></p>

<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span>
a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = http <span class="hljs-preprocessor">#指定source的类型为http</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.port</span> = <span class="hljs-number">5140</span> <span class="hljs-preprocessor">#指定监控的端口</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1 
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.handler</span> = org<span class="hljs-preprocessor">.example</span><span class="hljs-preprocessor">.rest</span><span class="hljs-preprocessor">.RestHandler</span>   <span class="hljs-preprocessor">#指定绑定的处理程序，如果自己定义这个处理程序需要需要定义一个实现了HTTPSourceHandler接口的类，然后打包放到Flume的lib目录下。</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.handler</span><span class="hljs-preprocessor">.nickname</span> = random props <span class="hljs-preprocessor">#配置处理程序的参数</span></code></pre>

<table>
<thead>
<tr>
  <th>属性名</th>
  <th align="center">默认值</th>
  <th align="right">属性名解释</th>
</tr>
</thead>
<tbody><tr>
  <td><strong>channels</strong></td>
  <td align="center">无</td>
  <td align="right">连接channel</td>
</tr>
<tr>
  <td><strong>type</strong></td>
  <td align="center">无</td>
  <td align="right">该组件的类型名称，必须是http</td>
</tr>
<tr>
  <td><strong>port</strong></td>
  <td align="center">无</td>
  <td align="right">监听的端口号</td>
</tr>
<tr>
  <td>bind</td>
  <td align="center">0.0.0.0</td>
  <td align="right">监听的主机名或者ip地址</td>
</tr>
<tr>
  <td>handler</td>
  <td align="center">org.apache.flume.source.http.JSONHandler</td>
  <td align="right">处理程序类</td>
</tr>
<tr>
  <td>handler.*</td>
  <td align="center">无</td>
  <td align="right">处理程序类的配置参数</td>
</tr>
<tr>
  <td>selector.type</td>
  <td align="center">replicating</td>
  <td align="right">复制或多路复用。复制就是把一个完整的事件发送到不同的channel中，多路复用就是根据不同的条件将同一个事件拆分成多个条目发送到channel中</td>
</tr>
<tr>
  <td>selector.*</td>
  <td align="center">无</td>
  <td align="right">取决于selector.type的值</td>
</tr>
<tr>
  <td>interceptors</td>
  <td align="center">无</td>
  <td align="right">空格分隔的列表的拦截器</td>
</tr>
<tr>
  <td>interceptors.*</td>
  <td align="center"></td>
  <td align="right"></td>
</tr>
<tr>
  <td>enableSSL</td>
  <td align="center">false</td>
  <td align="right">将属性设置为true，以启用SSL。HTTP源不支持SSLv3。</td>
</tr>
<tr>
  <td>excludeProtocols</td>
  <td align="center">SSLv3</td>
  <td align="right">要排除的SSL/TLS协议的空格分隔列表。SSLv3总是被排除在外。</td>
</tr>
<tr>
  <td>keystore</td>
  <td align="center"></td>
  <td align="right">密钥存储库的位置包括密钥存储库文件名</td>
</tr>
<tr>
  <td>keystorePassword Keystore password</td>
  <td align="center">无</td>
  <td align="right">密钥密码</td>
</tr>
</tbody></table>
</li></ol></li>
<li><p>Sink，红框内的比较常用 <br>
<img src="https://img-blog.csdn.net/20180531223644472?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1dWJ5eQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<ol><li><p>HDFS Sink：输出时间到HDFS中，以下是基本配置，如果想查看详细配置请点击该链接<a href="http://flume.apache.org/FlumeUserGuide.html#flume-sinks" rel="nofollow">http://flume.apache.org/FlumeUserGuide.html#flume-sinks</a></p>

<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = hdfs  <span class="hljs-preprocessor">#执行sink输出的类型为HDFS</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.path</span> = hdfs://hadoop001:<span class="hljs-number">8020</span>/flume/events/%<span class="hljs-built_in">y</span>-%m-%d/%H%M/%S  <span class="hljs-preprocessor">#指定Sink写入HDFS的路径</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.filePrefix</span> = events-  <span class="hljs-preprocessor">#指定sink写入HDFS文件的前缀名</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.round</span> = true  <span class="hljs-preprocessor">#是否开启时间戳的四舍五入</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.roundValue</span> = <span class="hljs-number">10</span>  <span class="hljs-preprocessor">#舍弃十分钟，也就是该目录每十分钟生成一个</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.roundUnit</span> = minute  <span class="hljs-preprocessor">#四舍五入的最小单位</span></code></pre>

<table>
<thead>
<tr>
  <th>属性名</th>
  <th align="center">默认值</th>
  <th align="right">属性名解释</th>
</tr>
</thead>
<tbody><tr>
  <td><strong>channels</strong></td>
  <td align="center">无</td>
  <td align="right">连接channel</td>
</tr>
<tr>
  <td><strong>type</strong></td>
  <td align="center">无</td>
  <td align="right">该组件的类型名称，必须是hdfs</td>
</tr>
<tr>
  <td><strong>hdfs.path</strong></td>
  <td align="center">无</td>
  <td align="right">HDFS目录路径</td>
</tr>
<tr>
  <td>hdfs.filePrefix</td>
  <td align="center">FlumeData</td>
  <td align="right">HDFS上前缀标识的为Flume创建的文件</td>
</tr>
<tr>
  <td>hdfs.fileSuffix</td>
  <td align="center">无</td>
  <td align="right">HDFS上后缀标识的为Flume创建的文件</td>
</tr>
<tr>
  <td>hdfs.inUsePrefix</td>
  <td align="center">无</td>
  <td align="right">用于flume主动写入的临时文件的前缀</td>
</tr>
<tr>
  <td>hdfs.inUseSuffix</td>
  <td align="center">.tmp</td>
  <td align="right">用于flume主动写入的临时文件的后缀</td>
</tr>
<tr>
  <td>hdfs.rollInterval</td>
  <td align="center">30</td>
  <td align="right">间隔多少秒数触发滚动当前文件(0 =从不基于时间间隔滚动)</td>
</tr>
<tr>
  <td>hdfs.rollSize</td>
  <td align="center">1024</td>
  <td align="right">文件的触发滚动当前文件 单位为bytes（0=从不基于大小滚动）</td>
</tr>
<tr>
  <td>hdfs.rollCount</td>
  <td align="center">10</td>
  <td align="right">事件的条目数触发滚动当前文件(0 =从不滚动基于事件数)</td>
</tr>
<tr>
  <td>hdfs.idleTimeout</td>
  <td align="center">0</td>
  <td align="right">超时后关闭非活跃文件(0 =禁用自动关闭空闲文件)</td>
</tr>
<tr>
  <td>hdfs.batchSize</td>
  <td align="center">100</td>
  <td align="right">一个批次向HDFS写入的事件数</td>
</tr>
<tr>
  <td>hdfs.codeC</td>
  <td align="center">无</td>
  <td align="right">指定压缩格式。gzip, bzip2, lzo, lzop, snappy</td>
</tr>
<tr>
  <td>hdfs.fileType</td>
  <td align="center">SequenceFile</td>
  <td align="right">文件格式:当前SequenceFile、DataStream或CompressedStream (1)DataStream不会压缩输出文件，请不要设置压缩格式(2)CompressedStream必须设置hdfs.codeC的压缩格式</td>
</tr>
<tr>
  <td>hdfs.maxOpenFiles</td>
  <td align="center">5000</td>
  <td align="right">只允许打开这个数目的文件。如果超过这个数字，就会关闭最老的文件</td>
</tr>
<tr>
  <td>hdfs.minBlockReplicas</td>
  <td align="center">无</td>
  <td align="right">指定每个HDFS块的最小复制数。如果没有指定，它来自类路径中的默认Hadoop配置。</td>
</tr>
<tr>
  <td>hdfs.writeFormat</td>
  <td align="center">Writable</td>
  <td align="right">向DFS文件里写的格式，要么是Text或者Writable，在使用Flume创建数据文件之前，将这些文件设置为Text，否则Apache Impala或Apache Hive都无法读取这些文件</td>
</tr>
<tr>
  <td>hdfs.callTimeout</td>
  <td align="center">10000</td>
  <td align="right">用于HDFS操作的毫秒数，如打开、写入、刷新、关闭。如果发生许多HDFS超时操作，则应该增加这个数字。</td>
</tr>
<tr>
  <td>hdfs.threadsPoolSize</td>
  <td align="center">10</td>
  <td align="right">HDFS IO操作的每个HDFS接收器的线程数</td>
</tr>
<tr>
  <td>hdfs.rollTimerPoolSize</td>
  <td align="center">1</td>
  <td align="right">用于调度定时文件滚动的每个HDFS接收器的线程数</td>
</tr>
<tr>
  <td>hdfs.kerberosPrincipal</td>
  <td align="center">无</td>
  <td align="right">用于访问安全HDFS的Kerberos用户主体</td>
</tr>
<tr>
  <td>hdfs.kerberosKeytab</td>
  <td align="center">无</td>
  <td align="right">用于访问安全HDFS的Kerberos keytab</td>
</tr>
<tr>
  <td>hdfs.round</td>
  <td align="center">false</td>
  <td align="right">是否时间戳被四舍五入</td>
</tr>
<tr>
  <td>hdfs.roundValue</td>
  <td align="center">1</td>
  <td align="right">四舍五入到最高倍数(在使用hdfs.roundUnit配置的单元中)，小于当前时间</td>
</tr>
<tr>
  <td>hdfs.roundUnit</td>
  <td align="center">second</td>
  <td align="right">事件四舍五入的最小单位- second, minute or hour.</td>
</tr>
<tr>
  <td>hdfs.timeZone</td>
  <td align="center">Local Time</td>
  <td align="right">用于解析目录路径的时区的名称，例如America/Los_Angeles。</td>
</tr>
<tr>
  <td>hdfs.useLocalTimeStamp</td>
  <td align="center">false</td>
  <td align="right">在替换转义序列时，使用本地时间(而不是事件头部的时间戳)。</td>
</tr>
</tbody></table>
</li>
<li><p>Hive Sink:该接收器将包含分隔文本或JSON数据的事件直接写到到Hive表或分区中。事件是使用Hive事务来编写的。一旦一组事件被提交到Hive中，它们就会立即出现在Hive查询中。flume要写入到的分区可以是预先创建好的，也可以是没创建好的，如果没有创建好这些分区，flume可以创建它们。事件数据的字段被映射到Hive表中的相应列。以下是基本的配置，如果想要查看更详细的配置，请查看下边对应的表格</p>

<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.channels</span> = c1 
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = memory
a1<span class="hljs-preprocessor">.sinks</span> = k1  <span class="hljs-preprocessor">#定义sink的名字，多个可以用逗号隔开</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = hive  <span class="hljs-preprocessor">#定义sink类型为Hive</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hive</span><span class="hljs-preprocessor">.metastore</span> = thrift://<span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">9083</span>  <span class="hljs-preprocessor">#连接MetaStore服务的地址</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hive</span><span class="hljs-preprocessor">.database</span> = logsdb  <span class="hljs-preprocessor">#写入的Hive的数据库</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hive</span><span class="hljs-preprocessor">.table</span> = weblogs  <span class="hljs-preprocessor">#写入的hive表</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hive</span><span class="hljs-preprocessor">.partition</span> = asia,%{country},%<span class="hljs-built_in">y</span>-%m-%d-%H-%M  <span class="hljs-preprocessor">#指定分区</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.useLocalTimeStamp</span> = <span class="hljs-preprocessor">#false 是否使用本地时间戳</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.round</span> = true  <span class="hljs-preprocessor">#是否开启时间的四舍五入</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.roundValue</span> = <span class="hljs-number">10</span>  <span class="hljs-preprocessor">#时间的四舍五入的最高倍数</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.roundUnit</span> = minute  <span class="hljs-preprocessor">#时间的四舍五入的最小单位</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.serializer</span> = DELIMITED <span class="hljs-preprocessor">#设定序列化器为分割</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.serializer</span><span class="hljs-preprocessor">.delimiter</span> = <span class="hljs-string">"\t"</span> <span class="hljs-preprocessor">#设定分割符号</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.serializer</span><span class="hljs-preprocessor">.serdeSeparator</span> = <span class="hljs-string">'\t'</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.serializer</span><span class="hljs-preprocessor">.fieldnames</span> =id,msg  <span class="hljs-preprocessor"># #字段名称，","分隔，不能有空格</span></code></pre>

<table>
<thead>
<tr>
  <th>属性名</th>
  <th align="center">默认值</th>
  <th align="right">属性名解释</th>
</tr>
</thead>
<tbody><tr>
  <td><strong>channels</strong></td>
  <td align="center">无</td>
  <td align="right">连接channel</td>
</tr>
<tr>
  <td><strong>type</strong></td>
  <td align="center">无</td>
  <td align="right">该组件的类型名称，必须是hive</td>
</tr>
<tr>
  <td><strong>hive.metastore</strong></td>
  <td align="center">无</td>
  <td align="right">MetaStore服务，例如thrift://localhost:9083</td>
</tr>
<tr>
  <td><strong>hive.database</strong></td>
  <td align="center">无</td>
  <td align="right">hive数据库</td>
</tr>
<tr>
  <td><strong>hive.table</strong></td>
  <td align="center">无</td>
  <td align="right">hive表</td>
</tr>
<tr>
  <td>hive.partition</td>
  <td align="center">无</td>
  <td align="right">逗号分隔的分区值列表，标识要写入的分区</td>
</tr>
<tr>
  <td>hive.txnsPerBatchAsk</td>
  <td align="center">100</td>
  <td align="right">Hive授予一批事务，而不是像Flume这样的流客户端的单个事务</td>
</tr>
<tr>
  <td>heartBeatInterval</td>
  <td align="center">240</td>
  <td align="right">心跳间隔，防止hive的事物过期，将此值设置为0以禁用心跳。秒为单位</td>
</tr>
<tr>
  <td>autoCreatePartitions</td>
  <td align="center">true</td>
  <td align="right">是否开启自动创建分区</td>
</tr>
<tr>
  <td>batchSize</td>
  <td align="center">15000</td>
  <td align="right">一个单独的hive事物一次的批处理的条数</td>
</tr>
<tr>
  <td>maxOpenConnections</td>
  <td align="center">500</td>
  <td align="right">只允许打开这个数目的连接。如果超过这个数字，则关闭最近最少使用的连接。</td>
</tr>
<tr>
  <td>hdfs.callTimeout</td>
  <td align="center">10000</td>
  <td align="right">(以毫秒为单位)Hive &amp; HDFS I/O操作的超时，比如openTxn、write、commit、abort。</td>
</tr>
<tr>
  <td>serializer</td>
  <td align="center">无</td>
  <td align="right">序列化器解根据什么规则解析事件映射到hive表中</td>
</tr>
<tr>
  <td>hdfs.round</td>
  <td align="center">false</td>
  <td align="right">是否时间戳被四舍五入</td>
</tr>
<tr>
  <td>hdfs.roundValue</td>
  <td align="center">1</td>
  <td align="right">四舍五入到最高倍数(在使用hdfs.roundUnit配置的单元中)，小于当前时间</td>
</tr>
<tr>
  <td>hdfs.roundUnit</td>
  <td align="center">second</td>
  <td align="right">事件四舍五入的最小单位- second, minute or hour.</td>
</tr>
<tr>
  <td>hdfs.timeZone</td>
  <td align="center">Local Time</td>
  <td align="right">用于解析目录路径的时区的名称，例如America/Los_Angeles。</td>
</tr>
<tr>
  <td>hdfs.useLocalTimeStamp</td>
  <td align="center">false</td>
  <td align="right">在替换转义序列时，使用本地时间(而不是事件头部的时间戳)。</td>
</tr>
</tbody></table>
</li>
<li><p>Hbase Sinks：将数据写到Hbase中</p>

<ol><li><p>HBase Sink</p>

<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = hbase  <span class="hljs-preprocessor">#sink类型 ，必须为hbase</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.table</span> = foo_table  <span class="hljs-preprocessor">#Hbase的表名</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.columnFamily</span> = bar_cf  <span class="hljs-preprocessor">#Hbase列簇</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.serializer</span> = org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.flume</span><span class="hljs-preprocessor">.sink</span><span class="hljs-preprocessor">.hbase</span><span class="hljs-preprocessor">.RegexHbaseEventSerializer</span>  <span class="hljs-preprocessor">#序列化解析器解析事件映射成Bhase中的字段</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1</code></pre>

<table>
<thead>
<tr>
  <th>属性名</th>
  <th align="center">默认值</th>
  <th align="right">属性名解释</th>
</tr>
</thead>
<tbody><tr>
  <td><strong>channels</strong></td>
  <td align="center">无</td>
  <td align="right">连接channel</td>
</tr>
<tr>
  <td><strong>type</strong></td>
  <td align="center">无</td>
  <td align="right">该组件的类型名称，必须是hbase</td>
</tr>
<tr>
  <td><strong>table</strong></td>
  <td align="center">无</td>
  <td align="right">指定将需要虚入数据的hbase的表</td>
</tr>
<tr>
  <td>columnFamily</td>
  <td align="center">无</td>
  <td align="right">指定数据写入的列簇</td>
</tr>
<tr>
  <td>zookeeperQuorum</td>
  <td align="center">无</td>
  <td align="right">指定zookeeper的链接地址，需要跟hbase.site.xml里的值一致</td>
</tr>
<tr>
  <td>znodeParent</td>
  <td align="center">/hbase</td>
  <td align="right">Hbase数据存储的根路径，跟hbase.site.xml里的值一致</td>
</tr>
<tr>
  <td>batchSize</td>
  <td align="center">100</td>
  <td align="right">一次写入的条数</td>
</tr>
<tr>
  <td>coalesceIncrements</td>
  <td align="center">false</td>
  <td align="right">如果sink合并多个增量到一个Cell中，如果多个增量合并到一个限定数量的cell中，那么就会有更好的性能</td>
</tr>
<tr>
  <td>serializer</td>
  <td align="center">org.apache.flume.sink.hbase.SimpleHbaseEventSerializer</td>
  <td align="right">Default increment column = “iCol”, payload column = “pCol”.</td>
</tr>
<tr>
  <td>serializer.*</td>
  <td align="center">无</td>
  <td align="right">要传递给序列化器的属性。</td>
</tr>
<tr>
  <td>kerberosPrincipal</td>
  <td align="center">无</td>
  <td align="right">用于访问安全HBase的Kerberos用户</td>
</tr>
<tr>
  <td>kerberosKeytab</td>
  <td align="center">无</td>
  <td align="right">用于访问安全HBase的Kerberos keytab</td>
</tr>
</tbody></table>
</li>
<li><p>AsyncHBaseSink：异步写入数据到Hbase中的sink</p>

<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = asynchbase <span class="hljs-preprocessor">#指定异步类型</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.table</span> = foo_table 
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.columnFamily</span> = bar_cf
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.serializer</span> = org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.flume</span><span class="hljs-preprocessor">.sink</span><span class="hljs-preprocessor">.hbase</span><span class="hljs-preprocessor">.SimpleAsyncHbaseEventSerializer</span>  <span class="hljs-preprocessor">#异步序列化器</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1</code></pre>

<table>
<thead>
<tr>
  <th>属性名</th>
  <th align="center">默认值</th>
  <th align="right">属性名解释</th>
</tr>
</thead>
<tbody><tr>
  <td><strong>channels</strong></td>
  <td align="center">无</td>
  <td align="right">连接channel</td>
</tr>
<tr>
  <td><strong>type</strong></td>
  <td align="center">无</td>
  <td align="right">该组件的类型名称，必须是hbase</td>
</tr>
<tr>
  <td><strong>table</strong></td>
  <td align="center">无</td>
  <td align="right">指定将需要虚入数据的hbase的表</td>
</tr>
<tr>
  <td>columnFamily</td>
  <td align="center">无</td>
  <td align="right">指定数据写入的列簇</td>
</tr>
<tr>
  <td>zookeeperQuorum</td>
  <td align="center">无</td>
  <td align="right">指定zookeeper的链接地址，需要跟hbase.site.xml里的值一致</td>
</tr>
<tr>
  <td>znodeParent</td>
  <td align="center">/hbase</td>
  <td align="right">Hbase数据存储的根路径，跟hbase.site.xml里的值一致</td>
</tr>
<tr>
  <td>batchSize</td>
  <td align="center">100</td>
  <td align="right">一次写入的条数</td>
</tr>
<tr>
  <td>timeout</td>
  <td align="center">60000</td>
  <td align="right"></td>
</tr>
<tr>
  <td>coalesceIncrements</td>
  <td align="center">false</td>
  <td align="right">如果sink合并多个增量到一个Cell中，如果多个增量合并到一个限定数量的cell中，那么就会有更好的性能</td>
</tr>
<tr>
  <td>serializer</td>
  <td align="center">org.apache.flume.sink.hbase.SimpleHbaseEventSerializer</td>
  <td align="right">Default increment column = “iCol”, payload column = “pCol”.</td>
</tr>
<tr>
  <td>serializer.*</td>
  <td align="center">无</td>
  <td align="right">要传递给序列化器的属性。</td>
</tr>
</tbody></table>
</li></ol></li>
<li><p>ElasticSearchSink</p>

<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = elasticsearch  <span class="hljs-preprocessor">#指定sink类型为elasticsearch  </span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hostNames</span> = <span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">9200</span>,<span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.2</span>:<span class="hljs-number">9300</span>  <span class="hljs-preprocessor">#es集群地址</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.indexName</span> = foo_index  <span class="hljs-preprocessor">#索引名</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.indexType</span> = bar_type  <span class="hljs-preprocessor">#索引类型</span>
    a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.clusterName</span> = foobar_cluster   <span class="hljs-preprocessor">#集群的名字</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.batchSize</span> = <span class="hljs-number">500</span>  <span class="hljs-preprocessor">#批处理的大小</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.ttl</span> = <span class="hljs-number">5</span>d  
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.serializer</span> = org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.flume</span><span class="hljs-preprocessor">.sink</span><span class="hljs-preprocessor">.elasticsearch</span><span class="hljs-preprocessor">.ElasticSearchDynamicSerializer</span>  <span class="hljs-preprocessor">#使用的序列化器</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1</code></pre>

<table>
<thead>
<tr>
  <th>属性名</th>
  <th align="center">默认值</th>
  <th align="right">属性名解释</th>
</tr>
</thead>
<tbody><tr>
  <td><strong>channels</strong></td>
  <td align="center">无</td>
  <td align="right">连接channel</td>
</tr>
<tr>
  <td><strong>type</strong></td>
  <td align="center">无</td>
  <td align="right">该组件的类型名称，必须是elasticsearch</td>
</tr>
<tr>
  <td><strong>indexName</strong></td>
  <td align="center">flume</td>
  <td align="right">索引名称，默认是flume</td>
</tr>
<tr>
  <td>indexType</td>
  <td align="center">logs</td>
  <td align="right">索引类型，默认是logs</td>
</tr>
<tr>
  <td>clusterName</td>
  <td align="center">elasticsearch</td>
  <td align="right">集群的名称，默认是elasticsearch</td>
</tr>
<tr>
  <td>batchSize</td>
  <td align="center">100</td>
  <td align="right">批处理的大小</td>
</tr>
<tr>
  <td>ttl</td>
  <td align="center">无</td>
  <td align="right">设置过期时间以后文档将会删除，ms(毫秒)，s(秒)，m(分钟)，h(小时)，d(天)和w(周)</td>
</tr>
<tr>
  <td>serializer</td>
  <td align="center">org.apache.flume.sink.hbase.SimpleHbaseEventSerializer</td>
  <td align="right">Default increment column = “iCol”, payload column = “pCol”.</td>
</tr>
<tr>
  <td>serializer.*</td>
  <td align="center">无</td>
  <td align="right">要传递给序列化器的属性。</td>
</tr>
</tbody></table>
</li></ol></li>
<li><p>Channel，红框内的比较常用 <br>
<img src="https://img-blog.csdn.net/20180531223434512?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1dWJ5eQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<ol><li><p>Memory Channel：事件存储在内存当中</p>

<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = memory  <span class="hljs-preprocessor">#指定channel的类型为内存</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.capacity</span> = <span class="hljs-number">10000</span>  <span class="hljs-preprocessor">#存储事件的最大数量</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.transactionCapacity</span> = <span class="hljs-number">10000</span>  <span class="hljs-preprocessor">#接受的最大数量</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.byteCapacityBufferPercentage</span> = <span class="hljs-number">20</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.byteCapacity</span> = <span class="hljs-number">800000</span></code></pre>

<table>
<thead>
<tr>
  <th>属性名</th>
  <th align="center">默认值</th>
  <th align="right">属性名解释</th>
</tr>
</thead>
<tbody><tr>
  <td><strong>channels</strong></td>
  <td align="center">无</td>
  <td align="right">连接channel</td>
</tr>
<tr>
  <td><strong>type</strong></td>
  <td align="center">无</td>
  <td align="right">该组件的类型名称，必须是memory</td>
</tr>
<tr>
  <td>capacity</td>
  <td align="center">100</td>
  <td align="right">存储在channel中的最大事件数</td>
</tr>
<tr>
  <td>transactionCapacity</td>
  <td align="center">100</td>
  <td align="right">接受最大的事件数</td>
</tr>
<tr>
  <td>keep-alive</td>
  <td align="center">3</td>
  <td align="right">增加或者删除一个事件的超时时间</td>
</tr>
</tbody></table>
</li>
<li><p>JDBC Channel：channel数据存储在数据库中</p>

<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = jdbc</code></pre>

<table>
<thead>
<tr>
  <th>属性名</th>
  <th align="center">默认值</th>
  <th align="right">属性名解释</th>
</tr>
</thead>
<tbody><tr>
  <td>type</td>
  <td align="center">无</td>
  <td align="right">该组件的类型名称，必须是jdbc</td>
</tr>
<tr>
  <td>db.type</td>
  <td align="center">DERBY</td>
  <td align="right">数据库类型</td>
</tr>
<tr>
  <td>driver.class</td>
  <td align="center">org.apache.derby.jdbc.EmbeddedDriver</td>
  <td align="right">jdbc驱动</td>
</tr>
<tr>
  <td>driver.url</td>
  <td align="center">(constructed from other properties)</td>
  <td align="right">jdbc连接url</td>
</tr>
<tr>
  <td>db.username</td>
  <td align="center">“sa”</td>
  <td align="right">用户名</td>
</tr>
<tr>
  <td>db.password</td>
  <td align="center">–</td>
  <td align="right">用户密码</td>
</tr>
<tr>
  <td>connection.properties.file</td>
  <td align="center">–</td>
  <td align="right">jdbc连接属性文件的路径</td>
</tr>
<tr>
  <td>create.schema</td>
  <td align="center">true</td>
  <td align="right">(如果为真)，则创建db模式(如果不为真不创建)</td>
</tr>
<tr>
  <td>create.index</td>
  <td align="center">true</td>
  <td align="right">创建索引加快查找速度</td>
</tr>
<tr>
  <td>create.foreignkey</td>
  <td align="center">true</td>
  <td align="right"></td>
</tr>
<tr>
  <td>transaction.isolation</td>
  <td align="center">“READ_COMMITTED”</td>
  <td align="right">I数据隔离级别 READ_UNCOMMITTED, READ_COMMITTED, SERIALIZABLE, REPEATABLE_READ</td>
</tr>
<tr>
  <td>maximum.connections</td>
  <td align="center">10</td>
  <td align="right">最大连接数</td>
</tr>
<tr>
  <td>maximum.capacity</td>
  <td align="center">0 (unlimited)</td>
  <td align="right">channel中最大的事件数</td>
</tr>
<tr>
  <td>sysprop.*</td>
  <td align="center">DB Vendor specific properties</td>
  <td align="right"></td>
</tr>
<tr>
  <td>sysprop.user.home</td>
  <td align="center">Home路径来存储嵌入式Derby数据库</td>
  <td align="right"></td>
</tr>
</tbody></table>
</li></ol></li>
</ol>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>