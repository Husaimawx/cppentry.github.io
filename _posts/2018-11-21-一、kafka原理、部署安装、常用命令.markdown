---
layout:     post
title:      一、kafka原理、部署安装、常用命令
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <ul><li>kafka的基本原理</li><li>kafka的安装部署</li><li>kafka的常用命令</li></ul><p>一、Kafka基本原理</p><p></p><p><strong><span style="color:#ff4c41;">Kafka架构</span></strong></p><p>它的架构包括以下组件：</p><ul class="list-paddingleft-2" style="list-style-type:disc;"><li><ul class="list-paddingleft-2"><li><p><span style="color:#404040;"><strong>Broker</strong>：Kafka节点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。</span></p></li><li><p><span style="color:#404040;"><strong>Topic</strong>：一类消息，消息存放的目录即主题，例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发。</span></p></li><li><p><span style="color:#404040;"><strong>Partition</strong>：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列</span></p></li><li><p><span style="color:#404040;"><strong>Segment</strong>：partition物理上由多个segment组成，每个Segment存着message信息</span></p></li><li><p><span style="color:#404040;"><strong>Producer</strong> : 生产message发送到topic</span></p></li><li><p><span style="color:#404040;"><strong>Consumer</strong> : 订阅topic消费message, consumer作为一个线程来消费</span></p></li><li><p><span style="color:#404040;"><strong>Consumer Group</strong>：一个</span>Consumer Group包含多个consumer, 这个是预先在配置文件中配置好的。各个consumer（consumer 线程）可以组成一个组（Consumer group ），partition中的每个message只能被组（Consumer group ） 中的一个consumer（consumer 线程 ）消费，如果一个message可以被多个consumer（consumer 线程 ） 消费的话，那么这些consumer必须在不同的组。Kafka不支持一个partition中的message由两个或两个以上的consumer thread来处理，即便是来自不同的consumer group的也不行。它不能像AMQ那样可以多个BET作为consumer去处理message，这是因为多个BET去消费一个Queue中的数据的时候，由于要保证不能多个线程拿同一条message，所以就需要行级别悲观所（for update）,这就导致了consume的性能下降，吞吐量不够。而kafka为了保证吞吐量，只允许一个consumer线程去访问一个partition。如果觉得效率不高的时候，可以加partition的数量来横向扩展，那么再加新的consumer thread去消费。这样没有锁竞争，充分发挥了横向的扩展性，吞吐量极高。这也就形成了分布式消费的概念。</p></li></ul></li></ul><img src="https://img-blog.csdn.net/20180228104408376?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaGFubnVvdGF5b3V4aQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><p><strong><span style="color:#ff4c41;">Kafka存储策略</span></strong></p><p>1）kafka以topic来进行消息管理，每个topic包含多个partition，每个partition对应一个逻辑log，有多个segment组成。</p><p>2）每个segment中存储多条消息（见下图），消息id由其逻辑位置决定，即从消息id可直接定位到消息的存储位置，避免id到位置的额外映射。</p><p>3）每个part在内存中对应一个index，记录每个segment中的第一条消息偏移。</p><p>4）发布者发到某个topic的消息会被均匀的分布到多个partition上（或根据用户指定的路由规则进行分布），broker收到发布消息往对应partition的最后一个segment上添加该消息，当某个segment上的消息条数达到配置值或消息发布时间超过阈值时，segment上的消息会被flush到磁盘，只有flush到磁盘上的消息订阅者才能订阅到，segment达到一定的大小后将不会再往该segment写数据，broker会创建新的segment。</p><p><img src="http://mmbiz.qpic.cn/mmbiz_png/eZzl4LXykQxiagbdcsT0u3aY9YcQGaehRG91n4VMmA349m26sAayMuXftcAmwl2V7RFPXxXducJaAoH7uOY9mUg/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p><p><br></p><p><strong><span style="color:#ff4c41;">Kafka删除策略</span></strong></p><p>1）N天前的删除。</p><p>2）保留最近的MGB数据。</p><p><span style="font-size:14px;color:#FF6666;"><span><strong>Topic &amp; Partition</strong></span></span><br></p><p></p><p><span style="font-size:14px;"><span style="color:#404040;">- <strong>Topic &amp; Partition：</strong>Topic相当于传统消息系统MQ中的一个队列queue，producer端发送的message必须指定是发送到哪个topic，但是不需要指定topic下的哪个partition，因为kafka会把收到的message进行load balance，均匀的分布在这个topic下的不同的partition上（ hash(message) % [broker数量]  ）。物理上存储上，这个topic会分成一个或多个partition，每个partiton相当于是一个子queue。在物理结构上，每个partition对应一个物理的目录（文件夹），文件夹命名是[topicname]_[partition]_[序号]，一个topic可以有无数多的partition，根据业务需求和数据量来设置。在kafka配置文件中可随时更高num.partitions参数来配置更改topic的partition数量，在</span></span><span style="font-size:14px;"><span style="color:#404040;">创建Topic时通过参数指定parittion数量。</span></span><span style="font-size:14px;"><span style="color:#404040;">Topic创建之后通过Kafka提供的工具也可以修改partiton数量。</span></span></p><p><span style="font-size:14px;"><span style="color:#404040;">   一般来说，（1）一个Topic的Partition数量大于等于Broker的数量，</span></span><span style="font-size:14px;"><span style="color:#404040;">可以提高吞吐率。（2）同一个Partition的Replica尽量分散到不同的机器，</span></span><span style="font-size:14px;"><span style="color:#404040;">高可用。</span></span></p><p><span style="font-size:14px;"><span style="color:#404040;">  <strong>当add a new partition的时候</strong>，partition里面的message不会重新进行分配，原来的partition里面的message数据不会变，新加的这个partition刚开始是空的，随后进入这个topic的message就会重新参与所有partition的load balance</span></span></p><p><span style="font-size:14px;color:#FF6666;"><strong>Partition Replica</strong></span></p><p><span style="font-size:14px;"><span style="color:#404040;">    每个partition可以在其他的kafka broker节点上存副本，以便某个kafka broker节点宕机不会影响这个kafka集群。存replica副本的方式是按照kafka broker的顺序存。例如有5个kafka broker节点，某个topic有3个partition，每个partition存2个副本，那么partition1存broker1,broker2，partition2存broker2,broker3。。。以此类推<strong>（replica副本数目不能大于kafka broker节点的数目，否则报错。这里的replica数其实就是partition的副本总数，其中包括一个leader，其他的就是copy副本）</strong>。这样如果某个broker宕机，其实整个kafka内数据依然是完整的。但是，replica副本数越高，系统虽然越稳定，但是回来带资源和性能上的下降；replica副本少的话，也会造成系统丢数据的风险。</span></span></p><p><span style="font-size:14px;"><span style="color:#404040;">  （1）怎样传送消息：producer先把message发送到partition leader，再由leader发送给其他partition follower。（如果让producer发送给每个replica那就太慢了）</span></span></p><p><span style="font-size:14px;"><span style="color:#404040;">  （2）</span></span><span style="font-size:14px;"><span style="color:#404040;">在向Producer发送ACK前需要保证有多少个Replica已经收到该消息：根据ack配的个数而定</span></span></p><p><span style="font-size:14px;"><span style="color:#404040;">  （3）</span></span><span style="font-size:14px;"><span style="color:#404040;">怎样处理某个Replica不工作的情况：如果这个部工作的partition replica不在ack列表中，就是producer在发送消息到partition leader上，partition leader向partition follower发送message没有响应而已，这个不会影响整个系统，也不会有什么问题。如果这个不工作的partition replica在ack列表中的话，producer发送的message的时候会等待这个不工作的partition replca写message成功，但是会等到time out，然后返回失败因为某个ack列表中的partition replica没有响应，此时kafka会自动的把这个部工作的partition replica从ack列表中移除，以后的producer发送message的时候就不会有这个ack列表下的这个部工作的partition replica了。 </span></span></p><p><span style="font-size:14px;"><span style="color:#404040;">  （4）</span></span><span style="font-size:14px;"><span style="color:#404040;">怎样处理Failed Replica恢复回来的情况：如果这个partition replica之前不在ack列表中，那么启动后重新受Zookeeper管理即可，之后producer发送message的时候，partition leader会继续发送message到这个partition follower上。如果这个</span></span><span style="font-size:14px;"><span style="color:#404040;">partition replica之前在ack列表中，此时重启后，需要把这个partition replica再手动加到ack列表中。（ack列表是手动添加的，出现某个部工作的partition replica的时候自动从ack列表中移除的）</span></span></p><p><span style="font-size:14px;"><span style="color:#404040;">- <strong>Partition leader与follower：</strong>partition也有leader和follower之分。leader是主partition，producer写kafka的时候先写partition leader，再由partition leader push给其他的partition follower。partition leader与follower的信息受Zookeeper控制，一旦partition leader所在的broker节点宕机，zookeeper会冲其他的broker的partition follower上选择follower变为parition leader。</span></span></p><p style="font-size:14px;"><span style="font-size:14px;color:#FF6666;">Kafka集群partition replication默认自动分配分析</span></p><p style="font-size:14px;">下面以一个Kafka集群中4个Broker举例，创建1个topic包含4个Partition，2 Replication；数据Producer流动如图所示：</p><p style="font-size:14px;">(1)</p><p style="font-size:14px;"><img style="border-width:0px;vertical-align:middle;" src="http://mmbiz.qpic.cn/mmbiz_png/tHmoDNCQLzWzwCibUKAIJGW6vVCwRVJCibMbrbHZmZ8ichs3JfsPPUP9QggRvCBrN7sicl6fPIHVXImeo0ibsxCV0ZA/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1" alt=""><br></p><p style="font-size:14px;"><span style="font-size:12px;"><br></span></p><p style="font-size:14px;"><br></p><p style="font-size:14px;">(2)当集群中新增2节点，Partition增加到6个时分布情况如下：</p><p style="font-size:14px;"><img style="border-width:0px;vertical-align:middle;" src="http://mmbiz.qpic.cn/mmbiz_png/tHmoDNCQLzWzwCibUKAIJGW6vVCwRVJCibf7qvIlqTyxCmZOdvQBibaNwoFdNaQUf530ib9u0tf8LCXEq9yA4Euxfg/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1" alt=""><br></p><p style="font-size:14px;"><br></p><p style="font-size:14px;"><span style="font-size:14px;color:#FF6666;">副本分配逻辑规则如下：</span></p><ul class="list-paddingleft-2"><li><p><span style="font-size:14px;">在Kafka集群中，每个Broker都有均等分配Partition的Leader机会。</span></p></li><li><p><span style="font-size:14px;">上述图Broker Partition中，箭头指向为副本，以Partition-0为例:broker1中parition-0为Leader，Broker2中Partition-0为副本。</span></p></li><li><p><span style="font-size:14px;">上述图种每个Broker(按照BrokerId有序)依次分配主Partition,下一个Broker为副本，如此循环迭代分配，多副本都遵循此规则。</span></p></li></ul><p><span style="font-size:14px;color:#FF6666;">副本分配算法如下：</span></p><ul class="list-paddingleft-2"><li><p><span style="font-size:14px;">将所有N Broker和待分配的i个Partition排序.</span></p></li><li><p><span style="font-size:14px;">将第i个Partition分配到第(i mod n)个Broker上.</span></p></li><li><p><span style="font-size:14px;">将第i个Partition的第j个副本分配到第((i + j) mod n)个Broker上.</span></p></li></ul><br><p><span style="font-size:14px;"><span style="color:#404040;"><span style="color:#FF6666;"><strong>Partition ack：</strong></span><br></span></span></p><p><span style="font-size:14px;"><span style="color:#404040;">当ack=1，表示producer写partition leader成功后，broker就返回成功，无论其他的partition follower是否写成功。</span></span></p><p><span style="font-size:14px;"><span style="color:#404040;">当ack=2，表示producer写partition leader和其他一个follower成功的时候，</span></span><span style="font-size:14px;"><span style="color:#404040;">broker就返回成功，无论其他的partition follower是否写成功。</span></span></p><p><span style="font-size:14px;"><span style="color:#404040;">当ack=-1</span></span><span style="font-size:14px;"><span style="color:#404040;">[parition的数量]的时候，表示只有producer全部写成功的时候，才算成功，kafka broker才返回成功信息。</span></span></p><p><span style="font-size:14px;"><span style="color:#404040;"></span></span></p><p><span style="color:#FF6666;">Consumer与Partition的关系：</span></p><p><span style="color:#3e3e3e;">- 如果consumer比partition多，是浪费，因为kafka的设计是在一个partition上是不允许并发的，所以consumer数不要大于partition数</span></p><p><span><span style="color:#3e3e3e;">- 如果consumer比partition少，一个consumer会对应于多个partitions，这里主要合理分配consumer数和partition数，否则会导致partition里面的数据被取的不均匀</span></span></p><p><span><span style="color:#3e3e3e;">- 如果consumer从多个partition读到数据，不保证数据间的顺序性，kafka只保证在一个partition上数据是有序的，但多个partition，根据你读的顺序会有不同</span></span></p><p><span><span style="color:#3e3e3e;">- 增减consumer，broker，partition会导致rebalance，所以rebalance后consumer对应的partition会发生变化</span></span></p><p><span><span style="color:#3e3e3e;">- High-level接口中获取不到数据的时候是会block的</span></span></p><p><span><span style="color:#3e3e3e;">负载低的情况下可以每个线程消费多个partition。但负载高的情况下，Consumer 线程数最好和Partition数量保持一致。如果还是消费不过来，应该再开 Consumer 进程，进程内线程数同样和分区数一致。</span></span></p><p><span style="font-size:14px;"><span style="color:#404040;"><span style="color:#FF6666;">kafka文件存储</span></span></span></p><p><span style="font-size:14px;"><span style="color:#404040;"><span style="color:#FF6666;"></span></span></span></p><p>假设实验环境中Kafka集群只有一个broker，xxx/message-folder为数据文件存储根目录，在Kafka broker中server.properties文件配置(参数log.dirs=xxx/message-folder)，例如创建2个topic名 称分别为report_push、launch_info, partitions数量都为partitions=4</p><p>存储路径和目录规则为：</p><p>xxx/message-folder</p><p>  |--report_push-0<br>  |--report_push-1<br>  |--report_push-2<br>  |--report_push-3<br>  |--launch_info-0<br>  |--launch_info-1<br>  |--launch_info-2<br>  |--launch_info-3<br></p><p>在Kafka文件存储中，同一个topic下有多个不同partition，每个partition为一个目录，partiton命名规则为<span style="color:#33CC00;">topic名称+有序序号</span>，第一个partiton序号从0开始，序号最大值为partitions数量减1。</p><p><span style="font-size:14px;"><span style="color:#404040;"><span style="color:#FF6666;"><span style="color:#464646;"><span style="font-size:15px;">消息发送时都被发送到一个topic，其本质就是一个目录，而topic由是由一些Partition组成,其组织结构</span></span></span></span></span></p><p><span style="font-size:14px;"><span style="color:#404040;"><span style="color:#FF6666;"><span style="color:#464646;"><span style="font-size:15px;"><span style="color:#464646;"><span style="font-size:15px;">Kafka集群会保存所有的消息，不管消息有没有被消费；<span style="color:#33CC00;"><strong>我们可以设定消息的过期时间，只有过期的数据才会被自动清除以释放磁盘空间。</strong></span>比如我们设置消息过期时间为2天，那么这2天内的所有消息都会被保存到集群中，数据只有超过了两天才会被清除。</span></span><br></span></span></span></span></span></p><p></p><p><span style="font-size:14px;"><span style="color:#404040;"><span style="color:#FF6666;">partiton中文件存储方式</span></span></span></p><ul style="margin-left:15px;" class="list-paddingleft-2"><li><p>每个partion(目录)相当于一个巨型文件被平均分配到多个大小相等segment(段)数据文件中。但每个段segment file消息数量不一定相等，这种特性方便old segment file快速被删除。</p></li><li><p>每个partiton只需要支持顺序读写就行了，segment文件生命周期由服务端配置参数决定。</p></li></ul><span style="color:#FF6666;">partiton中segment文件存储结构</span><p><span>producer发message到某个topic，message会被均匀的分布到多个partition上（随机或根据用户指定的回调函数进行分布），kafka broker收到message往对应partition的最后一个segment上添加该消息，当某个segment上的消息条数达到配置值或消息发布时间超过阈值时，segment上的消息会被flush到磁盘，只有flush到磁盘上的消息consumer才能消费，segment达到一定的大小后将不<span style="font-size:16px;"><span style="font-size:14px;">会再往该</span>se</span>gment写数据，broker会创建新的segment。</span></p><p><span>每个part在内存中对应一个index，记录每个segment中的第一条消息偏移。</span></p><ul style="margin-left:15px;" class="list-paddingleft-2"><li><p><span>segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀".index"和“.log”分别表示为segment索引文件、数据文件.</span></p></li><li><p><span>segment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个全局partion的最大offset(偏移message数)。数值最大为64位long大小，19位数字字符长度，没有数字用0填充。</span></p></li></ul><p></p><p><span>下面文件列表是笔者在Kafka broker上做的一个实验，创建一个topicXXX包含1 partition，设置每个segment大小为500MB,并启动producer向Kafka broker写入大量数据,如下图2所示segment文件列表形象说明了上述2个规则：</span></p><img style="border-width:0px;vertical-align:middle;" src="http://mmbiz.qpic.cn/mmbiz_png/tHmoDNCQLzWzwCibUKAIJGW6vVCwRVJCibjIkDnwZdQRYMrnflA4a6ESCmibibePcqCBhVzLOoValBECfNicjvgtpMA/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1" alt=""><p>以上述图2中一对segment file文件为例，说明segment中index&lt;—-&gt;data file对应关系物理结构如下：</p><p><span style="font-size:14px;"><span style="color:#404040;"><img style="border-width:0px;vertical-align:middle;" src="http://mmbiz.qpic.cn/mmbiz_png/tHmoDNCQLzWzwCibUKAIJGW6vVCwRVJCibkAgnIaW5QtGiaLrzc9W05smWnbRmGeicIkrd6NVXQd2YMUC74SkbhIlg/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1" alt=""><br></span></span></p><p><span style="color:#FF6666;">在partition中如何通过offset查找message</span></p><p style="color:rgb(64,64,64);font-size:14px;">例如读取offset=368776的message，需要通过下面2个步骤查找。</p><ul style="margin-left:15px;" class="list-paddingleft-2"><li><p>第一步查找segment file</p><p>上述图2为例，其中00000000000000000000.index表示最开始的文件，起始偏移量(offset)为0.第二个文件 00000000000000368769.index的消息量起始偏移量为368770 = 368769 + 1.同样，第三个文件00000000000000737337.index的起始偏移量为737338=737337 + 1，其他后续文件依次类推，以起始偏移量命名并排序这些文件，只要根据offset **二分查找**文件列表，就可以快速定位到具体文件。</p><p>当offset=368776时定位到00000000000000368769.index|log</p></li><li><p>第二步通过segment file查找message通过第一步定位到segment file，当offset=368776时，依次定位到00000000000000368769.index的元数据物理位置和 00000000000000368769.log的物理偏移地址，然后再通过00000000000000368769.log顺序查找直到 offset=368776为止。</p></li></ul><span style="font-size:14px;color:#FF6666;"><span style="font-size:23px;">Kafka 与 Zookeeper</span></span><p><span style="font-size:19px;"><span><span xml:lang="en-us" lang="en-us" style="font-family:'宋体';color:#000000;"><span style="font-size:16px;"><span> </span></span>1、Zookeeper </span><span style="font-family:'宋体';color:#000000;">协调控制</span></span></span></p><ul><li><span style="color:rgb(70,70,70);"><span><span style="font-size:12pt;" xml:lang="en-us" lang="en-us"><span></span></span><span style="font-size:12pt;">管理<span xml:lang="en-us" lang="en-us">broker</span>与<span xml:lang="en-us" lang="en-us">consumer</span></span></span><span><span style="font-size:12pt;">的动态加入与离开。(Producer不需要管理，随便一台计算机都可以作为Producer向Kakfa Broker发消息)</span></span></span></li><li><span style="color:rgb(70,70,70);"><span><span style="font-size:12pt;" xml:lang="en-us" lang="en-us"><span><span></span></span></span><span style="font-size:12pt;">触发负载均衡，当<span xml:lang="en-us" lang="en-us">broker</span>或<span xml:lang="en-us" lang="en-us">consumer</span>加入或离开时会触发负载均衡算法，使得一个<span xml:lang="en-us" lang="en-us">consumer group</span>内的多个<span xml:lang="en-us" lang="en-us">consumer</span></span></span><span><span style="font-size:12pt;">的消费负载平衡。（因为一个comsumer消费一个或多个partition，一个partition只能被一个consumer消费）</span></span></span></li><li><span style="color:rgb(70,70,70);"><span><span style="font-size:12pt;" xml:lang="en-us" lang="en-us"><span><span></span></span></span><span style="font-size:12pt;">维护消费关系及每个<span xml:lang="en-us" lang="en-us">partition</span>的消费信息。</span></span></span></li></ul><img src="https://img-blog.csdn.net/20180228135709584?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaGFubnVvdGF5b3V4aQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><p></p><p></p><p style="text-align:left;color:rgb(102,102,102);font-family:'宋体', Arial;"><span style="font-size:19px;"><span><span xml:lang="en-us" lang="en-us" style="font-family:'宋体';color:#000000;">2 Zookeeper</span><span style="font-family:'宋体';color:#000000;">上的细节：</span></span></span></p><ul><li><span style="color:rgb(70,70,70);"><span style="font-size:12pt;" xml:lang="en-us" lang="en-us"><span><span></span></span></span><span style="font-size:12pt;">每个<span xml:lang="en-us" lang="en-us">broker</span>启动后会在<span xml:lang="en-us" lang="en-us">zookeeper</span>上注册一个临时的<span xml:lang="en-us" lang="en-us">broker registry</span>，包含<span xml:lang="en-us" lang="en-us">broker</span>的<span xml:lang="en-us" lang="en-us">ip</span>地址和端口号，所存储的<span xml:lang="en-us" lang="en-us">topics</span>和<span xml:lang="en-us" lang="en-us">partitions</span>信息。</span></span></li><li><span style="color:rgb(70,70,70);"><span style="font-size:12pt;" xml:lang="en-us" lang="en-us"><span><span></span></span></span><span style="font-size:12pt;">每个<span xml:lang="en-us" lang="en-us">consumer</span>启动后会在<span xml:lang="en-us" lang="en-us">zookeeper</span>上注册一个临时的<span xml:lang="en-us" lang="en-us">consumer registry</span>：包含<span xml:lang="en-us" lang="en-us">consumer</span>所属的<span xml:lang="en-us" lang="en-us">consumer group</span>以及订阅的<span xml:lang="en-us" lang="en-us">topics</span>。</span></span></li><li><span style="color:rgb(70,70,70);"><span style="font-size:12pt;" xml:lang="en-us" lang="en-us"><span><span></span></span></span><span style="font-size:12pt;">每个<span xml:lang="en-us" lang="en-us">consumer group</span>关联一个临时的<span xml:lang="en-us" lang="en-us">owner registry</span>和一个持久的<span xml:lang="en-us" lang="en-us">offset registry</span>。对于被订阅的每个<span xml:lang="en-us" lang="en-us">partition</span>包含一个<span xml:lang="en-us" lang="en-us">owner registry</span>，内容为订阅这个<span xml:lang="en-us" lang="en-us">partition</span>的<span xml:lang="en-us" lang="en-us">consumer id</span>；同时包含一个<span xml:lang="en-us" lang="en-us">offset registry</span>，内容为上一次订阅的<span xml:lang="en-us" lang="en-us">offset</span>。</span></span></li></ul><p><br><span style="font-size:14px;"><span style="color:#404040;"></span></span></p><p></p><p><span style="font-size:14px;"><span style="color:#404040;"><br></span></span></p><p><span style="font-size:14px;"><span style="color:#404040;"><br></span></span></p><p><span style="font-size:14px;"><span style="color:#404040;"></span></span><br></p><br>            </div>
                </div>