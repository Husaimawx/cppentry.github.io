---
layout:     post
title:      hadoop2.7.1下的单词统计
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<span></span>
<div style="text-align:center;"><span><strong><span style="font-size:32px;">hadoop2.7.1下的单词统计</span><span><span style="font-size:16px;">(hadoop自带jar包)</span></span></strong></span></div>
<hr><div style="text-align:right;"><span style="font-size:21px;"><span><strong>注意：（本文的路径有点长，要注意对应的路径）</strong></span></span></div>
<div style="text-align:justify;"><span style="font-size:16px;">1、搭建好了集群式hadoop以后，测试一下小程序，本文测试的是hadoop的Wordcount程序，也就是一个简单的单词统计程序。<span>先启动hadoop</span></span></div>
<div><span style="font-size:16px;"><br></span></div>
<div><span style="font-size:16px;">2、hadoop的Wordcount程序是hadoop自带的一个小小的案例，可以在hadoop的解压包里找到这个jar文件其路径是（<span>/usr/local/hadoop/share/hadoop/mapreduce</span>）路径下的<span style="color:#ff7a74;"><span>hadoop-mapreduce-examples-2.7.1.jar</span></span>
  包。</span></div>
<div><span style="font-size:16px;">执行如下命令：</span></div>
<div><span style="font-size:16px;"><br></span></div>
<div>
<div>$ cd /usr/local/hadoop/share/hadoop/mapreduce</div>
<div>$ hadoop jar hadoop-mapreduce-examples-2.7.1.jar</div>
</div>
<div><span style="font-size:16px;"> </span></div>
<div><span style="font-size:16px;">下面直接上图：</span></div>
<div></div>
<div><br></div>
<div><img src="https://img-blog.csdn.net/20170518143934079?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR3JlYXRNaWNoYWVsMDAx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br></div>
<div><img src="https://img-blog.csdn.net/20170518144004361?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR3JlYXRNaWNoYWVsMDAx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br></div>
<div></div>
<div><br></div>
<div><span style="font-size:16px;">从这个截图中可以清晰的看到hadoop-mapreduce-examples-2.7.1.jar文件不只有一个Wordcount一个小案例，还有其他的小案例，但是现在我们是测试一下我们的hadoop到底是怎么运行的，所以就用一个简单的Wordcount程序就OK了。线面按照命令执行就一路畅通</span>：</div>
<div><br></div>
<div><br></div>
<div><span style="font-size:16px;">3、测试看看hadoop-mapreduce-examples-2.7.1.jar Wordcount这里面有什么小东东</span>。</div>
<div><span style="font-size:16px;">执行如下命令： </span></div>
<div>
<div>$ hadoop jar hadoop-mapreduce-examples-2.7.1.jar wordcount</div>
</div>
<div><img src="https://img-blog.csdn.net/20170518144034424?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR3JlYXRNaWNoYWVsMDAx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br></div>
<div></div>
<div><br></div>
<div><span style="font-size:16px;">根据上面显示。说明要我们输入文件和输出，下面我们就要开始输入要测试的单词文本了。</span></div>
<div><span style="font-size:16px;"><br></span></div>
<div><span style="font-size:16px;">4、为了方便使用<span>hadoop-mapreduce-examples-2.7.1.jar</span>文件，在<span>/usr/local/hadoop/share/hadoop/mapreduce</span>目录下创建一个文件</span></div>
<div><span style="font-size:16px;">执行如下命令：</span></div>
<div>
<div>$ mkdir input1</div>
<div>$ cd input1</div>
<div>$ echo "Hello hadoop , I'm xiao ming" &gt; f1.txt</div>
<div>$ echo "Hello world , I'm zhao ming ming" &gt; f2.txt</div>
<div>$ ls</div>
<div>$ cat f1.txt f2.txt</div>
</div>
<div><span style="font-size:16px;"><br></span></div>
<div><span style="font-size:16px;">如图：/</span></div>
<div><span style="font-size:16px;"><img src="https://img-blog.csdn.net/20170518144102534?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR3JlYXRNaWNoYWVsMDAx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br></span></div>
<div></div>
<div><br></div>
<div><span style="font-size:16px;">我的截图有文字有说明，非常清楚，我就不再啰嗦。</span></div>
<div><span style="font-size:16px;"><br></span></div>
<div><span style="font-size:16px;">5、要在HDFS上运行文件，我们也要在HDFS上新建一个文件，这里同样也是创建的名字为input1的文件。以便后以后使用的时候统一，其实命名为什么名字都一样。</span></div>
<div><span style="font-size:16px;">执行如下命令：</span></div>
<div>
<div>$ cd</div>
<div>$ cd /usr/local/hadoop</div>
<div>$ hadoop fs -mkdir /input1</div>
</div>
<div><br></div>
<div><img src="https://img-blog.csdn.net/20170518144125926?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR3JlYXRNaWNoYWVsMDAx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br></div>
<div></div>
<div><br></div>
<div><span style="font-size:16px;">6、目录创建好了以后，把刚才的本地文件（/usr/local/hadoop/share/hadoop/mapreduce/<span style="color:#f14f9a;">input1</span>）传输到HDFS上。执行如下命令：</span></div>
<div>
<div>$ cd /usr/local/hadoop/share/hadoop/mapreduce</div>
<div>$ hadoop fs -put input1/f*.txt /input1</div>
<div>$ hadoop fs -ls /input1</div>
</div>
<div><br></div>
<div></div>
<div><img src="https://img-blog.csdn.net/20170518144158518?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR3JlYXRNaWNoYWVsMDAx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br></div>
<div><br></div>
<div><span style="font-size:16px;">7、运行程序执行如下命令：</span></div>
<div><br></div>
<div>
<div>$ hadoop jar hadoop-mapreduce-examples-2.7.1.jar wordcount /input1/ /output1/</div>
</div>
<div><br></div>
<div><span style="font-size:16px;">下图的map和reduce的进度为100%表示运行处理结束。</span></div>
<div><span style="font-size:16px;"><br></span></div>
<div></div>
<div><img src="https://img-blog.csdn.net/20170518144254022?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR3JlYXRNaWNoYWVsMDAx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br></div>
<div><br></div>
<div><span style="font-size:16px;">8、程序运行完以后，要查看一下单词统计的结果是什么玩意儿，执行如下命令：</span></div>
<div><br></div>
<div>
<div>$ hadoop fs -ls /output1/*</div>
</div>
<div><br></div>
<div><br></div>
<div>
<div>$ hadoop fs -cat /output/*</div>
</div>
<div><br></div>
<div></div>
<div><img src="https://img-blog.csdn.net/20170518144648512?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR3JlYXRNaWNoYWVsMDAx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br></div>
<div><br></div>
<div><span style="font-size:16px;">哈哈，gameover，统计出来的结果如上图所示。</span></div>
<div>在HDFS上运行完以后，想删掉输入输出，执行：</div>
<div><br></div>
<div>
<div>$ hadoop fs -rmr /input1</div>
<div>$ hadoop fs -rmr /output1</div>
</div>
<div><br></div>
<div><br></div>
<div><br></div>
<div><br></div>
<div><br></div>
<div><br></div>
<br>            </div>
                </div>