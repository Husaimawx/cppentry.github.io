---
layout:     post
title:      hadoop集群
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-tomorrow-night">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h2 id="一安装配置hadoop">一.安装配置hadoop</h2>

<p>hadoop基于java环境进行运行，需要安装java</p>

<pre class="prettyprint"><code class=" hljs avrasm">建立hadoop运行用户:
[root@server1 ~]<span class="hljs-preprocessor"># useradd -u 800 hadoop   </span>
[root@server1 ~]<span class="hljs-preprocessor"># id hadoop</span>
uid=<span class="hljs-number">800</span>(hadoop) gid=<span class="hljs-number">800</span>(hadoop) groups=<span class="hljs-number">800</span>(hadoop）
[root@server1 ~]<span class="hljs-preprocessor"># ls</span>
hadoop-<span class="hljs-number">2.7</span><span class="hljs-number">.3</span><span class="hljs-preprocessor">.tar</span><span class="hljs-preprocessor">.gz</span>                       jdk-<span class="hljs-number">7</span>u79-linux-x64<span class="hljs-preprocessor">.tar</span><span class="hljs-preprocessor">.gz</span>
[root@server1 ~]<span class="hljs-preprocessor"># mv hadoop-2.7.3.tar.gz jdk-7u79-linux-x64.tar.gz /home/hadoop/</span>
[root@server1 ~]<span class="hljs-preprocessor"># su - hadoop</span>
解压配置软连接：
[hadoop@server1 ~]$ tar -zxf hadoop-<span class="hljs-number">2.7</span><span class="hljs-number">.3</span><span class="hljs-preprocessor">.tar</span><span class="hljs-preprocessor">.gz</span> 
[hadoop@server1 ~]$ tar -zxf jdk-<span class="hljs-number">7</span>u79-linux-x64<span class="hljs-preprocessor">.tar</span><span class="hljs-preprocessor">.gz</span> 
[hadoop@server1 ~]$ ls
hadoop-<span class="hljs-number">2.7</span><span class="hljs-number">.3</span>  hadoop-<span class="hljs-number">2.7</span><span class="hljs-number">.3</span><span class="hljs-preprocessor">.tar</span><span class="hljs-preprocessor">.gz</span>  jdk1<span class="hljs-number">.7</span><span class="hljs-number">.0</span>_79  jdk-<span class="hljs-number">7</span>u79-linux-x64<span class="hljs-preprocessor">.tar</span><span class="hljs-preprocessor">.gz</span>
[hadoop@server1 ~]$ ln -s jdk1<span class="hljs-number">.7</span><span class="hljs-number">.0</span>_79/ java
[hadoop@server1 ~]$ ln -s hadoop-<span class="hljs-number">2.7</span><span class="hljs-number">.3</span> hadoop
[hadoop@server1 ~]$ ll
total <span class="hljs-number">359004</span>
drwxr-xr-<span class="hljs-built_in">x</span> <span class="hljs-number">9</span> hadoop hadoop      <span class="hljs-number">4096</span> Aug <span class="hljs-number">18</span>  <span class="hljs-number">2016</span> hadoop-<span class="hljs-number">2.7</span><span class="hljs-number">.3</span>
-rw-r--r-- <span class="hljs-number">1</span> root   root   <span class="hljs-number">214092195</span> Mar  <span class="hljs-number">2</span>  <span class="hljs-number">2017</span> hadoop-<span class="hljs-number">2.7</span><span class="hljs-number">.3</span><span class="hljs-preprocessor">.tar</span><span class="hljs-preprocessor">.gz</span>
lrwxrwxrwx <span class="hljs-number">1</span> hadoop hadoop        <span class="hljs-number">12</span> Jul <span class="hljs-number">21</span> <span class="hljs-number">09</span>:<span class="hljs-number">59</span> java -&gt; jdk1<span class="hljs-number">.7</span><span class="hljs-number">.0</span>_79/
drwxr-xr-<span class="hljs-built_in">x</span> <span class="hljs-number">8</span> hadoop hadoop      <span class="hljs-number">4096</span> Apr <span class="hljs-number">11</span>  <span class="hljs-number">2015</span> jdk1<span class="hljs-number">.7</span><span class="hljs-number">.0</span>_79
-rw-r--r-- <span class="hljs-number">1</span> root   root   <span class="hljs-number">153512879</span> Jun <span class="hljs-number">23</span>  <span class="hljs-number">2016</span> jdk-<span class="hljs-number">7</span>u79-linux-x64<span class="hljs-preprocessor">.tar</span><span class="hljs-preprocessor">.gz</span>
编辑java环境,当java更新时更改软连接即可：
[hadoop@server1 ~]$ cd hadoop
[hadoop@server1 hadoop]$ cd etc/hadoop/
[hadoop@server1 hadoop]$ ls
capacity-scheduler<span class="hljs-preprocessor">.xml</span>      httpfs-env<span class="hljs-preprocessor">.sh</span>            mapred-env<span class="hljs-preprocessor">.sh</span>
configuration<span class="hljs-preprocessor">.xsl</span>           httpfs-log4j<span class="hljs-preprocessor">.properties</span>  mapred-queues<span class="hljs-preprocessor">.xml</span><span class="hljs-preprocessor">.template</span>
container-executor<span class="hljs-preprocessor">.cfg</span>      httpfs-signature<span class="hljs-preprocessor">.secret</span>  mapred-site<span class="hljs-preprocessor">.xml</span><span class="hljs-preprocessor">.template</span>
core-site<span class="hljs-preprocessor">.xml</span>               httpfs-site<span class="hljs-preprocessor">.xml</span>          slaves
hadoop-env<span class="hljs-preprocessor">.cmd</span>              kms-acls<span class="hljs-preprocessor">.xml</span>             ssl-client<span class="hljs-preprocessor">.xml</span><span class="hljs-preprocessor">.example</span>
hadoop-env<span class="hljs-preprocessor">.sh</span>               kms-env<span class="hljs-preprocessor">.sh</span>               ssl-server<span class="hljs-preprocessor">.xml</span><span class="hljs-preprocessor">.example</span>
hadoop-metrics2<span class="hljs-preprocessor">.properties</span>  kms-log4j<span class="hljs-preprocessor">.properties</span>     yarn-env<span class="hljs-preprocessor">.cmd</span>
hadoop-metrics<span class="hljs-preprocessor">.properties</span>   kms-site<span class="hljs-preprocessor">.xml</span>             yarn-env<span class="hljs-preprocessor">.sh</span>
hadoop-policy<span class="hljs-preprocessor">.xml</span>           log4j<span class="hljs-preprocessor">.properties</span>         yarn-site<span class="hljs-preprocessor">.xml</span>
hdfs-site<span class="hljs-preprocessor">.xml</span>               mapred-env<span class="hljs-preprocessor">.cmd</span>
[hadoop@server1 hadoop]$ vim hadoop-env<span class="hljs-preprocessor">.sh</span>
 <span class="hljs-number">24</span> <span class="hljs-preprocessor"># The java implementation to use.</span>
 <span class="hljs-number">25</span> export JAVA_HOME=/home/hadoop/java   <span class="hljs-preprocessor">###设置java路径</span>
测试hadoop是否安装成功：
[hadoop@server1 hadoop]$ bin/hadoop <span class="hljs-preprocessor">##只要后面出现命令即可</span>
<span class="hljs-label">Usage:</span> hadoop [--config confdir] [COMMAND | CLASSNAME]
.................................
[hadoop@server1 hadoop]$ mkdir input   <span class="hljs-preprocessor">###建立hadoop目录放置文件目录</span>
[hadoop@server1 hadoop]$ cd input/
[hadoop@server1 input]$ <span class="hljs-keyword">cp</span> ../etc/hadoop<span class="hljs-comment">/* .
[hadoop@server1 input]$ ls
capacity-scheduler.xml      httpfs-env.sh            mapred-env.sh
configuration.xsl           httpfs-log4j.properties  mapred-queues.xml.template
container-executor.cfg      httpfs-signature.secret  mapred-site.xml.template
core-site.xml               httpfs-site.xml          slaves
hadoop-env.cmd              kms-acls.xml             ssl-client.xml.example
hadoop-env.sh               kms-env.sh               ssl-server.xml.example
hadoop-metrics2.properties  kms-log4j.properties     yarn-env.cmd
hadoop-metrics.properties   kms-site.xml             yarn-env.sh
hadoop-policy.xml           log4j.properties         yarn-site.xml
hdfs-site.xml               mapred-env.cmd
[hadoop@server1 hadoop]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar  grep input output 'dfs[a-z.]+'
[hadoop@server1 hadoop]$ cd output/
[hadoop@server1 output]$ ls
part-r-00000  _SUCCESS
[hadoop@server1 output]$ cat *
6   dfs.audit.logger
4   dfs.class
3   dfs.server.namenode.
2   dfs.period
2   dfs.audit.log.maxfilesize
2   dfs.audit.log.maxbackupindex
1   dfsmetrics.log
1   dfsadmin
1   dfs.servers
1   dfs.file</span></code></pre>



<h2 id="二数据操作">二.数据操作</h2>

<p><strong>配置hadoop</strong></p>

<pre class="prettyprint"><code class=" hljs xml">[hadoop@server1 hadoop]$ pwd
/home/hadoop/hadoop/etc/hadoop

[hadoop@server1 hadoop]$ vim core-site.xml ###设置节点
 19 <span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
 20   <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
 21           <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
 22                   <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>hdfs://172.25.60.1:9000<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>   
 23                       <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
 24 
 25 <span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span>

[hadoop@server1 hadoop]$ vim slaves     
172.25.60.1

[hadoop@server1 hadoop]$ vim hdfs-site.xml  
 19 <span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
 20   <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
 21           <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
 22                   <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
 23                       <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
 24 <span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>

<p><strong>配置ssh</strong> <br>
进行无密码访问连接：生成公钥，将id_rsa.pub复制为私钥authorized_keys</p>

<pre class="prettyprint"><code class=" hljs java">[hadoop<span class="hljs-annotation">@server</span>1 hadoop]$ ssh-keygen  ###默认直接会车
Generating <span class="hljs-keyword">public</span>/<span class="hljs-keyword">private</span> rsa key pair.
Enter file in which to save the <span class="hljs-title">key</span> (/home/hadoop/.ssh/id_rsa): 
Created directory '/home/hadoop/.ssh'.
Enter <span class="hljs-title">passphrase</span> (empty <span class="hljs-keyword">for</span> no passphrase): 
Enter same passphrase again: 
Your identification has been saved in /home/hadoop/.ssh/id_rsa.
Your <span class="hljs-keyword">public</span> key has been saved in /home/hadoop/.ssh/id_rsa.pub.
The key fingerprint is:
e8:8d:6a:5a:b6:50:56:4f:c6:07:d1:3b:fc:0a:6b:75 hadoop@server1
The key's randomart image is:
+--[ RSA 2048]----+
|        oo       |
|       . ..      |
|      . +...     |
|     . = .+      |
|    o . S  o     |
|   o . o. . E    |
|  . o o .+ o     |
|   +.o  o .      |
|  .oo  .         |
+-----------------+
[hadoop<span class="hljs-annotation">@server</span>1 ~]$ cd .ssh/
[hadoop<span class="hljs-annotation">@server</span>1 .ssh]$ ls
id_rsa  id_rsa.pub
[hadoop<span class="hljs-annotation">@server</span>1 .ssh]$ cp id_rsa.pub authorized_keys
[hadoop<span class="hljs-annotation">@server</span>1 .ssh]$ ssh localhost   ###将本机加入无密访问列表
[hadoop<span class="hljs-annotation">@server</span>1 .ssh]$ logout
[hadoop<span class="hljs-annotation">@server</span>1 .ssh]$ ssh <span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.1</span>
[hadoop<span class="hljs-annotation">@server</span>1 .ssh]$ logout
[hadoop<span class="hljs-annotation">@server</span>1 .ssh]$ ssh server1
[hadoop<span class="hljs-annotation">@server</span>1 .ssh]$ logout
[hadoop<span class="hljs-annotation">@server</span>1 .ssh]$ ssh <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span>
[hadoop<span class="hljs-annotation">@server</span>1 .ssh]$ logout</code></pre>

<p><strong>启动dfs</strong></p>

<pre class="prettyprint"><code class=" hljs ruby">格式化：文件存在/tmp/目录
[hadoop<span class="hljs-variable">@server1</span> hadoop] pwd
/home/hadoop
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>bin/hdfs namenode -format

[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>ls /tmp/
hadoop-hadoop      yum.log
hsperfdata_hadoop  yum_save_tx-<span class="hljs-number">2018</span>-<span class="hljs-number">07</span>-<span class="hljs-number">20</span>-<span class="hljs-number">21</span>-<span class="hljs-number">44</span>UB94wi.yumtx

配置环境变量：
[hadoop<span class="hljs-variable">@server1</span> ~]<span class="hljs-variable">$ </span>vim .bash_profile   <span class="hljs-comment">###设置java全部变量，否则服务不能启动</span>
<span class="hljs-number">10</span> <span class="hljs-constant">PATH</span>=<span class="hljs-variable">$PATH</span><span class="hljs-symbol">:</span><span class="hljs-variable">$HOME</span>/<span class="hljs-symbol">bin:</span>~<span class="hljs-regexp">/java/bin</span>
[hadoop<span class="hljs-variable">@server1</span> ~]<span class="hljs-variable">$ </span>source .bash_profile

启动<span class="hljs-symbol">dfs:</span>
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>sbin/start-dfs.sh 
<span class="hljs-constant">Starting</span> namenodes on [server1]
<span class="hljs-symbol">server1:</span> starting namenode, logging to /home/hadoop/hadoop-<span class="hljs-number">2.7</span>.<span class="hljs-number">3</span>/logs/hadoop-hadoop-namenode-server1.out
<span class="hljs-number">172.25</span>.<span class="hljs-number">60.1</span><span class="hljs-symbol">:</span> starting datanode, logging to /home/hadoop/hadoop-<span class="hljs-number">2.7</span>.<span class="hljs-number">3</span>/logs/hadoop-hadoop-datanode-server1.out
<span class="hljs-constant">Starting</span> secondary namenodes [<span class="hljs-number">0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>]
<span class="hljs-number">0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span><span class="hljs-symbol">:</span> starting secondarynamenode, logging to /home/hadoop/hadoop-<span class="hljs-number">2.7</span>.<span class="hljs-number">3</span>/logs/hadoop-hadoop-secondarynamenode-server1.out

[hadoop<span class="hljs-variable">@server1</span> ~]<span class="hljs-variable">$ </span>jps
<span class="hljs-number">6906</span> <span class="hljs-constant">SecondaryNameNode</span>
<span class="hljs-number">6586</span> <span class="hljs-constant">NameNode</span>
<span class="hljs-number">6690</span> <span class="hljs-constant">DataNode</span>
<span class="hljs-number">7250</span> <span class="hljs-constant">Jps</span></code></pre>

<p>浏览器查看是否启动： <br>
<img src="https://img-blog.csdn.net/20180731230116869?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTI0OTMwNg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
<strong>处理文件系统</strong></p>

<pre class="prettyprint"><code class=" hljs ruby">[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>bin/hdfs dfs -usage   <span class="hljs-comment">##查看用法</span>
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>bin/hdfs dfs -mkdir /user
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>bin/hdfs dfs -mkdir /user/hadoop
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>bin/hdfs dfs -ls
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>bin/hdfs dfs -put input/
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>bin/hdfs dfs -ls
<span class="hljs-constant">Found</span> <span class="hljs-number">1</span> items
drwxr-xr-x   - hadoop supergroup          <span class="hljs-number">0</span> <span class="hljs-number">2018</span>-<span class="hljs-number">07</span>-<span class="hljs-number">21</span> <span class="hljs-number">10</span><span class="hljs-symbol">:</span><span class="hljs-number">56</span> input
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-<span class="hljs-number">2.7</span>.<span class="hljs-number">3</span>.jar  wordcount input output 
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>bin/hdfs dfs -cat output/*  <span class="hljs-comment">##查看生成文件</span></code></pre>

<p>查看新建目录output下生成的文件： <br>
<img src="https://img-blog.csdn.net/20180731230223125?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTI0OTMwNg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
<img src="https://img-blog.csdn.net/20180731230243146?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTI0OTMwNg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<h2 id="三分布式文件存储">三.分布式文件存储</h2>

<p><strong>namenode(172.25.60.1)</strong></p>

<pre class="prettyprint"><code class=" hljs ruby">需要停止server1的<span class="hljs-symbol">dfs:</span>
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>sbin/stop-dfs.sh
<span class="hljs-constant">Stopping</span> namenodes on [server1]
<span class="hljs-symbol">server1:</span> stopping namenode
<span class="hljs-number">172.25</span>.<span class="hljs-number">60.1</span><span class="hljs-symbol">:</span> stopping datanode
<span class="hljs-constant">Stopping</span> secondary namenodes [<span class="hljs-number">0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>]
<span class="hljs-number">0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span><span class="hljs-symbol">:</span> stopping secondarynamenod

[root<span class="hljs-variable">@server1</span> ~]<span class="hljs-comment"># yum insatll -y nfs-utils.x86_64</span>
[root<span class="hljs-variable">@server1</span> ~]<span class="hljs-comment"># /etc/init.d/rpcbind start</span>
[root<span class="hljs-variable">@server1</span> ~]<span class="hljs-comment"># vim /etc/exports </span>
/home/hadoop   *(rw,anonuid=<span class="hljs-number">800</span>,anongid=<span class="hljs-number">800</span>)
[root<span class="hljs-variable">@server1</span> ~]<span class="hljs-comment"># /etc/init.d/nfs start</span>
<span class="hljs-constant">Starting</span> <span class="hljs-constant">NFS</span> <span class="hljs-symbol">services:</span>                                     [  <span class="hljs-constant">OK</span>  ]
<span class="hljs-constant">Starting</span> <span class="hljs-constant">NFS</span> <span class="hljs-symbol">quotas:</span>                                       [  <span class="hljs-constant">OK</span>  ]
<span class="hljs-constant">Starting</span> <span class="hljs-constant">NFS</span> <span class="hljs-symbol">mountd:</span>                                       [  <span class="hljs-constant">OK</span>  ]
<span class="hljs-constant">Starting</span> <span class="hljs-constant">NFS</span> <span class="hljs-symbol">daemon:</span>                                       [  <span class="hljs-constant">OK</span>  ]
<span class="hljs-constant">Starting</span> <span class="hljs-constant">RPC</span> <span class="hljs-symbol">idmapd:</span>                                       [  <span class="hljs-constant">OK</span>  ]

[root<span class="hljs-variable">@server1</span> ~]<span class="hljs-comment"># exportfs -v</span>
/home/hadoop    &lt;world&gt;(rw,wdelay,root_squash,no_subtree_check,anonuid=<span class="hljs-number">800</span>,anongid=<span class="hljs-number">800</span>)
[root<span class="hljs-variable">@server1</span> ~]<span class="hljs-comment"># exportfs -rv</span>
exporting *<span class="hljs-symbol">:/home/hadoop</span></code></pre>

<p><strong>datanode（172.25.60.2和172.25.60.3操作一样）</strong></p>

<pre class="prettyprint"><code class=" hljs coffeescript">节点的用户uid和gid必须一样，安装nfs-utils
[root<span class="hljs-property">@server2</span> ~]<span class="hljs-comment"># useradd -u 800 hadoop</span>
[root<span class="hljs-property">@server2</span> ~]<span class="hljs-comment"># id hadoop</span>
uid=<span class="hljs-number">800</span>(hadoop) gid=<span class="hljs-number">800</span>(hadoop) groups=<span class="hljs-number">800</span>(hadoop)
[root<span class="hljs-property">@server2</span> ~]<span class="hljs-comment"># yum insatll -y nfs-utils.x86_64</span>
[root<span class="hljs-property">@server2</span> ~]<span class="hljs-comment"># /etc/init.d/rpcbind start</span>
Starting <span class="hljs-attribute">rpcbind</span>:                                          [  OK  ]
[root<span class="hljs-property">@server2</span> ~]<span class="hljs-comment"># showmount -e 172.25.60.1</span>
Export list <span class="hljs-keyword">for</span> <span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.1</span>:
/home/hadoop *
[root<span class="hljs-property">@server2</span> ~]<span class="hljs-comment"># mount 172.25.60.1:/home/hadoop/ /home/hadoop/</span>
[root<span class="hljs-property">@server2</span> ~]<span class="hljs-comment"># ll -d /home/hadoop/</span>
drwx------ <span class="hljs-number">5</span> hadoop hadoop <span class="hljs-number">4096</span> Jul <span class="hljs-number">21</span> <span class="hljs-number">11</span>:<span class="hljs-number">28</span> /home<span class="hljs-regexp">/hadoop/</span>
[root<span class="hljs-property">@server2</span> ~]<span class="hljs-comment"># df</span>
Filesystem                   <span class="hljs-number">1</span>K-blocks    Used Available Use% Mounted <span class="hljs-literal">on</span>
<span class="hljs-regexp">/dev/mapper/VolGroup-lv_root  19134332 1041524  17120828   6% /</span>
tmpfs                           <span class="hljs-number">510188</span>      <span class="hljs-number">16</span>    <span class="hljs-number">510172</span>   <span class="hljs-number">1</span>% /dev/shm
/dev/vda1                       <span class="hljs-number">495844</span>   <span class="hljs-number">33457</span>    <span class="hljs-number">436787</span>   <span class="hljs-number">8</span>% /boot
<span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.1</span>:<span class="hljs-regexp">/home/hadoop/</span>     <span class="hljs-number">19134336</span> <span class="hljs-number">2226816</span>  <span class="hljs-number">15935616</span>  <span class="hljs-number">13</span>% /home/hadoop</code></pre>

<p><strong>编辑配置文件</strong></p>

<pre class="prettyprint"><code class=" hljs ruby">[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>pwd
/home/hadoop/hadoop/etc
[hadoop<span class="hljs-variable">@server1</span> etc]<span class="hljs-variable">$ </span>vim slaves     
<span class="hljs-number">172.25</span>.<span class="hljs-number">60.2</span>
<span class="hljs-number">172.25</span>.<span class="hljs-number">60.3</span>
[hadoop<span class="hljs-variable">@server1</span> etc]<span class="hljs-variable">$ </span>vim mapred-site.xml
将&lt;value&gt;<span class="hljs-number">1</span>&lt;<span class="hljs-regexp">/value&gt;的1改为2即可</span></code></pre>

<p><strong>测试ssh服务</strong></p>

<pre class="prettyprint"><code class=" hljs applescript">[hadoop@server1 tmp]$ ssh server2
The authenticity <span class="hljs-keyword">of</span> host 'server2 (<span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.2</span>)' can't be established.
RSA key fingerprint <span class="hljs-keyword">is</span> f6:e9:<span class="hljs-number">06</span>:<span class="hljs-number">37</span>:<span class="hljs-number">67</span>:<span class="hljs-number">3</span>c:<span class="hljs-number">42</span>:<span class="hljs-number">3</span>b:<span class="hljs-number">94</span>:c1:b7:a7:<span class="hljs-number">31</span>:<span class="hljs-number">1</span>b:c4:<span class="hljs-number">2</span>d.
Are you sure you want <span class="hljs-keyword">to</span> <span class="hljs-keyword">continue</span> connecting (yes/no)? yes
Warning: Permanently added 'server2,<span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.2</span>' (RSA) <span class="hljs-keyword">to</span> <span class="hljs-keyword">the</span> <span class="hljs-type">list</span> <span class="hljs-keyword">of</span> known hosts.
[hadoop@server2 ~]$ logout
Connection <span class="hljs-keyword">to</span> server2 closed.
[hadoop@server1 tmp]$ ssh server3
The authenticity <span class="hljs-keyword">of</span> host 'server3 (<span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.3</span>)' can't be established.
RSA key fingerprint <span class="hljs-keyword">is</span> f6:e9:<span class="hljs-number">06</span>:<span class="hljs-number">37</span>:<span class="hljs-number">67</span>:<span class="hljs-number">3</span>c:<span class="hljs-number">42</span>:<span class="hljs-number">3</span>b:<span class="hljs-number">94</span>:c1:b7:a7:<span class="hljs-number">31</span>:<span class="hljs-number">1</span>b:c4:<span class="hljs-number">2</span>d.
Are you sure you want <span class="hljs-keyword">to</span> <span class="hljs-keyword">continue</span> connecting (yes/no)? yes
Warning: Permanently added 'server3,<span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.3</span>' (RSA) <span class="hljs-keyword">to</span> <span class="hljs-keyword">the</span> <span class="hljs-type">list</span> <span class="hljs-keyword">of</span> known hosts.
[hadoop@server3 ~]$ logout
Connection <span class="hljs-keyword">to</span> server3 closed.
[hadoop@server1 tmp]$ ssh <span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.2</span>
Last login: Sat Jul <span class="hljs-number">21</span> <span class="hljs-number">11</span>:<span class="hljs-number">44</span>:<span class="hljs-number">01</span> <span class="hljs-number">2018</span> <span class="hljs-keyword">from</span> server1
[hadoop@server2 ~]$ logout
Connection <span class="hljs-keyword">to</span> <span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.2</span> closed.
[hadoop@server1 tmp]$ ssh <span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.3</span>
Last login: Sat Jul <span class="hljs-number">21</span> <span class="hljs-number">11</span>:<span class="hljs-number">44</span>:<span class="hljs-number">07</span> <span class="hljs-number">2018</span> <span class="hljs-keyword">from</span> server1
[hadoop@server3 ~]$ logout
Connection <span class="hljs-keyword">to</span> <span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.3</span> closed.</code></pre>

<p><strong>格式化</strong></p>

<pre class="prettyprint"><code class=" hljs mel">[hadoop<span class="hljs-variable">@server1</span> hadoop]$ bin/hdfs namenode -<span class="hljs-keyword">format</span>
[hadoop<span class="hljs-variable">@server1</span> hadoop]$ <span class="hljs-keyword">ls</span> /tmp/
hadoop-hadoop      yum.<span class="hljs-keyword">log</span>
hsperfdata_hadoop  yum_save_tx-<span class="hljs-number">2018</span>-<span class="hljs-number">07</span>-<span class="hljs-number">20</span>-<span class="hljs-number">21</span>-<span class="hljs-number">44</span>UB94wi.yumtx</code></pre>

<p><strong>启动nfs:namenode和datanode节点分开</strong></p>

<pre class="prettyprint"><code class=" hljs vhdl">[hadoop@server1 hadoop]$ sbin/start-dfs.sh   ###开启nfs服务
Starting namenodes <span class="hljs-keyword">on</span> [server1]
server1: starting namenode, logging <span class="hljs-keyword">to</span> /home/hadoop/hadoop-<span class="hljs-number">2.7</span><span class="hljs-number">.3</span>/logs/hadoop-hadoop-namenode-server1.<span class="hljs-keyword">out</span>
<span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.2</span>: starting datanode, logging <span class="hljs-keyword">to</span> /home/hadoop/hadoop-<span class="hljs-number">2.7</span><span class="hljs-number">.3</span>/logs/hadoop-hadoop-datanode-server2.<span class="hljs-keyword">out</span>
<span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.3</span>: starting datanode, logging <span class="hljs-keyword">to</span> /home/hadoop/hadoop-<span class="hljs-number">2.7</span><span class="hljs-number">.3</span>/logs/hadoop-hadoop-datanode-server3.<span class="hljs-keyword">out</span>
Starting secondary namenodes [<span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span>]
<span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span>: starting secondarynamenode, logging <span class="hljs-keyword">to</span> /home/hadoop/hadoop-<span class="hljs-number">2.7</span><span class="hljs-number">.3</span>/logs/hadoop-hadoop-secondarynamenode-server1.<span class="hljs-keyword">out</span>

namenode节点：
[hadoop@server1 hadoop]$ jps
<span class="hljs-number">11609</span> Jps
<span class="hljs-number">11312</span> NameNode
<span class="hljs-number">11500</span> SecondaryNameNode
datanode节点：
[hadoop@server2 ~]$ jps
<span class="hljs-number">1261</span> Jps
<span class="hljs-number">1167</span> DateNode</code></pre>

<p><strong>处理文件</strong></p>

<pre class="prettyprint"><code class=" hljs ruby">[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>cd /tmp/
[hadoop<span class="hljs-variable">@server1</span> tmp]<span class="hljs-variable">$ </span>ls
hadoop-hadoop
hsperfdata_hadoop
<span class="hljs-constant">Jetty_0_0_0_0_50070_hdfs____w2cu08</span>
<span class="hljs-constant">Jetty_0_0_0_0_50090_secondary____y6aanv</span>
<span class="hljs-constant">Jetty_localhost_48651_datanode____</span>.mi2vgr
yum.log
yum_save_tx-<span class="hljs-number">2018</span>-<span class="hljs-number">07</span>-<span class="hljs-number">20</span>-<span class="hljs-number">21</span>-<span class="hljs-number">44</span>UB94wi.yumtx
删除/tmp目录下所有文件：
[hadoop<span class="hljs-variable">@server1</span> tmp]<span class="hljs-variable">$ </span>rm -fr *
<span class="hljs-symbol">rm:</span> cannot remove `yum.log<span class="hljs-string">': Operation not permitted
rm: cannot remove `yum_save_tx-2018-07-20-21-44UB94wi.yumtx'</span><span class="hljs-symbol">:</span> <span class="hljs-constant">Operation</span> <span class="hljs-keyword">not</span> permitted
重新格式化：
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>bin/hdfs namenode -format   
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>ls /tmp/
hadoop-hadoop      yum.log
hsperfdata_hadoop  yum_save_tx-<span class="hljs-number">2018</span>-<span class="hljs-number">07</span>-<span class="hljs-number">20</span>-<span class="hljs-number">21</span>-<span class="hljs-number">44</span>UB94wi.yumtx
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>ls
bin  <span class="hljs-keyword">include</span>  libexec      logs        <span class="hljs-constant">README</span>.txt  share
etc  lib      <span class="hljs-constant">LICENSE</span>.txt  <span class="hljs-constant">NOTICE</span>.txt  sbin
启动dfs服务，创建目录：
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>sbin/start-dfs.sh 
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>bin/hdfs dfs -mkdir /user
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>bin/hdfs dfs -mkdir /user/hadoop
将etc/hadoop/目录的文件放在input目录下：
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>bin/hdfs dfs -put etc/hadoop/ input
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>bin/hdfs dfs -ls input</code></pre>

<p>删除文件时： <br>
<img src="https://img-blog.csdn.net/20180731233121778?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTI0OTMwNg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
重新放置文件时： <br>
<img src="https://img-blog.csdn.net/20180731233158955?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTI0OTMwNg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
<img src="https://img-blog.csdn.net/20180731233205704?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTI0OTMwNg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>



<h2 id="四节点的添加和删除">四.节点的添加和删除</h2>

<p><strong>在线添加server4(在线扩容)</strong></p>

<pre class="prettyprint"><code class=" hljs ruby">[root<span class="hljs-variable">@server4</span> ~]<span class="hljs-comment"># yum install -y nfs-utils</span>
[root<span class="hljs-variable">@server4</span> ~]<span class="hljs-comment"># /etc/init.d/rpcbind start</span>
<span class="hljs-constant">Starting</span> <span class="hljs-symbol">rpcbind:</span>                                          [  <span class="hljs-constant">OK</span>  ]
[root<span class="hljs-variable">@server4</span> ~]<span class="hljs-comment"># useradd -u 800 hadoop</span>
[root<span class="hljs-variable">@server4</span> ~]<span class="hljs-comment"># id hadoop</span>
uid=<span class="hljs-number">800</span>(hadoop) gid=<span class="hljs-number">800</span>(hadoop) groups=<span class="hljs-number">800</span>(hadoop)
[root<span class="hljs-variable">@server4</span> sbin]<span class="hljs-comment"># pwd</span>
/home/hadoop/hadoop/sbin
[root<span class="hljs-variable">@server4</span> sbin]<span class="hljs-comment"># ./hadoop-daemon.sh start datanode</span>
starting datanode, logging to /home/hadoop/hadoop-<span class="hljs-number">2.7</span>.<span class="hljs-number">3</span>/logs/hadoop-root-datanode-server4.out
[root<span class="hljs-variable">@server4</span> sbin]<span class="hljs-comment"># su - hadoop </span>
[root<span class="hljs-variable">@server4</span> ~]<span class="hljs-comment"># vim hadoop/etc/hadoop/slave</span>
<span class="hljs-number">172.25</span>.<span class="hljs-number">60.2</span>
<span class="hljs-number">172.25</span>.<span class="hljs-number">60.3</span>
<span class="hljs-number">172.25</span>.<span class="hljs-number">60.4</span></code></pre>

<p>浏览器查看是否添加server4： <br>
<img src="https://img-blog.csdn.net/20180731233621749?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTI0OTMwNg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
<strong>namenode测试ssh服务</strong></p>

<pre class="prettyprint"><code class=" hljs ruby">[hadoop<span class="hljs-variable">@server4</span> ~]<span class="hljs-variable">$ </span>ssh server4
[hadoop<span class="hljs-variable">@server4</span> ~]<span class="hljs-variable">$ </span>logout
[hadoop<span class="hljs-variable">@server4</span> ~]<span class="hljs-variable">$ </span>ssh <span class="hljs-number">172.25</span>.<span class="hljs-number">60.4</span>
[hadoop<span class="hljs-variable">@server4</span> ~]<span class="hljs-variable">$ </span>logout
[hadoop<span class="hljs-variable">@server4</span> ~]<span class="hljs-variable">$ </span>cd hadoop
[hadoop<span class="hljs-variable">@server4</span> ~]<span class="hljs-variable">$ </span>sbin/hadoop-daemon.sh start datanode
[hadoop<span class="hljs-variable">@server4</span> ~]<span class="hljs-variable">$ </span>jps
<span class="hljs-number">1250</span> <span class="hljs-constant">Jps</span>
<span class="hljs-number">1177</span> <span class="hljs-constant">DateNode</span></code></pre>

<p><strong>server2测试</strong></p>

<pre class="prettyprint"><code class=" hljs coffeescript">[hadoop<span class="hljs-property">@server1</span> hadoop]$ pwd
/home/hadoop/hadoop/etc/hadoop
[hadoop<span class="hljs-property">@server1</span> hadoop]$ vim hdfs-site.xml 
    &lt;property&gt;
        &lt;name&gt;dfs.hosts.exclude&lt;/name&gt;
        &lt;value&gt;/home/hadoop/hadoop/etc/hadoop/hosts-exclude&lt;/value&gt;
    &lt;/property&gt;

[hadoop<span class="hljs-property">@server1</span> hadoop]$ vim hosts-exclude
<span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.2</span>    <span class="hljs-comment">##删除的节点IP</span>

[hadoop<span class="hljs-property">@server1</span> hadoop]$ dd <span class="hljs-keyword">if</span>=/dev/zero <span class="hljs-keyword">of</span>=bigfile bs=<span class="hljs-number">1</span>M count=<span class="hljs-number">200</span>
[hadoop<span class="hljs-property">@server1</span> hadoop]$ ../../bin/hdfs dfs -put bigfile 
[hadoop<span class="hljs-property">@server1</span> hadoop]$ vim slaves
<span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.3</span>
<span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.4</span>

[hadoop<span class="hljs-property">@server1</span> hadoop]$ ../../bin/hdfs dfsadmin -refreshNodes <span class="hljs-comment">##刷新节点</span>
Refresh nodes successful
[hadoop<span class="hljs-property">@server1</span> hadoop]$ ../../bin/hdfs dfsadmin -report
<span class="hljs-attribute">Name</span>: <span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.2</span>:<span class="hljs-number">50010</span> (server2)
<span class="hljs-attribute">Hostname</span>: server2
Decommission Status : Decommission <span class="hljs-keyword">in</span> progress
Configured <span class="hljs-attribute">Capacity</span>: <span class="hljs-number">19593555968</span> (<span class="hljs-number">18.25</span> GB)
DFS <span class="hljs-attribute">Used</span>: <span class="hljs-number">135581696</span> (<span class="hljs-number">129.30</span> MB)
Non DFS <span class="hljs-attribute">Used</span>: <span class="hljs-number">1954566144</span> (<span class="hljs-number">1.82</span> GB)
DFS <span class="hljs-attribute">Remaining</span>: <span class="hljs-number">17503408128</span> (<span class="hljs-number">16.30</span> GB)
DFS Used%: <span class="hljs-number">0.69</span>%
DFS Remaining%: <span class="hljs-number">89.33</span>%
Configured Cache <span class="hljs-attribute">Capacity</span>: <span class="hljs-number">0</span> (<span class="hljs-number">0</span> B)
Cache <span class="hljs-attribute">Used</span>: <span class="hljs-number">0</span> (<span class="hljs-number">0</span> B)
Cache <span class="hljs-attribute">Remaining</span>: <span class="hljs-number">0</span> (<span class="hljs-number">0</span> B)
Cache Used%: <span class="hljs-number">100.00</span>%
Cache Remaining%: <span class="hljs-number">0.00</span>%
<span class="hljs-attribute">Xceivers</span>: <span class="hljs-number">1</span>
Last <span class="hljs-attribute">contact</span>: Sat Jul <span class="hljs-number">21</span> <span class="hljs-number">14</span>:<span class="hljs-number">23</span>:<span class="hljs-number">43</span> CST <span class="hljs-number">2018</span>

<span class="hljs-attribute">Name</span>: <span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.2</span>:<span class="hljs-number">50010</span> (server2)
<span class="hljs-attribute">Hostname</span>: server2
Decommission Status : Decommissioned
[hadoop<span class="hljs-property">@server2</span> hadoop]$ sbin/hadoop-daemon.sh stop datanode
stopping datanode
[hadoop<span class="hljs-property">@server2</span> hadoop]$ jps
<span class="hljs-number">2039</span> Jps</code></pre>

<p><strong>yarn模式</strong></p>

<pre class="prettyprint"><code class=" hljs xml">[hadoop@server1 hadoop]$ cp mapred-site.xml.template mapred-site.xml
[hadoop@server1 hadoop]$ vim mapred-site.xml
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
 <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
[hadoop@server1 hadoop]$ vim yarn-site.xml
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
[hadoop@server1 hadoop]$ cd ..
[hadoop@server1 etc]$ cd ..
[hadoop@server1 hadoop]$ sbin/start-yarn.sh 
namenode：
[hadoop@server1 hadoop]$ jps
22720 Jps
11312 NameNode
11500 SecondaryNameNode
22461 ResourceManager
datanode:
[hadoop@server3 ~]$ jps
14481 Jps
4153 DataNode
14318 NodeManager
[hadoop@server4 hadoop]$ jps
2355 Jps
2119 DataNode
2257 NodeManager</code></pre>

<h2 id="五-zookeeper集群搭建">五. zookeeper集群搭建</h2>

<p>所有节点清空/tmp/目录 <br>
<strong>server5主机</strong></p>

<pre class="prettyprint"><code class=" hljs coffeescript">root<span class="hljs-property">@server5</span> ~]<span class="hljs-comment"># yum install -y nfs-utils</span>
[root<span class="hljs-property">@server5</span> ~]<span class="hljs-comment"># /etc/init.d/rpcbind start</span>
[root<span class="hljs-property">@server5</span> ~]<span class="hljs-comment"># useradd -u 800 hadoop</span>
[root<span class="hljs-property">@server5</span> ~]<span class="hljs-comment"># id hadoop</span>
uid=<span class="hljs-number">800</span>(hadoop) gid=<span class="hljs-number">800</span>(hadoop) groups=<span class="hljs-number">800</span>(hadoop)
[root<span class="hljs-property">@server5</span> ~]<span class="hljs-comment"># mount 172.25.60.1:/home/hadoop/ /home/hadoop/</span>
[root<span class="hljs-property">@server5</span> ~]<span class="hljs-comment"># df  </span>
Filesystem                   <span class="hljs-number">1</span>K-blocks    Used Available Use% Mounted <span class="hljs-literal">on</span>
<span class="hljs-regexp">/dev/mapper/VolGroup-lv_root  19134332 1184068  16978284   7% /</span>
tmpfs                           <span class="hljs-number">510188</span>       <span class="hljs-number">0</span>    <span class="hljs-number">510188</span>   <span class="hljs-number">0</span>% /dev/shm
/dev/vda1                       <span class="hljs-number">495844</span>   <span class="hljs-number">33457</span>    <span class="hljs-number">436787</span>   <span class="hljs-number">8</span>% /boot
<span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.1</span>:<span class="hljs-regexp">/home/hadoop/</span>     <span class="hljs-number">19134336</span> <span class="hljs-number">2297472</span>  <span class="hljs-number">15864832</span>  <span class="hljs-number">13</span>% /home/hadoop</code></pre>

<p><strong>server1主机</strong></p>

<pre class="prettyprint"><code class=" hljs ruby">server1停止所有服务
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>sbin/stop-all.sh 
server1无密连接<span class="hljs-symbol">server5:</span>
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>ssh server5
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>logout
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>ssh <span class="hljs-number">172.25</span>.<span class="hljs-number">60.5</span>
[hadoop<span class="hljs-variable">@server1</span> hadoop]<span class="hljs-variable">$ </span>logout</code></pre>

<p><strong>配置zookeeper</strong></p>

<pre class="prettyprint"><code class=" hljs avrasm">[hadoop@server1 ~]$ tar zxf zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span><span class="hljs-preprocessor">.tar</span><span class="hljs-preprocessor">.gz</span> 
[hadoop@server1 ~]$ cd zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span>
[hadoop@server1 zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span>]$ ls
bin          dist-maven       LICENSE<span class="hljs-preprocessor">.txt</span>           src
build<span class="hljs-preprocessor">.xml</span>    docs             NOTICE<span class="hljs-preprocessor">.txt</span>            zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span><span class="hljs-preprocessor">.jar</span>
CHANGES<span class="hljs-preprocessor">.txt</span>  ivysettings<span class="hljs-preprocessor">.xml</span>  README_packaging<span class="hljs-preprocessor">.txt</span>  zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span><span class="hljs-preprocessor">.jar</span><span class="hljs-preprocessor">.asc</span>
conf         ivy<span class="hljs-preprocessor">.xml</span>          README<span class="hljs-preprocessor">.txt</span>            zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span><span class="hljs-preprocessor">.jar</span><span class="hljs-preprocessor">.md</span>5
contrib      lib              recipes               zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span><span class="hljs-preprocessor">.jar</span><span class="hljs-preprocessor">.sha</span>1
[hadoop@server1 zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span>]$ cd conf/
[hadoop@server1 conf]$ ls
configuration<span class="hljs-preprocessor">.xsl</span>  log4j<span class="hljs-preprocessor">.properties</span>  zoo_sample<span class="hljs-preprocessor">.cfg</span>
[hadoop@server1 conf]$ <span class="hljs-keyword">cp</span> zoo_sample<span class="hljs-preprocessor">.cfg</span> zoo<span class="hljs-preprocessor">.cfg</span>
[hadoop@server1 conf]$ vim zoo<span class="hljs-preprocessor">.cfg</span>
server<span class="hljs-number">.1</span>=<span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.2</span>:<span class="hljs-number">2888</span>:<span class="hljs-number">3888</span>
server<span class="hljs-number">.2</span>=<span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.3</span>:<span class="hljs-number">2888</span>:<span class="hljs-number">3888</span>
server<span class="hljs-number">.3</span>=<span class="hljs-number">172.25</span><span class="hljs-number">.60</span><span class="hljs-number">.4</span>:<span class="hljs-number">2888</span>:<span class="hljs-number">3888</span></code></pre>

<p><strong>server2和server3和server4的配置</strong> <br>
注意myid的不同，对应上面的配置文件</p>

<pre class="prettyprint"><code class=" hljs ruby">[hadoop<span class="hljs-variable">@server2</span> zookeeper-<span class="hljs-number">3.4</span>.<span class="hljs-number">9</span>]<span class="hljs-variable">$ </span>cd /tmp/
[hadoop<span class="hljs-variable">@server2</span> tmp]<span class="hljs-variable">$ </span>mkdir zookeeper
[hadoop<span class="hljs-variable">@server2</span> tmp]<span class="hljs-variable">$ </span>cd zookeeper/
[hadoop<span class="hljs-variable">@server2</span> zookeeper]<span class="hljs-variable">$ </span>vim myid
<span class="hljs-number">1</span>

[hadoop<span class="hljs-variable">@server3</span> tmp]<span class="hljs-variable">$ </span>mkdir zookeeper
[hadoop<span class="hljs-variable">@server3</span> tmp]<span class="hljs-variable">$ </span>cd zookeeper/
[hadoop<span class="hljs-variable">@server3</span> zookeeper]<span class="hljs-variable">$ </span>echo <span class="hljs-number">2</span> &gt; myid
[hadoop<span class="hljs-variable">@server3</span> zookeeper]<span class="hljs-variable">$ </span>cat myid 
<span class="hljs-number">2</span>

[hadoop<span class="hljs-variable">@server4</span> tmp]<span class="hljs-variable">$ </span>mkdir zookeeper
[hadoop<span class="hljs-variable">@server4</span> tmp]<span class="hljs-variable">$ </span>cd zookeeper/
[hadoop<span class="hljs-variable">@server4</span> zookeeper]<span class="hljs-variable">$ </span>echo <span class="hljs-number">3</span> &gt; myid
[hadoop<span class="hljs-variable">@server4</span> zookeeper]<span class="hljs-variable">$ </span>cat myid 
<span class="hljs-number">3</span></code></pre>

<p><strong>3个datanode主机启动zookeeper集群</strong></p>

<pre class="prettyprint"><code class=" hljs r">[hadoop@server2 ~]$ cd zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span>
[hadoop@server2 zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span>]$ cd bin/
[hadoop@server2 bin]$ ./zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /home/hadoop/zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span>/bin/../conf/zoo.cfg
Starting zookeeper <span class="hljs-keyword">...</span> STARTED

[hadoop@server3 tmp]$ cd /home/hadoop/zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span>/bin/
[hadoop@server3 bin]$ ./zkServer.sh start 
ZooKeeper JMX enabled by default
Using config: /home/hadoop/zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span>/bin/../conf/zoo.cfg
Starting zookeeper <span class="hljs-keyword">...</span> STARTED

[hadoop@server4 zookeeper]$ cd /home/hadoop/zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span>/bin/
[hadoop@server4 bin]$ ./zkServer.sh start 
ZooKeeper JMX enabled by default
Using config: /home/hadoop/zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span>/bin/../conf/zoo.cfg
Starting zookeeper <span class="hljs-keyword">...</span> STARTED</code></pre>

<p><strong>查看所有节点信息</strong></p>

<pre class="prettyprint"><code class=" hljs coffeescript">[hadoop<span class="hljs-property">@server2</span> zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span>]$ bin/zkServer.sh status
ZooKeeper JMX enabled <span class="hljs-keyword">by</span> <span class="hljs-reserved">default</span>
Using <span class="hljs-attribute">config</span>: <span class="hljs-regexp">/home/hadoop/zookeeper-3.4.9/bin/</span>../conf/zoo.cfg
<span class="hljs-attribute">Mode</span>: follower

[hadoop<span class="hljs-property">@server3</span> zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span>]$ bin/zkServer.sh status
ZooKeeper JMX enabled <span class="hljs-keyword">by</span> <span class="hljs-reserved">default</span>
Using <span class="hljs-attribute">config</span>: <span class="hljs-regexp">/home/hadoop/zookeeper-3.4.9/bin/</span>../conf/zoo.cfg
<span class="hljs-attribute">Mode</span>: follower

[hadoop<span class="hljs-property">@server4</span> zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span>]$ bin/zkServer.sh status
ZooKeeper JMX enabled <span class="hljs-keyword">by</span> <span class="hljs-reserved">default</span>
Using <span class="hljs-attribute">config</span>: <span class="hljs-regexp">/home/hadoop/zookeeper-3.4.9/bin/</span>../conf/zoo.cfg
<span class="hljs-attribute">Mode</span>: leader

leader（server4）测试
[hadoop<span class="hljs-property">@server4</span> zookeeper-<span class="hljs-number">3.4</span><span class="hljs-number">.9</span>]$ bin/zkCli.sh
Connecting to <span class="hljs-attribute">localhost</span>:<span class="hljs-number">2181</span>
<span class="hljs-attribute">WATCHER</span>::

WatchedEvent <span class="hljs-attribute">state</span>:SyncConnected <span class="hljs-attribute">type</span>:None <span class="hljs-attribute">path</span>:<span class="hljs-literal">null</span>

[<span class="hljs-attribute">zk</span>: <span class="hljs-attribute">localhost</span>:<span class="hljs-number">2181</span>(CONNECTED) <span class="hljs-number">0</span>] ls
[<span class="hljs-attribute">zk</span>: <span class="hljs-attribute">localhost</span>:<span class="hljs-number">2181</span>(CONNECTED) <span class="hljs-number">1</span>] ls /
[zookeeper]
[<span class="hljs-attribute">zk</span>: <span class="hljs-attribute">localhost</span>:<span class="hljs-number">2181</span>(CONNECTED) <span class="hljs-number">2</span>] ls /zookeeper
[quota]
[<span class="hljs-attribute">zk</span>: <span class="hljs-attribute">localhost</span>:<span class="hljs-number">2181</span>(CONNECTED) <span class="hljs-number">3</span>] ls /zookeeper/quota
[]
[<span class="hljs-attribute">zk</span>: <span class="hljs-attribute">localhost</span>:<span class="hljs-number">2181</span>(CONNECTED) <span class="hljs-number">5</span>] quit 
Quitting...</code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>