---
layout:     post
title:      Flume安装测试
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/u010022051/article/details/50432835				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>1、从官网下载最新版的二进制Flume安装文件：apache-flume-1.6.0-bin.tar.gz</p>
<p>2、在指定目录/home/hadoop/下解压缩安装文件：tar -zxvf apache-flume-1.6.0-bin.tar.gz</p>
<p>3、在Flume安装目录下执行如下命令测试Flume是否安装成功：bin/flume-ng version</p>
<p><span></span>出现如下内容则表示Flume安装成功</p>
<p><span><img src="https://img-blog.csdn.net/20151230102906214?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></span></p>
<p><span>4</span>、Flume测试案例：</p>
<p><br></p>
<p>案例1：Avro<br>
Avro可以发送一个给定的文件给Flume，Avro 源使用AVRO RPC机制。<br>
a)创建agent配置文件<br></p>
<p>vi /home/hadoop/apache-flume-1.6.0-bin/conf/avro.conf<br>
  <br>
a1.sources = r1<br>
a1.sinks = k1<br>
a1.channels = c1<br>
  <br>
# Describe/configure the source<br>
a1.sources.r1.type = avro<br>
a1.sources.r1.channels = c1<br>
a1.sources.r1.bind = 172.26.40.74<br>
a1.sources.r1.port = 4141<br>
  <br>
# Describe the sink<br>
a1.sinks.k1.type = logger<br>
  <br>
# Use a channel which buffers events in memory<br>
a1.channels.c1.type = memory<br>
a1.channels.c1.capacity = 1000<br>
a1.channels.c1.transactionCapacity = 100<br>
  <br>
# Bind the source and sink to the channel<br>
a1.sources.r1.channels = c1<br>
a1.sinks.k1.channel = c1<br></p>
<p><br></p>
<p>b)启动flume agent a1<br></p>
<p>bin/flume-ng agent -c . -f /home/hadoop/apache-flume-1.6.0-bin/conf/avro.conf -n a1 -Dflume.root.logger=INFO,console<br></p>
<p>c)创建指定文件<br>
echo "hello world" &gt; /home/hadoop/apache-flume-1.6.0-bin/log.00<br>
d)使用avro-client发送文件<br>
bin/flume-ng avro-client -c . -H 172.26.40.74 -p 4141 -F /home/hadoop/apache-flume-1.6.0-bin/log.00<br>
f)在172.26.40.74的控制台，可以看到以下信息：<br></p>
<p><img src="https://img-blog.csdn.net/20151230124354254?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></p>
<p><br></p>
<p><br></p>
<p>案例2：Spool<br>
Spool监测配置的目录下新增的文件，并将文件中的数据读取出来。需要注意两点：<br>
1) 拷贝到spool目录下的文件不可以再打开编辑。<br>
2) spool目录下不可包含相应的子目录<br>
a)创建agent配置文件<br>
vi /home/hadoop/apache-flume-1.6.0-bin/conf/spool.conf<br>
a1.sources = r1<br>
a1.sinks = k1<br>
a1.channels = c1<br>
# Describe/configure the source<br>
a1.sources.r1.type = spooldir<br>
a1.sources.r1.channels = c1<br>
a1.sources.r1.spoolDir = /home/hadoop/apache-flume-1.6.0-bin/logs<br>
a1.sources.r1.fileHeader = true<br>
# Describe the sink<br>
a1.sinks.k1.type = logger<br>
# Use a channel which buffers events in memory<br>
a1.channels.c1.type = memory<br>
a1.channels.c1.capacity = 1000<br>
a1.channels.c1.transactionCapacity = 100<br>
# Bind the source and sink to the channel<br>
a1.sources.r1.channels = c1<br>
a1.sinks.k1.channel = c1<br>
b)启动flume agent a1<br>
bin/flume-ng agent -c . -f /home/hadoop/apache-flume-1.6.0-bin/conf/spool.conf -n a1 -Dflume.root.logger=INFO,console<br>
c)追加文件到/home/hadoop/flume-1.5.0-bin/logs目录<br>
echo "spool test1" &gt; /home/hadoop/apache-flume-1.6.0-bin/logs/spool_text.log<br>
d)在m1的控制台，可以看到以下相关信息：<br></p>
<p><img src="https://img-blog.csdn.net/20151230144315826?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></p>
<p><br></p>
            </div>
                </div>