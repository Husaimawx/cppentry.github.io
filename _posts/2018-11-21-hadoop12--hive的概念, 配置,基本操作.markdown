---
layout:     post
title:      hadoop12--hive的概念, 配置,基本操作
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，转载请标明出处。https://blog.csdn.net/kXYOnA63Ag9zqtXx0/article/details/82954503					https://blog.csdn.net/forever428/article/details/83865434				</div>
								            <div id="content_views" class="markdown_views prism-github-gist">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p></p><div class="toc"><h3>文章目录</h3><ul><ul><li><a href="#hive_1" rel="nofollow">hive</a></li><ul><li><a href="#hive_2" rel="nofollow">hive的基本概念</a></li><li><a href="#hive_4" rel="nofollow">hive的基本操作</a></li><ul><li><a href="#_5" rel="nofollow">数据库的操作</a></li><li><a href="#_9" rel="nofollow">数据表的操作</a></li><li><a href="#_16" rel="nofollow">管理表与外部表的区别</a></li></ul><li><a href="#hive_19" rel="nofollow">hive常用交互命令</a></li><li><a href="#hive_65" rel="nofollow">hive常见属性配置</a></li><ul><li><a href="#_70" rel="nofollow">创建自定义配置文件的步骤</a></li><li><a href="#_88" rel="nofollow">配置查询信息的显示（头信息）</a></li><li><a href="#hive_118" rel="nofollow">配置hive的日志信息</a></li><li><a href="#_143" rel="nofollow">参数的配置方式</a></li></ul><li><a href="#hive_162" rel="nofollow">hive数据类型</a></li><li><a href="#DDL_187" rel="nofollow">DDL数据定义</a></li><ul><li><a href="#1___HDFS_userhivewarehousedb_188" rel="nofollow">1.  创建数据库,创建的数据库存储在 HDFS 上的默认路径是/user/hive/warehouse/*.db</a></li><li><a href="#2____192" rel="nofollow">2.  删除数据库 以下官网提供的语法</a></li><li><a href="#3__DDL__create_drop_truncate_197" rel="nofollow">3.  表的DDL 定义 （create ,drop ,truncate）</a></li><ul><li><a href="#_207" rel="nofollow">分区表：</a></li><li><a href="#_218" rel="nofollow">查询分区表中的数据：</a></li><li><a href="#_HDFS_254" rel="nofollow">分表表加载数据的方式二： 先上传数据到HDFS上之后在和分区表进行关联</a></li><li><a href="#_274" rel="nofollow">上传数据之后增加分区：</a></li></ul><li><a href="#_294" rel="nofollow">修改表：</a></li></ul></ul></ul></ul></div><p></p>
<h2><a id="hive_1"></a>hive</h2>
<h3><a id="hive_2"></a>hive的基本概念</h3>
<p>Hive 作为一个数据仓库的工具，特点，操作简单 上手容易，由于其底层封装的是MR ，实际上hive不保存数据，数据都是保存在HDFS只上，所以说hive是基于hadoop之上的</p>
<h3><a id="hive_4"></a>hive的基本操作</h3>
<h4><a id="_5"></a>数据库的操作</h4>
<ul>
<li>创建数据库  create database 数据库名称</li>
<li>查看数据库   show  databases</li>
<li>删除数据库   drop database 数据库的名称， 只能删除空的数据库 如果要删除非空的数据库则需要加上关键字 cascade</li>
</ul>
<h4><a id="_9"></a>数据表的操作</h4>
<ul>
<li>创建表： create table 表名称 （属性 数据类型）</li>
<li>可以指定存储数据的分隔符</li>
</ul>
<pre><code> create table student(id int,name string) 
 row format delimited fields terminated by '\t';
</code></pre>
<h4><a id="_16"></a>管理表与外部表的区别</h4>
<p>管理表因为对表存在管理权，所以在删除该表的时候，元数据以及表中的存储在hdfs上的数据同时都会被删除，而外部表由于对表没有管理权，所以在删除的时候只会删除元数据，真正的数据不会被删除</p>
<h3><a id="hive_19"></a>hive常用交互命令</h3>
<pre><code>usage: hive
 -d,--define &lt;key=value&gt;          Variable subsitution to apply to hive
                                  commands. e.g. -d A=B or --define A=B
    --database &lt;databasename&gt;     Specify the database to use
 -e &lt;quoted-query-string&gt;         SQL from command line
 -f &lt;filename&gt;                    SQL from files
 -H,--help                        Print help information
    --hiveconf &lt;property=value&gt;   Use value for given property
    --hivevar &lt;key=value&gt;         Variable subsitution to apply to hive
                                  commands. e.g. --hivevar A=B
 -i &lt;filename&gt;                    Initialization SQL file
 -S,--silent                      Silent mode in interactive shell
 -v,--verbose                     Verbose mode (echo executed SQL to the
                                  console)

</code></pre>
<ol>
<li>-e 不进入到hive的交互窗口执行SQL语句</li>
</ol>
<pre><code>bin/hive -e "select name from student";
</code></pre>
<p>通过以上的方式，可以在不进入到hive中就可以执行sql语句进行查询<br>
2. -f 执行的sql语句来自文件，其实可以理解为执行一个脚本命令<br>
(1)首先在/data/目录下创建hivesql.sql文件，在该文件下编写sql语句</p>
<pre><code>vi test.sql
-----------------
Select * from student;
</code></pre>
<p>(2)在hive 的命令行中使用 -f参数执行该创建好的脚本文件，具体操作如下</p>
<pre><code>bin/hive -f /data/hiveql.sql
</code></pre>
<p>(3)在-f 之后给定脚本的绝对路径，之后就可以执行咱们的脚本命令 输出的结果如下</p>
<pre><code>1       zhangsan
2       lisi
3       banzhang
4       xuewei
</code></pre>
<ol start="3">
<li>在hive中也可以直接运行hdfs的命令，在进入hive的命令行模式下，可以直接操作hdfs文件系统，并且由于hive会一直连接hdfs 所以操作的时候会比平时不在hive中操作更快速一些操作的命令如下</li>
</ol>
<pre><code>hive&gt; dfs -mkdir /test;
</code></pre>
<h3><a id="hive_65"></a>hive常见属性配置</h3>
<p>数据仓库的位置配置 defualt数据库默认的位置在hdfs上的/user/hive/warehouse的路径下，没有对默认数据库创建目录<br>
修改默认数据库的原始位置： 肯定在配置文件中进行修改。<br>
打开hive中conf目录下发现直存在hive-default.xml.template，该配置文件为hive中默认的属性配置文件，在conf目录下需要配置自定义的配置文件hive-site.xml配置文件，可以参考默认的配置文件进行创建</p>
<h4><a id="_70"></a>创建自定义配置文件的步骤</h4>
<ol>
<li>复制出来一份默认的配置文件</li>
</ol>
<pre><code>cp hive-default.xml.template hive-site.xml
</code></pre>
<ol start="2">
<li>修改自定义的配置文件里面的内容，把该属性清空，只保留头信息，可以通过4000 dd删除里面的内容通过vi的方式<br>
3 通过参考默认配置文件查找需要配置的属性内容 例如修改默认的数据库位置则配置信息如下</li>
</ol>
<pre><code>&lt;property&gt;
    &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;
    &lt;value&gt;/user/hive/warehouse&lt;/value&gt;
    &lt;description&gt;location of default database for the warehouse&lt;/description&gt;
  &lt;/property&gt;
</code></pre>
<p>修改之后，还需要为其增加用户组的权限</p>
<pre><code>chmod g+w  /user/hive/warehouse
</code></pre>
<h4><a id="_88"></a>配置查询信息的显示（头信息）</h4>
<ol>
<li>在hive-site.xml 配置文件中增加如下信息，可以配置数据显示的名称.</li>
</ol>
<pre><code>&lt;property&gt;
    &lt;name&gt;hive.cli.print.current.db&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
    &lt;description&gt;Whether to include the current database in the Hive prompt.&lt;/description&gt;
  &lt;/property&gt;
</code></pre>
<p>改成true之后观察hive中显示的变化<br>
通过观察发现在配置了该属性之后，数据的当前名称可以显示出来<br>
hive (default)&gt; use test;</p>
<ol start="2">
<li>配置列的头信息显示<br>
在hive-site.xml配置文件中增加如下配置,可以显示头信息</li>
</ol>
<pre><code>&lt;property&gt;
    &lt;name&gt;hive.cli.print.header&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
    &lt;description&gt;Whether to print the names of the columns in query output.&lt;/description&gt;
  &lt;/property&gt;
</code></pre>
<p>输出的内容显示如下</p>
<pre><code>student.id      student.name
1       zhangsan
2       lisi
3       banzhang
4       xuewei
</code></pre>
<h4><a id="hive_118"></a>配置hive的日志信息</h4>
<p>Hive运行日志，默认保存在/tmp/hadoop(用户名)/hive.log 由于保存在/tmp目录下，该目录是一个临时目录，所以日志需要经常查看，所以需要修改默认的路径<br>
修改步骤：</p>
<ol>
<li>在hive的目录下创建一个目录命名为log    mkdir log</li>
</ol>
<pre><code>/opt/app/apache-hive-1.2.1-bin/log
</code></pre>
<ol start="2">
<li>接下来要把默认的日志路径修改为自己创建的路径<br>
(1)进入到hive 的conf目录下，该目录下存在一个配置文件为hive-log4j.properties.template，需要修改该文件,去掉template。应为加上template hive不识别所以需要去掉template后缀<br>
(2)重命名</li>
</ol>
<pre><code>mv hive-log4j.properties.template  hive-log4j.properties
</code></pre>
<p>打开该文件 修改如下属性</p>
<pre><code>hive.log.dir=${java.io.tmpdir}/${user.name}
</code></pre>
<p>修改为自定义的目录路径</p>
<pre><code>hive.log.dir=/opt/app/apache-hive-1.2.1-bin/log
</code></pre>
<p>该属性指定了hive的日志保存路径<br>
配置完该属性之后，重新进入一下hive ，在hive中进行一些命令操作，观察新配置的目录是否存在hive.log 日志</p>
<h4><a id="_143"></a>参数的配置方式</h4>
<ol>
<li>配置文件的方式<br>
默认的配置文件：hive-default.xml 该文件下存在所有默认属性配置信息<br>
用户自定义的配置文件：hive-site.xml 优先级高于默认的配置文件</li>
<li>命令行的参数配置<br>
在启动hive的时候可以通过命令行的方式进行配置 --hiveconf parm=value 来进行设定<br>
例如：bin/hive --hiveconf hive.cli.print.header=false;<br>
以上的配置，仅对本次启动的hive有效</li>
<li>查看参数设置：<br>
set hive.cli.print.current.db;  可以根据set命令查看已经设置的属性具体的参数内容<br>
得到的结果为：hive.cli.print.current.db=true</li>
<li>通过参数进行属性的设置<br>
范例：set hive.cli.print.current.db=false;<br>
在参数中设置了属性的内容，接下来可以通过set 方式查看属性的内容结果为false<br>
以上的方式也是临时对本次hive的启动有效，退出之后在进入hive 就失效了</li>
</ol>
<p><strong>注意</strong>:以上三种方式的优先级 参数方式&gt;命令行方式&gt;自定义配置文件。对于参数方式以及命令方式设置参数内容都是临时的，自定义配置文件设置的参数，在hive启动的时候进行读取</p>
<h3><a id="hive_162"></a>hive数据类型</h3>
<ol>
<li>基本数据类型 ，与mysql中的数据类型非常类似。由于hive是java编写的所以说和mysql 有不一样的地方</li>
</ol>

<table>
<thead>
<tr>
<th>hive的数据类型</th>
<th>Java 数据类型</th>
</tr>
</thead>
<tbody>
<tr>
<td>TINYINT</td>
<td>byte</td>
</tr>
<tr>
<td>SMALINT</td>
<td>short</td>
</tr>
<tr>
<td>INT</td>
<td>int</td>
</tr>
<tr>
<td>BIGINT</td>
<td>long</td>
</tr>
<tr>
<td>BOOLEAN</td>
<td>boolean</td>
</tr>
<tr>
<td>FLOAT</td>
<td>float</td>
</tr>
<tr>
<td>DOUBLE</td>
<td>double</td>
</tr>
<tr>
<td>String</td>
<td>String</td>
</tr>
<tr>
<td>TIMESTAMP</td>
<td>时间类型</td>
</tr>
<tr>
<td>BINARY</td>
<td>字节数组</td>
</tr>
</tbody>
</table><p>对于以上的数据类型，存在数据类型转换的关系</p>
<ol start="2">
<li>
<p>类型的转换<br>
Hive的数据类型类似于java中的数据类型转换，例如咱们使用的是INT数据类型，那INTYINT 会自动转换为INT类型，但是hive不会像java一样进行反向转换</p>
</li>
<li>
<p>CAST 转换操作：<br>
Cast 可以进行显示的数据类型的转换，例如 有一个 “1” 现在需要把字符串类型的1 转换为int类型的 1 可以通过cast进行操作<br>
例如： cast(“1” as INT) 就可以把字符串1 转换为整数1</p>
</li>
</ol>
<h3><a id="DDL_187"></a>DDL数据定义</h3>
<h4><a id="1___HDFS_userhivewarehousedb_188"></a>1.  创建数据库,创建的数据库存储在 HDFS 上的默认路径是/user/hive/warehouse/*.db</h4>
<p>例如： create database mytest;<br>
在创建数据库的时候，为了避免创建出错，可以使用IF NOT EXISTS 先判断要创建的数据库是否存在<br>
例如：create database if not exists test2;</p>
<h4><a id="2____192"></a>2.  删除数据库 以下官网提供的语法</h4>
<pre><code>DROP (DATABASE|SCHEMA) [IF EXISTS] database_name [RESTRICT|CASCADE];
CASCADE：删除一个非空的数据库
</code></pre>
<h4><a id="3__DDL__create_drop_truncate_197"></a>3.  表的DDL 定义 （create ,drop ,truncate）</h4>
<p>在创建表的时候，可以分为管理表，和外部表，管理表对数据存在管理权，删除的时候会删除到元数据，以及保存在HDFS上的数据，而外部表由于没有管理权不会删除掉HDFS上保存的数据，但是会删除该表的元数据<br>
EXTERNAL 创建外部表，在建表的同时指定一个路径通过location关键字指定该表要去加载的路径在HDFS上的位置</p>
<pre><code>create EXTERNAL table student4(id int,name string) 
 row format delimited fields terminated by '\t'
 stored as textfile 
 location '/user/hive/warehouse/student';
</code></pre>
<p>对于管理表来说，默认创建的表就为管理表</p>
<h5><a id="_207"></a>分区表：</h5>
<p>使用关键字PARTITIONED BY 定义的分区表，分区表实际上就是在HDFS上创建一个个的独立的文件夹,该文件夹下保存的就是为分区之后的数据文件 ,一般来说进行条件查询的都是使用where语句 ，那就可以通过where语句查询分区之后的数据</p>
<ul>
<li>分区表的创建语法：</li>
</ul>
<pre><code>create table dept_partion(deptno int,dname string) PARTITIONED BY (month string)
 row format delimited fields terminated by '\t';
</code></pre>
<ul>
<li>接下来加载数据到分区表中，需要把dept 数据文件上传到linux 文件系统 /data/ 目录下</li>
</ul>
<pre><code>load data local inpath '/data/dept.txt' into table dept_partion partition(month='201811');
</code></pre>
<h5><a id="_218"></a>查询分区表中的数据：</h5>
<ul>
<li>单分区查询：只查询一个分区</li>
</ul>
<pre><code>select * from dept_partion where month='201811';
</code></pre>
<ul>
<li>多分区查询</li>
</ul>
<pre><code class="prism language-select"> union
 select * from dept_partion where month='201812';
</code></pre>
<ul>
<li>增加分区：</li>
</ul>
<pre><code>alter table dept_partion add partition(month='201810');
</code></pre>
<ul>
<li>删除分区：</li>
</ul>
<pre><code>alter table dept_partion drop partition(month='201810');
</code></pre>
<ul>
<li>查看分区：</li>
</ul>
<pre><code>show partitions dept_partion;
</code></pre>
<ul>
<li>查看表结构 desc  进行查看，但是不是详细的信息，如果要查看表中详细的信息则可以使用</li>
</ul>
<pre><code>desc formatted dept_partion;
</code></pre>
<ul>
<li>创建两个分区：</li>
</ul>
<pre><code>create table dept_partion2(deptno int,dname string) PARTITIONED BY (month string,day string)
 row format delimited fields terminated by '\t';
</code></pre>
<ul>
<li>加载数据到两个分区字段的分区表中：</li>
</ul>
<pre><code>load data local inpath '/data/dept.txt' into table dept_partion2 partition(month='201810',day='18');
</code></pre>
<h5><a id="_HDFS_254"></a>分表表加载数据的方式二： 先上传数据到HDFS上之后在和分区表进行关联</h5>
<ol>
<li>创建要上传数据的目录</li>
</ol>
<pre><code>dfs -mkdir -p /user/hive/warehouse/dept_partion2/month=201809/day=1;
</code></pre>
<ol start="2">
<li>上传数据到该目录下</li>
</ol>
<pre><code>dfs -put /data/dept.txt /user/hive/warehouse/dept_partion2/month=201809/day=1;
</code></pre>
<p>查询该表表 发现没有查询到该表下的数据<br>
3. 执行关联元数据的命令</p>
<pre><code>msck repair table dept_partion2;
</code></pre>
<ol start="4">
<li>查询分区表中的数据</li>
</ol>
<pre><code>select * from  dept_partion2 where month=201809 and day=1;
</code></pre>
<h5><a id="_274"></a>上传数据之后增加分区：</h5>
<ol>
<li>先创建分区目录</li>
</ol>
<pre><code>dfs -mkdir -p /user/hive/warehouse/dept_partion2/month=201809/day=2;
</code></pre>
<ol start="2">
<li>上传数据到分区目录</li>
</ol>
<pre><code>dfs -put /data/dept.txt /user/hive/warehouse/dept_partion2/month=201809/day=2;
</code></pre>
<ol start="3">
<li>增加分区</li>
</ol>
<pre><code>alter table dept_partion2 add partition(month='201809',day='2');
</code></pre>
<ol start="4">
<li>查询数据</li>
</ol>
<pre><code>select * from  dept_partion2 where month=201809 and day=2;
</code></pre>
<h4><a id="_294"></a>修改表：</h4>
<ol>
<li>修改表名称</li>
</ol>
<pre><code>alter table dept_partion rename to dept_partion3;
</code></pre>
<ol start="2">
<li>修改列</li>
</ol>
<pre><code>alter table dept_partion3 change column  dname dnames string ;
</code></pre>
<ol start="3">
<li>增加列</li>
</ol>
<pre><code>alter table dept_partion3 add columns (depts string);
</code></pre>
<ol start="4">
<li>替换列</li>
</ol>
<pre><code>alter table dept_partion3 replace columns(deptno int ,dname string);
</code></pre>
<ol start="5">
<li>删除表 drop  table 表名称  表的结构也会被删除掉</li>
<li>清空表中的数据</li>
</ol>
<pre><code class="prism language-truncate">Truncate 只清空表中的数据，表的结构不删除
</code></pre>

            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>