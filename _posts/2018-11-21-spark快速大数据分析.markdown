---
layout:     post
title:      spark快速大数据分析
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p></p><h1><strong><span style="font-size:18px;">序</span></strong></h1><p>spark是一个通用计算框架。</p><p>spark是一个大一统的软件栈。</p><p>spark是大数据处理引擎。</p><p>—————————</p><p><strong style="font-size:28px;">前言</strong></p><p>spark主要有三个优点：</p><p></p><ol><li>spark好用，高级API剥离了对集群本身的关注，可以专注于计算本身。</li><li>spark很快，支持交互式使用和复杂算法。</li><li>spark是通用引擎，可以用于各种运算：sql查询、文本处理、机器学习（MLib机器学习库）等。</li></ol><p>—————————</p><h1>spark数据分析导论</h1><p>spark是一个实现快速而通用的集群计算的平台。</p><p>spark的一个主要特点之一就是速度快，因为在内存中进行计算；不过即使是必须在磁盘上的复杂计算，spark依然比mapreduce更高效。</p><p>spark适用于各类原先需要多种不同的分布式平台的场景：批处理、迭代算法、交互式查询、流处理。</p><p>spark的核心是一个对很多计算任务组成的、运行在多个工作机器或者是一个计算集群上的应用进行调度、分发以及监控的计算引擎。</p><p>——————</p><p>spark组件：</p><p></p><ul><li>spark core基本功能</li><li>spark sql结构化数据</li><li>spark streaming实时计算：对实时数据进行流式计算</li><li>数据流：网页服务器日志、用户提交的状态更新组成的消息队列等等</li><li>MLib机器学习：分类、回归、聚类、协同过滤等等</li><li>GraphX图计算</li><li>集群管理器（cluster manager）：Hadoop YARN、Apache Mesos、独立调度器</li></ul><p>——————</p><p>spark的用户和用途</p><p>数据科学任务：数据分析</p><p>数据处理应用：软件开发</p><p>——————</p><p>spark的存储层次：</p><p>spark不仅可以将任何Hadoop分布式文件系统（HDFS）上的文件读取为分布式数据集，也可以支持其他支持Hadoop接口的系统，如本地文件、Hive、HBase等。即，Hadoop并非spark的必要条件，spark支持任何实现了Hadoop接口的存储结构，包括文本文件等。</p><p><br></p>            </div>
                </div>