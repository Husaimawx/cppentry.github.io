---
layout:     post
title:      记一次Kafka不能消费故障
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/lingbo229/article/details/83538581				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h2>背景：</h2>

<p>kafka集群机器升级，使得部分spark Streaming不能消费读取数据</p>

<h2>问题原因：</h2>

<p>kafka会自动创建一个默认的topic __consumer_offsets，用于保存offset到Kafka系统</p>

<p>由于我们集群kafka节点有7个，当逐渐的下架上架机器后，使得__consumer_offsets  Partition 出现Leader为-1</p>

<p><img alt="" class="has" height="239" src="https://img-blog.csdnimg.cn/20181030110614669.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpbmdibzIyOQ==,size_16,color_FFFFFF,t_70" width="705"></p>

<p>Kafka将直连Kafka的消费信息记录到了__consumer_offset这个topic中，虽然这个topic在我们的集群中复制因子为3，但当partition所在的3个副本所在的机器都下架后，便会出现Leader为-1的情况 </p>

<h2>解决方法：</h2>

<p>方法一：设置auto.create.topics.enable =true，删除topic __consumer_offset即可。 （这种方法只适合于offset存储到外部系统的情况，否则会丢失offset信息），删除后，重启Kafka，会自动重建__consumer_offset，Spark Streaming消费读取数据正常。</p>

<p>方法二：事前预防，在做Kafka集群升级的时候，需要对__consumer_offset也进行数据迁移，迁移方法见</p>

<p><a href="https://blog.csdn.net/lingbo229/article/details/83309208" rel="nofollow">https://blog.csdn.net/lingbo229/article/details/83309208</a></p>            </div>
                </div>