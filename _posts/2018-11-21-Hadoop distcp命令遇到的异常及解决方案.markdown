---
layout:     post
title:      Hadoop distcp命令遇到的异常及解决方案
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/qq_29829081/article/details/79605028				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <div style="text-align:left;line-height:1.75;font-size:14px;"><strong>1 异常信息</strong></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="color:#ff0000;">         Caused by: java.io.IOException: Mismatch in length of source:hdfs://xxx and target:hdfs://xxx</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><strong>2 原因</strong></div><div style="text-align:left;line-height:1.75;font-size:14px;">        需要远程复制的文件没有关闭，还处于写的状态。</div><div style="text-align:left;line-height:1.75;font-size:14px;"><strong><br></strong></div><div style="text-align:left;line-height:1.75;font-size:14px;"><strong>3 解决方案：</strong></div><p></p><div style="text-align:left;line-height:1.75;font-size:14px;"><strong><span style="color:#000000;">1） 检查文件状态</span></strong></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="color:#ff0000;">hdfs fsck</span> hdfs://10.10.10.10:80/flume/xxx/xxxxxxxx/day=2018-03-12/xxx.2018-03-12.1520841735508                       </div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;">Connecting to namenode via http://xxx:50070/fsck?ugi=hadoop&amp;path=%2Fflume%2Fxxx%xxx%2Fday%3D2018-03-12%xxx.2018-03-12.1520841735508</div><div style="text-align:left;line-height:1.75;font-size:14px;">FSCK started by hadoop (auth:SIMPLE) from /139.5.108.244 for path /flume/xxx/xxx/day=2018-03-12/xxx.2018-03-12.1520841735508 at Tue Mar 13 16:12:39 CST 2018</div><div style="text-align:left;line-height:1.75;font-size:14px;">Status: HEALTHY</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Total size:    0 B (Total open files size: 420 B)</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Total dirs:    0</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Total files:   0</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Total symlinks:                0<span style="color:#ff0000;"> (Files currently being written: 1)</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"> Total blocks (validated):      0<span style="color:#ff0000;"> (Total open file blocks (not validated): 1)</span></div><div style="text-align:left;line-height:1.75;font-size:14px;"> Minimally replicated blocks:   0</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Over-replicated blocks:        0</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Under-replicated blocks:       0</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Mis-replicated blocks:         0</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Default replication factor:    3</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Average block replication:     0.0</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Corrupt blocks:                0</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Missing replicas:              0</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Number of data-nodes:          8</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Number of racks:               1</div><div style="text-align:left;line-height:1.75;font-size:14px;">FSCK ended at Tue Mar 13 16:12:39 CST 2018 in 2 milliseconds</div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;">The filesystem under path '/flume/xxx/xxx/day=2018-03-12/xxx.2018-03-12.1520841735508' is HEALTHY</div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><strong><span style="color:#000000;">2） 关闭文件</span></strong></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="color:#ff0000;">hdfs debug recoverLease -path</span> hdfs://10.10.10.10:8020/flume/xxx/xxx/day=2018-03-12/xxx.2018-03-12.1520841735508</div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;">可能会失败：</div><div style="text-align:left;line-height:1.75;font-size:14px;">recoverLease returned false.</div><div style="text-align:left;line-height:1.75;font-size:14px;">Giving up on recoverLease for hdfs://10.10.10.10:8020/flume/xxx/xxx/day=2018-03-12/xxx.2018-03-12.1520841735508 after 1 try.</div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;">尝试再次关闭：</div><div style="text-align:left;line-height:1.75;font-size:14px;">recoverLease SUCCEEDED on hdfs://<span style="font-size:14px;text-align:left;">10.10.10.10</span>:8020/flume/xxx/xxx/day=2018-03-12/xxx.2018-03-12.1520841735508</div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><strong><span style="color:#000000;">3）再次检查状态</span></strong></div><div style="text-align:left;line-height:1.75;font-size:14px;">Connecting to namenode via http://xxx:50070/fsck?ugi=hadoop&amp;path=%2Fflume%2Fxxx%xxx%2Fday%3D2018-03-12%xxx.2018-03-12.1520841735508</div><div style="text-align:left;line-height:1.75;font-size:14px;">FSCK started by hadoop (auth:SIMPLE) from /xx.xx.xx.xx for path /flume/xxx/xxx/day=2018-03-12/xxx.2018-03-12.1520841735508 at Tue Mar 13 16:19:57 CST 2018</div><div style="text-align:left;line-height:1.75;font-size:14px;">.Status: HEALTHY</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Total size:    838 B</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Total dirs:    0</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Total files:   1</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Total symlinks:                0</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Total blocks (validated):      1 (avg. block size 838 B)</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Minimally replicated blocks:   1 (100.0 %)</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Over-replicated blocks:        0 (0.0 %)</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Under-replicated blocks:       0 (0.0 %)</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Mis-replicated blocks:         0 (0.0 %)</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Default replication factor:    3</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Average block replication:     3.0</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Corrupt blocks:                0</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Missing replicas:              0 (0.0 %)</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Number of data-nodes:          8</div><div style="text-align:left;line-height:1.75;font-size:14px;"> Number of racks:               1</div><div style="text-align:left;line-height:1.75;font-size:14px;">FSCK ended at Tue Mar 13 16:19:57 CST 2018 in 2 milliseconds</div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;">The filesystem under path '/flume/xxx/xxx/day=2018-03-12/xxx.2018-03-12.1520841735508' is HEALTHY</div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><strong><span style="color:#000000;">4） 再次复制</span></strong></div><div style="text-align:left;line-height:1.75;font-size:14px;"> <span style="color:#ff0000;">hadoop distcp -bandwidth 15 -m 50 -pb </span>hdfs://10.10.10.10:8020//flume/xxx/xxx/day=2018-03-12 /flume/xxx/xxx/day=2018-03-12     </div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div><div style="text-align:left;line-height:1.75;font-size:14px;"><span style="color:#ff0000;">* 注意：在使用该命令时最好指定带宽限制（<span style="font-size:14px;text-align:left;">-bandwidth</span>），<span style="font-family:Arial, sans-serif;font-size:14px;text-align:left;background-color:rgb(255,255,255);">同时拷贝的最大数目</span>（<span style="font-size:14px;text-align:left;">-m</span>）。我在首次迁移数据时没有设置，一次性迁移了好几个月的数据，导致流量超标。 </span></div><div style="text-align:left;line-height:1.75;font-size:14px;"><br></div>            </div>
                </div>