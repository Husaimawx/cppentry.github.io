---
layout:     post
title:      《走进大数据之Hive入门》学习笔记（1）
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/to_Baidu/article/details/52432217				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h2 id="hive相关学习指南"><strong>Hive相关学习指南</strong></h2>

<p>Hive官网：<a href="http://hive.apache.org" rel="nofollow">http://hive.apache.org</a> <br>
Hive入门指南：<a href="http://wiki.apache.org/hadoop/Hive/GettingStarted" rel="nofollow">http://wiki.apache.org/hadoop/Hive/GettingStarted</a> <br>
HQL查询语言指南：<a href="http://wiki.apache.org/hadoop/Hive/HiveQL" rel="nofollow">http://wiki.apache.org/hadoop/Hive/HiveQL</a> <br>
演示文稿：<a href="http://wiki.apache.org/hadoop/Hive/Presentations" rel="nofollow">http://wiki.apache.org/hadoop/Hive/Presentations</a></p>

<hr>



<h2 id="第一章-概述"><strong>第一章 概述</strong></h2>



<h3 id="1-1-课程概述"><strong>1-1    课程概述</strong></h3>

<p><strong>Hive是基于Hadoop HDFS之上的数据仓库。</strong> <br>
数据仓库：本质上就是一个数据库。但有别于我们通常意义上的数据库 <br>
Hive安装有3种方式。 <br>
Hadoop和Hive都是基于Linux操作系统构建的，所以要有熟悉掌握Linux下操作命令。</p>



<h3 id="1-2-数据仓库简介"><strong>1-2    数据仓库简介</strong></h3>

<p>①数据仓库是一个面向主题的、集成的、不可更新的、随时间不变化的数据集合，它用于支持企业或组织的决策分析处理。 <br>
面向主题：主题是指用户使用数据仓库时关心的重点内容。 <br>
集成的：数据仓库可将不同类型数据库管理系统中的数据集成起来保存。 <br>
不可更新的：数据仓库一般只做数据查询，不做更新、删除等操作。 <br>
②<strong>数据仓库的结构和建立过程：数据源（可能来源于业务数据库系统、文档资料和其他数据）——&gt;数据存储及管理（ETL：抽取、转换、装载）——&gt;数据仓库引擎（不同的服务器有不同的功能）——&gt;前端展示（数据查询、数据报表、数据分析、各类应用）</strong> <br>
<strong>OLTP应用：</strong>典型应用-银行转账 <br>
<strong>OLAP应用：</strong>典型应用-商品推荐系统 <br>
<strong>数据仓库的数据模型：</strong>星型模型和雪花模型</p>



<h3 id="1-3-什么是hive"><strong>1-3    什么是Hive</strong></h3>

<p>①Hive是建立在Hadoop HDFS上的数据仓库基础架构。而传统的Oracle或MySQL数据仓库是直接建立在Oracle或MySQL数据库之上的。 <br>
②Hive可以用来进行数据提取、转化、加载（ETL）。 <br>
③Hive定义了简单的类似SQL查询语言，称为HQL它允许熟悉SQL的用户查询数据。 <br>
④Hive允许熟悉MapReduce开发者的开发自定义的mapper和reducer来处理內建mapper和reducer无法完成的复杂的分析工作。 <br>
⑤Hive的SQL解析引擎，它将SQL语句转移成M/R Job然后在Hadoop上执行。 <br>
⑥Hive的表其实就是HDFS的目录/文件。</p>

<hr>



<h2 id="第二章-hive的体系结构"><strong>第二章 Hive的体系结构</strong></h2>



<h3 id="2-1-hive的体系结构之元数据"><strong>2-1  Hive的体系结构之元数据</strong></h3>

<p>Hive讲元数据存储在数据库中（metastore），支持mysql、derby、oracle等传统数据库，<strong>默认为derby</strong>。 <br>
Hive中元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在的目录等。 <br>
元数据被默认创建在derby数据库中，以表的形式保存数据。表的元信息、列元信息。</p>



<h3 id="2-2-hive的体系结构之hql的执行过程"><strong>2-2  Hive的体系结构之HQL的执行过程</strong></h3>

<p><strong>①解析器、编译器、优化</strong>器完成HQL查询语句从词法分析、语法分析、编译、优化以及查询计划（plan）的生成。生成的查询计划存储在HDFS中，并在随后有MapReduce调用执行。 <br>
过程：HQL语句——》解析器：词法分析——》编译器：生成HQL的执行计划——》优化器：生成最优执行计划——》执行。</p>

<p>②在oracle数据库中： <br>
执行计划 <br>
explanin plan for select * from emp where deptno10 <br>
查询执行计划 <br>
select * from table(dbms_xplan.display) <br>
全表扫描 <br>
创建索引 <br>
create index myindex on emp(deptno)</p>

<p>Hive的执行计划跟上面的oracle的执行计划类似。</p>



<h3 id="2-3-hive体系结构"><strong>2-3  Hive体系结构</strong></h3>

<p>•hadoop <br>
    –用HDFS进行存储，利用mapreduce进行计算。 <br>
•元数据存储（metastroe） <br>
    –通常存储在关系数据库中，如mysql，derby。</p>

<p>Hive Driver：驱动，包括编译器、解析器、优化器。 <br>
<strong>访问接口：</strong>①CLI：Command Line Interface；②通过JDBC/ODBC连接Thrift Server在连接驱动；③Web Console 控制台（只能查询）</p>

<hr>



<h2 id="第三章-hive的安装"><strong>第三章 Hive的安装</strong></h2>



<h3 id="3-1-hive的安装模式"><strong>3-1  Hive的安装模式</strong></h3>

<p>①Apache的hive官网：hive.apache.org中下载hive. <br>
bin.tar包为安装包 <br>
src.tar为源代码，可用来编译hive的可执行程序，通过源文件生成打包生成基于web的图形化管理工具，再部署到hive中，才可使用该图形化管理工具。 <br>
Hive的源码中集成有WEB UI管理工具, 需要自行编译发布到Hive环境中. 注意Hive的安装包中并不会集成WEB U <br>
②安装hive之前要先安装hadoop，hadoop可以是单机环境、伪分布环境和集群环境中的一种。 <br>
Hive的安装有三种模式：嵌入模式、本地模式和远程模式。 <br>
1. <strong>嵌入模式</strong>： 即使用Hive自带的Derby数据库, 将元数据及其信息存储在Derby数据库上面, 但有个缺点, Derby在同一时间只能接受一个连接（即只能允许一个人对hive进行操作）, 故一般用作演示 <br>
2. <strong>本地模式:</strong> 将元数据存储到同一机器中的MySQL数据库当中, 此模式一般用于开发与测试 <br>
3. <strong>远程模式</strong>: 即是本地模式的升级版, 可将Hive的元数据存储到其它环境（可以是不同操作系统）机器上的MySQL当中.</p>



<h3 id="3-2-hive安装之嵌入模式"><strong>3-2  Hive安装之嵌入模式</strong></h3>

<pre><code>只需要解压Hive安装包, 然后直接执行bin目录的hive脚本, 便会自动创建一个metastore_db目录来保存元数据. 注意: 这个metastore_db目录是自动创建在执行hive时的当前目录下面, 即在嵌入模式中任意一个目录下执行hive都会创建此目录.
</code></pre>



<h3 id="3-3-hive安装之远程模式和本地模式"><strong>3-3  Hive安装之远程模式和本地模式</strong></h3>

<p>远程配置HIVE；命名hive-site.xml，要配置mysql的url、驱动、用户名、密码。</p>

<hr>



<h2 id="第四章-hive的管理"><strong>第四章 Hive的管理</strong></h2>



<h3 id="4-1-hive管理之cli方式"><strong>4-1  Hive管理之CLI方式</strong></h3>

<p>进入CLI方式： <br>
①   直接输入#/bin/hive的执行程序 <br>
②或者输入#hive –service cli <br>
退出CLI方式： <br>
①   quit; <br>
②   exit;</p>

<p>常用的CLI的命令： <br>
①   清屏：  Ctrl + L 或者 !clear <br>
②   查看数据仓库中的表：  show tables; <br>
③   查看数据仓库中内置的函数：  show functions; <br>
④   查看表的结构：  desc 表名 <br>
⑤   查看HDFS上的文件：  dfs –ls 目录 <br>
dfs –lsr 目录        （-lsr表示以递归的方式查看子目录） <br>
⑥   执行操作系统的命令：  ! 命令 <br>
⑦   执行HQL语句：  例如select  <strong><em>*  from **</em></strong> <br>
⑧   执行SQL的脚本：  source SQL文件 <br>
⑨   命令“hive –s”:    进入静默模式：不产生hive的调试信息(mapreduce过程)，只显示最后的结果。 <br>
⑩   hive –e ’HQL语句’ : 不进入hive直接执行HQL.</p>



<h3 id="4-2-hive管理之web界面方式"><strong>4-2  Hive管理之web界面方式</strong></h3>

<p>启动web界面方式： <br>
-端口号：9999 <br>
-启动方式：#hive –service hwi &amp; <br>
-通过浏览器来访问：http://</p>

<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>hive.hwi.listen.host<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>0.0.0.0<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>

<span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>hivehwi.listen.port<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>9999<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>

<span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>hive.hwi.war.file<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>lib/hive-hwi.war<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
</code></pre>



<h3 id="4-3-hive管理之远程模式"><strong>4-3  Hive管理之远程模式</strong></h3>

<p>远程服务启动方式： <br>
    -端口号：10000 <br>
    -启动方式：#hive –service hiveserver &amp;     即启动了Hive Thrift Server <br>
<strong>注意</strong>：如果以JDBC或ODBC的程序登录到hive中操作数据时，必须选用远程服务启动方式。</p>

<hr>



<h2 id="第五章-hive的数据类型"><strong>第五章 Hive的数据类型</strong></h2>



<h3 id="5-1-基本数据类型"><strong>5-1     基本数据类型</strong></h3>

<ul>
<li><strong>tinyint/smallint/int/bigint</strong> : 整数类型</li>
<li><strong>float/double</strong> : 浮点数类型</li>
<li><strong>boolean</strong> : 布尔类型</li>
<li><strong>string</strong> : 字符串类型</li>
</ul>



<h3 id="5-2-复杂数据类型"><strong>5-2    复杂数据类型</strong></h3>

<ul>
<li><strong>Array</strong> : 数组类型，由一系列<strong>相同</strong>数据类型的元素组成。</li>
<li><strong>Map</strong> : 集合类型，包含key-value键值对，可以通过key来访问元素。Array与map可以嵌套，比如array</li></ul>

<h3 id="5-3-时间数据类型"><strong>5-3  时间数据类型</strong></h3>

<p><strong>时间类型：</strong> <br>
-   <strong>Data</strong> : 从hive0.12.0开始支持。 <br>
-   <strong>Timestamp</strong> : 从hive0.8.0开始支持。 <br>
<strong>Data与Timestamp的区别</strong>：Data类型描述的是一个特定的日期（不包含时间，即精确到日）：YYYY-MM-DD。而Timestamp是相对于linux基准时间的偏移量，其实就是一个长整型数值，例如要获取系统当前的时间戳可以执行：select unix_timestamp();。  <strong>这两者可以转换</strong>。</p>

<hr>



<h2 id="第六章-hive1的数据模型"><strong>第六章 Hive1的数据模型</strong></h2>



<h3 id="6-1-hive的数据存储"><strong>6-1  Hive的数据存储</strong></h3>

<ul>
<li>基于HDFS</li>
<li>没有专门的数据存储格式，可以用.txt、.csv，默认情况下可以用’\t’作为分隔符</li>
<li>存储结构主要包括：数据库、文件、表、视图。</li>
<li>可以直接加载文本文件（.txt文件等）</li>
<li>创建表时，制定hive数据的列分隔符与行分隔符</li>
</ul>

<p>表： <br>
-   Table  内部表 <br>
-   Partition  分区表 <br>
-   External table  外部表 <br>
-   Bucket table  桶表 <br>
视图</p>



<h3 id="6-2-内部表"><strong>6-2  内部表</strong></h3>

<p>内部表（Table） <br>
-   与数据库中的table 在概念上是类似的。 <br>
-   每一个table在hive中都有一个相应的目录存储数据。 <br>
-   所有的table数据（不包括external table）都保存在这个目录中。 <br>
-   删除表时，元数据和数据都会被删除。 <br>
如果没指定保存的位置，则默认保存在user/hive/warehouse中 <br>
指定行分隔符：row format delimited fileds terminated by ‘,’; <br>
修改表添加新的一列：alter table t1 add columns(列名 数据类型); <br>
删除表时：如果开启了Hadoop的回收站功能，则drop表后会放在.trash，也就是说可以通过一定方式找回删除的表。</p>



<h3 id="6-3-分区表"><strong>6-3  分区表</strong></h3>

<p>分区表（Partition） <br>
-   Partition对应于数据库的Partition列的密集索引。 <br>
-   在hive中，表中的一个Partition对应于表下的一个目录，所有的Partition的数据都存储在对应的目录中。 <br>
作用：<strong>降低扫描的记录数，提高查询效率</strong>。当数据量很大的时候，我们就很需要创建分区。</p>

<p>可以通过explain语句查看HQL的执行计划，读执行计划STAGE PLANS的方式：从下往上，从右往左读。 <br>
Oracle中也有分区表，五种分区表。</p>



<h3 id="6-4-外部表"><strong>6-4  外部表</strong></h3>

<p>外部表（external table） <br>
-   指向已经在HDFS中存在的数据，可以创建Partition。 <br>
-   它和内部表在元数据的组织上是相同的，而实际数据的存储则有较大的差异 <br>
-   外部表<strong>只有一个过程</strong>，加载数据和创建表同时完成，并不会移动到数据仓库目录中，只是与外部数据建立一个链接。当删除一个外部表时，仅仅删除该链接。</p>



<h3 id="6-5-桶表"><strong>6-5  桶表</strong></h3>

<p>桶表（bucket table） <br>
-   桶表是对数据进行哈希取值，然后放到不同文件中存储。 <br>
作用：减低系统热块，提高查询效率。</p>

<p>create table bucket_table <br>
(id int,name string) <br>
clustered by(name) into 3 buckets    //按name进行哈希，哈希到3个表中 <br>
row format delimited <br>
fields terminated by ‘\t’; <br>
clustered要在row的前面，否则报错。</p>



<h3 id="6-6-视图"><strong>6-6  视图</strong></h3>

<p>视图（view） <br>
-   视图是一种<strong>虚表（不存数据）</strong>，是一个逻辑概念；可以跨越多张表。 <br>
-   首先视图是一张表，操作视图和操作表的方式是一样的。 <br>
-   视图建立在已有表的基础上，视图赖以建立的这些表称为<strong>基表</strong>。 <br>
-   视图可以<strong>简化复杂的查询</strong>。 <br>
-   <strong>hive的视图不存储数据的，oracle和mysql中的视图可以存储数据，称为物化视图.</strong> <br>
例如：查询员工信息：员工号，姓名，月薪，年薪，部门名称。（需要主外键关联员工表和部门表） <br>
create view empinfo <br>
as <br>
select e.empno, e.ename, e.sal, e.sal*12 annlsal, d.dname <br>
from emp e, dept d <br>
where e.deptno = d.deptno;</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>