---
layout:     post
title:      Kafka学习整理一(基础概念)
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/LOUISLIAOXH/article/details/51516823				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h1 id="kafka基础概念">Kafka基础概念</h1>

<p><strong>Kafka中包含以下基础概念</strong> <br>
1. Topic(话题)：Kafka中用于区分不同类别信息的类别名称。由producer指定 <br>
2. Producer(生产者)：将消息发布到Kafka特定的Topic的对象(过程) <br>
3. Consumers(消费者)：订阅并处理特定的Topic中的消息的对象(过程) <br>
4. Broker(Kafka服务集群)：已发布的消息保存在一组服务器中，称之为Kafka集群。集群中的每一个服务器都是一个代理(Broker). 消费者可以订阅一个或多个话题，并从Broker拉数据，从而消费这些已发布的消息。 <br>
5.  Partition(分区)：Topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset） <br>
6.  Message：消息，是通信的基本单位，每个producer可以向一个topic（主题）发布一些消息。</p>



<h2 id="消息">消息</h2>

<p>消息由一个固定大小的报头和可变长度但不透明的字节阵列负载。报头包含格式版本和CRC32效验和以检测损坏或截断</p>



<h3 id="消息格式">消息格式</h3>



<pre class="prettyprint"><code class=" hljs livecodeserver"><span class="hljs-number">1.</span> <span class="hljs-number">4</span> <span class="hljs-keyword">byte</span> CRC32 <span class="hljs-operator">of</span> <span class="hljs-operator">the</span> message
<span class="hljs-number">2.</span> <span class="hljs-number">1</span> <span class="hljs-keyword">byte</span> <span class="hljs-string">"magic"</span> identifier <span class="hljs-built_in">to</span> allow <span class="hljs-built_in">format</span> changes, <span class="hljs-built_in">value</span> is <span class="hljs-number">0</span> <span class="hljs-operator">or</span> <span class="hljs-number">1</span>
<span class="hljs-number">3.</span> <span class="hljs-number">1</span> <span class="hljs-keyword">byte</span> <span class="hljs-string">"attributes"</span> identifier <span class="hljs-built_in">to</span> allow annotations <span class="hljs-command"><span class="hljs-keyword">on</span> <span class="hljs-title">the</span> <span class="hljs-title">message</span> <span class="hljs-title">independent</span> <span class="hljs-title">of</span> <span class="hljs-title">the</span> <span class="hljs-title">version</span></span>
   bit <span class="hljs-number">0</span> ~ <span class="hljs-number">2</span> : Compression codec
       <span class="hljs-number">0</span> : no compression
       <span class="hljs-number">1</span> : gzip
       <span class="hljs-number">2</span> : snappy
       <span class="hljs-number">3</span> : lz4
   bit <span class="hljs-number">3</span> : Timestamp type
       <span class="hljs-number">0</span> : <span class="hljs-built_in">create</span> <span class="hljs-built_in">time</span>
       <span class="hljs-number">1</span> : <span class="hljs-built_in">log</span> append <span class="hljs-built_in">time</span>
   bit <span class="hljs-number">4</span> ~ <span class="hljs-number">7</span> : reserved
<span class="hljs-number">4.</span> (可选) <span class="hljs-number">8</span> <span class="hljs-keyword">byte</span> timestamp only <span class="hljs-keyword">if</span> <span class="hljs-string">"magic"</span> identifier is greater than <span class="hljs-number">0</span>
<span class="hljs-number">5.</span> <span class="hljs-number">4</span> <span class="hljs-keyword">byte</span> key <span class="hljs-built_in">length</span>, containing <span class="hljs-built_in">length</span> K
<span class="hljs-number">6.</span> K <span class="hljs-keyword">byte</span> key
<span class="hljs-number">7.</span> <span class="hljs-number">4</span> <span class="hljs-keyword">byte</span> payload <span class="hljs-built_in">length</span>, containing <span class="hljs-built_in">length</span> V
<span class="hljs-number">8.</span> V <span class="hljs-keyword">byte</span> payload</code></pre>



<h2 id="log日志">Log(日志)</h2>

<ol>
<li>日志是一个只能增加的，完全按照时间排序的一系列记录。我们可以给日志的末尾添加记录，并且可以从左到右读取日志记录。每一条记录都指定了一个唯一的有一定顺序的日志记录编号。详细见<a href="http://www.36dsj.com/archives/6387" rel="nofollow">首席工程师揭秘LinkedIn大数据后台</a></li>
<li>每个日志文件都是“log entries”序列，每一个log entry包含一个4字节整型数（值为N），其后跟N个字节的消息体。每条消息都有一个当前partition下唯一的64字节的offset，它指明了这条消息的起始位置</li>
<li>这个“log entries”并非由一个文件构成，而是分成多个segment，每个segment名为该segment第一条消息的offset和“.kafka”组成。另外会有一个索引文件，它标明了每个segment下包含的log entry的offset范围。 <br>
<img src="https://kafka.apache.org/images/kafka_log.png" alt="这里写图片描述" title=""></li>
</ol>



<h2 id="topic-partition">Topic &amp; Partition</h2>

<ol>
<li>为了使得Kafka的吞吐率可以水平扩展，物理上把topic分成一个或多个partition，每个partition在物理上对应一个文件夹，该文件夹下存储这个partition的所有消息和索引文件。</li>
<li>每一个分区都是一个顺序的、不可变的消息队列， 并且可以持续的添加。分区中的消息都被分配了一个序列号，称之为偏移量(64字节的offset),在每个分区中此偏移量都是唯一的</li>
<li>因为每条消息都被append到该partition中，是顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）</li>
<li>每一条消息被发送到broker时，会根据paritition规则选择被存储到哪一个partition。如果partition规则设置的合理，所有消息可以均匀分布到不同的partition里，这样就实现了水平扩展。（如果一个topic对应一个文件，那这个文件所在的机器I/O将会成为这个topic的性能瓶颈，而partition解决了这个问题）。在创建topic时可以在$KAFKA_HOME/config/server.properties中指定这个partition的数量(如下所示)，当然也可以在topic创建之后去修改parition数量</li>
<li>在发送一条消息时，可以指定这条消息的key，producer根据这个key和partition机制来判断将这条消息发送到哪个parition。paritition机制可以通过指定producer的paritition. class这一参数来指定，该class必须实现kafka.producer.Partitioner接口。本例中如果key可以被解析为整数则将对应的整数与partition总数取余，该消息会被发送到该数对应的partition。（每个parition都会有个序号）</li>
<li>key相同的消息会被发送并存储到同一个partition里，而且key的序号正好和partition序号相同。（partition序号从0开始，本例中的key也正好从0开始）</li>
</ol>



<h2 id="offset">offset</h2>

<ol>
<li>在每个分区中此偏移量都是唯一的</li>
<li>消费者所持有的仅有的元数据就是这个偏移量，也就是消费者在这个log中的位置。 这个偏移量由消费者控制。</li>
<li>正常情况当消费者消费消息的时候，偏移量也线性的的增加。但是实际偏移量由消费者控制，消费者可以将偏移量重置为更老的一个偏移量，重新读取消息。</li>
<li>一个消费者的操作不会影响其它消费者对此log的处理</li>
</ol>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>