---
layout:     post
title:      Spark 1.5.1客户端安装
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/hutao_hadoop/article/details/52693504				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="background-color:inherit;"><span style="font-size:18px;background-color:inherit;">安装spark客户端</span></span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">1、将spark-1.5.1-bin-hadoop2.4.tgz使用WinSCP上传到/usr/local目录下。</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">2、解压缩spark包：tar -zxvf spark-1.5.1-bin-hadoop2.4.tgz。</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">3、重命名spark目录：mv spark-1.5.1-bin-hadoop2.4 spark</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">4、修改spark环境变量</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">vi ~/.bashrc</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">export SPARK_HOME=/usr/local/spark</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">export PATH=$SPARK_HOME/bin</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="line-height:1.5;background-color:inherit;">source ~/.bashrc</span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><br style="background-color:inherit;"></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="line-height:1.5;background-color:inherit;"><span style="background-color:inherit;"><span style="font-size:18px;background-color:inherit;">修改spark-env.sh文件</span></span></span></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">1、cd /usr/local/spark/conf</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">2、cp spark-env.sh.template spark-env.sh</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">3、vi spark-env.sh</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">export JAVA_HOME=/usr/java/latest</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">export SCALA_HOME=/usr/local/scala</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">export HADOOP_HOME=/usr/local/hadoop</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><span style="line-height:1.5;background-color:inherit;">export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop</span> </div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><br style="background-color:inherit;"></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">要把hive-site.xml拷贝到spark/conf 否则spark读不到hive表</div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;"><br style="background-color:inherit;"></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">
<div><span style="background-color:inherit;"><span style="font-size:18px;background-color:inherit;">设置</span><span style="font-size:18px;background-color:inherit;">HistoryServer：</span></span></div>
<div>
<div>spark-defaults.conf</div>
<div><br style="background-color:inherit;"></div>
<div>spark.eventLog.enabled  true</div>
<div>spark.eventLog.dir      hdfs://192.168.0.103:9000/spark-events</div>
<div>spark.eventLog.compress true</div>
<div><br style="background-color:inherit;"></div>
<div>spark-env.sh</div>
<div><br style="background-color:inherit;"></div>
<div>export SPARK_HISTORY_OPTS="-Dspark.history.ui.port=18080 -Dspark.history.retainedApplications=50 -Dspark.history.fs.logDirectory=hdfs://192.168.0.103:9000/spark-events"</div>
<div><br style="background-color:inherit;"></div>
<div><span style="color:#ff0000;background-color:inherit;">务必预先创建好hdfs://192.168.0.103:9000/spark-events目录</span></div>
<div><span style="color:#ff0000;background-color:inherit;">而且要注意，spark.eventLog.dir与spark.history.fs.logDirectory指向的必须是同一个目录</span></div>
<div><span style="color:#ff0000;background-color:inherit;">因为spark.eventLog.dir会指定作业事件记录在哪里，spark.history.fs.logDirectory会指定从哪个目录中去读取作业数据</span></div>
<div><br style="background-color:inherit;"></div>
<div>启动HistoryServer: ./sbin/start-history-server.sh</div>
<div><br style="background-color:inherit;"></div>
<div>访问地址: 192.168.0.103:18080</div>
</div>
<br style="background-color:inherit;"></div>
<div style="font-family:'微软雅黑';font-size:14px;line-height:21px;">
<div>
<div style="background-color:inherit;"><span style="background-color:inherit;"><span style="font-size:18px;background-color:inherit;">standalone模式下使用动态资源分配</span></span></div>
</div>
<div>
<div>启动shuffle-service，他默认的端口号7337</div>
<div>./sbin/.start-shuffle-service.sh</div>
<div><br style="background-color:inherit;"></div>
<div>提交的时候加入以下3个参数</div>
<div>--conf spark.shuffle.service.enabled=true \</div>
<div>--conf spark.dynamicAllocation.enabled=true \</div>
<div>--conf spark.shuffle.service.port=7337 \</div>
<div><br style="background-color:inherit;"></div>
<div>1、启动external shuffle service</div>
<div>2、启动spark-shell，启用动态资源分配</div>
<div>3、过60s，发现打印日志，说executor被removed，executor进程也没了</div>
<div>4、然后动手写一个wordcount程序，最后提交job的时候，会动态申请一个新的executor，出来一个新的executor进程</div>
<div>5、然后整个作业执行完毕，证明external shuffle service+动态资源分配，流程可以走通</div>
<div>6、再等60s，executor又被释放掉</div>
</div>
</div>
            </div>
                </div>