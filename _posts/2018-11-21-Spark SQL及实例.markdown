---
layout:     post
title:      Spark SQL及实例
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h2 id="什么是spark-sql">什么是Spark SQL</h2>

<p>Spark SQL是Apache Spark用于处理结构化数据的模块。Spark SQL允许使用SQL或熟悉的DataFrame API查询Spark程序内的结构化数据。Spark SQL支持多语言编程包括Java、Scala、Python和R，可以根据自身喜好进行选择。本文中所涉及的Spark SQL代码示例均使用python语言。</p>

<h2 id="spark-sql的核心-dataframe">Spark SQL的核心-DataFrame</h2>

<p>DataFrame是一个以命名列（类似于关系表中的字段）组织的分布式数据集。可以把它看成关系数据库中的一张表或R/python中的DataFrame数据结构（在spark 1.3以前，称为schema-RDD，后改为DataFrame）。 <br>
DataFrame可以通过多种来源创建：结构化数据文件，hive的表，外部数据库或者RDDs</p>

<h2 id="spark-sql的使用">Spark SQL的使用</h2>

<p>Spark SQL所有的功能入口都是SQLContext 类，及其子类。不过要创建一个SQLContext对象，首先需要有一个SparkContext对象，然后再创建SQLContext </p>

<pre class="prettyprint"><code class=" hljs python"><span class="hljs-keyword">from</span> pyspark <span class="hljs-keyword">import</span> SparkContext
<span class="hljs-keyword">from</span> pyspark <span class="hljs-keyword">import</span> SQLContext
sc = SparkContext(<span class="hljs-string">"local"</span>,<span class="hljs-string">"my_pyspark"</span>)
spark = SQLContext(sc)</code></pre>

<p>除了SQLContext之外，你也可以创建HiveContext，HiveContext是SQLContext 的超集。</p>

<h3 id="创建dataframe">创建DataFrame</h3>

<p>数据来源可以是已有的RDD、或Hive表、或其他数据源</p>

<p>以下是一个从JSON文件创建DataFrame的小例子：</p>



<pre class="prettyprint"><code class=" hljs avrasm">df = spark<span class="hljs-preprocessor">.read</span><span class="hljs-preprocessor">.json</span>(<span class="hljs-string">"/usr/local/spark/examples/src/main/resources/people.json"</span>) <span class="hljs-preprocessor">#自带的示例文件，可在安装路径下查找</span>
df<span class="hljs-preprocessor">.show</span>() <span class="hljs-preprocessor">#展示DataFrame的内容</span></code></pre>

<p><img src="https://img-blog.csdn.net/20171228171337113?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbW9sZWR5emhhbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>以下是一个从RDD创建DataFrame的小例子：</p>

<pre class="prettyprint"><code class=" hljs mathematica">from pyspark import <span class="hljs-keyword">Row</span>
rdd = sc.parallelize([
        <span class="hljs-keyword">Row</span>(name=<span class="hljs-string">'Michael'</span>,age=<span class="hljs-number">29</span>),
        <span class="hljs-keyword">Row</span>(name=<span class="hljs-string">'Andy'</span>, age=<span class="hljs-number">30</span>),
        <span class="hljs-keyword">Row</span>(name=<span class="hljs-string">'Justin'</span>, age=<span class="hljs-number">19</span>)
    ])
df1 = spark.createDataFrame(rdd)
df1.show()</code></pre>

<p><img src="https://img-blog.csdn.net/20171228172035528?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbW9sZWR5emhhbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>从文本文件创建DataFrame的小例子：</p>

<pre class="prettyprint"><code class=" hljs avrasm">rdd2 = sc<span class="hljs-preprocessor">.textFile</span>(<span class="hljs-string">"/usr/local/spark/examples/src/main/resources/people.txt"</span>)
df2 = spark<span class="hljs-preprocessor">.createDataFrame</span>(rdd)
df2<span class="hljs-preprocessor">.show</span>()</code></pre>

<p><img src="https://img-blog.csdn.net/20171228172547336?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbW9sZWR5emhhbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<h3 id="dataframe操作">DataFrame操作</h3>



<pre class="prettyprint"><code class=" hljs avrasm">df<span class="hljs-preprocessor">.printSchema</span>() <span class="hljs-preprocessor">#打印数据的树形结构</span></code></pre>

<p><img src="https://img-blog.csdn.net/20171228173914786?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbW9sZWR5emhhbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<pre class="prettyprint"><code class=" hljs avrasm">df<span class="hljs-preprocessor">.select</span>(<span class="hljs-string">"name"</span>)<span class="hljs-preprocessor">.show</span>()<span class="hljs-preprocessor">#查询name字段</span></code></pre>

<p><img src="https://img-blog.csdn.net/20171228174004183?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbW9sZWR5emhhbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<pre class="prettyprint"><code class=" hljs cs">df.<span class="hljs-keyword">select</span>(df[<span class="hljs-string">'name'</span>], df[<span class="hljs-string">'age'</span>] + <span class="hljs-number">1</span>).show()<span class="hljs-preprocessor">#查询每个人的name和age字段，但age加1</span></code></pre>

<p><img src="https://img-blog.csdn.net/20171228174228638?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbW9sZWR5emhhbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>



<pre class="prettyprint"><code class=" hljs livecodeserver">df.<span class="hljs-built_in">filter</span>(df[<span class="hljs-string">'age'</span>] &gt; <span class="hljs-number">21</span>).show()<span class="hljs-comment">#筛选年龄大于21的</span></code></pre>

<p><img src="https://img-blog.csdn.net/20171228174430433?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbW9sZWR5emhhbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>



<pre class="prettyprint"><code class=" hljs avrasm">df<span class="hljs-preprocessor">.groupBy</span>(<span class="hljs-string">"age"</span>)<span class="hljs-preprocessor">.count</span>()<span class="hljs-preprocessor">.show</span>()<span class="hljs-preprocessor">#按年龄统计人数</span></code></pre>

<p><img src="https://img-blog.csdn.net/20171228174708263?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbW9sZWR5emhhbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>



<h3 id="运行sql查询">运行SQL查询</h3>

<p>SQLContext.sql可以执行SQL查询，并返回DataFrame结果。</p>



<pre class="prettyprint"><code class=" hljs avrasm">df<span class="hljs-preprocessor">.createOrReplaceTempView</span>(<span class="hljs-string">"people"</span>)<span class="hljs-preprocessor">#将DataFrame注册为SQL临时视图</span>
sqlDF = spark<span class="hljs-preprocessor">.sql</span>(<span class="hljs-string">"SELECT * FROM people"</span>)
sqlDF<span class="hljs-preprocessor">.show</span>()</code></pre>

<p><img src="https://img-blog.csdn.net/20171228175747146?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbW9sZWR5emhhbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<h3 id="全局临时视图">全局临时视图</h3>

<p>Spark SQL中的临时视图是会话范围的，如果创建它的会话终止，将会消失。 如果您希望在所有会话之间共享一个临时视图并保持活动状态，直到Spark应用程序终止，则可以创建一个全局临时视图。 全局临时视图与系统保存的数据库global_temp绑定，我们必须使用限定名称来引用它，例如， SELECT * FROM global_temp.view1。</p>

<pre class="prettyprint"><code class=" hljs avrasm">df<span class="hljs-preprocessor">.createGlobalTempView</span>(<span class="hljs-string">"people1"</span>)
spark<span class="hljs-preprocessor">.sql</span>(<span class="hljs-string">"SELECT * FROM global_temp.people1"</span>)<span class="hljs-preprocessor">.show</span>()
spark<span class="hljs-preprocessor">.newSession</span>()<span class="hljs-preprocessor">.sql</span>(<span class="hljs-string">"SELECT * FROM global_temp.people1"</span>)<span class="hljs-preprocessor">.show</span>()</code></pre>

<h3 id="dataframe与rdd的互相转换">DataFrame与RDD的互相转换</h3>

<p>Spark SQL将现有RDD转换为Datasets的方法有两种。 <br>
    1.  使用反射机制，推导包含指定类型对象RDD的schema。这种基于反射机制的方法使代码更简洁，而且如果你事先知道数据schema，推荐使用这种方式； <br>
   2.  编程方式构建一个schema，然后应用到指定RDD上。这种方式更啰嗦，但如果你事先不知道数据有哪些字段，或者数据schema是运行时读取进来的，那么你很可能需要用这种方式。 <br>
第一种方法使用反射来推断包含特定类型对象的RDD的模式。这种基于反射的方法导致更简洁的代码，并且在编写Spark应用程序时已经知道模式的情况下运行良好。</p>

<p>创建数据集的第二种方法是通过编程接口，允许您构建模式，然后将其应用于现有的RDD。虽然这个方法比较冗长，但是它允许你在构造数据集的时候直到运行时才知道列和它们的类型</p>

<h4 id="利用反射推导schema">利用反射推导schema</h4>

<p>Spark SQL可以将Row对象的RDD转换为DataFrame，从而推断出数据类型。 行是通过将一个键/值对列表作为kwargs传递给Row类来构造的。 此列表的键定义了表的列名，类型是通过对整个数据集进行采样来推断的，类似于在JSON文件上执行的推断。</p>

<pre class="prettyprint"><code class=" hljs avrasm">from pyspark import SparkContext
from pyspark<span class="hljs-preprocessor">.sql</span> import Row
from pyspark import SQLContext
sc = SparkContext()
spark  = SQLContext(sc)
<span class="hljs-preprocessor">#加载一个文本文件，并将每行转换为一个Row对象。</span>
lines = sc<span class="hljs-preprocessor">.textFile</span>(<span class="hljs-string">"/usr/local/spark/examples/src/main/resources/people.txt"</span>)<span class="hljs-preprocessor">#换成自己的地址</span>
parts = lines<span class="hljs-preprocessor">.map</span>(lambda l: l<span class="hljs-preprocessor">.split</span>(<span class="hljs-string">","</span>))
people = parts<span class="hljs-preprocessor">.map</span>(lambda p: Row(name=p[<span class="hljs-number">0</span>], age=int(p[<span class="hljs-number">1</span>])))
<span class="hljs-preprocessor">#</span>
schemaPeople = spark<span class="hljs-preprocessor">.createDataFrame</span>(people)
schemaPeople<span class="hljs-preprocessor">.createOrReplaceTempView</span>(<span class="hljs-string">"people"</span>)
teenagers = spark<span class="hljs-preprocessor">.sql</span>(<span class="hljs-string">"SELECT name FROM people WHERE age &gt;= 13 AND age &lt;= 19"</span>)
teenNames = teenagers<span class="hljs-preprocessor">.rdd</span><span class="hljs-preprocessor">.map</span>(lambda p: <span class="hljs-string">"Name: "</span> + p<span class="hljs-preprocessor">.name</span>)<span class="hljs-preprocessor">.collect</span>()
for name <span class="hljs-keyword">in</span> teenNames:
    print(name)</code></pre>

<p>结果： <br>
<img src="https://img-blog.csdn.net/20171228185418108?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbW9sZWR5emhhbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<h4 id="编程方式定义schema">编程方式定义schema</h4>



<pre class="prettyprint"><code class=" hljs avrasm">from pyspark import SparkContext
from pyspark<span class="hljs-preprocessor">.sql</span><span class="hljs-preprocessor">.types</span> import *
from pyspark import SQLContext
sc = SparkContext()
spark  = SQLContext(sc)
<span class="hljs-preprocessor"># 加载文本文件</span>
lines = sc<span class="hljs-preprocessor">.textFile</span>(<span class="hljs-string">"/usr/local/spark/examples/src/main/resources/people.txt"</span>)
<span class="hljs-preprocessor">#分割每一行</span>
parts = lines<span class="hljs-preprocessor">.map</span>(lambda l: l<span class="hljs-preprocessor">.split</span>(<span class="hljs-string">","</span>))
<span class="hljs-preprocessor"># 将每一行都转换为一个元组</span>
people = parts<span class="hljs-preprocessor">.map</span>(lambda p: (p[<span class="hljs-number">0</span>], p[<span class="hljs-number">1</span>]<span class="hljs-preprocessor">.strip</span>()))

<span class="hljs-preprocessor"># 可以理解为定义列表占位符</span>
<span class="hljs-preprocessor"># schemaString = "name age"</span>

fields = [StructField(field_name, StringType(), True) for field_name <span class="hljs-keyword">in</span> schemaString<span class="hljs-preprocessor">.split</span>()]
schema = StructType(fields)

<span class="hljs-preprocessor"># 将schema应用到指定RDD上</span>
schemaPeople = spark<span class="hljs-preprocessor">.createDataFrame</span>(people, schema)

<span class="hljs-preprocessor"># 使用DataFrame创建一个临时视图</span>
schemaPeople<span class="hljs-preprocessor">.createOrReplaceTempView</span>(<span class="hljs-string">"people"</span>)

<span class="hljs-preprocessor"># SQL可以通过已注册为表的DataFrame运行。</span>
results = spark<span class="hljs-preprocessor">.sql</span>(<span class="hljs-string">"SELECT name FROM people"</span>)

results<span class="hljs-preprocessor">.show</span>()</code></pre>

<p>结果：</p>

<h2 id="title"><img src="https://img-blog.csdn.net/20171228194516766?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbW9sZWR5emhhbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></h2>

<p>参考文档：<a href="http://spark.apache.org/docs/2.2.1/sql-programming-guide.html" rel="nofollow" target="_blank">http://spark.apache.org/docs/2.2.1/sql-programming-guide.html</a></p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>