---
layout:     post
title:      hadoop hdfs的一些操作
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<div class="showContent">
<p><span><strong>HDFS的文件操作<br>
格式化HDFS<br></strong>命令：user@namenode:hadoop$ bin/hadoop namenode -format <br><strong>启动HDFS<br></strong>命令：user@namenode:hadoop$ bin/start-dfs.sh </span></p>
<p><span><strong>列出HDFS上的文件</strong> </span></p>
<p><span>命令：user@namenode:hadoop$ bin/hadoop dfs -ls  </span></p>
<p><span><strong>使用hadoop API</strong></span></p>
<p><span> </span></p>
<div class="dp-highlighter">
<div class="bar">
<div class="tools">Java代码  <a title="收藏这段代码"><img alt="收藏代码" src="http://yu06206.iteye.com/images/icon_star.png" class="star"></a></div>
</div>
<ol start="1" class="dp-j"><li><span><span>&lt;span style=</span><span class="string">""</span><span>&gt;</span><span class="keyword">public</span><span> List&lt;String[]&gt; GetFileBolckHost(Configuration conf, String FileName) {  </span></span></li><li><span>        <span class="keyword">try</span><span> {  </span></span></li><li><span>            List&lt;String[]&gt; list = <span class="keyword">new</span><span> ArrayList&lt;String[]&gt;();  </span></span></li><li><span>            FileSystem hdfs = FileSystem.get(conf);  </span></li><li><span>            Path path = <span class="keyword">new</span><span> Path(FileName);  </span></span></li><li><span>            FileStatus fileStatus = hdfs.getFileStatus(path);  </span></li><li><span>  </span></li><li><span>            BlockLocation[] blkLocations = hdfs.getFileBlockLocations(  </span></li><li><span>                    fileStatus, <span class="number">0</span><span>, fileStatus.getLen());  </span></span></li><li><span>  </span></li><li><span>            <span class="keyword">int</span><span> blkCount = blkLocations.length;  </span></span></li><li><span>            <span class="keyword">for</span><span> (</span><span class="keyword">int</span><span> i = </span><span class="number">0</span><span>; i &lt; blkCount; i++) {  </span></span></li><li><span>                String[] hosts = blkLocations[i].getHosts();  </span></li><li><span>                list.add(hosts);  </span></li><li><span>            }  </span></li><li><span>            <span class="keyword">return</span><span> list;  </span></span></li><li><span>        } <span class="keyword">catch</span><span> (IOException e) {  </span></span></li><li><span>            e.printStackTrace();  </span></li><li><span>        }  </span></li><li><span>        <span class="keyword">return</span><span> </span><span class="keyword">null</span><span>;  </span></span></li><li><span>    }&lt;/span&gt;  </span></li></ol></div>
<p><span> </span></p>
<p><span> </span></p>
<p><span><strong>在HDFS上创建目录<br></strong>命令：user@namenode:hadoop$ bin/hadoop dfs -mkdir /文件名</span></p>
<p><span><strong>使用hadoop API</strong></span></p>
<div class="dp-highlighter">
<div class="bar">
<div class="tools">Java代码  <a title="收藏这段代码"><img alt="收藏代码" src="http://yu06206.iteye.com/images/icon_star.png" class="star"></a></div>
</div>
<ol start="1" class="dp-j"><li><span><span>&lt;span style=</span><span class="string">""</span><span>&gt;</span><span class="comment">// 在HDFS新建文件</span><span>  </span></span></li><li><span>    <span class="keyword">public</span><span> FSDataOutputStream CreateFile(Configuration conf, String FileName) {  </span></span></li><li><span>        <span class="keyword">try</span><span> {  </span></span></li><li><span>            FileSystem hdfs = FileSystem.get(conf);  </span></li><li><span>            Path path = <span class="keyword">new</span><span> Path(FileName);  </span></span></li><li><span>            FSDataOutputStream outputStream = hdfs.create(path);  </span></li><li><span>            <span class="keyword">return</span><span> outputStream;  </span></span></li><li><span>        } <span class="keyword">catch</span><span> (IOException e) {  </span></span></li><li><span>            e.printStackTrace();  </span></li><li><span>        }  </span></li><li><span>        <span class="keyword">return</span><span> </span><span class="keyword">null</span><span>;  </span></span></li><li><span>    }&lt;/span&gt;  </span></li></ol></div>
<p><span> <br><strong>上传一个文件到HDFS<br></strong>命令：user@namenode:hadoop$ bin/hadoop dfs -put 文件名 /user/yourUserName/ </span>
</p>
<p><span><strong>使用hadoop API</strong></span></p>
<div class="dp-highlighter">
<div class="bar">
<div class="tools">Java代码  <a title="收藏这段代码"><img alt="收藏代码" src="http://yu06206.iteye.com/images/icon_star.png" class="star"></a></div>
</div>
<ol start="1" class="dp-j"><li><span><span>&lt;span style=</span><span class="string">""</span><span>&gt;</span><span class="comment">// 上传文件到HDFS</span><span>  </span></span></li><li><span>    <span class="keyword">public</span><span> </span><span class="keyword">void</span><span> PutFile(Configuration conf, String srcFile, String dstFile) {  </span></span></li><li><span>        <span class="keyword">try</span><span> {  </span></span></li><li><span>            FileSystem hdfs = FileSystem.get(conf);  </span></li><li><span>            Path srcPath = <span class="keyword">new</span><span> Path(srcFile);  </span></span></li><li><span>            Path dstPath = <span class="keyword">new</span><span> Path(dstFile);  </span></span></li><li><span>            hdfs.copyFromLocalFile(srcPath, dstPath);  </span></li><li><span>        } <span class="keyword">catch</span><span> (IOException e) {  </span></span></li><li><span>            e.printStackTrace();  </span></li><li><span>        }  </span></li><li><span>    }&lt;/span&gt;  </span></li></ol></div>
<p><span> <br><strong>从 HDFS 中导出数据 </strong></span></p>
<p><span>命令：user@namenode:hadoop$ bin/hadoop dfs -cat foo </span></p>
<p><span><strong>使用hadoop API</strong></span></p>
<div class="dp-highlighter">
<div class="bar">
<div class="tools">Java代码  <a title="收藏这段代码"><img alt="收藏代码" src="http://yu06206.iteye.com/images/icon_star.png" class="star"></a></div>
</div>
<ol start="1" class="dp-j"><li><span><span>&lt;span style=</span><span class="string">""</span><span>&gt;</span><span class="comment">// 从HDFS读取文件</span><span>  </span></span></li><li><span>    <span class="keyword">public</span><span> </span><span class="keyword">void</span><span> ReadFile(Configuration conf, String FileName) {  </span></span></li><li><span>        <span class="keyword">try</span><span> {  </span></span></li><li><span>            FileSystem hdfs = FileSystem.get(conf);  </span></li><li><span>            FSDataInputStream dis = hdfs.open(<span class="keyword">new</span><span> Path(FileName));  </span></span></li><li><span>            IOUtils.copyBytes(dis, System.out, <span class="number">4096</span><span>, </span><span class="keyword">false</span><span>);  </span></span></li><li><span>            dis.close();  </span></li><li><span>        } <span class="keyword">catch</span><span> (IOException e) {  </span></span></li><li><span>            e.printStackTrace();  </span></li><li><span>        }  </span></li><li><span>    }&lt;/span&gt;  </span></li></ol></div>
<p><span><strong> <br>
HDFS 的关闭 <br></strong>命令：user@namenode:hadoop$ bin/stop-dfs.sh </span></p>
<p><span> </span></p>
<p><span><strong>HDFS全局状态信息</strong></span></p>
<p><span>命令：bin/hadoop dfsadmin -report</span></p>
<p><span>我们可以得到一份全局状态报告。这份报告包含了HDFS集群的基本信息，当然也有每台机器的一些情况。 <br></span></p>
<p><span>    以上讲的都是本地操作HDFS，都是基于在ubuntu下并配置有hadoop环境下对HDFS的操作，作为客户端也可以在window系统下远程的对 HDFS进行操作，其实原理基本上差不多，只需要集群中namenode对外开放的IP和端口，就可以访问到HDFS</span></p>
<div class="dp-highlighter">
<div class="bar">
<div class="tools">Java代码  <a title="收藏这段代码"><img alt="收藏代码" src="http://yu06206.iteye.com/images/icon_star.png" class="star"></a></div>
</div>
<ol start="1" class="dp-j"><li><span><span>&lt;span style=</span><span class="string">""</span><span>&gt;</span><span class="comment">/**</span> </span></li><li><span><span class="comment"> * 对HDFS操作</span> </span></li><li><span><span class="comment"> * @author yujing</span> </span></li><li><span><span class="comment"> *</span> </span></li><li><span><span class="comment"> */</span><span>  </span></span></li><li><span><span class="keyword">public</span><span> </span><span class="keyword">class</span><span> Write {  </span></span></li><li><span>    <span class="keyword">public</span><span> </span><span class="keyword">static</span><span> </span><span class="keyword">void</span><span> main(String[] args) {  </span></span></li><li><span>        <span class="keyword">try</span><span> {  </span></span></li><li><span>            uploadTohdfs();  </span></li><li><span>            readHdfs();  </span></li><li><span>            getDirectoryFromHdfs();  </span></li><li><span>        } <span class="keyword">catch</span><span> (FileNotFoundException e) {  </span></span></li><li><span>            e.printStackTrace();  </span></li><li><span>        } <span class="keyword">catch</span><span> (IOException e) {  </span></span></li><li><span>            e.printStackTrace();  </span></li><li><span>        }  </span></li><li><span>    }  </span></li><li><span>  </span></li><li><span>    <span class="keyword">public</span><span> </span><span class="keyword">static</span><span> </span><span class="keyword">void</span><span> uploadTohdfs() </span><span class="keyword">throws</span><span> FileNotFoundException, IOException {  </span></span></li><li><span>        String localSrc = <span class="string">"D://qq.txt"</span><span>;  </span></span></li><li><span>        String dst = <span class="string">"hdfs://192.168.1.11:9000/usr/yujing/test.txt"</span><span>;  </span></span></li><li><span>        InputStream in = <span class="keyword">new</span><span> BufferedInputStream(</span><span class="keyword">new</span><span> FileInputStream(localSrc));  </span></span></li><li><span>        Configuration conf = <span class="keyword">new</span><span> Configuration();  </span></span></li><li><span>        FileSystem fs = FileSystem.get(URI.create(dst), conf);  </span></li><li><span>        OutputStream out = fs.create(<span class="keyword">new</span><span> Path(dst), </span><span class="keyword">new</span><span> Progressable() {  </span></span></li><li><span>            <span class="keyword">public</span><span> </span><span class="keyword">void</span><span> progress() {  </span></span></li><li><span>                System.out.println(<span class="string">"."</span><span>);  </span></span></li><li><span>            }  </span></li><li><span>        });  </span></li><li><span>        System.out.println(<span class="string">"上传文件成功"</span><span>);  </span></span></li><li><span>        IOUtils.copyBytes(in, out, <span class="number">4096</span><span>, </span><span class="keyword">true</span><span>);  </span></span></li><li><span>    }  </span></li><li><span>  </span></li><li><span>    <span class="comment">/** 从HDFS上读取文件 */</span><span>  </span></span></li><li><span>    <span class="keyword">private</span><span> </span><span class="keyword">static</span><span> </span><span class="keyword">void</span><span> readHdfs() </span><span class="keyword">throws</span><span> FileNotFoundException, IOException {  </span></span></li><li><span>        String dst = <span class="string">"hdfs://192.168.1.11:9000/usr/yujing/test.txt"</span><span>;  </span></span></li><li><span>        Configuration conf = <span class="keyword">new</span><span> Configuration();  </span></span></li><li><span>        FileSystem fs = FileSystem.get(URI.create(dst), conf);  </span></li><li><span>        FSDataInputStream hdfsInStream = fs.open(<span class="keyword">new</span><span> Path(dst));  </span></span></li><li><span>  </span></li><li><span>        OutputStream out = <span class="keyword">new</span><span> FileOutputStream(</span><span class="string">"d:/qq-hdfs.txt"</span><span>);  </span></span></li><li><span>        <span class="keyword">byte</span><span>[] ioBuffer = </span><span class="keyword">new</span><span> </span><span class="keyword">byte</span><span>[</span><span class="number">1024</span><span>];  </span></span></li><li><span>        <span class="keyword">int</span><span> readLen = hdfsInStream.read(ioBuffer);  </span></span></li><li><span>  </span></li><li><span>        <span class="keyword">while</span><span> (-</span><span class="number">1</span><span> != readLen) {  </span></span></li><li><span>            out.write(ioBuffer, <span class="number">0</span><span>, readLen);  </span></span></li><li><span>            readLen = hdfsInStream.read(ioBuffer);  </span></li><li><span>        }  </span></li><li><span>        System.out.println(<span class="string">"读文件成功"</span><span>);  </span></span></li><li><span>        out.close();  </span></li><li><span>        hdfsInStream.close();  </span></li><li><span>        fs.close();  </span></li><li><span>    }  </span></li><li><span>  </span></li><li><span>    <span class="comment">/**</span> </span></li><li><span><span class="comment">     * 以append方式将内容添加到HDFS上文件的末尾;注意：文件更新，需要在hdfs-site.xml中添&lt;property&gt;&lt;name&gt;dfs.</span> </span></li><li><span><span class="comment">     * append.support&lt;/name&gt;&lt;value&gt;true&lt;/value&gt;&lt;/property&gt;</span> </span></li><li><span><span class="comment">     */</span><span>  </span></span></li><li><span>    <span class="keyword">private</span><span> </span><span class="keyword">static</span><span> </span><span class="keyword">void</span><span> appendToHdfs() </span><span class="keyword">throws</span><span> FileNotFoundException,  </span></span></li><li><span>            IOException {  </span></li><li><span>        String dst = <span class="string">"hdfs://192.168.1.11:9000/usr/yujing/test.txt"</span><span>;  </span></span></li><li><span>        Configuration conf = <span class="keyword">new</span><span> Configuration();  </span></span></li><li><span>        FileSystem fs = FileSystem.get(URI.create(dst), conf);  </span></li><li><span>        FSDataOutputStream out = fs.append(<span class="keyword">new</span><span> Path(dst));  </span></span></li><li><span>  </span></li><li><span>        <span class="keyword">int</span><span> readLen = </span><span class="string">"zhangzk add by hdfs java api"</span><span>.getBytes().length;  </span></span></li><li><span>  </span></li><li><span>        <span class="keyword">while</span><span> (-</span><span class="number">1</span><span> != readLen) {  </span></span></li><li><span>            out.write(<span class="string">"zhangzk add by hdfs java api"</span><span>.getBytes(), </span><span class="number">0</span><span>, readLen);  </span></span></li><li><span>        }  </span></li><li><span>        out.close();  </span></li><li><span>        fs.close();  </span></li><li><span>    }  </span></li><li><span>  </span></li><li><span>    <span class="comment">/** 从HDFS上删除文件 */</span><span>  </span></span></li><li><span>    <span class="keyword">private</span><span> </span><span class="keyword">static</span><span> </span><span class="keyword">void</span><span> deleteFromHdfs() </span><span class="keyword">throws</span><span> FileNotFoundException,  </span></span></li><li><span>            IOException {  </span></li><li><span>        String dst = <span class="string">"hdfs://192.168.1.11:9000/usr/yujing"</span><span>;  </span></span></li><li><span>        Configuration conf = <span class="keyword">new</span><span> Configuration();  </span></span></li><li><span>        FileSystem fs = FileSystem.get(URI.create(dst), conf);  </span></li><li><span>        fs.deleteOnExit(<span class="keyword">new</span><span> Path(dst));  </span></span></li><li><span>        fs.close();  </span></li><li><span>    }  </span></li><li><span>  </span></li><li><span>    <span class="comment">/** 遍历HDFS上的文件和目录 */</span><span>  </span></span></li><li><span>    <span class="keyword">private</span><span> </span><span class="keyword">static</span><span> </span><span class="keyword">void</span><span> getDirectoryFromHdfs() </span><span class="keyword">throws</span><span> FileNotFoundException,  </span></span></li><li><span>            IOException {  </span></li><li><span>        String dst = <span class="string">"hdfs://192.168.1.11:9000/usr/yujing"</span><span>;  </span></span></li><li><span>        Configuration conf = <span class="keyword">new</span><span> Configuration();  </span></span></li><li><span>        FileSystem fs = FileSystem.get(URI.create(dst), conf);  </span></li><li><span>        FileStatus fileList[] = fs.listStatus(<span class="keyword">new</span><span> Path(dst));  </span></span></li><li><span>        <span class="keyword">int</span><span> size = fileList.length;  </span></span></li><li><span>        <span class="keyword">for</span><span> (</span><span class="keyword">int</span><span> i = </span><span class="number">0</span><span>; i &lt; size; i++) {  </span></span></li><li><span>            System.out.println(<span class="string">"文件名name:"</span><span> + fileList[i].getPath().getName()  </span></span></li><li><span>                    + <span class="string">"文件大小/t/tsize:"</span><span> + fileList[i].getLen());  </span></span></li><li><span>        }  </span></li><li><span>        fs.close();  </span></li><li><span>    }  </span></li><li><span>  </span></li><li><span>}  </span></li><li><span>&lt;/span&gt;  </span></li></ol></div>
<p><span> </span></p>
<p> </p>
<p><span>我们可以通过http://主机IP：50030就可以查看集群的所有信息，也可以查看到自己上传到HDFS上的文件</span></p>
</div>
            </div>
                </div>