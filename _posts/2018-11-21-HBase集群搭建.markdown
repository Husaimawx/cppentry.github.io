---
layout:     post
title:      HBase集群搭建
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h2 id="一hbase安装">一、HBase安装</h2>

<ol>
<li><p>安装zookeeper集群</p>

<pre><code>见上一篇zookeeper集群搭建
</code></pre></li>
<li><p>下载：</p>

<pre><code>找到官网下载 hbase 安装包 
下载地址：[http://mirrors.hust.edu.cn/apache/hbase/]
</code></pre></li>
<li><p>解压：</p>

<pre><code> tar -zxvf hbase-1.2.6-bin.tar.gz -C /home/hadoop/apps/
</code></pre></li>
<li><p>修改配置文件：</p>

<pre><code>进入到Hbase安装目录conf下：
1）vi hbase-env.sh            
    修改两个地方：
export JAVA_HOME=/usr/local/java/jdk1.8.0_73，表示修改为自己的 jdk 目录
export HBASE_MANAGES_ZK=false，表示不引用 hbase 自带的 zookeeper，用我们自己安装的
2）vi hbase-site.xml
    增加以下配置：
        &lt;configuration&gt;
         &lt;property&gt;
        &lt;!-- 指定 hbase 在 HDFS 上存储的路径 --&gt;
         &lt;name&gt;hbase.rootdir&lt;/name&gt;
         &lt;value&gt;hdfs://bd1804/hbase&lt;/value&gt;
         &lt;/property&gt;
         &lt;property&gt;
        &lt;!-- 指定 hbase 是分布式的 --&gt;
         &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
         &lt;value&gt;true&lt;/value&gt;
         &lt;/property&gt;
         &lt;property&gt;
        &lt;!-- 指定 zk 的地址，多个用“,”分割 --&gt;
         &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
         &lt;value&gt;hadoop01:2181,hadoop02:2181,hadoop03:2181&lt;/value&gt;
         &lt;/property&gt;
        &lt;/configuration&gt;
        保存退出
3） vi regionservers
        hadoop01
        hadoop02
        hadoop03
4）修改 backup-masters（自行创建），指定备用的主节点
        vi backup-masters
        hadoop03
5）最重要一步，要把 hadoop 的 hdfs-site.xml 和 core-site.xml 放到 hbase-1.2.6/conf 下
        cp ~/apps/hadoop-2.7.5/etc/hadoop/core-site.xml ~/apps/hbase-1.2.6/conf/
        cp ~/apps/hadoop-2.7.5/etc/hadoop/hdfs-site.xml ~/apps/hbase-1.2.6/conf/
</code></pre></li>
<li><p>分发安装到各节点：</p>

<pre><code>scp -r hbase-1.2.6 root@hadoop01:/home/hadoop/apps/
scp -r hbase-1.2.6 root@hadoop02:/home/hadoop/apps/
scp -r hbase-1.2.6 root@hadoop03:/home/hadoop/apps/
</code></pre></li>
<li><p>同步时间：</p>

<pre><code>ntpdate 时间同步服务器
sudo ntpdate ntpl.aliyun.com
</code></pre></li>
<li><p>配置环境变量：</p>

<pre><code>sudo vi /etc/profile
添加两行:
export HBASE_HOME=/home/hadoop/apps/hbase-1.2.6
export PATH=$PATH:$HBASE_HOME/bin
保存退出！！！
source /etc/profile
</code></pre></li>
<li><p>启动：</p>

<pre><code>1) 先启动 zookeeper 集群
    zkServer.sh start
2) 启动 hdfs 集群
    start-dfs.sh
3) 启动 hbase
    保证 ZooKeeper 集群和 HDFS 集群启动正常的情况下启动 HBase 集群
    启动命令：start-hbase.sh
</code></pre></li>
<li><p>查看启动是否正常，是否成功</p>

<pre><code>1) 检查各进程是否启动正常
    主节点和备用节点都启动 hmaster 进程
    各从节点都启动 hregionserver 进程
2) 通过访问浏览器页面，格式为”主节点：16010”
    http://hadoop02:16010/
</code></pre></li>
<li><p>如果有节点相应的进程没有启动，那么可以手动启动</p>

<pre><code>hbase-daemon.sh start master
hbase-daemon.sh start regionserver  
</code></pre></li>
</ol>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>