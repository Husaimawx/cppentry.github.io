---
layout:     post
title:      采集框架Flume
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h1><strong>1. <span style="font-family:'宋体';">日志采集框架</span><span style="font-family:Calibri;">Flume</span></strong></h1><h2><strong>1.1 Flume<span style="font-family:'宋体';">介绍</span></strong></h2><h3><strong>1.1.1 <span style="font-family:'宋体';">概述</span></strong></h3><p>u Flume<span style="font-family:'宋体';">是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。</span></p><p>u Flume<span style="font-family:'宋体';">可以采集文件，</span><span style="font-family:Calibri;">socket</span><span style="font-family:'宋体';">数据包等各种形式源数据，又可以将采集到的数据输出到</span><span style="font-family:Calibri;">HDFS</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">hbase</span><span style="font-family:'宋体';">、</span><span style="font-family:Calibri;">hive</span>、kafka等众多外部存储系统中</p><p>u <span style="font-family:'宋体';">一般的采集需求，通过对</span>flume<span style="font-family:'宋体';">的简单配置即可实现</span></p><p>u Flume<span style="font-family:'宋体';">针对特殊场景也具备良好的自定义扩展能力，因此，</span><span style="font-family:Calibri;">flume</span><span style="font-family:'宋体';">可以适用于大部分的日常数据采集场景</span></p><p> </p><h3><strong>1.1.2 <span style="font-family:'宋体';">运行机制</span></strong></h3><p>1、 Flume<span style="font-family:'宋体';">分布式系统中最</span><strong><span style="font-family:'宋体';">核心的角色是</span>agent</strong><span style="font-family:'宋体';">，</span>flume<span style="font-family:'宋体';">采集系统就是由一个个</span><span style="font-family:Calibri;">agent</span><span style="font-family:'宋体';">所连接起来形成</span></p><p>2、 <strong><span style="font-family:'宋体';">每一个</span>agent<span style="font-family:'宋体';">相当于一个数据传递员</span>，内部有三个组件：</strong></p><p>a) Source<span style="font-family:'宋体';">：采集源，用于跟数据源对接，以获取数据</span></p><p>b) Sink<span style="font-family:'宋体';">：下沉地，采集数据的传送目的，用于往下一级</span><span style="font-family:Calibri;">agent</span><span style="font-family:'宋体';">传递数据或者往最终存储系统传递数据</span></p><p>c) Channel<span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">angent</span><span style="font-family:'宋体';">内部的数据传输通道，用于从</span><span style="font-family:Calibri;">source</span><span style="font-family:'宋体';">将数据传递到</span><span style="font-family:Calibri;">sink</span></p><p> </p><p><strong> </strong></p><p><strong> </strong></p><p><strong> </strong></p><p><strong> </strong></p><p> </p><p> </p><p> </p><p> </p><p> </p><p><br clear="all"></p><h3><strong>1.1.4 Flume<span style="font-family:'宋体';">采集系统结构图</span></strong></h3><p> </p><h4><strong>1. <span style="font-family:'宋体';">简单结构</span></strong></h4><p><span style="font-family:'宋体';">单个</span>agent<span style="font-family:'宋体';">采集数据</span></p><p> </p><h4><strong>2. <span style="font-family:'宋体';">复杂结构</span></strong></h4><p><span style="font-family:'宋体';">多级</span>agent<span style="font-family:'宋体';">之间串联</span></p><p> </p><p> </p><p> </p><p> </p><p> </p><h2><strong>1.2 Flume<span style="font-family:'宋体';">实战案例</span></strong></h2><h4><strong>1.2.1 Flume<span style="font-family:'宋体';">的安装部署</span></strong></h4><p>1、Flume<span style="font-family:'宋体';">的安装非常简单，只需要解压即可，当然，前提是已有</span><span style="font-family:Calibri;">hadoop</span><span style="font-family:'宋体';">环境</span></p><p>上传安装包到数据源所在节点上</p><p>然后解压  tar -zxvf apache-flume-1.6.0-bin.tar.gz</p><p><span style="font-family:'宋体';">然后进入</span>flume<span style="font-family:'宋体';">的目录，修改</span><span style="font-family:Calibri;">conf</span><span style="font-family:'宋体';">下的</span><span style="font-family:Calibri;">flume-env.sh</span><span style="font-family:'宋体';">，在里面配置</span><span style="font-family:Calibri;">JAVA_HOME</span></p><p> </p><p>2<span style="font-family:'宋体';">、根据数据采集的</span>需求<strong>配置采集方案</strong>，描述在配置文件中(<span style="font-family:'宋体';">文件名可任意自定义</span><span style="font-family:Calibri;">)</span></p><p>3<span style="font-family:'宋体';">、</span><strong>指定采集方案配置文件</strong><span style="font-family:'宋体';">，在相应的节点上启动</span>flume agent</p><p> </p><p>先用一个最简单的例子来测试一下程序环境是否正常</p><p>1、<span style="font-family:'宋体';">先在</span>flume<span style="font-family:'宋体';">的</span><span style="font-family:Calibri;">conf</span><span style="font-family:'宋体';">目录下新建一个文件</span></p><p>vi   netcat-logger.conf</p><table><tbody><tr><td valign="top"><p># <span style="font-family:'宋体';">定义这个</span><span style="font-family:Calibri;">agent</span><span style="font-family:'宋体';">中各组件的名字</span></p><p>a1.sources = r1</p><p>a1.sinks = k1</p><p>a1.channels = c1</p><p> </p><p># <span style="font-family:'宋体';">描述和配置</span><span style="font-family:Calibri;">source</span><span style="font-family:'宋体';">组件：</span><span style="font-family:Calibri;">r1</span></p><p>a1.sources.r1.type = netcat</p><p>a1.sources.r1.bind = localhost</p><p>a1.sources.r1.port = 44444</p><p> </p><p># <span style="font-family:'宋体';">描述和配置</span><span style="font-family:Calibri;">sink</span><span style="font-family:'宋体';">组件：</span><span style="font-family:Calibri;">k1</span></p><p>a1.sinks.k1.type = logger</p><p> </p><p># <span style="font-family:'宋体';">描述和配置</span><span style="font-family:Calibri;">channel</span><span style="font-family:'宋体';">组件，此处使用是内存缓存的方式</span></p><p>a1.channels.c1.type = memory</p><p>a1.channels.c1.capacity = 1000</p><p>a1.channels.c1.transactionCapacity = 100</p><p> </p><p># <span style="font-family:'宋体';">描述和配置</span><span style="font-family:Calibri;">source  channel   sink</span><span style="font-family:'宋体';">之间的连接关系</span></p><p>a1.sources.r1.channels = c1</p><p>a1.sinks.k1.channel = c1</p></td></tr></tbody></table><p> </p><p>2、<span style="font-family:'宋体';">启动</span>agent<span style="font-family:'宋体';">去采集数据</span></p><table><tbody><tr><td valign="top"><p>bin/flume-ng agent -c conf -f conf/netcat-logger.conf -n a1  -Dflume.root.logger=INFO,console</p></td></tr></tbody></table><p>-c conf   <span style="font-family:'宋体';">指定</span><span style="font-family:Calibri;">flume</span><span style="font-family:'宋体';">自身的配置文件所在目录</span></p><p>-f conf/netcat-logger.con  <span style="font-family:'宋体';">指定我们所描述的采集方案</span></p><p>-n a1  <span style="font-family:'宋体';">指定我们这个</span><span style="font-family:Calibri;">agent</span><span style="font-family:'宋体';">的名字</span></p><p>3、测试</p><p><span style="font-family:'宋体';">先要往</span>agent<span style="font-family:'宋体';">采集监听的端口上发送数据，让</span><span style="font-family:Calibri;">agent</span><span style="font-family:'宋体';">有数据可采</span></p><p><span style="font-family:'宋体';">随便在一个能跟</span>agent<span style="font-family:'宋体';">节点联网的机器上</span></p><p>telnet anget-hostname  port   <span style="font-family:'宋体';">（</span><span style="font-family:Calibri;">telnet localhost 44444</span><span style="font-family:'宋体';">） </span></p><p> </p><p> </p><p> </p><p> </p><h4><strong>1.2.2 <span style="font-family:'宋体';">采集案例</span></strong></h4><h5><strong>1<span style="font-family:'宋体';">、采集目录到</span><span style="font-family:Calibri;">HDFS</span></strong></h5><p><span style="font-family:'宋体';">采集需求：某服务器的某特定目录下，会不断产生新的文件，每当有新文件出现，就需要把文件采集到</span>HDFS<span style="font-family:'宋体';">中去</span></p><p><span style="font-family:'宋体';">根据需求，首先定义以下</span>3<span style="font-family:'宋体';">大要素</span></p><p>l <span style="font-family:'宋体';">采集源，即</span>source<span style="font-family:'宋体';">——监控文件目录 </span><span style="font-family:Calibri;">:  spooldir</span></p><p>l <span style="font-family:'宋体';">下沉目标，即</span>sink<span style="font-family:'宋体';">——</span><span style="font-family:Calibri;">HDFS</span><span style="font-family:'宋体';">文件系统  </span><span style="font-family:Calibri;">:  hdfs sink</span></p><p>l source<span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">sink</span><span style="font-family:'宋体';">之间的传递通道——</span><span style="font-family:Calibri;">channel</span><span style="font-family:'宋体';">，可用</span><span style="font-family:Calibri;">file channel </span><span style="font-family:'宋体';">也可以用内存</span><span style="font-family:Calibri;">channel</span></p><p> </p><p>配置文件编写：</p><table><tbody><tr><td valign="top"><p>#<span style="font-family:'宋体';">定义三大组件的名称</span></p><p>agent1.sources = source1</p><p>agent1.sinks = sink1</p><p>agent1.channels = channel1</p><p> </p><p># 配置<span style="font-family:Calibri;">source</span><span style="font-family:'宋体';">组件</span></p><p>agent1.sources.source1.<span style="color:rgb(255,0,0);">type = spooldir</span></p><p>agent1.sources.source1.<span style="color:rgb(255,0,0);">spoolDir = /home/hadoop/logs/</span></p><p>agent1.sources.source1.fileHeader = false</p><p> </p><p>#配置拦截器</p><p>agent1.sources.source1.interceptors = i1</p><p>agent1.sources.source1.interceptors.i1.type = host</p><p>agent1.sources.source1.interceptors.i1.hostHeader = hostname</p><p> </p><p># 配置<span style="font-family:Calibri;">sink</span><span style="font-family:'宋体';">组件</span></p><p><span style="font-family:'宋体';">#分为几部：1.把文件bash（刷入）到hdfs的临时文件 2.把临时文件roll成真正的存储文件。</span></p><p>agent1.sinks.sink1.type = hdfs</p><p>agent1.sinks.sink1.hdfs.path =hdfs://hdp-node-01:9000/weblog/flume-collection/%y-%m-%d/%H-%M</p><p>agent1.sinks.sink1.hdfs.filePrefix = access_log</p><p>agent1.sinks.sink1.hdfs.maxOpenFiles = 5000</p><p>agent1.sinks.sink1.hdfs.batchSize= 100</p><p>agent1.sinks.sink1.hdfs.fileType = DataStream</p><p>agent1.sinks.sink1.hdfs.writeFormat =Text</p><p>agent1.sinks.sink1.hdfs.rollSize = 102400</p><p>agent1.sinks.sink1.hdfs.rollCount = 1000000</p><p>agent1.sinks.sink1.hdfs.rollInterval = 0</p><p>#agent1.sinks.sink1.hdfs.round = true</p><p>#agent1.sinks.sink1.hdfs.roundValue = 10</p><p>#agent1.sinks.sink1.hdfs.roundUnit = minute</p><p>agent1.sinks.sink1.hdfs.useLocalTimeStamp = true</p><p># Use a channel which buffers events in memory</p><p>agent1.channels.channel1.type = memory</p><p>agent1.channels.channel1.keep-alive = 120</p><p>agent1.channels.channel1.capacity = 500000</p><p>agent1.channels.channel1.transactionCapacity = 600</p><p> </p><p># Bind the source and sink to the channel</p><p>agent1.sources.source1.channels = channel1</p><p>agent1.sinks.sink1.channel = channel1</p></td></tr></tbody></table><p> </p><p>Channel<span style="font-family:'宋体';">参数解释：</span></p><p>capacity<span style="font-family:'宋体';">：默认该通道中最大的可以存储的</span><span style="font-family:Calibri;">event</span><span style="font-family:'宋体';">数量</span></p><p>trasactionCapacity<span style="font-family:'宋体';">：每次最大可以</span>从source<span style="font-family:'宋体';">中拿到或者送到</span><span style="font-family:Calibri;">sink</span><span style="font-family:'宋体';">中的</span><span style="font-family:Calibri;">event</span><span style="font-family:'宋体';">数量</span></p><p>keep-alive<span style="font-family:'宋体';">：</span><span style="font-family:Calibri;">event</span><span style="font-family:'宋体';">添加到通道中或者移出的允许时间</span></p><p> </p><h5><strong>2<span style="font-family:'宋体';">、采集文件到</span><span style="font-family:Calibri;">HDFS</span></strong></h5><p><span style="font-family:'宋体';">采集需求：比如业务系统使用</span>log4j<span style="font-family:'宋体';">生成的日志，日志内容不断增加，需要把追加到日志文件中的数据实时采集到</span><span style="font-family:Calibri;">hdfs</span></p><p> </p><p><span style="font-family:'宋体';">根据需求，首先定义以下</span>3<span style="font-family:'宋体';">大要素</span></p><p>l <span style="font-family:'宋体';">采集源，即</span>source<span style="font-family:'宋体';">——监控文件内容更新 </span><span style="font-family:Calibri;">:  exec  </span>‘tail -F file’</p><p>l <span style="font-family:'宋体';">下沉目标，即</span>sink<span style="font-family:'宋体';">——</span><span style="font-family:Calibri;">HDFS</span><span style="font-family:'宋体';">文件系统  </span><span style="font-family:Calibri;">:  hdfs sink</span></p><p>l Source<span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">sink</span><span style="font-family:'宋体';">之间的传递通道——</span><span style="font-family:Calibri;">channel</span><span style="font-family:'宋体';">，可用</span><span style="font-family:Calibri;">file channel </span><span style="font-family:'宋体';">也可以用 内存</span><span style="font-family:Calibri;">channel</span></p><p> </p><p>配置文件编写：</p><table><tbody><tr><td valign="top"><p>agent1.sources = source1</p><p>agent1.sinks = sink1</p><p>agent1.channels = channel1</p><p> </p><p># Describe/configure tail -F source1</p><p>agent1.sources.source1.type = exec</p><p>agent1.sources.source1.command = tail -F /home/hadoop/logs/access_log</p><p>agent1.sources.source1.channels = channel1</p><p> </p><p>#configure host for source</p><p>agent1.sources.source1.interceptors = i1</p><p>agent1.sources.source1.interceptors.i1.type = host</p><p>agent1.sources.source1.interceptors.i1.hostHeader = hostname</p><p> </p><p># Describe sink1</p><p>agent1.sinks.sink1.type = hdfs</p><p>#a1.sinks.k1.channel = c1</p><p>agent1.sinks.sink1.hdfs.path =hdfs://hdp-node-01:9000/weblog/flume-collection/%y-%m-%d/%H-%M</p><p>agent1.sinks.sink1.hdfs.filePrefix = access_log</p><p>agent1.sinks.sink1.hdfs.maxOpenFiles = 5000</p><p>agent1.sinks.sink1.hdfs.batchSize= 100</p><p>agent1.sinks.sink1.hdfs.fileType = DataStream</p><p>agent1.sinks.sink1.hdfs.writeFormat =Text</p><p>agent1.sinks.sink1.hdfs.rollSize = 102400</p><p>agent1.sinks.sink1.hdfs.rollCount = 1000000</p><p>agent1.sinks.sink1.hdfs.rollInterval = 60</p><p>agent1.sinks.sink1.hdfs.round = true</p><p>agent1.sinks.sink1.hdfs.roundValue = 10</p><p>agent1.sinks.sink1.hdfs.roundUnit = minute</p><p>agent1.sinks.sink1.hdfs.useLocalTimeStamp = true</p><p> </p><p># Use a channel which buffers events in memory</p><p>agent1.channels.channel1.type = memory</p><p>agent1.channels.channel1.keep-alive = 120</p><p>agent1.channels.channel1.capacity = 500000</p><p>agent1.channels.channel1.transactionCapacity = 600</p><p> </p><p># Bind the source and sink to the channel</p><p>agent1.sources.source1.channels = channel1</p><p>agent1.sinks.sink1.channel = channel1</p></td></tr></tbody></table><p> </p><p> </p><p> </p><h2><strong>1.3 <span style="font-family:'宋体';">更多</span><span style="font-family:Cambria;">source</span><span style="font-family:'宋体';">和</span><span style="font-family:Cambria;">sink</span><span style="font-family:'宋体';">组件</span></strong></h2><p>Flume<span style="font-family:'宋体';">支持众多的</span><span style="font-family:Calibri;">source</span><span style="font-family:'宋体';">和</span><span style="font-family:Calibri;">sink</span><span style="font-family:'宋体';">类型，详细手册可参考官方文档</span></p><p><a href="http://flume.apache.org/FlumeUserGuide.html" rel="nofollow"><u><span style="color:rgb(0,0,255);background:rgb(255,255,255);">http://flume.apache.org/FlumeUserGuide.html</span></u></a></p>            </div>
                </div>