---
layout:     post
title:      MapReduce基础-自定义WordCount过程
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <div><span style="color:#663300;">hadoop自带的wordcount应用：</span><br>&gt;1）本地文件hello.txt<br> cat hello.txt<br>2）复制文件：<br>cp hello.txt hello2.txt<br>3）在远程<span style="color:#660000;">创建</span>d3文件夹<br>hadoop@Master:/usr/local/hadoop/share/hadoop/mapreduce$ hadoop fs -mkdir /user/hadoop/d3<br>4）分别将本地的hello.txt文件<span style="color:#660000;">上传</span>到远程hdfs<br>hadoop@Master:/usr/local/hadoop/share/hadoop/mapreduce$ hadoop fs -put hello.txt /user/hadoop/d3<br><br>hadoop@Master:/usr/local/hadoop/share/hadoop/mapreduce$ hadoop fs -put hello2.txt /user/hadoop/d3<br><br>5）执行任务<span style="color:#660000;">,统计hadoop下d3文件夹下的文本文件单词</span>：<br>&gt;hadoop jar hadoop-mapreduce-examples-2.8.0.jar<span style="color:#993300;"> wordcount</span> /user/hadoop/d3 /user/hadoop/d3output<br>这个过程会有mapreduce执行的过程，输出很多info信息，时间从几十秒到几分钟，看统计任务的大小<br>   <br>6）查看输出文件夹，有Success文件表示成功<br>&gt;hadoop fs -ls /user/hadoop/d3output<br>7）显示输出文件中内容结果：<br>&gt;hadoop fs -cat /user/hadoop/d3output/part-r-00000<br><br><span style="font-size:18px;color:#993300;">自定义的WordCount过程：<br><br><img src="https://img-blog.csdn.net/20180502182738786?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d3dzY2Nl8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="285" height="190"><img src="https://img-blog.csdn.net/2018050218282566?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d3dzY2Nl8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="620" height="538"><br><img src="https://img-blog.csdn.net/20180502183014434?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d3dzY2Nl8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="631" height="385"><br><span style="font-size:16px;"><img src="https://img-blog.csdn.net/20180502183503714?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d3dzY2Nl8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br>运行完成后，将<span style="color:#999900;">整个项目</span>导出export成<span style="color:#CC6600;"> <span style="color:#FF6600;">jar file</span></span> <br><span style="font-size:14px;">(我导出的路径是本地的hadoop_file文件夹中的MyWordCount.jar)<br><br>在hadoop中的/user/hadoop/d3文件夹中放入了两个文档如下：<br><img src="https://img-blog.csdn.net/20180502183542700?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d3dzY2Nl8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br>在导出的路径下执行：hadoop jar MyWordCount.jar MyWordCount 输入文件 输出文件<br><img src="https://img-blog.csdn.net/20180502183659819?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d3dzY2Nl8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br><img src="https://img-blog.csdn.net/20180502183731769?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d3dzY2Nl8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br>查看输出文件是否成功输出内容：<br><img src="https://img-blog.csdn.net/20180502183942341?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d3dzY2Nl8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br>最后执行hadoop fs -cat /user/hadoop/output0502单词查看统计结果：<br><img src="https://img-blog.csdn.net/20180502184426399?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d3dzY2Nl8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br><img src="https://img-blog.csdn.net/2018050218462512?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d3dzY2Nl8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="438" height="130"><br></span></span><br></span></div>            </div>
                </div>