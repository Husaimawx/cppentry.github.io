---
layout:     post
title:      hadoop日记2.2：hdfs编程实践
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>Hdfs shell接口 <br>
一、  Hdfs编程实践 <br>
1.  Hadoop提供了关于HDFS在Linux操作系统上进行文件操作的常用Shell命令以及Java API。同时还可以利用Web界面查看和管理Hadoop文件系统 <br>
2.  Hadoop安装成功后，已经包含HDFS和MapReduce，不需要额外安装。而HBase等其他组件，则需要另外下载安装。 <br>
3.  在学习HDFS编程实践前，我们需要启动Hadoop。执行如下命令： <br>
start-all.sh <br>
二、  Hdfs shell常用指令 <br>
1.  HDFS有很多shell命令，利用该命令可以查看HDFS文件系统的目录结构、上传和下载数据、创建文件等。 <br>
2.  Hadoop中有三种Shell命令方式： <br>
hadoop fs适用于任何不同的文件系统，比如本地文件系统和HDFS文件系统 <br>
hadoop dfs只能适用于HDFS文件系统 <br>
hdfs dfs跟hadoop dfs的命令作用一样，也只能适用于HDFS文件系统 <br>
3.  命令的用法为： <br>
hdfs dfs [genericOptions] [commandOptions] <br>
hadoop fs [genericOptions] [commandOptions <br>
三、  Hdfs shell 接口—文件操作指令 <br>
1.  显示指定目录下文件的详细信息 <br>
hdfs dfs -ls / <br>
2.  创建目录 <br>
hdfs dfs -mkdir /music  <br>
3.  上传文件 <br>
hdfs dfs -put test.txt /music <br>
hdfs dfs -copyFromLocal /data/aaa.mp3 /music/b.mp3 <br>
4.  下载文件 <br>
hdfs dfs -copyToLocal /music/b.mp3 /data/bbb.mp3 <br>
5.  查看文件内容 <br>
hdfs dfs -cat /music/test.txt <br>
6.  追加内容 <br>
hdfs dfs -appendToFile README.txt /music/test.txt <br>
7.  复制文件 <br>
hdfs dfs -cp /music/test.txt /music/ljs.txt <br>
8.  重命名文件 <br>
hdfs dfs -mv /user/hadoop/ljs.txt /music/neu.txt <br>
9.  删除文件 <br>
hdfs dfs -rm /music/neu.txt <br>
四、  Hdfs shell接口—管理命令 <br>
dfsadmin 命令用来管理HDFS集群，这些命令只有HDFS的管理员才能使用 <br>
1.  显示集群状态信息 <br>
hdfs dfsadmin -report <br>
2.  将集群置于安全模式 <br>
hdfs dfsadmin -safemode enter <br>
3.  设置每个数据节点在HDFS块平衡时的网络带宽 <br>
hdfs dfsadmin -setBalancerBandwidth 1000 <br>
4.  显示拓扑 <br>
hdfs dfsadmin -printTopology <br>
五、  Hdfs shell接口—文件系统检查 <br>
1.  Hadoop提供一个fsck工具来检查HDFS中文件的健康情况。该工具将查找所有数据节点中丢失的块；副本不足或者副本过多的块；查看一个文件的所有数据块位置；删除损坏的数据块。 <br>
2.  hdfs fsck / <br>
3.  hdfs fsck /music/README.txt –locations <br>
六、  动态新增节点 <br>
1.  clone 一份 slave2 作为新增的节点 slave3，修改静态 IP ，同时修改 master 、slave1 和 slave2 的 /etc/hosts 文件 <br>
2.  修改 master 的 etc/hadoop/slaves 文件，添加新增的节点 slave3，并将其更新到各个节点。 <br>
3.  在新增的 slave3 节点执行命令启动 datanode  <br>
./sbin/hadoop-daemon.sh start datanode <br>
4.  在新增的 slave3 节点执行命令启动 nodemanager <br>
./sbin/yarn-daemon.sh start nodemanager <br>
七、  动态删除节点 <br>
1.  在etc/hadoop/ 目录下添加 excludes 文件，配置需要删除的节点 <br>
2.  修改 etc/hadoop/hdfs-site.xml <br>
 <br>
   dfs.hosts.exclude <br>
   /home/hadoop/hadoop-2.7.2/etc/hadoop/excludes <br>
 <br>
3.  修改 mapred-site.xml <br>
 <br>
        mapred.hosts.exclude <br>
        /home/hadoop/hadoop-2.7.2/etc/hadoop/excludes <br>
        true <br>
 <br>
4.  对节点进行强制刷新 <br>
hdfs dfsadmin –refreshNodes <br>
5.  查看节点状态，该节点的状态为Decommissioned （退役） <br>
6.  在 slave3 节点上关闭 datanode 和 nodemanager 进程 <br>
hadoop-daemon.sh stop datanode <br>
yarn-daemon.sh stop nodemanager <br>
7.  运行start-balancer.sh均衡 block <br>
8.  start-balancer.sh <br>
hdfs自带的WEB接口 <br>
•   HDFS自带的WEB接口主要面向HDFS管理员 <br>
•   页面的信息主要包括HDFS系统级别统计信息和文件系统 <br>
•   hdfs管理界面：   <a href="http://NameNodeIP:50070/" rel="nofollow">http://NameNodeIP:50070/</a> <br>
hdfs java编程</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>