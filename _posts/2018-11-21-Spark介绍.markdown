---
layout:     post
title:      Spark介绍
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/chengqiuming/article/details/79252657				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<div><strong>一 Spark是什么</strong></div>
<div>Spark是一个快速且通用的集群计算平台。</div>
<div><br></div>
<div><strong>二 Spark的特点</strong></div>
<div>1 Spark是快速的</div>
<div>Spark扩充了流行的Mapreduce计算模型</div>
<div>Spark是基于内存的计算</div>
<div>2 Spark是通用的</div>
<div>Spark的设计容纳了其它分布式系统拥有的功能</div>
<div>批处理（Hadoop），迭代式计算（机器学习）、交互查询（Hive）和流处理（Storm）等</div>
<div>优点：降低了维护成本</div>
<div>3 Spark是高度开放的</div>
<div>Spark提供了Python，Java，Scala，SQL的API和丰富的内置库。</div>
<div>Spark和其它的大数据工具整合得很好，包括hadoop，kafka等。</div>
<div><br></div>
<div><strong>三 Spark历史</strong></div>
<div>诞生于2009年，加州大学伯克利分校AMP实验室的一个研究项目。</div>
<div>最初是基于Hadoop Mapreduce的。</div>
<div>发现Mapreduce在迭代式计算和交互上低效，引入了内存存储。</div>
<div>2010年3月份Spark开源</div>
<div>2011年AMP实验室在Spark上开发高级组件，像Spark Streaming</div>
<div>2013年转移到了Apache下，不久便成为顶级项目。</div>
<div><br></div>
<div><strong>四 Spark的组件</strong></div>
<div>Spark包括多个紧密集成的组件</div>
<div><img src="https://img-blog.csdn.net/20180204145538655?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2hlbmdxaXVtaW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></div>
<div>1 Spark Core</div>
<div>包含了Spark的基本功能，包含任务调度，内存管理，容错机制等等。</div>
<div>内部定义了RDD（弹性分布式数据集）</div>
<div>提供了很多APIs来创建和操作这些RDD</div>
<div>应用场景：为其他组件提供底层的服务</div>
<div>2 Spark SQL</div>
<div>是Spark处理结构化数据的库，就像Hive SQL，Mysql一样。</div>
<div>应用场景：企业中用来做报表统计</div>
<div>3 Spark Streaming</div>
<div>是实时数据流处理组件，类似Storm</div>
<div>Spark Streaming提供了API操作实时流数据</div>
<div>应用场景：企业中用来从Kafka接收数据做实时统计。</div>
<div>4 Mlib</div>
<div>一个包含通用机器学习功能的包，Machine learning lib</div>
<div>包含分类、聚类、回归等，还包括模型评估和数据导入。</div>
<div>MLib提供的上面这些方法，都支持集群上的横向扩展。</div>
<div>应用场景：机器学习</div>
<div>5 Graphx</div>
<div>是处理图的库（例如，社交网络图），并进行图的并行计算。</div>
<div>像Spark Streaming，Spark SQL一样，它也继承了RDD API。</div>
<div>它提供了各种图的操作，和常用的图算法，例如PangeRank算法。</div>
<div>应用场景：图计算。</div>
<div>6 Cluster Managers</div>
<div>就是集群管理，Spark自带一个集群管理是单独调度器。</div>
<div>常见集群管理包括Hadoop YARN,Apache Mesos</div>
<div><br></div>
<div><strong>五 紧密集成的优点</strong></div>
<div>Spark底层优化了，基于Spark底层的组件，也得到了相应的优化。</div>
<div>紧密集成，节省了各个组件组合使用时的部署，测试等时间。</div>
<div>向Spark增加新的组件时，其他组件，可立刻享用新组件的功能。</div>
<div><br></div>
<div><strong>六 Spark和Hadoop的比较</strong></div>
<div>1 Hadoop应用场景</div>
<div>离线处理</div>
<div>对时效性要求不高</div>
<div>2 Spark应用场景</div>
<div>时效性要求高的场景</div>
<div>机器学习等领域</div>
<div>3 比较</div>
<div>Doug Cutting的观点</div>
<div>这是一个生态系统，每个组件都有其作用，各善其职即可。</div>
<div>Spark不具有HDFS的存储能力，要借助于HDFS等持久化数据。</div>
<div>大数据将会孕育出更多的新技术。</div>
            </div>
                </div>