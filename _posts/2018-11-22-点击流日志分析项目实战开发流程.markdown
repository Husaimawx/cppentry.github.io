---
layout:     post
title:      点击流日志分析项目实战开发流程
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<hr>

<p>step-1： <br>
使用flume采集数据到 /flume/events/%y-%m-%d/下面 <br>
 flume配置</p>



<pre class="prettyprint"><code class=" hljs avrasm"> tail-hdfs<span class="hljs-preprocessor">.conf</span>

用tail命令获取数据，下沉到hdfs
启动命令：
bin/flume-ng agent -c conf -f conf/tail-hdfs<span class="hljs-preprocessor">.conf</span> -n a1
<span class="hljs-preprocessor">########</span>

<span class="hljs-preprocessor"># Name the components on this agent</span>
a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span>
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.channels</span> = c1

<span class="hljs-preprocessor"># Describe/configure the source</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = exec
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.command</span> = tail -F /home/hadoop/log/test<span class="hljs-preprocessor">.log</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1

<span class="hljs-preprocessor"># Describe the sink</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = hdfs
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.path</span> = /flume/events/%<span class="hljs-built_in">y</span>-%m-%d/
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.filePrefix</span> = events-
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.round</span> = true
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.roundValue</span> = <span class="hljs-number">10</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.roundUnit</span> = minute
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.rollInterval</span> = <span class="hljs-number">3</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.rollSize</span> = <span class="hljs-number">20</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.rollCount</span> = <span class="hljs-number">5</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.batchSize</span> = <span class="hljs-number">1</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.useLocalTimeStamp</span> = true
<span class="hljs-preprocessor">#生成的文件类型，默认是Sequencefile，可用DataStream，则为普通文本</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.fileType</span> = DataStream



<span class="hljs-preprocessor"># Use a channel which buffers events in memory</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = memory
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.capacity</span> = <span class="hljs-number">1000</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.transactionCapacity</span> = <span class="hljs-number">100</span>

<span class="hljs-preprocessor"># Bind the source and sink to the channel</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1</code></pre>

<p>step-2 移动数据到预处理工作目录 <br>
tail-hdfs.conf</p>



<pre class="prettyprint"><code class=" hljs bash"> <span class="hljs-comment">#!/bin/bash</span>

<span class="hljs-comment">#</span>
<span class="hljs-comment"># ===========================================================================</span>
<span class="hljs-comment"># 程序名称:     </span>
<span class="hljs-comment"># 功能描述:     移动文件到预处理工作目录</span>
<span class="hljs-comment"># 输入参数:     运行日期</span>
<span class="hljs-comment"># 目标路径:     /data/weblog/preprocess/input</span>
<span class="hljs-comment"># 数据源 :     /data/weblog/preprocess/output</span>
<span class="hljs-comment"># 创建人 :     ljt</span>
<span class="hljs-comment"># 创建日期:     2016-12-21</span>
<span class="hljs-comment"># 版本说明:     v1.0</span>
<span class="hljs-comment"># 代码审核:     </span>
<span class="hljs-comment"># 修改人名:</span>
<span class="hljs-comment"># 修改日期:</span>
<span class="hljs-comment"># 修改原因:</span>
<span class="hljs-comment"># 修改列表: </span>
<span class="hljs-comment"># ===========================================================================</span>

<span class="hljs-comment">#set java env</span>
<span class="hljs-keyword">export</span> JAVA_HOME=/home/hadoop/apps/jdk1.<span class="hljs-number">7.0</span>_51
<span class="hljs-keyword">export</span> JRE_HOME=<span class="hljs-variable">${JAVA_HOME}</span>/jre
<span class="hljs-keyword">export</span> CLASSPATH=.:<span class="hljs-variable">${JAVA_HOME}</span>/lib:<span class="hljs-variable">${JRE_HOME}</span>/lib
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">${JAVA_HOME}</span>/bin:<span class="hljs-variable">$PATH</span>

<span class="hljs-comment">#set hadoop env</span>
<span class="hljs-keyword">export</span> HADOOP_HOME=/home/hadoop/apps/hadoop-<span class="hljs-number">2.6</span>.<span class="hljs-number">1</span>
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">${HADOOP_HOME}</span>/bin:<span class="hljs-variable">${HADOOP_HOME}</span>/sbin:<span class="hljs-variable">$PATH</span>



<span class="hljs-comment">#flume采集生成的日志文件存放的目录</span>
log_flume_dir=/data/flumedata/

<span class="hljs-comment">#预处理程序的工作目录</span>
log_pre_input=/data/weblog/preprocess/input


<span class="hljs-comment">#获取时间信息</span>
day_01=`date <span class="hljs-operator">-d</span><span class="hljs-string">'-1 day'</span> +%Y-%m-%d`
syear=`date --date=<span class="hljs-variable">$day_01</span> +%Y`
smonth=`date --date=<span class="hljs-variable">$day_01</span> +%m`
sday=`date --date=<span class="hljs-variable">$day_01</span> +%d`


<span class="hljs-comment">#读取日志文件的目录，判断是否有需要上传的文件</span>
files=`hadoop fs -ls <span class="hljs-variable">$log_flume_dir</span> | grep <span class="hljs-variable">$day_01</span> | wc <span class="hljs-operator">-l</span>`
<span class="hljs-keyword">if</span> [ <span class="hljs-variable">$files</span> <span class="hljs-operator">-gt</span> <span class="hljs-number">0</span> ]; <span class="hljs-keyword">then</span>
hadoop fs -mv <span class="hljs-variable">${log_flume_dir}</span>/<span class="hljs-variable">${day_01}</span> <span class="hljs-variable">${log_pre_input}</span>
<span class="hljs-built_in">echo</span> <span class="hljs-string">"success moved <span class="hljs-variable">${log_flume_dir}</span>/<span class="hljs-variable">${day_01}</span> to <span class="hljs-variable">${log_pre_input}</span> ....."</span>
<span class="hljs-keyword">fi</span>
</code></pre>

<p>step-3 运行预处理MR程序 <br>
log_click.sh：</p>



<pre class="prettyprint"><code class=" hljs bash"> <span class="hljs-comment">#!/bin/bash</span>

<span class="hljs-comment">#</span>
<span class="hljs-comment"># ===========================================================================</span>
<span class="hljs-comment"># 程序名称:     </span>
<span class="hljs-comment"># 功能描述:     点击流模型数据预处理</span>
<span class="hljs-comment"># 输入参数:     运行日期</span>
<span class="hljs-comment"># 目标路径:     /data/weblog/preprocess/input</span>
<span class="hljs-comment"># 数据源  :     /data/weblog/preprocess/output</span>
<span class="hljs-comment">#   创建人:     ljt</span>
<span class="hljs-comment"># 创建日期:     2016-12-21</span>
<span class="hljs-comment"># 版本说明:     v1.0</span>
<span class="hljs-comment"># 代码审核:     </span>
<span class="hljs-comment"># 修改人名:</span>
<span class="hljs-comment"># 修改日期:</span>
<span class="hljs-comment"># 修改原因:</span>
<span class="hljs-comment"># 修改列表: </span>
<span class="hljs-comment"># ===========================================================================</span>

<span class="hljs-comment">#set java env</span>
<span class="hljs-keyword">export</span> JAVA_HOME=/home/hadoop/apps/jdk1.<span class="hljs-number">7.0</span>_51
<span class="hljs-keyword">export</span> JRE_HOME=<span class="hljs-variable">${JAVA_HOME}</span>/jre
<span class="hljs-keyword">export</span> CLASSPATH=.:<span class="hljs-variable">${JAVA_HOME}</span>/lib:<span class="hljs-variable">${JRE_HOME}</span>/lib
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">${JAVA_HOME}</span>/bin:<span class="hljs-variable">$PATH</span>

<span class="hljs-comment">#set hadoop env</span>
<span class="hljs-keyword">export</span> HADOOP_HOME=/home/hadoop/apps/hadoop-<span class="hljs-number">2.6</span>.<span class="hljs-number">1</span>
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">${HADOOP_HOME}</span>/bin:<span class="hljs-variable">${HADOOP_HOME}</span>/sbin:<span class="hljs-variable">$PATH</span>


<span class="hljs-comment">#点击流pagevies模型预处理程序类名</span>
click_pv_class=<span class="hljs-string">"cn.itcast.bigdata.hive.mr.ClickStreamThree"</span>
<span class="hljs-comment">#点击流pagevies模型程序输入目录，即预处理输出结果(valid)目录</span>
log_pre_output=/data/weblog/preprocess/output
<span class="hljs-comment">#点击流pagevies模型预处理程序输出目录</span>
click_pvout=/data/weblog/preprocess/click_pv_out



<span class="hljs-comment">#点击流visit模型预处理程序类名</span>
click_visit_class=<span class="hljs-string">"cn.itcast.bigdata.hive.mr.ClickStreamVisit"</span>


<span class="hljs-comment">#点击流visit模型预处理程序输入目录，即pagevies模型预处理程序输出目录  $click_pvout</span>

<span class="hljs-comment">#点击流visit模型预处理程序输出目录</span>
click_vstout=/data/weblog/preprocess/click_visit_out


<span class="hljs-comment">#获取时间信息</span>
day_01=`date <span class="hljs-operator">-d</span><span class="hljs-string">'-1 day'</span> +%Y-%m-%d`
syear=`date --date=<span class="hljs-variable">$day_01</span> +%Y`
smonth=`date --date=<span class="hljs-variable">$day_01</span> +%m`
sday=`date --date=<span class="hljs-variable">$day_01</span> +%d`


<span class="hljs-comment">#读取日志文件的目录，判断是否有当日待处理的目录(如：2016-03-18)</span>
files=`hadoop fs -ls <span class="hljs-variable">$log_pre_output</span> | grep <span class="hljs-variable">$day_01</span> | wc <span class="hljs-operator">-l</span>`
<span class="hljs-keyword">if</span> [ <span class="hljs-variable">$files</span> <span class="hljs-operator">-gt</span> <span class="hljs-number">0</span> ]; <span class="hljs-keyword">then</span>
<span class="hljs-comment">#提交mr任务job运行</span>
<span class="hljs-built_in">echo</span> <span class="hljs-string">"running..    hadoop jar weblog.jar <span class="hljs-variable">$click_pv_class</span> <span class="hljs-variable">$log_pre_output</span>/<span class="hljs-variable">$day_01</span> <span class="hljs-variable">$click_pvout</span>/<span class="hljs-variable">$day_01</span>"</span>
hadoop jar weblog.jar <span class="hljs-variable">$click_pv_class</span> <span class="hljs-variable">$log_pre_output</span>/<span class="hljs-variable">$day_01</span> <span class="hljs-variable">$click_pvout</span>/<span class="hljs-variable">$day_01</span>
<span class="hljs-keyword">fi</span>

<span class="hljs-built_in">echo</span> <span class="hljs-string">"pv处理运行结果： $?"</span>
<span class="hljs-keyword">if</span> [ $? <span class="hljs-operator">-eq</span> <span class="hljs-number">0</span> ];<span class="hljs-keyword">then</span>
<span class="hljs-comment">#提交mr任务job运行</span>
<span class="hljs-built_in">echo</span> <span class="hljs-string">"running..    hadoop jar weblog.jar <span class="hljs-variable">$click_visit_class</span> <span class="hljs-variable">$click_pvout</span> <span class="hljs-variable">$day_01</span> <span class="hljs-variable">$click_vstout</span>/<span class="hljs-variable">$day_01</span>"</span>
hadoop jar weblog.jar <span class="hljs-variable">$click_visit_class</span> <span class="hljs-variable">$click_pvout</span>/<span class="hljs-variable">$day_01</span> <span class="hljs-variable">$click_vstout</span>/<span class="hljs-variable">$day_01</span>
<span class="hljs-keyword">fi</span>
</code></pre>

<p>log_preprocess.sh</p>



<pre class="prettyprint"><code class=" hljs bash"> <span class="hljs-comment">#!/bin/bash</span>

<span class="hljs-comment">#</span>
<span class="hljs-comment"># ===========================================================================</span>
<span class="hljs-comment"># 程序名称:     </span>
<span class="hljs-comment"># 功能描述:     预处理原始日志</span>
<span class="hljs-comment"># 输入参数:     运行日期</span>
<span class="hljs-comment"># 目标路径:     /data/weblog/preprocess/input</span>
<span class="hljs-comment"># 数据源  :     /data/weblog/preprocess/output</span>
<span class="hljs-comment">#   创建人:     ljt</span>
<span class="hljs-comment"># 创建日期:     2016-12-21</span>
<span class="hljs-comment"># 版本说明:     v1.0</span>
<span class="hljs-comment"># 代码审核:     </span>
<span class="hljs-comment"># 修改人名:</span>
<span class="hljs-comment"># 修改日期:</span>
<span class="hljs-comment"># 修改原因:</span>
<span class="hljs-comment"># 修改列表: </span>
<span class="hljs-comment"># ===========================================================================</span>

<span class="hljs-comment">#set java env</span>
<span class="hljs-keyword">export</span> JAVA_HOME=/home/hadoop/apps/jdk1.<span class="hljs-number">7.0</span>_51
<span class="hljs-keyword">export</span> JRE_HOME=<span class="hljs-variable">${JAVA_HOME}</span>/jre
<span class="hljs-keyword">export</span> CLASSPATH=.:<span class="hljs-variable">${JAVA_HOME}</span>/lib:<span class="hljs-variable">${JRE_HOME}</span>/lib
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">${JAVA_HOME}</span>/bin:<span class="hljs-variable">$PATH</span>

<span class="hljs-comment">#set hadoop env</span>
<span class="hljs-keyword">export</span> HADOOP_HOME=/home/hadoop/apps/hadoop-<span class="hljs-number">2.6</span>.<span class="hljs-number">1</span>
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">${HADOOP_HOME}</span>/bin:<span class="hljs-variable">${HADOOP_HOME}</span>/sbin:<span class="hljs-variable">$PATH</span>


<span class="hljs-comment">#预处理程序类名</span>
preprocess_class=<span class="hljs-string">"cn.itcast.bigdata.hive.mr.pre.WeblogPreProcess"</span>
<span class="hljs-comment">#只输出valid记录的预处理程序类名</span>
pre_valid_class=<span class="hljs-string">"cn.itcast.bigdata.hive.mr.pre.WeblogPreValid"</span>

<span class="hljs-comment">#待处理日志存放的目录</span>
log_pre_input=/data/weblog/preprocess/input

<span class="hljs-comment">#预处理输出结果(raw)目录</span>
log_pre_output=/data/weblog/preprocess/output
<span class="hljs-comment">#预处理输出结果(valid)目录</span>
log_pre_valid_output=/data/weblog/preprocess/valid_output


<span class="hljs-comment">#获取时间信息</span>
day_01=`date <span class="hljs-operator">-d</span><span class="hljs-string">'-1 day'</span> +%Y-%m-%d`
syear=`date --date=<span class="hljs-variable">$day_01</span> +%Y`
smonth=`date --date=<span class="hljs-variable">$day_01</span> +%m`
sday=`date --date=<span class="hljs-variable">$day_01</span> +%d`


<span class="hljs-comment">#读取日志文件的目录，判断是否有当日待处理的目录(如：2016-03-18)</span>
files=`hadoop fs -ls <span class="hljs-variable">$log_pre_input</span> | grep <span class="hljs-variable">$day_01</span> | wc <span class="hljs-operator">-l</span>`
<span class="hljs-keyword">if</span> [ <span class="hljs-variable">$files</span> <span class="hljs-operator">-gt</span> <span class="hljs-number">0</span> ]; <span class="hljs-keyword">then</span>
<span class="hljs-comment">#提交mr任务job运行</span>
<span class="hljs-built_in">echo</span> <span class="hljs-string">"running..    hadoop jar weblog.jar <span class="hljs-variable">$preprocess_class</span> <span class="hljs-variable">$log_pre_input</span>/<span class="hljs-variable">$day_01</span> /<span class="hljs-variable">$log_pre_output</span>/<span class="hljs-variable">$day_01</span>"</span>
hadoop jar weblog.jar <span class="hljs-variable">$preprocess_class</span> <span class="hljs-variable">$log_pre_input</span>/<span class="hljs-variable">$day_01</span> <span class="hljs-variable">$log_pre_output</span>/<span class="hljs-variable">$day_01</span>
<span class="hljs-keyword">fi</span>

<span class="hljs-built_in">echo</span> <span class="hljs-string">"raw预处理运行结果： $?"</span>
<span class="hljs-keyword">if</span> [ $? <span class="hljs-operator">-eq</span> <span class="hljs-number">0</span> ];<span class="hljs-keyword">then</span>
<span class="hljs-comment">#提交mr任务job运行</span>
<span class="hljs-built_in">echo</span> <span class="hljs-string">"running..    hadoop jar weblog.jar <span class="hljs-variable">$pre_valid_class</span> <span class="hljs-variable">$log_pre_input</span> <span class="hljs-variable">$day_01</span> /<span class="hljs-variable">$log_pre_valid_output</span>/<span class="hljs-variable">$day_01</span>"</span>
hadoop jar weblog.jar <span class="hljs-variable">$pre_valid_class</span> <span class="hljs-variable">$log_pre_input</span>/<span class="hljs-variable">$day_01</span> <span class="hljs-variable">$log_pre_valid_output</span>/<span class="hljs-variable">$day_01</span>
<span class="hljs-keyword">fi</span>


<span class="hljs-comment">#如果失败</span>
<span class="hljs-comment">#发送邮件或短信，人为来干预 </span></code></pre>

<p>step-4 加载数据到ODS（Operational Data Store）进行数据仓库存储 <br>
建立数据仓库，连接hive创建对应的数据仓库ODS</p>



<pre class="prettyprint"><code class=" hljs applescript"> hive&gt; create database click_streaming;
OK
Time taken: <span class="hljs-number">0.521</span> seconds
hive&gt; show databases;
OK
click_streaming
default
Time taken: <span class="hljs-number">0.022</span> seconds, Fetched: <span class="hljs-number">2</span> row(s)
hive&gt; use click_streaming;

<span class="hljs-comment">#数据仓库DDL</span>

<span class="hljs-comment">#ods贴源表</span>
drop table <span class="hljs-keyword">if</span> exists ods_weblog_origin;
create table ods_weblog_origin(
valid <span class="hljs-type">string</span>,
remote_addr <span class="hljs-type">string</span>,
remote_user <span class="hljs-type">string</span>,
time_local <span class="hljs-type">string</span>,
request <span class="hljs-type">string</span>,
status <span class="hljs-type">string</span>,
body_bytes_sent <span class="hljs-type">string</span>,
http_referer <span class="hljs-type">string</span>,
http_user_agent <span class="hljs-type">string</span>)
partitioned <span class="hljs-keyword">by</span> (datestr <span class="hljs-type">string</span>)
row format delimited
fields terminated <span class="hljs-keyword">by</span> '\<span class="hljs-number">001</span>';



<span class="hljs-comment">#ods点击流pageviews表</span>
drop table <span class="hljs-keyword">if</span> exists ods_click_pageviews;
create table ods_click_pageviews(
Session <span class="hljs-type">string</span>,
remote_addr <span class="hljs-type">string</span>,
<span class="hljs-comment">#加一个字段   user string,</span>
time_local <span class="hljs-type">string</span>,
request <span class="hljs-type">string</span>,
visit_step <span class="hljs-type">string</span>,
page_staylong <span class="hljs-type">string</span>,
http_referer <span class="hljs-type">string</span>,
http_user_agent <span class="hljs-type">string</span>,
body_bytes_sent <span class="hljs-type">string</span>,
status <span class="hljs-type">string</span>)
partitioned <span class="hljs-keyword">by</span> (datestr <span class="hljs-type">string</span>)
row format delimited
fields terminated <span class="hljs-keyword">by</span> '\<span class="hljs-number">001</span>';


<span class="hljs-comment">#点击流visit表</span>
drop table <span class="hljs-keyword">if</span> exist ods_click_visit;
create table ods_click_visit(
session     <span class="hljs-type">string</span>,
remote_addr <span class="hljs-type">string</span>,
inTime      <span class="hljs-type">string</span>,
outTime     <span class="hljs-type">string</span>,
inPage      <span class="hljs-type">string</span>,
outPage     <span class="hljs-type">string</span>,
referal     <span class="hljs-type">string</span>,
pageVisits  int)
partitioned <span class="hljs-keyword">by</span> (datestr <span class="hljs-type">string</span>);



<span class="hljs-comment">#etl明细宽表</span>
drop table ods_weblog_detail;
create table ods_weblog_detail(
valid           <span class="hljs-type">string</span>, <span class="hljs-comment">--有效标识</span>
remote_addr     <span class="hljs-type">string</span>, <span class="hljs-comment">--来源IP</span>
remote_user     <span class="hljs-type">string</span>, <span class="hljs-comment">--用户标识</span>
time_local      <span class="hljs-type">string</span>, <span class="hljs-comment">--访问完整时间</span>
daystr          <span class="hljs-type">string</span>, <span class="hljs-comment">--访问日期</span>
timestr         <span class="hljs-type">string</span>, <span class="hljs-comment">--访问时间</span>
<span class="hljs-property">month</span>           <span class="hljs-type">string</span>, <span class="hljs-comment">--访问月</span>
<span class="hljs-property">day</span>             <span class="hljs-type">string</span>, <span class="hljs-comment">--访问日</span>
hour            <span class="hljs-type">string</span>, <span class="hljs-comment">--访问时</span>
request         <span class="hljs-type">string</span>, <span class="hljs-comment">--请求的url</span>
status          <span class="hljs-type">string</span>, <span class="hljs-comment">--响应码</span>
body_bytes_sent <span class="hljs-type">string</span>, <span class="hljs-comment">--传输字节数</span>
http_referer    <span class="hljs-type">string</span>, <span class="hljs-comment">--来源url</span>
ref_host        <span class="hljs-type">string</span>, <span class="hljs-comment">--来源的host</span>
ref_path        <span class="hljs-type">string</span>, <span class="hljs-comment">--来源的路径</span>
ref_query       <span class="hljs-type">string</span>, <span class="hljs-comment">--来源参数query</span>
ref_query_id    <span class="hljs-type">string</span>, <span class="hljs-comment">--来源参数query的值</span>
http_user_agent <span class="hljs-type">string</span> <span class="hljs-comment">--客户终端标识</span>
)
partitioned <span class="hljs-keyword">by</span>(datestr <span class="hljs-type">string</span>);

<span class="hljs-comment">#时间维度表</span>
create table v_time(<span class="hljs-property">year</span> <span class="hljs-type">string</span>,<span class="hljs-property">month</span> <span class="hljs-type">string</span>,<span class="hljs-property">day</span> <span class="hljs-type">string</span>,hour <span class="hljs-type">string</span>)
row format delimited
fields terminated <span class="hljs-keyword">by</span> ',';

load data <span class="hljs-keyword">local</span> inpath '/home/hadoop/v_time.txt' <span class="hljs-keyword">into</span> table v_time;


<span class="hljs-comment">#每小时pv统计表</span>
drop table dw_pvs_hour;
create table dw_pvs_hour(<span class="hljs-property">month</span> <span class="hljs-type">string</span>,<span class="hljs-property">day</span> <span class="hljs-type">string</span>,hour <span class="hljs-type">string</span>,pvs bigint) partitioned <span class="hljs-keyword">by</span>(datestr <span class="hljs-type">string</span>);

<span class="hljs-comment">#每日用户平均pv</span>
drop table dw_avgpv_user_d;
create table dw_avgpv_user_d(
<span class="hljs-property">day</span> <span class="hljs-type">string</span>,
avgpv <span class="hljs-type">string</span>);

<span class="hljs-comment">#来源维度PV统计表(小时粒度)</span>
drop table zs.dw_pvs_referer_h;
create table zs.dw_pvs_referer_h(referer_url <span class="hljs-type">string</span>,referer_host <span class="hljs-type">string</span>,<span class="hljs-property">month</span> <span class="hljs-type">string</span>,<span class="hljs-property">day</span> <span class="hljs-type">string</span>,hour <span class="hljs-type">string</span>,pv_referer_cnt bigint) partitioned <span class="hljs-keyword">by</span>(datestr <span class="hljs-type">string</span>);

<span class="hljs-comment">#每小时来源PV topn</span>
drop table zs.dw_pvs_refhost_topn_h;
create table zs.dw_pvs_refhost_topn_h(
hour <span class="hljs-type">string</span>,
toporder <span class="hljs-type">string</span>,
ref_host <span class="hljs-type">string</span>,
ref_host_cnts <span class="hljs-type">string</span>
) partitioned <span class="hljs-keyword">by</span>(datestr <span class="hljs-type">string</span>);
</code></pre>



<pre class="prettyprint"><code class=" hljs bash"> <span class="hljs-comment">#!/bin/bash</span>

<span class="hljs-comment">#</span>
<span class="hljs-comment"># ===========================================================================</span>
<span class="hljs-comment"># 程序名称:     </span>
<span class="hljs-comment"># 功能描述:     加载数据到ODS</span>
<span class="hljs-comment"># 输入参数:     运行日期</span>
<span class="hljs-comment"># 数据路径:     /data/weblog/preprocess/output</span>
<span class="hljs-comment"># 目标hive:     sz.ods_weblog_orgin</span>
<span class="hljs-comment">#   创建人:     ljt</span>
<span class="hljs-comment"># 创建日期:     2016-12-21</span>
<span class="hljs-comment"># 版本说明:     v1.0</span>
<span class="hljs-comment"># 代码审核:     </span>
<span class="hljs-comment"># 修改人名:</span>
<span class="hljs-comment"># 修改日期:</span>
<span class="hljs-comment"># 修改原因:</span>
<span class="hljs-comment"># 修改列表: </span>
<span class="hljs-comment"># ===========================================================================</span>

<span class="hljs-comment">#set java env</span>
<span class="hljs-keyword">export</span> JAVA_HOME=/home/hadoop/apps/jdk1.<span class="hljs-number">7.0</span>_51
<span class="hljs-keyword">export</span> JRE_HOME=<span class="hljs-variable">${JAVA_HOME}</span>/jre
<span class="hljs-keyword">export</span> CLASSPATH=.:<span class="hljs-variable">${JAVA_HOME}</span>/lib:<span class="hljs-variable">${JRE_HOME}</span>/lib
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">${JAVA_HOME}</span>/bin:<span class="hljs-variable">$PATH</span>

<span class="hljs-comment">#set hadoop env</span>
<span class="hljs-keyword">export</span> HADOOP_HOME=/home/hadoop/apps/hadoop-<span class="hljs-number">2.6</span>.<span class="hljs-number">1</span>
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">${HADOOP_HOME}</span>/bin:<span class="hljs-variable">${HADOOP_HOME}</span>/sbin:<span class="hljs-variable">$PATH</span>


<span class="hljs-comment">#获取时间信息</span>
day_01=`date <span class="hljs-operator">-d</span><span class="hljs-string">'-1 day'</span> +%Y-%m-%d`
syear=`date --date=<span class="hljs-variable">$day_01</span> +%Y`
smonth=`date --date=<span class="hljs-variable">$day_01</span> +%m`
sday=`date --date=<span class="hljs-variable">$day_01</span> +%d`

<span class="hljs-comment">#预处理输出结果(raw)目录</span>
log_pre_output=/data/weblog/preprocess/output
<span class="hljs-comment">#点击流pagevies模型预处理程序输出目录</span>
click_pvout=<span class="hljs-string">"/data/weblog/preprocess/click_pv_out"</span>
<span class="hljs-comment">#点击流visit模型预处理程序输出目录</span>
click_vstout=<span class="hljs-string">"/data/weblog/preprocess/click_visit_out"</span>

<span class="hljs-comment">#目标hive表</span>
ods_weblog_origin=<span class="hljs-string">"shizhan.ods_weblog_origin"</span>
ods_click_pageviews=<span class="hljs-string">"shizhan.ods_click_pageviews"</span>
ods_click_visit=<span class="hljs-string">"shizhan.ods_click_visit"</span>

<span class="hljs-comment">#导入raw数据到zs.ods_weblog_origin</span>
HQL_origin=<span class="hljs-string">"load data inpath '<span class="hljs-variable">$log_pre_output</span>/<span class="hljs-variable">$day_01</span>' into table <span class="hljs-variable">$ods_weblog_origin</span> partition(datestr='<span class="hljs-variable">$day_01</span>')"</span>
<span class="hljs-built_in">echo</span> <span class="hljs-variable">$HQL_origin</span> 
/home/hadoop/apps/hive/bin/hive <span class="hljs-operator">-e</span> <span class="hljs-string">"<span class="hljs-variable">$HQL_origin</span>"</span>


<span class="hljs-comment">#导入点击流模型pageviews数据到</span>
HQL_pvs=<span class="hljs-string">"load data inpath '<span class="hljs-variable">$click_pvout</span>/<span class="hljs-variable">$day_01</span>' into table <span class="hljs-variable">$ods_click_pageviews</span> partition(datestr='<span class="hljs-variable">$day_01</span>')"</span>
<span class="hljs-built_in">echo</span> <span class="hljs-variable">$HQL_pvs</span> 
/home/hadoop/apps/hive/bin/hive <span class="hljs-operator">-e</span> <span class="hljs-string">"<span class="hljs-variable">$HQL_pvs</span>"</span>

<span class="hljs-comment">#导入点击流模型visit数据到</span>
HQL_vst=<span class="hljs-string">"load data inpath '<span class="hljs-variable">$click_vstout</span>/<span class="hljs-variable">$day_01</span>' into table <span class="hljs-variable">$ods_click_visit</span> partition(datestr='<span class="hljs-variable">$day_01</span>')"</span>
<span class="hljs-built_in">echo</span> <span class="hljs-variable">$HQL_vst</span> 
/home/hadoop/apps/hive/bin/hive <span class="hljs-operator">-e</span> <span class="hljs-string">"<span class="hljs-variable">$HQL_vst</span>"</span>


</code></pre>

<p><strong>step-5 ETL(extract transfer load )处理</strong></p>

<p>etl_detail.sh</p>



<pre class="prettyprint"><code class=" hljs bash"> <span class="hljs-comment">#!/bin/bash</span>
<span class="hljs-comment"># . /home/anjianbing/soft/functions/wait4FlagFile.sh</span>
<span class="hljs-comment"># ===========================================================================</span>
<span class="hljs-comment"># 程序名称:     </span>
<span class="hljs-comment"># 功能描述:     抽取明细宽表</span>
<span class="hljs-comment"># 输入参数:     运行日期</span>
<span class="hljs-comment"># 目标表名:     zs.ods_weblog_detail</span>
<span class="hljs-comment"># 数据源表:     zs.ods_weblog_origin</span>
<span class="hljs-comment">#   创建人:     ljt</span>
<span class="hljs-comment"># 创建日期:     2016-12-21</span>
<span class="hljs-comment"># 版本说明:     v1.0</span>
<span class="hljs-comment"># 代码审核:     </span>
<span class="hljs-comment"># 修改人名:</span>
<span class="hljs-comment"># 修改日期:</span>
<span class="hljs-comment"># 修改原因:</span>
<span class="hljs-comment"># 修改列表: </span>
<span class="hljs-comment"># ===========================================================================</span>
<span class="hljs-comment">### 1.参数加载</span>
exe_hive=<span class="hljs-string">"/home/hadoop/apps/hive/bin/hive"</span>
<span class="hljs-keyword">if</span> [ <span class="hljs-variable">$#</span> <span class="hljs-operator">-eq</span> <span class="hljs-number">1</span> ]
<span class="hljs-keyword">then</span>
    day_01=`date --date=<span class="hljs-string">"<span class="hljs-variable">${1}</span>"</span> +%Y-%m-%d`
<span class="hljs-keyword">else</span>
    day_01=`date <span class="hljs-operator">-d</span><span class="hljs-string">'-1 day'</span> +%Y-%m-%d`
<span class="hljs-keyword">fi</span>
syear=`date --date=<span class="hljs-variable">$day_01</span> +%Y`
smonth=`date --date=<span class="hljs-variable">$day_01</span> +%m`
sday=`date --date=<span class="hljs-variable">$day_01</span> +%d`

TARGET_DB=zs
TARGET_TABLE=ods_weblog_detail

<span class="hljs-comment">### 2.定义执行HQL</span>
HQL=<span class="hljs-string">"
insert into table zs.ods_weblog_detail partition(datestr='<span class="hljs-variable">$day_01</span>')
select c.valid,c.remote_addr,c.remote_user,c.time_local,
substring(c.time_local,0,10) as daystr,
substring(c.time_local,12) as tmstr,
substring(c.time_local,6,2) as month,
substring(c.time_local,9,2) as day,
substring(c.time_local,11,3) as hour,
c.request,
c.status,
c.body_bytes_sent,
c.http_referer,
c.ref_host,
c.ref_path,
c.ref_query,
c.ref_query_id,
c.http_user_agent
from
(SELECT 
a.valid,
a.remote_addr,
a.remote_user,a.time_local,
a.request,a.status,a.body_bytes_sent,a.http_referer,a.http_user_agent,b.ref_host,b.ref_path,b.ref_query,b.ref_query_id 
FROM zs.ods_weblog_origin a 
LATERAL VIEW 
parse_url_tuple(regexp_replace(http_referer, \"\\\"\", \"\"), 'HOST', 'PATH','QUERY', 'QUERY:id') b 
as ref_host, ref_path, ref_query, ref_query_id) c
"</span>

<span class="hljs-comment">#执行hql</span>
<span class="hljs-variable">$exe_hive</span> <span class="hljs-operator">-e</span> <span class="hljs-string">"<span class="hljs-variable">$HQL</span>"</span>

<span class="hljs-comment">#异常处理</span>
<span class="hljs-comment">#如果失败，发送邮件、短信</span></code></pre>

<p>etl_pvs_hour.sh</p>



<pre class="prettyprint"><code class=" hljs bash"> <span class="hljs-comment">#!/bin/bash</span>
<span class="hljs-comment"># . /home/anjianbing/soft/functions/wait4FlagFile.sh</span>
<span class="hljs-comment"># ===========================================================================</span>
<span class="hljs-comment"># 程序名称:     </span>
<span class="hljs-comment"># 功能描述:     抽取明细宽表</span>
<span class="hljs-comment"># 输入参数:     运行日期</span>
<span class="hljs-comment"># 目标表名:     zs.dw_pvs_hours</span>
<span class="hljs-comment"># 数据源表:     zs.ods_weblog_detail</span>
<span class="hljs-comment">#   创建人:     ljt</span>
<span class="hljs-comment"># 创建日期:     2016-12-21</span>
<span class="hljs-comment"># 版本说明:     v1.0</span>
<span class="hljs-comment"># 代码审核:     </span>
<span class="hljs-comment"># 修改人名:</span>
<span class="hljs-comment"># 修改日期:</span>
<span class="hljs-comment"># 修改原因:</span>
<span class="hljs-comment"># 修改列表: </span>
<span class="hljs-comment"># ===========================================================================</span>
<span class="hljs-comment">### 1.参数加载</span>
exe_hive=<span class="hljs-string">"/home/hadoop/apps/hive/bin/hive"</span>
<span class="hljs-keyword">if</span> [ <span class="hljs-variable">$#</span> <span class="hljs-operator">-eq</span> <span class="hljs-number">1</span> ]
<span class="hljs-keyword">then</span>
    day_01=`date --date=<span class="hljs-string">"<span class="hljs-variable">${1}</span>"</span> +%Y-%m-%d`
<span class="hljs-keyword">else</span>
    day_01=`date <span class="hljs-operator">-d</span><span class="hljs-string">'-1 day'</span> +%Y-%m-%d`
<span class="hljs-keyword">fi</span>
syear=`date --date=<span class="hljs-variable">$day_01</span> +%Y`
smonth=`date --date=<span class="hljs-variable">$day_01</span> +%m`
sday=`date --date=<span class="hljs-variable">$day_01</span> +%d`

TARGET_DB=zs
TARGET_TABLE=dw_pvs_hours

HQL=<span class="hljs-string">"
insert into table zs.dw_pvs_hour partition(datestr='<span class="hljs-variable">$day_01</span>')
select a.month as month,a.day as day,a.hour as hour,count(1) as pvs from zs.ods_weblog_detail a
where a.datestr='<span class="hljs-variable">$day_01</span>' group by a.month,a.day,a.hour;
"</span>
<span class="hljs-comment">#执行hql</span>
<span class="hljs-variable">$exe_hive</span> <span class="hljs-operator">-e</span> <span class="hljs-string">"<span class="hljs-variable">$HQL</span>"</span>
</code></pre>

<p>step-6 sqoop导出结果</p>

<p>sqoop_export.sh</p>

<pre class="prettyprint"><code class=" hljs bash"> <span class="hljs-comment">#!/bin/bash</span>
<span class="hljs-keyword">if</span> [ <span class="hljs-variable">$#</span> <span class="hljs-operator">-eq</span> <span class="hljs-number">1</span> ]
<span class="hljs-keyword">then</span>
    cur_date=`date --date=<span class="hljs-string">"<span class="hljs-variable">${1}</span>"</span> +%Y-%m-%d`
<span class="hljs-keyword">else</span>
    cur_date=`date <span class="hljs-operator">-d</span><span class="hljs-string">'-1 day'</span> +%Y-%m-%d`
<span class="hljs-keyword">fi</span>

<span class="hljs-built_in">echo</span> <span class="hljs-string">"cur_date:"</span><span class="hljs-variable">${cur_date}</span>

year=`date --date=<span class="hljs-variable">$cur_date</span> +%Y`
month=`date --date=<span class="hljs-variable">$cur_date</span> +%m`
day=`date --date=<span class="hljs-variable">$cur_date</span> +%d`

table_name=<span class="hljs-string">""</span>
table_columns=<span class="hljs-string">""</span>
hadoop_dir=/user/rd/bi_dm/app_user_experience_d/year=<span class="hljs-variable">${year}</span>/month=<span class="hljs-variable">${month}</span>/day=<span class="hljs-variable">${day}</span>
mysql_db_<span class="hljs-built_in">pwd</span>=biall_<span class="hljs-built_in">pwd</span>2015
mysql_db_name=bi_tag_all


<span class="hljs-built_in">echo</span> <span class="hljs-string">'sqoop start'</span>
<span class="hljs-variable">$SQOOP_HOME</span>/bin/sqoop <span class="hljs-keyword">export</span> \
--connect <span class="hljs-string">"jdbc:mysql://hadoop03:3306/biclick"</span> \
--username <span class="hljs-variable">$mysql_db_name</span> \
--password <span class="hljs-variable">$mysql_db_pwd</span> \
--table <span class="hljs-variable">$table_name</span> \
--columns <span class="hljs-variable">$table_columns</span> \
--fields-terminated-by <span class="hljs-string">'\001'</span> \
--export-dir <span class="hljs-variable">$hadoop_dir</span>

<span class="hljs-built_in">echo</span> <span class="hljs-string">'sqoop end'</span>
</code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>