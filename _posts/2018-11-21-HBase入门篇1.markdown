---
layout:     post
title:      HBase入门篇1
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p><strong>HBase是什么？ </strong><br>
HBase是Apache Hadoop中的一个子项目，Hbase依托于Hadoop的HDFS作为最基本存储基础单元，通过使用hadoop的DFS工具就可以看到这些这些数据 存储文件夹的结构,还可以通过Map/Reduce的框架(算法)对HBase进行操作，如右侧的图所示：<br><img alt="http://niaklq.bay.livefilestore.com/y1pG0dfN--ZmWUPjevQkIGp0CsXxWQQ6tyzYR-XAsrWWAJYHtvcdtxk0tIK66x8N_1TKj1CO79xLljO32yk0KvLiNi7GAAaa2Lm/storage-hbase-m.png?psid=1" align="right" src="http://niaklq.bay.livefilestore.com/y1pG0dfN--ZmWUPjevQkIGp0CsXxWQQ6tyzYR-XAsrWWAJYHtvcdtxk0tIK66x8N_1TKj1CO79xLljO32yk0KvLiNi7GAAaa2Lm/storage-hbase-m.png?psid=1"><br>
HBase在产品中还包含了Jetty，在HBase启动时采用嵌入式的方式来启动Jetty，因此可以通过web界面对HBase进行管理和查看当前运行的一些状态，非常轻巧。</p>
<p><strong>为什么采用<strong>HBase</strong></strong>？<br>
HBase 不同于一般的关系数据库,它是一个适合于非结构化数据存储的数据库.所谓非结构化数据存储就是说HBase是基于列的而不是基于行的模式，这样方面读写你的大数据内容。</p>
<p>HBase是介于Map Entry(key &amp; value)和DB Row之间的一种数据存储方式。就点有点类似于现在流行的Memcache，但不仅仅是简单的一个key对应一个 value，你很可能需要存储多个属性的数据结构，但没有传统数据库表中那么多的关联关系，这就是所谓的松散数据。</p>
<p>简单来说，你在HBase中的表创建的可以看做是一张很大的表，而这个表的属性可以根据需求去动态增加，在HBase中没有表与表之间关联查询。你只需要 告诉你的数据存储到Hbase的那个column families 就可以了，不需要指定它的具体类型：char,varchar,int,tinyint,text等等。但是你需要注意HBase中不包含事务此类的功 能。</p>
<p>Apache HBase 和Google Bigtable 有非常相似的地方，一个数据行拥有一个可选择的键和任意数量的列。表是疏松的存储的，因此用户可以给行定义各种不同的列，对于这样的功能在大项目中非常实用，可以简化设计和升级的成本。</p>
<p><strong>如何运行<strong>HBase？</strong></strong><br>
从 Apache的HBase的镜像网站上下载一个稳定版本的HBase http://mirrors.devlib.org/apache/hbase/stable/hbase-0.20.6.tar.gz， 下载完成后，对其进行解压缩。确定你的机器中已经正确的安装了Java SDK、SSH，否则将无法正常运行。</p>
<p>$ cd /work/hbase<br>
进入此目录</p>
<p>$ vim conf/hbase-env.sh<br>
export JAVA_HOME=/JDK_PATH<br>
编辑 conf/hbase-env.sh 文件,将JAVA_HOME修改为你的JDK安装目录</p>
<p>$ vim conf/regionservers<br>
输入你的所有HBase服务器名,localhost,或者是ip地址</p>
<p>$ bin/start-hbase.sh<br>
启动hbase, 中间需要你输入两次密码，也可以进行设置不需要输入密码，启动成功，如图所示：<br><a href="http://niaklq.bay.livefilestore.com/y1pWFYhWvI5ERgwMG4bePdDz83rR26EjUEZLSutErAYIwSHutiy3ACDtKYv7rpCFRCojMOhjtnDK2fvJAT9ItlT3lAECIADFbL4/hbase-start.jpg?psid=1" rel="nofollow"><img alt="" src="http://niaklq.bay.livefilestore.com/y1pWFYhWvI5ERgwMG4bePdDz83rR26EjUEZ9Gsh4HolDsWdf6fWSUI1-a8vNa8eg7J70o_4Bwk6B6Dv45QmEP_8Z0wKmYe9lpI7/hbase-start.jpg?psid=1" width="600" height="75"></a></p>
<p>$ bin/hbase rest start<br>
启动hbase REST服务后就可以通过对uri: http://localhost:60050/api/ 的通用REST操作(GET/POST/PUT/DELETE)实现对hbase的REST形式数据操作.</p>
<p>也可以输入以下指令进入HQL指令模式<br>
$ bin/hbase shell</p>
<p>$ bin/stop-hbase.sh<br>
关闭HBase服务</p>
<p><strong>启动时存在的问题</strong></p>
<p>由于linux系统的主机名配置不正确，在运行HBase服务器中可能存在的问题，如图所示：<br><a href="http://niaklq.bay.livefilestore.com/y1pT26oX2ZC-ku7h2O_zxioNgWtxrjuOFgLTpmEkEfwIn6UIeI49S6z3YjAgmj9Z8Sk0jOH9BS4nMXJ44G3z2qlfSVRU4Hlvjov/hbase-start-err.jpg?psid=1" rel="nofollow"><img alt="http://niaklq.bay.livefilestore.com/y1pT26oX2ZC-ku7h2O_zxioNgWtxrjuOFgLRUAcXUB3hW4nQ3hkDj0fvBSIZtAIOa7oairRjCFT8k2D8pzxdQhSCMAqqMHQb4yZ/hbase-start-err.jpg?psid=1" src="http://niaklq.bay.livefilestore.com/y1pT26oX2ZC-ku7h2O_zxioNgWtxrjuOFgLRUAcXUB3hW4nQ3hkDj0fvBSIZtAIOa7oairRjCFT8k2D8pzxdQhSCMAqqMHQb4yZ/hbase-start-err.jpg?psid=1"></a><br>
2010-11-05 11:10:20,189 ERROR org.apache.hadoop.hbase.master.HMaster: Can not start master<br>
java.net.UnknownHostException: ubuntu-server216: ubuntu-server216<br>
表示你的主机名不正确，你可以先查看一下 /etc/hosts/中名称是什么，再用 hostname 命令进行修改， hostname you_server_name</p>
<p><strong>查看运行状态</strong><br>
1、如果你需要对HBase的日志进行监控你可以查看 hbase.x.x./logs/下的日志文件，可以使用tail -f 来查看。<br>
2、通过 web方式查看运行在 HBase 下的zookeeper  http://localhost:60010/zk.jsp<br>
3、如果你需要查看当前的运行状态可以通过web的方式对HBase服务器进行查看，如图所示：<br><a href="http://niaklq.bay.livefilestore.com/y1pT26oX2ZC-ks0XJYGI5SXaYs8SuRTryRl4ikLj1cKpMmEQy4unmQkEIO-mA9k3T-bQkN45OTDCr3B9rk0HWzOW4K5fGdhPvry/hbase-web-1.jpg?psid=1" rel="nofollow"><img alt="http://niaklq.bay.livefilestore.com/y1pT26oX2ZC-ks0XJYGI5SXaYs8SuRTryRlxDB9g5r9cZTiNKbgMuzExCWjDHgc8n-QGH7DTZXqpbWunZMyp3o6dwbiehAsbztO/hbase-web-1.jpg?psid=1" src="http://niaklq.bay.livefilestore.com/y1pT26oX2ZC-ks0XJYGI5SXaYs8SuRTryRlxDB9g5r9cZTiNKbgMuzExCWjDHgc8n-QGH7DTZXqpbWunZMyp3o6dwbiehAsbztO/hbase-web-1.jpg?psid=1"></a></p>
<p><span style="color:#ffffff;"><span style="background-color:rgb(0,0,0);"><strong>扩展阅读1：</strong></span></span><br>
    Apach 的 Hadoop的项目中包含了那些产品，如图所示：<img alt="http://niaklq.bay.livefilestore.com/y1pw70RQtwqhvDs46920vBXAzmfyo0ijLV3suYQl92Y-LClSJfB9zobeWUseNdadE9hcM-8Oh_fRh6HSkrtvpedqdVj7TlR0ioJ/Hadoop.png?psid=1" align="right" src="http://niaklq.bay.livefilestore.com/y1pw70RQtwqhvDs46920vBXAzmfyo0ijLV3suYQl92Y-LClSJfB9zobeWUseNdadE9hcM-8Oh_fRh6HSkrtvpedqdVj7TlR0ioJ/Hadoop.png?psid=1" style="width:309px;"><br>
    <em><strong>Pig </strong></em>是在MapReduce上构建的查询语言(SQL-like),适用于大量并行计算。<br>
    <em><strong>Chukwa </strong></em>是基于Hadoop集群中监控系统，简单来说就是一个“看门狗” (WatchDog)<br>
    <strong><em>Hive </em></strong>是DataWareHouse 和 Map Reduce交集，适用于ETL方面的工作。<br>
    <em><strong>HBase</strong></em> 是一个面向列的分布式数据库。<br>
    <strong><em>Map Reduce</em></strong> 是Google提出的一种算法，用于超大型数据集的并行运算。<br>
    <em><strong>HDFS </strong></em>可以支持千万级的大型分布式文件系统。<br>
    <em><strong>Zookeeper  </strong></em>提供的功能包括：配置维护、名字服务、分布式同步、组服务等，用于分布式系统的可靠协调系统。<br>
    <strong><em>Avro </em></strong>是一个数据序列化系统，设计用于支持大批量数据交换的应用。</p>
<p><span style="color:#ffffff;"><span style="background-color:rgb(0,0,0);"><strong>扩展阅读2：</strong></span></span><br>
    什么是列存储？列存储不同于传统的关系型数据库，其数据在表中是按行存储的，列方式所带来的重要好处之一就是，由于查询中的选择规则是通过列来定义的，因 此整个数据库是自动索引化的。按列存储每个字段的数据聚集存储，在查询只需要少数几个字段的时候，能大大减少读取的数据量，一个字段的数据聚集存储，那就 更容易为这种聚集存储设计更好的压缩/解压算法。这张图讲述了传统的行存储和列存储的区别：<br><img alt="http://niaklq.bay.livefilestore.com/y1pw70RQtwqhvCwKHlcQPk1AohZmNofsBvSo--4NgUV9qk4-V-2Oju2mqEOttZVbxjre3wmVzhp5aWA8-93PR1_gKa6CaTOVyn8/columsbasedvsrowbased-thumb.png?psid=1" src="http://niaklq.bay.livefilestore.com/y1pw70RQtwqhvCwKHlcQPk1AohZmNofsBvSo--4NgUV9qk4-V-2Oju2mqEOttZVbxjre3wmVzhp5aWA8-93PR1_gKa6CaTOVyn8/columsbasedvsrowbased-thumb.png?psid=1" style="width:473px;"><br><br><span style="color:#ffffff;"><span style="background-color:rgb(0,0,0);"><strong>扩展阅读3：</strong></span></span><br>
    对系统海量的Log4J日志可以存放在一个集中式的机器上，在此机器上安装 splunk 可以方便对所有日志查看，安装方法可以参考：<br>
    <a href="http://www.splunk.com/base/Documentation/latest/Installation/InstallonLinux" rel="nofollow">
http://www.splunk.com/base/Documentation/latest/Installation/InstallonLinux</a></p>
            </div>
                </div>