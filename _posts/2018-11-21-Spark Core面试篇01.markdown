---
layout:     post
title:      Spark Core面试篇01
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;background-color:rgb(255,255,255);font-size:24px;">Spark Core面试篇01</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">随着Spark技术在企业中应用越来越广泛，Spark成为大数据开发必须掌握的技能。前期分享了很多关于Spark的学习视频和文章，为了进一步巩固和掌握Spark，在原有spark专刊基础上，新增《Spark面试2000题》专刊，题集包含基础概念、原理、编码开发、性能调优、运维、源代码以及Spark周边生态系统等。部分题集来源于互联网，由梅峰谷志愿者收集和整理，部分题集由梅峰谷志愿者结合生产实际碰到的问题设计出来，希望能给大家带来帮助。</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(255,76,65);"><span style="font-size:18px;"><span style="font-weight:700;">一、简答题</span></span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">1.Spark master使用zookeeper进行HA的，有哪些元数据保存在Zookeeper？</span></span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">答：spark通</span></span><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(85,85,85);"><span style="font-size:16px;">过这个参数spark.deploy.zookeeper.dir指定ma</span></span><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(51,51,51);"><span style="font-size:16px;">ster元数据在zookeeper中保存的位置，包括Worker，Driver和Application以及Executors。</span></span><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">standby节点要从zk中，获得元数据信息，恢复集群运行状态，才能对外继续提供服务，作业提交资源申请等，在恢复前是不能接受请求的。另外，Master切换需要注意2点</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">1）在Master切换的过程中，所有的已经在运行的程序皆正常运行！因为Spark Application在运行前就已经通过Cluster Manager获得了计算资源，所以在运行时Job本身的调度和处理和Master是没有任何关系的！</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">2） 在Master的切换过程中唯一的影响是不能提交新的Job：一方面不能够提交新的应用程序给集群，因为只有Active Master才能接受新的程序的提交请求；另外一方面，已经运行的程序中也不能够因为Action操作触发新的Job的提交请求；</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">2.Spark master HA 主从切换过程不会影响集群已有的作业运行，为什么？</span></span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">答：因为程序在运行之前，已经申请过资源了，driver和</span></span><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(51,51,51);"><span style="font-size:16px;"><span style="font-weight:700;">Executors</span></span></span><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">通讯，不需要和master进行通讯的。</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);">3.Spark on Mesos中，什么是的粗粒度分配，什么是细粒度分配，各自的优点和缺点是什么？</span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">答：1）粗粒度：启动时就分配好资源， 程序启动，后续具体使用就使用分配好的资源，不需要再分配资源；好处：作业特别多时，资源复用率高，适合粗粒度；不好：容易资源浪费，假如一个job有1000个task，完成了999个，还有一个没完成，那么使用粗粒度，999个资源就会闲置在那里，资源浪费。2）细粒度分配：用资源的时候分配，用完了就立即回收资源，启动会麻烦一点，启动一次分配一次，会比较麻烦。</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">4.如何配置spark master的HA？</span></span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">1)配置zookeeper</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(85,85,85);"><span style="font-size:16px;"></span></span><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">2)修改spark_env.sh文件,spark的master参数不在指定，添加如下代码到各个master节点</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">  export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=zk01:2181,zk02:2181,zk03:2181 -Dspark.deploy.zookeeper.dir=/spark"</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">3) 将spark_env.sh分发到各个节点</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">4)找到一个master节点，执行./start-all.sh，会在这里启动主master,其他的master备节点，启动master命令: ./sbin/start-master.sh </span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">5)提交程序的时候指定master的时候要指定三台master，例如</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">./spark-shell --master spark://master01:7077,master02:7077,master03:7077</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">5.Apache Spark有哪些常见的稳定版本，Spark1.6.0的数字分别代表什么意思？</span></span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">答：常见的大的稳定版本有Spark 1.3,Spark1.6, Spark 2.0 ，</span></span><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">Spark1.6.0的数字含义</span></span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">1）第一个数字：1 </span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">major version : 代表大版本更新，一般都会有一些 api 的变化，以及大的优化或是一些结构的改变；</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">2）第二个数字：6 </span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">minor version : 代表小版本更新，一般会新加 api，或者是对当前的 api 就行优化，或者是其他内容的更新，比如说 WEB UI 的更新等等；</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">3）第三个数字：0</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">patch version ， 代表修复当前小版本存在的一些 bug，基本不会有任何 api 的改变和功能更新；记得有一个大神曾经说过，如果要切换 spark 版本的话，最好选 patch version 非 0 的版本，因为一般类似于 1.2.0, … 1.6.0 这样的版本是属于大更新的，有可能会有一些隐藏的 bug 或是不稳定性存在，所以最好选择 1.2.1, … 1.6.1 这样的版本。</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">通过版本号的解释说明，可以很容易了解到，spark2.1.1的发布时是针对大版本2.1做的一些bug修改，不会新增功能，也不会新增API，会比2.1.0版本更加稳定。</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">6.driver的功能是什么？</span></span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">答： 1）一个Spark作业运行时包括一个Driver进程，也是作业的主进程，具有main函数，并且有SparkContext的实例，是程序的人口点；2）功能：负责向集群申请资源，向master注册信息，负责了作业的调度，，负责作业的解析、生成Stage并调度Task到Executor上。包括DAGScheduler，TaskScheduler。</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">7.spark的有几种部署模式，每种模式特点？</span></span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">1）本地模式</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">Spark不一定非要跑在hadoop集群，可以在本地，起多个线程的方式来指定。将Spark应用以多线程的方式直接运行在本地，一般都是为了方便调试，本地模式分三类</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">·  local：只启动一个executor</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">·  local[k]:启动k个executor</span></span><br style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);"><span style="font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;background-color:rgb(255,255,255);color:rgb(62,62,62);"><span style="font-size:16px;">·  local</span></span><span style="color:rgb(62,62,62);"><span style="font-size:16px;">：启动跟cpu数目相同的 executor</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2)standalone模式</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">分布式部署集群， 自带完整的服务，资源管理和任务监控是Spark自己监控，这个模式也是其他模式的基础，</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">3)Spark on yarn模式</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">分布式部署集群，资源和任务监控交给yarn管理，但是目前仅支持粗粒度资源分配方式，包含cluster和client运行模式，cluster适合生产，driver运行在集群子节点，具有容错功能，client适合调试，dirver运行在客户端</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">4）Spark On Mesos模式。官方推荐这种模式（当然，原因之一是血缘关系）。正是由于Spark开发之初就考虑到支持Mesos，因此，目前而言，Spark运行在Mesos上会比运行在YARN上更加灵活，更加自然。用户可选择两种调度模式之一运行自己的应用程序：</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">1)   粗粒度模式（Coarse-grained Mode）：每个应用程序的运行环境由一个Dirver和若干个Executor组成，其中，每个Executor占用若干资源，内部可运行多个Task（对应多少个“slot”）。应用程序的各个任务正式运行之前，需要将运行环境中的资源全部申请好，且运行过程中要一直占用这些资源，即使不用，最后程序运行结束后，回收这些资源。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2)   细粒度模式（Fine-grained Mode）：鉴于粗粒度模式会造成大量资源浪费，Spark On Mesos还提供了另外一种调度模式：细粒度模式，这种模式类似于现在的云计算，思想是按需分配。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">8.Spark技术栈有哪些组件，每个组件都有什么功能，适合什么应用场景？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">答：可以画一个这样的技术栈图先，然后分别解释下每个组件的功能和场景</span></span></span><br><br>file:///E:/%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6/%E6%9C%89%E9%81%93%E7%AC%94%E8%AE%B0%E6%96%87%E4%BB%B6/qq19B99AF2399E52F466CC3CF7E3B24ED5/dc318cd93346448487e9f423ce499b4b/d1d97571615f01111094fdcae4bed078.jpg<br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">1）Spark core：是其它组件的基础，spark的内核，主要包含：有向循环图、RDD、Lingage、Cache、broadcast等，并封装了底层通讯框架，是Spark的基础。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2）SparkStreaming是一个对实时数据流进行高通量、容错处理的流式处理系统，可以对多种数据源（如Kdfka、Flume、Twitter、Zero和TCP 套接字）进行类似Map、Reduce和Join等复杂操作，将流式计算分解成一系列短小的批处理作业。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">3）Spark sql：Shark是SparkSQL的前身，Spark SQL的一个重要特点是其能够统一处理关系表和RDD，使得开发人员可以轻松地使用SQL命令进行外部查询，同时进行更复杂的数据分析</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">4）BlinkDB ：是一个用于在海量数据上运行交互式 SQL 查询的大规模并行查询引擎，它允许用户通过权衡数据精度来提升查询响应时间，其数据的精度被控制在允许的误差范围内。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">5）MLBase是Spark生态圈的一部分专注于机器学习，让机器学习的门槛更低，让一些可能并不了解机器学习的用户也能方便地使用MLbase。MLBase分为四部分：MLlib、MLI、ML Optimizer和MLRuntime。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">6）GraphX是Spark中用于图和图并行计算</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">9.Spark中Work的主要工作是什么？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：主要功能：管理当前节点内存，CPU的使用状况，接收master分配过来的资源指令，通过ExecutorRunner启动程序分配任务，worker就类似于包工头，管理分配新进程，做计算的服务，相当于process服务。需要注意的是：1）worker会不会汇报当前信息给master，worker心跳给master主要只有workid，它不会发送资源信息以心跳的方式给mater，master分配的时候就知道work，只有出现故障的时候才会发送资源。2）worker不会运行代码，具体运行的是Executor是可以运行具体appliaction写的业务逻辑代码，操作代码的节点，它不会运行程序的代码的。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">10.Spark为什么比mapreduce快？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：1）基于内存计算，减少低效的磁盘交互；2）高效的调度算法，基于DAG；3)容错机制Linage，精华部分就是DAG和Lingae</span></span><br><span style="color:rgb(85,85,85);"><span style="font-size:16px;"><span style="font-weight:700;">11.简单说一下hadoop和spark的shuffle相同和差异？</span></span></span><br><span style="color:rgb(85,85,85);"><span style="font-size:16px;">答：1）</span></span><span style="color:rgb(62,62,62);"><span style="font-size:16px;">从 high-level 的角度来看，两者并没有大的差别。 都是将 mapper（Spark 里是 ShuffleMapTask）的输出进行 partition，不同的 partition 送到不同的 reducer（Spark 里 reducer 可能是下一个 stage 里的 ShuffleMapTask，也可能是 ResultTask）。Reducer 以内存作缓冲区，边 shuffle 边 aggregate 数据，等到数据 aggregate 好以后进行 reduce() （Spark 里可能是后续的一系列操作）。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2）从 low-level 的角度来看，两者差别不小。 Hadoop MapReduce 是 sort-based，进入 combine() 和 reduce() 的 records 必须先 sort。这样的好处在于 combine/reduce() 可以处理大规模的数据，因为其输入数据可以通过外排得到（mapper 对每段数据先做排序，reducer 的 shuffle 对排好序的每段数据做归并）。目前的 Spark 默认选择的是 hash-based，通常使用 HashMap 来对 shuffle 来的数据进行 aggregate，不会对数据进行提前排序。如果用户需要经过排序的数据，那么需要自己调用类似 sortByKey() 的操作；如果你是Spark 1.1的用户，可以将spark.shuffle.manager设置为sort，则会对数据进行排序。在Spark 1.2中，sort将作为默认的Shuffle实现。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">3）从实现角度来看，两者也有不少差别。 Hadoop MapReduce 将处理流程划分出明显的几个阶段：map(), spill, merge, shuffle, sort, reduce() 等。每个阶段各司其职，可以按照过程式的编程思想来逐一实现每个阶段的功能。在 Spark 中，没有这样功能明确的阶段，只有不同的 stage 和一系列的 transformation()，所以 spill, merge, aggregate 等操作需要蕴含在 transformation() 中。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">如果我们将 map 端划分数据、持久化数据的过程称为 shuffle write，而将 reducer 读入数据、aggregate 数据的过程称为 shuffle read。那么在 Spark 中，问题就变为怎么在 job 的逻辑或者物理执行图中加入 shuffle write 和 shuffle read 的处理逻辑？以及两个处理逻辑应该怎么高效实现？ </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">Shuffle write由于不要求数据有序，shuffle write 的任务很简单：将数据 partition 好，并持久化。之所以要持久化，一方面是要减少内存存储空间压力，另一方面也是为了 fault-tolerance。</span></span><br><span style="color:rgb(85,85,85);"><span style="font-size:16px;"><span style="font-weight:700;">12.Mapreduce和</span></span></span><span style="color:rgb(223,52,52);"><span style="font-size:16px;"><span style="font-weight:700;">Spark</span></span></span><span style="color:rgb(85,85,85);"><span style="font-size:16px;"><span style="font-weight:700;">的都是并行计算，那么他们有什么相同和区别</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：两者都是用mr模型来进行并行计算:</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">1)hadoop的一个作业称为job，job里面分为map task和reduce task，每个task都是在自己的进程中运行的，当task结束时，进程也会结束。 </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2)spark用户提交的任务成为application，一个application对应一个sparkcontext，app中存在多个job，每触发一次action操作就会产生一个job。这些job可以并行或串行执行，每个job中有多个stage，stage是shuffle过程中DAGSchaduler通过RDD之间的依赖关系划分job而来的，每个stage里面有多个task，组成taskset有TaskSchaduler分发到各个executor中执行，executor的生命周期是和app一样的，即使没有job运行也是存在的，所以task可以快速启动读取内存进行计算。 </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">3)hadoop的job只有map和reduce操作，表达能力比较欠缺而且在mr过程中会重复的读写hdfs，造成大量的io操作，多个job需要自己管理关系。 </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">spark的迭代计算都是在内存中进行的，API中提供了大量的RDD操作如join，groupby等，而且通过DAG图可以实现良好的容错。</span></span><br><span style="color:rgb(85,85,85);"><span style="font-size:16px;"><span style="font-weight:700;">13.RDD机制？ </span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：rdd分布式弹性数据集，简单的理解成一种</span></span><span style="color:rgb(67,149,245);"><span style="font-size:16px;">数据结构</span></span><span style="color:rgb(62,62,62);"><span style="font-size:16px;">，是spark框架上的通用货币。 </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">所有算子都是基于rdd来执行的，不同的场景会有不同的rdd实现类，但是都可以进行互相转换。 </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">rdd执行过程中会形成dag图，然后形成lineage保证容错性等。 从物理的角度来看rdd存储的是block和node之间的映射。</span></span><br><span style="color:rgb(85,85,85);"><span style="font-size:16px;"><span style="font-weight:700;">14、spark有哪些组件？</span></span></span><span style="color:rgb(85,85,85);"><span style="font-size:16px;"> </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：主要有如下组件：</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">1）master：管理集群和节点，不参与计算。 </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2）worker：计算节点，进程本身不参与计算，和master汇报。 </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">3）Driver：运行程序的main方法，创建spark context对象。 </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">4）spark context：控制整个application的生命周期，包括dagsheduler和task scheduler等组件。 </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">5）client：用户提交程序的入口。</span></span><br><span style="color:rgb(85,85,85);"><span style="font-size:16px;"><span style="font-weight:700;">15、spark工作机制？</span></span></span><span style="color:rgb(85,85,85);"><span style="font-size:16px;"> </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：用户在client端提交作业后，会由Driver运行main方法并创建spark context上下文。 </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">执行add算子，形成dag图输入dagscheduler，按照add之间的依赖关系划分stage输入task scheduler。 task scheduler会将stage划分为task set分发到各个节点的executor中执行。</span></span><br><span style="color:rgb(85,85,85);"><span style="font-size:16px;"><span style="font-weight:700;">16、spark的优化怎么做？</span></span></span><span style="color:rgb(85,85,85);"><span style="font-size:16px;"> </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答： spark调优比较复杂，但是大体可以分为三个方面来进行，1）平台层面的调优：防止不必要的jar包分发，提高数据的本地性，选择高效的存储格式如parquet，2）应用程序层面的调优：过滤操作符的优化降低过多小任务，降低单条记录的资源开销，处理数据倾斜，复用RDD进行缓存，作业并行化执行等等，3）JVM层面的调优：设置合适的资源量，设置合理的JVM，启用高效的序列化方法如kyro，增大off head内存等等</span></span><br><span style="color:rgb(85,85,85);"><span style="font-size:16px;"><span style="font-weight:700;">17.</span></span></span><span style="color:rgb(51,51,51);"><span style="font-size:17px;"><span style="font-weight:700;">简要描述Spark分布式集群搭建的步骤</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">1）准备linux环境，设置集群搭建账号和用户组，设置ssh，关闭防火墙，关闭seLinux，配置host，hostname</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2）配置jdk到环境变量</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">3）搭建hadoop集群，如果要做master ha，需要搭建zookeeper集群</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">   修改hdfs-site.xml,hadoop_env.sh,yarn-site.xml,slaves等配置文件</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">4）启动hadoop集群，启动前要格式化namenode</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">5）配置spark集群，修改spark-env.xml，slaves等配置文件，拷贝hadoop相关配置到spark conf目录下</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">6)启动spark集群。</span></span><br><span style="color:rgb(51,51,51);"><span style="font-size:17px;"><span style="font-weight:700;">18.</span></span></span><span style="color:rgb(85,85,85);"><span style="font-size:16px;"><span style="font-weight:700;">什么是RDD宽依赖和窄依赖？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-family:Verdana;"><span style="font-size:16px;">R</span></span></span><span style="color:rgb(85,85,85);"><span style="font-size:16px;">DD和它依赖的parent RDD(s)的关系有两种不同的类型，即窄依赖（narrow dependency）和宽依赖（wide dependency）。</span></span><br><span style="color:rgb(85,85,85);"><span style="font-size:16px;">1）窄依赖指的是每一个parent RDD的Partit</span></span><span style="color:rgb(62,62,62);"><span style="font-family:Verdana;"><span style="font-size:16px;">ion最多被子RDD的一个Partition使用</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-family:Verdana;"><span style="font-size:16px;">2）宽依赖指的是多个子RDD的Partition会依赖同一个parent RDD的Partition</span></span></span><br><span style="color:rgb(102,102,102);"><span style="font-size:15px;"><span style="font-weight:700;">19.spark-submit的时候如何引入外部jar包 </span></span></span><br><span style="color:rgb(85,85,85);"><span style="font-size:16px;">方法一：spark-submit –jars</span></span><br><span style="color:rgb(85,85,85);"><span style="font-size:16px;">根据spark官网，在提交任务的时候指定–jars，用逗号分开。这样做的缺点是每次都要指定jar包，如果jar包少的话可以这么做，但是如果多的话会很麻烦。</span></span><br><span style="color:rgb(85,85,85);"><span style="font-size:16px;">命令：spark-submit --master yarn-client --jars ***.jar,***.jar</span></span><br><span style="color:rgb(85,85,85);"><span style="font-size:16px;">方法二：</span></span><span style="color:rgb(85,85,85);"><span style="font-size:18px;">extraClassPath</span></span><br><span style="color:rgb(85,85,85);"><span style="font-size:16px;">提交时在spark-default中设定参数，将所有需要的jar包考到一个文件里，然后在参数中指定该目录就可以了，较上一个方便很多：</span></span><br><span style="color:rgb(85,85,85);"><span style="font-size:16px;">spark.executor.extraClassPath=/home/hadoop/wzq_workspace/lib/* spark.driver.extraClassPath=/home/hadoop/wzq_workspace/lib/*</span></span><br><span style="color:rgb(85,85,85);"><span style="font-size:16px;">需要注意的是,你要在所有可能运行spark任务的机器上保证该目录存在，并且将jar包考到所有机器上。这样做的好处是提交代码的时候不用再写一长串jar了，缺点是要把所有的jar包都拷一遍。</span></span><br><span style="color:rgb(102,102,102);"><span style="font-size:15px;"><span style="font-weight:700;">20.cache和pesist的区别 </span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：1）cache和persist都是用于将一个RDD进行缓存的，这样在之后使用的过程中就不需要重新计算了，可以大大节省程序运行时间；2） cache只有一个默认的缓存级别MEMORY_ONLY ，cache调用了persist，而persist可以根据情况设置其它的缓存级别；3）executor执行的时候，默认60%做cache，40%做task操作，persist最根本的函数，最底层的函数</span></span><br><br><span style="color:rgb(51,51,51);"><span style="font-size:17px;">二、选择题</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">1. Spark 的四大组件下面哪个不是 (D )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A.Spark Streaming    B. Mlib </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">C Graphx    D.Spark R</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2.下面哪个端口不是 spark 自带服务的端口 (C )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A.8080 B.4040 C.8090 D.18080</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">备注：8080：spark集群web ui端口，4040：sparkjob监控端口，18080：jobhistory端口</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">3.spark 1.4 版本的最大变化 (B )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A spark sql Release 版本  B .引入 Spark R </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">C DataFrame D.支持动态资源分配</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">4. Spark Job 默认的调度模式 (A )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A FIFO   B FAIR   </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">C 无   D 运行时指定</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">5.哪个不是本地模式运行的个条件 ( D)</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A spark.localExecution.enabled=true  </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">B 显式指定本地运行</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">C finalStage 无父 Stage</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">D partition默认值</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">6.下面哪个不是 RDD 的特点 (C )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A. 可分区   B 可序列化   C 可修改   D 可持久化</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">7. 关于广播变量，下面哪个是错误的 (D )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A 任何函数调用    B 是只读的  </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">C 存储在各个节点    D 存储在磁盘或 HDFS</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">8. 关于累加器，下面哪个是错误的 (D )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A 支持加法 B 支持数值类型 </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">C 可并行 D 不支持自定义类型</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">9.Spark 支持的分布式部署方式中哪个是错误的 (D )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A standalone B spark on mesos  </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">C spark on YARN D Spark on local</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">10.Stage 的 Task 的数量由什么决定 (A )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A Partition B Job C Stage D TaskScheduler</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">11.下面哪个操作是窄依赖 (B )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A join B filter </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">C group D sort</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">12.下面哪个操作肯定是宽依赖 (C )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A map B flatMap </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">C reduceByKey D sample</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">13.spark 的 master 和 worker 通过什么方式进行通信的？ (D )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A http B nio C netty D Akka</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">14 默认的存储级别 (A )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A MEMORY_ONLY B MEMORY_ONLY_SER</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">C MEMORY_AND_DISK D MEMORY_AND_DISK_SER</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">15 spark.deploy.recoveryMode 不支持那种 (D )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A.ZooKeeper B. FileSystem </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">D NONE D Hadoop</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">16.下列哪个不是 RDD 的缓存方法 (C )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A persist() B Cache() </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">C Memory()</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">17.Task 运行在下来哪里个选项中 Executor 上的工作单元 (C )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A Driver program B. spark master </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">C.worker node D Cluster manager</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">18.hive 的元数据存储在 derby 和 MySQL 中有什么区别 (B )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A.没区别 B.多会话</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">C.支持网络环境 D数据库的区别</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">19.DataFrame 和 RDD 最大的区别 (B )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A.科学统计支持 B.多了 schema </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">C.存储方式不一样 D.外部数据源支持</span></span><br><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">20.Master 的 ElectedLeader 事件后做了哪些操作 (D )</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">A. 通知 driver B.通知 worker </span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">C.注册 application D.直接 ALIVE</span></span><br><br><br><br><br><br>-----------------------------------------------------------------------------------------------------------------------------<br><br><span style="font-size:24px;">【Spark面试2000题41-70】Spark core面试篇02</span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">这批Spark面试题由志愿者Taffry（某高校研究生）提供，非常感谢志愿者的优质题集，大家如果有好的面试题可以私信给群主（可加入志愿者群QQ群：233864572）。为确保题集质量，志愿者贡献出来的题集，群主及各位梅峰谷平台组成员会审核，个别地方会略加修改，还请志愿者理解。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">一、面试30题</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">1.cache后面能不能接其他算子,它是不是action操作？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：cache可以接其他算子，但是接了算子之后，起不到缓存应有的效果，因为会重新触发cache。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">cache不是action操作</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">2.reduceByKey是不是action？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：不是，很多人都会以为是action，reduce rdd是action</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">3.数据本地性是在哪个环节确定的？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">具体的task运行在那他机器上，dag划分stage的时候确定的</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">4.RDD的弹性表现在哪几点？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">1）自动的进行内存和磁盘的存储切换；</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2）基于Lingage的高效容错；</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">3）task如果失败会自动进行特定次数的重试；</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">4）stage如果失败会自动进行特定次数的重试，而且只会计算失败的分片；</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">5）checkpoint和persist，数据计算之后持久化缓存</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">6）数据调度弹性，DAG TASK调度和资源无关</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">7）数据分片的高度弹性，a.分片很多碎片可以合并成大的，b.par</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">5.常规的容错方式有哪几种类型？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">1）.数据检查点,会发生拷贝，浪费资源</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2）.记录数据的更新，每次更新都会记录下来，比较复杂且比较消耗性能</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">6.RDD通过Linage（记录数据更新）的方式为何很高效？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">1）lazy记录了数据的来源，RDD是不可变的，且是lazy级别的，且rDD</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">之间构成了链条，lazy是弹性的基石。由于RDD不可变，所以每次操作就</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">产生新的rdd，不存在全局修改的问题，控制难度下降，所有有计算链条</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">将复杂计算链条存储下来，计算的时候从后往前回溯</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">900步是上一个stage的结束，要么就checkpoint</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2）记录原数据，是每次修改都记录，代价很大</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">如果修改一个集合，代价就很小，官方说rdd是</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">粗粒度的操作，是为了效率，为了简化，每次都是</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">操作数据集合，写或者修改操作，都是基于集合的</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">rdd的写操作是粗粒度的，rdd的读操作既可以是粗粒度的</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">也可以是细粒度，读可以读其中的一条条的记录。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">3）简化复杂度，是高效率的一方面，写的粗粒度限制了使用场景</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">如网络爬虫，现实世界中，大多数写是粗粒度的场景</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">7.RDD有哪些缺陷？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">1）不支持细粒度的写和更新操作（如网络爬虫），spark写数据是粗粒度的</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">所谓粗粒度，就是批量写入数据，为了提高效率。但是读数据是细粒度的也就是</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">说可以一条条的读</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2）不支持增量迭代计算，Flink支持</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">8.说一说Spark程序编写的一般步骤？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">答：</span></span></span><span style="color:rgb(62,62,62);"><span style="font-size:16px;">初始化，资源，数据源，并行化，rdd转化，action算子打印输出结果或者也可以存至相应的数据存储介质，具体的可看下图：</span></span><br>file:///E:/%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6/%E6%9C%89%E9%81%93%E7%AC%94%E8%AE%B0%E6%96%87%E4%BB%B6/qq19B99AF2399E52F466CC3CF7E3B24ED5/069fa7b471f54e038440faf63233acce/640.webp<br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">9. Spark有哪两种算子？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">答：</span></span></span><span style="color:rgb(62,62,62);"><span style="font-size:16px;">Transformation（转化）算子和Action（执行）算子。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">10. Spark提交你的jar包时所用的命令是什么？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">答：</span></span></span><span style="color:rgb(62,62,62);"><span style="font-size:16px;">spark-submit。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">11. Spark有哪些聚合类的算子,我们应该尽量避免什么类型的算子？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">答：</span></span></span><span style="color:rgb(62,62,62);"><span style="font-size:16px;">在我们的开发过程中，能避免则尽可能避免使用reduceByKey、join、distinct、repartition等会进行shuffle的算子，尽量使用map类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">12. 你所理解的Spark的shuffle过程？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">答：从下面三点去展开</span></span></span><br><span style="color:rgb(51,51,51);"><span style="background-color:rgb(254,254,254);"><span style="font-family:Tahoma;"><span style="font-size:16px;">1）shuffle过程的划分</span></span></span></span><br><span style="color:rgb(51,51,51);"><span style="background-color:rgb(254,254,254);"><span style="font-family:Tahoma;"><span style="font-size:16px;">2）shuffle的中间结果如何存储</span></span></span></span><br><span style="color:rgb(51,51,51);"><span style="background-color:rgb(254,254,254);"><span style="font-family:Tahoma;"><span style="font-size:16px;">3）shuffle的数据如何拉取过来</span></span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">可以参考这篇博文：</span></span><span style="color:rgb(67,149,245);"><span style="font-size:16px;">http://www.cnblogs.com/jxhd1/p/6528540.html</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">13. 你如何从Kafka中获取数据？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">1</span></span></span><span style="color:rgb(51,51,51);"><span style="font-size:13px;">)基于Receiver的方式</span></span><br><span style="color:rgb(51,51,51);"><span style="font-size:13px;">这种方式使用Receiver来获取数据。Receiver是使用Kafka的高层次Consumer API来实现的。receiver从Kafka中获取的数据都是存储在Spark Executor的内存中的，然后Spark Streaming启动的job会去处理那些数据。</span></span><br><span style="color:rgb(51,51,51);"><span style="font-size:13px;">2)基于Direct的方式</span></span><br><span style="color:rgb(51,51,51);"><span style="font-size:13px;">这种新的不基于Receiver的直接方式，是在Spark 1.3中引入的，从而能够确保更加健壮的机制。替代掉使用Receiver来接收数据后，这种方式会周期性地查询Kafka，来获得每个topic+partition的最新的offset，从而定义每个batch的offset的范围。当处理数据的job启动时，就会使用Kafka的简单consumer api来获取Kafka指定offset范围的数据</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">14. 对于Spark中的数据倾斜问题你有什么好的方案？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">1）前提是定位数据倾斜，是OOM了，还是任务执行缓慢，看日志，看WebUI</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2)解决方法，有多个方面</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">· 避免不必要的shuffle，如使用广播小表的方式，将reduce-side-join提升为map-side-join</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">·分拆发生数据倾斜的记录，分成几个部分进行，然后合并join后的结果</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">·改变并行度，可能并行度太少了，导致个别task数据压力大</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">·两阶段聚合，先局部聚合，再全局聚合</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">·自定义paritioner，分散key的分布，使其更加均匀</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">详细解决方案参考博文</span></span><a href="http://mp.weixin.qq.com/s?__biz=MzIzNzI1NzY3Nw==&amp;mid=2247484221&amp;idx=1&amp;sn=7e20f08bfb490b91f0920aefb29ca271&amp;chksm=e8ca159fdfbd9c89f610dd230e07f414521b4dd13018994ee9b873421d1e8efcdc535c810225&amp;scene=21#wechat_redirect" rel="nofollow" style="color:rgb(51,102,153);"><span style="color:rgb(67,149,245);"><span style="font-size:16px;">《Spark数据倾斜优化方法》</span></span></a><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">15.RDD创建有哪几种方式？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">1).使用程序中的集合创建rdd</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2).使用本地文件系统创建rdd</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">3).使用hdfs创建rdd，</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">4).基于数据库db创建rdd</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">5).基于Nosql创建rdd，如hbase</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">6).基于s3创建rdd，</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">7).基于数据流，如socket创建rdd</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">如果只回答了前面三种，是不够的，只能说明你的水平还是入门级的，实践过程中有很多种创建方式。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">16.Spark并行度怎么设置比较合适</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：spark并行度，每个core承载2~4个partition,如，32个core，那么64~128之间的并行度，也就是</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">设置64~128个partion，并行读和数据规模无关，只和内存使用量和cpu使用</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">时间有关</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">17.Spark中数据的位置是被谁管理的？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：每个数据分片都对应具体物理位置，数据的位置是被blockManager，无论</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">数据是在磁盘，内存还是tacyan，都是由blockManager管理</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">18.Spark的数据本地性有哪几种？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：Spark中的数据本地性有三种：</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">a.PROCESS_LOCAL是指读取缓存在本地节点的数据</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">b.NODE_LOCAL是指读取本地节点硬盘数据</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">c.ANY是指读取非本地节点数据</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">通常读取数据PROCESS_LOCAL&gt;NODE_LOCAL&gt;ANY，尽量使数据以PROCESS_LOCAL或NODE_LOCAL方式读取。其中PROCESS_LOCAL还和cache有关，如果RDD经常用的话将该RDD cache到内存中，注意，由于cache是lazy的，所以必须通过一个action的触发，才能真正的将该RDD cache到内存中。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">19.rdd有几种操作类型</span></span><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">1）transformation，rdd由一种转为另一种rdd</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2）action，</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">3）cronroller，crontroller是控制算子,cache,persist，对性能和效率的有很好的支持</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">三种类型，不要回答只有2中操作</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">19.rdd有几种操作类型？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">1）transformation，rdd由一种转为另一种rdd</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2）action，</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">3）cronroller，crontroller是控制算子,cache,persist，对性能和效率的有很好的支持</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">三种类型，不要回答只有2中操作</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">20.Spark如何处理不能被序列化的对象？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">将不能序列化的内容封装成object</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">21.collect功能是什么，其底层是怎么实现的？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：driver通过collect把集群中各个节点的内容收集过来汇总成结果，collect返回结果是Array类型的，collect把各个节点上的数据抓过来，抓过来数据是Array型，collect对Array抓过来的结果进行合并，合并后Array中只有一个元素，是tuple类型（KV类型的）的。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">22.Spaek程序执行，有时候默认为什么会产生很多task，怎么修改默认task执行个数？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：1）因为输入数据有很多task，尤其是有很多小文件的时候，有多少个输入</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">block就会有多少个task启动；2）spark中有partition的概念，每个partition都会对应一个task，task越多，在处理大规模数据的时候，就会越有效率。不过task并不是越多越好，如果平时测试，或者数据量没有那么大，则没有必要task数量太多。3）参数可以通过spark_home/conf/spark-default.conf配置文件设置:</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">spark.sql.shuffle.partitions 50 spark.default.parallelism 10</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">第一个是针对spark sql的task数量</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">第二个是非spark sql程序设置生效</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">23.为什么Spark Application在没有获得足够的资源，job就开始执行了，可能会导致什么什么问题发生?</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：会导致执行该job时候集群资源不足，导致执行job结束也没有分配足够的资源，分配了部分Executor，该job就开始执行task，应该是task的调度线程和Executor资源申请是异步的；如果想等待申请完所有的资源再执行job的：需要将spark.scheduler.maxRegisteredResourcesWaitingTime设置的很大；spark.scheduler.minRegisteredResourcesRatio 设置为1，但是应该结合实际考虑</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">否则很容易出现长时间分配不到资源，job一直不能运行的情况。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">24.map与flatMap的区别</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">map：对RDD每个元素转换，文件中的每一行数据返回一个数组对象</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">flatMap：对RDD每个元素转换，然后再扁平化</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">将所有的对象合并为一个对象，文件中的所有行数据仅返回一个数组</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">对象，会抛弃值为null的值</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">25.列举你常用的action？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">collect，reduce,take,count,saveAsTextFile等</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">26.Spark为什么要持久化，一般什么场景下要进行persist操作？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">为什么要进行持久化？</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">spark所有复杂一点的算法都会有persist身影,spark默认数据放在内存，spark很多内容都是放在内存的，非常适合高速迭代，1000个步骤</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">只有第一个输入数据，中间不产生临时数据，但分布式系统风险很高，所以容易出错，就要容错，rdd出错或者分片可以根据血统算出来，如果没有对父rdd进行persist 或者cache的化，就需要重头做。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">以下场景会使用persist</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">1）某个步骤计算非常耗时，需要进行persist持久化</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">2）计算链条非常长，重新恢复要算很多步骤，很好使，persist</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">3）checkpoint所在的rdd要持久化persist，</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">lazy级别，框架发现有checnkpoint，checkpoint时单独触发一个job，需要重算一遍，checkpoint前</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">要持久化，写个rdd.cache或者rdd.persist，将结果保存起来，再写checkpoint操作，这样执行起来会非常快，不需要重新计算rdd链条了。checkpoint之前一定会进行persist。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">4）shuffle之后为什么要persist，shuffle要进性网络传输，风险很大，数据丢失重来，恢复代价很大</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">5）shuffle之前进行persist，框架默认将数据持久化到磁盘，这个是框架自动做的。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">27.为什么要进行序列化</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">序列化可以减少数据的体积，减少存储空间，高效存储和传输数据，不好的是使用的时候要反序列化，非常消耗CPU</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">28.介绍一下join操作优化经验？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：join其实常见的就分为两类： map-side join 和  reduce-side join。当大表和小表join时，用map-side join能显著提高效率。将多份数据进行关联是数据处理过程中非常普遍的用法，不过在分布式计算系统中，这个问题往往会变的非常麻烦，因为框架提供的 join 操作一般会将所有数据根据 key 发送到所有的 reduce 分区中去，也就是 shuffle 的过程。造成大量的网络以及磁盘IO消耗，运行效率极其低下，这个过程一般被称为 reduce-side-join。如果其中有张表较小的话，我们则可以自己实现在 map 端实现数据关联，跳过大量数据进行 shuffle 的过程，运行时间得到大量缩短，根据不同数据可能会有几倍到数十倍的性能提升。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">备注：这个题目面试中非常非常大概率见到，务必搜索相关资料掌握，这里抛砖引玉。</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">29.介绍一下cogroup rdd实现原理，你在什么场景下用过这个rdd？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答：cogroup的函数实现:这个实现根据两个要进行合并的两个RDD操作,生成一个CoGroupedRDD的实例,这个RDD的返回结果是把相同的key中两个RDD分别进行合并操作,最后返回的RDD的value是一个Pair的实例,这个实例包含两个Iterable的值,第一个值表示的是RDD1中相同KEY的值,第二个值表示的是RDD2中相同key的值.由于做cogroup的操作,需要通过partitioner进行重新分区的操作,因此,执行这个流程时,需要执行一次shuffle的操作(如果要进行合并的两个RDD的都已经是shuffle后的rdd,同时他们对应的partitioner相同时,就不需要执行shuffle,)，</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">场景：表关联查询</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;"><span style="font-weight:700;">30 下面这段代码输出结果是什么？</span></span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">--------------------------</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">def joinRdd(sc:SparkContext) {</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">val name= Array(</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">Tuple2(1,"spark"),</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">Tuple2(2,"tachyon"),</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">Tuple2(3,"hadoop")</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">)</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">val score= Array(</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">Tuple2(1,100),</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">Tuple2(2,90),</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">Tuple2(3,80)</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">)</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">val namerdd=sc.parallelize(name);</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">val scorerdd=sc.parallelize(score);</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">val result = namerdd.join(scorerdd);</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">result .collect.foreach(println);</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">}</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">--------------------------</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">答案:</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">(1,(Spark,100))</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">(2,(tachyon,90))</span></span><br><span style="color:rgb(62,62,62);"><span style="font-size:16px;">(3,(hadoop,80))</span></span><br><br>            </div>
                </div>