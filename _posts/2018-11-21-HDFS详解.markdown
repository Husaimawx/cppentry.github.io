---
layout:     post
title:      HDFS详解
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/zuochang_liu/article/details/81814595				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p id="main-toc"><strong>目录</strong></p>

<p id="-toc" style="margin-left:0px;"> </p>

<p id="1%20HDFS%E5%89%8D%E8%A8%80-toc" style="margin-left:0px;"><a href="#1%20HDFS%E5%89%8D%E8%A8%80" rel="nofollow">1 HDFS前言</a></p>

<p id="2%20HDFS%E7%9A%84%E6%A6%82%E5%BF%B5%E5%92%8C%E7%89%B9%E6%80%A7-toc" style="margin-left:0px;"><a href="#2%20HDFS%E7%9A%84%E6%A6%82%E5%BF%B5%E5%92%8C%E7%89%B9%E6%80%A7" rel="nofollow">2 HDFS的概念和特性</a></p>

<p id="3%20HDFS%E7%9A%84shell(%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%AE%A2%E6%88%B7%E7%AB%AF)%E6%93%8D%E4%BD%9C-toc" style="margin-left:0px;"><a href="#3%20HDFS%E7%9A%84shell(%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%AE%A2%E6%88%B7%E7%AB%AF)%E6%93%8D%E4%BD%9C" rel="nofollow">3 HDFS的shell(命令行客户端)操作</a></p>

<p id="3.1%20HDFS%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BD%BF%E7%94%A8%C2%A0-toc" style="margin-left:40px;"><a href="#3.1%20HDFS%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BD%BF%E7%94%A8%C2%A0" rel="nofollow">3.1 HDFS命令行客户端使用 </a></p>

<p id="3.2%C2%A0%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%94%AF%E6%8C%81%E7%9A%84%E5%91%BD%E4%BB%A4%E5%8F%82%E6%95%B0-toc" style="margin-left:40px;"><a href="#3.2%C2%A0%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%94%AF%E6%8C%81%E7%9A%84%E5%91%BD%E4%BB%A4%E5%8F%82%E6%95%B0" rel="nofollow">3.2 命令行客户端支持的命令参数</a></p>

<p id="3.2%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%8F%82%E6%95%B0%E4%BB%8B%E7%BB%8D-toc" style="margin-left:40px;"><a href="#3.2%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%8F%82%E6%95%B0%E4%BB%8B%E7%BB%8D" rel="nofollow">3.2 常用命令参数介绍</a></p>

<p id="4%20HDFS%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6-toc" style="margin-left:0px;"><a href="#4%20HDFS%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6" rel="nofollow">4 HDFS的工作机制</a></p>

<p id="4.1%20%E6%A6%82%E8%BF%B0-toc" style="margin-left:40px;"><a href="#4.1%20%E6%A6%82%E8%BF%B0" rel="nofollow">4.1 概述</a></p>

<p id="4.2%20HDFS%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B-toc" style="margin-left:40px;"><a href="#4.2%20HDFS%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B" rel="nofollow">4.2 HDFS写数据流程</a></p>

<p id="4.2.1%20%E6%A6%82%E8%BF%B0-toc" style="margin-left:80px;"><a href="#4.2.1%20%E6%A6%82%E8%BF%B0" rel="nofollow">4.2.1 概述</a></p>

<p id="4.2.2%20%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4%E5%9B%BE-toc" style="margin-left:80px;"><a href="#4.2.2%20%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4%E5%9B%BE" rel="nofollow">4.2.2 详细步骤图</a></p>

<p id="4.2.3%20%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4%E8%A7%A3%E6%9E%90-toc" style="margin-left:80px;"><a href="#4.2.3%20%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4%E8%A7%A3%E6%9E%90" rel="nofollow">4.2.3 详细步骤解析</a></p>

<p id="4.3%20HDFS%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B-toc" style="margin-left:40px;"><a href="#4.3%20HDFS%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B" rel="nofollow">4.3 HDFS读数据流程</a></p>

<p id="4.3.1%20%E6%A6%82%E8%BF%B0-toc" style="margin-left:80px;"><a href="#4.3.1%20%E6%A6%82%E8%BF%B0" rel="nofollow">4.3.1 概述</a></p>

<p id="4.3.2%20%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4%E5%9B%BE-toc" style="margin-left:80px;"><a href="#4.3.2%20%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4%E5%9B%BE" rel="nofollow">4.3.2 详细步骤图</a></p>

<p id="4.3.3%20%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4%E8%A7%A3%E6%9E%90-toc" style="margin-left:80px;"><a href="#4.3.3%20%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4%E8%A7%A3%E6%9E%90" rel="nofollow">4.3.3 详细步骤解析</a></p>

<p id="5%20NameNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6-toc" style="margin-left:0px;"><a href="#5%20NameNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6" rel="nofollow">5 NameNode工作机制</a></p>

<p id="5.1%20namenode%E8%81%8C%E8%B4%A3-toc" style="margin-left:40px;"><a href="#5.1%20namenode%E8%81%8C%E8%B4%A3" rel="nofollow">5.1 namenode职责</a></p>

<p id="5.2%20%E5%85%83%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86-toc" style="margin-left:40px;"><a href="#5.2%20%E5%85%83%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86" rel="nofollow">5.2 元数据管理</a></p>

<p id="5.2.1%20%E5%85%83%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6-toc" style="margin-left:80px;"><a href="#5.2.1%20%E5%85%83%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6" rel="nofollow">5.2.1 元数据存储机制</a></p>

<p id="5.2.2%20%E5%85%83%E6%95%B0%E6%8D%AE%E6%89%8B%E5%8A%A8%E6%9F%A5%E7%9C%8B-toc" style="margin-left:80px;"><a href="#5.2.2%20%E5%85%83%E6%95%B0%E6%8D%AE%E6%89%8B%E5%8A%A8%E6%9F%A5%E7%9C%8B" rel="nofollow">5.2.2 元数据手动查看</a></p>

<p id="5.2.3%20%E5%85%83%E6%95%B0%E6%8D%AE%E7%9A%84checkpoint-toc" style="margin-left:80px;"><a href="#5.2.3%20%E5%85%83%E6%95%B0%E6%8D%AE%E7%9A%84checkpoint" rel="nofollow">5.2.3 元数据的checkpoint</a></p>

<p id="5.2.4%20%E5%85%83%E6%95%B0%E6%8D%AE%E7%9B%AE%E5%BD%95%E8%AF%B4%E6%98%8E-toc" style="margin-left:80px;"><a href="#5.2.4%20%E5%85%83%E6%95%B0%E6%8D%AE%E7%9B%AE%E5%BD%95%E8%AF%B4%E6%98%8E" rel="nofollow">5.2.4 元数据目录说明</a></p>

<p id="6%20Datanode%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6-toc" style="margin-left:0px;"><a href="#6%20Datanode%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6" rel="nofollow">6 Datanode的工作机制</a></p>

<p id="6.1%20%E6%A6%82%E8%BF%B0-toc" style="margin-left:40px;"><a href="#6.1%20%E6%A6%82%E8%BF%B0" rel="nofollow">6.1 概述</a></p>

<p id="6.2%20%E8%A7%82%E5%AF%9F%E9%AA%8C%E8%AF%81Datanode%E5%8A%9F%E8%83%BD-toc" style="margin-left:40px;"><a href="#6.2%20%E8%A7%82%E5%AF%9F%E9%AA%8C%E8%AF%81Datanode%E5%8A%9F%E8%83%BD" rel="nofollow">6.2 观察验证Datanode功能</a></p>

<p id="7%20HDFS%E7%9A%84java%E6%93%8D%E4%BD%9C-toc" style="margin-left:0px;"><a href="#7%20HDFS%E7%9A%84java%E6%93%8D%E4%BD%9C" rel="nofollow">7 HDFS的java操作</a></p>

<p id="7.1%20%E6%90%AD%E5%BB%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83-toc" style="margin-left:40px;"><a href="#7.1%20%E6%90%AD%E5%BB%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83" rel="nofollow">7.1 搭建开发环境</a></p>

<p id="7.2%20%E8%8E%B7%E5%8F%96api%E4%B8%AD%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AF%B9%E8%B1%A1-toc" style="margin-left:40px;"><a href="#7.2%20%E8%8E%B7%E5%8F%96api%E4%B8%AD%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AF%B9%E8%B1%A1" rel="nofollow">7.2 获取api中的客户端对象</a></p>

<p id="7.3%C2%A0DistributedFileSystem%E5%AE%9E%E4%BE%8B%E5%AF%B9%E8%B1%A1%E6%89%80%E5%85%B7%E5%A4%87%E7%9A%84%E6%96%B9%E6%B3%95-toc" style="margin-left:40px;"><a href="#7.3%C2%A0DistributedFileSystem%E5%AE%9E%E4%BE%8B%E5%AF%B9%E8%B1%A1%E6%89%80%E5%85%B7%E5%A4%87%E7%9A%84%E6%96%B9%E6%B3%95" rel="nofollow">7.3 DistributedFileSystem实例对象所具备的方法</a></p>

<p id="7.4%20HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B-toc" style="margin-left:40px;"><a href="#7.4%20HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B" rel="nofollow">7.4 HDFS客户端操作数据代码示例</a></p>

<p id="7.4.1%20%E6%96%87%E4%BB%B6%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5-toc" style="margin-left:80px;"><a href="#7.4.1%20%E6%96%87%E4%BB%B6%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5" rel="nofollow">7.4.1 文件的增删改查</a></p>

<hr id="hr-toc"><h1 id="1%20HDFS%E5%89%8D%E8%A8%80">1 HDFS前言</h1>

<ul><li><span style="color:#000000;">设计思想</span></li>
</ul><p><span style="color:#000000;">          分而治之：将大文件、大批量文件，分布式存放在大量服务器上，</span><strong><span style="color:#000000;"><strong>以便于采取分而治之的方式对海量数据进行运算分析；</strong></span></strong></p>

<ul><li><span style="color:#000000;">在大数据系统中作用：</span></li>
</ul><p><span style="color:#000000;">          为各类分布式运算框架（如：mapreduce，spark，tez，</span><span style="color:#000000;">……</span><span style="color:#000000;">）提供数据存储服务</span></p>

<ul><li><span style="color:#000000;">重点概念：文件切块，副本存放，元数据</span></li>
</ul><h1 id="2%20HDFS%E7%9A%84%E6%A6%82%E5%BF%B5%E5%92%8C%E7%89%B9%E6%80%A7"><span style="color:#000000;">2 HDFS的概念和特性</span></h1>

<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>首先，它是一个文件系统</strong></span></strong><span style="color:#000000;">，用于存储文件，通过统一的命名空间——目录树来定位文件</span></p>

<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>其次，它是分布式的</strong></span></strong><span style="color:#000000;">，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色；</span></p>

<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>重要特性如下：</strong></span></strong></p>

<ol><li><span style="color:#000000;">HDFS中的文件在物理上是</span><strong><span style="color:#000000;"><strong>分块存储（block）</strong></span></strong><span style="color:#000000;">，块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在hadoop2.x版本中是128M，老版本中是64M</span></li>
	<li><span style="color:#000000;">HDFS文件系统会给客户端提供一个</span><strong><span style="color:#000000;"><strong>统一的抽象目录树</strong></span></strong><span style="color:#000000;">，客户端通过路径来访问文件，形如：hdfs://namenode:port/dir-a/dir-b/dir-c/file.data</span></li>
	<li><strong><span style="color:#000000;"><strong>目录结构及文件分块信息</strong></span></strong><strong><span style="color:#000000;"><strong>(元数据)</strong></span></strong><span style="color:#000000;">的管理由namenode节点承担</span><span style="color:#000000;">——namenode是HDFS集群主节点，负责维护整个hdfs文件系统的目录树，以及每一个路径（文件）所对应的block块信息（block的id，及所在的datanode服务器）</span></li>
	<li><span style="color:#000000;">文件的各个block的存储管理由datanode节点承担</span><span style="color:#000000;">---- datanode是HDFS集群从节点，每一个block都可以在多个datanode上存储多个副本（副本数量也可以通过参数设置dfs.replication）</span></li>
	<li><span style="color:#000000;">HDFS是设计成适应一次写入，多次读出的场景，且不支持文件的修改</span></li>
</ol><p style="margin-left:0pt;"><em><span style="color:#000000;"><em>(注：适合用来做数据分析，并不适合用来做网盘应用，因为，不便修改，延迟大，网络开销大，成本太高)</em></span></em></p>

<h1 id="3%20HDFS%E7%9A%84shell(%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%AE%A2%E6%88%B7%E7%AB%AF)%E6%93%8D%E4%BD%9C" style="margin-left:0pt;"><em><span style="color:#000000;"><em>3 HDFS的shell(命令行客户端)操作</em></span></em></h1>

<h2 id="3.1%20HDFS%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BD%BF%E7%94%A8%C2%A0"><em><span style="color:#000000;"><em>3.1 HDFS命令行客户端使用 </em></span></em></h2>

<p>HDFS提供shell命令行客户端，使用方法如下：</p>

<blockquote>
<p>hadoop fs -ls /</p>

<p>hdfs dfs -ls /</p>
</blockquote>

<h2 id="3.2%C2%A0%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%94%AF%E6%8C%81%E7%9A%84%E5%91%BD%E4%BB%A4%E5%8F%82%E6%95%B0">3.2 命令行客户端支持的命令参数</h2>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><span style="color:#000000;">        [-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-cat [-ignoreCrc] &lt;src&gt; ...]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-checksum &lt;src&gt; ...]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-chgrp [-R] GROUP PATH...]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-chown [-R] [OWNER][:[GROUP]] PATH...]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-copyFromLocal [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-copyToLocal [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-count [-q] &lt;path&gt; ...]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-cp [-f] [-p] &lt;src&gt; ... &lt;dst&gt;]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-df [-h] [&lt;path&gt; ...]]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-du [-s] [-h] &lt;path&gt; ...]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-expunge]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-get [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-getfacl [-R] &lt;path&gt;]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-getmerge [-nl] &lt;src&gt; &lt;localdst&gt;]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-help [cmd ...]]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-ls [-d] [-h] [-R] [&lt;path&gt; ...]]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-mkdir [-p] &lt;path&gt; ...]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-moveToLocal &lt;src&gt; &lt;localdst&gt;]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-mv &lt;src&gt; ... &lt;dst&gt;]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-put [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-rm [-f] [-r|-R] [-skipTrash] &lt;src&gt; ...]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-setfacl [-R] [{-b|-k} {-m|-x &lt;acl_spec&gt;} &lt;path&gt;]|[--set &lt;acl_spec&gt; &lt;path&gt;]]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-stat [format] &lt;path&gt; ...]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-tail [-f] &lt;file&gt;]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-test -[defsz] &lt;path&gt;]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-text [-ignoreCrc] &lt;src&gt; ...]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-touchz &lt;path&gt; ...]</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        [-usage [cmd ...]]</span></p>
			</td>
		</tr></tbody></table><h2 id="3.2%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%8F%82%E6%95%B0%E4%BB%8B%E7%BB%8D">3.2 常用命令参数介绍</h2>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><span style="color:#000000;">-help             </span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">功能：输出这个命令参数手册</span></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-ls                  </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：显示目录信息</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例： </em></span></em><em><span style="color:#000000;"><em>hadoop fs -ls hdfs://hadoop-server01:9000/</em></span></em></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>备注：这些参数中，所有的hdfs路径都可以简写</em></span></em></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>--&gt;</em></span></em><em><span style="color:#000000;"><em>hadoop fs -ls /   等同于上一条命令的效果</em></span></em></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-mkdir              </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：在hdfs上创建目录</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：</em></span></em><em><span style="color:#000000;"><em>hadoop fs  -mkdir  -p  /aaa/bbb/cc/dd</em></span></em></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-moveFromLocal            </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：从本地剪切粘贴到hdfs</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：hadoop  fs  - moveFromLocal  /home/hadoop/a.txt  /aaa/bbb/cc/dd</em></span></em></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-moveToLocal              </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：从hdfs剪切粘贴到本地</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：hadoop  fs  - moveToLocal   /aaa/bbb/cc/dd  /home/hadoop/a.txt </em></span></em></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>--appendToFile  </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：追加一个文件到已经存在的文件末尾</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：</em></span></em><em><span style="color:#000000;"><em>hadoop  fs  -appendToFile  ./hello.txt  hdfs://hadoop-server01:9000/hello.txt</em></span></em></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>可以简写为：</em></span></em></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>H</em></span></em><em><span style="color:#000000;"><em>adoop  fs  -appendToFile  ./hello.txt  /hello.txt</em></span></em></p>

			<p style="margin-left:0pt;"> </p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-cat  </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：显示文件内容  </strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：</em></span></em><em><span style="color:#000000;"><em>hadoop fs -cat  /hello.txt</em></span></em></p>

			<p style="margin-left:0pt;"> </p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-tail                 </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：显示一个文件的末尾</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：hadoop  fs  -tail  /weblog/access_log.1</em></span></em></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-text                  </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：以字符形式打印一个文件的内容</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：hadoop  fs  -text  /weblog/access_log.1</em></span></em></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-chgrp </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-chmod</strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-chown</strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：linux文件系统中的用法一样，对文件所属权限</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：</em></span></em></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>hadoop  fs  -chmod  666  /hello.txt</em></span></em></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>hadoop</em></span></em><em><span style="color:#000000;"><em>  fs  -chown  someuser:somegrp   /hello.txt</em></span></em></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-copyFromLocal    </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：从本地文件系统中拷贝文件到hdfs路径去</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：</em></span></em><em><span style="color:#000000;"><em>hadoop  fs  -copyFromLocal  ./jdk.tar.gz  /aaa/</em></span></em></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-copyToLocal      </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：从hdfs拷贝到本地</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：hadoop fs -copyToLocal /aaa/jdk.tar.gz</em></span></em></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-cp              </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：从hdfs的一个路径拷贝hdfs的另一个路径</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例： </em></span></em><em><span style="color:#000000;"><em>hadoop</em></span></em><em> </em><em><span style="color:#000000;"><em> fs</em></span></em><em> </em><em><span style="color:#000000;"><em> -cp  /aaa/jdk.tar.gz  /bbb/jdk.tar.gz.2</em></span></em></p>

			<p style="margin-left:0pt;"> </p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-mv                     </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：在hdfs目录中移动文件</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例： </em></span></em><em><span style="color:#000000;"><em>hadoop</em></span></em><em> </em><em><span style="color:#000000;"><em> fs</em></span></em><em> </em><em><span style="color:#000000;"><em> -</em></span></em><em><span style="color:#000000;"><em>mv</em></span></em><em><span style="color:#000000;"><em>  /aaa/jdk.tar.gz  /</em></span></em></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-get              </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：等同于copyToLocal，就是从hdfs下载文件到本地</strong></span></strong></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">示例：hadoop fs -get  /aaa/jdk.tar.gz</span></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-getmerge             </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：合并下载多个文件</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：</em></span></em><em><span style="color:#000000;"><em>比如hdfs的目录 /aaa/下有多个文件:log.1, log.2,log.3,...</em></span></em></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">hadoop fs -getmerge /aaa/log.* ./log.sum</span></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-put                </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：等同于copyFromLocal</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：</em></span></em><em><span style="color:#000000;"><em>hadoop</em></span></em><em> </em><em><span style="color:#000000;"><em> fs</em></span></em><em> </em><em><span style="color:#000000;"><em> -</em></span></em><em><span style="color:#000000;"><em>put</em></span></em><em><span style="color:#000000;"><em>  /aaa/jdk.tar.gz  /bbb/jdk.tar.gz.2</em></span></em></p>

			<p style="margin-left:0pt;"> </p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-rm                </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：删除文件或文件夹</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：</em></span></em><em><span style="color:#000000;"><em>hadoop fs -rm -r /aaa/bbb/</em></span></em></p>

			<p style="margin-left:0pt;"> </p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-rmdir                 </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：删除空目录</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：hadoop  fs  -rmdir   /aaa/bbb/ccc</em></span></em></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-df               </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：统计文件系统的可用空间信息</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：h</em></span></em><em><span style="color:#000000;"><em>adoop</em></span></em><em> </em><em><span style="color:#000000;"><em> fs</em></span></em><em> </em><em><span style="color:#000000;"><em> -df</em></span></em><em><span style="color:#000000;"><em>  -h </em></span></em><em><span style="color:#000000;"><em> /</em></span></em></p>

			<p style="margin-left:0pt;"> </p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-du </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：统计文件夹的大小信息</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：</em></span></em></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>hadoop  fs  -du  -s  -h /aaa/*</em></span></em></p>

			<p style="margin-left:0pt;"> </p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-count         </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：统计一个指定目录下的文件节点数量</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：</em></span></em><em><span style="color:#000000;"><em>hadoop fs -count /aaa/</em></span></em></p>

			<p style="margin-left:0pt;"> </p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>-setrep                </strong></span></strong></p>

			<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>功能：设置hdfs中文件的副本数量</strong></span></strong></p>

			<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>示例：</em></span></em><em><span style="color:#000000;"><em>hadoop fs -setrep 3 /aaa/jdk.tar.gz</em></span></em></p>

			<p style="margin-left:0pt;"> </p>
			</td>
		</tr></tbody></table><h1 id="4%20HDFS%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6">4 HDFS的工作机制</h1>

<p style="margin-left:0pt;"><em><em>（工作机制的学习主要是为加深对分布式系统的理解，以及增强遇到各种问题时的分析解决能力，形成一定的集群运维能力）</em></em></p>

<p style="margin-left:0pt;"><em><em>注：很多不是真正理解hadoop技术体系的人会常常觉得HDFS可用于网盘类应用，但实际并非如此。要想将技术准确用在恰当的地方，必须对技术有深刻的理解</em></em></p>

<h2 id="4.1%20%E6%A6%82%E8%BF%B0" style="margin-left:0pt;">4.1 概述</h2>

<ol><li><span style="color:#000000;">HDFS集群分为两大角色：NameNode、DataNode</span><span style="color:#000000;">  (Secondary Namenode)</span></li>
	<li><span style="color:#000000;">NameNode负责管理整个文件系统的元数据</span></li>
	<li><span style="color:#000000;">DataNode 负责管理用户的文件数据块</span></li>
	<li><span style="color:#000000;">文件会按照固定的大小（blocksize）切成若干块后分布式存储在若干台datanode上</span></li>
	<li><span style="color:#000000;">每一个文件块可以有多个副本，并存放在不同的datanode上</span></li>
	<li><span style="color:#000000;">D</span><span style="color:#000000;">atanode会定期向</span><span style="color:#000000;">N</span><span style="color:#000000;">amenode汇报自身所保存的文件block信息，而namenode则会负责保持文件的副本数量</span></li>
	<li><span style="color:#000000;">HDFS的内部工作机制对客户端保持透明，客户端请求访问HDFS都是通过向namenode申请来进行</span></li>
</ol><h2 id="4.2%20HDFS%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B"><span style="color:#000000;">4.2 HDFS写数据流程</span></h2>

<h3 id="4.2.1%20%E6%A6%82%E8%BF%B0"><span style="color:#000000;">4.2.1 概述</span></h3>

<p>客户端要向HDFS写数据，首先要跟namenode通信以确认可以写文件并获得接收文件block的datanode，然后，客户端按顺序将文件逐个block传递给相应datanode，并由接收到block的datanode负责向其他datanode复制block的副本</p>

<h3 id="4.2.2%20%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4%E5%9B%BE">4.2.2 详细步骤图</h3>

<p><img alt="" class="has" height="599" src="https://img-blog.csdn.net/20180819004255670?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p1b2NoYW5nX2xpdQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="1200"></p>

<h3 id="4.2.3%20%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4%E8%A7%A3%E6%9E%90">4.2.3 详细步骤解析</h3>

<blockquote>
<p style="margin-left:0pt;"><span style="color:#000000;">1、根namenode通信请求上传文件，namenode检查目标文件是否已存在，父目录是否存在</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">2、namenode返回是否可以上传</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">3、client请求第一个 block该传输到哪些datanode服务器上</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">4、namenode返回3个datanode服务器ABC</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">5、client请求3台dn中的一台A上传数据（本质上是一个RPC调用，建立pipeline），A收到请求会继续调用B，然后B调用C，将真个pipeline建立完成，逐级返回客户端</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">6、client开始往A上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，A收到一个packet就会传给B，B传给C；A每传一个packet会放入一个应答队列等待应答</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">7、当一个block传输完成之后，client再次请求namenode上传第二个block的服务器。</span></p>
</blockquote>

<h2 id="4.3%20HDFS%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B">4.3 HDFS读数据流程</h2>

<h3 id="4.3.1%20%E6%A6%82%E8%BF%B0">4.3.1 概述</h3>

<p style="margin-left:0pt;">客户端将要读取的文件路径发送给namenode，namenode获取文件的元信息（主要是block的存放位置信息）返回给客户端，客户端根据返回的信息找到相应datanode逐个获取文件的block并在客户端本地进行数据追加合并从而获得整个文件</p>

<h3 id="4.3.2%20%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4%E5%9B%BE" style="margin-left:0pt;">4.3.2 详细步骤图</h3>

<p><img alt="" class="has" height="465" src="https://img-blog.csdn.net/20180819211221194?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p1b2NoYW5nX2xpdQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="1200"></p>

<h3 id="4.3.3%20%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4%E8%A7%A3%E6%9E%90">4.3.3 详细步骤解析</h3>

<blockquote>
<p style="margin-left:0pt;"><span style="color:#000000;">1、跟namenode通信查询元数据，找到文件块所在的datanode服务器</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">2、挑选一台datanode（就近原则，然后随机）服务器，请求建立socket流</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">3、datanode开始发送数据（从磁盘里面读取数据放入流，以packet为单位来做校验）</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">4、客户端以packet为单位接收，现在本地缓存，然后写入目标文件</span></p>
</blockquote>

<h1 id="5%20NameNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6">5 NameNode工作机制</h1>

<p style="margin-left:0pt;">学习目标：理解namenode的工作机制尤其是<strong><strong>元数据管理</strong></strong>机制，以增强对HDFS工作原理的理解，及培养hadoop集群运营中“性能调优”、“namenode”故障问题的分析解决能力</p>

<h2 id="5.1%20namenode%E8%81%8C%E8%B4%A3" style="margin-left:0pt;">5.1 namenode职责</h2>

<p style="margin-left:0pt;"><span style="color:#000000;">NAMENODE职责：</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">负责客户端请求的响应</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">元数据的管理（查询，修改）</span></p>

<h2 id="5.2%20%E5%85%83%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86" style="margin-left:0pt;"><span style="color:#000000;">5.2 元数据管理</span></h2>

<p style="margin-left:0pt;">namenode对数据的管理采用了三种存储形式：</p>

<ul><li style="margin-left:0pt;">内存元数据(NameSystem)</li>
	<li style="margin-left:0pt;">磁盘元数据镜像文件</li>
	<li style="margin-left:0pt;">数据操作日志文件（可通过日志运算出元数据）</li>
</ul><h3 id="5.2.1%20%E5%85%83%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6" style="margin-left:0pt;">5.2.1 元数据存储机制</h3>

<p style="margin-left:0pt;"><span style="color:#000000;">A、内存中有一份完整的元数据(</span><strong><span style="color:#ff0000;"><strong>内存meta data</strong></span></strong><span style="color:#000000;">)</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">B、磁盘有一个“准完整”的元数据镜像（</span><strong><span style="color:#ff0000;"><strong>fsimage</strong></span></strong><span style="color:#000000;">）</span><span style="color:#000000;">文件</span><span style="color:#000000;">(在namenode的工作目录中)</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">C、用于衔接内存metadata和持久化元数据镜像fsimage之间的操作日志（</span><strong><span style="color:#ff0000;"><strong>edits文件</strong></span></strong><span style="color:#000000;">）</span></p>

<p style="margin-left:0pt;"><em><span style="color:#000000;"><em>注：当客户端对hdfs中的文件进行新增或者修改操作，操作记录首先被记入edits日志文件中，当客户端操作成功后，相应的元数据会更新到内存meta.data中</em></span></em></p>

<h3 id="5.2.2%20%E5%85%83%E6%95%B0%E6%8D%AE%E6%89%8B%E5%8A%A8%E6%9F%A5%E7%9C%8B" style="margin-left:0pt;"><span style="color:#000000;">5.2.2 元数据手动查看</span></h3>

<p style="margin-left:0pt;"><span style="color:#000000;">可以通过hdfs的一个工具来查看edits中的信息</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">bin/hdfs oev -i edits -o edits.xml</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">bin/</span><span style="color:#000000;">hdfs oiv -i fsimage_0000000000000000087 -p XML -o fsimage.xml</span></p>

<h3 id="5.2.3%20%E5%85%83%E6%95%B0%E6%8D%AE%E7%9A%84checkpoint" style="margin-left:0pt;"><span style="color:#000000;">5.2.3 元数据的checkpoint</span></h3>

<p><span style="color:#000000;">每隔一段时间，会由secondary namenode将namenode上积累的所有edits和一个最新的fsimage下载到本地，并加载到内存进行merge（这个过程称为checkpoint）</span></p>

<p><span style="color:#000000;"><strong>checkpoint的详细过程</strong></span></p>

<p><img alt="" class="has" height="593" src="https://img-blog.csdn.net/20180819211948640?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p1b2NoYW5nX2xpdQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="1200"></p>

<p><strong><strong><strong>checkpoint操作的触发条件配置参数</strong></strong></strong></p>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><span style="color:#000000;">dfs.namenode.checkpoint.check.period=60  </span><span style="color:#000000;">#</span><span style="color:#000000;">检查触发条件是否满足的频率，60秒</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">dfs.namenode.checkpoint.dir=file://${hadoop.tmp.dir}/dfs/namesecondary</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">#</span><span style="color:#000000;">以上两个参数做</span><span style="color:#000000;">checkpoint</span><span style="color:#000000;">操作时，</span><span style="color:#000000;">secondary namenode</span><span style="color:#000000;">的本地工作目录</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">dfs.namenode.checkpoint.edits.dir=${dfs.namenode.checkpoint.dir}</span></p>

			<p style="margin-left:0pt;"> </p>

			<p style="margin-left:0pt;"><span style="color:#000000;">dfs.namenode.checkpoint.max-retries=3</span><span style="color:#000000;">  #</span><span style="color:#000000;">最大重试次数</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">dfs.namenode.checkpoint.period=3600</span><span style="color:#000000;">  #</span><span style="color:#000000;">两次</span><span style="color:#000000;">checkpoint</span><span style="color:#000000;">之间的时间间隔</span><span style="color:#000000;">3600</span><span style="color:#000000;">秒</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">dfs.namenode.checkpoint.txns=1000000</span><span style="color:#000000;"> #</span><span style="color:#000000;">两次</span><span style="color:#000000;">checkpoint</span><span style="color:#000000;">之间最大的操作记录</span></p>

			<p style="margin-left:0pt;"> </p>
			</td>
		</tr></tbody></table><p><strong><strong><strong>checkpoint</strong></strong><strong><strong>的附带作用</strong></strong></strong></p>

<p style="margin-left:0pt;"><span style="color:#000000;">namenode和secondary namenode的工作目录存储结构完全相同，所以，当namenode故障退出需要重新恢复时，可以从secondary namenode的工作目录中将fsimage拷贝到namenode的工作目录，以恢复namenode的元数据</span></p>

<h3 id="5.2.4%20%E5%85%83%E6%95%B0%E6%8D%AE%E7%9B%AE%E5%BD%95%E8%AF%B4%E6%98%8E" style="margin-left:0pt;">5.2.4 元数据目录说明</h3>

<p style="margin-left:0pt;"><span style="color:#000000;">在第一次部署好Hadoop集群的时候，我们需要在NameNode（NN）节点上格式化磁盘：</span></p>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><span style="color:#000000;">$HADOOP_HOME/bin/hdfs namenode -format</span></p>
			</td>
		</tr></tbody></table><p><span style="color:#000000;">格式化完成之后，将会在$dfs.namenode.name.dir/current目录下如下的文件结构</span></p>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><span style="color:#000000;">current/</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">|-- VERSION</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">|-- edits_*</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">|-- fsimage_0000000000008547077</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">|-- fsimage_0000000000008547077.md5</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">`-- seen_txid</span></p>
			</td>
		</tr></tbody></table><p><span style="color:#000000;">其中的dfs.name.dir是在hdfs-site.xml文件中配置的，默认值如下：</span></p>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><span style="color:#000000;">&lt;property&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">  &lt;name&gt;dfs.name.dir&lt;/name&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">  &lt;value&gt;file://${hadoop.tmp.dir}/dfs/name&lt;/value&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">&lt;/property&gt;</span></p>

			<p style="margin-left:0pt;"> </p>

			<p style="margin-left:0pt;"><span style="color:#000000;">hadoop.tmp.dir是在core-site.xml中配置的，默认值如下</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">&lt;property&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">  &lt;value&gt;/tmp/hadoop-${user.name}&lt;/value&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">  &lt;description&gt;A base for other temporary directories.&lt;/description&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">&lt;/property&gt;</span></p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;"><span style="color:#000000;">dfs.namenode.name.dir属性可以配置多个目录，</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">如/data1/dfs/name,/data2/dfs/name,/data3/dfs/name,....。各个目录存储的文件结构和内容都完全一样，相当于备份，这样做的好处是当其中一个目录损坏了，也不会影响到Hadoop的元数据，特别是当其中一个目录是NFS（网络文件系统Network File System，NFS）之上，即使你这台机器损坏了，元数据也得到保存。</span><br><span style="color:#000000;">下面对$dfs.namenode.name.dir/current/目录下的文件进行解释。</span><br><span style="color:#000000;">1、VERSION文件是Java属性文件，内容大致如下：</span></p>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><span style="color:#000000;">#Fri Nov 15 19:47:46 CST 2013</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">namespaceID=934548976</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">clusterID=CID-cdff7d73-93cd-4783-9399-0a22e6dce196</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">cTime=0</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">storageType=NAME_NODE</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">blockpoolID=BP-893790215-192.168.24.72-1383809616115</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">layoutVersion=-47</span></p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;"><span style="color:#000000;">其中</span><br><span style="color:#000000;">　　（1）、namespaceID是文件系统的唯一标识符，在文件系统首次格式化之后生成的；</span><br><span style="color:#000000;">　　（2）、storageType说明这个文件存储的是什么进程的数据结构信息（如果是DataNode，storageType=DATA_NODE）；</span><br><span style="color:#000000;">　　（3）、cTime表示NameNode存储时间的创建时间，由于我的NameNode没有更新过，所以这里的记录值为0，以后对NameNode升级之后，cTime将会记录更新时间戳；</span><br><span style="color:#000000;">　　（4）、layoutVersion表示HDFS永久性数据结构的版本信息， 只要数据结构变更，版本号也要递减，此时的HDFS也需要升级，否则磁盘仍旧是使用旧版本的数据结构，这会导致新版本的NameNode无法使用；</span><br><span style="color:#000000;">　　（5）、clusterID是系统生成或手动指定的集群ID，在-clusterid选项中可以使用它；如下说明</span></p>

<p style="margin-left:0pt;"> </p>

<p><span style="color:#000000;">a.使用如下命令格式化一个Namenode：</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">$HADOOP_HOME/bin/hdfs namenode -format [-clusterId &lt;cluster_id&gt;]</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">选择一个唯一的cluster_id，并且这个cluster_id不能与环境中其他集群有冲突。如果没有提供cluster_id，则会自动生成一个唯一的ClusterID。</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">b、使用如下命令格式化其他Namenode：</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;"> $HADOOP_HOME/bin/hdfs namenode -format -clusterId &lt;cluster_id&gt;</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">c、升级集群至最新版本。在升级过程中需要提供一个ClusterID，例如：</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">$HADOOP_PREFIX_HOME/bin/hdfs start namenode --config $HADOOP_CONF_DIR  -upgrade -clusterId &lt;cluster_ID&gt;</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">如果没有提供ClusterID，则会自动生成一个ClusterID。</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">　　（6）、blockpoolID：是针对每一个Namespace所对应的blockpool的ID，上面的这个BP-893790215-192.168.24.72-1383809616115就是在我的ns1的namespace下的存储块池的ID，这个ID包括了其对应的NameNode节点的ip地址。</span><br><br><span style="color:#000000;">2、$dfs.namenode.name.dir/current/seen_txid非常重要，是存放transactionId的文件，format之后是0，它代表的是namenode里面的edits_*文件的尾数，namenode重启的时候，会按照seen_txid的数字，循序从头跑edits_0000001~到seen_txid的数字。所以当你的hdfs发生异常重启的时候，一定要比对seen_txid内的数字是不是你edits最后的尾数，不然会发生建置namenode时metaData的资料有缺少，导致误删Datanode上多余Block的资讯。</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">3、$dfs.namenode.name.dir/current目录下在format的同时也会生成fsimage和edits文件，及其对应的md5校验文件。</span></p>

<p style="margin-left:0pt;"><span style="color:#ff0000;">补充：seen_txid </span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">文件中记录的是edits滚动的序号，每次重启namenode时，namenode就知道要将哪些edits进行加载edits</span></p>

<h1 id="6%20Datanode%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6" style="margin-left:0pt;"><span style="color:#000000;">6 Datanode的工作机制</span></h1>

<h2 id="6.1%20%E6%A6%82%E8%BF%B0">6.1 概述</h2>

<p style="margin-left:0pt;"><span style="color:#000000;">1、</span><span style="color:#000000;">D</span><span style="color:#000000;">atanode工作职责：</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">          存储管理用户的文件块数据</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">          定期向namenode汇报自身所持有的block信息（通过心跳信息上报）</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">（这点很重要，因为，当集群中发生某些</span><span style="color:#000000;">block副本失效时，集群如何恢复block初始副本数量的问题</span><span style="color:#000000;">）</span></p>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><span style="color:#000000;">&lt;property&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">&lt;name&gt;dfs.blockreport.intervalMsec&lt;/name&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">&lt;value&gt;3600000&lt;/value&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">&lt;description&gt;Determines block reporting interval in milliseconds.&lt;/description&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">&lt;/property&gt;</span></p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;"><span style="color:#000000;">2、Datanode掉线判断时限参数</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">datanode进程死亡或者网络故障造成datanode无法与namenode通信，namenode不会立即把该节点判定为死亡，要经过一段时间，这段时间暂称作超时时长。HDFS默认的超时时长为10分钟+30秒。如果定义超时时间为timeout，则超时时长的计算公式为：</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">timeout  = 2 * heartbeat.recheck.interval + 10 * dfs.heartbeat.interval。</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">而默认的heartbeat.recheck.interval 大小为5分钟，dfs.heartbeat.interval默认为3秒。</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">需要注意的是hdfs-site.xml 配置文件中的heartbeat.recheck.interval的单位为毫秒，dfs.heartbeat.interval的单位为秒。所以，举个例子，如果heartbeat.recheck.interval设置为5000（毫秒），dfs.heartbeat.interval设置为3（秒，默认），则总的超时时间为40秒。</span></p>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><span style="color:#000000;">&lt;property&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        &lt;name&gt;heartbeat.recheck.interval&lt;/name&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        &lt;value&gt;2000&lt;/value&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">&lt;/property&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">&lt;property&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        &lt;name&gt;dfs.heartbeat.interval&lt;/name&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">        &lt;value&gt;1&lt;/value&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">&lt;/property&gt;</span></p>
			</td>
		</tr></tbody></table><h2 id="6.2%20%E8%A7%82%E5%AF%9F%E9%AA%8C%E8%AF%81Datanode%E5%8A%9F%E8%83%BD">6.2 观察验证Datanode功能</h2>

<p style="margin-left:0pt;"><span style="color:#000000;">上传一个文件，观察文件的block具体的物理存放情况：</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">在每一台datanode机器上的这个目录中能找到文件的切块：</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">/home/hadoop/app/hadoop-2.4.1/tmp/dfs/data/current/BP-193442119-192.168.2.120-1432457733977/current/finalized</span></p>

<h1 id="7%20HDFS%E7%9A%84java%E6%93%8D%E4%BD%9C" style="margin-left:0pt;"><span style="color:#000000;">7 HDFS的java操作</span></h1>

<p><em><em>hdfs在生产应用中主要是客户端的开发，其核心步骤是从hdfs提供的api中构造一个HDFS的访问客户端对象，然后通过该客户端对象操作（增删改查）HDFS上的文件</em></em></p>

<h2 id="7.1%20%E6%90%AD%E5%BB%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83">7.1 搭建开发环境</h2>

<p style="margin-left:0pt;">1、引入依赖</p>

<table border="1" cellspacing="0" style="width:247.5pt;"><tbody><tr><td style="vertical-align:top;width:247.5pt;">
			<p style="margin-left:0pt;"><span style="color:#000000;">&lt;dependency&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">    &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</span></p>

			<p style="margin-left:0pt;">    <span style="color:#000000;">&lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">    &lt;version&gt;2.</span><span style="color:#000000;">6</span><span style="color:#000000;">.1&lt;/version&gt;</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">&lt;/dependency&gt;</span></p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;"><em><span style="color:#000000;"><em>注：如需手动引入jar包，hdfs的jar包----hadoop的安装目录的share下</em></span></em></p>

<p style="margin-left:0pt;"><span style="color:#000000;">2、window下开发的说明</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">建议在linux下进行hadoop应用的开发，不会存在兼容性问题。如在window上做客户端应用开发，需要设置以下环境：</span></p>

<ol><li><span style="color:#000000;">在windows的某个目录下解压一个hadoop的安装包</span></li>
	<li><span style="color:#000000;">将安装包下的lib和bin目录用对应windows版本平台编译的本地库替换</span></li>
	<li><span style="color:#000000;">在window系统中配置HADOOP_HOME指向你解压的安装包</span></li>
	<li><span style="color:#000000;">在windows系统的path变量中加入hadoop的bin目录</span></li>
</ol><h2 id="7.2%20%E8%8E%B7%E5%8F%96api%E4%B8%AD%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AF%B9%E8%B1%A1">7.2 获取api中的客户端对象</h2>

<p style="margin-left:0pt;"><span style="color:#000000;">在java中操作hdfs，首先要获得一个客户端实例</span></p>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0pt;"><span style="color:#000000;">Configuration conf = new Configuration()</span></p>

			<p style="margin-left:0pt;"><span style="color:#000000;">FileSystem fs = FileSystem.get(conf)</span></p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;"><span style="color:#000000;">而我们的操作目标是HDFS，所以获取到的fs对象应该是DistributedFileSystem的实例；</span></p>

<p style="margin-left:0pt;"><span style="color:#000000;">get方法是从何处判断具体实例化那种客户端类呢？</span></p>

<p style="margin-left:0pt;"><strong><span style="color:#000000;"><strong>——从conf中的一个参数 fs.defaultFS的配置值判断；</strong></span></strong></p>

<p style="margin-left:0pt;"><span style="color:#000000;">如果我们的代码中没有指定</span><span style="color:#000000;">fs.defaultFS</span><span style="color:#000000;">，并且工程classpath下也没有给定相应的配置，conf中的默认值就来自于hadoop的jar包中的core-default.xml，默认值为： </span><a><u><span style="color:#000000;"><u>file:///</u></span></u></a><span style="color:#000000;">，则获取的将不是一个DistributedFileSystem的实例，而是一个本地文件系统的客户端对象</span></p>

<h2 id="7.3%C2%A0DistributedFileSystem%E5%AE%9E%E4%BE%8B%E5%AF%B9%E8%B1%A1%E6%89%80%E5%85%B7%E5%A4%87%E7%9A%84%E6%96%B9%E6%B3%95" style="margin-left:0pt;"><span style="color:#000000;">7.3 </span><strong><strong><span style="color:#000000;"><strong>DistributedFileSystem实例</strong></span></strong><strong><strong>对象所具备的方法</strong></strong></strong></h2>

<p><img alt="" class="has" height="432" src="https://img-blog.csdn.net/20180819215058973?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p1b2NoYW5nX2xpdQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="439"></p>

<h2 id="7.4%20HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B">7.4 HDFS客户端操作数据代码示例</h2>

<h3 id="7.4.1%20%E6%96%87%E4%BB%B6%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5">7.4.1 文件的增删改查</h3>

<pre class="has">
<code class="language-java">public class HdfsClient {

	FileSystem fs = null;

	@Before
	public void init() throws Exception {

		// 构造一个配置参数对象，设置一个参数：我们要访问的hdfs的URI
		// 从而FileSystem.get()方法就知道应该是去构造一个访问hdfs文件系统的客户端，以及hdfs的访问地址
		// new Configuration();的时候，它就会去加载jar包中的hdfs-default.xml
		// 然后再加载classpath下的hdfs-site.xml
		Configuration conf = new Configuration();
		conf.set("fs.defaultFS", "hdfs://hdp-node01:9000");
		/**
		 * 参数优先级： 1、客户端代码中设置的值 2、classpath下的用户自定义配置文件 3、然后是服务器的默认配置
		 */
		conf.set("dfs.replication", "3");

		// 获取一个hdfs的访问客户端，根据参数，这个实例应该是DistributedFileSystem的实例
		// fs = FileSystem.get(conf);

		// 如果这样去获取，那conf里面就可以不要配"fs.defaultFS"参数，而且，这个客户端的身份标识已经是hadoop用户
		fs = FileSystem.get(new URI("hdfs://hdp-node01:9000"), conf, "hadoop");

	}

	/**
	 * 往hdfs上传文件
	 * 
	 * @throws Exception
	 */
	@Test
	public void testAddFileToHdfs() throws Exception {

		// 要上传的文件所在的本地路径
		Path src = new Path("g:/redis-recommend.zip");
		// 要上传到hdfs的目标路径
		Path dst = new Path("/aaa");
		fs.copyFromLocalFile(src, dst);
		fs.close();
	}

	/**
	 * 从hdfs中复制文件到本地文件系统
	 * 
	 * @throws IOException
	 * @throws IllegalArgumentException
	 */
	@Test
	public void testDownloadFileToLocal() throws IllegalArgumentException, IOException {
		fs.copyToLocalFile(new Path("/jdk-7u65-linux-i586.tar.gz"), new Path("d:/"));
		fs.close();
	}

	@Test
	public void testMkdirAndDeleteAndRename() throws IllegalArgumentException, IOException {

		// 创建目录
		fs.mkdirs(new Path("/a1/b1/c1"));

		// 删除文件夹 ，如果是非空文件夹，参数2必须给值true
		fs.delete(new Path("/aaa"), true);

		// 重命名文件或文件夹
		fs.rename(new Path("/a1"), new Path("/a2"));

	}

	/**
	 * 查看目录信息，只显示文件
	 * 
	 * @throws IOException
	 * @throws IllegalArgumentException
	 * @throws FileNotFoundException
	 */
	@Test
	public void testListFiles() throws FileNotFoundException, IllegalArgumentException, IOException {

		// 思考：为什么返回迭代器，而不是List之类的容器
		RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(new Path("/"), true);

		while (listFiles.hasNext()) {
			LocatedFileStatus fileStatus = listFiles.next();
			System.out.println(fileStatus.getPath().getName());
			System.out.println(fileStatus.getBlockSize());
			System.out.println(fileStatus.getPermission());
			System.out.println(fileStatus.getLen());
			BlockLocation[] blockLocations = fileStatus.getBlockLocations();
			for (BlockLocation bl : blockLocations) {
				System.out.println("block-length:" + bl.getLength() + "--" + "block-offset:" + bl.getOffset());
				String[] hosts = bl.getHosts();
				for (String host : hosts) {
					System.out.println(host);
				}
			}
			System.out.println("--------------为angelababy打印的分割线--------------");
		}
	}

	/**
	 * 查看文件及文件夹信息
	 * 
	 * @throws IOException
	 * @throws IllegalArgumentException
	 * @throws FileNotFoundException
	 */
	@Test
	public void testListAll() throws FileNotFoundException, IllegalArgumentException, IOException {

		FileStatus[] listStatus = fs.listStatus(new Path("/"));

		String flag = "d--             ";
		for (FileStatus fstatus : listStatus) {
			if (fstatus.isFile())  flag = "f--         ";
			System.out.println(flag + fstatus.getPath().getName());
		}
	}
}</code></pre>

<p> </p>            </div>
                </div>