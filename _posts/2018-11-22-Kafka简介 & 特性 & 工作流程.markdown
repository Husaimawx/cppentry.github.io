---
layout:     post
title:      Kafka简介 & 特性 & 工作流程
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/lemonZhaoTao/article/details/79605392				</div>
								            <div id="content_views" class="markdown_views prism-github-gist">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h3 id="kafka简介-特性-软件安装包下载">Kafka简介 &amp; 特性 &amp; 软件安装包下载</h3>

<blockquote>
  <p>官网：<a href="http://kafka.apache.org/" rel="nofollow">http://kafka.apache.org/</a> <br>
  Kafka可以用于做消息队列 <br>
  A distributed streaming platform (分布式的流处理平台) <br>
  Kafka原来就是一个队列，但是现在Kafka的功能越来越强大了，因为现在Kafka已经是一个分布式的流处理平台了 <br>
  我们做流处理，可以使用Storm来实现，也可以使用Spark Streaming来实现，同时也可以使用Kafka来实现(因为目前Kafka是分布式的流处理平台了) <br>
  但是，目前国内使用Kafka去做流处理的不多，基本没有使用这一套的(Storm最多，之后Spark Streaming)</p>
</blockquote>



<h4 id="特性">特性</h4>

<ul>
<li><p>publish &amp; subscribe <br>
发布和订阅 <br>
需要什么东西就订阅一下，当有新的东西过来之后，你订阅课就可以直接进行消费了</p></li>
<li><p>process <br>
能够写这种可以扩展的流处理应用程序，去做实时的流处理</p></li>
<li><p>store <br>
流数据能够存储进来，以安全(这个安全包括好几个方面，比如数据丢不丢失等)、分布式、多副本、容错的这些方式存储进来</p></li>
</ul>

<p>kafka被使用过去构建实时的data pipeline 和 streaming apps。它能够做到水平扩展、容错的、相当快的，在许多公司会运行在生产环境上(其实在国内，做流处理的话，至少70%的公司会选用到Kafka)</p>



<h4 id="kafka介绍">Kafka介绍</h4>

<blockquote>
  <p>官网：<a href="http://kafka.apache.org/intro" rel="nofollow">http://kafka.apache.org/intro</a> <br>
  1.能够让你发布和订阅stream里面的记录(这和传统意义上的队列是一样的) <br>
  2.能够刚你存储stream里的records 以容错的方式(后面会讲kafka到底体现在哪些容错的方面) <br>
  3.能够让你再一发生的时候就立刻处理stream的records</p>
</blockquote>

<p>Kafka适合用在哪些方面：</p>

<ol>
<li>构建一个实时数据的pipeline操作</li>
<li>构建一个流处理的应用程序</li>
</ol>

<p>First a few concepts:</p>

<ol>
<li>Kafka能够在1个或者多个server上面作为集群进行运行</li>
<li>Kafka集群能够存储stream的records，这些记录可以分类(这里每一个分类可以理解为topic) <br>
topic ： category <br>
比如说：优酷上面有很多分类，每一个分类就是一个topic</li>
<li>每个record是由key、value、timestamp构成的</li>
</ol>

<p>Kafka既然有订阅和发布，那么就会有生产和消费：</p>

<ol>
<li>The Producer API允许应用程序发布stream的record到1个或者多个Kafka的topic</li>
<li>The Consumer API允许应用程序订阅1个或者多个topic，然后处理stream的record</li>
</ol>

<p>高级别的Kafka给了我们如下的保障措施：</p>

<ol>
<li>Messages sent by a producer to a particular topic partition will be appended in the order they are sent.  <br>
That is, if a record M1 is sent by the same producer as a record M2,  <br>
and M1 is sent first, then M1 will have a lower offset than M2 and appear earlier in the log.</li>
<li>A consumer instance sees records in the order they are stored in the log.</li>
<li>For a topic with replication factor N, we will tolerate up to N-1 server failures without losing any records committed to the log.</li>
</ol>



<h4 id="版本选择-下载">版本选择 &amp; 下载</h4>

<p>Kafka版本： <br>
kafka_2.11-1.0.0.tgz (2.11是scala的版本，1.0.0是kafka的版本) <br>
这次选择所使用的版本：kafka_2.11-0.9.0.0.tgz</p>

<p>Kafka下载： <br>
解压到/opt/app/下 <br>
<code>$&gt;tar -xzvf /opt/software/kafka_2.11-0.9.0.0.tgz -C /opt/app/</code></p>

<p><code>$KAFKA_HOME/bin</code>下有用的shell脚本：</p>

<ul>
<li>kafka-topics.sh</li>
<li>kafka-server-start.sh</li>
<li>kafka-server-stop.sh</li>
</ul>

<p>测试时候用的：</p>

<ul>
<li>kafka-console-consumer.sh</li>
<li>kafka-console-producer.sh</li>
</ul>



<h3 id="kafka工作流程">Kafka工作流程</h3>

<p>提出问题：如果让你自己去实现一个消息订阅与发布的系统，该如何去实现呢？ <br>
我们将一步一步去完善设计的流程，从而理解Kafka的工作流程</p>

<p>准备： <br>
在工作中的日志通常有两大类： <br>
a ) 访问日志(access) <br>
b)  ugc日志(和费用相关)</p>

<ol>
<li><p>最low的版本，v1.0： <br>
<img src="//img-blog.csdn.net/2018031822065677?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L2xlbW9uWmhhb1Rhbw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
生产者A  ==生产==&gt;  access <br>
生产者A  ==生产==&gt;  ugc</p>

<p>产生的日志丢到Linux机器里去</p>

<p>通常情况下，生产出来的数据先到内存中(不可能直接与磁盘打交道的)，再到磁盘中去</p>

<p>后面由消费者进行消费：消费者1、消费者2</p>

<p>这种架构的缺点： <br>
假设现在只有1台机器，把所有的日志都丢到1台机器上来了 <br>
==&gt; 会引发1个问题： <br>
　　如果数据非常大，会怎么办？ <br>
　　机器肯定是扛不住的</p></li>
<li><p>针对v1.0架构设计的解决方案，v2.0： <br>
<img src="//img-blog.csdn.net/2018031822071826?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L2xlbW9uWmhhb1Rhbw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
采用分布式 <br>
如图中所示，有2台机器 <br>
==&gt; 提出问题：2台机器上的数据是存一样还是不一样？ <br>
　　必然是存不一样的</p>

<p>生产者A  ==生产==&gt;  机器1：access partition0 + 机器2：access partition1 <br>
生产者A  ==生产==&gt;  机器1：ugc partition0    + 机器2：ugc partition1 <br>
生产者A生产数据，将access分开，存取到Linux机器1与机器2中(每个机器中的数据都不同) <br>
生产者B也是如此</p>

<p>将一个大的数据以多partition的方式分开存储在各个机器上</p>

<p>v2.0的设计方式与v1.0的设计方式进行对比，好处在哪里？ <br>
==&gt; 负载明显是小很多 <br>
　　假设：原来进来100G的数据，那么所有的书都是落在1台机器上 <br>
　　　　　现在的话，有2台机器的话，负载会小很多 <br>
==&gt; 但是，同样带来了1个问题： <br>
　　存在着单点的问题 <br>
　　虽然，我们将1份数据拆成了多partition组成的 <br>
　　但是，我们的每份数据都是单partition的(如图，partition0只有在1个地方有，partition1也是) <br>
    ==&gt; 因此，这种方式仍然是不行的</p></li>
<li><p>针对v2.0架构设计的解决方案，v3.0： <br>
<img src="//img-blog.csdn.net/20180318220740222?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L2xlbW9uWmhhb1Rhbw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
将Linux机器1上的access partition0放一份到机器2上 ==&gt; partition0的副本 <br>
将Linux机器2上的access partition1放一份到机器1上 ==&gt; partition1的副本 <br>
ugc同理</p>

<p>这样改进之后，容错性好很多 <br>
但是，生产者生产数据，到底是把哪一个partition的数据丢到哪个地方(决定哪个partition) <br>
在MapReduce中，默认的partition是什么样的规则？ <br>
==&gt; 对key取hash，然后对reduce的数量取模(这样保证了，相同的key被分到同一个reduce上面去) <br>
　　那么在Kafka中是怎么样的呢？(这点将在后续文章中进行剖析)</p></li>
</ol>

<p><strong>总结：</strong> <br>
Producer,Topic,Broker,Consumer概念 &amp; Kafka工作流程： <br>
　　Producer把我们的数据生产，丢到Topic里面，Consumer去把数据从Topic里面拿出来进行消费 <br>
　　Linux机器就是Broker(即Kafka中的server，即每个Server就是Broker)</p>

<p>Topic与Partition之间的关系： <br>
　　1个topic有n个partition <br>
　　1个partition有n个副本</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>