---
layout:     post
title:      Flume日志采集框架（1）
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h3>Flume 介绍</h3>

<p><strong>1：概述</strong></p>

<p style="text-indent:50px;">Flume 是 Cloudera 提供的一个分布式、高可靠、和高可用的海量日志采集、聚合和传输系统。</p>

<p style="text-indent:50px;">Flume 可以采集文件，socket 数据包、文件夹等各种形式源数据，又可以将采集到的数据输出到 HDFS、hbase、hive、kafka 等众多外部存储系统中。</p>

<p style="text-indent:50px;">一般的采集需求，通过对 flume 的简单配置即可实现。</p>

<p style="text-indent:50px;">Flume 针对特殊场景也具备良好的自定义扩展能力，因此，flume可以适用于大部分的日常数据采集场景。</p>

<p style="text-indent:50px;"> </p>

<p style="text-indent:0;"><strong>2：运行机制</strong></p>

<p style="text-indent:50px;">Flume 分布式系统中最核心的角色是 agent ，flume 采集系统就是由一个个 agent 所连接起来形成的。</p>

<p style="text-indent:50px;">每一个 agent 相当于一个数据传递员，内部有三个组件：</p>

<p style="text-indent:50px;">           a) Source：采集源，用于跟数据源对接，以获取数据。</p>

<p style="text-indent:50px;">           b) Sink：下沉地，采集数据的传送目的，用于下一级 agent 传递数据或者往最终存储系统传递数据</p>

<p style="text-indent:50px;">           c) Channel：angent 内部的数据传输通道，用于从 source 将数据传递到 sink。</p>

<p style="text-align:center;"><img alt="" class="has" height="214" src="https://img-blog.csdnimg.cn/20181103154557507.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1dhbmRhWnc=,size_16,color_FFFFFF,t_70" width="554"></p>

<p style="text-indent:50px;"> </p>

<p style="text-indent:0;"><strong>3：复杂结构</strong></p>

<p style="text-indent:0;">多级 agent 之间串联</p>

<p style="text-indent:0;">（1） 第一种：2个 agent 串联</p>

<p style="text-align:center;"><img alt="" class="has" height="116" src="https://img-blog.csdnimg.cn/20181103155124525.png" width="577"></p>

<p style="text-indent:0;">（2） 第二种：多个 agent 的采集的数据进行汇总</p>

<p style="text-align:center;"><img alt="" class="has" height="324" src="https://img-blog.csdnimg.cn/20181103155212502.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1dhbmRhWnc=,size_16,color_FFFFFF,t_70" width="481"></p>

<p style="text-indent:0;">（3）第三种：采集的数据可以下层到不同的系统中</p>

<p style="text-align:center;"><img alt="" class="has" height="307" src="https://img-blog.csdnimg.cn/2018110315532331.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1dhbmRhWnc=,size_16,color_FFFFFF,t_70" width="578"></p>

<hr><h3>Flume 实战案例</h3>

<p><strong>1：Flume 的安装部署</strong></p>

<p style="text-indent:50px;">a) Flume 的安装非常简单，只需要解压即可，当然，前提是已有 hadoop 环境上传安装包到数据元所有在节点上</p>

<p style="text-indent:50px;">b) 然后解压 tar -zxvf apache-flume-1.6.0-bin.tar.gz</p>

<p style="text-indent:50px;">c) 进入 flume 的目录，修改 conf 下的 flume-enc.sh ,在里面配置 JAVA_HOME</p>

<p style="text-indent:0;">根据数据采集的需求配置采集方案，描述在配置文件中（文件名可任意自定义）</p>

<p style="text-indent:0;">指定采集方案配置文件，在相应的节点上启动 flume agent</p>

<p style="text-indent:0;"> </p>

<p><strong>2：简单案例</strong></p>

<p style="text-align:center;"><img alt="" class="has" height="273" src="https://img-blog.csdnimg.cn/20181103164054427.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1dhbmRhWnc=,size_16,color_FFFFFF,t_70" width="553"></p>

<p style="text-indent:0;">a) 现在 flume 的 conf 目录下新建一个文件</p>

<p style="text-indent:0;">vi netcat-logger.conf</p>

<pre class="has">
<code class="language-bash"># 定义这个agent中各组件的名字
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# 描述和配置source组件：r1
a1.sources.r1.type = netcat
a1.sources.r1.bind = hadoop01
a1.sources.r1.port = 44444

# 描述和配置sink组件：k1
a1.sinks.k1.type = logger

# 描述和配置channel组件，此处使用是内存缓存的方式
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# 描述和配置source  channel   sink之间的连接关系
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

2、启动agent去采集数据
bin/flume-ng agent -c conf -f conf/netcat-logger.conf -n a1  -Dflume.root.logger=INFO,console</code></pre>

<p style="text-indent:0;">b) 启动 agent 去采集数据</p>

<pre class="has">
<code class="language-bash">bin/flume-ng agent -c conf -f conf/netcat-logger.conf -n a1  -Dflume.root.logger=INFO,console</code></pre>

<p style="text-indent:50px;">-c conf 指定flume 自身的配置文件所在目录</p>

<p style="text-indent:50px;">-f conf/netcat-logger.con 指定我们所描述的采集方案</p>

<p style="text-indent:50px;">-n a1 指定我们这个 agent 的名字</p>

<p style="text-indent:0;"><strong>3：测试</strong></p>

<p style="text-indent:0;">先要往 agent 采集监听的端口上发送数据，让 agent 有数据可采，随便在一个能跟 agent 节点联网的机器上</p>

<pre class="has">
<code class="language-bash">telnet anget-hostname  port   （telnet itcast01 44444） </code></pre>

<p style="text-align:center;"><img alt="" class="has" height="140" src="https://img-blog.csdnimg.cn/20181103164752802.png" width="469"></p>

<p style="text-indent:0;"> </p>

<h3>Source 组件</h3>

<table align="center" border="1" cellpadding="1" cellspacing="1"><tbody><tr><td>Source类型</td>
			<td>说明</td>
		</tr><tr><td>Avro Source</td>
			<td>支持 Avro 协议（实际上是 Avro RPC），内置支持。</td>
		</tr><tr><td>Exec Source</td>
			<td>基于 Unix 的 command 的标准输出上生产数据</td>
		</tr><tr><td>Spooling Directory Source</td>
			<td>监控指定目录内数据变更。</td>
		</tr><tr><td>Netcat Source</td>
			<td>监控某个端口，将流经端口的每一个文本行数据作为 Event 输入。</td>
		</tr><tr><td>Thrift Source</td>
			<td>支持 Thrift 协议，内置支持。</td>
		</tr><tr><td>JMS Source</td>
			<td>从 JMS 系统（消息、主题）中读取数据，ActiveMQ 已经测试过。</td>
		</tr><tr><td>Sequence Generator Source </td>
			<td>序列生成器数据源，生产序列数据。</td>
		</tr><tr><td>Syslog Source</td>
			<td>读取 syslog 数据，产生 Event ，支持 UDP 和 TPC 两种协议。</td>
		</tr><tr><td>HTTP Source</td>
			<td>基于 HTTP POST 或 GET 方式的数据源，支持 JSON、BLOB 表现形式。</td>
		</tr><tr><td>Legacy Source</td>
			<td>兼容老的 Flume OG 中的 Source （0.9.x版本）。</td>
		</tr></tbody></table><h3>Channel 组件</h3>

<table align="center" border="1" cellpadding="1" cellspacing="1"><tbody><tr><td>Channel类型</td>
			<td>说明</td>
		</tr><tr><td>Memory Channel</td>
			<td>Event 数据存储在内存中。</td>
		</tr><tr><td>File Channel</td>
			<td>Event 数据存储在磁盘文件中。</td>
		</tr><tr><td>JDBC Channel</td>
			<td>Event 数据存储在持久化存储中，当前 Flume Channel 内置支持 Derby数据库。</td>
		</tr><tr><td>Spillable Memory Channel</td>
			<td>Event 数据存储在内存中和磁盘上，当内存队列满了，会持久化到磁盘文件。</td>
		</tr><tr><td>Pseudo Transaction Channel</td>
			<td>测试用途</td>
		</tr><tr><td>Custom Channel</td>
			<td>自定义 Channel 实现。</td>
		</tr></tbody></table><h3>Sink 组件</h3>

<table border="1" cellpadding="1" cellspacing="1"><tbody><tr><td>Sink 类型</td>
			<td>说明</td>
		</tr><tr><td>HDFS Sink</td>
			<td>数据写入 HDFS。</td>
		</tr><tr><td>Avro Sink </td>
			<td>数据被转换成 Avro Event,然后发送到配置的 RPC 端口上。</td>
		</tr><tr><td>Thrift Sink</td>
			<td>数据被转换成 Thrift Event，然后发送到配置的 RPC 端口上。</td>
		</tr><tr><td>IRC Sink</td>
			<td>数据在 IRC 上进行回放。</td>
		</tr><tr><td>File Roll Sink</td>
			<td>存储数据到本地文件系统。</td>
		</tr><tr><td>Null Sink</td>
			<td>丢弃到所有数据。</td>
		</tr><tr><td>HBase Sink</td>
			<td>数据写入到 HBase 数据库。</td>
		</tr><tr><td>Morphline Solr Sink</td>
			<td>数据发送到 Solr 搜索服务器。</td>
		</tr><tr><td>ElasticSearch Sink</td>
			<td>数据发送到 Elastic Search 搜索服务器（集群）</td>
		</tr><tr><td>Custom Sink</td>
			<td>自定义 Sink 实现</td>
		</tr></tbody></table><p><em>Flume 支持众多的 source 、 channel 、 sink 类型，详细手册可参考官方文档 <a href="http://flume.apache.org/FlumeUserGuide.html" rel="nofollow">http://flume.apache.org/FlumeUserGuide.html</a></em></p>            </div>
                </div>