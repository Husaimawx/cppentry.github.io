---
layout:     post
title:      hadoop编程工具类
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>1、遍历一个HDFS文件夹</p>
<p></p><pre><code class="language-java">	public static void Scanner() throws IOException{
		Configuration conf=new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
		FileSystem hdfs=FileSystem.get(conf);
		
		FileStatus [] fs=hdfs.listStatus(new Path("/"));
		for(FileStatus  f:fs){
//			System.out.println(f.getLen());
			System.out.println(f.getPath());
		}
		hdfs.close();
	}</code></pre><br>
2、创建HDFS文件夹和创建文件（多级创建）<br><p></p><pre><code class="language-java">	public static void createFIle() throws IOException{
		Configuration conf=new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
		FileSystem hdfs=FileSystem.get(conf);
		
		hdfs.mkdirs(new Path("/zgf/hei/2"));
		hdfs.mkdirs(new Path("/zgf/hei/2.txt"));
		
		hdfs.close();
	}</code></pre><br>
3、可以把本地处理的文本结果上传HDFS（HDFS下载查看文本内容）
<p></p><pre><code class="language-java">	public static void writeString() throws IOException{
		Configuration conf=new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
		FileSystem hdfs=FileSystem.get(conf);
		
		FSDataOutputStream out=hdfs.create(new Path("/zgf/hei/kf.txt"));
		out.write("heiheihei".getBytes("GB2312"));
	    
		out.close();
		hdfs.close();
	}</code></pre><br>
4、删除HDFS文件，多个删除可以遍历--删除HSFS目录及文件
<p></p><pre><code class="language-java">	public static void deleteFile() throws IOException{
		Configuration conf=new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
		FileSystem hdfs=FileSystem.get(conf);
		
//		hdfs.delete(new Path("/zgf/hei/2.txt"));//删文件夹
		hdfs.delete(new Path("/zgf/hei/2.txt"),true);//true强制删，无论是否有文件
		
		hdfs.close();
	}</code></pre>5、判断HDFS文件是否存在
<p></p><pre><code class="language-java">	public static void isExist() throws IOException{
		Configuration conf=new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
		FileSystem hdfs=FileSystem.get(conf);
		
		boolean isexist=hdfs.exists(new Path("/zgf/hei/kf.txt"));
		System.out.println(isexist);
	}</code></pre><br>
6、获得hadoop子节点的信息
<p></p><pre><code class="language-java">	public static void childNode() throws IOException{
		Configuration conf=new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
		FileSystem hdfs=FileSystem.get(conf);
	
		DistributedFileSystem hdfsPlus=(DistributedFileSystem) hdfs;
		DatanodeInfo [] dis=hdfsPlus.getDataNodeStats();
		for(DatanodeInfo d:dis){
			System.out.println(d.getInfoAddr());
			System.out.println(d.getHostName());
			System.out.println(d.getCacheRemaining());
			System.out.println(d.getInfoPort());
			System.out.println(d.getCapacity());
		}
	}</code></pre><br>
7、获取HDFS子节点的主机
<p></p><pre><code class="language-java">	public static void childNode2() throws IOException{
		Configuration conf=new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
		FileSystem hdfs=FileSystem.get(conf);
		
		Path path=new Path("/output/part-r-00000");
		FileStatus fileStatus=hdfs.getFileStatus(path);
		BlockLocation []bl=hdfs.getFileBlockLocations(fileStatus, 0, fileStatus.getLen());
		int l=bl.length;
		for(int  i=0;i&lt;l;i++){
			String [] hosts=bl[i].getHosts();
			for(String host:hosts){
				System.out.println(host);
			}
		}
	}
	</code></pre><br><br>            </div>
                </div>