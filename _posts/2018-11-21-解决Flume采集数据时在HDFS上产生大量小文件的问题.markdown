---
layout:     post
title:      解决Flume采集数据时在HDFS上产生大量小文件的问题
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：如需转载，请注明出处					https://blog.csdn.net/whdxjbw/article/details/80606917				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>问题：flume指定HDFS类型的Sink时，采集数据至HDFS指定目录，会产生大量小文件。</p><p><br></p><p><span style="font-size:24px;"><strong>问题重现：</strong></span></p><p><strong>1、创建flume配置文件flume-env.sh，：</strong></p><p><img src="https://img-blog.csdn.net/20180607115244601?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3doZHhqYnc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p>flume配置文件如下（根据自身需要修改）：</p><p><img src="https://img-blog.csdn.net/20180607115147993?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3doZHhqYnc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p>    因为flume可以配置多种采集方式，每种采集方式对应一个agent配置文件，flume即通过运行agent完成采集工作，这里为了方便重现问题，直接监控整个目录。</p><p>flume的agent配置文件如下（根据自身需要修改）：</p><p><img src="https://img-blog.csdn.net/20180607115712235?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3doZHhqYnc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p><img src="https://img-blog.csdn.net/20180607120357457?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3doZHhqYnc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p><br></p><p><strong>2、建立待监控目录：</strong></p><p><img src="https://img-blog.csdn.net/20180607115845987?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3doZHhqYnc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p><br></p><p><strong>3、执行flume的agent</strong></p><pre><code class="language-plain">/mnt/disk1/apache-flume-1.7.0-bin/bin/flume-ng agent -n a1 -c /root/flume_conf_jbw -f /root/flume_agent_conf_jbw/a1.conf -Dflume.root.logger=INFO,console</code></pre>a1为agent的名称<br>a1.conf为flume配置文件的名称<br>-c指向log4j.properties文件和flume_env.sh文件所在目录。<br>--Dflume.root.logger=INFO,console 在终端输出运行日志<p><br></p><p>    可见以采集完成的 文件会加上.COMPLETE后缀，注意，若此时再在监控目录新建同名文件，flume会报错，因为采集完成后会产生相同的文件名的文件。若发生此情况，需要重新运行flume的agent。</p><p><img src="https://img-blog.csdn.net/20180607125135771?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3doZHhqYnc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p><p>    在HDFS目录上查看采集到的数据，内容如下，零散小文件：<br></p><p><img src="https://img-blog.csdn.net/20180607130211126?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3doZHhqYnc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p><br></p><p><span style="font-size:24px;"><strong>解决方案：</strong></span></p><p>检查flume配置文件</p><p><img src="https://img-blog.csdn.net/20180607172649340?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3doZHhqYnc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></p><p>    </p><pre><code class="language-plain">a1.sinks.k1.hdfs.round=true</code></pre><pre><code class="language-plain">a1.sinks.k1.hdfs.round=true</code></pre><pre><code class="language-plain">a1.sinks.k1.hdfs.round=true，</code></pre><p>将以上三行删除，新增如下两行</p><pre><code class="language-plain">a1.sinks.k1.hdfs.rollSize=0</code></pre><pre><code class="language-plain">a1.sinks.k1.hdfs.rollCount=0</code></pre><p>再次重启Flume客户端采集即可。可见不再是小文件了，如下：</p><p><img src="https://img-blog.csdn.net/201806071740441?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3doZHhqYnc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p><p><br></p><p><span style="font-size:24px;"><strong>分析原因：</strong></span></p><p><span style="font-size:14px;">    Flume可以设置文件<br></span></p><p><span style="font-size:14px;">查阅flume配置参数，如下：</span></p><p>rollSize<br>默认值：1024，当临时文件达到该大小（单位：bytes）时，滚动成目标文件。如果设置成0，则表示不根据临时文件大小来滚动文件。<br><br>rollCount<br>默认值：10，当events数据达到该数量时候，将临时文件滚动成目标文件，如果设置成0，则表示不根据events数据来滚动文件。<br><br>round<br>默认值：false，是否启用时间上的”舍弃”，类似于”四舍五入”，如果启用，则会影响除了%t的其他所有时间表达式；<br><br>roundValue<br>默认值：1，时间上进行“舍弃”的值；<br><br>roundUnit<br></p><p>默认值：seconds，时间上进行”舍弃”的单位，包含：second,minute,hour</p><p>当设置了round、roundValue、roundUnit参数收，需要在sink指定的HDFS路径上指定按照时间生成的目录的格式，例如有需求，每采集1小时就在HDFS目录上生成一个目录，里面存放这1小时内采集到的数据。</p><p>编写sink部分的配置文件如下：</p><pre><code class="language-plain">a1.sinks.k1.hdfs.path = hdfs://nameservice1/tmp/flume/jbw/%y-%m-%d/%H%M%S
a1.sinks.k1.hdfs.round = true
a1.sinks.k1.hdfs.roundValue = 60
a1.sinks.k1.hdfs.roundUnit = minute

当时间为2018-6-7 17:38:59时候，hdfs.path依然会被解析为：

/flume/events/20151016/17:30/00
因为设置的是舍弃10分钟内的时间，因此，该目录每10分钟新生成一个。</code></pre><p>此时，若当时间为2018-6-7 10:00:00时候，hdfs.path会被解析为：</p><p>hdfs://nameservice1/tmp/flume/jbw/20180607/10:00:00</p><p>在时间为2018-6-7 10:59:59时候，hdfs.path依旧会被解析为：</p><p>hdfs://nameservice1/tmp/flume/jbw/20180607/10:00:00</p><p>在时间为2018-6-7 11:02:00时候，hdfs.path则会被解析为：</p><p>hdfs://nameservice1/tmp/flume/jbw/20180607/11:00:00</p><p><strong><span style="font-size:16px;">本次产生大量小文件的原因就是hdfs.path中没有指定对应的目录日期对应格式（%y-%m-%d/%H%M%S）。</span></strong></p><p><strong><span style="font-size:16px;"><br></span></strong></p><p><strong><span style="font-size:24px;">解决方案：</span></strong></p><p><span style="font-size:16px;"><strong>去掉round时间系列参数，并将rollSize和rollCount置0，表示不根据临时文件大小和event数量来滚动文件（滚动文件即指将HDFS上生成的以.tmp结尾的临时文件转换为实际存储文件）。当然，也可以调大rollSize参数（如调至100000000,表示100MB滚动文件，单位是bytes）。</strong></span></p><p><br></p><p>PS：网上还有另一种出现大量小文件对应的解决方案，即设置a1.sinks.k1.hdfs.minBlockReplicas=1。因为文件会因为所在块的复制而滚动文件。  </p><p><br></p><p><br></p><p><br></p><p><br></p>            </div>
                </div>