---
layout:     post
title:      大数据IMF传奇行动绝密课程第55课：60分钟从零起步驾驭Hive实战
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h1 id="60分钟从零起步驾驭hive实战">60分钟从零起步驾驭Hive实战</h1>

<p>1、Hive本质解析 <br>
2、Hive安装实战 <br>
3、使用Hive操作搜索引擎数据实战 <br>
一、Hive的本质是什么？ <br>
1、Hive是分布式数据仓库，同时又是查询引擎，所以SparkSQL取代的只是Hive查询引擎，在企业实际生产环境下Hive+Spark SQL是目前最为经典的数据分析组合； <br>
2、Hive本身就是一个简单单机版本的软件，主要负责： <br>
a)把HQL翻译成Mapper(s)-Reducer-Mapper(s)的代码；并且可能产生很多MapReduce的Job； <br>
b)把生成的MapReduce代码及相关资源打包成为Jar并发布到Hadoop集群中且进行运行（这一切都是自动的）。 <br>
<img title="" alt="图55-1 Hive架构" src="https://img-blog.csdn.net/20160905215330054"> <br>
二、Hive安装和配置实战 <br>
1、我们使用的是Hive1.2.1版本 <br>
2、安装： <br>
a)配置./.bashrc <br>
export HIVE_HOME= <br>
export HIVE_CONF_DIR= <br>
PATH追加${HIVE_HOME}/bin <br>
b)配置conf/hive-env.sh <br>
export HADOOP_HOME HIVE_HOME HIVE_CONF_DIR <br>
c)hive-default.xml.template 变成hive-site.xml <br>
Hive默认情况下存放元数据的是Derby，遗憾的是Derby是单用户的，所以在生产环境下一般会采用支持多用户的数据库来进行Meta Store，且进行Master-Slaves主从读写分离和备份；我们最常使用MySQL。 <br>
hive.metastore.sarehouse.dir <br>
默认/user/hive/warehouse(HDFS)L的安装和配置 <br>
4、Hive的表有两种基本类型：一种内部表（这种表数据属于Hive本身，言外之意是如果原来的数据在HDFS的其它地方，此时数据会通过HDFS移动到Hive数据仓库所在的目录，如果删除Hive中的该表的话，数据和元素据均会被删除），另外一种是外部表（这种表数据不属于Hive数据仓库，元数据中会表达具体数据在哪里，使用的时候和内部表的使用是一样的，只是如果通过Hive去删除的话，此时删除的只是元数据，并没有删除数据本身）。 <br>
三、使用Hive分析搜索数据</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>