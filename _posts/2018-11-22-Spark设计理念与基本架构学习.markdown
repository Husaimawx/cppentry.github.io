---
layout:     post
title:      Spark设计理念与基本架构学习
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>《深入理解Spark核心思想与源码分析》学习</p>
<p>一、Spark模块设计</p>
<p>Spark模块包括Spark Core，Spark SQL, Spark Streaming， GraphX， MLlib。<br>
其中，Spark Core是Spark的核心功能实现，包括SparkContext的初始化，部署模式，存储体系，计算引擎，任务提交与执行；<br>
Spark SQL提供关系型数据库SQL处理能力；Spark Streaming提供流式计算处理能力；GraphX提供图计算能力；MLlib提供机器学习相关算法实现。</p>
<p>Spark的核心功能由Spark Core提供，如下：<br>
SparkContext：在编写Spark程序时，首先应对SparkContext进行初始化，我们编写的 Driver Application的执行与输出都是通过SparkContext来实现。SparkContext中的DAGScheduler负责Job的创建，将DAG中的RDD划分到不同的Stage，提交Stage等，TaskScheduler中的Schedulerbackend负责资源的申请分配与任务调度。<br>
存储体系：Spark是基于内存的，优先选择各节点的内存进行存储，当内存不够用时，才会考虑使用磁盘存储，尽可能减少了磁盘I/O操作，提升了效率，这使得Spark适用于实时计算、流式计算的场景。<br>
计算引擎：计算引擎由SparkContext中的DAGScheduler、RDD和具体节点上的Executor进程负责执行的Map和Reduce任务组成。<br>
部署模式：提供了Standalone模式的部署实现，支持Yarn等分布式资源管理系统，这主要解决单节点不足以提供足够的存储和计算能力的问题。<br>
Spark扩展功能包括Spark SQL, Spark Streaming， GraphX， MLlib。</p>
<p>二、Spark模型设计</p>
<p>Spark编程模型：</p>
<ol>
<li>初始化SparkContext，并编写Driver Application程序；</li>
<li>通过SparkContext提交用户应用程序。内部执行过程为首先使用BlockManager和BroadcastManager对任务的Hadoop配置进行广播，然后DAGScheduler会将任务转换为RDD并组织成DAG，DAG会被划分为不同的Stage，最后TaskScheduler借助ActorSystem将任务提交给集群管理器Cluster Manager。</li>
<li>集群管理器Cluster Manager将为Task分配资源，也就是把Task分配到具体Worker节点上，Worker节点创建Executor进程运行Task。<br>
<img src="https://img-blog.csdn.net/2018092821481257?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTA3NDkyOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="Spark程序执行过程"><br>
RDD计算模型：<br>
Spark的计算过程就是RDD的迭代计算。所有数据会被分区，即分为不同的Partition，分区数量取决于Partition的设置，每个Partition的数据只能在一个Task中计算，所有Partition的数据在多个Worker节点的Executor中并行执行。<br>
<img src="https://img-blog.csdn.net/20180928215309981?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTA3NDkyOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="不同Partition的RDD数据并行执行"></li>
</ol>
<p>三、Spark基本架构：<br>
从集群部署角度，Spark集群的组成包括：Cluster Manager，Worker，Executor，drive APP。<br>
Cluster Manager：集群管理器，负责资源的分配与管理，集群管理器的资源分配属于一级分配。因为Cluster Manager负责给各Task分配资源，也就是把各Task分配到不同的Worker节点，即把各个Worker的CPU、内存等资源分配给应用程序，并不负责对Executor的资源分配。Executor的资源分配是通过TaskScheduler中的Schedulerbackend进行的。<br>
Worker：工作节点。负责Executor进程的创建，将资源和任务进一步分配给Executor，同步资源信息给Cluster Manager。每个Worker节点默认只创建一个Executor进程。<br>
Executor：执行计算任务的进程。负责任务执行及与Worker、Driver APP的信息同步。<br>
Driver APP：客户端应用程序。将任务转换成RDD并组织成DAG，与Cluster Manager进行通信与调度。<br>
<img src="https://img-blog.csdn.net/20180928222119104?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTA3NDkyOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="Spark架构"></p>

            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>