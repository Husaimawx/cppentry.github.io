---
layout:     post
title:      在spark集群中运行程序遇到的一些问题
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>使用的是yarn模式，所以运行程序之前需要先将所用数据集传到hdfs上</p>
<pre><code>//查看hdfs的目录
./hdfs dfs -ls
//新建一个data文件夹
./hdfs dfs -mkdir /data
//将文件上传到data文件夹下
./hdfs dfs -put /root/Readme.txt  /data
</code></pre>
<p>在程序中，读取文件可以读取本地文件，也有读取hdfs中的文件</p>
<pre><code>val sc = new SparkContext(conf)
//在本地运行，读取本地磁盘中的文件，只需写明路径即可
val data = sc.textFile("D:/data/Readme.txt")
//读取hdfs中的文件，下列两个方法都可
val data1 = sc.textFile("hdfs://master:9000/user/root/Readme.txt")
val data2 = sc.textFile("hdfs:///data/Readme.txt")
</code></pre>
<p>运行程序时，使用eclipse将程序打成jar包上传到spark集群中，使用如下命令运行程序</p>
<pre><code>//在spark的bin目录下运行
./bin/spark-submit   --class CLASSNAME   --master spark://192.168.45.145:7077  /root/CLASSNAME.jar 
</code></pre>

            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>