---
layout:     post
title:      大数据实习笔记
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创学习笔记，如需转载请注明来源：					https://blog.csdn.net/wugenqiang/article/details/81075446				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>#2018-07-19#</p>

<p>1.同步集群时间</p>

<p>2.数据导入flume</p>

<p style="margin-left:0cm;"><span style="color:#333333;">使用</span><span style="color:#333333;"> flume </span><span style="color:#333333;">收集</span><span style="color:#333333;"> nginx </span><span style="color:#333333;">服务器的日志到</span><span style="color:#333333;"> hdfs </span></p>

<p>（1）配置代理</p>

<p>[root@master1 ~]# vim /etc/flume/conf/flume.conf<br>
添加：</p>

<p style="margin-left:0cm;"><span style="color:#333333;"># </span><span style="color:#333333;">#</span><span style="color:#333333;">配置</span><span style="color:#333333;">Agent</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sources</span> <span style="color:#333333;">= r1</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sinks = k1</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.channels = c1</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;"># # </span><span style="color:#333333;">配置</span><span style="color:#333333;">Source</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sources.r1.type = exec</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sources.r1.channels = c1</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sources.r1.deserializer.outputCharset</span> <span style="color:#333333;">= UTF-8</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;"># # </span><span style="color:#333333;">配置需要监控的日志输出目录</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sources.r1.command = tail -F /var/log/nginx/access.log</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;"># # </span><span style="color:#333333;">配置</span><span style="color:#333333;">Sink</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sinks.k1.type = hdfs</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sinks.k1.channel = c1</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sinks.k1.hdfs.useLocalTimeStamp = true</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sinks.k1.hdfs.path = hdfs://master1:8020/user/hdfs/flume/collector1</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sinks.k1.hdfs.filePrefix = %Y-%m-%d-%H</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sinks.k1.hdfs.fileSuffix = .log</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sinks.k1.hdfs.minBlockReplicas = 1</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sinks.k1.hdfs.fileType</span> <span style="color:#333333;">= DataStream</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sinks.k1.hdfs.writeFormat = Text</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sinks.k1.hdfs.rollInterval = 86400</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sinks.k1.hdfs.rollSize = 1000000</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sinks.k1.hdfs.rollCount = 10000</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sinks.k1.hdfs.idleTimeout = 0</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;"># # </span><span style="color:#333333;">配置</span><span style="color:#333333;">Channel</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.channels.c1.type = memory</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.channels.c1.capacity = 1000</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.channels.c1.transactionCapacity = 100</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;"># # </span><span style="color:#333333;">将三者连接</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sources.r1.channel = c1</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">a1.sinks.k1.channel = c1</span><br><br>
（2）<span style="color:#333333;">准备实验环境</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">--1---挂载光盘，并且安装</span><span style="color:#333333;"> nginx </span><span style="color:#333333;">服务</span></p>

<p style="margin-left:0cm;">[root@master1 mnt]# mkdir cdrom<br>
[root@master1 mnt]# ls<br>
cdrom</p>

<p style="margin-left:0cm;"><span style="color:#333333;">[root@master1 ~]# mount /dev/sr0 /mnt/cdrom<br>
mount: /dev/sr0 写保护，将以只读方式挂载</span></p>

<p style="margin-left:0cm;">[root@master1 ~]# yum install nginx<br>
已加载插件：fastestmirror<br>
There are no enabled repos.<br>
 Run "yum repolist all" to see the repos you have.<br>
 To enable Red Hat Subscription Management repositories:<br>
     subscription-manager repos --enable &lt;repo&gt;<br>
 To enable custom repositories:<br>
     yum-config-manager --enable &lt;repo&gt;<br>
 </p>

<p style="margin-left:0cm;">---2----安装repos，输入命令“cd /etc/yum.repos.d/”如图命令操作</p>

<p>[root@master1 ~]# cd /etc/yum.repos.d/<br>
[root@master1 yum.repos.d]# ls<br>
hanwate_cdrom.repo  online_repos<br>
[root@master1 yum.repos.d]# vim hanwate_cdrom.repo</p>

<p>[hanwate_install]<br>
name=hanwate install cdrom<br>
baseurl=file:///mnt/cdrom/<br>
path=/<br>
enabled=1<br>
gpgcheck=1<br>
gpgkey=file:///mnt/cdrom/RPM-GPG-KEY-HanWate<br>
 </p>

<p>----3----测试ok</p>

<p>[root@master1 ~]# yum install nginx<br>
已加载插件：fastestmirror<br>
hanwate_install                                                     | 3.7 kB  00:00:00     <br>
(1/2): hanwate_install/group_gz                                     | 2.1 kB  00:00:01     <br>
(2/2): hanwate_install/primary_db                                   | 917 kB  00:00:01 </p>

<p>-----4------</p>

<p style="margin-left:0cm;"><span style="color:#333333;">准备</span><span style="color:#333333;"> web </span><span style="color:#333333;">服务器日志，开启</span><span style="color:#333333;"> nginx </span><span style="color:#333333;">服务</span></p>

<p style="margin-left:0cm;">[root@master1 ~]# systemctl start nginx<br>
 </p>

<p style="margin-left:0cm;">----5-----</p>

<p style="margin-left:0cm;"><span style="color:#333333;">开启服务后可以通过查看</span><span style="color:#333333;"> /var/log/flume/flume.log </span><span style="color:#333333;">来</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">看到运行日志。</span></p>

<p style="margin-left:0cm;">先开启权限<strong>chmod 777</strong></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><strong>---6---</strong></p>

<p style="margin-left:0cm;"><span style="color:#333333;">创建日志导入</span><span style="color:#333333;"> hdfs </span><span style="color:#333333;">的目录</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">[root@master1 ~]# su - hdfs<br>
上一次登录：三 7月 18 08:21:40 CST 2018pts/1 上<br>
-bash-4.2$ hadoop fs -mkdir /user/hdfs/<br>
-bash-4.2$ hadoop fs -mkdir /user/hdfs/flume/<br>
-bash-4.2$ hadoop fs -mkdir /user/hdfs/flume/collector1<br>
-bash-4.2$ hadoop fs -chmod 777  /user/hdfs/flume</span><br>
 </p>

<p style="margin-left:0cm;">----7-----<span style="color:#333333;">在地址栏输入开了</span> <span style="color:#333333;">nginx</span> <span style="color:#333333;">服务的机器</span><span style="color:#333333;">IP</span><span style="color:#333333;">即可</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;">打开NGINX web界面</span></p>

<p style="margin-left:0cm;"><span style="color:#333333;"><img alt="" class="has" src="https://img-blog.csdn.net/20180719232908991?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VucWlhbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></span></p>

<p style="margin-left:0cm;">（3）启动代理：</p>

<p style="margin-left:0cm;">[root@master1 ~]# flume-ng agent --conf /etc/flume/conf/ --conf-file /etc/flume/conf/flume.conf --name a1 -Dflume.root.logger=INFO,console</p>

<p style="margin-left:0cm;">（4）查看</p>

<p style="margin-left:0cm;"><img alt="" class="has" src="https://img-blog.csdn.net/20180720094405437?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VucWlhbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>

<p style="margin-left:0cm;"> </p>

<p>#2018-07-18#</p>

<h3 style="margin-left:0cm;">取消权限验证</h3>

<p style="margin-left:0cm;">若出现权限问题则可采取下面策略解决：</p>

<p style="margin-left:0cm;">取消权限验证：</p>

<p style="margin-left:0cm;">可以考虑把 hdfs 的权限验证给去掉。在 hdfs-site.xml 中添加一个配置项：</p>

<p style="margin-left:0cm;">&lt;property&gt;</p>

<p style="margin-left:0cm;">&lt;name&gt;dfs.permissions&lt;/name&gt;</p>

<p style="margin-left:0cm;">&lt;value&gt;false&lt;/value&gt;</p>

<p style="margin-left:0cm;">&lt;/property&gt;</p>

<p>#2018-07-17#</p>

<p>一、hadoop集群</p>

<p>1.节点</p>

<p>master:</p>

<p>master1:  ip:192.168.75.137</p>

<p>master2:  ip:192.168.75.138</p>

<p>slave:</p>

<p>slave1:  ip:192.168.75.139</p>

<p>slave2:  ip:192.168.75.140</p>

<p>操作：</p>

<p>（1）查看ip</p>

<p>ifconfig</p>

<p>（2）更改hostname主机名</p>

<p>hostnamectl set-hostname 主机名</p>

<p>（3）添加域名映射</p>

<p>vim /etc/hosts</p>

<p>（4）查看是否存在.sh</p>

<p>[root@master1 ~]# ls -a</p>

<p>如果有则输入：rm -rf /root/.ssh卸载<br>
（5）生成ssh</p>

<p> ssh-keygen -t rsa</p>

<p>（6）给钥匙</p>

<p>master上执行</p>

<p>scp id_rsa.pub root@master1:/root/</p>

<p>scp id_rsa.pub root@slave1:/root/</p>

<p>等等等</p>

<p>（7）加保险</p>

<p>master和slave上都需要</p>

<p>cat id_rsa.pub&gt;&gt;.ssh/authorized_keys<br>
（8）测试</p>

<p>[root@master1 ~]# ssh slave1<br>
Last login: Tue Jul 17 09:52:38 2018 from 192.168.75.1<br>
[root@slave1 ~]# </p>

<p> </p>

<p>2.配置java环境变量</p>

<p>（1）vim /etc/profile</p>

<p>末尾添加：</p>

<p>export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.151-1.b12.el7_4.x86_64/jre<br>
export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib<br>
export PATH=$PATH:$JAVA_HOME/bin<br>
（2）执行source /etc/profile生效</p>

<p>（3）查看</p>

<p>$PATH</p>

<p> </p>

<p>3.集群搭建</p>

<p>（1）配置文件路径：</p>

<p>配置集群的配置文件目录：cd $HADOOP_HOME/etc/hadoop/conf<br>
（2）增加slave节点</p>

<p>[root@master1 conf]# vim /etc/hadoop/conf/slaves</p>

<p>添加</p>

<p>master1<br>
master2<br>
slave1<br>
slave2<br>
（3）配置集群core-site.xml</p>

<p>[root@master2 ~]# vim /etc/hadoop/conf/core-site.xml<br>
添加：</p>

<p>&lt;property&gt;<br>
                &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;<br>
                &lt;value&gt;/usr/hdp/tmp&lt;/value&gt;<br>
        &lt;/property&gt;<br>
        &lt;property&gt;<br>
                &lt;name&gt;fs.defaultFS&lt;/name&gt;<br>
                &lt;value&gt;hdfs://master1:8020&lt;/value&gt;<br>
        &lt;/property&gt;<br>
（4）配置集群hdfs-site.xml</p>

<p>[root@master1 conf]# vim hdfs-site.xml</p>

<p>添加：</p>

<p>&lt;!--<br>
       Licensed under the Apache License, Version 2.0 (the "License");<br>
  you may not use this file except in compliance with the License.<br>
  You may obtain a copy of the License at</p>

<p>    http://www.apache.org/licenses/LICENSE-2.0</p>

<p>  Unless required by applicable law or agreed to in writing, software<br>
  distributed under the License is distributed on an "AS IS" BASIS,<br>
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br>
  See the License for the specific language governing permissions and<br>
  limitations under the License. See accompanying LICENSE file.<br>
--&gt;</p>

<p>&lt;!-- Put site-specific property overrides in this file. --&gt;</p>

<p>&lt;configuration&gt;<br>
        &lt;property&gt;<br>
                &lt;name&gt;dfs.replication&lt;/name&gt;<br>
                &lt;value&gt;4&lt;/value&gt;(注意：不大于datanode节点的数量)<br>
        &lt;/property&gt;<br>
        &lt;property&gt;<br>
                &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;<br>
                &lt;value&gt;/hadoop/hdfs/name&lt;/value&gt;<br>
        &lt;/property&gt;<br>
        &lt;property&gt;<br>
                &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;<br>
                &lt;value&gt;/hadoop/hdfs/data&lt;/value&gt;<br>
        &lt;/property&gt;<br>
&lt;/configuration&gt;</p>

<p>（5）创建hdfs需要用的文件目录</p>

<p>[root@master1 ~]# mkdir /usr/hdp/tmp -p<br>
[root@master1 ~]# mkdir /hadoop/hdfs/{data,name} -p<br>
[root@master1 ~]# chown -R hdfs:hadoop /hadoop<br>
[root@master1 ~]# chown -R hdfs:hadoop /usr/hdp/tmp<br>
 </p>

<p>（6）初始化hdfs文件系统</p>

<p>在master1上操作：</p>

<p>[root@master1 ~]# sudo -E -u hdfs hdfs namenode -format<br>
 </p>

<p>（7）启动hdfs文件系统</p>

<p>启动master1节点上的服务：</p>

<p>[root@master1 ~]# systemctl start hadoop-hdfs-namenode<br>
[root@master1 ~]# systemctl start hadoop-hdfs-datanode</p>

<p>启动master2节点上的服务：</p>

<p>[root@master2 ~]# systemctl start hadoop-hdfs-datanode<br>
[root@master2 ~]# systemctl start hadoop-hdfs-secondarynamenode</p>

<p>启动slave1、slave2节点上的服务：</p>

<p>[root@slave1 ~]# systemctl start hadoop-hdfs-datanode<br>
[root@slave2 ~]# systemctl start hadoop-hdfs-datanode</p>

<p>（8）使用jps命令查看</p>

<p>4.网址查看</p>

<p>192.168.75.137:50070</p>

<p><img alt="" class="has" src="https://img-blog.csdn.net/20180717141619522?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VucWlhbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>

<p>二、大数据开发环境</p>

<p>1.准备程序运行目录</p>

<p>[root@master1 ~]# su - hdfs</p>

<p>-bash-4.2$ hadoop fs -mkdir /tmp</p>

<p>-bash-4.2$ hadoop fs -chmod -R 1777 /tmp</p>

<p>-bash-4.2$ hadoop fs -mkdir -p /var/log/hadoop-yarn</p>

<p>-bash-4.2$ hadoop fs -chown yarn:mapred /var/log/hadoop-yarn</p>

<p>-bash-4.2$ hadoop fs -mkdir /user</p>

<p>-bash-4.2$ hadoop fs -mkdir /user/hadoop</p>

<p>-bash-4.2$ hadoop fs -mkdir /user/history</p>

<p>-bash-4.2$ hadoop fs -chmod 1777 /user/history</p>

<p>-bash-4.2$ hadoop fs -chown mapred:hadoop /user/history<br>
 </p>

<p>2.配置yarn-site.xml</p>

<p>[root@master1 conf]# vim yarn-site.xml<br>
添加：</p>

<p>&lt;configuration&gt;<br>
        &lt;property&gt;<br>
                &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;<br>
                &lt;value&gt;master2&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>        &lt;property&gt;<br>
                &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;<br>
                &lt;value&gt;mapreduce_shuffle&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>        &lt;property&gt;<br>
                &lt;name&gt;yarn.nodemanager.local-dirs&lt;/name&gt;<br>
                &lt;value&gt;file:///hadoop/yarn/local&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>        &lt;property&gt;<br>
                &lt;name&gt;yarn.nodemanager.log-dirs&lt;/name&gt;<br>
                &lt;value&gt;/var/log/hadoop-yarn/containers&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>        &lt;property&gt;<br>
                &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;<br>
                &lt;value&gt;/var/log/hadoop-yarn/apps&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>        &lt;property&gt;<br>
                &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;<br>
                &lt;value&gt;true&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p><br>
        &lt;property&gt;<br>
                &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;<br>
                &lt;value&gt;511&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>        &lt;property&gt;<br>
                &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;<br>
                &lt;value&gt;2049&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>        &lt;property&gt;<br>
                &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;<br>
                &lt;value&gt;4&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>        &lt;property&gt;<br>
                &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;<br>
                &lt;value&gt;false&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>       &lt;property&gt;<br>
                &lt;name&gt;yarn.application.classpath&lt;/name&gt;<br>
                &lt;value&gt;$HADOOP_CONF_DIR,<br>
                        /usr/hdp/2.6.3.0-235/hadoop/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop/lib/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop-hdfs/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop-hdfs/lib/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop-yarn/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop-yarn/lib/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop-mapreduce/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop-mapreduce/lib/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop-httpfs/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop-httpfs/lib/*<br>
                &lt;/value&gt;<br>
        &lt;/property&gt;<br>
&lt;/configuration&gt;<br>
 </p>

<p> </p>

<p>3.配置mapred-site.xml</p>

<p>[root@master1 conf]# vim mapred-site.xml</p>

<p>添加：</p>

<p>&lt;configuration&gt;<br>
        &lt;property&gt;<br>
                &lt;name&gt;mapreduce.framework.name&lt;/name&gt;<br>
                &lt;value&gt;yarn&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>        &lt;property&gt;<br>
                &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;<br>
                &lt;value&gt;slave1:10020&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>        &lt;property&gt;<br>
                &lt;name&gt;mapreduce.jobhistory.webapps.address&lt;/name&gt;<br>
                &lt;value&gt;slave1:19888&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>        &lt;property&gt;<br>
                &lt;name&gt;yarn.app.mapreduce.am.staging-dir&lt;/name&gt;<br>
                &lt;value&gt;/user&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>        &lt;property&gt;<br>
                &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;<br>
                &lt;value&gt;<br>
                        /etc/hadoop/conf/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop-hdfs/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop-yarn/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop-mapreduce/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop/lib/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop-hdfs/lib/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop-yarn/lib/*,<br>
                        /usr/hdp/2.6.3.0-235/hadoop-mapreduce/lib/*<br>
                &lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>       &lt;property&gt;<br>
                &lt;name&gt;mapreduce.map.java.opts&lt;/name&gt;<br>
                &lt;value&gt;-Xmx1024M&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>        &lt;property&gt;<br>
                &lt;name&gt;mapreduce.map.memory.mb&lt;/name&gt;<br>
                &lt;value&gt;31&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>        &lt;property&gt;<br>
                &lt;name&gt;mapreduce.reduce.java.opts&lt;/name&gt;<br>
                &lt;value&gt;-Xmx1024M&lt;/value&gt;<br>
        &lt;/property&gt;</p>

<p>        &lt;property&gt;<br>
                &lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt;<br>
                &lt;value&gt;63&lt;/value&gt;<br>
        &lt;/property&gt;<br>
 </p>

<p>&lt;/configuration&gt;<br>
 </p>

<p>4.配置yarn的本地目录</p>

<p>[root@master1 ~]# touch /etc/hadoop/conf/yarn-env.sh<br>
[root@master1 ~]# mkdir -p /hadoop/yarn/local<br>
[root@master1 ~]# chown yarn:yarn -R /hadoop/yarn/local<br>
 </p>

<p>5.启动服务</p>

<p>在master2上开启resourcemanager：</p>

<p>[root@master2 ~]# systemctl start hadoop-yarn-resourcemanager</p>

<p>访问web后台master2:8088</p>

<p>在slave1、slave2上开启historyserver</p>

<p>[root@slave1 ~]# systemctl start hadoop-mapreduce-historyserver</p>

<p>[root@slave2 ~]# systemctl start hadoop-mapreduce-historyserver</p>

<p>在所有启动datanode的节点上开nodemanager</p>

<p>[root@slave2 ~]# systemctl start hadoop-yarn-nodemanager<br>
 </p>

<p>6.验证</p>

<p>master2:8088</p>

<p><img alt="" class="has" src="https://img-blog.csdn.net/20180717230311915?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VucWlhbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>

<p>slave1:19888</p>

<p><img alt="" class="has" src="https://img-blog.csdn.net/20180718102658255?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VucWlhbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>

<p>vim 的简单快捷键<br>
在命令模式下，<br>
dd 删除一行<br>
yy 复制一行 <br>
y3 复制此行下面的三行（共四行）<br>
3yy 复制包括此行的三行（共三行）<br>
u 恢复上一步（后退）<br>
r 替换<br>
x 删除</p>

<p>p 粘贴</p>

<p> </p>

<p> </p>

<p>#2018-07-16#<br>
ip:192.168.75.213<br>
 cd $HADOOP_HOME/etc/hadoop<br>
systemctl start hadoop-hdfs-namenode</p>

<p>cd /var/log/<br>
more hadoop-hdfs-namenode-wugenqiang.bigdata.log </p>

<p>[root@wugenqiang /]# mkdir -p /hdfs/{name,data}<br>
[root@wugenqiang /]# chown -R hdfs:hadoop /hdfs</p>

<p>使用“hdfs dfsadmin -report”命令查看节点的报告信息</p>

<p> </p>

<p>#2018-07-13#</p>

<p>db<br>
use wgq<br>
show tables</p>

<p>gte大于等于<br>
lte小于等于</p>

<p><br>
创建root用户</p>

<p>db.createUser({user:"root",pwd:"123456",roles:["root"]})</p>

<p>mongod -shutdown -dbpath=/usr/local/mongodb/data<br>
mongod --auth --dbpath=/usr/local/mongodb/data --journal </p>

<p>mongo</p>

<p>&gt; use admin<br>
switched to db admin<br>
&gt; db.auth("root","123456")</p>

<p>#2018-07-12#</p>

<p>10.10.12.213 wugenqiang.bigdata weigion<br>
192.168.35.241 yuc.hanwate yuc<br>
192.168.35.226 lxj.jit lxj</p>

<p>/usr/local/mongodb/bin/mongod --dbpath=/usr/local/mongodb/data --logpath=/usr/local/mongodb/mongodb.log --logappend  --auth  --port=27017 --fork</p>

<p>设置监听<br>
mongod --dbpath=/usr/local/mongodb/data --journal</p>

<p>查看开启服务<br>
netstat -ntlp</p>

<p>db.students.find().pretty()<br>
 </p>

<p>#2018-07-11#</p>

<p>别名：alias <br>
eg:alias tom='ls -la'<br>
unalias 删除别名<br>
unalias tom<br>
vi /etc/bashrc<br>
export PATH="/home/weigion/study":$PATH</p>

<p>source /etc/bashrc</p>

<p>env |grrep PATH<br>
vi .bashrc<br>
44</p>

<p><br>
du -sh *<br>
按文件大小查看文件<br>
du -sh *|grep k |sort</p>

<p>reboot重启</p>

<p>分磁盘查看</p>

<p>fdisk -l<br>
ls /dev/sda</p>

<p><br>
fdisk /etc/sdb<br>
分区  n<br>
打印  p<br>
删除  d<br>
退出  q<br>
写入  w<br>
修改类型 t<br>
查看ls /dev/sdb*<br>
mkfs<br>
格式化<br>
mkfs.ext4 /dev/sdb1</p>

<p>挂载磁盘<br>
建立挂载点<br>
mkdir /mnt/sdb1<br>
mount /dev/sdb1 /mnt/sdb1<br>
df |grep sdb</p>

<p>cd /mnt/sdb1</p>

<p>查看挂载点df -h</p>

<p>umount /home </p>

<p>文件更改挂载点<br>
vim /etc/fstab</p>

<p>软链接<br>
ln -s hello.sh hello</p>

<p><br>
ps ax</p>

<p>ps axu<br>
top -d<br>
uptime<br>
free -h</p>

<p>vim /etc/sysconfig/network-scripts/ifcfg-ens33</p>

<p>重启网络systemctl restart network</p>

<p><br>
ip:192.168.52.174 </p>

<p>ip:10.10.12.213<br>
老师 10.10.10.217<br>
192.168.35.241</p>

<p>ping dev.mysql.com</p>

<p>ps<br>
fg<br>
fg 命令使用最近在后台被暂挂的作业，或者作为后台作业运行<br>
 </p>

<p>#2018-07-10#<br>
1. dev中设备<br>
创建文件夹 mkdir<br>
删除 rmdir 或 rm<br>
更名/移动 mv<br>
设置行号:set number</p>

<p>查找文件 find /usr/sbin -name ssh*<br>
   </p>

<p>locate sshd</p>

<p>使用命令iconv对文件内容编码进行转换。<br>
例如我有一个文件"pos.txt"在windows下打开正常，<br>
而在linux下打开则会乱码，办法为在终端输入：<br>
iconv -f gbk -tutf8 pos.txt &gt; pos.txt.utf8</p>

<p>tcpdump抓取包</p>

<p>scp拷贝<br>
scp a weigion@wugenqiang.bigdata:~/a2<br>
chmod 改权限<br>
rwx：4 2 1 可读可写可执行</p>

<p>/etc/group</p>

<p> </p>            </div>
                </div>