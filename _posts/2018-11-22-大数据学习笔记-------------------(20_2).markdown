---
layout:     post
title:      大数据学习笔记-------------------(20_2)
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/henni_719/article/details/52873779				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<h2><strong>Step_4:HIVE安装</strong></h2>
<h3><strong>Step_4.1:下载Hive</strong></h3>
<p><span>通过：</span><span><a>http://apache.petsads.us/hive/hive-2.1.0/</a></span><span>，链接下载。记录下载的路径</span><strong><span>/</span><span>下载</span></strong><span>，进入到下载路径下，下载成功会发现：</span><span>apache-hive-2.1.0-bin.tar.gz</span><strong></strong></p>
<p><span><img src="https://img-blog.csdn.net/20161020161448572?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p>
<p align="center"><strong></strong></p>
<h3><strong>Step_4.2：解压并验证Hive压缩问价</strong></h3>
<p><span>进入到</span><span>hive</span><span>所在路径，执行</span><strong>：<span>tarzxvf apache-hive-2.1.0-bin.tar.gz</span></strong><span>，然后执行</span><span>:ls</span><span>，查看问价是否解压成功：</span></p>
<p><span> <img src="https://img-blog.csdn.net/20161020161504822?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="">  </span></p>
<h3><strong>Step_4.3：把文件复制到/usr/local/hive路径下</strong></h3>
<p><span>在复制文件时由于权限不够，需要超级管理员权限。然后执行复制命令，把文件复制过去：</span></p>
<pre><code class="language-plain">sudo mv apache-hive-0.14.0-bin/usr/local/hive </code></pre><br><span> <img src="https://img-blog.csdn.net/20161020161538011?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></span>
<p></p>
<p align="center"><strong></strong></p>
<h3><strong>Step_4.4：设置Hive环境变量</strong></h3>
<p align="left">在~/.bashrc文件设置Hive环境变量：</p>
<p align="left"></p>
<pre><code class="language-plain">export HIVE_HOME=/usr/local/hive
export PATH=$PATH:$HIVE_HOME/bin
export CLASSPATH=$CLASSPATH:/usr/local/hadoop/lib/*:.
export CLASSPATH=$CLASSPATH:/usr/local/hive/lib/*:.&lt;span style="font-family: Arial, Helvetica, sans-serif; background-color: rgb(255, 255, 255);"&gt;        &lt;/span&gt;</code></pre>
<p></p>
<p align="left">然后执行:<strong>source ~/.bashrc</strong></p>
<p align="left"><strong> <img src="https://img-blog.csdn.net/20161020161650265?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="">       </strong></p>
<h3><strong>Step_5：配置Hive</strong></h3>
<p>为Hadoop配置Hive，需要编辑hive-env.sh文件，替换$HIVE_HOME/conf路径。执行命令重定向到Hiveconfig文件夹，并复制模板文件：</p>
<p> <img src="https://img-blog.csdn.net/20161020161719216?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="">   </p>
<p><span>编辑</span><span>hive-env.sh</span><span>文件，并在文件中追加命令：</span></p>
<pre><code class="language-plain">export  HADOOP_HOME=/usr/local/hadoop</code></pre>
<p></p>
<p><span>Hive</span><span>安装成功后，需要一个外部数据库服务来配置</span><span>Metastore</span><span>。外部服务选择</span><span>Apache Derby</span><span>。</span></p>
<h2><strong>Step_6:下载并安装Apache Derby</strong></h2>
<h3><strong>Step_6.1：下载Apache Derby</strong></h3>
<p><strong> </strong>使用命令下载Apache Derby：</p>
<pre><code class="language-plain">  wget http://archive.apache.org/dist/db/derby/db-derby-10.4.2.0/db-derby-10.4.2.0-bin.tar.gz</code></pre><img src="https://img-blog.csdn.net/20161020161902062?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br><p></p>
<p align="center"><strong></strong></p>
<p><strong> </strong>下载完成，执行:<strong>ls</strong>，查看下载文件：</p>
<p>   <img src="https://img-blog.csdn.net/20161020161917234?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
<h3><strong>Step_6.2：解压Derby文件并验证解压</strong></h3>
<p><span>进入到下载路径下，执行命令：</span><strong>tar zxvf  db-derby-10.4.2.0-bin.tar.gz</strong>，解压文件，然后执行：<strong>ls</strong>，查看解压是否成功：</p>
<p>  <img src="https://img-blog.csdn.net/20161020161940016?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="">  </p>
<h3><strong>Step_6.3：把文件复制到/usr/local/derby路径下</strong></h3>
<p><span>在复制文件时由于权限不够，需要超级管理员权限。然后执行复制命令，把文件复制过去：</span><strong><span>sudo mv db-derby-10.4.2.0-bin/usr/local/derby</span><span> </span></strong></p>
<p><span> <img src="https://img-blog.csdn.net/20161020161959032?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></span></p>
<h3><strong>Step_6.4：设置Derby的环境 </strong></h3>
<p align="left">在~/.bashrc文件设置Derby环境变量：</p>
<p align="left"> </p>
<pre><code class="language-plain">export DERBY_HOME=/usr/local/derby
export PATH=$PATH:$DERBY_HOME/bin
export CLASSPATH=$CLASSPATH:$DERBY_HOME/lib/derby.jar:$DERBY_HOME/lib/derbytools.jar</code></pre>   
<p></p>
<p align="left">然后执行:<strong>source ~/.bashrc</strong></p>
<p align="left"><strong>  <img src="https://img-blog.csdn.net/20161020162053469?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="">      </strong></p>
<h3><strong>Step_6.5:创建存储Metastore的路径</strong></h3>
<p><span>在</span><span>$DERBY_HOME</span><span>路径下创建一个命名为</span><span>data</span><span>的文件夹来存储</span><span>Metastore</span><span>数据，执行命令：</span><strong><span>mkdir
 $DERBY_HOME/data </span></strong></p>
<p><strong><span>  <img src="https://img-blog.csdn.net/20161020162120596?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="">      </span></strong></p>
<p><span>到现在为止，</span><span>Derby</span><span>的安装和系统设置完成！</span></p>
<h2><strong>Step_7:配置Hive的Metastore</strong></h2>
<p><strong> </strong><span>配置</span><span>Metastore</span><span>意味着指定</span><span>Hive</span><span>存储数据库的位置。通过编辑</span><span>$HIVE_HOME/conf</span><span>中的</span><span>hive-site.xml</span><span>文件。首先，进入到路径下，执行：</span><strong><span>sudo </span>cp
 hive-default.xml.template hive-site.xml</strong></p>
<p><strong><img src="https://img-blog.csdn.net/20161020162155392?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="">        </strong></p>
<p><span> </span><span>打开</span><span>hive-site.xml</span><span>文件，在</span><span>&lt;configuration&gt;</span><span>与</span><span>
 &lt;/configuration&gt;</span><span>之间添加如下属性：</span></p>
<p><span></span></p>
<pre><code class="language-plain">&lt;property&gt;
&lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
&lt;value&gt;jdbc:derby://localhost:1527/metastore_db;create=true &lt;/value&gt;
&lt;description&gt;JDBC connect string for a JDBC metastore &lt;/description&gt;
&lt;/property&gt;</code></pre>    
<p></p>
<p><strong>创建一个名为:jpox.properites的文件，并把以下内容添加进去：</strong></p>
<p><strong>   </strong></p>
<pre><code class="language-plain">javax.jdo.PersistenceManagerFactoryClass = org.jpox.PersistenceManagerFactoryImpl
org.jpox.autoCreateSchema = false
org.jpox.validateTables = false
org.jpox.validateColumns = false
org.jpox.validateConstraints = false
org.jpox.storeManagerType = rdbms
org.jpox.autoCreateSchema = true
org.jpox.autoStartMechanismMode = checked
org.jpox.transactionIsolation = read_committed
javax.jdo.option.DetachAllOnCommit = true
javax.jdo.option.NontransactionalRead = true
javax.jdo.option.ConnectionDriverName = org.apache.derby.jdbc.ClientDriver
javax.jdo.option.ConnectionURL = jdbc:derby://hadoop1:1527/metastore_db;create = true
javax.jdo.option.ConnectionUserName = APP
javax.jdo.option.ConnectionPassword = mine</code></pre><br>
    
<p></p>
<h2><strong>Step_8:验证Hive安装</strong></h2>
<p>在运行Hive之前，需要创建一个<strong>/tmp</strong>文件夹，同时在HDFS中分离Hive文件。这里，使用<strong>/user/hive/warehouse</strong>文件夹。需要给新建的文件夹赋予写的权限：<strong>chmod g+w </strong></p>
<p>在验证Hive之前，需要设置在HDFS中的文件。执行命令如下：</p>
<pre><code class="language-plain">$ $HADOOP_HOME/bin/hadoop fs -mkdir /tmp
$ $HADOOP_HOME/bin/hadoop fs -mkdir /user/hive/warehouse 
$ $HADOOP_HOME/bin/hadoop fs -chmod g+w /tmp 
$ $HADOOP_HOME/bin/hadoop fs -chmod g+w /user/hive/warehouse</code></pre>
<p></p>
<p>执行下面命令，验证Hive安装：</p>
<p></p>
<pre><code class="language-plain">cd $HIVE_HOME/bin
./hive</code></pre><br><strong> </strong>安装成功，响应显示如下：
<p></p>
<p><img src="https://img-blog.csdn.net/20161020162554587?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></p>
<p>         </p>
<p>         </p>
            </div>
                </div>