---
layout:     post
title:      搭建spark完全分布式
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/ting_163/article/details/80473833				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h4 id="安装spark">安装spark</h4>

<p>1.列表内容 <br>
 spark下载：<a href="http://spark.apache.org/downloads.html" rel="nofollow">http://spark.apache.org/downloads.html</a> <br>
 2.将spark进行解压：</p>



<pre class="prettyprint"><code class=" hljs lasso"> s100:/soft $<span class="hljs-subst">&gt;</span>tar <span class="hljs-attribute">-zxvf</span> spark<span class="hljs-subst">-</span><span class="hljs-number">2.3</span><span class="hljs-number">.0</span><span class="hljs-attribute">-bin</span><span class="hljs-attribute">-hadoop2</span><span class="hljs-number">.7</span><span class="hljs-built_in">.</span>tgz
 s100:/soft $<span class="hljs-subst">&gt;</span> ln <span class="hljs-attribute">-s</span> spark<span class="hljs-subst">-</span><span class="hljs-number">2.3</span><span class="hljs-number">.0</span><span class="hljs-attribute">-bin</span><span class="hljs-attribute">-hadoop2</span><span class="hljs-number">.7</span> spark</code></pre>

<p>3.配置环境变量</p>

<pre class="prettyprint"><code class=" hljs mel"><span class="hljs-variable">$&gt;</span> sudo nano /etc/environment

PATH = <span class="hljs-string">':/soft/spark/bin:/soft/spark/sbin'</span>
SPARK_HOME=/<span class="hljs-keyword">soft</span>/spark
使配置生效： <span class="hljs-variable">$&gt;</span> <span class="hljs-keyword">source</span> /etc/environment
</code></pre>

<p>4.配置/spark/conf</p>

<pre class="prettyprint"><code class=" hljs mel"> s100:/<span class="hljs-keyword">soft</span>/spark/conf <span class="hljs-variable">$&gt;</span> cp slaves.template slaves
 s100:/<span class="hljs-keyword">soft</span>/spark/conf <span class="hljs-variable">$&gt;</span> sudo nano slaves
在slaves文件下填上slave主机名：
s101
s102
s103</code></pre>

<p>5.配置spark/sbin</p>



<pre class="prettyprint"><code class=" hljs lasso"> s100:/soft/spark/sbin $<span class="hljs-subst">&gt;</span>mv start<span class="hljs-attribute">-all</span><span class="hljs-built_in">.</span>sh start<span class="hljs-attribute">-spark</span><span class="hljs-attribute">-all</span><span class="hljs-built_in">.</span>sh
 s100:/soft/spark/sbin $<span class="hljs-subst">&gt;</span>mv stop<span class="hljs-attribute">-all</span><span class="hljs-built_in">.</span>sh stop<span class="hljs-attribute">-spark</span><span class="hljs-attribute">-all</span><span class="hljs-built_in">.</span>sh
原因：
如果集群中也配置HADOOP_HOME，那么在HADOOP_HOME/sbin目录下也有start<span class="hljs-attribute">-all</span><span class="hljs-built_in">.</span>sh和stop<span class="hljs-attribute">-all</span><span class="hljs-built_in">.</span>sh这两个文件，当你执行这两个文件，系统不知道是操作hadoop集群还是spark集群。修改后就不会冲突了，当然，不修改的话，你需要进入它们的sbin目录下执行这些文件，这肯定就不会发生冲突了。</code></pre>

<p>6.配置集群</p>



<pre class="prettyprint"><code class=" hljs ">将以上配置分发到其他节点：s101,s102,s103</code></pre>

<p>7.启动spark集群</p>



<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-label">s100:</span>$&gt; start-spark-all<span class="hljs-preprocessor">.sh</span>
<span class="hljs-label">s100:</span>$&gt; jps
<span class="hljs-number">4064</span> Jps
<span class="hljs-number">3846</span> Master</code></pre>

<p>8.webUI查看集群启动情况 <br>
<img title="" alt="这里写图片描述" src="https://img-blog.csdn.net/20180527225007576?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RpbmdfMTYz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>