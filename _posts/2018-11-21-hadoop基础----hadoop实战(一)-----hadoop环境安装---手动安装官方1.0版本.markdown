---
layout:     post
title:      hadoop基础----hadoop实战(一)-----hadoop环境安装---手动安装官方1.0版本
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/q383965374/article/details/51597978				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p><br></p><p><br></p><h1><span style="color:#ff0000;">准备工作</span></h1><p><span style="font-size:18px;">前面我们已经了解了有关于hadoop的相关原理</span></p><p></p><h1 style="list-style-type:none;list-style-image:none;font-size:14px;overflow:hidden;color:rgb(51,51,51);line-height:24px;background-image:none;background-attachment:scroll;background-position:0% 0%;background-repeat:repeat;"><span style="color:#2f649a;"><a href="http://blog.csdn.net/zzq900503/article/details/43449685" rel="nofollow">hadoop基础----hadoop理论(一)----Hadoop简介</a></span></h1><div><h1 style="list-style-type:none;list-style-image:none;font-size:14px;overflow:hidden;color:rgb(51,51,51);line-height:24px;background-image:none;background-attachment:scroll;background-position:0% 0%;background-repeat:repeat;"><span style="color:#2f649a;"><a href="http://blog.csdn.net/zzq900503/article/details/43486055" rel="nofollow">hadoop基础----hadoop理论(二)-----hadoop学习路线(持续更新)</a></span></h1><h1 style="list-style-type:none;list-style-image:none;font-size:14px;overflow:hidden;color:rgb(51,51,51);line-height:24px;background-image:none;background-attachment:scroll;background-position:0% 0%;background-repeat:repeat;"><span style="color:#2f649a;"><a href="http://blog.csdn.net/zzq900503/article/details/50782389" rel="nofollow">hadoop基础----hadoop理论(三)-----hadoop分布式文件系统HDFS详解</a></span></h1><div><h1 style="list-style-type:none;list-style-image:none;font-size:14px;overflow:hidden;color:rgb(51,51,51);line-height:24px;background-image:none;background-attachment:scroll;background-position:0% 0%;background-repeat:repeat;"><span style="color:#2f649a;"><a href="http://blog.csdn.net/zzq900503/article/details/50827268" rel="nofollow">hadoop基础----hadoop理论(四)-----hadoop分布式并行计算模型MapReduce详解</a></span></h1><br></div><br></div><br><p></p><p><span style="font-size:18px;">本章开始进入实际操作阶段</span></p><p><span style="font-size:18px;">因为在学习阶段一般我们没有那么多实体机来进行操作。也就是不能实现真正的分布式。</span></p><p><span style="font-size:18px;">但是我们可以通过虚拟机来模拟分布式。</span></p><p><span style="font-size:18px;">所以在安装hadoop之前，我们需要先准备好3台虚拟机。</span></p><p><span style="font-size:18px;">这里我们使用的VMware  Workstation</span></p><p><span style="font-size:18px;">新建虚拟机的步骤如下:</span></p><p><span style="font-family:'Microsoft YaHei';"><span style="font-size:20px;line-height:30px;"><a href="http://blog.csdn.net/zzq900503/article/details/43565419" rel="nofollow">hadoop基础------虚拟机(二)---虚拟机安装以及安装linux系统</a></span></span><br></p><p><span style="font-size:18px;">根据上面的文章，我们就已经有了3台CentOS 6.4系统的虚拟机。</span></p><p><span style="font-size:18px;">为了方便我们操作命令，我们需要让虚拟机与本机共享剪切板也就是我在本机剪切的命令能够直接粘贴到虚拟机里使用，相关设置参考:</span></p><p><span style="font-size:18px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:20px;line-height:30px;"><a href="http://blog.csdn.net/zzq900503/article/details/12152859" rel="nofollow">hadoop基础-------虚拟机(三)-----VMware虚拟机下linux系统的与windows主机实现复制粘贴</a></span></span><br></span></p><p><span style="font-size:18px;">然后我们需要把它们之间的网络调试一下，目的是 让3台虚拟机都能上外网而且 与 本机 能够相互通信。</span></p><p><span style="font-size:18px;">因为我们是克隆的机子 所以虚拟机的mac是有冲突的 详细的解决注意看 linux基础十中的 可能遇到的问题。</span></p><p><span style="font-size:18px;">虚拟机网络模式了解(熟悉的人可直接配置成桥接，并设置ip即可，不熟悉的需要看详细步骤):</span></p><p><span style="font-size:18px;"><a href="http://blog.csdn.net/zzq900503/article/details/12152859" rel="nofollow">hadoop基础-------虚拟机(五)-----虚拟机linux系统网络配置的三种模式</a></span><br></p><p><span style="font-size:18px;">详细网络配置步骤在:</span></p><p><span style="font-size:18px;"><a href="http://blog.csdn.net/zzq900503/article/details/50158495" rel="nofollow">linux基础(十)----linux网络配置详细步骤---桥接模式和两台机子的远程通信</a></span></p><p><br></p><p><br></p><p><span style="font-size:18px;">网络调好之后我们就可以就可以开始安装 hadoop环境了。</span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;">但是hadoop是开源的，所以发展到现在，已经有了很多分支版本。</span></p><p><span style="font-size:18px;">由于Hadoop版本混乱多变，因此，Hadoop的版本选择问题一直令很多初级用户苦恼。</span></p><p><span style="font-size:18px;">所以我们有必要对如果选取版本和了解版本信息的方法进行熟悉：</span></p><p><span style="font-size:18px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:20px;line-height:30px;"><a href="http://blog.csdn.net/zzq900503/article/details/51614159" rel="nofollow">hadoop基础----hadoop实战(零)-----hadoop的平台版本选择</a></span></span><br></span></p><p><img src="https://img-blog.csdn.net/20160613142636310?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></p><p><br></p><p><br></p><p><span style="font-size:18px;">我们在生产环境中 建议使用第三方发行版，但是这里为了学习hadoop的安装原理等 我们这一次先手动安装hadoop1.0版，等学习到2.0版本的时候 再使用 第三方发行版进行安装。</span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><span style="font-size:18px;">根据上表 我们这里 就要进行 1.2.1版本的 Hadoop安装。</span><br></span></p><p><span style="font-size:18px;">官网安装配置文档</span></p><p><span style="font-size:18px;"><a href="http://hadoop.apache.org/docs/r1.2.1/cluster_setup.html" rel="nofollow">http://hadoop.apache.org/docs/r1.2.1/cluster_setup.html</a><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><h1><span style="color:#ff0000;">熟悉虚拟机环境</span></h1><h2><span style="color:#cc33cc;">查看到系统版本</span></h2><p><span style="font-size:18px;">使用命令</span></p><p><span style="font-size:18px;"></span></p><pre><code class="language-plain">cat /etc/redhat-release</code></pre><p></p><p><span style="font-size:18px;"><br></span></p><span style="font-size:18px;">查看到系统版本是CentOS release 6.4 (Final)</span><br><br><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><h2><span style="color:#cc33cc;">查看主机名</span></h2><p><span style="font-size:18px;">使用命令</span></p><p></p><pre><code class="language-plain">hostname </code></pre><p></p><p><span style="font-size:18px;">查看主机名</span></p><p><span style="font-size:18px;">一般没修改过的话 都是localhost.localdomain</span></p><p><span style="font-size:18px;">我们需要修改主机名方便区分和识别。</span></p><p><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><h2><span style="color:#cc33cc;">设置主机名</span></h2><h3><span style="color:#3333ff;">临时设置</span></h3><p><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">使用hostname命令设置主机名。格式为：hostname 主机名，如下。 </span><br style="color:rgb(51,51,51);font-family:Arial;line-height:26px;"><span style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">[root@joe /]# hostname hadoop1</span><br style="color:rgb(51,51,51);font-family:Arial;line-height:26px;"><span style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">该设置为临时生效。重新启动系统后，设置失效。 </span><br></span></span></p><p><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><h3><span style="color:#3333ff;">永久设置</span></h3><p><span style="font-size:18px;">编辑/etc/sysconfig/network文件中的HOSTNAME字段就可以修改主机名。如下所示： </span></p><p><span style="font-size:18px;"></span></p><pre><code class="language-plain">vim /etc/sysconfig/network </code></pre>[root@<span style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">joe</span><span style="font-family:Arial;color:#333333;"><span style="line-height:26px;"> /]# vim /etc/sysconfig/network                                       </span></span><br style="color:rgb(51,51,51);font-family:Arial;line-height:26px;"><span style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">NETWORKING=yes                                                                    </span><br style="color:rgb(51,51,51);font-family:Arial;line-height:26px;"><span style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">NETWORKING_IPV6=yes                                                               </span><br style="color:rgb(51,51,51);font-family:Arial;line-height:26px;"><span style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">HOSTNAME=hadoop1         </span><p></p><p><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">                                                     </span><br style="color:rgb(51,51,51);font-family:Arial;line-height:26px;"><span style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">HOSTNAME=<span style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">hadoop1 </span>表示主机设置为<span style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">hadoop1 </span>. </span><br style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">注意：修改主机名后，需要重启系统后永久生效。 <br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><h2><span style="color:#cc33cc;">查看ip</span></h2><p><span style="font-size:18px;">使用命令<span style="font-size:18px;">查看ip</span></span></p><p></p><pre><code class="language-plain">ifconfig</code></pre><br><br><p></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><h1><span style="color:#ff0000;">架构和角色分配</span></h1><p><span style="font-size:18px;">我们先整理出三台虚拟机的ip和主机名</span></p><p><span style="font-size:18px;"></span></p><p><span style="font-size:18px;">192.168.30.180      hadoop0    <br></span></p><p><span style="font-size:18px;">192.168.30.189      hadoop1    <br></span></p><p><span style="font-size:18px;">192.168.30.186      hadoop2    </span></p><p><span style="font-size:18px;"> 角色如下</span></p><p><span style="font-size:18px;">192.168.30.180      hadoop0    作为master担任NameNode 和 JobTracker<br></span></p><p><span style="font-size:18px;">192.168.30.189      hadoop1    作为slave担任DataNode  和 TaskTracker<br></span></p><p><span style="font-size:18px;">192.168.30.186      hadoop2    作为slave担任DataNode  和 TaskTracker</span><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;font-size:14px;line-height:21px;"></span><br></p><p><br></p><p><span style="font-size:18px;">其中NameNode/DataNode工作在HDFS层，JobTracker/TaskTracker工作在MapReduce层。</span></p><p><span style="font-size:18px;">设备列表中hadoop0是master，担任NameNode 和<span style="font-size:18px;">JobTracker</span>，<span style="font-size:18px;">hadoop1 ，<span style="font-size:18px;">hadoop2</span></span>为slave，担任<span style="font-size:18px;">DataNode</span>和<span style="font-size:18px;">TaskTracker</span>。secondary namenode在hadoop 1.03中被废弃，用checkpoint node或backupnode来代替。这里暂没有配checkpoint node或backupnode。</span><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><h1><span style="color:#ff0000;">用户权限配置</span></h1><p><span style="font-size:18px;"><span style="color:rgb(68,68,68);font-family:Tahoma, 'Microsoft Yahei', Simsun;line-height:21px;">在各机器建立同名用户joe，可选自己喜欢的名称，用于管理hadoop。</span><br></span></p><p><span style="font-size:18px;">如果当前是超级用户root</span></p><p><span style="font-size:18px;">新建如下：</span></p><p></p><pre><code class="language-plain">adduser joe</code></pre><span style="font-size:18px;">设置密码</span><p></p><p></p><pre><code class="language-plain">passwd joe</code></pre><br><p></p><p><span style="font-size:18px;">关于用户设置的详情可查看</span></p><p><a href="http://blog.csdn.net/zzq900503/article/details/51773810" rel="nofollow"> </a></p><h1 style="display:inline;vertical-align:middle;"><span class="link_title"><a href="http://blog.csdn.net/zzq900503/article/details/51773810" rel="nofollow">linux管理(一)---用户管理及权限</a></span></h1><br><p></p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><h1><span style="color:#ff0000;">下载hadoop安装包</span></h1><p><span style="font-size:18px;">进入官网中找到镜像页面找到我们使用的版本，这里是1.2.1稳定版。下载步骤如下图:</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160621172945667?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><span style="font-size:18px;">任意选择一个镜像，我这里选择第一个：</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160621172959632?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><span style="font-size:18px;">选择版本:</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160621173027054?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><span style="font-size:18px;">选择需要下载的文件，因为我们是linux系统中使用所以下载hadoop-1.2.1.tar.gz</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160621173124716?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><br></p><p><br></p><p><br></p><p><span style="font-size:18px;">ps: 熟悉linux系统的同学也可以直接使用wget命令下载</span></p><p></p><pre><code class="language-plain">wget http://apache.fayea.com/hadoop/common/hadoop-1.2.1/hadoop-1.2.1.tar.gz</code></pre><p></p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><h1><span style="color:#ff0000;">配置hosts</span></h1><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="font-size:18px;">在每一台机器的/etc/hosts文件中加入ip地址和主机名的映射，也就是把之前查询出来的ip和主机名信息(<span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;">下面的三行</span>)加入到hosts文件中。</span></span><br></span></p><p></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);font-size:14px;"><span style="font-size:18px;">192.168.30.180      hadoop0    <br></span></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);font-size:14px;"><span style="font-size:18px;">192.168.30.189      hadoop1    <br></span></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);font-size:14px;"><span style="font-size:18px;">192.168.30.186      hadoop2    </span></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);font-size:14px;"></p><pre><code class="language-plain">vim  /etc/hosts</code></pre><p></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="font-size:18px;">配置好的hosts内容如下所示：</span></span></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);font-size:14px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><img src="https://img-blog.csdn.net/20160708102503196?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></span></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);font-size:14px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);font-size:14px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="font-size:18px;color:#ff0000;"><span style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;">ps:如果遇到</span><span style="line-height:25.2px;">'readonly' option is set (add ! to override) 需要用root权限</span></span></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);font-size:14px;"></p><pre><code class="language-plain">su -</code></pre><p></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);"><span style="line-height:25.2px;"><span style="font-size:18px;">输入root密码再编辑即可。</span></span></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);font-size:14px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);font-size:14px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);font-size:14px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);font-size:14px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);font-size:14px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);font-size:14px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);font-size:14px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;color:rgb(51,51,51);font-size:14px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p></p><h1><span style="color:#ff0000;">配置ssh无密码访问</span></h1><p></p><p><span style="font-size:18px;">ssh 用于登录远程主机, 并且在远程主机上执行命令. 它的目的是替换 rlogin 和 rsh, 同时在不安全的网络之上, 两个互不信任的主机之间, 提供加密的, 安全的通信连接. X11 连接和任意 TCP/IP 端口均可以通过此安全通道转发(forward).当用户通过连接并登录主机 hostname 后, 根据所用的协议版本, 用户必须通过钥匙的方法向远程主机证明他/她的身份。</span><br></p><p style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="font-size:18px;">执行以下命令：</span></p><h2><span style="color:#cc33cc;">生成密钥文件</span></h2><p style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"></p><pre><code class="language-plain">ssh-keygen -t dsa -P "" -f ~/.ssh/id_dsa</code></pre><p></p><p style="font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="font-size:18px;color:#ff0000;">ps:主要 不是 shh  -keygen 中间没有空格。然后当前用户也需要注意，因为我们主要是用之前的同名用户joe在操作，所以应该用joe用户生成密钥文件。这样它们生成的目录路径是不一样的。</span></p><p style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160708112143601?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160708112156446?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="font-size:18px;"><br></span></p><h2><span style="color:#cc33cc;">把密钥内容写到授权文件中</span></h2><p style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"></p><pre><code class="language-plain">cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</code></pre><p></p><p style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="font-size:18px;line-height:25.2px;">并且把所有节点的authorized_keys的内容相互拷贝加入到每一个节点的authorized_keys中，配置完成后每一个节点的authorized_keys文件的内容应该是一样的。</span></p><p style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="font-size:18px;line-height:25.2px;"><img src="https://img-blog.csdn.net/20160708112422840?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><br><img src="https://img-blog.csdn.net/20160708112432856?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br><p><span style="font-size:18px;">这是其中一台的授权文件，我们把三台的内容都取出来 组合成最终的文件。最终每一台的<span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;">authorized_keys内容都如下:</span></span></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:18px;line-height:25.2px;"><img src="https://img-blog.csdn.net/20160708113224930?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><br></p><p><br></p><h2><span style="color:#cc33cc;">密钥文件授权</span></h2><p></p><pre><code class="language-plain">chmod 700 ~/.ssh
chmod 644   ~/.ssh/authorized_keys</code></pre><br><br><pre><code class="language-plain"></code></pre><p></p><p></p><p></p><h2><span style="color:#cc33cc;">把密钥添加到缓存中</span></h2><p></p><pre class="plain">ssh-add</pre><br><br><p></p><br><h2><span style="color:#cc33cc;">测试ssh功能</span></h2><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="font-size:18px;">在继续安装前，一定要保证这一步安装正确，可以使用ssh 主机名命令来测试是否成功，例如：ssh hadoop1，如果成功则会进入到hadoop1机器中。</span></span><br></p><p><span style="font-family:verdana, Arial, Helvetica, sans-serif;font-size:18px;color:#333333;"><span style="line-height:25.2px;">第一次连接可能会遇到询问:</span></span></p><p><span style="font-family:verdana, Arial, Helvetica, sans-serif;font-size:18px;color:#333333;"><span style="line-height:25.2px;">The authenticity of host 'hadoop0 (192.168.30.180)' can't be established.<br>RSA key fingerprint is 21:b8:6a:49:c3:41:96:aa:5a:f0:cd:76:75:6c:1f:4e.<br>Are you sure you want to continue connecting (yes/no)? ^<br>如果回答yes的话能无密码登录 则没问题 这样会生成一个know hosts文件下次登录后就不会询问了，这种情况是主机有变动，估计是ip变了。<br></span></span></p><p><span style="font-family:verdana, Arial, Helvetica, sans-serif;font-size:18px;color:#333333;"><span style="line-height:25.2px;"><img src="https://img-blog.csdn.net/20160708161204364?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></span></p><p><span style="font-family:verdana, Arial, Helvetica, sans-serif;font-size:18px;color:#333333;"><span style="line-height:25.2px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:18px;line-height:25.2px;">如果回答yes的话会再次询问你的密码才能登录</span><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:18px;line-height:25.2px;">就不能达到我们无密码登录的目的，这种情况需要解决一下，解决的方法看下文的可能遇到的问题。</span><br></span></span></p><p><span style="font-family:verdana, Arial, Helvetica, sans-serif;font-size:18px;color:#333333;"><span style="line-height:25.2px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:18px;line-height:25.2px;"><img src="https://img-blog.csdn.net/20160708161313820?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></span></span></p><p><span style="font-size:18px;">成功无密码连接之后 ~/.ssh/路径下会生成一个know hosts文件记录 成功连接过的密钥。</span></p><p><span style="font-size:18px;">我们依次检查几台机器的~/.ssh/know hosts，如果都成功互联了对方，则ssh无密码登录设置成功。</span></p><p></p><pre><code class="language-plain">cat  ~/.ssh/know hosts</code></pre><img src="https://img-blog.csdn.net/20160708160739265?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br><p></p><p><br></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="font-size:18px;"><br></span></span></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="font-size:18px;"><br></span></span></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;">PS：</span></p><h2><span style="color:#cc33cc;">可能遇到的问题ssh: connect to host hadoop1 port 22: No route to host</span></h2><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="font-size:18px;">这种情况是虚拟机的ip与hosts中写的不对应了。</span></span></p><h3><span style="color:#3333ff;">解决方法</span></h3><p><span style="font-size:18px;">重新检查 几台机器的ip  以及相互之间 分别用 ip和 主机名是否能ping通。重新编辑hosts配置文件后重新生成密钥。</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160708140715077?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><span style="font-size:18px;"><br></span></p><p><br></p><p><span style="font-size:18px;"><br></span></p><h2><span style="color:#cc33cc;">可能遇到的问题:The authenticity of host 'hadoop0 (192.168.30.180)' can't be established.</span></h2><div><span style="color:#3333ff;">RSA key fingerprint is 21:b8:6a:49:c3:41:96:aa:5a:f0:cd:76:75:6c:1f:4e.<br>Are you sure you want to continue connecting (yes/no)? ^<br></span></div><div><span style="color:#3333ff;"><br></span><span style="font-size:18px;">如果回答yes的话能无密码登录 则没问题 这样会生成一个know hosts文件下次登录后就不会询问了，这种情况是主机有变动，估计是ip变了。</span><span style="color:#3333ff;"><br></span></div><p></p><p><span style="font-size:18px;">如果回答yes的话</span><span style="font-size:18px;">会再次询问你的密码才能登录。</span></p><p><span style="font-size:18px;">就不能达到我们无密码登录的目的。</span></p><p><span style="font-size:18px;">原因</span></p><p><span style="font-size:18px;">密钥文件不起作用---权限问题或者主机的ip等信息有变动。</span></p><p><span style="font-size:18px;"><br></span></p><h3><span style="color:#3333ff;">解决方法一</span></h3><p><span style="font-size:18px;">重新生成一遍密钥 分发一次。</span></p><p><span style="font-size:18px;"></span></p><pre><code class="language-plain">ssh-keygen -t dsa -P "" -f ~/.ssh/id_dsa
cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</code></pre><p><span style="font-size:18px;">授权密钥文件</span></p><p><span style="font-size:18px;"></span></p><pre><code class="language-plain">chmod 700 ~/.ssh
chmod 644   ~/.ssh/authorized_keys</code></pre><p></p><p><br></p><p><span style="font-size:18px;">检查是否生成正确<br></span><span style="font-size:18px;"></span></p><pre><code class="language-plain">ll ~/.ssh/</code></pre><span style="font-size:18px;">如果生成有known_hosts文件那应该就没问题了。</span><br><img src="https://img-blog.csdn.net/20160708153249871?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br><p></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><h3><span style="color:#3333ff;">解决方法二</span></h3><p><span style="font-size:18px;">使用命令(<span style="color:#ff0000;">相对安全的内网时才建议使用</span>)<br></span><span style="font-size:18px;"></span></p><pre><code class="language-plain">ssh -o StrictHostKeyChecking=no hadoop1  </code></pre><p></p><p><span style="font-size:18px;">能实现无密码登录。</span></p><p><span style="font-size:18px;">SSH对主机的public_key的检查等级是根据StrictHostKeyChecking变量来配置的。默认情况下，StrictHostKeyChecking=ask。简单所下它的三种配置值：<br>1.StrictHostKeyChecking=no  <br>#最不安全的级别，当然也没有那么多烦人的提示了，相对安全的内网测试时建议使用。如果连接server的key在本地不存在，那么就自动添加到文件中（默认是known_hosts），并且给出一个警告。<br>2.StrictHostKeyChecking=ask  #默认的级别，就是出现刚才的提示了。如果连接和key不匹配，给出提示，并拒绝登录。<br>3.StrictHostKeyChecking=yes  #最安全的级别，如果连接与key不匹配，就拒绝连接，不会提示详细信息。</span><br></p><p><span style="font-size:18px;"><br></span></p><h3><span style="color:#3333ff;">解决方法三</span></h3><p><span style="font-size:18px;">这个也是修改StrictHostKeyChecking配置实现无密码登录。</span></p><p><span style="font-size:18px;">不过是直接修改配置文件。<span style="font-size:18px;">(</span><span style="font-size:18px;"><span style="color:#ff0000;">相对安全的内网时才建议使用</span></span><span style="font-size:18px;">)</span></span></p><p><span style="font-size:18px;">修改/etc/ssh/ssh_config文件（或$HOME/.ssh/config）中的配置，添加如下两行配置：<br></span><span style="font-size:18px;"></span></p><pre><code class="language-plain">StrictHostKeyChecking no
UserKnownHostsFile /dev/null</code></pre><span style="font-size:18px;">修改好配置后，重新启动sshd服务即可，命令为：/etc/init.d/sshd restart   （或 service sshd restart ）<br>当然，这是内网中非常信任的服务器之间的ssh连接，所以不考虑安全问题，就直接去掉了主机密钥（host key）的检查。</span><br><p></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><h2><span style="color:#cc33cc;">可能遇到问题:Agent admitted failure to sign using the key</span></h2><p></p><h3><span style="color:#3333ff;">解决方法</span></h3><p></p><p style="border:0px;list-style:none;">使用命令</p><p style="border:0px;list-style:none;"></p><pre><code class="language-plain">ssh-add</code></pre><p></p><p><span style="font-size:18px;">再尝试一次 ssh hadoop1</span></p><p><span style="font-size:18px;">成功了。无密码登录成功。</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160708154224962?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><br></p><p><br></p><p><br></p><p><br></p><h2><span style="color:#cc33cc;">可能遇到的情况:hadoop0能免密ssh到hadoop2,但hadoop2ssh到hadoop0需要密码</span></h2><p><span style="font-size:18px;">这种情况是因为 hadoop0中的密钥文件authorized_keys中hadoop2的密钥字符串有问题。 这种情况需要仔细检查一下 是否少了开头结尾的一些字符，或者 重新把hadoop2中authorized_keys的hadoop2的密钥字符串重新粘贴过来到hadoop0中一次。应该就可以了。 如果还是不行 就在 hadoop2中重新执行一次生成密钥 授权，把新的密钥粘贴到<br> hadoop0中的密钥文件authorized_keys中，并给hadoop0中的密钥文件authorized_keys授权 664即可。</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160708174121249?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><h1><span style="color:#ff0000;">安装hadoop</span></h1><p><span style="font-size:18px;">我们在前面已经下载了hadoop-1.2.1.tar.gz文件，现在用ssh工具把安装文件分别放到三台机子中的/home/joe目录下新建的hadoop文件夹中。</span></p><p><span style="font-size:18px;">如下图:</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160711111121861?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160711110931954?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><span style="font-size:18px;">然后在控制台进入/home/joe/hadoop路径执行下面的命令把hadoop解压出来则安装完成。</span></p><p><span style="font-size:18px;"></span></p><pre><code class="language-plain">cd /home/joe/hadoop
tar -zxvf hadoop-1.2.1.tar.gz </code></pre><br><br><p></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><h1><span style="color:#ff0000;">配置hadoop</span></h1><p><span style="font-size:18px;">因为在配置过程中会使用jdk的路径，如果之前没安装jdk的话可以安装下面的步骤把每一台的机子都安装上jdk。</span></p><p><span style="font-size:18px;"><span style="font-family:Arial;"><span style="line-height:30px;"><a href="http://blog.csdn.net/zzq900503/article/details/51879745" rel="nofollow">linux软件(一)---CentOS安装jdk</a></span></span><br></span></p><p><span style="text-align:justify;"><span style="font-size:18px;">进入到hadoop安装目录，(我自己的是/home/joe/hadoop/)，运行ls看到conf文件夹，这里存放的是配置相关信息；bin文件夹，存放的是可执行的文件；</span></span></p><p><span style="text-align:justify;"><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160712114030029?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></span></p><p><span style="text-align:justify;"><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160712114109985?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></span></p><p><span style="font-size:18px;">进入conf目录，配置hadoop文件，我们需要配置以下几个文件：<br></span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160712114258691?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><span style="font-size:18px;"></span></p><pre><code class="language-plain">cd /home/joe/hadoop/hadoop-1.2.1/conf</code></pre><br><br><p></p><p><br></p><h2><span style="color:#cc33cc;">配置masters文件</span></h2><p><span style="font-size:18px;">我们上面已经做了角色分配</span></p><p><span style="font-size:18px;">192.168.30.180      hadoop0    作为master担任NameNode 和 JobTracker<br></span></p><p></p><pre><code class="language-plain">vim masters</code></pre><span style="font-size:18px;">去掉原文件中的localhost然后把192.168.30.180添加到文件中如下图:</span><p></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160712120003663?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><span style="font-size:18px;"><br></span></p><p><br></p><h2><span style="color:#cc33cc;">配置slaves文件</span></h2><p><span style="font-size:18px;">192.168.30.189      hadoop1    作为slave担任DataNode  和 TaskTracker<br>192.168.30.186      hadoop2    作为slave担任DataNode  和 TaskTracke</span><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;line-height:25.2px;"><span style="font-size:18px;">r</span><br></span></p><p></p><pre><code class="language-plain">vim slaves</code></pre><span style="font-size:18px;">去掉localhost 写入作为slave的2台机子的ip如下：</span><p></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><img src="https://img-blog.csdn.net/20160712120535650?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><br></p><p><br></p><p><br></p><h2><span style="color:#cc33cc;">配置hadoop-env.sh文件</span></h2><p><span style="font-size:18px;">这里是配置jdk的安装地址,也就是jdk安装配置时的JAVA_HOME。我这里的路径是/home/joe/java/jdk1.8.0_91</span><br></p><p></p><pre><code class="language-plain">vim hadoop-env.sh</code></pre><span style="font-size:18px;">在文件中加入</span><p></p><p><span style="font-size:18px;">export JAVA_HOME=/home/joe/java/jdk1.8.0_91</span><br></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></p><h2><span style="color:#cc33cc;">配置hdfs-site.xml文件</span></h2><p><span style="font-size:18px;">配置replication，即数据保存份数。一般根据集群的机器数量来调整。我们这里是3台，可以设置成3。</span><br></p><p></p><pre><code class="language-plain">vim hdfs-site.xml</code></pre><p></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><img src="https://img-blog.csdn.net/20160720164743772?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><span style="font-size:18px;">在&lt;configuration&gt;&lt;/configuration&gt;之间加上:</span></p><p><span style="font-size:18px;"><span style="text-align:justify;">&lt;property&gt;</span><br style="text-align:justify;"><span style="text-align:justify;">    &lt;name&gt;dfs.replication&lt;/name&gt;</span><br style="text-align:justify;"><span style="text-align:justify;">    &lt;value&gt;3&lt;/value&gt;</span><br style="text-align:justify;"><span style="text-align:justify;"> &lt;/property&gt;</span></span></p><p><span style="font-size:18px;">如图:</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160720165431224?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><span style="font-size:18px;">PS：配置中还可以指定dfs.data.dir数据存储路径等参数。我们先用默认的，如有特殊需求可参考官网的配置。</span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><h2><span style="color:#cc33cc;">配置core-site.xml</span></h2><p><span style="font-size:18px;">配置namenode的地址和端口,以及临时目录<br></span></p><p><span style="font-size:18px;">回顾一下角色:</span></p><p><span style="font-size:18px;">192.168.30.180      hadoop0    作为master担任NameNode 和 JobTracker<br></span></p><p><span style="font-size:18px;">端口可以自己选择 这里采用9000</span></p><p></p><pre><code class="language-plain">vim core-site.xml</code></pre><img src="https://img-blog.csdn.net/20160720172237523?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><p></p><p><span style="font-size:18px;">在&lt;configuration&gt; &lt;/configuration&gt;之间加上:</span></p><p><span style="font-size:18px;"> &lt;property&gt;  <br>         &lt;name&gt;fs.default.name&lt;/name&gt;  <br>         &lt;value&gt;hdfs://192.168.30.180:9000&lt;/value&gt;  <br>  &lt;/property&gt;  <br>  &lt;property&gt;  <br>         &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;  <br>         &lt;value&gt;/home/joe/hadoop/hadooptmpdir&lt;/value&gt;  <br>         &lt;description&gt;A base for other temporary directories.&lt;/description&gt;  <br> &lt;/property&gt;  </span><br></p><p><span style="font-size:18px;">如图：</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160721144845343?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><span style="font-size:18px;"><br></span></p><p><br><span style="font-size:18px;"></span></p><p><span style="font-size:18px;"><br></span></p><h2><span style="color:#cc33cc;">配置mapred-site.xml</span></h2><p><span style="font-size:18px;">配置jobtracker的地址和端口<br></span></p><p></p><p><span style="font-size:18px;">回顾一下角色:</span></p><p><span style="font-size:18px;">192.168.30.180      hadoop0    作为master担任NameNode 和 JobTracker</span></p><p><span style="font-size:18px;">所以这里的ip还是180 跟 core-site.xml中的一样。</span></p><p><span style="font-size:18px;">但是端口需要另外分配一个，因为NameNode已经用了9000端口，所以这里我们用9001.</span></p><p></p><pre><code class="language-plain">vim mapred-site.xml</code></pre><img src="https://img-blog.csdn.net/20160721163123466?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br><p></p><p><span style="font-size:18px;">在&lt;configuration&gt; &lt;/configuration&gt;之间加上:</span></p><p><span style="font-size:18px;"> &lt;property&gt;  <br>         &lt;name&gt;mapred.job.tracker&lt;/name&gt;  <br>         &lt;value&gt;hdfs://192.168.30.180:9001&lt;/value&gt;  <br>  &lt;/property&gt;</span><br></p><p><span style="font-size:18px;">如图：</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160721181019300?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><h2><span style="color:#cc33cc;">同步配置</span></h2><p><span style="font-size:18px;">这样我们就配置好了其中一台机器，其它几台机器也需要一模一样的配置。</span></p><p><span style="font-size:18px;">我们可以分别手动去设置。但最好是 把配置复制过去。</span></p><p><span style="font-size:18px;">我这里把整个hadoop文件夹复制过去,我首先设置了hadoop2,这里需要赋值到hadoop0和hadoop1:</span></p><p><span style="font-size:18px;"></span></p><pre><code class="language-plain">scp -r /home/joe/hadoop/  hadoop0:/home/joe/
scp -r /home/joe/hadoop/  hadoop1:/home/joe/</code></pre><img src="https://img-blog.csdn.net/20160721182500563?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br><br><p></p><p></p><p><br></p><p><br></p><h2><span style="color:#cc33cc;">检查配置</span></h2><p><span style="font-size:18px;">我们已经把hadoop2的给同步复制过来了，这里的路径要尤其注意，需要确保是 原安装路径的覆盖 替换，并检查 我们配置文件是否已经跟我们在hadoop2中的配置一样。</span></p><p><img src="https://img-blog.csdn.net/20160721182852861?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></p><p><br></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><br></p><p><br></p><p><br></p><p><br></p><h1><span style="color:#ff0000;">格式化hadoop的文件系统HDFS</span></h1><p><span style="font-size:18px;">配置完成之后我们已经安装完毕，现在做启动前的准备：格式化hadoop的文件系统。</span></p><p><span style="font-size:18px;">三台机器任意一台 进入bin目录</span></p><p></p><pre><code class="language-plain">cd /home/joe/hadoop/hadoop-1.2.1/bin/
./hadoop namenode -format</code></pre><span style="font-size:18px;">如果出现……has been successfully formatted，说明格式化成功。</span><br><img src="https://img-blog.csdn.net/20160727200633559?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br><p></p><p><img src="https://img-blog.csdn.net/20160727200645591?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></p><p></p><p><br></p><p style="color:rgb(51,51,51);font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="color:rgb(51,51,51);font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="color:rgb(51,51,51);font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="color:rgb(51,51,51);font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="color:rgb(51,51,51);font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="color:rgb(51,51,51);font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><h1><span style="color:#ff0000;">关闭master防火墙</span></h1><p><span style="font-size:18px;"><span style="font-size:18px;">192.168.30.180      hadoop0    作为master担任NameNode 和 JobTracker</span><br></span></p><p><span style="font-size:18px;">防火墙关闭</span></p><p><span style="font-size:18px;">也可把相应的配置中的端口打开，例如我上面设置的9000和9001，需要把每台机器的这2个端口都打开，</span></p><p><span style="font-size:18px;">我这里为了方便，把<span style="font-size:18px;">hadoop0 </span>机器(也就是master)的防火墙暂时关闭。需要root权限！再关闭防火墙。否则关闭无效。</span></p><p></p><pre><code class="language-plain">service iptables stop</code></pre><p></p><p><br></p><img src="https://img-blog.csdn.net/20160727205823286?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br><span style="font-size:18px;">可以用下面命令查询防火墙状态，如果不是root权限该命令无效。</span><p><span style="font-size:18px;"></span></p><pre><code class="language-plain">service iptables status</code></pre><p></p><p><img src="https://img-blog.csdn.net/20160727213942315?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" style="color:rgb(51,51,51);font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;" alt=""></p><p><span style="font-size:18px;">切换到root后关闭防火墙</span></p><p style="color:rgb(51,51,51);font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"></span></span></p><pre><code class="language-plain">su root
service iptables stop
service iptables status</code></pre><img src="https://img-blog.csdn.net/20160727214216600?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br><br><p></p><p style="color:rgb(51,51,51);font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="color:rgb(51,51,51);font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="color:rgb(51,51,51);font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="color:rgb(51,51,51);font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="color:rgb(51,51,51);font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><p style="color:rgb(51,51,51);font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;"><span style="font-size:18px;"><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></span></p><br><h1><span style="color:#ff0000;">启动hadoop</span></h1><p><span style="font-family:verdana, Arial, Helvetica, sans-serif;font-size:18px;color:#333333;"><span style="line-height:25.2px;">切换回joe用户,因为我们只配置了joe用户在三台机器之间的互通访问。在三台机子中的任意一台进入hadoop的bin目录启动</span></span></p><p><span style="font-family:verdana, Arial, Helvetica, sans-serif;color:#333333;"><span style="font-size:14px;line-height:25.2px;"></span></span></p><pre><code class="language-plain">cd /home/joe/hadoop/hadoop-1.2.1/bin/
./start-all.sh</code></pre><img src="https://img-blog.csdn.net/20160727201335475?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br><br><p></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><h1><span style="color:#ff0000;">验证是否启动成功</span></h1><h2><span style="color:#cc33cc;">方法一</span></h2><h3><span style="color:#3333ff;">验证Name和JobTracker</span></h3><p><span style="font-size:18px;">在master节点运行jps，如果出现以下红色框里的进程，说明<span style="font-size:18px;">NameNode </span>和<span style="font-size:18px;">JobTracker启动</span>成功。<br></span></p><p><span style="font-size:18px;">我们这里master是<span style="font-size:18px;">hadoop0    </span></span></p><p><span style="font-size:18px;">192.168.30.180      hadoop0    作为master担任NameNode 和 JobTracker</span><br></p><p><img src="https://img-blog.csdn.net/20160727203005748?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;"><br></span></p><h3><span style="color:#3333ff;">验证DataNode  和 TaskTracker</span></h3><p></p><p><span style="font-size:18px;">在slave节点运行jps，如果出现以下红色框里的进程，说明DataNode  和 TaskTracker启动成功</span></p><p></p><p><span style="font-size:18px;">192.168.30.189      hadoop1    作为slave担任DataNode  和 TaskTracker<br></span></p><p><span style="font-size:18px;">192.168.30.186      hadoop2    作为slave担任DataNode  和 TaskTracker</span></p><span style="font-size:18px;">我们分别在 hadoop1和hadoop2运行jps</span><p><img src="https://img-blog.csdn.net/20160727205945318?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><h3><span style="color:#3333ff;">可能遇到的情况</span></h3><p><span style="font-size:18px;">DataNode  和<span style="font-size:18px;">TaskTracker没启动起来</span></span><br></p><p><span style="font-size:18px;"><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160727203936808?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></span></p><p><br></p><p><br></p><h3><span style="color:#3333ff;">解决方法</span></h3><p><span style="font-size:18px;">需要去相关的日志中查看原因，相应解决。如果要查看hadoop1的日志则需要在hadoop1中查看</span></p><p><span style="font-size:18px;"></span></p><pre><code class="language-plain">cd /home/joe/hadoop/hadoop-1.2.1/libexec/../logs
ls
tail -f -n 800  hadoop-joe-datanode-hadoop1.log</code></pre><br><br><p></p><p><img src="https://img-blog.csdn.net/20160727204017714?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p><p><img src="https://img-blog.csdn.net/20160727204513435?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></p><p><img src="https://img-blog.csdn.net/20160727204846838?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></p><p><br></p><p><span style="font-size:18px;">遇到的问题是java.net.NoRouteToHostException: No route to host</span></p><p></p><p><span style="font-size:18px;">在配置hadoop的时候，很容易遇到以上错误，遇到以上问题的时候，一般可以通过以下几种方法解决。 <br>1、从namenode主机ping其它主机名（如：ping slave1），如果ping不通,原因可能是namenode节点的/etc/hosts配置错误。</span></p><p><span style="font-size:18px;">2、从datanode主机ping namenode主机名，如果ping不通,原因可能是datenode节点的/etc/hosts配置的配置错误。</span></p><p><span style="font-size:18px;">3、查看namenode主机的9000（具体根据core-site.xml中的fs.default.name节点配置）端口，是否打开。</span></p><p><span style="font-size:18px;"><span style="color:rgb(69,69,69);font-family:arial, '宋体', sans-serif, tahoma, 'Microsoft YaHei';font-size:14px;line-height:24px;"><span style="font-size:18px;"></span></span></span></p><pre><code class="language-plain">netstat -lnp|grep 9000</code></pre><p></p><p><span style="font-size:18px;"><span style="color:rgb(69,69,69);font-family:arial, '宋体', sans-serif, tahoma, 'Microsoft YaHei';font-size:14px;line-height:24px;">#<span style="font-size:18px;">9000</span>请换为你的设置的端口</span> </span></p><p><span style="font-size:18px;"><span style="color:rgb(69,69,69);font-family:arial, '宋体', sans-serif, tahoma, 'Microsoft YaHei';font-size:14px;line-height:24px;">执行以上命令，可以查看到9000端口正在被哪个进程使用。如下图，进程号为25601。</span></span></p><p><span style="font-family:arial, '宋体', sans-serif, tahoma, 'Microsoft YaHei';color:#454545;"><span style="font-size:14px;line-height:24px;"><img src="https://img-blog.csdn.net/20160727212744237?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></span></p><p></p><pre><code class="language-plain">ps 25601</code></pre><span style="font-size:18px;">执行以上命令。查看相应进程号的程序详细路径。<br></span><p></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160727213022490?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;">如果是nameNode 在使用该端口，则是对的。</span></p><p><span style="font-size:18px;"><br></span></p><p><span style="font-size:18px;">4、关闭系统防火墙。这是最容易出现的问题。用此命令service iptables stop关闭后。</span></p><p><span style="font-size:18px;">进入hadoop的bin目录 用下面命令</span></p><p><span style="font-size:18px;"></span></p><pre><code class="language-plain">./stop-all.sh</code></pre><p></p><p><span style="font-size:18px;">停止所有集群再启动一遍</span></p><p></p><pre><code class="language-plain">./start-all.sh</code></pre><p></p><p><span style="font-size:18px;">一切正常集群正常使用。</span></p><p style="font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;"><br></p><p style="font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;"><br></p><p style="font-family:Helvetica, Tahoma, Arial, sans-serif;font-size:14px;line-height:25.2px;"><br></p><br><p><br></p><h2><span style="color:#cc33cc;">方法二</span></h2><p><span style="font-size:18px;">通过浏览器查看---端口是hadoop默认的 --NameNode是50070，JobTracker是50030，TaskTracker是50060.<br></span></p><p><span style="font-size:18px;">192.168.30.180      hadoop0    作为master担任NameNode 和 JobTracker<br></span></p><p><span style="font-size:18px;">192.168.30.189      hadoop1    作为slave担任DataNode  和 TaskTracker<br>192.168.30.186      hadoop2    作为slave担任DataNode  和 TaskTracker<br></span></p><h3><span style="color:#3333ff;">NameNode</span></h3><p><span style="font-size:18px;">http://192.168.30.180:50070/dfshealth.jsp</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160727215539572?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><h3><span style="color:#3333ff;">JobTracker</span></h3><p><span style="font-size:18px;">http://192.168.30.180:50030/jobtracker.jsp</span></p><p><span style="font-size:18px;"><img src="https://img-blog.csdn.net/20160727215705402?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p></p><h3><span style="color:#3333ff;">TaskTracker</span></h3><span style="font-size:18px;">http://192.168.30.189:50060/tasktracker.jsp<br>http://192.168.30.186:50060/tasktracker.jsp</span><br><p></p><p><span style="font-size:18px;">PS:这2个打不开的话 需要把他们的防火墙也关闭才能用局域网内的浏览器访问。</span></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><img src="https://img-blog.csdn.net/20160727220205283?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><img src="https://img-blog.csdn.net/20160727220219862?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></p><h1><span style="color:#ff0000;">一些启动停止的命令</span></h1><p><span style="text-indent:28px;"><span style="font-size:18px;">正式启动Hadoop啦，bin/目录下有很多启动脚本，可以根据自己的需要来启动停止Hadoop的守护进程。</span></span></p><p></p><pre><code class="language-plain">start-all.sh </code></pre><p></p><p><span style="text-indent:28px;"><span style="font-size:18px;">启动所有的Hadoop守护进程。包括NameNode、 Secondary NameNode、DataNode、JobTracker、 TaskTrack</span></span></p><p><span style="text-indent:28px;"><span style="font-size:18px;"><br></span></span></p><p></p><p style="border-width:0px;list-style:none;"></p><pre><code class="language-plain">stop-all.sh </code></pre><p></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">停止所有的Hadoop守护进程。包括NameNode、 Secondary NameNode、DataNode、JobTracker、 TaskTrack</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><pre><code class="language-plain">start-dfs.sh </code></pre><p></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">启动Hadoop HDFS守护进程NameNode、SecondaryNameNode和DataNode</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><pre><code class="language-plain">stop-dfs.sh </code></pre><p></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">停止Hadoop HDFS守护进程NameNode、SecondaryNameNode和DataNode</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><pre><code class="language-plain">hadoop-daemons.sh start namenode </code></pre><p></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">单独启动NameNode守护进程</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><pre><code class="language-plain">hadoop-daemons.sh stop namenode</code></pre><p></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">单独停止NameNode守护进程</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><pre><code class="language-plain">hadoop-daemons.sh start datanode </code></pre><p></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">单独启动DataNode守护进程</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><pre><code class="language-plain">hadoop-daemons.sh stop datanode </code></pre><p></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">单独停止DataNode守护进程</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><pre><code class="language-plain">hadoop-daemons.sh start secondarynamenode</code></pre><p></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">单独启动SecondaryNameNode守护进程</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><pre><code class="language-plain">hadoop-daemons.sh stop secondarynamenode </code></pre><p></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">单独停止SecondaryNameNode守护进程</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><pre><code class="language-plain">start-mapred.sh </code></pre><p></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">启动Hadoop MapReduce守护进程JobTracker和TaskTracker</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><pre><code class="language-plain">stop-mapred.sh</code></pre><p></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">停止Hadoop MapReduce守护进程JobTracker和TaskTracker</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><pre><code class="language-plain">hadoop-daemons.sh start jobtracker </code></pre><p></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">单独启动JobTracker守护进程</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><pre><code class="language-plain">hadoop-daemons.sh stop jobtracker </code></pre><p></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">单独停止JobTracker守护进程</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><pre><code class="language-plain">hadoop-daemons.sh start tasktracker </code></pre><p></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">单独启动TaskTracker守护进程</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><pre><code class="language-plain">hadoop-daemons.sh stop tasktracker </code></pre><p></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">单独启动TaskTracker守护进程</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;"><br></span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">如果Hadoop集群是第一次启动，可以用start-all.sh。比较常用的启动方式是一个一个守护进程来启动，启动的步骤如下。</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">1．启动Hadoop的HDFS模块里的守护进程</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">HDFS里面的守护进程启动也有顺序，即：</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">1）启动NameNode守护进程；</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">2）启动DataNode守护进程；</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">3）启动SecondaryNameNode守护进程。</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">2．启动MapReduce模块里面的守护进程</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">MapReduce的守护进程启动也是有顺序的，即：</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">1）启动 JobTracker守护进程；</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">2）启动TaskTracker守护进程。</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">关闭的步骤正好相反，在这里就不描述了，可以自己试一下。</span></p><p style="border-width:0px;list-style:none;"><span style="font-size:18px;">注意　正常情况下，我们是不使用start-all.sh和stop-all.sh来启动和停止Hadoop集群的。这样出错了不好找原因。建议一个一个守护进程来启动，哪个启动失败就去看相应的log日志，这样就缩小了找错的范围。</span></p><br><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></p><p><span style="color:rgb(51,51,51);font-family:verdana, Arial, Helvetica, sans-serif;font-size:14px;line-height:25.2px;"><br></span></p>            </div>
                </div>