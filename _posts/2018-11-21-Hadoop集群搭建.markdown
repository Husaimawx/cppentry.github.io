---
layout:     post
title:      Hadoop集群搭建
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p id="main-toc"><strong>目录</strong></p>

<p id="-toc" style="margin-left:80px;"> </p>

<p id="Hadoop%E7%AE%80%E4%BB%8B-toc" style="margin-left:80px;"><a href="#Hadoop%E7%AE%80%E4%BB%8B" rel="nofollow">Hadoop简介</a></p>

<p id="Hadoop%E7%9A%84%E6%9E%B6%E6%9E%84-toc" style="margin-left:80px;"><a href="#Hadoop%E7%9A%84%E6%9E%B6%E6%9E%84" rel="nofollow">Hadoop的架构</a></p>

<p id="Hadoop%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%EF%BC%9F-toc" style="margin-left:80px;"><a href="#Hadoop%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%EF%BC%9F" rel="nofollow">Hadoop如何工作？</a></p>

<p id="Hadoop%E7%9A%84%E4%BC%98%E7%82%B9-toc" style="margin-left:80px;"><a href="#Hadoop%E7%9A%84%E4%BC%98%E7%82%B9" rel="nofollow">Hadoop的优点</a></p>

<p id="Hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-toc" style="margin-left:80px;"><a href="#Hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA" rel="nofollow">Hadoop集群搭建</a></p>

<p id="SSH%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95-toc" style="margin-left:80px;"><a href="#SSH%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95" rel="nofollow">SSH免密码登录</a></p>

<p id="%E9%85%8D%E7%BD%AE%E4%B8%A4%E4%B8%AA%E4%BB%8E%E8%8A%82%E7%82%B9-toc" style="margin-left:80px;"><a href="#%E9%85%8D%E7%BD%AE%E4%B8%A4%E4%B8%AA%E4%BB%8E%E8%8A%82%E7%82%B9" rel="nofollow">配置两个从节点</a></p>

<hr id="hr-toc"><h3 id="Hadoop%E7%AE%80%E4%BB%8B">Hadoop简介</h3>

<p><a href="https://baike.baidu.com/item/Hadoop" rel="nofollow">Hadoop</a>是一个由Apache基金会所开发的<a href="https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/4905336" rel="nofollow">分布式系统</a>基础架构。</p>

<p>用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。</p>

<p><a name="ref_%5B1%5D_908354"></a>Hadoop实现了一个<a href="https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/1250388" rel="nofollow">分布式文件系统</a>（Hadoop Distributed File System），简称HDFS。HDFS有高<a href="https://baike.baidu.com/item/%E5%AE%B9%E9%94%99%E6%80%A7/9131391" rel="nofollow">容错性</a>的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问<a href="https://baike.baidu.com/item/%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F/5985445" rel="nofollow">应用程序</a>的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）POSIX的要求，可以以流的形式访问（streaming access）文件系统中的数据。</p>

<p>Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算。</p>

<h3 id="Hadoop%E7%9A%84%E6%9E%B6%E6%9E%84">Hadoop的架构</h3>

<p><span>在其核心，Hadoop主要有两个层次，即：</span></p>

<ul><li><span>加工/计算层(MapReduce)，以及</span></li>
	<li><span>存储层(Hadoop分布式文件系统)。</span></li>
</ul><p><img alt="" class="has" src="https://img-blog.csdnimg.cn/20181111103933912.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3l1YW5mYW5nUE9FVA==,size_16,color_FFFFFF,t_70"></p>

<p><strong>MapReduce</strong></p>

<p>MapReduce是一种并行编程模型，用于编写普通硬件的设计，谷歌对大量数据的高效处理(多TB数据集)的分布式应用在大型集群(数千个节点)以及可靠的容错方式。 MapReduce程序可在Apache的开源框架Hadoop上运行。</p>

<p><strong>Hadoop分布式文件系统</strong></p>

<p>Hadoop分布式文件系统（HDFS）是基于谷歌文件系统（GFS），并提供了一个设计在普通硬件上运行的分布式文件系统。它与现有的分布式文件系统有许多相似之处。来自其他分布式文件系统的差别是显著。它高度容错并设计成部署在低成本的硬件。提供了高吞吐量的应用数据访问，并且适用于具有大数据集的应用程序。</p>

<p>除了上面提到的两个核心组件，Hadoop的框架还包括以下两个模块：</p>

<ul><li>
	<p>Hadoop通用：这是Java库和其他Hadoop组件所需的实用工具。</p>
	</li>
	<li>
	<p>Hadoop YARN ：这是作业调度和集群资源管理的框架.</p>
	</li>
</ul><h3 id="Hadoop%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%EF%BC%9F">Hadoop如何工作？</h3>

<p>建立重配置，处理大规模处理服务器这是相当昂贵的，但是作为替代，可以联系许多普通电脑采用单CPU在一起，作为一个单一功能的分布式系统，实际上，集群机可以平行读取数据集，并提供一个高得多的吞吐量。此外，这样便宜不到一个高端服务器价格。因此使用Hadoop跨越集群和低成本的机器上运行是一个不错不选择。</p>

<p>Hadoop运行整个计算机集群代码。这个过程包括以下核心任务由 Hadoop 执行：</p>

<ul><li>数据最初分为目录和文件。文件分为128M和64M（128M最好）统一大小块。</li>
	<li>然后这些文件被分布在不同的群集节点，以便进一步处理。</li>
	<li>HDFS，本地文件系统的顶端﹑监管处理。</li>
	<li>块复制处理硬件故障。</li>
	<li>检查代码已成功执行。</li>
	<li>执行发生映射之间，减少阶段的排序。</li>
	<li>发送排序的数据到某一计算机。</li>
	<li>为每个作业编写的调试日志。</li>
</ul><h3 id="Hadoop%E7%9A%84%E4%BC%98%E7%82%B9">Hadoop的优点</h3>

<ol><li>
	<p><strong>高可靠性</strong>。Hadoop按位存储和处理数据的能力值得人们信赖。</p>
	</li>
	<li>
	<p><strong>高扩展性</strong>。Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。</p>
	</li>
	<li>
	<p><strong>高效性</strong>。Hadoop能够在节点之间动态地移动数据，并保证各个节点的<a href="https://baike.baidu.com/item/%E5%8A%A8%E6%80%81%E5%B9%B3%E8%A1%A1" rel="nofollow">动态平衡</a>，因此处理速度非常快。</p>
	</li>
	<li>
	<p><strong>高容错性</strong>。Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。</p>
	</li>
	<li>
	<p><strong>低成本</strong>。与一体机、商用数据仓库以及QlikView、Yonghong Z-Suite等数据集市相比，hadoop是开源的，项目的软件成本因此会大大降低。</p>
	</li>
</ol><h3 id="Hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA">Hadoop集群搭建</h3>

<p style="margin-left:0pt;">1个master,2个slaver</p>

<p style="margin-left:0pt;">3个节点的IP地址及角色</p>

<table border="1" cellspacing="0" style="width:426.1pt;"><tbody><tr><td style="vertical-align:top;width:142pt;">
			<p style="margin-left:0pt;">节点主机名</p>
			</td>
			<td style="vertical-align:top;width:142.05pt;">
			<p style="margin-left:0pt;">IP地址</p>
			</td>
			<td style="vertical-align:top;width:142.05pt;">
			<p style="margin-left:0pt;">角色</p>
			</td>
		</tr><tr><td style="vertical-align:top;width:142pt;">
			<p style="margin-left:0pt;">lb01</p>
			</td>
			<td style="vertical-align:top;width:142.05pt;">
			<p style="margin-left:0pt;">192.168.231.141</p>
			</td>
			<td style="vertical-align:top;width:142.05pt;">
			<p style="margin-left:0pt;">namenode节点</p>
			</td>
		</tr><tr><td style="vertical-align:top;width:142pt;">
			<p style="margin-left:0pt;">web01</p>
			</td>
			<td style="vertical-align:top;width:142.05pt;">
			<p style="margin-left:0pt;">192.168.231.142</p>
			</td>
			<td style="vertical-align:top;width:142.05pt;">
			<p style="margin-left:0pt;">datanode节点</p>
			</td>
		</tr><tr><td style="vertical-align:top;width:142pt;">
			<p style="margin-left:0pt;">web02</p>
			</td>
			<td style="vertical-align:top;width:142.05pt;">
			<p style="margin-left:0pt;">192.168.231.143</p>
			</td>
			<td style="vertical-align:top;width:142.05pt;">
			<p style="margin-left:0pt;">datanode节点</p>
			</td>
		</tr></tbody></table><p style="margin-left:0pt;">注意：本机节点主机名可以修改为master,slaver01,slaver02,好辨识一些,当然，下边修改配置文件时，也要进行替换。</p>

<p style="margin-left:0pt;">1.创建hadoop用户及用户组</p>

<blockquote>
<p style="margin-left:0pt;">[root@lb01 ~]# groupadd hadoop</p>

<p style="margin-left:0pt;">[root@lb01 ~]# useradd -g hadoop  hadoop</p>

<p style="margin-left:0pt;">[root@lb01 ~]# passwd hadoop</p>

<p style="margin-left:0pt;">Changing password for user hadoop.</p>

<p style="margin-left:0pt;">New password:</p>

<p style="margin-left:0pt;">BAD PASSWORD: it is based on a dictionary word</p>

<p style="margin-left:0pt;">BAD PASSWORD: is too simple</p>

<p style="margin-left:0pt;">Retype new password:</p>

<p style="margin-left:0pt;">passwd: all authentication tokens updated successfully.</p>
</blockquote>

<p style="margin-left:0pt;">再创建一个hadoop用户一是为了怕不熟悉的人误操而损坏操作系统核心内容</p>

<p style="margin-left:0pt;">二是为了方便同一个组的用户可以共享hadoop集群</p>

<p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;">上传hadoop和jdk压缩包到/usr /local目录下</p>

<blockquote>
<p style="margin-left:0pt;">[root@lb01 local]# ls</p>

<p style="margin-left:0pt;"> hadoop-2.7.7.tar.gz  jdk-8u191-linux-x64.tar.gz</p>
</blockquote>

<p style="margin-left:0pt;">进行解压：</p>

<blockquote>
<p style="margin-left:0pt;">[root@lb01 local]# tar xf hadoop-2.7.7.tar.gz</p>

<p style="margin-left:0pt;">[root@lb01 local]# tar xf jdk-8u191-linux-x64.tar.gz  </p>

<p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;">[root@lb01 local]# mv hadoop-2.7.7 /home/hadoop/hadoop2.7</p>

<p style="margin-left:0pt;">[root@lb01 local]# mv jdk1.8.0_191 /home/hadoop/jdk1.8</p>
</blockquote>

<p style="margin-left:0pt;">修改权限</p>

<blockquote>
<p style="margin-left:0pt;">[root@lb01 hadoop]# chown -R hadoop.hadoop hadoop2.7/</p>

<p style="margin-left:0pt;">[root@lb01 hadoop]# chown -R hadoop.hadoop jdk1.8/</p>
</blockquote>

<p style="margin-left:0pt;"><strong><strong>导入JAVA环境</strong></strong></p>

<blockquote>
<p style="margin-left:0pt;">[root@lb01 local]# vim /etc/profile</p>

<p style="margin-left:0pt;">export JAVA_HOME=/home/hadoop/jdk1.8</p>

<p style="margin-left:0pt;">export CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar</p>

<p style="margin-left:0pt;">export PATH=.:$JAVA_HOME/bin:$PATH</p>
</blockquote>

<p style="margin-left:0pt;">使配置立即生效</p>

<p style="margin-left:0pt;">[root@lb01 local]# source /etc/profile</p>

<p style="margin-left:0pt;">查看JAVA是否安装成功</p>

<blockquote>
<p style="margin-left:0pt;">[root@lb01 lib]# java -version</p>

<p style="margin-left:0pt;">java version "1.8.0_191"</p>

<p style="margin-left:0pt;">Java(TM) SE Runtime Environment (build 1.8.0_191-b12)</p>

<p style="margin-left:0pt;">Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)</p>
</blockquote>

<p style="margin-left:0pt;"><strong><strong>导入hadoop环境</strong></strong></p>

<blockquote>
<p style="margin-left:0pt;">export JAVA_HOME=/home/hadoop/jdk1.8</p>

<p style="margin-left:0pt;">export CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar</p>

<p style="margin-left:0pt;">export HADOOP_HOME=/home/hadoop/hadoop2.7</p>

<p style="margin-left:0pt;">export PATH=.:$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$JAVA_HOME/bin:$PATH</p>
</blockquote>

<p style="margin-left:0pt;">使用hadoop命令，查看hadoop是否安装成功，若出现如下内容，则说明安装成功</p>

<blockquote>
<p style="margin-left:0pt;">[root@lb01 local]# hadoop</p>

<p style="margin-left:0pt;">Usage: hadoop [--config confdir] [COMMAND | CLASSNAME]</p>

<p style="margin-left:0pt;">  CLASSNAME            run the class named CLASSNAME</p>

<p style="margin-left:0pt;"> or</p>

<p style="margin-left:0pt;">  where COMMAND is one of:</p>

<p style="margin-left:0pt;">  fs                   run a generic filesystem user client</p>

<p style="margin-left:0pt;">  version              print the version</p>

<p style="margin-left:0pt;">  jar &lt;jar&gt;            run a jar file</p>

<p style="margin-left:0pt;">                       note: please use "yarn jar" to launch</p>

<p style="margin-left:0pt;">                             YARN applications, not this command.</p>

<p style="margin-left:0pt;">  checknative [-a|-h]  check native hadoop and compression libraries availability</p>

<p style="margin-left:0pt;">  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively</p>

<p style="margin-left:0pt;">  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive</p>

<p style="margin-left:0pt;">  classpath            prints the class path needed to get the</p>

<p style="margin-left:0pt;">  credential           interact with credential providers</p>

<p style="margin-left:0pt;">                       Hadoop jar and the required libraries</p>

<p style="margin-left:0pt;">  daemonlog            get/set the log level for each daemon</p>

<p style="margin-left:0pt;">  trace                view and modify Hadoop tracing settings</p>

<p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;">Most commands print help when invoked w/o parameters.</p>
</blockquote>

<p style="margin-left:0pt;"><strong><strong>修改hadoop2.7的配置文件：</strong></strong></p>

<p style="margin-left:0pt;">1、配置/home/hadoop/hadoop2.7/etc/hadoop目录中的hadoop-env.sh、yarn-env.sh、mapred-env.sh的JAVA_HOME值，向文件中添加：</p>

<blockquote>
<p style="margin-left:0pt;">[hadoop@lb01 hadoop]$ vim hadoop-env.sh</p>

<p style="margin-left:0pt;">[hadoop@lb01 hadoop]$ vim yarn-env.sh</p>

<p style="margin-left:0pt;">[hadoop@lb01 hadoop]$ vim mapred-env.sh</p>

<p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;"><span style="color:#f33b45;">export JAVA_HOME=/home/hadoop/jdk1.8</span></p>
</blockquote>

<p style="margin-left:0pt;">2、配置/home/hadoop/hadoop2.7/etc/hadoop下的slavers，这个文件中保存了所有slaver节点：</p>

<p style="margin-left:0pt;">把其中的localhost删除了，添加slave节点</p>

<blockquote>
<p style="margin-left:0pt;">[hadoop@lb01 hadoop]$ vim slaves</p>

<p style="margin-left:0pt;">web01</p>

<p style="margin-left:0pt;">web02</p>
</blockquote>

<p style="margin-left:0pt;">添加后，向/etc/hosts中添加主机名解析</p>

<blockquote>
<p style="margin-left:0pt;">192.168.231.142 web01</p>

<p style="margin-left:0pt;">192.168.231.143 web02</p>

<p style="margin-left:0pt;">192.168.231.141 lb01</p>
</blockquote>

<p style="margin-left:0pt;">3、配置core-site.xml文件：</p>

<pre class="has">
<code>&lt;configuration&gt;

    &lt;property&gt;

        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;

        &lt;value&gt;file:/home/hadoop/hadoop2.7/tmp&lt;/value&gt;

    &lt;/property&gt;

    &lt;property&gt;

        &lt;name&gt;fs.defaultFS&lt;/name&gt;

        &lt;value&gt;hdfs://lb01:9000&lt;/value&gt;

    &lt;/property&gt;

&lt;/configuration&gt;</code></pre>

<p style="margin-left:0pt;">4、配置hdfs-site.xml文件：</p>

<pre class="has">
<code>&lt;configuration&gt;

   &lt;property&gt;

                &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;

                &lt;value&gt;file:/home/hadoop/hadoop2.7/hdfs/name&lt;/value&gt;

        &lt;/property&gt;

        &lt;property&gt;

                &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;

                &lt;value&gt;file:/home/hadoop/hadoop2.7/hdfs/data&lt;/value&gt;

        &lt;/property&gt;

        &lt;property&gt;

#设置HDFS存储文件的副本数

                &lt;name&gt;dfs.replication&lt;/name&gt;

                &lt;value&gt;2&lt;/value&gt;

        &lt;/property&gt;

        &lt;property&gt;

        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;

        &lt;value&gt;lb01:50090&lt;/value&gt;

        &lt;/property&gt;

&lt;/configuration&gt;</code></pre>

<p style="margin-left:0pt;">5、配置mapred-site.xml</p>

<blockquote>
<p style="margin-left:0pt;">[hadoop@lb01 hadoop]$ mv mapred-site.xml.template mapred-site.xml</p>

<p style="margin-left:0pt;">[hadoop@lb01 hadoop]$ vim mapred-site.xml</p>
</blockquote>

<pre class="has">
<code>&lt;configuration&gt;

&lt;property&gt;

                &lt;name&gt;mapreduce.framework.name&lt;/name&gt;

                &lt;value&gt;yarn&lt;/value&gt;

                &lt;final&gt;true&lt;/final&gt;

        &lt;/property&gt;

        &lt;property&gt;

        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;

        &lt;value&gt;lb01:10020&lt;/value&gt;

    &lt;/property&gt;

    &lt;property&gt;

        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;

        &lt;value&gt;lb01:19888&lt;/value&gt;

    &lt;/property&gt;

&lt;/configuration&gt;</code></pre>

<p style="margin-left:0pt;">6、配置yarn-site.xml<br>
 </p>

<pre class="has">
<code>&lt;configuration&gt;


&lt;!-- Site specific YARN configuration properties --&gt;

 &lt;property&gt;

            &lt;name&gt;yarn.acl.enable&lt;/name&gt;

               &lt;value&gt;false&lt;/value&gt;

   &lt;/property&gt;

   &lt;property&gt;

            &lt;name&gt;yarn.admin.acl&lt;/name&gt;

                &lt;value&gt;*&lt;/value&gt;

   &lt;/property&gt;

    &lt;property&gt;

          &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;

                  &lt;value&gt;false&lt;/value&gt;

    &lt;/property&gt;

    &lt;property&gt;

     &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;

            &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;

    &lt;/property&gt;

    &lt;property&gt;

              &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;

                 &lt;value&gt;lb01:8032&lt;/value&gt;

    &lt;/property&gt;

    &lt;property&gt;

            &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;

                     &lt;value&gt;lb01:8030&lt;/value&gt;

    &lt;/property&gt;

&lt;property&gt;

      &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;

                &lt;value&gt;lb01:8035&lt;/value&gt;

    &lt;/property&gt;

    &lt;property&gt;

            &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;

                   &lt;value&gt;lb01:8033&lt;/value&gt;

    &lt;/property&gt;

    &lt;property&gt;

          &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;

                  &lt;value&gt;lb01:8088&lt;/value&gt;

   &lt;/property&gt;

  &lt;property&gt;

            &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;

                  &lt;value&gt;lb01&lt;/value&gt;

  &lt;/property&gt;

   &lt;property&gt;

           &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;

              &lt;value&gt;mapreduce_shuffle&lt;/value&gt;

  &lt;/property&gt;


&lt;/configuration&gt;

</code></pre>

<p style="margin-left:0pt;">修改完配置之后,向/etc/hosts文件中添加解析(三台主机都进行添加)：</p>

<p style="margin-left:0pt;">192.168.231.160 MASTER</p>

<p style="margin-left:0pt;">192.168.231.161 SLAVER01</p>

<p style="margin-left:0pt;">192.168.231.162 SLAVER02</p>

<h3 id="SSH%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95" style="margin-left:0pt;">SSH免密码登录</h3>

<p style="margin-left:0pt;">hadoop集群交互时，要进行输入密码，很麻烦，而用SSH提供公钥登录，就会省去输入密码的步骤，下面进行配置SSH免密码登录：</p>

<p style="margin-left:0pt;">生成秘钥和公钥：</p>

<blockquote>
<p style="margin-left:0pt;">[hadoop@lb01 ~]$ ssh-keygen</p>

<p style="margin-left:0pt;">Generating public/private rsa key pair.</p>

<p style="margin-left:0pt;">Enter file in which to save the key (/home/hadoop/.ssh/id_rsa):</p>

<p style="margin-left:0pt;">Created directory '/home/hadoop/.ssh'.</p>

<p style="margin-left:0pt;">Enter passphrase (empty for no passphrase):</p>

<p style="margin-left:0pt;">Enter same passphrase again:</p>

<p style="margin-left:0pt;">Your identification has been saved in /home/hadoop/.ssh/id_rsa.</p>

<p style="margin-left:0pt;">Your public key has been saved in /home/hadoop/.ssh/id_rsa.pub.</p>

<p style="margin-left:0pt;">The key fingerprint is:</p>

<p style="margin-left:0pt;">32:63:b7:b0:db:80:29:59:aa:7d:4d:11:d7:00:fb:5d hadoop@lb01</p>

<p style="margin-left:0pt;">The key's randomart image is:</p>

<p style="margin-left:0pt;">+--[ RSA 2048]----+</p>

<p style="margin-left:0pt;">|      ...o       |</p>

<p style="margin-left:0pt;">|      ... .      |</p>

<p style="margin-left:0pt;">|      .o    E    |</p>

<p style="margin-left:0pt;">|      .. . .     |</p>

<p style="margin-left:0pt;">|    . *.S .      |</p>

<p style="margin-left:0pt;">|   + +.B .       |</p>

<p style="margin-left:0pt;">|  + ooo .        |</p>

<p style="margin-left:0pt;">| o .. .+         |</p>

<p style="margin-left:0pt;">|. ..  . .        |</p>

<p style="margin-left:0pt;">+-----------------+</p>
</blockquote>

<blockquote>
<p style="margin-left:0pt;">[hadoop@lb01 ~]$ cd .ssh/</p>

<p style="margin-left:0pt;">[hadoop@lb01 .ssh]$ ls</p>

<p style="margin-left:0pt;">id_rsa  id_rsa.pub</p>
</blockquote>

<p style="margin-left:0pt;">然后把公钥分配给slave节点：</p>

<blockquote>
<p style="margin-left:0pt;">[hadoop@lb01 ~]$ ssh-copy-id -i .ssh/id_rsa.pub hadoop@web01</p>

<p style="margin-left:0pt;">[hadoop@lb01 ~]$ ssh-copy-id -i .ssh/id_rsa.pub hadoop@web02</p>
</blockquote>

<p style="margin-left:0pt;">测试：</p>

<blockquote>
<p style="margin-left:0pt;">[hadoop@lb01 ~]$ ssh web01</p>

<p style="margin-left:0pt;">Last login: Thu Nov  8 23:11:56 2018 from 192.168.231.141</p>

<p style="margin-left:0pt;">[hadoop@web01 ~]$</p>
</blockquote>

<h3 id="%E9%85%8D%E7%BD%AE%E4%B8%A4%E4%B8%AA%E4%BB%8E%E8%8A%82%E7%82%B9" style="margin-left:0pt;">配置两个从节点</h3>

<p style="margin-left:0pt;">将主节点的hadoop2.7和jdk1.8复制到两个从节点(web01,web02，已添加hadoop用户，传完之后，修改属主，属组):</p>

<blockquote>
<p style="margin-left:0pt;">[hadoop@lb01 ~]$ scp -r hadoop2.7/ hadoop@web01:/home/hadoop</p>

<p style="margin-left:0pt;">[hadoop@lb01 ~]$ scp -r jdk1.8/ hadoop@web01:/home/hadoop</p>

<p style="margin-left:0pt;">[hadoop@lb01 ~]$ scp -r hadoop2.7/ hadoop@web02:/home/hadoop</p>

<p style="margin-left:0pt;">[hadoop@lb01 ~]$ scp -r jdk1.8/ hadoop@web02:/home/hadoop</p>
</blockquote>

<p style="margin-left:0pt;">两个从节点都进行chown -R hadoop.hadoop  hadoop2.7/</p>

<blockquote>
<p style="margin-left:0pt;">chown -R hadoop.hadoop  jdk1.8/</p>
</blockquote>

<p style="margin-left:0pt;">传输完之后，添加java和hadoop的安装环境（root用户进行添加，并进行hadoop命令测试），参考上边</p>

<p style="margin-left:0pt;">格式化hadoop</p>

<blockquote>
<p style="margin-left:0pt;">[hadoop@lb01 ~]$ hdfs namenode -format</p>
</blockquote>

<p style="margin-left:0pt;"><span style="color:#f33b45;">18/11/08 23:23:21 INFO util.ExitUtil: Exiting with status 0</span></p>

<p style="margin-left:0pt;">出现 status 0 时为正确</p>

<p style="margin-left:0pt;">用jps查看已启动的hadoop进程</p>

<blockquote>
<p style="margin-left:0pt;">[hadoop@lb01 ~]$ jps</p>

<p style="margin-left:0pt;">12884 ResourceManager</p>

<p style="margin-left:0pt;">13141 Jps</p>

<p style="margin-left:0pt;">12535 NameNode</p>

<p style="margin-left:0pt;">12734 SecondaryNameNode</p>
</blockquote>

<blockquote>
<p style="margin-left:0pt;">[hadoop@web01 ~]$ jps</p>

<p style="margin-left:0pt;">8949 DataNode</p>

<p style="margin-left:0pt;">9175 Jps</p>

<p style="margin-left:0pt;">9051 NodeManager</p>
</blockquote>

<blockquote>
<p style="margin-left:0pt;">[hadoop@web02 ~]$ jps</p>

<p style="margin-left:0pt;">8949 DataNode</p>

<p style="margin-left:0pt;">9175 Jps</p>

<p style="margin-left:0pt;">9051 NodeManager</p>
</blockquote>

<p style="margin-left:0pt;">这样一个简单的Hadoop集群就搭建完成了。</p>

<p> </p>

<p> </p>            </div>
                </div>