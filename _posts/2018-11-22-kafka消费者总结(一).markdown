---
layout:     post
title:      kafka消费者总结(一)
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>   最近项目中大量用到了kafka作为两个系统之间传递消息的中间件，前段时间专门买了两本介绍kafka使用和源码分析的书，最近闲下来了，想对kafka做个小结。kafka Consumer 主要是从kafka上拉取消息的客户端，其基本的使用方法如下：</p><p>  Properties props = new Properties();<br>  props.put("bootstrap.servers", "localhost:9092");  //kafka集群的连接地址<br>  props.put("group.id", "test"); //goupId为test<br>  props.put("enable.auto.commit", "false");//不自动提交offset<br>  props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");//key反序列化类<br>  props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");//value反序列化类<br>  KafkaConsumer&lt;String, String&gt;; consumer = new KafkaConsumer&lt;&gt;(props);<br>  consumer.subscribe(Arrays.asList("foo", "bar")); //订阅foo和bar两个topic<br>  final int minBatchSize = 200; //最小处理批次数<br>  List&lt;ConsumerRecord&lt;String, String&gt;&gt; buffer = new ArrayList&lt;&gt;();<br>  while (true) {<br>      ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);//从服务器集群上拉取消息，阻塞时间100ms<br>      for (ConsumerRecord&lt;String, String&gt; record : records) {<br>          buffer.add(record);<br>      }<br>      if (buffer.size() &gt;= minBatchSize) {<br>          insertIntoDb(buffer);//将消息存入数据库  <br>          consumer.commitSync();//同步提交offset<br>          buffer.clear();<br>      }<br></p><p>  }</p><p>   上面是java版consumer client，使用起来还是比较简单，主要是不断轮询从kafka集群拉取消息。但是这里有一个比较关键的问题，如何保证 insertIntoDb(buffer)和 consumer.commitSync()这两个操作的一致性，一旦insertIntoDb发生异常导致offset没有提交，就可能导致重复消费。kafka官方也考虑到了这个问题，他们的建议是将offset和消息的处理结果放到同一事务（这里的事务可以通过关系型数据的事务来实现）中处理，一旦事务执行成功，则任务消息消费成功，事务回滚则需要重新消费。当发生服务端重启或者Rebalance操作时，消费者可以从关系数据库中找到offset并从此位置消费。</p><p>  那么如何知道消费着发生了Rebance操作呢，可以通过ConsumerRebalanceListener接口开始实现，代码如下：</p><p> public class SaveOffsetsOnRebalance implements ConsumerRebalanceListener {<br>       private Consumer&lt;?,?&gt; consumer;<br> <br>       public SaveOffsetsOnRebalance(Consumer&lt;?,?&gt; consumer) {<br>           this.consumer = consumer;<br>       }<br>       //此方法会在consumer停止拉取数据，Rebalance之前调用<br>       public void onPartitionsRevoked(Collection&lt;TopicPartition&gt; partitions) {<br>           // save the offsets in an external store using some custom code not described here<br>           for(TopicPartition partition: partitions)<br>              saveOffsetInExternalStore(consumer.position(partition));<br>       }<br>       //此方法会在offset重新分配之后，消费者拉取消息之前调用<br>       public void onPartitionsAssigned(Collection&lt;TopicPartition&gt; partitions) {<br>           // read the offsets from an external store using some custom code not described here<br>           for(TopicPartition partition: partitions)<br>              consumer.seek(partition, readOffsetFromExternalStore(partition));<br>       }<br>    }<br></p><p>通过这个接口再rebalance之前保存offset，然后在Rebance之后拉取数据之前读取offset消费。这样可以实现消息传递保证的 Exactly once（从消费端保证不会重复消费或者少消费，生产端还需要做相应的设置），kafka的消息传递保证有三个级别：</p><p>  At most once：至多一次，消息不会重复传递，但可能会丢</p><p>  At least once ：至少一次，消息可能回重复，但肯定不会丢</p><p>  Exactly once：正好一次，消息不会重复，也不会丢</p><p>当然这个三个级别需要kafka 的生产者和消费者同时做相应的设置才能做到的，可以根据不同的业务需求做相应的设置，生产端要做到Exactly once，可以给消息设置全局唯一ID，由消费者进行去重。</p><p><br></p>            </div>
                </div>