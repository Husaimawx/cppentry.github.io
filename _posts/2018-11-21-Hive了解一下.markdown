---
layout:     post
title:      Hive了解一下
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/u011521382/article/details/81560562				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>本文分为5部分：</p>

<ol>
<li>Hive产生背景&amp;Hive是什么？</li>
<li>为什么使用Hive&amp;Hive发展历程</li>
<li>Hive体系架构及部署架构</li>
<li>Hive环境搭建</li>
<li>Hive基本使用</li>
</ol>



<h2 id="1-hive产生背景hive是什么">1. Hive产生背景&amp;Hive是什么？</h2>

<p><strong>MapReduce编程的不便性：</strong> <br>
前面的博文我们介绍了Map Reduce的使用。我们首先要申明一个Map和一个Reduce才能处理作业。代码量大，复杂。而且需要部署jar执行。流程繁琐。 <br>
<strong>HDFS的文件缺少Schema</strong> <br>
关系型数据库里面创建表要指定表名，指定列的名称，列的类型。这些可以理解为Schema。HDFS上是没有Schema的，这样HDFS就无法使用SQL的方式来对分布式系统上的文件进行查询。 <br>
<strong>Hive是什么？</strong></p>

<ul>
<li>由Facebook开源，最初用于解决海量结构化的日志数据统计问题</li>
<li>构建在Hadoop之上的数据仓库</li>
<li>Hive定义了一种类SQL的语言：HQL</li>
<li>通常用于处理离线数据处理（采用MapReduce）</li>
<li>底层支持多种不同的执行引擎（Mapreduce,Tez,Spark） <br>
<ul><li>Hive on Mapreduce</li>
<li>Hive on Tez</li>
<li>Hive on Spark</li></ul></li>
<li>支持多种不同的压缩格式，存储格式以及自定义函数</li>
<li> <br>
看一下官网的介绍：</li>
</ul>

<blockquote>
  <p>APACHE HIVE TM <br>
  The Apache Hive ™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure can be projected onto data already in storage. A command line tool and JDBC driver are provided to connect users to Hive.</p>
</blockquote>

<p>Hive数据仓库可以通过SQL方便地读，写，和管理分布式式存储系统上的大数据集。用户可以使用命令行工具或者JDBC驱动来连接Hive</p>



<h2 id="2为什么使用hivehive发展历程">2.为什么使用Hive&amp;Hive发展历程</h2>

<ol>
<li>简单、容易上手（提供了类SQL的查询语言）</li>
<li>为超大数据集设计的计算/存储扩展能力（MR计算，HDFS存储）</li>
<li>统一的元数据管理（可与Preso/Impala/SparkSQL等共享数据）</li>
</ol>

<p><strong>Hive发展历程</strong> <br>
2007.08诞生于Facebook <br>
2013.05-Hive 0.11.0  <br>
2013.10-Hive 0.12.0 <br>
2014.04-Hive 0.13.0 <br>
2014.11-HIve 0.14.0 <br>
2015.01-Hive 1.0.0 <br>
Hive在Hadoop生态系统中的位置： <br>
<img src="https://img-blog.csdn.net/20180810141828777?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTE1MjEzODI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>



<h2 id="3-hive体系架构及部署架构">3. Hive体系架构及部署架构</h2>

<p><img src="https://img-blog.csdn.net/20180810142303708?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTE1MjEzODI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<p>最上面的shell，和JDBC相当于连接Hive的两个客户端。然后下面是Driver驱动。SQL Parser负责将SQL语句解析成数据库执行计划等等。再往下是MapReduce,所有的SQL都是翻译成Map,Recude作业来执行的。最下面就是HDFS存储系统。 <br>
左边的Metastore 负责元数据管理。它是基于关系型数据库MySQL的。</p>

<p>下面看一下Hive的部署架构: <br>
<img src="https://img-blog.csdn.net/20180810143518976?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTE1MjEzODI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
测试环境HIve可以存放在MySQL ，也可以放在DerBy上。</p>

<p><img src="https://img-blog.csdn.net/20180810143529984?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTE1MjEzODI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>



<h2 id="4-hive环境搭建">4 Hive环境搭建</h2>

<p>1.Hive下载：<a href="http://archive.cloudera.com/cdh5/cdh/5/" rel="nofollow">http://archive.cloudera.com/cdh5/cdh/5/</a> <br>
wget <a href="http://archive.cloudera.com/cdh5/cdh/5/hive-1.1.0-cdh5.7.0.tar.gz" rel="nofollow">http://archive.cloudera.com/cdh5/cdh/5/hive-1.1.0-cdh5.7.0.tar.gz</a> <br>
2.解压：tar -zxvf hive-1.1.0-cdh5.7.0.tar.gz -C ~/opt/ <br>
3.配置 <br>
    系统环境变量 /etc/profile</p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-keyword">export</span> HIVE_HOME=/opt/hive-<span class="hljs-number">1.1</span>.<span class="hljs-number">0</span>-cdh5.<span class="hljs-number">7.0</span>
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">$HIVE_HOME</span>/bin:<span class="hljs-variable">$PATH</span></code></pre>

<p>4.安装MySQL <br>
5.配置hive-site.xml <br>
进入/opt/hive-1.1.0-cdh5.7.0/conf/</p>

<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>jdbc:mysql://localhost:3306/sparksql?createDatabaseIfNotExist=true<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>

    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>

    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>root<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>

    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>root<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>

<p>6.配置hive-env.sh 中的HADOOP_HOME内容。 <br>
7.拷贝MySQL驱动到/opt/hive-1.1.0-cdh5.7.0/lib下。我这里是mysql-connector-java-5.1.27.jar。 <br>
8.启动hive：$HIVE_HOME/bin/hive <br>
<img src="https://img-blog.csdn.net/20180810175737225?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTE1MjEzODI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<p>可以看出hive已经启动成功。我们看下MySQL是否按照hive-site.xml生成sqparksql数据库。 <br>
<img src="https://img-blog.csdn.net/20180810180015961?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTE1MjEzODI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<p><img src="https://img-blog.csdn.net/20180810180136559?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTE1MjEzODI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<p>我们看到sparksql中已经有表产生，这些都是由hive自动产生的，来管理相应的元数据。</p>



<h2 id="5hive基本使用">5.Hive基本使用</h2>

<p><strong>创建表：</strong> <br>
用hive创建表格式：</p>



<pre class="prettyprint"><code class=" hljs sql">`<span class="hljs-operator"><span class="hljs-keyword">CREATE</span>  <span class="hljs-keyword">TABLE</span> table_name 
  [(col_name data_type [COMMENT col_comment])]<span class="hljs-string">`</span></span></code></pre>

<p>我们按照这个格式创建一个表：</p>

<pre class="prettyprint"><code class=" hljs sql"><span class="hljs-operator"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> hive_wordcount(context string);</span></code></pre>

<p><img src="https://img-blog.csdn.net/201808101811180?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTE1MjEzODI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<p>创建成功。下面我们看下MySQL中这个表的内容： <br>
<img src="https://img-blog.csdn.net/20180810181153703?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTE1MjEzODI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<p>可以看到在hive中创建表以后，MySQL中也对应有相应的表生成。 <br>
<strong>下面我们加载数据到hive表</strong>。</p>

<pre class="prettyprint"><code class=" hljs sql"><span class="hljs-operator"><span class="hljs-keyword">LOAD</span> DATA <span class="hljs-keyword">LOCAL</span> INPATH <span class="hljs-string">'filepath'</span> <span class="hljs-keyword">INTO</span> <span class="hljs-keyword">TABLE</span> tablename </span></code></pre>



<pre class="prettyprint"><code class=" hljs sql"><span class="hljs-operator"><span class="hljs-keyword">load</span> data <span class="hljs-keyword">local</span> inpath <span class="hljs-string">'/data/hello.txt'</span> <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> hive_wordcount;</span></code></pre>

<p>执行结果： <br>
<img src="https://img-blog.csdn.net/20180810181447349?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTE1MjEzODI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<p><strong>接下来我们使用sql语句来统计下词频</strong>。</p>

<pre class="prettyprint"><code class=" hljs sql"><span class="hljs-operator"><span class="hljs-keyword">select</span> word, <span class="hljs-aggregate">count</span>(<span class="hljs-number">1</span>) <span class="hljs-keyword">from</span> hive_wordcount lateral <span class="hljs-keyword">view</span> explode(split(context,<span class="hljs-string">' '</span>)) wc <span class="hljs-keyword">as</span> word <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> word;</span>

//lateral view explode(): 是把每行记录按照指定分隔符进行拆解</code></pre>

<p>运行上述代码，hive ql提交执行以后会生成mr作业，并在yarn上运行。 <br>
<em>我这里的环境不知道为啥只要往yarn上提交作业，resourcemanager,nodemanager就会停止运行，jps上就没有进程了。这边这个只做个例子，就不展示结果了。</em></p>

<p>hive就先介绍到这里。</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>