---
layout:     post
title:      HDFS基础操作一览
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：所爱隔山海。					https://blog.csdn.net/tongxinzhazha/article/details/62043551				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>命令基本格式: <br>
hadoop fs -cmd &lt; args &gt;</p>

<p>1.ls <br>
hadoop fs -ls  / <br>
列出hdfs文件系统根目录下的目录和文件 <br>
hadoop fs -ls -R / <br>
列出hdfs文件系统所有的目录和文件</p>

<p>2.put    将本地数据推送到HDFS上 <br>
hadoop fs -put &lt; local file &gt; &lt; hdfs file &gt; <br>
hdfs file的父目录一定要存在,否则命令不会执行</p>

<p>2.1moveFromLocal <br>
hadoop fs -moveFromLocal  &lt; local src &gt; … &lt; hdfs dst &gt; <br>
与put相类似，命令执行后源文件 local src 被删除 <br>
2.2.copyFromLocal <br>
hadoop fs -copyFromLocal  &lt; local src &gt; … &lt; hdfs dst &gt; <br>
保留了原始数据</p>

<p>3.get    复制数据 <br>
hadoop fs -get &lt; hdfs file &gt; &lt; local file or dir&gt; <br>
local file不能和 hdfs file名字不能相同，否则会提示文件已存在，没有重名的文件会复制到本地</p>

<p>hadoop fs -get &lt; hdfs file or dir &gt; … &lt; local  dir &gt; <br>
拷贝多个文件或目录到本地时，本地要为文件夹路径 <br>
注意：如果用户不是root， local 路径要为用户文件夹下的路径，否则会出现权限问题， <br>
3.1.moveToLocal <br>
当前版本中还未实现此命令 <br>
3.2.copyToLocal <br>
hadoop fs -copyToLocal &lt; local src &gt; … &lt; hdfs dst &gt; <br>
与get相类似</p>

<p>4.rm <br>
hadoop fs -rm &lt; hdfs file &gt; … <br>
hadoop fs -rm -r &lt; hdfs dir&gt;… <br>
每次可以删除多个文件或目录</p>

<p>5.mkdir <br>
hadoop fs -mkdir &lt; hdfs path&gt;</p>

<p>只能一级一级的建目录，父目录不存在的话使用这个命令会报错</p>

<p>hadoop fs -mkdir -p &lt; hdfs path&gt;  <br>
所创建的目录如果父目录不存在就创建该父目录</p>

<p>6.getmerge <br>
hadoop fs -getmerge &lt; hdfs dir &gt;  &lt; local file &gt; <br>
将hdfs指定目录下所有文件排序后合并到local指定的文件中，文件不存在时会自动创建，文件存在时会覆盖里面的内容</p>

<p>hadoop fs -getmerge -nl  &lt; hdfs dir &gt;  &lt; local file &gt; <br>
加上nl后，合并到local file中的hdfs文件之间会空出一行</p>

<p>7.cp <br>
hadoop fs -cp  &lt; hdfs file &gt;  &lt; hdfs file &gt; <br>
目标文件不能存在，否则命令不能执行，相当于给文件重命名并保存，源文件还存在 hadoop fs -cp &lt; hdfs file or dir &gt;… &lt; hdfs dir &gt; <br>
目标文件夹要存在，否则命令不能执行</p>

<p>8.mv <br>
hadoop fs -mv &lt; hdfs file &gt;  &lt; hdfs file &gt; <br>
目标文件不能存在，否则命令不能执行，相当于给文件重命名并保存，源文件不存在 <br>
hadoop fs -mv  &lt; hdfs file or dir &gt;…  &lt; hdfs dir &gt; <br>
源路径有多个时，目标路径必须为目录，且必须存在。 <br>
注意：跨文件系统的移动（local到hdfs或者反过来）都是不允许的</p>

<p>9.count <br>
hadoop fs -count &lt; hdfs path &gt; <br>
统计hdfs对应路径下的目录个数，文件个数，文件总计大小  <br>
显示为目录个数，文件个数，文件总计大小，输入路径</p>

<p>10.du <br>
hadoop fs -du &lt; hdsf path&gt;  <br>
显示hdfs对应路径下每个文件夹和文件的大小 <br>
hadoop fs -du -s &lt; hdsf path&gt;  <br>
显示hdfs对应路径下所有文件和的大小 <br>
hadoop fs -du - h &lt; hdsf path&gt;  <br>
显示hdfs对应路径下每个文件夹和文件的大小,文件的大小用方便阅读的形式表示，例如用64M代替67108864</p>

<p>11.text <br>
hadoop fs -text &lt; hdsf file&gt;</p>

<p>将文本文件或某些格式的非文本文件通过文本格式输出</p>

<p>12.setrep <br>
hadoop fs -setrep -R 3 &lt; hdfs path &gt; <br>
改变一个文件在hdfs中的副本个数，上述命令中数字3为所设置的副本个数，-R选项可以对一个人目录下的所有目录+文件递归执行改变副本个数的操作</p>

<p>13.stat <br>
hdoop fs -stat [format] &lt; hdfs path &gt; <br>
返回对应路径的状态信息 <br>
[format]可选参数有：%b（文件大小），%o（Block大小），%n（文件名），%r（副本个数），%y（最后一次修改日期和时间） <br>
可以这样书写hadoop fs -stat %b%o%n &lt; hdfs path &gt;，不过不建议，这样每个字符输出的结果不是太容易分清楚</p>

<p>14.tail <br>
hadoop fs -tail &lt; hdfs file &gt; <br>
在标准输出中显示文件末尾的1KB数据</p>

<p>15.balancer <br>
hdfs balancer <br>
如果管理员发现某些DataNode保存数据过多，某些DataNode保存数据相对较少，可以使用上述命令手动启动内部的均衡过程</p>

<p>16.dfsadmin <br>
hdfs dfsadmin -help <br>
管理员可以通过dfsadmin管理HDFS， <br>
hdfs dfsadmin -report显示文件系统的基本数据 <br>
hdfs dfsadmin -safemode &lt; enter | leave | get | wait &gt; <br>
enter：进入安全模式； <br>
leave：离开安全模式； <br>
get：获知是否开启安全模式；  <br>
wait：等待离开安全模式</p>

<p>17.distcp <br>
用来在两个HDFS之间拷贝数据</p>

<p>18.archive <br>
hadoop archive -archiveName name.har -p &lt; hdfs parent dir &gt; &lt; src &gt;* &lt; hdfs dst &gt; <br>
命令中参数name：压缩文件名，自己任意取；&lt; hdfs parent dir &gt; ：压缩文件所在的父目录；&lt; src &gt;：要压缩的文件名；&lt; hdfs dst &gt;：压缩文件存放路径 <br>
*示例：hadoop archive -archiveName hadoop.har -p /user 1.txt 2.txt /des <br>
示例中将hdfs中/user目录下的文件1.txt，2.txt压缩成一个名叫hadoop.har的文件存放在hdfs中/des目录下，如果1.txt，2.txt不写就是将/user目录下所有的目录和文件压缩成一个名叫hadoop.har的文件存放在hdfs中/des目录下</p>

<p>显示har的内容可以用如下命令： <br>
hadoop fs -ls /des/hadoop.jar</p>

<p>显示har压缩的是那些文件可以用如下命令 <br>
hadoop fs -ls -R har:///des/hadoop.har</p>

<p>注意：har文件不能进行二次压缩。如果想给.har加文件，只能找到原来的文件，重新创建一个。har文件中原来文件的数据并没有变化，har文件真正的作用是减少NameNode和DataNode过多的空间浪费。</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>