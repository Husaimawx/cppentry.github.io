---
layout:     post
title:      第十一天 - 大数据项目结构 - Hive简介与安装配置、基本操作
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h1 id="第十一天-大数据项目结构-hive简介与安装配置基本操作">第十一天 - 大数据项目结构 - Hive简介与安装配置、基本操作</h1>

<p></p><div class="toc">
<ul>
<li><a href="#%E7%AC%AC%E5%8D%81%E4%B8%80%E5%A4%A9-%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84-hive%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C" rel="nofollow">第十一天 - 大数据项目结构 - Hive简介与安装配置、基本操作</a><ul>
<li><ul>
<li><a href="#%E4%B8%80%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%A1%B9%E7%9B%AE%E6%A8%A1%E5%9D%97%E7%AE%80%E4%BB%8B" rel="nofollow">一、大数据项目模块简介</a><ul>
<li><ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E6%BA%90%E7%AE%A1%E7%90%86" rel="nofollow">数据源管理</a></li>
<li><a href="#%E8%AE%A1%E7%AE%97%E4%BB%BB%E5%8A%A1" rel="nofollow">计算任务</a></li>
<li><a href="#%E7%BB%93%E6%9E%9C%E5%B1%95%E7%A4%BA" rel="nofollow">结果展示</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B%E7%AE%A1%E7%90%86" rel="nofollow">数据流程管理</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E4%BA%8C%E5%B0%86%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E5%88%B0linux%E4%B8%AD%E8%BF%90%E8%A1%8C" rel="nofollow">二、将项目部署到Linux中运行</a><ul>
<li><ul>
<li><a href="#%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80" rel="nofollow">项目地址</a></li>
<li><a href="#%E6%AD%A5%E9%AA%A4" rel="nofollow">步骤</a></li>
<li><a href="#%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9" rel="nofollow">注意事项</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E4%B8%89hive%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C" rel="nofollow">三、Hive简介与安装配置、基本操作</a><ul>
<li><ul>
<li><a href="#hive%E7%AE%80%E4%BB%8B" rel="nofollow">Hive简介</a></li>
<li><a href="#hive%E7%9A%84%E7%89%B9%E7%82%B9" rel="nofollow">Hive的特点</a></li>
<li><a href="#hive%E6%9E%B6%E6%9E%84" rel="nofollow">Hive架构</a></li>
<li><a href="#mysql%E8%A1%A5%E5%85%85" rel="nofollow">MySql补充</a></li>
<li><a href="#mysqlrdbms%E4%B8%8Ehive%E5%AF%B9%E6%AF%94" rel="nofollow">MySql(RDBMS)与Hive对比</a></li>
<li><a href="#hive%E5%AD%98%E5%82%A8" rel="nofollow">Hive存储</a></li>
<li><a href="#hive%E5%AE%89%E8%A3%85" rel="nofollow">Hive安装</a></li>
<li><a href="#hive%E5%90%AF%E5%8A%A8" rel="nofollow">Hive启动</a></li>
<li><a href="#%E5%AF%B9hive%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E4%B8%80" rel="nofollow">对Hive的数据基本操作(一)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>




<h3 id="一大数据项目模块简介">一、大数据项目模块简介</h3>



<h5 id="数据源管理">数据源管理</h5>

<ul>
<li><p>给每个用户分配固定的存储路径，根据用户标识分配独有的空间用于存储该用户的数据源和结果输出</p>

<ol><li><p>给每个用户分配固定的存储路径：在项目部署时手动创建；</p>

<p>根据用户标识分配独有的空间：在用户注册时生成对应的路径</p></li>
<li><p>数据源名称和数据文件需要有映射关系，并且能获取输入数据文件路径inputPath</p></li></ol></li>
<li><p>添加数据源</p>

<ol><li>在数据库中进行记录(当前用户的数据表中记录数据文件的相关信息，路径，数据源名称)</li>
<li>上传文件至相应路径</li></ol></li>
<li><p>删除数据源</p>

<ol><li>在数据源列表中选择要删除的数据</li>
<li>清除数据库中的记录信息</li>
<li>在hdfs中将数据文件删除</li></ol></li>
<li><p>数据源信息</p>

<ol><li>数据文件的基本信息：数据名称、数据大小、上传时间等</li>
<li>数据预览，比如展示前20条</li></ol></li>
<li><p>数据源分组</p>

<p>一个用户上传了多份数据源，进行归类分组，对每一个组添加一个标识(组名)</p></li>
</ul>



<h5 id="计算任务">计算任务</h5>

<ul>
<li>在列表中罗列显示当前应用中支持的算法，可以固定写死或者通过配置文件读取展示</li>
<li>向项目中添加算法时，重新编译jar包上传，更改jps页面或者更改web应用配置文件</li>
<li>用户选择相应的算法，生成命令执行所需要的信息</li>
</ul>



<h5 id="结果展示">结果展示</h5>

<ul>
<li>到相应的目录下读取结果文件，展示信息</li>
</ul>



<h5 id="数据流程管理">数据流程管理</h5>

<ul>
<li>记录整个数据处理流程，数据源，计算节点，结果文件，执行顺序，数据流程状态标识</li>
<li>数据流程列表(根据数据流程状态标识区分) <br>
<ol><li>对于已经完成的流程，可以查看结果、重新运行、删除结果、修改执行流程</li>
<li>对于新建的流程，可以进行修改流程、运行</li></ol></li>
<li>数据流程id，记录了节点(包括数据源/计算/展示)以及执行顺序</li>
</ul>



<h3 id="二将项目部署到linux中运行">二、将项目部署到Linux中运行</h3>



<h5 id="项目地址">项目地址</h5>

<p><a href="https://blog.csdn.net/cry970795248/article/details/82596923#%E4%BA%8Cmapreduce%E4%B8%8Eweb%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92%E6%A1%88%E4%BE%8B" rel="nofollow">mapreduce与web进行交互案例</a></p>



<h5 id="步骤">步骤</h5>

<ol>
<li><p>在eclipse中执行导出，导出格式为war</p>

<p>右键项目 – export – war File – 选择输出路径</p></li>
<li><p>使用Xftp将导出的wat文件上传至Linux下的tomcat安装路径下的webapps目录中</p>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536637337801.png" alt="1536637337801" title=""></p></li>
<li><p>启动tomcat，详见<a href="https://blog.csdn.net/cry970795248/article/details/82261437#tomcat%E9%85%8D%E7%BD%AE" rel="nofollow">tomcat配置</a></p></li>
<li><p>通过浏览器访问地址：sz01/WebProject，选择数据源文件和计算任务</p>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536637539310.png" alt="1536637539310" title=""></p>

<p>运行结果：</p>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536637809695.png" alt="1536637809695" title=""></p></li>
</ol>



<h5 id="注意事项">注意事项</h5>

<p>MapReduce执行以队列方式执行，意思是同时跑多个MapReduce任务时，只会执行一个MapReduce任务，其他需要排队等待。所以在同时访问WebProject并且执行任务时，会排队执行MapReduce任务，等待时间较长。</p>



<h3 id="三hive简介与安装配置基本操作">三、Hive简介与安装配置、基本操作</h3>

<p>本文以hive-1.2.2作为学习版本。</p>



<h5 id="hive简介">Hive简介</h5>

<p>Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能(Hive SQL，简称HQL)。 Hive使用HDFS作为数据存储，核心工作是将hql语句转换为MapReduce任务运行，默认使用Hadoop中的yarn作为资源调度系统。</p>



<h5 id="hive的特点">Hive的特点</h5>

<ul>
<li>可扩展 <br>
Hive可以自由的扩展集群的规模，一般情况下不需要重启服务。</li>
<li>延展性 <br>
Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。</li>
<li>容错 <br>
良好的容错性，节点出现问题SQL仍可完成执行。</li>
</ul>



<h5 id="hive架构">Hive架构</h5>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536662394339.png" alt="1536662394339" title=""></p>

<p>Hive包含用户访问接口（CLI、JDBC/ODBC、Web GUI和Thrift Server）、元数据存储（Metastore）、驱动组件（编译器、优化器、执行器）。 　　</p>

<p>用户访问接口即用户用来访问Hive数据仓库所使用的工具接口。 </p>



<h5 id="mysql补充">MySql补充</h5>

<p>数据库(mysql)包含数据文件、数据元信息，其中数据文件在本地磁盘中进行存储，而数据元信息记录表结构(表名，字段名，列名)，记录在特定的数据表中。</p>

<p>mysql数据库，在库information_schema中，表schemata存储数据库信息，tables存储表的信息</p>

<p>schemata：</p>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536663178489.png" alt="1536663178489" title=""></p>

<p>tables：</p>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536663238987.png" alt="1536663238987" title=""></p>



<h5 id="mysqlrdbms与hive对比">MySql(RDBMS)与Hive对比</h5>

<table>
<thead>
<tr>
  <th>项目</th>
  <th>MySql</th>
  <th>Hive</th>
</tr>
</thead>
<tbody><tr>
  <td>数据存储</td>
  <td>本地磁盘</td>
  <td>HDFS</td>
</tr>
<tr>
  <td>执行器</td>
  <td>Executor</td>
  <td>MapReduce</td>
</tr>
<tr>
  <td>数据插入</td>
  <td>批量/单条</td>
  <td>批量/单条</td>
</tr>
<tr>
  <td>数据操作</td>
  <td>以行位单位更新删除</td>
  <td>覆盖追加</td>
</tr>
<tr>
  <td>处理数据规模</td>
  <td>小</td>
  <td>大</td>
</tr>
<tr>
  <td>处理数据延迟</td>
  <td>低</td>
  <td>高</td>
</tr>
<tr>
  <td>分区</td>
  <td>支持</td>
  <td>支持</td>
</tr>
<tr>
  <td>拓展性</td>
  <td>弱</td>
  <td>强</td>
</tr>
<tr>
  <td>数据加载模式</td>
  <td>写时模式</td>
  <td>读时模式</td>
</tr>
</tbody></table>


<p>对数据的操作：</p>

<ul>
<li><p>小数据量：</p>

<p>MySql先进行数据校验，数据是否符合格式，符合才能追加写入数据文件；</p>

<p>Hive直接通过插入语句生成新的数据，在相应的目录下创建新的文件，由于在集群进行操作，所以需要创建多个文件，各个节点的数据进行同步。</p>

<p>由于数据量小，所以Hive所花费的时间大部分花在了数据节点之间的通信、同步上，所以小数据量时的感受是mysql速度快于hive。</p></li>
<li><p>大数据量：</p>

<p>MySq支持l批量sql、结构化文件导入，首先获取数据元信息(结构信息)，然后对数据库中的数据进行变更；</p>

<p>Hive则是将数据文件(本地磁盘)上传或移动到hdfs对应目录下，需要进行查询计算时再读取元信息，得出结果。</p></li>
</ul>

<p>写时模式与读时模式对比：</p>

<p>MySql：写时模式，当数据发生变化时(数据插入)进行校验</p>

<p>Hive：读时模式，写入数据时是将数据文件移动到了目标文件夹下，当数据被使用时(查询数据、计算数据)才进行校验，容错性较强，当数据格式不对应时也不会立即报错，</p>



<h5 id="hive存储">Hive存储</h5>

<ul>
<li>Hive同样包含数据文件、数据元信息，其中数据文件存储在hdfs上，数据元信息则借助mysql存储。</li>
<li>hive管理的库在hdfs储存为文件夹，warehouse为default库所在的路径，其他的库以.db为结尾(存储路径可在hive-site.xml中进行配置)；</li>
<li>hive管理的表在hdfs存储为文件夹，在相应的库文件夹下，存储的是各个表文件夹</li>
<li>hive管理的表的数据在hdfs存储为文件，在相应的表文件夹下</li>
</ul>



<h5 id="hive安装">Hive安装</h5>

<ol>
<li><p>通过官网下载apache-hive-1.2.2-bin.tar.gz</p></li>
<li><p>将apache-hive-1.2.2-bin.tar.gz通过Xftp上传至CentOS的bigdata用户家目录</p></li>
<li><p>解压缩</p>

<blockquote>
  <p>tar -zxvf apache-hive-1.2.2-bin.tar.gz</p>
</blockquote></li>
<li><p>配置</p>

<ul><li><p>用户环境变量</p>

<p>修改.bash_profie</p>

<blockquote>
  <p>vi .bash_profile</p>
  
  <p>添加两行</p>
  
  <p>HIVE_HOME=/home/bigdata/apache-hive-1.2.2-bin</p>
  
  <p>PATH=<span>$</span>PATH:<span>$</span>HIVE_HOME/bin</p>
</blockquote>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536650785738.png" alt="1536650785738" title=""></p>

<p>保存退出</p>

<p>刷新配置文件</p>

<blockquote>
  <p>source .bash_profile</p>
</blockquote>

<p>通过which hive命令检测环境变量是否配置成功</p></li>
<li><p>配置文件</p>

<p>hive-site.xml</p>

<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-pi">&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;</span>
<span class="hljs-pi">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
<span class="hljs-comment">&lt;!--配置hive元数据存储使用的数据库连接驱动名--&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-comment">&lt;!--配置hive元数据存储使用的数据库URL和存储库位置(是否自动创建)--&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>jdbc:mysql://SZ01:3306/hive?createDatabaseIfNotExist=true<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-comment">&lt;!--配置hive元数据存储使用的数据库连接用户名--&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>root<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-comment">&lt;!--配置hive元数据存储使用的数据库连接密码--&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>root<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-comment">&lt;!-- 
&lt;!--配置hive数据可视化需要的包--&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>hive.hwi.war.file<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>lib/hive-hwi-1.2.2.war<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
--&gt;
<span class="hljs-comment">&lt;!--配置hive数据文件在hdfs中的存储位置，如果未配置则默认/user/hive/warehouse--&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>/user/hive/warehouse<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>

<p>hive-log4j.properties(19-21行)</p>

<pre class="prettyprint"><code class=" hljs avrasm">
<span class="hljs-preprocessor">#日志级别</span>

hive<span class="hljs-preprocessor">.root</span><span class="hljs-preprocessor">.logger</span>=DEBUG,DRFA

<span class="hljs-preprocessor">#日志存储目录</span>

hive<span class="hljs-preprocessor">.log</span><span class="hljs-preprocessor">.dir</span>=/home/${user<span class="hljs-preprocessor">.name</span>}

<span class="hljs-preprocessor">#日志名</span>

hive<span class="hljs-preprocessor">.log</span><span class="hljs-preprocessor">.file</span>=hive<span class="hljs-preprocessor">.log</span></code></pre></li>
<li><p>引入jdbc的jar包</p>

<p>将mysql-connector-java-5.1.46-bin.jar放在hive安装路径下的lib目录中</p></li>
<li><p>修改mysql在任何host下都能以root的用户密码登录</p>

<ol><li>使用命令启动mysql，注意加上-h选项</li></ol>

<blockquote>
  <p>mysql -u root -h sz01 -p</p>
</blockquote>

<ol><li>修改密码</li></ol>

<blockquote>
  <p>set password=password(‘root’)</p>
</blockquote>

<ol><li>刷新权限</li></ol>

<blockquote>
  <p>flush privileges</p>
</blockquote></li></ul></li>
</ol>



<h5 id="hive启动">Hive启动</h5>

<p>可以直接使用hive命令启动hive客户端</p>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536666015555.png" alt="1536666015555" title=""></p>

<p>hive启动成功后，会根据hive-site.xml和hive-log4j.properties配置文件在对应的mysql数据库中生成相应的表，在对应的位置创建日志文件</p>

<ul>
<li><p>通过navicat远程连接至CentOS中的mysql查看</p>

<ol><li><p>创建库</p>

<blockquote>
  <p>create database test;</p>
</blockquote>

<p>库hive中表DBS存储了创建库的信息</p>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536666223360.png" alt="1536666223360" title=""></p>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536655169705.png" alt="1536655169705" title=""></p>

<p>hdfs中/user/hive/warehouse目录下创建了对应的数据库test.db文件夹用于存储表文件夹</p></li></ol>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536655202469.png" alt="1536655202469" title=""></p>

<ol><li><p>创建表</p>

<blockquote>
  <p>use test;</p>
  
  <p>create table t1(</p>
  
  <p>c1 int</p>
  
  <p>);</p>
</blockquote>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536655419374.png" alt="1536655419374" title=""></p>

<p>库hive中表TBLS存储了创建表的信息</p>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536655400714.png" alt="1536655400714" title=""></p>

<p>库hive中表记录表信息</p>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536655437759.png" alt="1536655437759" title=""></p>

<p>hdfs中/user/hive/warehouse/test.db目录下创建了对应的表文件夹用于存储表数据文件</p>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536655467476.png" alt="1536655467476" title=""></p></li></ol></li>
</ul>



<h5 id="对hive的数据基本操作一">对Hive的数据基本操作(一)</h5>

<ol>
<li><p>插入数据</p>

<blockquote>
  <p>insert into t1 values (1);</p>
  
  <p>insert into t1 values (2);</p>
</blockquote>

<p>插入数据后，将存储在hdfs中相应的表文件夹下</p>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536655826353.png" alt="1536655826353" title=""></p></li>
<li><p>创建第二个表，第二个表有两列</p>

<blockquote>
  <p>create table t2(</p>
  
  <p>c1 int,</p>
  
  <p>c2 int</p>
  
  <p>);</p>
</blockquote>

<p>插入数据</p>

<blockquote>
  <p>insert into t2 values(3,3);</p>
</blockquote>

<p>当表出现多个列时，查看hdfs中存储的hive数据文件，会有一个制表符进行分割</p>

<p><img src="https://day11-1253629415.cos.ap-guangzhou.myqcloud.com/1536656613837.png" alt="1536656613837" title=""></p></li>
<li><p>将结构化数据文件导入到hive表中</p>

<p>数据导入时，需要指定行分隔符，列分隔符，通过这两个分隔符去解析文件中的数据</p>

<p>如数据文件1内容为：</p>

<pre class="prettyprint"><code class=" hljs ">aaa,bbb,ccc;111,222,333;
ddd,eee,fff;444,555,666;
ggg,hhh,iii;777,888,999;</code></pre>

<p>当指定行分隔符为”;”，列分隔符为”,”时，以上文件则解析为六行，每行有三列数据。</p>

<p>指定的分隔符必须与文件中的分隔符相一致，否则虽然导入时不会出问题，但是在读取、操作数据时就会出现错误</p>

<p>例如：</p>

<p>数据文件2内容为：以“-”为列分隔符，”\n“为行分隔符</p>

<pre class="prettyprint"><code class=" hljs tex">1-1-1<span class="hljs-command">\n</span>
2-2-2<span class="hljs-command">\n</span>
3-3-3<span class="hljs-command">\n</span></code></pre>

<p>将此文件作为数据导入源文件</p>

<p>此时有一个表test，以c1 int, c2 int, c3 int为表数据结构，当读取此导入的数据时，期待的数据应该是</p>

<pre class="prettyprint"><code class=" hljs ">1 1 1
2 2 2
3 3 3</code></pre>

<p>但此时如果指定了以“\n”为行分隔符，“,”为列分隔符进行读取时，读取到的数据将会是：</p>

<pre class="prettyprint"><code class=" hljs cs"><span class="hljs-number">1</span>-<span class="hljs-number">1</span>-<span class="hljs-number">1</span> <span class="hljs-keyword">null</span> <span class="hljs-keyword">null</span>
<span class="hljs-number">2</span>-<span class="hljs-number">2</span>-<span class="hljs-number">2</span> <span class="hljs-keyword">null</span> <span class="hljs-keyword">null</span>
<span class="hljs-number">3</span>-<span class="hljs-number">3</span>-<span class="hljs-number">3</span> <span class="hljs-keyword">null</span> <span class="hljs-keyword">null</span></code></pre>

<p>不符合预期，所以在读取数据时需要指定与源文件向符合的行、列分隔符。</p></li>
</ol>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>