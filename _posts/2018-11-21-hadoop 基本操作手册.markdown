---
layout:     post
title:      hadoop 基本操作手册
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/qq359605040/article/details/45669781				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<pre><code class="language-java">####hdfs
./bin/hdfs dfs -mkdir /user
./bin/hdfs dfs -mkdir /user/Administrator
./bin/hdfs dfs -chmod 777 /user/Administrator
 bin/hadoop dfs -put /home/logonuser/hadoop-2.6.0/aa.txt /lbda/
bin/hadoop dfs -ls /

查看hdfs 50070
    mapreduce  8088
		 
####mapreduce执行jar
hadoop jar wordcount.jar org.apache.hadoop.examples.WordCount /lbda/rtd/2015/04/DT_CDMA_20150408_1 /lbda/output

mapreduce设置输出分隔符
job.getConfiguration().set("mapred.textoutputformat.separator", "\t");

####hive创建表
create table test(type1 string,type2 string,type3 string)row format delimited fields terminated by ','
####外部表
create EXTERNAL table IF NOT EXISTS testrtd 
(type1 string,type2 string, type3 string, type4 string, type5 string,type6 string, type7 string,type8 string,type9 string,type10 string,type11 string)  
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' location '/lbda/rtd/2015/04';
####hive导出hdfs
insert overwrite  directory '/lbda/count' 
select count(*) from ( select type1,type2,type3,row_number() over (distribute by type1,type3) as rn  from test ) t where t.rn=1

####hdfs导入hive
load data inpath '/lbda/asd' into table test;

hive服务启动
hive --service hiveserver2 &amp;
启动元数据存储服务
hive --service metastore &amp;
查看hive错误
hive -hiveconf hive.root.logger=DEBUG,console
修改mysql数据库编码
alter database hive character set latin1 
 
 
hive服务端启动查看
./beeline
 !connect jdbc:hive2://172.17.5.120:10000</code></pre><span style="font-size:14px;"><br><br></span>
            </div>
                </div>