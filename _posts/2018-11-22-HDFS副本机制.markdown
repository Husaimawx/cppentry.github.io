---
layout:     post
title:      HDFS副本机制
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/weixin_39216383/article/details/78841983				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<ul>
<li>为什么要出现HDFS？ <br>
<ul><li>首先要说起hdfs的由来，hdfs由谷歌最先研发，其需求是单独一台计算机所能存储的空间是有限的，而随着计算机存储空间的加大，其价格是呈几何倍的增长，所以就有了hdfs的产生，hdfs架构在相对廉价的计算机上，以分布式的方式，这样想要扩大空间只要增加集群的数量就可以</li></ul></li>
<li><p>为什么hdfs需要副本机制？</p>

<ul><li>在上个问题的时候，我说过我们需要的是大量相对廉价的计算机，那么宕机就是一种必然事件，我们需要让数据避免丢失，就只有采取冗余数据存储，而具体的实现就是副本机制</li></ul></li>
<li><p>这是副本机制的官网图解</p></li>
</ul>

<p><img src="https://img-blog.csdn.net/20171219131807069?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VpeGluXzM5MjE2Mzgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这是官网对于HDFS副本机制的描述" title=""> <br>
地址：<a href="http://hadoop.apache.org/docs/r2.8.3/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" rel="nofollow">http://hadoop.apache.org/docs/r2.8.3/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html</a></p>

<ul>
<li>三副本机制详解（三个以上的随机存储） <br>
第一副本：如果上传节点是DN，则上传该节点；如果上传节点是NN，则随机选择DN <br>
第二副本：放置在不同机架的DN上 <br>
第三副本：放置在与第二副本相同机架的不同DN上</li>
<li>副本机制的作用 <br>
<ul><li>极大程度上避免了宕机所造成的数据丢失（除非命不好）</li>
<li>可以在数据读取时进行数据校验</li></ul></li>
</ul>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>