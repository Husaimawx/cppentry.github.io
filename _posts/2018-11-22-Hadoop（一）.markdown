---
layout:     post
title:      Hadoop（一）
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <ul><li>
	<p id="main-toc"><strong>目录</strong></p>

	<p id="-toc" style="margin-left:80px;"> </p>

	<p id="Hadoop%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D-toc" style="margin-left:80px;"><a href="#Hadoop%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D" rel="nofollow">Hadoop背景介绍</a></p>

	<p id="Hadoop%E7%94%9F%E4%BA%A7%E8%83%8C%E6%99%AF-toc" style="margin-left:80px;"><a href="#Hadoop%E7%94%9F%E4%BA%A7%E8%83%8C%E6%99%AF" rel="nofollow">Hadoop生产背景</a></p>

	<p id="Hadoop%E5%9C%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%AD%E4%BD%8D%E7%BD%AE%E5%92%8C%E5%85%B3%E7%B3%BB-toc" style="margin-left:80px;"><a href="#Hadoop%E5%9C%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%AD%E4%BD%8D%E7%BD%AE%E5%92%8C%E5%85%B3%E7%B3%BB" rel="nofollow">Hadoop在大数据云计算中位置和关系</a></p>

	<p id="Hadoop%E6%A1%88%E4%BE%8B-toc" style="margin-left:80px;"><a href="#Hadoop%E6%A1%88%E4%BE%8B" rel="nofollow">Hadoop案例</a></p>

	<p id="Hadoop%E9%87%8D%E8%A6%81%E7%BB%84%E4%BB%B6-toc" style="margin-left:80px;"><a href="#Hadoop%E9%87%8D%E8%A6%81%E7%BB%84%E4%BB%B6" rel="nofollow">Hadoop重要组件</a></p>

	<p id="%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-toc" style="margin-left:80px;"><a href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F" rel="nofollow">什么是分布式系统</a></p>

	<p id="%E7%A6%BB%E7%BA%BF%E6%95%B0%E6%8D%AE%E7%9A%84%E5%88%86%E6%9E%90%E6%B5%81%E7%A8%8B-toc" style="margin-left:80px;"><a href="#%E7%A6%BB%E7%BA%BF%E6%95%B0%E6%8D%AE%E7%9A%84%E5%88%86%E6%9E%90%E6%B5%81%E7%A8%8B" rel="nofollow">离线数据的分析流程</a></p>

	<p id="Hadoop%E5%8D%95%E6%9C%BA%E7%89%88%E5%AE%9E%E9%99%85%E6%93%8D%E4%BD%9C-toc" style="margin-left:80px;"><a href="#Hadoop%E5%8D%95%E6%9C%BA%E7%89%88%E5%AE%9E%E9%99%85%E6%93%8D%E4%BD%9C" rel="nofollow">Hadoop单机版实际操作</a></p>

	<p id="HDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-toc" style="margin-left:80px;"><a href="#HDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F" rel="nofollow">HDFS分布式文件系统</a></p>

	<p id="HDFS%E7%9A%84%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%E5%92%8C%E4%BD%9C%E7%94%A8-toc" style="margin-left:80px;"><a href="#HDFS%E7%9A%84%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%E5%92%8C%E4%BD%9C%E7%94%A8" rel="nofollow">HDFS的核心设计思想和作用</a></p>

	<p id="NameNode%E5%92%8CDataNode-toc" style="margin-left:80px;"><a href="#NameNode%E5%92%8CDataNode" rel="nofollow">NameNode和DataNode</a></p>

	<p id="HDFS%E5%9C%A8Hadoop%E4%B8%AD%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9E%8B%EF%BC%9A-toc" style="margin-left:80px;"><a href="#HDFS%E5%9C%A8Hadoop%E4%B8%AD%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9E%8B%EF%BC%9A" rel="nofollow">HDFS在Hadoop中存储模型：</a></p>

	<p id="%E2%80%8B-toc" style="margin-left:80px;"><a href="#%E2%80%8B" rel="nofollow">​</a></p>

	<hr id="hr-toc"></li>
	<li>
	<h3 id="Hadoop%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D">Hadoop背景介绍</h3>

	<ul><li>Apache Hadoop是一个可靠的，可扩展的分布式计算开发软件</li>
		<li>Apache Hadoop可以理解为一个框架，它允许使用简单的编程模型来计算分布式的大型数据集合（海量数据）</li>
		<li><a href="http://hadoop.apache.org/" rel="nofollow">http://hadoop.apache.org/</a> 官网</li>
		<li>包括模块</li>
	</ul><ol><li>Hadoop Common ： Hadoop的一些模块工具</li>
		<li>Hadoop 分布式文件系统（HDFS）：一种分布式文件系统，它可以提供应用程序的高吞吐量的访问</li>
		<li>Hadoop YARN：作业调度和集群资源管理的框架</li>
		<li>Hadoop MapReduce：是一种用于处理大型数据集的基于YARN的系统（分布式计算框架）</li>
		<li>上述每个模块都有自己独立的功能，而模块和模块之间又有一种联系</li>
	</ol></li>
	<li>
	<h3 id="Hadoop%E7%94%9F%E4%BA%A7%E8%83%8C%E6%99%AF">Hadoop生产背景</h3>

	<ol><li>雏形开始于2002年Apache的Nutch，Nutch是由java开发的一个搜索引擎，它包含了所有搜索引擎所需要的全部工具
		<ol><li>包括全文搜索</li>
			<li>web爬虫</li>
		</ol></li>
		<li>Nutch的目的是设计一个发行的全网络的搜索引擎
		<ol><li>包括，抓取</li>
			<li>索引</li>
			<li>查询等功能</li>
		</ol></li>
		<li>随着网络的发展，碰到了一个瓶颈
		<ol><li>如何解决10亿网页的存储和索引问题：2003年google发表了一篇学术论文谷歌文件系统（GFS），goodle公司为了存储海量搜索数据设计的专用文件系统，2004年Nutch创始人（DougCutting）基于GFS的论文，实现了分布式文件存储系统（HDFS）</li>
			<li>2003-2004年，Google公开了部分GFS和MapReduce的思想细节，以此为基础Doug Cutting 等人用两年业余时间，实现了DFS和MapReduce机制的一个微缩版的Nutch</li>
			<li>2004年，Google又发表了一个技术学术论文（MapReduce），MapReduce是一种编程编程模型用于大规模数据集（大于1TB）的处理和并计算</li>
			<li>2005年Doug Cutting 又基于MapReduce在Nutch搜索开发了该功能</li>
		</ol></li>
	</ol></li>
	<li>
	<h3 id="Hadoop%E5%9C%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%AD%E4%BD%8D%E7%BD%AE%E5%92%8C%E5%85%B3%E7%B3%BB">Hadoop在大数据云计算中位置和关系</h3>

	<ul><li>云计算是分布式计算，并行技术，网络计算，多核计算，网络存储，虚拟化，负载均衡等传统的额计算和互联网技术融合的一个产物</li>
	</ul><ol><li>现阶段云计算的底层两大技术支撑
		<ol><li>虚拟化：</li>
			<li>大数据技术：</li>
			<li>Hadoop则是云计算平台即服务的解决方案</li>
		</ol></li>
		<li>云计算分为几大类
		<ol><li>laaS：基础设施即服务</li>
			<li>PaaS：平台即服务</li>
			<li>SaaS：软件即服务</li>
		</ol></li>
	</ol></li>
	<li>
	<h3 id="Hadoop%E6%A1%88%E4%BE%8B">Hadoop案例</h3>

	<ol><li>大型网站web服务器的日志分析：一个大型网站的web服务器就能，每5分钟就收录的点击量就高达800GB（小型的除以2/3）左右，峰值点击可以达到每秒900万次，每隔5分钟将数据装在内存中，高速计算网站的热点url，并将这些信息反馈前段缓存服务器，以提高缓存命中率</li>
		<li>运营商流量分析，每天的流量数据在2TB-5TB之间，拷贝到HDFS上，通过交互式分析引擎模板，能够运行几百个复杂的数据清洗，ETL（数据清洗：拿到想要的数据），报表业务，总时间类似的硬件配置的小集群（DB2）要快2-3倍</li>
		<li>程序交通卡扣视频监控信息实时分析，采用基于流式进行全省范围的交通卡扣的监控的信息实时的进行分析，警告，和统计，可以对全省范围内未年检等车辆在300毫秒左右就可以得到结论进行警告</li>
	</ol></li>
	<li>
	<h3 id="Hadoop%E9%87%8D%E8%A6%81%E7%BB%84%E4%BB%B6">Hadoop重要组件</h3>

	<ol><li>HDFS：分布式文件系统</li>
		<li>MapReduce：分布式计算框架</li>
		<li>Hive：基于大数据技术的SQL数据仓库工具（文件系统+运算框架）</li>
		<li>HBASE：基于Hadoop的分布式海量数据库（NOSQL（非关系型数据库）属于列式存储）</li>
		<li>ZooKeeper：分布式系统协调服务基础组件</li>
		<li>Oozie：工作流调度框架</li>
		<li>Sqoop：数据导入导出工具</li>
		<li>Flume：日志数据采集框架</li>
		<li>Mahout：基于MapReduce/spark/flink等分布式框架的机器学习算法库</li>
	</ol></li>
	<li>
	<h3 id="%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F">什么是分布式系统</h3>

	<ol><li>分布式软件系统：
		<ol><li>是由一组通过网络进行通信，为了完成共同的任务而协调工作的计算机节点所组成的系统</li>
			<li>分布式系统的出现为了廉价，普通的机器完成单个计算机无法完成的计算，存储等任务，其目的就是充分利用计算机来处理更多的任务</li>
		</ol></li>
		<li>常用的分布式软件系统的案例
		<ol><li>web服务器集群，单台服务器的性能和资源是有限的，支持的连接并发数也是有限的，因此必须采用多台服务器集群的方式才能提供并发数据和计算机计算速度</li>
			<li>每台web服务器分配一个域名，肯定是同一个域名的进入的是同一个入口<br>
			百度有上千台web服务器，此时我们使用www.baidu.com一个入口进行访问，至于哪台服务器提供我们服务，具体的就需要底层实现一个技术</li>
		</ol></li>
	</ol></li>
	<li>
	<h3 id="%E7%A6%BB%E7%BA%BF%E6%95%B0%E6%8D%AE%E7%9A%84%E5%88%86%E6%9E%90%E6%B5%81%E7%A8%8B">离线数据的分析流程</h3>

	<blockquote>
	<ol><li>web日志数据挖掘，<br>
		案例分析：</li>
		<li>网站点击流量日志数据挖掘系统，<br>
		需求：<br>
		web点击流日志，包含着网站运行的重要信息，通过日志的分析，我们就可以知道网站的访问量，那网页访问人数最多，哪个网站页最有价值，广告转换率，方可的来源信息，访客的终端信息<br>
		数据来源：<br>
		获取方式：在页面处理一段js程序，为了页面想要监听的标签绑定时间，只要用户点击或触发，就可以达到用户的信息，并产生日志文件<br>
		数据处理流程：
		<ol><li>数据采集：定制开发程序或使用Flume</li>
			<li>数据预处理：定制开发MapReduce程序运行在Hadoop计算</li>
			<li>数据库计算：基于Hadoop智商使用Hive技术完成数仓<br>
			数仓中会完成数据清洗ETL</li>
			<li>数据导出：需要使用sqoop将数据导出</li>
			<li>数据可视化：就有web人员完成</li>
		</ol></li>
	</ol></blockquote>
	</li>
	<li>
	<h3 id="Hadoop%E5%8D%95%E6%9C%BA%E7%89%88%E5%AE%9E%E9%99%85%E6%93%8D%E4%BD%9C">Hadoop单机版实际操作</h3>

	<ol><li>Hadoop是java开发的，需要在服务器上安装相对应的JDK1.7<br>
		Linux默认自带JDK----&gt;open.JDK----&gt;Hadoop不能应用open.JDK</li>
		<li>将当前Hadoop安装包上传到服务器端，Hadoop版本是2.x版本----&gt;2.7.1<br>
		在实际开发中若需要其他安装包（看不懂，就翻译）</li>
		<li>进行解压tar -zxvf hadoop-2.7.1.tar.gz -C /opt/software，解压到新建目录：opt/software/<br><img alt="" class="has" src="https://img-blog.csdn.net/20180917140934831?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjc2NDU1Ng==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></li>
		<li>bin：Hadoop最近管理脚本个使用的目录<br><img alt="" class="has" src="https://img-blog.csdn.net/2018091718444074?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjc2NDU1Ng==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"><br>
		etc：Hadoop配置文件所在目录<br>
		包：core-site.xml hdfs-site.xml yarn-site.xml mapred-site.xml<br>
		include：对外提供的编程库文件（具有存在静态和动态链接，这些都是C++定义，通常适用于C++成员编写MapReduce）<br>
		sbin：Hadoop管理脚本的目录，包含HDFS和YARN的各种启动服务<br>
		share：Hadoop各个模块编译后jar包所在目录<br>
		lib：包含Hadoop对外提供的编译</li>
		<li>Hadoop环境变量配置：<br>
		进入编辑：vi  /etc/profile<br>
		export JAVA_HOME=/bigdata/app/jdk1.7.0_79<br>
		export HADOOP_HOME=/opt/software/hadoop-2.7.1<br>
		export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:</li>
		<li>配置hadoop-env.sh中的jdk路径<br>
		cd /opt/software/hadoop-2.7.1/<br>
		cd ./etc<br>
		cd ./hadoop/<br>
		命令：vi hadoop-env.sh<br><img alt="" class="has" height="108" src="https://img-blog.csdn.net/20180917185436468?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjc2NDU1Ng==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="653"></li>
		<li>让环境变量生效：<br>
		source /etc/profile<br>
		pwd</li>
		<li>测试Hadoop是否生效<br>
		hadoopversion</li>
		<li>查看Hadoop<br><img alt="" class="has" src="https://img-blog.csdn.net/20180917143311469?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjc2NDU1Ng==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></li>
		<li>上传文件之后运行了一个程序，这个程序是：wordCount.txt<br><img alt="" class="has" src="https://img-blog.csdn.net/20180917145425529?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjc2NDU1Ng==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"><br>
		hadoop：是命令，执行jar包<br>
		路径：是当前jar包所在的路径，wordcount是当前jar的类，是单词统计方法<br>
		后面第一个路径是数据文件所存在的路径，第二个路径是得到结果输出的路径（成功后自动创建）<br><img alt="" class="has" src="https://img-blog.csdn.net/20180917145659842?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjc2NDU1Ng==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"><br>
		然后在查看会出现个两个文件，SUCCESS是代表执行成功<br>
		另一个文件是数据存放的文件，将结果直接打印到文件中</li>
	</ol></li>
	<li>
	<h3 id="HDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F">HDFS分布式文件系统</h3>

	<ol><li><strong>HDFS（Hadoop Distributed File System）介绍：</strong>

		<ol><li>HDFS是源于Google的一篇技术论文GFS，HDFS是GFS的一个克隆</li>
			<li>HDFS易于扩展你的分布式文件系统，运行在大量普通廉价的机器上，提供容错机制，为大量用户提供性能不错的文件存取服务，</li>
		</ol></li>
		<li><strong>HDFS设计目标：</strong>
		<ol><li>自动快速的检测应对硬件错误</li>
			<li>流式的访问数据</li>
			<li><span style="color:#f33b45;">移动计算</span>比<span style="color:#f33b45;">移动数据</span>本身更划算<br>
			移动计算：就是把计算任务下发到数据所在的节点进行处理<br>
			移动数据：就是将数据移动到计算任务节点，这样就损耗了大量的网络开销，导致流量激增，处理效率低</li>
			<li>简单一致性模型</li>
			<li>构建平台可移植性好</li>
		</ol></li>
		<li><strong>HDFS的优点：</strong>
		<ol><li>高可靠性：Hadoop按位存储和处理数据的能力强</li>
			<li>高扩展性：Hadoop是在可用的计算机集群中分配数据完成计算计算任务</li>
			<li>高效性：Hadoop能够站在节点之间动态的移动数据，并保持每个节点的动态平衡</li>
			<li>高容错性：Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配</li>
		</ol></li>
		<li><strong>HDFS的缺点：</strong>
		<ol><li>不适合低延迟访问</li>
			<li>无法达到存储大量小文件</li>
			<li>不支持多用户写入任意修改文件</li>
		</ol></li>
	</ol></li>
	<li>
	<h3 id="HDFS%E7%9A%84%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%E5%92%8C%E4%BD%9C%E7%94%A8">HDFS的核心设计思想和作用</h3>

	<ol><li>.HDSF中文件在物理上是分块存储(block),块的大小可以通过参数(dfs.blocksize)来设置<br>
		默认大小Hadoop2.x版本中默认大小128M , hadoop1.x版本即使64M</li>
		<li>HDFS文件系统会给客户端提供一个统一的抽象目录树,通过客户端对相应路径下的文件进行访问</li>
		<li>目录结构及文件的分块信息(元数据)都由<span style="color:#f33b45;"><strong>NameNode</strong></span>节点承担<br><strong>NameNode</strong>是HDFS集合中的主节点,负责维护整个HDFS文件系统的目录树,以及每一个路径所对应的Block块信息 (block是id以及所在<span style="color:#f33b45;"><strong>DataNode</strong></span>服务器)</li>
		<li>文件的各个block块存储的管理DataNode来节点进行管理<br>
		DataNode是HDFS集群的从节点,每一个Block都可以在多个DataNode上存储多个副本(副本数量是可以设置 dfs.replication)</li>
	</ol></li>
	<li>
	<h3 id="NameNode%E5%92%8CDataNode">NameNode和DataNode</h3>

	<ol><li><strong>NameNode</strong>：是整个文件系统的管理节点。它维护着整个文件系统的文件目录树，文件/目录的元信息和每个文件对应的数据块列表。接收用户的操作请求。

		<ol><li>文件包括：
			<ol><li>fsimage:元数据镜像文件。存储某一时段NameNode内存元数据信息。（内存中元数据序列化到磁盘的数据）</li>
				<li>edits:操作日志文件。</li>
				<li>fstime:保存最近一次checkpoint（类似于还原点）的时间</li>
			</ol></li>
			<li>以上文件保存在linux中。（hadoop/dfs/name）</li>
		</ol></li>
		<li><strong>NameNode</strong>工作特点：
		<ol><li>Namenode始终在内存中保存metedata，用于处理“读请求”</li>
			<li>到有“写请求”到来时，namenode会首先写editlog到磁盘，即向edits文件中写日志，成功返回后，才会修改内存，并且向客户端返回</li>
			<li>Hadoop会维护一个fsimage文件，也就是namenode中metedata的镜像，但是fsimage不会随时与namenode内存中的metedata保持一致，而是每隔一段时间通过合并edits和fsimage文件来更新内容（伪分布式是这样，hadoop2的分布式可以实时同步）。Secondary namenode就是用来合并fsimage和edits文件来更新NameNode的metedata的。</li>
		</ol></li>
		<li><strong>DataNode</strong>：
		<ol><li>提供真实文件数据的存储服务。</li>
			<li>文件块（block）：最基本的存储单位。对于文件内容而言，一个文件的长度大小是size，那么从文件的０偏移开始，按照固定的大小，顺序对文件进行划分并编号，划分好的每一个块称一个Block。HDFS默认Block大小是128MB(hadoop2.0)，以一个256MB文件，共有256/128=2个Block.</li>
			<li>不同于普通文件系统的是，HDFS中，如果一个文件小于一个数据块的大小，并不占用整个数据块存储空间<br>
			Replication。多复本。默认是三个。</li>
		</ol></li>
	</ol></li>
	<li>
	<h3 id="HDFS%E5%9C%A8Hadoop%E4%B8%AD%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9E%8B%EF%BC%9A">HDFS在Hadoop中存储模型：</h3>
	</li>
</ul><h3 id="%E2%80%8B"><img alt="" class="has" src="https://img-blog.csdn.net/20180917190735208?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjc2NDU1Ng==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></h3>

<ol><li>HDFS是面向文件，文件线性切割成块（Block）<br>
	每一块都有一个偏移量offset（byte），偏移量是描述这个块是属于这个文件的哪一个部分，一个大文件切分成很多块，每个块是这个文件的位置，也就是说每一个块的第一个字节对应着这个大文件某个位置的字节，这个字节就是便宜量</li>
	<li>Block分散存储到集群节点中单一文件block的大小是一致的,也就是说一个大的文件,定义的每个块的大小是固定的,所有切出来的文件大小也是固 定的.但若文件最后剩余大小和块的大小不一致,那么会按照块的大小占位,实际存储剩余文件的大小,也就是说在内存 中开辟的空间是实际文件的大小</li>
	<li>Block可以设置的副本数,副本分散在不同的节点中,副本数不要超过节点的数量</li>
	<li>副本相当于一个备份(拷贝),HDFS的默认副本数量是3,副本的额作用就是保证文件丢失的情况下,可以在其他节点中 得到同一个信息,所以绝对不能出现副本和块出现在同一个节点</li>
	<li>文件上传的时候可以设置Block块的大小和副本的而数量,已经上传的block副本数可以调整,但是块的是不变,只支持 一写入</li>
	<li>但是可以多次读取,若想追加数据只能在最后一个节点中添加</li>
</ol><p> </p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>            </div>
                </div>