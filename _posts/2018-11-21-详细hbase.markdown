---
layout:     post
title:      详细hbase
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p><a href="http://www.cnblogs.com/hark0623/p/5526888.html" rel="nofollow">点击打开链接</a></p>
<p class="artdir1">1-HBase的安装<a name="1"></a></p>
<p class="artdir2">HBase是什么？</p>
<p class="artcon">HBase是Apache <a class="replace_word" title="Hadoop知识库" href="http://lib.csdn.net/base/20" rel="nofollow">Hadoop</a>中的一个子项目，Hbase依托于Hadoop的HDFS作为最基本存储基础单元，通过使用hadoop的DFS工具就可以看到这些这些数据 存储文件夹的结构,还可以通过Map/Reduce的框架(算法)对HBase进行操作，如右侧的图所示：</p>
<p class="artcon" align="center"><img alt="" src="http://www.uml.org.cn/sjjm/images/2012121411.png"></p>
<p class="artcon">HBase在产品中还包含了Jetty，在HBase启动时采用嵌入式的方式来启动Jetty，因此可以通过web界面对HBase进行管理和查看当前运行的一些状态，非常轻巧。</p>
<p class="artcon"><strong>为什么采用HBase？</strong></p>
<p class="artcon">HBase 不同于一般的关系<a class="replace_word" title="MySQL知识库" href="http://lib.csdn.net/base/14" rel="nofollow">数据库</a>,它是一个适合于非结构化数据存储的数据库.所谓非结构化数据存储就是说HBase是基于列的而不是基于行的模式，这样方面读写你的<a class="replace_word" title="Hadoop知识库" href="http://lib.csdn.net/base/20" rel="nofollow">大数据</a>内容。</p>
<p class="artcon">HBase是介于Map Entry(key &amp; value)和DB Row之间的一种数据存储方式。就点有点类似于现在流行的Memcache，但不仅仅是简单的一个key对应一个 value，你很可能需要存储多个属性的数据结构，但没有传统数据库表中那么多的关联关系，这就是所谓的松散数据。</p>
<p class="artcon">简单来说，你在HBase中的表创建的可以看做是一张很大的表，而这个表的属性可以根据需求去动态增加，在HBase中没有表与表之间关联查询。你只需要 告诉你的数据存储到Hbase的那个column families 就可以了，不需要指定它的具体类型：char,varchar,int,tinyint,text等等。但是你需要注意HBase中不包含事务此类的功 能。</p>
<p class="artcon">Apache HBase 和Google Bigtable 有非常相似的地方，一个数据行拥有一个可选择的键和任意数量的列。表是疏松的存储的，因此用户可以给行定义各种不同的列，对于这样的功能在大项目中非常实用，可以简化设计和升级的成本。</p>
<p class="artcon"><strong>如何运行HBase？</strong></p>
<p class="artcon">从 Apache的HBase的镜像网站上下载一个稳定版本的HBase http://mirrors.devlib.org/apache/hbase/stable/hbase-0.20.6.tar.gz， 下载完成后，对其进行解压缩。确定你的机器中已经正确的安装了<a class="replace_word" title="Java EE知识库" href="http://lib.csdn.net/base/17" rel="nofollow">Java</a> SDK、SSH，否则将无法正常运行。</p>
<p class="artcon">$ cd /work/hbase</p>
<p class="artcon">进入此目录</p>
<p class="artcon">$ vim conf/hbase-env.sh</p>
<p class="artcon">export JAVA_HOME=/JDK_PATH</p>
<p class="artcon">编辑 conf/hbase-env.sh 文件,将JAVA_HOME修改为你的JDK安装目录</p>
<p class="artcon">$ vim conf/regionservers</p>
<p class="artcon">输入你的所有HBase服务器名,localhost,或者是ip地址</p>
<p class="artcon">$ bin/start-hbase.sh</p>
<p class="artcon">启动hbase, 中间需要你输入两次密码，也可以进行设置不需要输入密码，启动成功，如图所示：</p>
<p class="artcon" align="center"><img alt="" src="http://www.uml.org.cn/sjjm/images/2012121412.jpg"></p>
<p class="artcon">$ bin/hbase rest start</p>
<p class="artcon">启动hbase REST服务后就可以通过对uri: http://localhost:60050/api/ 的通用REST操作(GET/POST/PUT/DELETE)实现对hbase的REST形式数据操作.</p>
<p class="artcon">也可以输入以下指令进入HQL指令模式</p>
<p class="artcon">$ bin/hbase shell</p>
<p class="artcon">$ bin/stop-hbase.sh</p>
<p class="artcon">关闭HBase服务</p>
<p class="artcon"><strong>启动时存在的问题</strong></p>
<p class="artcon">由于linux系统的主机名配置不正确，在运行HBase服务器中可能存在的问题，如图所示：</p>
<p class="artcon" align="center"><img alt="" src="http://www.uml.org.cn/sjjm/images/2012121413.jpg"></p>
<p class="artcon">2010-11-05 11:10:20,189 ERROR org.apache.hadoop.hbase.master.HMaster: Can not start master</p>
<p class="artcon">java.net.UnknownHostException: ubuntu-server216: ubuntu-server216</p>
<p class="artcon">表示你的主机名不正确，你可以先查看一下 /etc/hosts/中名称是什么，再用 hostname 命令进行修改， hostname you_server_name</p>
<p class="artcon"><strong>查看运行状态</strong></p>
<ol><li>如果你需要对HBase的日志进行监控你可以查看 hbase.x.x./logs/下的日志文件，可以使用tail -f 来查看。</li><li>通过 web方式查看运行在 HBase 下的zookeeper http://localhost:60010/zk.jsp</li><li>如果你需要查看当前的运行状态可以通过web的方式对HBase服务器进行查看，如图所示：</li></ol><p class="artcon" align="center"><img alt="" src="http://www.uml.org.cn/sjjm/images/2012121414.jpg"></p>
<p class="artdir2">扩展阅读1：</p>
<p class="artcon">Apach 的 Hadoop的项目中包含了那些产品，如图所示：</p>
<p class="artcon" align="center"><img alt="" src="http://www.uml.org.cn/sjjm/images/2012121415.png"></p>
<p class="artcon">Pig 是在MapReduce上构建的查询语言(SQL-like),适用于大量并行计算。</p>
<p class="artcon">Chukwa 是基于Hadoop集群中监控系统，简单来说就是一个“看门狗” (WatchDog)</p>
<p class="artcon">Hive 是DataWareHouse 和 Map Reduce交集，适用于ETL方面的工作。</p>
<p class="artcon">HBase 是一个面向列的分布式数据库。</p>
<p class="artcon">Map Reduce 是Google提出的一种算法，用于超大型数据集的并行运算。</p>
<p class="artcon">HDFS 可以支持千万级的大型分布式文件系统。</p>
<p class="artcon">Zookeeper 提供的功能包括：配置维护、名字服务、分布式同步、组服务等，用于分布式系统的可靠协调系统。</p>
<p class="artcon">Avro 是一个数据序列化系统，设计用于支持大批量数据交换的应用。</p>
<p class="artdir2">扩展阅读2：</p>
<p class="artcon">什么是列存储？列存储不同于传统的关系型数据库，其数据在表中是按行存储的，列方式所带来的重要好处之一就是，由于查询中的选择规则是通过列来定义的，因 此整个数据库是自动索引化的。按列存储每个字段的数据聚集存储，在查询只需要少数几个字段的时候，能大大减少读取的数据量，一个字段的数据聚集存储，那就 更容易为这种聚集存储设计更好的压缩/解压算法。这张图讲述了传统的行存储和列存储的区别：</p>
<p class="artcon" align="center"><img alt="" src="http://www.uml.org.cn/sjjm/images/2012121416.jpg"></p>
<p class="artdir2">扩展阅读3：</p>
<p class="artcon">对系统海量的Log4J日志可以存放在一个集中式的机器上，在此机器上安装 splunk 可以方便对所有日志查看，安装方法可以参考：<br>
http://www.splunk.com/base/Documentation/latest/Installation/InstallonLinux</p>
<p class="artdir1">2-Java操作HBase例子<a name="2"></a></p>
<p class="artcon">本篇文章讲述用HBase Shell命令 和 HBase Java API 对HBase 服务器 进行操作。在此之前需要对HBase的总体上有个大概的了解。比如说HBase服务器内部由哪些主要部件构成？HBase的内部工作原理是什么？我想学习任何一项知识、技术的态度不能只是知道如何使用，对产品的内部构建一点都不去关心，那样出了问题，很难让你很快的找到答案，甚至我们希望最后能对该项技术的领悟出自己的心得，为我所用，借鉴该项技术其中的设计思想创造出自己的解决方案，更灵活的去应对多变的计算场景与<a class="replace_word" title="大型网站架构知识库" href="http://lib.csdn.net/base/16" rel="nofollow">架构</a>设计。以我目前的对HBase的了解还不够深入，将来不断的学习，我会把我所知道的点滴分享到这个Blog上。</p>
<p class="artcon">先来看一下读取一行记录HBase是如何进行工作的，首先HBase Client端会连接Zookeeper Qurom(从下面的代码也能看出来，例如：HBASE_CONFIG.set("hbase.zookeeper.quorum", "192.168.50.216") )。通过Zookeeper组件Client能获知哪个Server管理-ROOT- Region。那么Client就去访问管理-ROOT-的Server，在META中记录了HBase中所有表信息，(你可以使用
 scan '.META.' 命令列出你创建的所有表的详细信息),从而获取Region分布的信息。一旦Client获取了这一行的位置信息，比如这一行属于哪个Region，Client将会缓存这个信息并直接访问HRegionServer。久而久之Client缓存的信息渐渐增多，即使不访问.META.表也能知道去访问哪个HRegionServer。HBase中包含两种基本类型的文件，一种用于存储WAL的log，另一种用于存储具体的数据，这些数据都通过DFS Client和分布式的文件系统HDFS进行交互实现存储。</p>
<p class="artcon">如图所示：</p>
<p class="artcon" align="center"><img alt="" src="http://www.uml.org.cn/sjjm/images/2012121417.jpg"></p>
<p class="artcon">再来看看HBase的一些内存实现原理：</p>
<ul><li>HMaster— HBase中仅有一个Master server。</li><li>HRegionServer—负责多个HRegion使之能向client端提供服务，在HBase cluster中会存在多个HRegionServer。</li><li>ServerManager—负责管理Region server信息，如每个Region server的HServerInfo(这个对象包含HServerAddress和startCode),已load Region个数，死亡的Region server列表</li><li>RegionManager—负责将region分配到region server的具体工作，还监视root和meta 这2个系统级的region状态。</li><li>RootScanner—定期扫描root region，以发现没有分配的meta region。</li><li>MetaScanner—定期扫描meta region,以发现没有分配的user region。</li></ul><p class="artcon"><strong>HBase基本命令</strong></p>
<p class="artcon">下面我们再看看看HBase的一些基本操作命令，我列出了几个常用的HBase Shell命令，如下：</p>
<p>
</p><table class="content" border="0" bgcolor="#666666" align="center" style="width:674px;"><tbody><tr valign="top" bgcolor="#ffffff"><td>
<div align="center">名称</div>
</td>
<td colspan="2">
<div align="center">命令表达式</div>
</td>
</tr><tr valign="top" bgcolor="#ffffff"><td>创建表</td>
<td colspan="2">create '表名称', '列名称1','列名称2','列名称N'</td>
</tr><tr valign="top" bgcolor="#ffffff"><td>添加记录</td>
<td colspan="2">put '表名称', '行名称', '列名称:', '值'</td>
</tr><tr valign="top" bgcolor="#ffffff"><td>查看记录</td>
<td colspan="2">get '表名称', '行名称'</td>
</tr><tr valign="top" bgcolor="#ffffff"><td>查看表中的记录总数</td>
<td colspan="2">count '表名称'</td>
</tr><tr valign="top" bgcolor="#ffffff"><td>删除记录</td>
<td colspan="2">delete '表名' ,'行名称' , '列名称'</td>
</tr><tr valign="top" bgcolor="#ffffff"><td>删除一张表</td>
<td colspan="2">先要屏蔽该表，才能对该表进行删除，第一步 disable '表名称' 第二步 drop '表名称'</td>
</tr><tr valign="top" bgcolor="#ffffff"><td>查看所有记录</td>
<td colspan="2">scan "表名称"</td>
</tr><tr valign="top" bgcolor="#ffffff"><td>查看某个表某个列中所有数据</td>
<td colspan="2">scan "表名称" , ['列名称:']</td>
</tr><tr valign="top" bgcolor="#ffffff"><td>更新记录</td>
<td colspan="2">就是重写一遍进行覆盖</td>
</tr></tbody></table><p class="artcon">如果你是一个新手队HBase的一些命令还不算非常熟悉的话，你可以进入 hbase 的shell 模式中你可以输入 help 命令查看到你可以执行的命令和对该命令的说明，例如对scan这个命令，help中不仅仅提到有这个命令，还详细的说明了scan命令中可以使用的参数和作用，例如，根据列名称查询的方法和带LIMIT 、STARTROW的使用方法：</p>
<p>
</p><table class="content" border="0" bgcolor="#666666" align="center" style="width:700px;"><tbody><tr valign="top" bgcolor="#ffffff"><td bgcolor="#cccccc" colspan="3">
<pre> scan   Scan a table; pass table name and optionally a dictionary of scanner specifications.  
 Scanner specifications may include one or more of  the following: LIMIT, STARTROW, STOPROW, TIMESTAMP, or COLUMNS.
 If no columns are specified, all columns will be scanned.  To scan all members of a column family, leave the 
 qualifier empty as in  'col_family:'.  Examples:
   hbase&gt; scan '.META.'
   hbase&gt; scan '.META.', {COLUMNS =&gt; 'info:regioninfo'}
   hbase&gt; scan 't1', {COLUMNS =&gt; ['c1', 'c2'], LIMIT =&gt; 10, STARTROW =&gt; 'xyz'}</pre>
</td>
</tr></tbody></table><p class="artcon"><strong>使用Java API对HBase服务器进行操作</strong></p>
<p class="artcon">需要下列jar包</p>
<p>
</p><table class="content" border="0" bgcolor="#666666" align="center" style="width:700px;"><tbody><tr valign="top" bgcolor="#ffffff"><td bgcolor="#cccccc">
<pre>     hbase-0.20.6.jar
      hadoop-core-0.20.1.jar
      commons-logging-1.1.1.jar
      zookeeper-3.3.0.jar
      log4j-1.2.91.jar
 
import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.HBaseConfiguration;
 import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.KeyValue;
 import org.apache.hadoop.hbase.client.HBaseAdmin;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Result;
 import org.apache.hadoop.hbase.client.ResultScanner;
 import org.apache.hadoop.hbase.client.Scan;
 import org.apache.hadoop.hbase.io.BatchUpdate;
 
@SuppressWarnings("deprecation")
 public class HBaseTestCase {
     
    static HBaseConfiguration cfg = null;
     static {
         Configuration HBASE_CONFIG = new Configuration();
         HBASE_CONFIG.set("hbase.zookeeper.quorum", "192.168.50.216");
         HBASE_CONFIG.set("hbase.zookeeper.property.clientPort", "2181");
         cfg = new HBaseConfiguration(HBASE_CONFIG);
     }
    
    /**
      * 创建一张表
     */
     public static void creatTable(String tablename) throws Exception {
         HBaseAdmin admin = new HBaseAdmin(cfg);
         if (admin.tableExists(tablename)) {
             System.out.println("table   Exists!!!");
         }
         else{
             HTableDescriptor tableDesc = new HTableDescriptor(tablename);
             tableDesc.addFamily(new HColumnDescriptor("name:"));
             admin.createTable(tableDesc);
             System.out.println("create table ok .");
         }
         
     }
     
    /**
      * 添加一条数据
     */
     public static void addData (String tablename) throws Exception{
          HTable table = new HTable(cfg, tablename);
              BatchUpdate update = new BatchUpdate("Huangyi");  
             update.put("name:java", "http://www.javabloger.com".getBytes());  
             table.commit(update);  
         System.out.println("add data ok .");
     }
     
    /**
      * 显示所有数据
     */
     public static void getAllData (String tablename) throws Exception{
          HTable table = new HTable(cfg, tablename);
          Scan s = new Scan();
          ResultScanner ss = table.getScanner(s);
          for(Result r:ss){
              for(KeyValue kv:r.raw()){
                 System.out.print(new String(kv.getColumn()));
                 System.out.println(new String(kv.getValue()    ));
              }
 
         }
     }
     
    
    public static void  main (String [] agrs) {
         try {
                 String tablename="tablename";
                 HBaseTestCase.creatTable(tablename);
                 HBaseTestCase.addData(tablename);
                 HBaseTestCase.getAllData(tablename);
             } 
        catch (Exception e) {
             e.printStackTrace();
         }
         
    }
     
} </pre>
</td>
</tr></tbody></table><p class="artdir1">3-HBase优化技巧<a name="3"></a></p>
<p class="artcon">这篇文章浅显的从几个方面谈谈HBase的一些优化技巧，只能作为我学习笔记的一部分，因为学多了怕忘，留给自己以后看看。</p>
<p class="artcon"><strong>1 修改 linux 系统参数</strong></p>
<p class="artcon">Linux系统最大可打开文件数一般默认的参数值是1024,如果你不进行修改并发量上来的时候会出现“Too Many Open Files”的错误，导致整个HBase不可运行，你可以用ulimit -n 命令进行修改，或者修改/etc/security/limits.conf 和/proc/sys/fs/file-max 的参数，具体如何修改可以去Google 关键字 “linux limits.conf ”</p>
<p class="artcon"><strong>2 JVM 配置</strong></p>
<p class="artcon">修改 hbase-env.sh 文件中的配置参数，根据你的机器硬件和当前操作系统的JVM(32/64位)配置适当的参数</p>
<p class="artcon">HBASE_HEAPSIZE 4000 HBase使用的 JVM 堆的大小</p>
<p class="artcon">HBASE_OPTS "‐server ‐XX:+UseConcMarkSweepGC"JVM GC 选项</p>
<p class="artcon">HBASE_MANAGES_ZKfalse 是否使用Zookeeper进行分布式管理</p>
<p class="artcon"><strong>3 HBase持久化</strong></p>
<p class="artcon">重启操作系统后HBase中数据全无，你可以不做任何修改的情况下，创建一张表，写一条数据进行，然后将机器重启，重启后你再进入HBase的shell中使用 list 命令查看当前所存在的表，一个都没有了。是不是很杯具？没有关系你可以在hbase/conf/hbase-default.xml中设置hbase.rootdir的值，来设置文件的保存位置指定一个文件夹 ，例如：&lt;value&gt;file:///you/hbase-data/path&lt;/value&gt;，你建立的HBase中的表和数据就直接写到了你的磁盘上，如图所示：</p>
<p class="artcon" align="center"><img alt="" src="http://www.uml.org.cn/sjjm/images/2012121418.jpg"></p>
<p class="artcon">同样你也可以指定你的分布式文件系统HDFS的路径例如: hdfs://NAMENODE_SERVER:PORT/HBASE_ROOTDIR，这样就写到了你的分布式文件系统上了。</p>
<p class="artcon"><strong>4 配置HBase运行参数</strong></p>
<p class="artcon">其次就需要对hbase/conf/hbase-default.xml 文件进行配置，以下是我认为比较重要的配置参数</p>
<p class="artcon">hbase.client.write.buffer</p>
<p class="artcon">描述：这个参数可以设置写入数据缓冲区的大小，当客户端和服务器端传输数据，服务器为了提高系统运行性能开辟一个写的缓冲区来处理它， 这个参数设置如果设置的大了，将会对系统的内存有一定的要求，直接影响系统的性能。</p>
<p class="artcon">hbase.master.meta.thread.rescanfrequency</p>
<p class="artcon">描述：多长时间 HMaster对系统表 root 和 meta 扫描一次，这个参数可以设置的长一些，降低系统的能耗。</p>
<p class="artcon">hbase.regionserver.handler.count</p>
<p class="artcon">描述：由于HBase/Hadoop的Server是采用Multiplexed, non-blocking I/O方式而设计的，所以它可以透过一个Thread来完成处理，但是由于处理Client端所呼叫的方法是Blocking I/O，所以它的设计会将Client所传递过来的物件先放置在Queue，并在启动Server时就先产生一堆Handler(Thread)，该Handler会透过Polling的方式来取得该物件并执行对应的方法，默认为25，根据实际场景可以设置大一些。</p>
<p class="artcon">hbase.regionserver.thread.splitcompactcheckfrequency</p>
<p class="artcon">描述：这个参数是表示多久去RegionServer服务器运行一次split/compaction的时间间隔，当然split之前会先进行一个compact操作.这个compact操作可能是minor compact也可能是major compact.compact后,会从所有的Store下的所有StoreFile文件最大的那个取midkey.这个midkey可能并不处于全部数据的mid中.一个row-key的下面的数据可能会跨不同的HRegion。</p>
<p class="artcon">hbase.hregion.max.filesize</p>
<p class="artcon">描述：HRegion中的HStoreFile最大值，任何表中的列族一旦超过这个大小将会被切分，而HStroeFile的默认大小是256M。</p>
<p class="artcon">hfile.block.cache.size</p>
<p class="artcon">描述：指定 HFile/StoreFile 缓存在JVM堆中分配的百分比，默认值是0.2，意思就是20%，而如果你设置成0，就表示对该选项屏蔽。</p>
<p class="artcon">hbase.zookeeper.property.maxClientCnxns</p>
<p class="artcon">描述： 这项配置的选项就是从zookeeper中来的，表示ZooKeeper客户端同时访问的并发连接数，ZooKeeper对于HBase来说就是一个入口这个参数的值可以适当放大些。</p>
<p class="artcon">hbase.regionserver.global.memstore.upperLimit</p>
<p class="artcon">描述：在Region Server中所有memstores占用堆的大小参数配置，默认值是0.4，表示40%，如果设置为0，就是对选项进行屏蔽。</p>
<p class="artcon">hbase.hregion.memstore.flush.size</p>
<p class="artcon">描述：Memstore中缓存的内容超过配置的范围后将会写到磁盘上，例如：删除操作是先写入MemStore里做个标记，指示那个value, column 或 family等下是要删除的，HBase会定期对存储文件做一个major compaction，在那时HBase会把MemStore刷入一个新的HFile存储文件中。如果在一定时间范围内没有做major compaction，而Memstore中超出的范围就写入磁盘上了。</p>
<p class="artcon"><strong>5 HBase中log4j的日志</strong></p>
<p class="artcon">HBase中日志输出等级默认状态下是把debug、 info 级别的日志打开的，可以根据自己的需要调整log级别，HBase的log4j日志配置文件在 hbase\conf\log4j.properties 目录下。</p>
<p class="artdir1">4–存储<a name="4"></a></p>
<p class="artcon">在HBase中创建的一张表可以分布在多个Hregion，也就说一张表可以被拆分成多块，每一块称我们呼为一个Hregion。每个Hregion会保 存一个表里面某段连续的数据，用户创建的那个大表中的每个Hregion块是由Hregion服务器提供维护，访问Hregion块是要通过 Hregion服务器，而一个Hregion块对应一个Hregion服务器，一张完整的表可以保存在多个Hregion 上。HRegion Server 与Region的对应关系是一对多的关系。每一个HRegion在物理上会被分为三个部分：Hmemcache(缓存)、Hlog(日志)、HStore(持久层)。<br>
上述这些关系在我脑海中的样子，如图所示：</p>
<p class="artcon">1.HRegionServer、HRegion、Hmemcache、Hlog、HStore之间的关系，如图所示：</p>
<p class="artcon" align="center"><img alt="" src="http://www.uml.org.cn/sjjm/images/2012121419.jpg"></p>
<p class="artcon">2.HBase表中的数据与HRegionServer的分布关系，如图所示：</p>
<p class="artcon" align="center"><img alt="" src="http://www.uml.org.cn/sjjm/images/20121214110.jpg"></p>
<p class="artcon">HBase读数据</p>
<p class="artcon">HBase读取数据优先读取HMemcache中的内容，如果未取到再去读取Hstore中的数据，提高数据读取的性能。</p>
<p class="artcon">HBase写数据</p>
<p class="artcon">HBase写入数据会写到HMemcache和Hlog中，HMemcache建立缓存，Hlog同步Hmemcache和Hstore的事务日志，发起Flush Cache时，数据持久化到Hstore中，并清空HMemecache。</p>
<p class="artcon">客户端访问这些数据的时候通过Hmaster ，每个 Hregion 服务器都会和Hmaster 服务器保持一个长连接，Hmaster 是HBase分布式系统中的管理者，他的主要任务就是要告诉每个Hregion 服务器它要维护哪些Hregion。用户的这些都数据可以保存在Hadoop 分布式文件系统上。 如果主服务器Hmaster死机，那么整个系统都会无效。下面我会考虑如何解决Hmaster的SPFO的问题，这个问题有点类似Hadoop的SPFO 问题一样只有一个NameNode维护全局的DataNode，HDFS一旦死机全部挂了，也有人说采用Heartbeat来解决这个问题，但我总想找出
 其他的解决方案，多点时间，总有办法的。</p>
<p class="artcon">昨天在hadoop-0.21.0、hbase-0.20.6的环境中折腾了很久，一直报错，错误信息如下：</p>
<p>
</p><table class="content" border="0" bgcolor="#666666" align="center" style="width:700px;"><tbody><tr valign="top" bgcolor="#ffffff"><td bgcolor="#cccccc">
<pre>Exception in thread "main" java.io.IOException: Call to localhost/serv6:9000 failed on local exception: 
java.io.EOFException
 10/11/10 15:34:34 ERROR master.HMaster: Can not start master
 java.lang.reflect.InvocationTargetException
         at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
         at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
         at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
         at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
         at org.apache.hadoop.hbase.master.HMaster.doMain(HMaster.java:1233)
         at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:1274) </pre>
</td>
</tr></tbody></table><p class="artcon">死活连接不上HDFS，也无法连接HMaster，郁闷啊。</p>
<p class="artcon">我想想啊，慢慢想，我眼前一亮 java.io.EOFException 这个异常，是不是有可能是RPC 协定格式不一致导致的？也就是说服务器端和客户端的版本不一致的问题？换了一个HDFS的服务器端以后，一切都好了，果然是版本的问题，最后采用 hadoop-0.20.2 搭配hbase-0.20.6 比较稳当。</p>
<p class="artcon">最后的效果如图所示：</p>
<p class="artcon" align="center"><img alt="" src="http://www.uml.org.cn/sjjm/images/20121214111.png"></p>
<p class="artcon">上图的一些文字说明：</p>
<ol><li>hadoop版本是0.20.2 ,</li><li>hbase版本是0.20.6,</li><li>在hbase中创建了一张表 tab1，退出hbase shell环境,</li><li>用hadoop命令查看，文件系统中的文件果然多了一个刚刚创建的tab1目录,以上这张图片说明HBase在分布式文件系统Apache HDFS中运行了。</li></ol><p class="artdir1">5(集群) -压力分载与失效转发<a name="5"></a></p>
<p class="artcon">在上一篇关于HBase的文章中曾经讲述过HBase在分布式中的架构，这篇文章将会讲述HBase在分布式环境中是如何排除单点故障的(SPFO)，做一个小实验讲述HBase在分布式环境中的高可用性，亲眼看到一些现象，延伸一些思考的话题。</p>
<p class="artcon">先来回顾一下HBase主要部件：</p>
<ol><li>HBaseMaster</li><li>HRegionServer</li><li>HBase Client</li><li>HBase Thrift Server</li><li>HBase REST Server</li></ol><p class="artcon"><strong>HBaseMaster</strong></p>
<p class="artcon">HMaster 负责给HRegionServer分配区域,并且负责对集群环境中的HReginServer进行负载均衡，HMaster还负责监控集群环境中的HReginServer的运行状况，如果某一台HReginServer down机，HBaseMaster将会把不可用的HReginServer来提供服务的HLog和表进行重新分配转交给其他HReginServer来提供，HBaseMaster还负责对数据和表进行管理，处理表结构和表中数据的变更，因为在 META 系统表中存储了所有的相关表信息。并且HMaster实现了ZooKeeper的Watcher接口可以和zookeeper集群交互。</p>
<p class="artcon"><strong>HRegionServer</strong></p>
<p class="artcon">HReginServer负责处理用户的读和写的操作。HReginServer通过与HBaseMaster通信获取自己需要服务的数据表，并向HMaster反馈自己的运行状况。当一个写的请求到来的时候，它首先会写到一个叫做HLog的write-ahead log中。HLog被缓存在内存中，称为Memcache，每一个HStore只能有一个Memcache。当Memcache到达配置的大小以后，将会创建一个MapFile，将其写到磁盘中去。这将减少HReginServer的内存压力。当一起读取的请求到来的时候，HReginServer会先在Memcache中寻找该数据，当找不到的时候，才会去在MapFiles
 中寻找。</p>
<p class="artcon"><strong>HBase Client</strong></p>
<p class="artcon">HBase Client负责寻找提供需求数据的HReginServer。在这个过程中，HBase Client将首先与HMaster通信，找到ROOT区域。这个操作是Client和Master之间仅有的通信操作。一旦ROOT区域被找到以后，Client就可以通过扫描ROOT区域找到相应的META区域去定位实际提供数据的HReginServer。当定位到提供数据的HReginServer以后，Client就可以通过这个HReginServer找到需要的数据了。这些信息将会被Client缓存起来，当下次请求的时候，就不需要走上面的这个流程了。</p>
<p class="artcon"><strong>HBase服务接口</strong></p>
<p class="artcon">HBase Thrift Server和HBase REST Server是通过非Java程序对HBase进行访问的一种途径。</p>
<p class="artcon">进入正题</p>
<p class="artcon">先来看一个HBase集群的模拟环境，此环境中一共有4台机器，分别包含 zookeeper、HBaseMaster、HReginServer、HDSF 4个服务，为了展示失效转发的效果HBaseMaster、HReginServer各有2台，只是在一台机器上即运行了HBaseMaster，也运行了HReginServer。<br>
注意，HBase的集群环境中HBaseMaster只有失效转发没有压力分载的功能，而HReginServer即提供失效转发也提供压力分载。</p>
<p class="artcon">服务器清单如下：</p>
<ol><li>zookeeper 192.168.20.214</li><li>HBaseMaster 192.168.20.213/192.168.20.215</li><li>HReginServer 192.168.20.213/192.168.20.215</li><li>HDSF 192.168.20.212</li></ol><p class="artcon">整个模拟环境的架构如图所示：</p>
<p class="artcon" align="center"><img alt="" src="http://www.uml.org.cn/sjjm/images/20121214112.jpg"></p>
<p class="artcon">注意，这里只是做了一个模拟环境，因为这个环境的重点是HBase，所以zookeeper和HDFS服务都是单台。</p>
<p class="artcon">虽然说在整个HBase的集群环境中只能有一个HMaster，可是在集群环境中HMaster可以启动多个，但真正使用到的HMaster Server只有一个，他不down掉的时候，其他启动的HMaster Server并不会工作，直到与ZooKeeper服务器判断与当前运行的HMaster通讯超时，认为这个正在运行的HMaster服务器down掉了，Zookeeper才会去连接下一台HMaster Server。</p>
<p class="artcon">简单来说,如果运行中HMaster服务器down掉了，那么zookeeper会从列表中选择下一个HMaster 服务器进行访问，让他接管down掉的HMaster任务，换而言之，用Java客户端对HBase进行操作是通过ZooKeeper的，也就是说如果zookeeper集群中的节点全挂了 那么HBase的集群也挂了。本身HBase并不存储中的任何数据 真正的数据是保存在HDFS上，所以HBase的数据是一致的，但是HDFS文件系统挂了，HBase的集群也挂。</p>
<p class="artcon">在一台HMaster失败后，客户端对HBase集群环境访问时，客户端先会通过zookeeper识别到HMaster运行异常，直到确认多次后，才连接到下一个HMaster，此时，备份的HMaster服务才生效，在IDE环境中的效果，如图所示：</p>
<p class="artcon" align="center"><img alt="" src="http://www.uml.org.cn/sjjm/images/20121214113.jpg"></p>
<p class="artcon">上图中能看见抛出的一些异常和name:javahttp://www.javabloger.com和name:javahttp://www.javabloger.com1的结果集，因为我在serv215机器上用killall java命令把 HMaster和HReginServer都关掉，并且立刻用Java客户端对HBase的集群环境进行访问有异常抛出，但是retry到一定次数后查询出结果，前面已经说了访问HBase是通过zookeeper再和真正的数据打交道，也就是说zookeeper接管了一个standby
 的 HMaster，让原先Standby的HMaster接替了失效的HMaster任务，而被接管的HBaseMaster再对HReginServer的任务进行分配，当 HReginServer失败后zookeeper会通知 HMaster对HReginServer的任务进行分配。这样充分的说明了HBase做到了实效转发的功能。</p>
<p class="artcon">如图所示：</p>
<p class="artcon" align="center"><img alt="" src="http://www.uml.org.cn/sjjm/images/20121214114.jpg"></p>
<p class="artcon"><strong>口水：</strong></p>
<p class="artcon">1、HBase的失效转发的效率比较慢了，不指望能在1-2秒切换和恢复完毕，也许是我暂时没有发现有什么参数可以提高失效转发和恢复过程的速度，将来会继续关注这个问题。</p>
<p class="artcon">2、在官方网站上看见HBase0.89.20100924的版本有篇讲述关于数据同步的文章，我尝试了一下在一台机器上可以运行所谓的HBase虚拟集群环境，但是切换到多台机器的分布式环境中，单点失效转发的速度很慢比HBase0.20.6还要慢，我又检查了是否存在网络的问题，目前尚未找到正确的答案，对与HBase0.89.20100924 新版中的数据同步的原理，如图所示：(更多信息)</p>
<p class="artcon" align="center"><img alt="" src="http://www.uml.org.cn/sjjm/images/20121214115.jpg"></p>
<p class="artdir1">前辈的东西，原样复制过来的。</p>
<p> </p>
            </div>
                </div>