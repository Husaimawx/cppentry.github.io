---
layout:     post
title:      Hadoop基础命令
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p style="margin-left:0cm;">hadoop fs -cmd <br>
cmd: 具体的操作，基本上与UNIX的命令行相同 <br>
hadoop fs -mkdir /user/trunk (创建目录) <br>
hadoop fs -ls /user (显示目录文件) <br>
hadoop fs -lsr /user (递归的) <br>
hadoop fs -put test.txt /user/trunk (复制文件到/user/trunk 目录下) <br>
hadoop fs -put test.txt . (复制到hdfs当前目录下，首先要创建当前目录) <br>
hadoop fs -get /user/trunk/test.txt . (复制到本地当前目录下) <br>
hadoop fs -cat /user/trunk/test.txt (查看文件) <br>
hadoop fs -touchz /user/new.txt(在hadoop指定目录下新建一个空文件) <br>
hadoop fs -tail /user/trunk/test.txt (查看最后1000字节) <br>
hadoop fs –rm /user/trunk/test.txt (删除文件) <br>
hadoop fs –rmr /user/trunk/test.txt (删除目录) <br>
hadoop fs –cp /user/a.txt /user/b.txt(拷贝文件) <br>
hadoop fs –mv /user/test.txt /user/ok.txt 将hadoop上某个文件重命名 <br>
hadoop dfs –getmerge /user /home/t 将hadoop指定目录下所有内容保存为一个文件，同时down至本地 <br>
hadoop fs -help ls (查看ls命令的帮助文档) <br>
hadoop job –kill [job-id] 将正在运行的hadoop作业kill掉 <br>
hadoop Admin <br>
hadoop dfsadmin -safemode leave 切换安全模式 <br>
hadoop dfsadmin –report 显示Datanode列表</p>

<p style="margin-left:0cm;">整理需求感谢博主：<br>
原文：https://blog.csdn.net/cdl2008sky/article/details/79026860 </p>            </div>
                </div>