---
layout:     post
title:      HDFS基本操作
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，欢迎转载。					https://blog.csdn.net/kan2281123066/article/details/78241321				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>一、HDFS的相关命令 <br>
    -mkdir            #在HDFS创建目录    hdfs dfs -mkdir /data <br>
    -ls                   #查看当前目录      hdfs dfs -ls / <br>
    -ls -R              #查看目录与子目录 <br>
    -put              #上传一个文件      hdfs dfs -put data.txt /data/input <br>
    -moveFromLocal    #上传一个文件，会删除本地文件：ctrl + X <br>
    -copyFromLocal    #上传一个文件，与put一样 <br>
    -copyToLocal      #下载文件  hdfs dfs -copyToLocal /data/input/data.txt  <br>
    -get              #下载文件  hdfs dfs -get /data/input/data.txt  <br>
    -rm               #删除文件  hdfs dfs -rm /data/input/data.txt  <br>
    -getmerge         #将目录所有的文件先合并，再下载 <br>
    -cp               #拷贝： hdfs dfs -cp /data/input/data.txt  /data/input/data01.txt  <br>
    -mv               #移动： hdfs dfs -mv /data/input/data.txt  /data/input/data02.txt  <br>
    -count            #统计目录下的文件个数 <br>
    -text、-cat       #查看文件的内容  hdfs dfs -cat /data/input/data.txt  <br>
    -balancer         #平衡操作</p>

<p>二、HDFS的Java API <br>
    用Java API的方式在HDFS上创建一个目录： <br>
        在本地导入依赖的jar包： <br>
        /usr/hadoop/hadoop-2.7.3/share/hadoop/common/lib <br>
        /usr/hadoop/hadoop-2.7.3/share/hadoop/common/ <br>
        /usr/hadoop/hadoop-2.7.3/share/hadoop/hdfs/lib <br>
        /usr/hadoop/hadoop-2.7.3/share/hadoop/hdfs/</p>

<pre class="prettyprint"><code class=" hljs actionscript"><span class="hljs-preprocessor"><span class="hljs-keyword">import</span> java.io.IOException;</span>

<span class="hljs-preprocessor"><span class="hljs-keyword">import</span> org.apache.hadoop.conf.Configuration;</span>
<span class="hljs-preprocessor"><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FileSystem;</span>
<span class="hljs-preprocessor"><span class="hljs-keyword">import</span> org.apache.hadoop.fs.Path;</span>

<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TestMain</span> {</span>

    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> main(String[] args) throws Exception {
        <span class="hljs-comment">// 使用HDFS的API创建目录</span>
        <span class="hljs-comment">//设置NameNode地址</span>
        Configuration conf = <span class="hljs-keyword">new</span> Configuration();
        conf.<span class="hljs-keyword">set</span>(<span class="hljs-string">"fs.defaultFS"</span>, <span class="hljs-string">"hdfs://192.168.222.100:9000"</span>);

        <span class="hljs-comment">//得到HDFS的文件系统</span>
        FileSystem fs = FileSystem.<span class="hljs-keyword">get</span>(conf);
        fs.mkdirs(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">"/folder1"</span>));
    }

}
</code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>