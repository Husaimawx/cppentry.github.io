---
layout:     post
title:      spark提交任务启动参数调优
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/qq_29726869/article/details/82460772				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <pre>
//指定spark运行模式
spark.master = spark://master:7707
//指定spark程序运行内存
spark.executor.memory = 2000M   
//指定spark申请管理的内存(executorMemory基于driverMemory调整)
spark.driver.memory =8000M
//指定一个executor占用cpu核数(一个节点就是一个executor)
spark.executor.cores = 4
//指定申请几个executor(申请几个节点)
spark.num.executors = 5
//分配spark申请最大cpu数目
spark.cores.max = 20
//设置task任务(spark任务并行度,设置为申请最大cpu数的2-3倍最优)
spark.default.parallelism = 60

//读取路径
qqPath =  C:/Users/zixiang/Desktop/qq词库
baiduPath = C:/Users/zixiang/Desktop/百度词库
sougouPath = C:/Users/zixiang/Desktop/搜狗词库
dictPath = C:/Users/zixiang/Desktop/sougoudict
//保存路径
savePath = hdfs://master:9000/result
hdfsPath = hdfs://master:9000</pre>            </div>
                </div>