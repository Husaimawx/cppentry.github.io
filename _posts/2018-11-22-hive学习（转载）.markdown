---
layout:     post
title:      hive学习（转载）
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <span style="font-family:Arial, sans-serif, Helvetica, Tahoma;font-size:14px;line-height:25px;"></span><p style="margin-left:0px;"><span style="font-size:16px;">     Hive是构建在Hadoop的数据仓库平台，最初Hive被Facebook用来处理海量的用户和日志数据。利用Hive处理分析的数据一般满足结构化的特征，Hive基于MapReduce之上增加了优化和更可用性的特性，Hive把用户从复杂的MapReduce编程中解脱出来，Hive定义了类似于SQL的查询语言：HQL，Hive能够将HQL转换为相应的MapReduce程序，并在Hadoop平台上执行。</span></p><p style="margin-left:0px;"><span style="font-size:16px;"></span></p><p style="margin-left:0px;"><span style="font-size:16px;">一、Hive的安装与启动</span></p><p style="margin-left:0px;"><span style="font-size:16px;">     Hive的运行环境需要Jdk1.6、Hadoop0.17及以上版本，在这里我下载了hive-0.6.0.tar.gz。解压到/usr/local/hive，在环境变量中</span></p><div class="dp-highlighter" style="font-family:Monaco, 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', Consolas, 'Courier New', monospace;font-size:12px;background-color:transparent;width:694px;margin-left:9px;"><div class="bar"><div class="tools" style="text-align:left;margin-left:0px;color:#000000;font-weight:bold;">Shell代码  <a href="http://xm-king.iteye.com/blog/1088422" rel="nofollow" title="收藏这段代码" style="color:rgb(0,102,0);text-decoration:underline;"><img class="star" src="http://xm-king.iteye.com/images/icon_star.png" alt="收藏代码" style="border-top-width:0px;border-right-width:0px;border-bottom-width:0px;border-left-width:0px;"></a></div></div><ol start="1" class="dp-default" style="font-size:1em;line-height:1.4em;margin-left:0px;border-top-width:1px;border-right-width:1px;border-bottom-width:1px;border-left-width:1px;border-top-style:solid;border-right-style:solid;border-bottom-style:solid;border-left-style:solid;border-top-color:rgb(209,215,220);border-right-color:rgb(209,215,220);border-bottom-color:rgb(209,215,220);border-left-color:rgb(209,215,220);list-style-type:decimal;background-color:rgb(255,255,255);color:rgb(43,145,175);"><li style="font-size:1em;margin-left:38px;border-left-width:1px;border-left-style:solid;border-left-color:rgb(209,215,220);background-color:rgb(250,250,250);line-height:18px;"><span style="color:#000000;"><span style="color:#000000;">&lt;span style=</span><span class="string" style="color:#0000FF;">"font-size: medium;"</span><span style="color:#000000;">&gt;HIVE_HOME=/usr/local/hive  </span></span></li><li style="font-size:1em;margin-left:38px;border-left-width:1px;border-left-style:solid;border-left-color:rgb(209,215,220);background-color:rgb(250,250,250);line-height:18px;"><span style="color:#000000;">PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HIVE_HOME/bin&lt;/span&gt;  </span></li><li style="font-size:1em;margin-left:38px;border-left-width:1px;border-left-style:solid;border-left-color:rgb(209,215,220);background-color:rgb(250,250,250);line-height:18px;"><span style="color:#000000;">&lt;span style=<span class="string" style="color:#0000FF;">"font-size: medium;"</span><span style="color:#000000;">&gt;  </span></span></li><li style="font-size:1em;margin-left:38px;border-left-width:1px;border-left-style:solid;border-left-color:rgb(209,215,220);background-color:rgb(250,250,250);line-height:18px;"><span style="color:#000000;">&lt;/span&gt;  </span></li></ol></div><p style="margin-left:0px;"><span style="font-size:16px;">      首先，启动Hadoop，到HADOOP_HOME/bin下，执行start-all.sh，然后在命令行中输入hive，回车，就进入了Hive的执行界面：</span></p><p style="margin-left:0px;"><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92258/4b8d4092-1cb9-398e-b7ae-e51873bfc4da.jpg" alt="" width="580" height="45" style="border-top-width:0px;border-right-width:0px;border-bottom-width:0px;border-left-width:0px;"></span></p><p style="margin-left:0px;"><span style="font-size:16px;">二、HQL</span></p><p style="margin-left:0px;"><span style="font-size:16px;">create table 语句</span></p><p style="margin-left:0px;"><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92260/c2df43c9-f8f1-364f-9c90-be7bffc6bf02.jpg" alt="" width="350" height="69" style="border-top-width:0px;border-right-width:0px;border-bottom-width:0px;border-left-width:0px;"></span></p><p style="margin-left:0px;"><span style="font-size:16px;">     第一行声明了一个名为user的一张表，该表包括两个字段id和name，分别为int和string类型。剩下的两行表示在存储user的数据的文件中每一行应该有三个字段，字段用tab键隔开，每行用回车隔开。</span></p><p style="margin-left:0px;"><span style="font-size:16px;">Load Data语句</span></p><p style="margin-left:0px;"><span style="font-size:16px;">    将数据加载到user表中</span></p><p style="margin-left:0px;"><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92262/683e7fad-f2cb-3fd4-9816-3f4db135786c.jpg" alt="" width="347" height="97" style="border-top-width:0px;border-right-width:0px;border-bottom-width:0px;border-left-width:0px;"></span></p><p style="margin-left:0px;"><span style="font-size:16px;">通过上面的命令告诉Hive将sample.txt移动到hive的仓库目录(默认为/user/hive/warehouse)下面，在这个过程中不涉及到文件的解析，hive也不会按照特殊的格式来存储sample.txt。我们可以通过命令来浏览HDFS目录</span></p><p style="margin-left:0px;"><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92264/6e5c5f70-8882-3c52-a29f-5d060a25c5fc.jpg" alt="" width="700" height="65" title="点击查看原始大小图片" class="magplus" style="border-top-width:0px;border-right-width:0px;border-bottom-width:0px;border-left-width:0px;"></span></p><p style="margin-left:0px;"><span style="font-size:16px;">select 语句</span></p><p style="margin-left:0px;"><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92266/1136c25c-0e34-3b27-bab4-f05f834785b6.jpg" alt="" width="205" height="123" style="border-top-width:0px;border-right-width:0px;border-bottom-width:0px;border-left-width:0px;"></span></p><p style="margin-left:0px;"><span style="font-size:16px;">      HQL的select操作和SQL非常相似，但是也有一些细微差别，这在以后会慢慢地讲到的</span></p><p style="margin-left:0px;"><span style="font-size:16px;">三、partitions and buckets</span></p><p style="margin-left:0px;"><span style="font-size:16px;">      hive可以通过partitions将表粗粒度划分为不同的目录来提高查询的效率，例如包含时间戳的日志文件，如果我们按照时间来把日志文件分在不同的目录下，那么相同日期的记录就会存储在同一个分区目录下面，那我们就可以更高效率地查询特定某个时间的记录了。例如：</span></p><p style="margin-left:0px;"><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92268/b04dedde-521d-340a-b3b7-95aeabe1c96a.jpg" alt="" width="375" height="81" style="border-top-width:0px;border-right-width:0px;border-bottom-width:0px;border-left-width:0px;"></span></p><p style="margin-left:0px;"><span style="font-size:16px;">通过partitioned by声明的字段表面上和在普通的column没什么不一样的。如下所示：</span></p><p style="margin-left:0px;"><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92270/4222b0f4-ef5d-355d-b53b-c313d9465b15.jpg" alt="" width="200" height="95" style="border-top-width:0px;border-right-width:0px;border-bottom-width:0px;border-left-width:0px;"></span></p><p style="margin-left:0px;"><span style="font-size:16px;">      不同之处在于，表并不存储通过partitioned by声明的字段，而是将不同字段的数据放在partitioned字段目录下面，通过路径来获得partitioned字段的值。所以在我们想partitioned 表中加载数据时，需要指明partitioned 字段的值，例如：</span></p><p style="margin-left:0px;"><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92274/b1c78c6b-c0a9-3d40-b0e4-2224b0abf2b8.jpg" alt="" width="504" height="94" style="border-top-width:0px;border-right-width:0px;border-bottom-width:0px;border-left-width:0px;"></span></p><p style="margin-left:0px;"><span style="font-size:16px;">      我们可以查看一个table的partitioned 情况：</span></p><p style="margin-left:0px;"><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92272/86c1157e-1738-3acc-bf42-60bb3d699690.jpg" alt="" width="215" height="92" style="border-top-width:0px;border-right-width:0px;border-bottom-width:0px;border-left-width:0px;"></span></p><p style="margin-left:0px;"><span style="font-size:16px;"></span></p><p style="margin-left:0px;"><span style="font-size:16px;">      为了是查询效率更高以及采样数据更方便，在Hive中引入了bucket的概念，首先来看一下如何产生一个bucketed的table。</span></p><p style="margin-left:0px;"><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92276/94e58507-8d71-35a7-8e2c-dd0321cab81b.jpg" alt="" width="420" height="57" style="border-top-width:0px;border-right-width:0px;border-bottom-width:0px;border-left-width:0px;"></span></p><p style="margin-left:0px;"><span style="font-size:16px;">      首先需要将Hive的hive.enforce.bucketing属性设置为ture，然后加载数据：</span></p><p style="margin-left:0px;"><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92278/a68b8629-15f3-3466-a994-a9759697e45b.jpg" alt="" width="700" height="258" title="点击查看原始大小图片" class="magplus" style="border-top-width:0px;border-right-width:0px;border-bottom-width:0px;border-left-width:0px;"></span></p><p style="margin-left:0px;"><span style="font-size:16px;">       下面我们来看一下bucketed_user 下的数据文件结构,包含了四个部分。</span></p><p style="margin-left:0px;"><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92282/853249d7-280a-3247-a92c-cd593555da83.jpg" alt="" width="700" height="92" title="点击查看原始大小图片" class="magplus" style="border-top-width:0px;border-right-width:0px;border-bottom-width:0px;border-left-width:0px;"></span></p><p style="margin-left:0px;"><span style="font-size:16px;">      我们随便查看一个文件</span></p><p style="margin-left:0px;"><span style="font-size:16px;"><img src="http://dl.iteye.com/upload/picture/pic/92284/5d613212-1368-37d3-96f3-aa127df96cc2.jpg" alt="" width="700" height="41" title="点击查看原始大小图片" class="magplus" style="border-top-width:0px;border-right-width:0px;border-bottom-width:0px;border-left-width:0px;"></span></p><p style="margin-left:0px;"><span style="font-size:16px;">     可以看到id为1和5的记录被放进了同一个文件中，主要是应为我们设置了bucketed的参数为4，hive会按照id的hash值对4取模来确定存储的bucketed。</span></p><p style="margin-left:0px;"><span style="font-size:16px;"><br></span></p><p style="margin-left:0px;"><span style="font-size:16px;">更多的学习资料见：<a href="http://phz50.iteye.com/blog/932373" rel="nofollow">http://phz50.iteye.com/blog/932373</a></span></p>            </div>
                </div>