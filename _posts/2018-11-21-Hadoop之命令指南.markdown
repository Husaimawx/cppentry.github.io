---
layout:     post
title:      Hadoop之命令指南
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h3>概述<br></h3>
<p>所有的Hadoop命令都通过bin/hadoop脚本调用。在没有任何参数的情况下，运行Hadoop脚本将打印该命令描述。</p>
<p></p>
<pre><code class="language-java">[hduser@hadoop3 hadoop-2.4.1]$ bin/hadoop
Usage: hadoop [--config confdir] COMMAND
       where COMMAND is one of:
  fs                   run a generic filesystem user client
  version              print the version
  jar &lt;jar&gt;            run a jar file
  checknative [-a|-h]  check native hadoop and compression libraries availability
  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively
  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive
  classpath            prints the class path needed to get the
                       Hadoop jar and the required libraries
  daemonlog            get/set the log level for each daemon
 or
  CLASSNAME            run the class named CLASSNAME

Most commands print help when invoked w/o parameters.</code></pre>
<br><br><table border="1" cellpadding="2" cellspacing="0" style="border-collapse:collapse;background-color:rgb(255,255,255);font-family:'微软雅黑';letter-spacing:normal;text-indent:0px;"><thead style="background-color:inherit;"><tr style="background-color:inherit;"><th style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
字段</th>
<th style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
描述</th>
</tr></thead><tbody style="background-color:inherit;"><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
<code style="font-family:Monaco, Consolas, Courier, 'Lucida Console', monospace;font-style:normal;background-color:inherit;">--config confdir</code>
</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
配置文件目录，默认是：${HADOOP_HOME}/conf。</td>
</tr><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
<code style="font-family:Monaco, Consolas, Courier, 'Lucida Console', monospace;font-style:normal;background-color:inherit;">--loglevel loglevel</code>
</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
日志级别，有效的日志级别有：FATAL, ERROR, WARN, INFO, DEBUG, and TRACE. 默认是INFO。</td>
</tr></tbody></table><div>
<div>
<p><strong>通用选项</strong></p>
<table border="1" cellpadding="2" cellspacing="0" style="border-collapse:collapse;background-color:inherit;"><thead style="background-color:inherit;"><tr style="background-color:inherit;"><th style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
通用项</th>
<th style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
Description</th>
</tr></thead><tbody style="background-color:inherit;"><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
<code style="font-family:Monaco, Consolas, Courier, 'Lucida Console', monospace;font-style:normal;background-color:inherit;">-archives &lt;comma separated list of archives&gt;</code>
</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
用逗号分隔计算中未归档的文件。 仅仅针对JOB。</td>
</tr><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
<code style="font-family:Monaco, Consolas, Courier, 'Lucida Console', monospace;font-style:normal;background-color:inherit;">-conf &lt;configuration file&gt;</code>
</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
制定应用程序的配置文件Specify an application configuration file.</td>
</tr><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
<code style="font-family:Monaco, Consolas, Courier, 'Lucida Console', monospace;font-style:normal;background-color:inherit;">-D &lt;property&gt;=&lt;value&gt;</code>
</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
使用给定的属性值。</td>
</tr><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
<code style="font-family:Monaco, Consolas, Courier, 'Lucida Console', monospace;font-style:normal;background-color:inherit;">-files &lt;comma separated list of files&gt;</code>
</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
用逗号分隔的文件,拷贝到Map reduce机器，仅仅针对JOB</td>
</tr><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
<code style="font-family:Monaco, Consolas, Courier, 'Lucida Console', monospace;font-style:normal;background-color:inherit;">-jt &lt;local&gt; or &lt;resourcemanager:port&gt;</code>
</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
指定一个ResourceManager. 仅仅针对JOB。</td>
</tr><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
<code style="font-family:Monaco, Consolas, Courier, 'Lucida Console', monospace;font-style:normal;background-color:inherit;">-libjars &lt;comma seperated list of jars&gt;</code>
</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
将用逗号分隔的jar路径包含到classpath中去，仅仅针对JOB。</td>
</tr></tbody></table></div>
<br>
执行所有命令都是通过hadoop shell的命令的，可以分为用户命令和管理员命令。<br></div>
<p></p>
<p><strong><br></strong></p>
<h3><span style="font-size:18px;"><strong>用户命令</strong></span></h3>
<p>用于Hadoop集群用户命令。</p>
<h4><strong>Archive</strong></h4>
<p>Hadoop Archive是一个高效地将小文件放入HDFS块中的文件存档文件格式，它能够将多个小文件打包成一个后缀为.har文件，这样减少Namenode内存使用的同时（减少Namenode内存空间可以参考：Hdfs Federation），仍然允许对文件进行透明的访问。</p>
<p><img src="http://img.blog.csdn.net/20150806202927109?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></p>
<p>我们要知道创建Archive文件要消耗和原文件一样多的硬盘空间，并且Archive文件不支持压缩，一旦Archive文件创建了就无法改变。如果要修改Archive文件的内容，就需要重新创建Archive文件。<br></p>
<p>Hadoop Archive目录包含元数据文件（_index 和 _masterindex）和数据文件（part-*），这个_index文件包含了所有文件的名称和他对应part文件的位置。</p>
<p>（1）怎么使用Archive</p>
<p>使用：<tt><br></tt></p>
<p></p>
<pre><code class="language-java">hadoop archive -archiveName name -p &lt;parent&gt; [-r &lt;replication factor&gt;] &lt;src&gt;* &lt;dest&gt;</code></pre>-archiveName 你需要创建的archive的文件名， 例如：foo.har. 名字应该用*.har后缀。&lt;parent&gt;是指定Archive文件的相对路径，例如：<tt>-p /foo/bar a/b/c e/f/g</tt>
<p></p>
<p>这里 /foo/bar是a/b/c和e/f/g两个相对路径的父路径. 注意：Archive是MapReduce创建了。所以要在map reduce集群环境下运行它。</p>
<p><br></p>
<p>-r 指示所需的复制因子；如果该可选参数未指定，将使用10的复制因子。<br></p>
<tt>例如：将/</tt>flume<tt>/data目录下的文件归档到/flume文件夹下的test.har文件：</tt>
<p><tt></tt></p>
<pre><code class="language-java">hadoop archive -archiveName test.har -p /flume/ data/ /flume/</code></pre>
<p></p>
<p><tt>例如：使用通配符，将/user/fish/2015 10，11,12月归档到/user/test33文件夹下：</tt><br></p>
<p><tt></tt></p>
<pre><code class="language-java">hadoop archive -archiveName combine.har -p /user/fish2015 1[0-2] /user/test33</code></pre>
<tt></tt>
<p></p>
<p><tt></tt></p>
<div class="quote_div">
<tt>例如：不指定归档目录，直接归档parent目录：/user/fish/目录到/user/test33文件夹下：</tt><br><pre><code class="language-java">hadoop archive -archiveName combine.har -p /user/fish /user/test33</code></pre>
<tt><tt></tt></tt>
</div>
<p><tt></tt></p>
<div class="quote_div">
<tt><tt>例如：归档多个目录，归档/user/fish/目录下的111,222,333目录到/user/test33文件夹下：</tt></tt><br><pre><code class="language-java">hadoop archive -archiveName combine.har -p /user/fish/ 111 222 333 /user/test33</code></pre>
<tt><tt><tt></tt></tt></tt>
</div>
<br><p></p>
<p>（2）怎么查找Archive文件</p>
<p></p>
<pre><code class="language-java">[root@hadoopcluster78 bin]# ./hdfs dfs -ls /flume/test.har
Found 4 items
-rw-r--r-- 3 root supergroup 0 2015-09-22 10:43 /flume/test.har/_SUCCESS
-rw-r--r-- 5 root supergroup 541 2015-09-22 10:43 /flume/test.har/_index
-rw-r--r-- 5 root supergroup 23 2015-09-22 10:43 /flume/test.har/_masterindex
-rw-r--r-- 3 root supergroup 3609 2015-09-22 10:43 /flume/test.har/part-0
[root@hadoopcluster78 bin]# ./hdfs dfs -ls har:////flume/test.har/data
Found 4 items
-rw-r--r-- 3 root supergroup 779 2015-09-21 19:53 har:///flume/test.har/data/events-.1442836401377
-rw-r--r-- 3 root supergroup 1155 2015-09-21 19:54 har:///flume/test.har/data/events-.1442836453077
-rw-r--r-- 3 root supergroup 520 2015-09-21 19:55 har:///flume/test.har/data/events-.1442836494183
-rw-r--r-- 3 root supergroup 1155 2015-09-21 20:08 har:///flume/test.har/data/events-.1442837275306</code></pre>
<p></p>
<p><br></p>
<p>（3）怎样解压Archive文件<br></p>
<p></p>
<p>串行解压：</p>
<p></p>
<pre><code class="language-java">[root@hadoopcluster78 bin]# ./hdfs dfs -cp har:////flume/test.har/data /flume/data1</code></pre>
<p></p>
<p>并行解压（Mapreduce），使用DistCp:</p>
<p></p>
<pre><code class="language-java">[root@hadoopcluster78 bin]# ./hdfs dfs -cp har:////flume/test.har/data /flume/data2</code></pre>
<p></p>
<h4><strong>checknative</strong></h4>
<p>使用: hadoop checknative [-a] [-h]<br></p>
<p></p>
<div>
<table border="1" cellpadding="2" cellspacing="0" style="border-collapse:collapse;background-color:inherit;"><thead style="background-color:inherit;"><tr style="background-color:inherit;"><th style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
命令参数</th>
<th style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
描述</th>
</tr></thead><tbody style="background-color:inherit;"><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
<code style="font-family:Monaco, Consolas, Courier, 'Lucida Console', monospace;font-style:normal;background-color:inherit;">-a</code>
</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
核对所有libraries的可用性</td>
</tr><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
<code style="font-family:Monaco, Consolas, Courier, 'Lucida Console', monospace;font-style:normal;background-color:inherit;">-h</code>
</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
打印帮助</td>
</tr></tbody></table><p style="background-color:inherit;">这个命令用来核对可用的本地Code，默认情况下只核对libhadoop的可用性。</p>
<p style="background-color:inherit;"></p>
<pre><code class="language-java">[hadoop@hadoopcluster78 bin]$ hadoop checknative
15/08/07 10:48:25 WARN bzip2.Bzip2Factory: Failed to load/initialize native-bzip2 library system-native, will use pure-Java version
15/08/07 10:48:25 INFO zlib.ZlibFactory: Successfully loaded &amp; initialized native-zlib library
Native library checking:
hadoop: true /home/hadoop/apache/hadoop-2.4.1/lib/native/libhadoop.so
zlib:   true /lib64/libz.so.1
snappy: false 
lz4:    true revision:99
bzip2:  false </code></pre>
<p></p>
<h4><strong>classpath</strong></h4>
<p style="background-color:inherit;">使用: hadoop classpath [--glob |--jar &lt;path&gt; |-h |--help]<br></p>
<table border="1" cellpadding="2" cellspacing="0"><thead style="background-color:inherit;"><tr style="background-color:inherit;"><th style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
命令参数</th>
<th style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
描述</th>
</tr></thead><tbody style="background-color:inherit;"><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
<code style="font-family:Monaco, Consolas, Courier, 'Lucida Console', monospace;font-style:normal;background-color:inherit;">--glob</code>
</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
<div class="output-bd" dir="ltr">
<p class="ordinary-output target-output"><span>通配符</span></p>
</div>
</td>
</tr><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
<code style="font-family:Monaco, Consolas, Courier, 'Lucida Console', monospace;font-style:normal;background-color:inherit;">--jar</code><span></span><em style="background-color:inherit;">path</em>
</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
</td>
</tr><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
<code style="font-family:Monaco, Consolas, Courier, 'Lucida Console', monospace;font-style:normal;background-color:inherit;">-h</code>,<span></span><code style="font-family:Monaco, Consolas, Courier, 'Lucida Console', monospace;font-style:normal;background-color:inherit;">--help</code>
</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
打印帮助信息</td>
</tr></tbody></table><p></p>
<pre><code class="language-java">[hadoop@hadoopcluster78 bin]$ hadoop classpath
/home/hadoop/apache/hadoop-2.4.1/etc/hadoop:/home/hadoop/apache/hadoop-2.4.1/share/hadoop/common/lib/*:/home/hadoop/apache/hadoop-2.4.1/share/hadoop/common/*:/home/hadoop/apache/hadoop-2.4.1/share/hadoop/hdfs:/home/hadoop/apache/hadoop-2.4.1/share/hadoop/hdfs/lib/*:/home/hadoop/apache/hadoop-2.4.1/share/hadoop/hdfs/*:/home/hadoop/apache/hadoop-2.4.1/share/hadoop/yarn/lib/*:/home/hadoop/apache/hadoop-2.4.1/share/hadoop/yarn/*:/home/hadoop/apache/hadoop-2.4.1/share/hadoop/mapreduce/lib/*:/home/hadoop/apache/hadoop-2.4.1/share/hadoop/mapreduce/*:/home/hadoop/apache/hadoop-2.4.1/contrib/capacity-scheduler/*.jar</code></pre>
<br><p></p>
<h4><strong>credential</strong></h4>
<p>使用: hadoop credential &lt;subcommand&gt; [options]</p>
<p><br></p>
<table border="1" cellpadding="2" cellspacing="0"><thead style="background-color:inherit;"><tr style="background-color:inherit;"><th style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
命令参数</th>
<th style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
描述</th>
</tr></thead><tbody style="background-color:inherit;"><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
create<span></span><em style="background-color:inherit;">alias</em><span></span>[-provider<span></span><em style="background-color:inherit;">provider-path</em>]</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
提示证书被存储为指定别名的用户。如果没有-provider选项的话，那么将会默认使用core-site.xml文件中hadoop.security.credential.provider.path项对应的值。</td>
</tr><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
delete<span></span><em style="background-color:inherit;">alias</em><span></span>[-provider<span></span><em style="background-color:inherit;">provider-path</em>] [-f]</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
删除与所提供的别名对应的证书文件。如果没有-provider选项的话，那么将会默认使用core-site.xml文件中hadoop.security.credential.provider.path项对应的值。这项操作需要通过用户的确认，除非使用了-f选项。</td>
</tr><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
list [-provider<span></span><em style="background-color:inherit;">provider-path</em>]</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
列出所有的证书别名。如果没有-provider选项的话，那么将会默认使用core-site.xml文件中hadoop.security.credential.provider.path项对应的值。</td>
</tr></tbody></table><p>该命令在凭证提供者内部管理凭证（credentials），密码（passwords）和秘密（secrets）。</p>
<p><br></p>
<p>Hadoop的CredentialProvider API支持应用程序拆分，并且要求拆分后的应用如何储存所需的密码（passwords）和秘密（secrets）。为了指明一个Provider的位置和类型，需要在core-site.xml添加hadoop.security.credential.provider.path配置项，或者通过指令中-provider命令选项进行设置。Provider路径是一串以逗号分割的URL字符串。这些字符串会说明Provider的类型和位置，举个例子：</p>
<p></p>
<div>
<pre><code class="language-java">user:///,jceks://file/tmp/test.jceks,jceks:/hdfs@nn1.example.com/my/path/test.jceks</code></pre>
<br>
指示当前用户的凭证，需要通过User Provider咨询。存储在本地文件系统的文件/tmp/test.jceks是一个Java Keystore Provider，相应的存储在hdfs上的文件nn1.example.com/my/path/test.jcek也是一个Java Keystore Provider。<br><br>
当使用credential命令时，它通常要提供密码（password）或秘密（secret）给一个特定的凭证存储provider。为了清晰的表明要显示使用哪个provider存储，可以在命令中使用-provider选项。否则，给定多个provider的时候，则使用的哥非持久的provider，这可能不是你预期的<br>
例如：hadoop credential list -provider jceks://file/tmp/test.jceks<br><br><h4><strong>distcp</strong></h4>
<p>递归的拷贝文件或者目录。查看上面的示例。<a href="http://blog.csdn.net/qianshangding0708/article/details/47321523" rel="nofollow"></a><br></p>
<strong><br></strong>
<h4><strong>fs</strong></h4>
和hdfs脚本的dfs类似<strong><br><br></strong>
<h4><strong>jar</strong></h4>
<p>使用: <tt>hadoop jar &lt;jar&gt; [mainClass] args...</tt></p>
<p>运行一个jar文件<br></p>
<strong><br></strong>
<h4><strong>key</strong></h4>
通过KeyProvider管理秘钥<strong><br><br></strong>
<h4><strong>trace</strong></h4>
查看和修改Hadoop跟踪（tracing）设置。查看：跟踪（tracing）指南。<strong><br><br></strong>
<h4><strong>version</strong></h4>
查看hadoop版本<strong><br></strong><pre><code class="language-java">[hadoop@hadoopcluster78 bin]$ hadoop version
Hadoop 2.4.1
Subversion Unknown -r Unknown
Compiled by root on 2014-07-13T01:39Z
Compiled with protoc 2.5.0
From source with checksum bb7ac0a3c73dc131f4844b873c74b630
This command was run using /home/hadoop/apache/hadoop-2.4.1/share/hadoop/common/hadoop-common-2.4.1.jar</code></pre>
<br><h4><span style="font-size:14px;"><strong><strong>CLASSNAME</strong></strong></span></h4>
</div>
使用: hadoop CLASSNAME<br>
运行一个名字叫 CLASSNAME的类。<br><p></p>
<p><span style="font-size:18px;"><strong><br></strong></span></p>
<h3><span style="font-size:18px;"><strong>用户命令</strong></span></h3>
<p>对于hadoop集群管理员很有用的一些命令。<br><br></p>
<h4>daemonlog</h4>
<p>用以设置或获取指定后台进程的日志级别<br></p>
<p>使用：</p>
<p>hadoop daemonlog -getlevel &lt;host:httpport&gt; &lt;classname&gt;</p>
<p>hadoop daemonlog -setlevel &lt;host:httpport&gt; &lt;classname&gt; &lt;level&gt;</p>
<p><br></p>
<table border="1" cellpadding="2" cellspacing="0"><thead style="background-color:inherit;"><tr style="background-color:inherit;"><th style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
COMMAND_OPTION</th>
<th style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
Description</th>
</tr></thead><tbody style="background-color:inherit;"><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
<code style="font-family:Monaco, Consolas, Courier, 'Lucida Console', monospace;font-style:normal;background-color:inherit;">-getlevel</code><em style="background-color:inherit;">host:httpportclassname</em>
</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
打印运行在&lt;host:port&gt;的守护进程的日志级别。这个命令内部会连接http://&lt;host:port&gt;/logLevel?log=&lt;name&gt;</td>
</tr><tr style="background-color:inherit;"><td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
<code style="font-family:Monaco, Consolas, Courier, 'Lucida Console', monospace;font-style:normal;background-color:inherit;">-setlevel</code><em style="background-color:inherit;">host:httpportclassnamelevel</em>
</td>
<td style="border:1px solid rgb(153,153,153);min-width:25px;background-color:inherit;">
设置运行在&lt;host:port&gt;的守护进程的日志级别。这个命令内部会连接http://&lt;host:port&gt;/logLevel?log=&lt;name&gt;</td>
</tr></tbody></table>
例如：
<p></p>
<pre><code class="language-java">[root@hadoopcluster78 ~]# hadoop daemonlog -setlevel hadoopcluster78:50070 org.apache.hadoop.hdfs.server.namenode.NameNode WARN
Connecting to http://hadoopcluster78:50070/logLevel?log=org.apache.hadoop.hdfs.server.namenode.NameNode&amp;level=WARN
Submitted Log Name: org.apache.hadoop.hdfs.server.namenode.NameNode
Log Class: org.apache.commons.logging.impl.Log4JLogger
Submitted Level: WARN
Setting Level to WARN ...
Effective level: WARN
[root@hadoopcluster78 ~]# hadoop daemonlog -getlevel hadoopcluster78:50070 org.apache.hadoop.hdfs.server.namenode.NameNode
Connecting to http://hadoopcluster78:50070/logLevel?log=org.apache.hadoop.hdfs.server.namenode.NameNode
Submitted Log Name: org.apache.hadoop.hdfs.server.namenode.NameNode
Log Class: org.apache.commons.logging.impl.Log4JLogger
Effective level: WARN</code></pre>
</div>            </div>
                </div>