---
layout:     post
title:      深入浅出学Hive：Hive高级编程
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>目录：</p>

<p><a href="http://blog.csdn.net/guohecang/article/details/51576755" rel="nofollow">初始Hive</a></p>

<p><a href="http://blog.csdn.net/guohecang/article/details/51576829" rel="nofollow">Hive安装与配置</a></p>

<p><a href="http://blog.csdn.net/guohecang/article/details/51576891" rel="nofollow">Hive内建操作符与函数开发</a></p>

<p><a href="http://blog.csdn.net/guohecang/article/details/51576917" rel="nofollow">Hive JDBC</a></p>

<p><a href="http://blog.csdn.net/guohecang/article/details/51576933" rel="nofollow">Hive参数</a></p>

<p><a href="http://blog.csdn.net/guohecang/article/details/51576957" rel="nofollow">Hive高级编程</a></p>

<p><a href="http://blog.csdn.net/guohecang/article/details/51576975" rel="nofollow">Hive QL</a></p>

<p><a href="http://blog.csdn.net/guohecang/article/details/51576993" rel="nofollow">Hive Shell基本操作</a></p>

<p><a href="http://blog.csdn.net/guohecang/article/details/51577027" rel="nofollow">Hive优化</a></p>

<p><a href="http://blog.csdn.net/guohecang/article/details/51577040" rel="nofollow">Hive体系结构</a></p>

<p><a href="http://blog.csdn.net/guohecang/article/details/51577052" rel="nofollow">Hive原理</a></p>

<p> </p>

<p> </p>

<p> </p>

<p>第一部分：产生背景</p>

<p>产生背景</p>

<p>•为了满足客户个性化的需求，Hive被设计成一个很开放的系统，很多内容都支持用户定制，包括：</p>

<p>•文件格式：Text File，Sequence File</p>

<p>•内存中的数据格式： Java Integer/String, Hadoop  IntWritable/Text</p>

<p>•用户提供的 map/reduce 脚本：不管什么语言，利用 stdin/stdout 传输数据</p>

<p>•用户自定义函数</p>

<p>自定义函数</p>

<p>•虽然Hive提供了很多函数，但是有些还是难以满足我们的需求。因此Hive提供了自定义函数开发</p>

<p>•自定义函数包括三种UDF、UADF、UDTF</p>

<p>•UDF(User-Defined-Function)</p>

<p>•UDAF（User- Defined Aggregation Funcation）</p>

<p>•UDTF(User-Defined Table-Generating Functions)  用来解决 输入一行输出多行(On-to-many maping) 的需求。 </p>

<p>HIVE中使用定义的函数的三种方式</p>

<p>•在HIVE会话中add 自定义函数的jar文件，然后创建function，继而使用函数</p>

<p>•在进入HIVE会话之前先自动执行创建function，不用用户手工创建</p>

<p>•把自定义的函数写到系统函数中，使之成为HIVE的一个默认函数，这样就不需要create temporary function</p>

<p> </p>

<p>第二部分：UDF</p>

<p>UDF用法</p>

<p>•UDF(User-Defined-Function)</p>

<p>•UDF函数可以直接应用于select语句，对查询结构做格式化处理后，再输出内容</p>

<p>•编写UDF函数的时候需要注意一下几点</p>

<p>•自定义UDF需要继承org.apache.hadoop.hive.ql.UDF</p>

<p>•需要实现evaluate函数</p>

<p>•evaluate函数支持重载</p>

<p>•UDF只能实现一进一出的操作，如果需要实现多进一出，则需要实现UDAF</p>

<p>UDF用法代码示例</p>

<p> </p>

<p>import org.apache.Hadoop.hive.ql.exec.UDF   </p>

<p>   public  class Helloword  extends UDF{   </p>

<p>      public String evaluate(){   </p>

<p>           return "hello world!";   </p>

<p>     }   </p>

<p>  </p>

<p>      public String evaluate(String str){   </p>

<p>           return "hello world: " + str;   </p>

<p>     }   </p>

<p>}</p>

<p>开发步骤</p>

<p>•开发代码</p>

<p>•把程序打包放到目标机器上去</p>

<p>•进入hive客户端</p>

<p>•添加jar包：hive&gt;add jar /run/jar/udf_test.jar;</p>

<p>•创建临时函数：hive&gt;CREATE TEMPORARY FUNCTION my_add AS 'com.hive.udf.Add ‘</p>

<p>•查询HQL语句：</p>

<p>•SELECT my_add (8, 9) FROM scores;</p>

<p>•SELECT my_add (scores.math, scores.art) FROM scores;</p>

<p>•销毁临时函数：hive&gt; DROP TEMPORARY FUNCTION my_add ;</p>

<p>•细节</p>

<p>•在使用UDF的时候，会自动进行类型转换，例如： <br>
SELECT my_add (8,9.1) FROM scores;</p>

<p>•结果是17.1，UDF将类型为Int的参数转化成double。类型的饮食转换是通过UDFResolver来进行控制的</p>

<p>第三部分：UDAF</p>

<p>UDAF</p>

<p>•Hive查询数据时，有些聚类函数在HQL没有自带，需要用户自定义实现</p>

<p>•用户自定义聚合函数: Sum, Average…… n – 1</p>

<p>•UDAF（User- Defined Aggregation Funcation） </p>

<p>用法</p>

<p>•一下两个包是必须的import org.apache.hadoop.hive.ql.exec.UDAF和 org.apache.hadoop.hive.ql.exec.UDAFEvaluator</p>

<p>开发步骤</p>

<p>•函数类需要继承UDAF类，内部类Evaluator实UDAFEvaluator接口</p>

<p>•Evaluator需要实现 init、iterate、terminatePartial、merge、terminate这几个函数</p>

<p>a）init函数实现接口UDAFEvaluator的init函数。</p>

<p>b）iterate接收传入的参数，并进行内部的轮转。其返回类型为boolean。</p>

<p>c）terminatePartial无参数，其为iterate函数轮转结束后，返回轮转数据，terminatePartial类似于hadoop的Combiner。</p>

<p>d）merge接收terminatePartial的返回结果，进行数据merge操作，其返回类型为boolean。</p>

<p>e）terminate返回最终的聚集函数结果。</p>

<p>执行步骤</p>

<p>•执行求平均数函数的步骤</p>

<p>a）将java文件编译成Avg_test.jar。</p>

<p>b）进入hive客户端添加jar包：</p>

<p>hive&gt;add jar /run/jar/Avg_test.jar。</p>

<p>c）创建临时函数：</p>

<p>hive&gt;create temporary function avg_test 'hive.udaf.Avg';</p>

<p>d）查询语句：</p>

<p>hive&gt;select avg_test(scores.math) from scores;</p>

<p>e）销毁临时函数：</p>

<p>hive&gt;drop temporary function avg_test;</p>

<p> </p>

<p>UDAF代码示例</p>

<p>public class MyAvg extends UDAF {</p>

<p> </p>

<p>public static class AvgEvaluator implements UDAFEvaluator {</p>

<p>}</p>

<p>public void init() {}</p>

<p>public boolean iterate(Double o) {}</p>

<p>public AvgState terminatePartial() {}</p>

<p>public boolean terminatePartial(Double o) { }</p>

<p>public Double terminate() {}</p>

<p> </p>

<p>}</p>

<p>第四部分：UDTF</p>

<p>UDTF</p>

<p>•UDTF(User-Defined Table-Generating Functions)  用来解决 输入一行输出多行(On-to-many maping) 的需求。</p>

<p>开发步骤</p>

<p>•UDTF步骤：</p>

<p>•必须继承org.apache.Hadoop.hive.ql.udf.generic.GenericUDTF</p>

<p>•实现initialize, process, close三个方法</p>

<p>•UDTF首先会</p>

<p>•调用initialize方法，此方法返回UDTF的返回行的信息（返回个数，类型） <br>
初始化完成后，会调用process方法，对传入的参数进行处理，可以通过forword()方法把结果返回</p>

<p>•最后close()方法调用，对需要清理的方法进行清理</p>

<p>使用方法</p>

<p>•UDTF有两种使用方法，一种直接放到select后面，一种和lateral view一起使用</p>

<p>•直接select中使用：select explode_map(properties) as (col1,col2) from src;</p>

<p>•不可以添加其他字段使用：select a, explode_map(properties) as (col1,col2) from src</p>

<p>•不可以嵌套调用：select explode_map(explode_map(properties)) from src</p>

<p>•不可以和group by/cluster by/distribute by/sort by一起使用：select explode_map(properties) as (col1,col2) from src group by col1, col2</p>

<p>•和lateral view一起使用：select src.id, mytable.col1, mytable.col2 from src lateral view explode_map(properties) mytable as col1, col2;</p>

<p>此方法更为方便日常使用。执行过程相当于单独执行了两次抽取，然后union到一个表里。</p>

<p>lateral view</p>

<p>• Lateral View语法</p>

<p>•lateralView: LATERAL VIEW udtf(expression) tableAlias AS columnAlias (',' columnAlias)* fromClause: FROM baseTable (lateralView)*  </p>

<p> </p>

<p>•Lateral View用于UDTF(user-defined table generating functions)中将行转成列，例如explode().</p>

<p>•目前Lateral View不支持有上而下的优化。如果使用Where子句，查询可能将不被编译。解决方法见：</p>

<p>     此时，在查询之前执行set hive.optimize.ppd=false;</p>

<p>•  例子</p>

<p>•pageAds。它有两个列</p>

<table cellpadding="0" cellspacing="0"><tbody><tr><td>
			<p>string pageid</p>
			</td>
			<td>
			<p>Array&lt;int&gt; adid_list</p>
			</td>
		</tr><tr><td>
			<p>" front_page"</p>
			</td>
			<td>
			<p>[1, 2, 3]</p>
			</td>
		</tr><tr><td>
			<p>"contact_page "</p>
			</td>
			<td>
			<p>[ 3, 4, 5]</p>
			</td>
		</tr></tbody></table><p>•SELECT pageid, adid FROM pageAds LATERAL VIEW explode(adid_list) adTable AS adid;</p>

<p>•将输出如下结果</p>

<p>string pageid int adid</p>

<p>"front_page" 1</p>

<p>…….</p>

<p>“contact_page" 3</p>

<p> </p>

<p>代码示例</p>

<p>public class MyUDTF extends GenericUDTF{</p>

<p>public StructObjectInspector initialize(ObjectInspector[] args) {}</p>

<p>public void process(Object[] args) throws HiveException { }</p>

<p>}</p>

<p>实现：切分 ” key:value;key:value;” 这种字符串， 返回结果为 key, value 两个字段</p>

<p>转载请注明出处【 <a href="http://sishuok.com/forum/blogPost/list/6226.html" rel="nofollow">http://sishuok.com/forum/blogPost/list/6226.html</a>】</p>            </div>
                </div>