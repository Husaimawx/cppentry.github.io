---
layout:     post
title:      Hive入门--4.flume-数据收集工具
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/u014726937/article/details/51993674				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h1 id="flume简介">Flume简介</h1>

<p><font size="4"> <br>
 　　flume是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。支持在日志系统中定制各类数据发送方，用于收集数据;同时，Flume提供对数据进行简单处理，并写到各种数据接受方(比如文本、HDFS、Hbase等)的能力 。 <br>
<font size="4"> <br>
　　flume的数据流由事件(Event)贯穿始终。事件是Flume的基本数据单位，它携带日志数据(字节数组形式)并且携带有头信息，这些Event由Agent外部的Source生成，当Source捕获事件后会进行特定的格式化，然后Source会把事件推入(单个或多个)Channel中。你可以把Channel看作是一个缓冲区，它将保存事件直到Sink处理完该事件。Sink负责持久化日志或者把事件推向另一个Source。</font></font></p>

<p><img src="https://img-blog.csdn.net/20160724100635304" alt="这里写图片描述" title=""></p>

<h1 id="flume安装">Flume安装</h1>



<h2 id="1-解压-flume安装包到-itcast-目录下">1.   解压 flume安装包到 /itcast/ 目录下</h2>

<p><font size="4" face="consolas" color="#0066CC"> <br>
tar -zxvf /*flume安装包*/  /itcast/</font></p>



<h2 id="2-修改-flume配置文件">2.   修改 flume配置文件：</h2>



<h2 id="21-flume-envsh">2.1  flume-env.sh</h2>

<p>修改文件名称： <br>
<font size="4" face="consolas" color="#0066CC"> <br>
mv flume-env.sh.template flume-env.sh</font></p>

<p>添加<code>java_home</code>，保证<code>flume</code>所使用的jdk和hdfs是一样的（可以使用 <code>echo JAVA_HOME</code> 查看当前机器所使用的javaHome所在路径）</p>



<h2 id="22-编写agent配置文件a4conf">2.2  编写agent配置文件a4.conf</h2>



<h3 id="定义agent名-sourcechannelsink的名称">定义agent名， source、channel、sink的名称</h3>

<p><font size="4" face="consolas" color="#0066CC"> <br>
a4.sources = r1 <br>
a4.channels = c1 <br>
a4.sinks = k1</font></p>



<h3 id="具体定义source">具体定义source</h3>

<p><font size="4" face="consolas" color="#0066CC"> <br>
a4.sources.r1.type = spooldir       #具体实现类是通过反射加载的 <br>
a4.sources.r1.spoolDir = /root/logs  #监听这个目录</font></p>



<h3 id="具体定义channel">具体定义channel</h3>

<p><font size="4" face="consolas" color="#0066CC"> <br>
a4.channels.c1.type = memory    # <br>
a4.channels.c1.capacity = 10000 #多少条数据进行一次发送  <br>
a4.channels.c1.transactionCapacity = 100    #事物的容量</font></p>



<h3 id="定义拦截器为消息添加时间戳">定义拦截器，为消息添加时间戳</h3>

<p><font size="4" face="consolas" color="#0066CC"> <br>
a4.sources.r1.interceptors = i1 <br>
a4.sources.r1.interceptors.i1.type= org.apache.flume.interceptor.TimestampInterceptor$Builder</font></p>



<h3 id="具体定义sink">具体定义sink</h3>

<p><font size="4" face="consolas" color="#0066CC"> <br>
a4.sinks.k1.type = hdfs <br>
a4.sinks.k1.hdfs.path = hdfs://ns1/flume/%Y%m%d #根据时间动态生成 <br>
a4.sinks.k1.hdfs.filePrefix = events-   #产生日志的前缀 <br>
a4.sinks.k1.hdfs.fileType = DataStream  #纯文本方式接收</font></p>



<h3 id="不按照条数生成文件">不按照条数生成文件</h3>

<p><font size="4" face="consolas" color="#0066CC"> <br>
a4.sinks.k1.hdfs.rollCount = 0      #多少条flush成1个文件</font></p>



<h3 id="hdfs上的文件达到128m时生成一个文件">HDFS上的文件达到128M时生成一个文件</h3>

<p><font size="4" face="consolas" color="#0066CC"> <br>
a4.sinks.k1.hdfs.rollSize = 134217728   #文件达到多大时flush成一个文件 </font></p>



<h3 id="hdfs上的文件达到60秒生成一个文件">HDFS上的文件达到60秒生成一个文件</h3>

<p><font size="4" face="consolas" color="#0066CC"> <br>
a4.sinks.k1.hdfs.rollInterval = 60  #flush成一个文件的时间间隔</font></p>



<h3 id="组装sourcechannelsink">组装source、channel、sink</h3>

<p><font size="4" face="consolas" color="#0066CC"> <br>
a4.sources.r1.channels = c1 <br>
a4.sinks.k1.channel = c1</font></p>



<h1 id="3-启动flume">3.    启动flume</h1>

<p><font size="4" face="微软雅黑"> <br>
先切换到 <code>/itcast/apache-flume-1.5.0-bin/</code> 目录下:</font></p>

<p>输入命令： <br>
<font size="4" face="consolas" color="#0066CC"> <br>
 bin/flume-ng agent -n a4 -c conf -f conf a4.conf -Dflume.root.logger=INFO,console</font></p>

<p>命令解释：</p>

<p><img src="https://img-blog.csdn.net/20160724100705288" alt="这里写图片描述" title=""></p>

<p><font size="4" face="微软雅黑"> <br>
<strong>启动后有可能遇到如下的错误，这里一一列举出来，出错的童鞋对号入座：</strong></font></p>

<p><font size="4" face="微软雅黑"> <br>
<strong>错误1：</strong> <br>
<img src="https://img-blog.csdn.net/20160724100735335" alt="这里写图片描述" title=""> <br>
 <font size="4" face="微软雅黑"> <br>
<strong>解决：</strong>说明缺少jar包，拷贝 <code>/itcast/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar</code> 到 <code>/itcast/apache-flume-1.5.0-bin/lib/</code> 文件夹下</font></font></p>

<p>使用scp命令： <br>
<img src="https://img-blog.csdn.net/20160724100822539" alt="这里写图片描述" title=""></p>

<p><font size="4" face="微软雅黑"> <br>
<strong>错误2：</strong> <br>
 <img src="https://img-blog.csdn.net/20160724100840557" alt="这里写图片描述" title=""></font></p>

<p><font size="4" face="微软雅黑"> <br>
解决：说明缺少jar包，拷贝<code>/itcast/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-.jar</code>到<code>/itcast/apache-flume-1.5.0-bin/lib/</code>文件夹下 <br>
 <img src="https://img-blog.csdn.net/20160724100854586" alt="这里写图片描述" title=""></font></p>

<p><font size="4" face="微软雅黑"> <br>
<strong>错误3：</strong> <br>
 <img src="https://img-blog.csdn.net/20160724100908683" alt="这里写图片描述" title=""> <br>
 <font size="4" face="微软雅黑"></font></font></p>

<p>解决：将/itcast/hadoop-2.6.0/share/hadoop/common/lib/ hadoop-auth-2.6.0.jar拷贝到flume/lib目录下</p>

<p><font size="4" face="微软雅黑"> <br>
<strong>错误4：</strong> <br>
 <img src="https://img-blog.csdn.net/20160724100926399" alt="这里写图片描述" title=""> <br>
 <font size="4" face="微软雅黑"></font></font></p>

<p>解决：在 /root目录下创建logs目录 ：mkdir /root/logs</p>

<p><font size="4" face="微软雅黑"> <br>
<strong>错误5：</strong></font></p>

<p><img src="https://img-blog.csdn.net/20160724101024841" alt="这里写图片描述" title=""></p>

<p><font size="4" face="微软雅黑"> <br>
解决：告知flume ns1的配置信息</font></p>

<p>1）拷贝core-site.xml和 hdfs-site.xml到flume的conf目录下</p>



<pre class="prettyprint"><code class=" hljs ruby">scp /itcast/hadoop-<span class="hljs-number">2.6</span>.<span class="hljs-number">0</span>/etc/hadoop/{core-site.xml, hdfs-site.xml}  

<span class="hljs-number">192.168</span>.<span class="hljs-number">1.204</span><span class="hljs-symbol">:/itcast/apache-flume-</span><span class="hljs-number">1.5</span>.<span class="hljs-number">0</span>-bin/conf</code></pre>

<p>2）修改/etc/hosts 文件，让该主机知道itcast01 和itcast02的IP地址</p>

<p>添加itcast01 和itcast02 ip和主机名的映射</p>

<p>3）拷贝hadoop-hdfs-2.6.0.jar</p>

<p><img src="https://img-blog.csdn.net/20160724101039841" alt="这里写图片描述" title=""></p>

<p><font size="4" face="微软雅黑"> <br>
如果出现如下的内容并且显示在不断滚动，说明没问题了，flume启动成功！ <br>
 启动成功之后的样子应该是这样的： <br>
<img src="https://img-blog.csdn.net/20160724101218540" alt="" title=""></font></p>



<h2 id="31-写入测试">3.1  写入测试</h2>

<p>现在如果向 /root/logs 目录下丢进文件，flume则会将这个文件下的内容写入hdfs中</p>

<p>先执行命令：</p>



<pre class="prettyprint"><code class=" hljs lasso">    bin/flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-attribute">-n</span> a4 <span class="hljs-attribute">-c</span> conf <span class="hljs-attribute">-f</span> conf/a4<span class="hljs-built_in">.</span>conf 
    <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>INFO,console</code></pre>

<p>启动flume之后，将日志文件 <strong>access_2013_05_30.log</strong> 放到 logs 文件夹下： <br>
<img src="https://img-blog.csdn.net/20160724101253869" alt="这里写图片描述" title=""></p>

<p><img src="https://img-blog.csdn.net/20160724101309517" alt="这里写图片描述" title=""> <br>
通过网页查看hdfs，发现多了一个目录  <strong>/flume</strong> ，在这个目录下的文件有 <strong>20160618</strong> ，说明文件是以时间命名的 <br>
<img src="https://img-blog.csdn.net/20160724101743914" alt="这里写图片描述" title=""> <br>
在 <strong>/flume/20160618</strong> 这个文件夹下</p>

<p><img src="https://img-blog.csdn.net/20160724101751856" alt="这里写图片描述" title=""> <br>
<font size="4" face="微软雅黑"> <br>
<strong>问题</strong>：为什么生成的是3个文件，我写入的不是1个吗？而且这3个文件大小加起来刚好等于日志文件access_2013_05_30.log的大小</font></p>

<p><font size="4" face="微软雅黑"> <br>
<strong>原因</strong>：这里sink设置了每60秒滚动写入一次或者当缓冲区文件大小达到134217728字节（128M）时进行滚动写入。 <br>
<font size="4" face="微软雅黑"> <br>
通过计算时间，写入总共花费几分钟，那势必第二个滚动选项是无法满足的，所以文件每60s的时候刚刚读入了一部分，接着就被写入hdfs中了。</font></font></p>



<h1 id="4flume的另外一种配置">4.flume的另外一种配置</h1>

<p><font size="5" face="consolas" color="#336633"> <br>
source—exec <br>
channel—memory  <br>
sink—logger</font></p>

<p><font size="4" face="微软雅黑"> <br>
启动方式和之前的一样，只是读入的配置文件不同： <br>
<font size="4" face="consolas" color="#0066CC"> <br>
bin/flume-ng agent -n a2 -f /home/hadoop/a2.conf -c conf -Dflume.root.logger=INFO,console</font></font></p>

<p><strong>a2.conf配置文件：</strong></p>



<h3 id="定义agent名-sourcechannelsink的名称-1">定义agent名， source、channel、sink的名称</h3>

<p><font size="4" face="consolas" color="#0066CC"> <br>
a2.sources = r1 <br>
a2.channels = c1 <br>
a2.sinks = k1</font></p>



<h3 id="具体定义source-1">具体定义source</h3>

<p><font size="4" face="consolas" color="#0066CC"> <br>
a2.sources.r1.type = exec <br>
a2.sources.r1.command = tail -F /home/hadoop/a.log</font></p>



<h3 id="具体定义channel-1">具体定义channel</h3>

<p><font size="4" face="consolas" color="#0066CC"> <br>
a2.channels.c1.type = memory <br>
a2.channels.c1.capacity = 1000 <br>
a2.channels.c1.transactionCapacity = 100</font></p>



<h3 id="具体定义sink-1">具体定义sink</h3>

<p><font size="4" face="consolas" color="#0066CC"> <br>
a2.sinks.k1.type = logger</font></p>



<h3 id="组装sourcechannelsink-1">组装source、channel、sink</h3>

<p><font size="4" face="consolas" color="#0066CC"> <br>
a2.sources.r1.channels = <font color="#0066CC">c1</font> <br>
a2.sinks.k1.channel = c1</font></p>

<p>监控当有数据写入这个log文件中时，flume将这些数据采集并打印在控制台上 <br>
a)  就像tail –F file 命令一样</p>



<pre class="prettyprint"><code class=" hljs bash">    <span class="hljs-comment"># echo 111111 &gt;&gt; log</span>
    <span class="hljs-comment"># echo 222222 &gt;&gt; log</span>
    <span class="hljs-comment"># echo 333333 &gt;&gt; log</span></code></pre>

<p>以阻塞形式打印，向log文件中追加记录 <br>
 <img src="https://img-blog.csdn.net/20160724101837400" alt="这里写图片描述" title=""></p>

<p>b)  以a2.conf配置文件运行flume  <br>
将a2.conf文件拷贝到flume/conf 目录下 <br>
在/root目录下创建文件log</p>

<p>运行命令：</p>



<pre class="prettyprint"><code class=" hljs lasso">    bin/flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-attribute">-n</span> a2 <span class="hljs-attribute">-f</span> /itcast/apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.0</span><span class="hljs-attribute">-bin</span>/conf/a2<span class="hljs-built_in">.</span>conf 
    <span class="hljs-attribute">-c</span> conf <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>INFO,console</code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>