---
layout:     post
title:      大数据集群搭建（10）——Flume的多节点集群搭建
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p style="margin-left:0pt;"><strong><strong>Flume的多节点集群搭建</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>1.将主节点的flume拷贝到其他节点上</strong></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#df402a;"><strong>scp -r  /usr/flume/ root@slaver1:/usr/flume/</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#df402a;"><strong>scp -r  /usr/flume/ root@slaver2:/usr/flume/</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><strong>2. 在master上面配置conf文件：  从某个文件夹里面采集数据，采集到的数据sink到slaver2里面(文件名:m-s2.conf)</strong></strong></p>

<blockquote>
<p style="margin-left:0pt;"><strong><strong>##########################################################</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>##主要作用是监听目录中的新增数据，采集到数据之后，输出到avro （输出到agent）</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>##    注意：Flume agent的运行，主要就是配置source channel sink</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>##  下面的a1就是agent的代号，source叫r1 channel叫c1 sink叫k1</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>#########################################################</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sources = r1</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sinks = k1</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.channels = c1</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>#具体定义source  </strong></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#df402a;"><strong>a1.sources.r1.type = spooldir</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><strong>#先创建此目录，保证里面空的  </strong></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#df402a;"><strong>a1.sources.r1.spoolDir = /logs</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><strong>#对于sink的配置描述 使用avro日志做数据的消费</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sinks.k1.type = </strong></strong><strong><span style="color:#0000ff;"><strong>avro</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#df402a;"><strong>a1.sinks.k1.hostname = slaver2</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sinks.k1.port = 44444</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>#对于channel的配置描述 使用文件做数据的临时缓存 这种的安全性要高</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.channels.c1.type = file</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.channels.c1.checkpointDir = /home/uplooking/data/flume/checkpoint</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.channels.c1.dataDirs = /home/uplooking/data/flume/data</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>#通过channel c1将source r1和sink k1关联起来</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sources.r1.channels = c1</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>a1.sinks.k1.channel = c1</strong></strong></p>
</blockquote>

<p style="margin-left:0pt;"><strong><strong>3. 在slaver1上面写配置文件   （master和slaver1是一样的）</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>(文件名:s1-s2.conf）</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>4. 写slaver2的配置文件： 从master,slaver1上获取数据，sink到hdfs上；</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>(文件名:s2-hdfs.conf）</strong></strong></p>

<blockquote>
<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>#########################################################</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>## 获取zhiyou01,02上的数据，聚合起来，传到hdfs上面</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>##    注意：Flume agent的运行，主要就是配置source channel sink</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>##  下面的a1就是agent的代号，source叫r1 channel叫c1 sink叫k1</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>#########################################################</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.sources = r1</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.sinks = k1</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.channels = c1</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>#对于source的配置描述 监听avro</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.sources.r1.type = </strong></span></strong><strong><span style="color:#528cd8;"><strong>avro</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#df402a;"><strong>a1.sources.r1.bind = slaver2</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.sources.r1.port = 44444</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>#定义拦截器，为消息添加时间戳  </strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.sources.r1.interceptors = i1  </strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.sources.r1.interceptors.i1.type = org.apache.flume.interceptor.TimestampInterceptor$Builder</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>#对于sink的配置描述 传递到hdfs上面</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.sinks.k1.type = hdfs  </strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>             #集群的nameservers名字</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>             #单节点的直接写：hdfs://master:9000/xxx</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.sinks.k1.hdfs.path = </strong></span></strong><strong><span style="color:#df402a;"><strong>hdfs://master:9000/flume/%Y%m%d </strong></span></strong><strong> </strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.sinks.k1.hdfs.filePrefix = events-  </strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.sinks.k1.hdfs.fileType = DataStream  </strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>#不按照条数生成文件  </strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.sinks.k1.hdfs.rollCount = 0  </strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>#HDFS上的文件达到128M时生成一个文件  </strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.sinks.k1.hdfs.rollSize = 134217728  </strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>#HDFS上的文件达到60秒生成一个文件  </strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.sinks.k1.hdfs.rollInterval = 60  </strong></span> </strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>#对于channel的配置描述 使用内存缓冲区域做数据的临时缓存</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.channels.c1.type = memory</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.channels.c1.capacity = 1000</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.channels.c1.transactionCapacity = 100</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>#通过channel c1将source r1和sink k1关联起来</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.sources.r1.channels = c1</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#999999;"><strong>a1.sinks.k1.channel = c1  </strong></span></strong></p>
</blockquote>

<p style="margin-left:0pt;"><strong><strong>5.清空/logs ,slaver1上面没有logs目录，需要建立一个</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>6.启动</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>先启动slaver2,再启动master,slaver1</strong></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#df402a;"><strong>bin/flume-ng agent -n a1 -c conf -f conf/s2-hdfs.conf -Dflume.root.logger=INFO,console</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#df402a;"><strong>bin/flume-ng agent -n a1 -c conf -f conf/m-s2.conf -Dflume.root.logger=INFO,console</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><span style="color:#df402a;"><strong>bin/flume-ng agent -n a1 -c conf -f conf/s1-s2.conf -Dflume.root.logger=INFO,console</strong></span></strong></p>

<p style="margin-left:0pt;"><strong><strong>7.测试</strong></strong></p>

<p style="margin-left:0pt;"><strong><strong>在master或者slaver1的logs里面添加内容，观察hdfs</strong></strong></p>            </div>
                </div>