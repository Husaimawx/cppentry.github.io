---
layout:     post
title:      Spark 概述
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h3 id="spark-概述-原文-spark-overview">Spark 概述 【原文 <a href="http://spark.apache.org/docs/latest/" rel="nofollow" target="_blank">Spark overview</a>】</h3>

<p>Apache Spark 是一个快速、通用的集群计算系统。除了为Java、Scala、Python与R用户提供了高级编程接口，Spark还提供了支持通用执行图的优化引擎。作为计算引擎，Spark 提供了一系列高级工具，应对各类场景：</p>

<ul>
<li><a href="http://spark.apache.org/docs/latest/sql-programming-guide.html" rel="nofollow" target="_blank">Spark SQL</a> : SQL与结构化数据处理</li>
<li><a href="http://spark.apache.org/docs/latest/ml-guide.html" rel="nofollow" target="_blank">MLlib</a> : 机器学习</li>
<li><a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html" rel="nofollow" target="_blank">GrapX</a> : 图计算</li>
<li><a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html" rel="nofollow" target="_blank">Spark Streaming</a> : 实时计算</li>
</ul>

<h3 id="环境准备">环境准备</h3>



<h4 id="兼容性">兼容性</h4>

<p><font color="#ff0000">Spark 2.2.0 支持 Java8+,Python2.7+/3.4+,Scala2.11+，Hadoop 2.6.5+ </font></p>

<p><em>注</em>：不推荐在 spark2.1.0+版本上使用scala2.10-虽然可行；spark2.3.0可能会不支持scala 2.10 </p>

<h4 id="下-载">下 载</h4>

<p>地 址：<a href="http://spark.apache.org/downloads.html" rel="nofollow">downloads page</a> <br>
获取spark的几种方式：</p>

<ul>
<li>Pre-built for Apache Hadoop 2.6+ 版</li>
<li><a href="http://spark.apache.org/docs/latest/building-spark.html" rel="nofollow">源码自行构建</a></li>
</ul>

<p><em>说 明：</em> <br>
 1) 为了方便与hdfs、yarn的交互，Spark预打包了2.6+版Hadoop的客户端库 - 当然，你也可通过[增加Spark类路径]。(<a href="http://spark.apache.org/docs/latest/hadoop-provided.html" rel="nofollow">http://spark.apache.org/docs/latest/hadoop-provided.html</a>)来下载兼容任何Hadoop版本的二进制Spark文件。 <br>
 2）Scala与Java用户可在Maven中引入Spark相关包；Python用户，可通过PyPI安装Spark。 <br>
 3）可在window与类UNIX系统（e.g.Linux,Mac OS等）上运行。 在本地环境以单机模式运行Spark非常简单：保证 java -version 命令可在控制台正常执行。</p>

<h3 id="小实验">小实验</h3>

<p>Spark自带一些简单的Scala、Java、Python与R版小程序，详见 /src/main下相关子目录。这里以 SparkPi (就是计算 π 的值啦)为例,加以说明如何启动spark应用程序： <br>
1 ) scala 用户</p>



<pre class="prettyprint"><code class=" hljs applescript">./bin/<span class="hljs-command">run</span>-example SparkPi <span class="hljs-number">10</span></code></pre>

<p>执行环境与结果：</p>

<p><img src="https://img-blog.csdn.net/20171218152047257?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGVuZ3ljaF8zMjE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p><img src="https://img-blog.csdn.net/20171218151952495?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGVuZ3ljaF8zMjE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p><em>说明</em> ：A)  run-example程序内部调用了 spark-submit 脚本执行的。</p>



<pre class="prettyprint"><code class=" hljs livecodeserver">./bin/spark-<span class="hljs-built_in">shell</span> <span class="hljs-comment">--master local[2] //本地单机模式，双线程运行</span></code></pre>

<p>B) standalone 模式执行：<code>./bin/spark-shell --master spark://ip:port</code>;yarn 模式执行：<code>./bin/spark-shell --master yarn</code></p>

<p>2 ) python 用户：</p>



<pre class="prettyprint"><code class=" hljs livecodeserver">./bin/spark-submit examples/src/main/python/<span class="hljs-constant">pi</span>.py <span class="hljs-number">10</span></code></pre>



<pre class="prettyprint"><code class=" hljs brainfuck"><span class="hljs-string">.</span><span class="hljs-comment">/bin/pyspark</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">master</span> <span class="hljs-comment">local</span><span class="hljs-title">[</span><span class="hljs-comment">2</span><span class="hljs-title">]</span></code></pre>



<h3 id="部署模式">部署模式</h3>

<p>Spark可独立或者混合部署，目前支持三种集群部署模式： <br>
 - <a href="http://spark.apache.org/docs/latest/spark-standalone.html" rel="nofollow" target="_blank">Standalone Deploy Mode</a> <br>
 - <a href="http://spark.apache.org/docs/latest/running-on-mesos.html" rel="nofollow" target="_blank">Apache Mesos</a> <br>
 - <a href="http://spark.apache.org/docs/latest/running-on-yarn.html" rel="nofollow" target="_blank">Hadoop YARN</a> <br>
 更详细的部署说明，详见 <a href="http://spark.apache.org/docs/latest/cluster-overview.html" rel="nofollow" target="_blank">cluster mode 概述</a></p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>