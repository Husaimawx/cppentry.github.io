---
layout:     post
title:      大数据的电花火石！
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">什么是Spark？可能你很多年前就使用过Spark，反正当年我四六级单词都是用的星火系列，没错，星火系列的洋名就是Spark。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">当然这里说的Spark指的是Apache Spark，<strong>Apache Spark™</strong>is a fast and general engine for large-scale data processing： 一种快速通用可扩展的数据分析引擎。如果想要搞清楚Spark是什么，那么我们需要知道它解决了什么问题，还有是怎么解决这些问题的。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
 </p>
<h1 style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">
<a name="t0" style="color:rgb(51,102,153);"></a>Spark解决了什么问题？</h1>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">在这里不得不提大数据，大数据有两个根本性的问题，一个是数据很大，如何存储？另外一个是数据很大，如何分析？毕竟分析大数据是为了改善产品的用户体验，从而获取更多的价值。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">对于第一个问题，开源社区给出的方案就是HDFS，一个非常优秀的分布式存储系统。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">对于第二个问题，在Hadoop之 后，开源社区推出了许多值得关注的大数据分析平台。这些平台范围广阔，从简单的基于脚本的产品到与Hadoop 类似的生产环境。Bashreduce在 Bash环境中的多个机器上执行 MapReduce 类型的操作，可以直接引用强大的Linux命令。GraphLab 也是一种MapReduce 抽象实现，侧重于机器学习算法的并行实现。还有Twitter 的 Storm（通过收购 BackType 获得）。Storm 被定义为
 “实时处理的 Hadoop”，它主要侧重于流处理和持续计算。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">Spark就是解决第二个问题的佼佼者。Why Spark？<br></span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<br></p>
<h1 style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">
<a name="t1" style="color:rgb(51,102,153);"></a>Why Spark?</h1>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">现在有很多值得关注的大数据分析平台，那么为什么要选择Spark呢？</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;"><br></span></p>
<h2 style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">
<a name="t2" style="color:rgb(51,102,153);"></a>速度</h2>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">与Hadoop的MapReduce相比，Spark基于内存的运算比MR要快100倍；而基于硬盘的运算也要快10倍！</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<img src="https://img-blog.csdn.net/20140612205516859?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYW56aHNvZnQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" style="border:none;">(From the Project HomePage)<br></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
</p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<br></p>
<h2 style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">
<a name="t3" style="color:rgb(51,102,153);"></a>易用</h2>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">Spark支持Java，Python和Scala。而且支持交互式的Python和Scala的shell，这意味这你可以非常方便的在这些shell中使用Spark集群来验证你的解决问题的方法，而不是像以前一样，打包。。。这对于原型开发非常重要！</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">Hadoop的WorldCount的Mapper和Reducer加起来要20多行吧。Spark仅需要：</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;"></span></p>
<div class="dp-highlighter bg_java" style="font-family:Consolas, 'Courier New', Courier, mono, serif;background-color:rgb(231,229,220);overflow:auto;color:rgb(51,51,51);line-height:26px;">
<div class="bar">
<div class="tools" style="font-size:9px;line-height:normal;font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;color:#C0C0C0;background-color:rgb(248,248,248);border-left-width:3px;border-left-style:solid;border-left-color:rgb(108,226,108);">
<strong>[java]</strong> <a href="http://blog.csdn.net/anzhsoft/article/details/30272867#" rel="nofollow" class="ViewSource" title="view plain" style="color:rgb(160,160,160);text-decoration:none;background-color:inherit;border:none;font-size:9px;display:inline-block;width:16px;text-indent:-2000px;">view
 plain</a><a href="http://blog.csdn.net/anzhsoft/article/details/30272867#" rel="nofollow" class="CopyToClipboard" title="copy" style="color:rgb(160,160,160);text-decoration:none;background-color:inherit;border:none;font-size:9px;display:inline-block;width:16px;text-indent:-2000px;">copy</a><a href="https://code.csdn.net/snippets/391884" rel="nofollow" title="在CODE上查看代码片" style="color:rgb(160,160,160);text-decoration:none;background-color:inherit;border:none;font-size:9px;display:inline-block;width:16px;"><img src="https://code.csdn.net/assets/CODE_ico.png" width="12" height="12" alt="在CODE上查看代码片" style="border:none;"></a><a href="https://code.csdn.net/snippets/391884/fork" rel="nofollow" title="派生到我的代码片" style="color:rgb(160,160,160);text-decoration:none;background-color:inherit;border:none;font-size:9px;display:inline-block;width:16px;"><img src="https://code.csdn.net/assets/ico_fork.svg" width="12" height="12" alt="派生到我的代码片" style="border:none;"></a>
<div style="width:18px;z-index:99;">
</div>
</div>
</div>
<ol start="1" class="dp-j" style="border:none;background-color:rgb(255,255,255);color:rgb(92,92,92);"><li class="alt" style="border-style:none none none solid;border-left-width:3px;border-left-color:rgb(108,226,108);list-style:outside;color:inherit;line-height:18px;">
<span style="border:none;color:#000000;background-color:inherit;"><span style="border:none;background-color:inherit;">val file = spark.textFile(</span><span class="string" style="border:none;color:#0000FF;background-color:inherit;">"hdfs://..."</span><span style="border:none;background-color:inherit;">)  </span></span></li><li style="border-style:none none none solid;border-left-width:3px;border-left-color:rgb(108,226,108);list-style:outside;background-color:rgb(248,248,248);line-height:18px;">
<span style="border:none;color:#000000;background-color:inherit;">val counts = file.flatMap(line =&gt; line.split(<span class="string" style="border:none;color:#0000FF;background-color:inherit;">" "</span><span style="border:none;background-color:inherit;">))  </span></span></li><li class="alt" style="border-style:none none none solid;border-left-width:3px;border-left-color:rgb(108,226,108);list-style:outside;color:inherit;line-height:18px;">
<span style="border:none;color:#000000;background-color:inherit;">                 .map(word =&gt; (word, <span class="number" style="border:none;color:rgb(192,0,0);background-color:inherit;">1</span><span style="border:none;background-color:inherit;">))  </span></span></li><li style="border-style:none none none solid;border-left-width:3px;border-left-color:rgb(108,226,108);list-style:outside;background-color:rgb(248,248,248);line-height:18px;">
<span style="border:none;color:#000000;background-color:inherit;">                 .reduceByKey(_ + _)  </span></li><li class="alt" style="border-style:none none none solid;border-left-width:3px;border-left-color:rgb(108,226,108);list-style:outside;color:inherit;line-height:18px;">
<span style="border:none;color:#000000;background-color:inherit;">counts.saveAsTextFile(<span class="string" style="border:none;color:#0000FF;background-color:inherit;">"hdfs://..."</span><span style="border:none;background-color:inherit;">)   </span></span></li></ol></div>
<span style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">甚至可以将它们放到一行。</span><br style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;"><p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
</p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<br></p>
<h2 style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">
<a name="t4" style="color:rgb(51,102,153);"></a>通用性</h2>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">Spark提供了All in One的解决方案！</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<img src="https://img-blog.csdn.net/20140612205604453?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYW56aHNvZnQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" style="border:none;">(From the Project HomePage)<br></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
</p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">·        Shark SQ：应用于即席查询（Ad-hocquery）</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">·        Spark Streaming：应用于流式计算</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">·        MLlib：应用于机器学习</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">·        GraphX: 应用于图处理</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
 <img src="https://img-blog.csdn.net/20140612211342000?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYW56aHNvZnQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" style="border:none;"></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">Spark All In One的解决方案非常具有吸引力，毕竟任何公司都想要Unified的平台去处理遇到的问题，可以减少开发和维护的人力成本和部署平台的物力成本。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">当然还有，作为All in One的解决方案，Spark并没有以牺牲性能为代价。相反，在性能方面，Spark还有很大的优势。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;"><br></span></p>
<h2 style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">
<a name="t5" style="color:rgb(51,102,153);"></a>和Hadoop的集成</h2>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">Spark可以使用YARN作为它的集群管理器，并且可以处理HDFS的数据。这对于已经部署Hadoop集群的用户特别重要，毕竟不需要做任何的数据迁移就可以使用Spark的强大处理能力。Spark可以读取<a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;">HDFS</a>,<a href="http://hbase.apache.org/" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;">HBase</a>, <a href="http://cassandra.apache.org/" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;">Cassandra</a>等一切Hadoop的数据。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">当然了对于没有部署并且没有计划部署Hadoop集群的用户来说，Spark仍然是一个非常好的解决方法，它还支持<a href="http://spark.apache.org/docs/latest/spark-standalone.html" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;">standalone</a>， <a href="http://spark.apache.org/docs/latest/ec2-scripts.html" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;">EC2</a> 和 <a href="http://mesos.apache.org/" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;">Mesos</a>。你只要保证集群的节点可以访问共享的内容，比如通过NFS你就可以非常容易的使用Spark！</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<br></p>
<h1 style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">
<a name="t6" style="color:rgb(51,102,153);"></a>How Spark？</h1>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">Spark是如何做到呢？或者说Spark的内核是如何实现的？</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;"><br></span></p>
<h2 style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">
<a name="t7" style="color:rgb(51,102,153);"></a>架构综述</h2>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
</p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<img src="https://img-blog.csdn.net/20140612205637187?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYW56aHNvZnQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" style="border:none;">(From the Project HomePage)<br></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">先说解释一下上图的术语：</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;"><strong>Driver Program：</strong> 运行main函数并且新建SparkContext的程序。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;"><strong>SparkContext</strong>：Spark程序的入口，负责调度各个运算资源，协调各个Worker Node上的Executor。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;"><strong>Application：</strong> 基于Spark的用户程序，包含了driver程序和集群上的executor</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;"><strong>Cluster Manager：</strong> 集群的资源管理器(例如: Standalone,Mesos,Yarn)</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;"><strong>Worker Node：</strong> 集群中任何可以运行应用代码的节点</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;"><strong>Executor:</strong> 是在一个worker node上为某应用启动的一个进程，该进程负责运行任务，并且负责将数据存在内存或者磁盘上。每个应用都有各自独立的executors</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;"><strong>Task:</strong> 被送到某个executor上的工作单元</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">了解了各个术语的含义后，我们看一下一个用户程序是如何从提交到最终到集群上执行的：</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">1.      SparkContext连接到ClusterManager，并且向ClusterManager申请executors。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">2.      SparkContext向executors发送application code。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">3.      SparkContext向executors发送tasks，executor会执行被分配的tasks。<br></span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">运行时的状态如下图：</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<img src="https://img-blog.csdn.net/20140612211627453?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYW56aHNvZnQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" style="border:none;">(<span style="font-size:10px;">From
 Paper <a href="http://www.cs.berkeley.edu/~matei/papers/2011/tr_spark.pdf" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;">Resilient Distributed Datasets: A Fault-Tolerant Abstractionfor In-Memory Cluster Computing</a>)</span><br></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
 </p>
<h2 style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">
<a name="t8" style="color:rgb(51,102,153);"></a>Spark为什么这么快？</h2>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">首先看一下为什么MapReduce那么慢。速度可能是MapReduce最被人们诟病的地方。<a href="http://jerryshao.me/architecture/2013/04/15/%E4%BC%A0%E7%BB%9F%E7%9A%84MapReduce%E6%A1%86%E6%9E%B6%E6%85%A2%E5%9C%A8%E5%93%AA%E9%87%8C/" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;">传统的MapReduce框架慢在哪里。</a></span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">基于内存的计算式Spark速度很快的原因之一。Spark的运算模型也是它出色性能的重要保障。Spark的关键运算组件如下图。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;"><img src="https://img-blog.csdn.net/20140613204502171?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYW56aHNvZnQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" style="border:none;"></span></p>
<h2 style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">
<a name="t9" style="color:rgb(51,102,153);"></a>什么是RDD<br></h2>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">RDD是Spark的基石，也是Spark的灵魂。说Spark不得不提RDD，那么RDD（Resilient Distributed Dataset，弹性分布式数据集）是什么呢？当然了，论文<a href="http://www.cs.berkeley.edu/~matei/papers/2011/tr_spark.pdf" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;">Resilient
 Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing</a>是了解RDD必不可少的，它从学术，实现给出了什么是RDD。下面是从RDD的实现源码的注释中说明了RDD的特性。</span></p>
<ol style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;"><li><span style="font-size:18px;">A list of partitions</span></li><li><span style="font-size:18px;">A function for computing each split</span></li><li><span style="font-size:18px;">A list of dependencies on other RDDs</span></li><li><span style="font-size:18px;">Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)</span></li><li><span style="font-size:18px;">Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)<br></span></li></ol><p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">接着把对应的实现接口的源码贴一下，以方便去源码中查找RDD的核心框架：</span></p>
<ol style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;"><li><span style="font-size:18px;">分区 protected def getPartitions: Array[Partition]</span></li><li><span style="font-size:18px;">依赖 protected def getDependencies: Seq[Dependency[_]] = deps</span></li><li><span style="font-size:18px;">函数 def compute(split: Partition, context: TaskContext): Iterator[T]</span></li><li><span style="font-size:18px;">最佳位置(可选) protected def getPreferredLocations(split: Partition): Seq[String] = Nil</span></li><li><span style="font-size:18px;">分区策略(可选) @transient val partitioner: Option[Partitioner] = None</span></li></ol><p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<br></p>
<h2 style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">
<a name="t10" style="color:rgb(51,102,153);"></a>RDD的操作</h2>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
</p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">RDD支持两种操作：<strong>转换（<em>transformation</em>）</strong>从现有的数据集创建一个新的数据集；而<strong>动作（actions）</strong>在数据集上运行计算后，返回一个值给驱动程序。 例如，<samp>map</samp>就是一种转换，它将数据集每一个元素都传递给函数，并返回一个新的分布数据集表示结果。另一方面，<samp>reduce</samp>是一种动作，通过一些函数将所有的元素叠加起来，并将最终结果返回给Driver程序。（不过还有一个并行的<samp>reduceByKey</samp>，能返回一个分布式数据集）</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">Spark中的所有转换都是惰性的，也就是说，他们并不会直接计算结果。相反的，它们只是记住应用到基础数据集（例如一个文件）上的这些转换动作。只有当发生一个要求返回结果给Driver的动作时，这些转换才会真正运行。这个设计让Spark更加有效率的运行。例如，我们可以实现：通过<samp>map</samp>创建的一个新数据集，并在<samp>reduce</samp>中使用，最终只返回<samp>reduce</samp>的结果给driver，而不是整个大的新数据集。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">默认情况下，每一个转换过的RDD都会在你在它之上执行一个动作时被重新计算。不过，你也可以使用<samp>persist</samp>(或者<samp>cache</samp>)方法，持久化一个RDD在内存中。在这种情况下，Spark将会在集群中，保存相关元素，下次你查询这个RDD时，它将能更快速访问。在磁盘上持久化数据集，或在集群间复制数据集也是支持的，详尽的RDD操作请参见 <a href="http://spark.incubator.apache.org/docs/latest/api/core/index.html#org.apache.spark.rdd.RDD" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;">RDD
 API doc</a>。</span></p>
<br style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;"><h2 style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">
<a name="t11" style="color:rgb(51,102,153);"></a>数据的本地性</h2>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">数据本地性的意思就是尽量的避免数据在网络上的传输。Hadoop的MR之所以慢，频繁的读写HDFS是原因之一，为了解决这个问题，Spark将数据都放在了内存中（当然这是理想的情况，当内存不够用时数据仍然需要写到文件系统中）。但是如果数据需要在网络上传输，也会导致大量的延时和开销，毕竟disk IO和network IO都是集群的昂贵资源。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">数据本地性是尽量将计算移到数据所在的节点上进行。毕竟移动计算要比移动数据所占的网络资源要少得多。而且，由于Spark的延时调度机制，使得Spark可以在更大的程度上去做优化。比如，拥有数据的节点当前正被其他的task占用，那么这种情况是否需要将数据移动到其他的空闲节点呢？答案是不一定。因为如果预测当前节点结束当前任务的时间要比移动数据的时间还要少，那么调度会等待，直到当前节点可用。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<img src="https://img-blog.csdn.net/20140613214032687?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYW56aHNvZnQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" style="border:none;"></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<br></p>
<h1 style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">
<a name="t12" style="color:rgb(51,102,153);"></a>Spark的现状与未来</h1>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">值得庆祝的里程碑：</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">·        2009：Spark诞生于AMPLab</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">·        2010：开源</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">·        2013年6月：Apache孵化器项目</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">·        2014年2月：Apache顶级项目</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">·        Hadoop最大的厂商Cloudera宣称加大Spark框架的投入来取代Mapreduce</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">·        Hadoop厂商MapR投入Spark阵营</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">·        Apache mahout放弃MapReduce，将使用Spark作为后续算子的计算平台</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">·        2014年5月30日Spark1.0.0发布</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
 </p>
<h1 style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">
<a name="t13" style="color:rgb(51,102,153);"></a>进一步学习</h1>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">熟读源码永远是知道真相的唯一方式。尤其是Scala语言是如此简洁，如此易读。当然了在这之前最好还是读一下论文，尤其是<a href="http://www.cs.berkeley.edu/~matei/papers/2011/tr_spark.pdf" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;">RDD</a>的，这样可以让你有个整体把握整个系统的能力。</span></p>
<ul type="disc" style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;"><li><span style="font-size:18px;"><a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/2012/EECS-2012-214.pdf" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;">Shark: SQL and Rich Analytics at Scale</a>. Reynold Xin, Joshua
 Rosen, Matei Zaharia, Michael J. Franklin, Scott Shenker, Ion Stoica. <em>Technical Report UCB/EECS-2012-214</em>. November 2012.</span></li><li><span style="font-size:18px;"><a href="http://www.cs.berkeley.edu/~matei/papers/2012/hotcloud_spark_streaming.pdf" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;">Discretized Streams: An Efficient and Fault-Tolerant Model
 for Stream Processing on Large Clusters</a>. Matei Zaharia, Tathagata Das, Haoyuan Li, Scott Shenker, Ion Stoica. <em>HotCloud 2012</em>. June 2012.</span></li><li><span style="font-size:18px;"><a href="http://www.cs.berkeley.edu/~matei/papers/2012/sigmod_shark_demo.pdf" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;">Shark: Fast Data Analysis Using Coarse-grained Distributed Memory</a> (demo).
 Cliff Engle, Antonio Lupher, Reynold Xin, Matei Zaharia, Haoyuan Li, Scott Shenker, Ion Stoica. <em>SIGMOD 2012</em>. May 2012. <strong>Best Demo Award</strong>.</span></li><li><span style="font-size:18px;"><a href="http://www.cs.berkeley.edu/~matei/papers/2011/tr_spark.pdf" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;">Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory
 Cluster Computing</a>. Matei Zaharia, Mosharaf Chowdhury, Tathagata Das, Ankur Dave, Justin Ma, Murphy McCauley, Michael J. Franklin, Scott Shenker, Ion Stoica.<em>Technical Report UCB/EECS-2011-82</em>. July 2011.</span></li><li><span style="font-size:18px;"><a href="http://www.cs.berkeley.edu/~matei/papers/2010/hotcloud_spark.pdf" rel="nofollow" style="color:rgb(51,102,153);text-decoration:none;">Spark: Cluster Computing with Working Sets</a>. Matei Zaharia, Mosharaf
 Chowdhury, Michael J. Franklin, Scott Shenker, Ion Stoica. <em>HotCloud 2010</em>. June 2010.</span></li></ul><p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<br></p>
<h1 style="color:rgb(51,51,51);font-family:Arial;line-height:26px;">
<a name="t14" style="color:rgb(51,102,153);"></a>敬请期待</h1>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">   源码之前，了无真相。接下来，我将从源码分析的角度，深入Spark内部，来系统学习Spark，学习它的架构，学习它的实现。</span></p>
<p style="color:rgb(51,51,51);font-family:Arial;font-size:14px;line-height:26px;">
<span style="font-size:18px;">www.aibang.com/detail/700432115-423278073/product/15432865.html<br>
www.aibang.com/detail/700432115-423278073/product/15432949.html<br>
www.aibang.com/detail/700432115-423278073/product/15433025.html<br>
www.aibang.com/article/700432115-423278073/product/15433121.html<br>
www.aibang.com/detail/700432115-423278073/product/15433199.html<br>
www.aibang.com/detail/700432115-423278073/product/15433289.html<br>
www.aibang.com/detail/700432115-423278073/product/15433377.html<br>
www.aibang.com/detail/700432115-423278073/product/15433463.html<br>
www.aibang.com/detail/700432115-423278073/product/15433527.html<br>
www.aibang.com/detail/700432115-423278073/product/15433611.html<br>
www.aibang.com/detail/700432115-423278073/product/15433685.html<br>
www.aibang.com/article/700432115-423278073/product/15433741.html<br>
www.aibang.com/detail/700432115-423278073/product/15433911.html<br>
www.aibang.com/detail/700432115-423278073/product/15433965.html<br>
www.aibang.com/detail/700432115-423278073/product/15434017.html<br>
www.aibang.com/detail/700432115-423278073/product/15434105.html<br>
www.aibang.com/detail/700432115-423278073/product/15434189.html<br>
www.aibang.com/article/700432115-423278073/product/15434241.html<br>
www.aibang.com/article/700432115-423278073/product/15434701.html<br>
www.aibang.com/detail/700432115-423278073/product/15434759.html<br>
www.aibang.com/detail/700432115-423278073/product/15434833.html<br>
www.aibang.com/detail/700432115-423278073/product/15434903.html<br>
www.aibang.com/detail/700432115-423278073/product/15434969.html<br>
www.aibang.com/detail/700432115-423278073/product/15435035.html<br>
www.aibang.com/detail/700432115-423278073/product/15435079.html<br>
www.aibang.com/detail/700432115-423278073/product/15435805.html<br>
www.aibang.com/detail/700432115-423278073/product/15435849.html<br>
www.aibang.com/detail/700432115-423278073/product/15436053.html<br>
www.aibang.com/detail/700432115-423278073/product/15436085.html<br>
www.aibang.com/article/700432115-423278073/product/15436121.html<br>
www.aibang.com/detail/700432115-423278073/product/15436191.html<br>
www.aibang.com/detail/700432115-423278073/product/15436233.html<br>
www.aibang.com/detail/700432115-423278073/product/15436377.html<br>
www.aibang.com/detail/700432115-423278073/product/15436437.html<br>
www.aibang.com/article/700432115-423278073/product/15436481.html<br>
www.aibang.com/detail/700432115-423278073/product/15436905.html<br>
www.aibang.com/detail/700432115-423278073/product/15437189.html<br>
www.aibang.com/detail/700432115-423278073/product/15437211.html<br>
www.aibang.com/detail/700432115-423278073/product/15437235.html<br>
www.aibang.com/detail/700432115-423278073/product/15437267.html<br></span></p>
            </div>
                </div>