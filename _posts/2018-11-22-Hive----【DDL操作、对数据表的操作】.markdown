---
layout:     post
title:      Hive----【DDL操作、对数据表的操作】
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h1><a id="HiveDDL_0"></a>Hive–DDL基本操作</h1>
<p><strong>Hive中错误分类 :</strong></p>
<pre><code>Error while compiling statement  hive编译器错误  sql语法问题
Error while processing statement hive执行期错误  应用逻辑上的问题
</code></pre>
<h3><a id="1_DDL_9"></a>1. DDL操作</h3>
<h4><a id="11__11"></a>1.1 创建表</h4>
<p>建表语法</p>
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token punctuation">[</span>external<span class="token punctuation">]</span> <span class="token keyword">table</span> <span class="token punctuation">[</span><span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span><span class="token punctuation">(</span>判断有无表<span class="token punctuation">)</span><span class="token punctuation">]</span> table_name
<span class="token punctuation">[</span><span class="token punctuation">(</span>col_name<span class="token punctuation">(</span>列名<span class="token punctuation">)</span> data_type<span class="token punctuation">(</span>数据类型<span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token keyword">comment</span> col_comment<span class="token punctuation">(</span>数据描述<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token keyword">comment</span> table_comment<span class="token punctuation">(</span>数据表描述<span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span>partitioned <span class="token keyword">by</span> <span class="token punctuation">(</span>col_name data_type <span class="token punctuation">[</span><span class="token keyword">comment</span> col_comment<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token keyword">clustered</span> <span class="token keyword">by</span> <span class="token punctuation">(</span>col_name<span class="token punctuation">,</span> col_name<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span>sorted <span class="token keyword">by</span> <span class="token punctuation">(</span>col_name <span class="token punctuation">[</span><span class="token keyword">asc</span><span class="token operator">|</span><span class="token keyword">desc</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">into</span> num_buckets buckets<span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token keyword">row</span> format row_format<span class="token punctuation">]</span>
<span class="token punctuation">[</span>stored <span class="token keyword">as</span> file_format<span class="token punctuation">]</span>
<span class="token punctuation">[</span>location hdfs_path<span class="token punctuation">]</span>
</code></pre>
<p><code>说明:</code></p>
<ol>
<li><strong>创建表:</strong> create table [if not exsists] 表名(列,数据类型);</li>
</ol>
<p>例子 : 创建一个名为t_test的表<code>create table t_test(id int,name string,age int);</code>此时采用的是默认的分隔符<code>'\001'</code> 用 vi 编辑器 Ctrl+v 然后 Ctrl+a 即可输入’\001’ -----------&gt; <code>^A</code></p>
<p>通常我们需要指定分隔符!!!</p>
<p>准备数据</p>
<pre><code>在根目录创建一个文件专门存放hsql的测试数据hivedata
mkdir hivedata
进入该目录 创建数据文件 
vi 1.txt
1,zhangsan,18
2,lisi,19
3,wangwu,20
</code></pre>
<p><code>create table t_test(id int,name string,age int) row format delimited fields terminated by ",";</code></p>
<p>将数据传送到hdfs的hive存放数据的指定目录下</p>
<p><code>hadoop fs -put 1.txt /user/hive/warehouse/test01.db/t_test1</code></p>
<p>在远程连接设备上查看表即可<code>select * from t_test1;</code></p>
<p>总结 :</p>
<ul>
<li>结构化文件位置不能瞎放  hive中建立的表有对应的文件夹存在</li>
</ul>
<pre><code>test01.db--&gt;t_test01---&gt;/user/hive/warehouse/test01.db/t_test1
</code></pre>
<ul>
<li>分隔符不一定需要指定 , 因为默认有个分隔符<code>'\001'</code></li>
<li>建表的数据类型一定要跟结构化文件一致、顺序一致</li>
</ul>
<p>只有当结构化数据映射成功一张表之后，就可以使用hive sql来对数据进行分析。</p>
<ul>
<li>hive的数据类型
<ul>
<li>除了支持sql的类型外  还支持java类型  且大小写不敏感</li>
</ul>
</li>
<li>hive的分隔符
<ul>
<li>row format delimited | serde</li>
</ul>
</li>
</ul>
<pre><code>row format delimited
[fields terminated by char]
[collection items terminated by char]
[map keys terminated by char]
[lines terminated by char] | serde serde_name
[with serdeproperties

row format delimited fields terminated by ","
row format:表明开始指定分隔符
delimited :表明使用hive内置分隔符类来处理数据分割（默认LazySimpleSerDe）
fields : 指的是字段分隔符的指定
collection : 指的是集合数据的分隔符
map : 指的是map数据的分隔符
</code></pre>
<p>练习 :</p>
<ul>
<li>简单类型</li>
</ul>
<pre><code class="prism language-sql">allen<span class="token operator">|</span><span class="token number">19</span><span class="token operator">|</span>beijing
tom<span class="token operator">|</span><span class="token number">20</span><span class="token operator">|</span>shanghai
  
<span class="token keyword">create</span> <span class="token keyword">table</span> t_t1<span class="token punctuation">(</span>name string<span class="token punctuation">,</span>age <span class="token keyword">int</span><span class="token punctuation">,</span>city string<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'|'</span><span class="token punctuation">;</span>
加载数据<span class="token punctuation">(</span>如果不在hdfs上 <span class="token punctuation">,</span> 在hive服务器所在的linux上 <span class="token punctuation">,</span> 是复制操作<span class="token punctuation">)</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/root/hivedata/1.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_t1<span class="token punctuation">;</span>
如果在hdfs的根目录下<span class="token punctuation">(</span>是移动操作<span class="token punctuation">)</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> inpath <span class="token string">'/1.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_t1<span class="token punctuation">;</span>
</code></pre>
<ul>
<li>复杂类型</li>
</ul>
<pre><code class="prism language-sql">如果是复杂类型：
  zhangsan	beijing<span class="token punctuation">,</span>shanghai<span class="token punctuation">,</span>tianjin<span class="token punctuation">,</span>hangzhou
  wangwu	shanghai<span class="token punctuation">,</span>chengdu<span class="token punctuation">,</span>wuhan<span class="token punctuation">,</span>haerbin
  
<span class="token keyword">create</span> <span class="token keyword">table</span> complex_array<span class="token punctuation">(</span>name string<span class="token punctuation">,</span>work_locations array<span class="token operator">&lt;</span>string<span class="token operator">&gt;</span><span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span> collection items <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>
</code></pre>
<pre><code class="prism language-sql"><span class="token number">1</span><span class="token punctuation">,</span>zhangsan<span class="token punctuation">,</span>唱歌:非常喜欢<span class="token operator">-</span>跳舞:喜欢<span class="token operator">-</span>游泳:一般般
<span class="token number">2</span><span class="token punctuation">,</span>lisi<span class="token punctuation">,</span>打游戏:非常喜欢<span class="token operator">-</span>篮球:不喜欢
<span class="token keyword">create</span> <span class="token keyword">table</span> t_map<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name string<span class="token punctuation">,</span>hobby map<span class="token operator">&lt;</span>string<span class="token punctuation">,</span>string<span class="token operator">&gt;</span><span class="token punctuation">)</span>
	<span class="token keyword">row</span> format delimited 
	<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span>
	collection items <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'-'</span>
	map <span class="token keyword">keys</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">':'</span> <span class="token punctuation">;</span>
</code></pre>
<ul>
<li>hive建表的时候 如果语法中木有row  format，表面不指定分隔符 ，这时候使用默认分隔符去创建表</li>
</ul>
<p>“\001”------&gt;用 vi 编辑器<code>Ctrl+v 然后 Ctrl+a</code> 即可输入’\001’—&gt;<code>^A</code></p>
<p>如果此时结构化数据恰好也是\001分割 这时候不指定分隔符也能映射成功 , 如下图</p>
<p><code>^A</code>字端在vi编辑器中是变色的</p>
<p><img src="/1542612176745.png" alt="1542612176745"></p>
<p><img src="/1542612196795.png" alt="1542612196795"></p>
<ul>
<li>hive 中数据库  表跟hdfs中位置的映射对应关系</li>
</ul>
<p>hive默认会把数据存放在<code>hdfs : /user/hive/warehouse</code></p>
<pre><code>database ------&gt;/user/hive/warehouse/db_name.db
database.table----&gt;/user/hive/warehouse/db_name.db/table_name
</code></pre>
<ol start="2">
<li>创建外部表(…external…location…) , <code>external</code>关键字可以让用户创建一个外部表 , 在建表的同时指定一个指向实际数据的路径（ <code>location</code>）</li>
</ol>
<pre><code>create external table allen(id int,name string,age int) row format delimited fields terminated by ',' location '/allenwoon';
</code></pre>
<p>Hive 创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。</p>
<p>测试 :</p>
<p>首先我们在hdfs上新建一个文件夹用于存储数据"/hivedata" , 然后创建测试数据1.txt</p>
<pre><code>1,hello,2
3,hi,4
5,see,6
</code></pre>
<p>创建表</p>
<pre><code class="prism language-sql"><span class="token keyword">create</span> external <span class="token keyword">table</span> t_t1<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name string<span class="token punctuation">,</span>age <span class="token keyword">int</span><span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">","</span> location <span class="token string">'/hivedata'</span><span class="token punctuation">;</span>
</code></pre>
<p>外部表意味着数据可以在hdfs任意路径下 , 不需要移动到hive的默认路径下</p>
<ul>
<li>外部表的好处
<ul>
<li>内部表：删除表除了删除hive中的表信息 还会把对应的结构化文件删除</li>
<li>外部表：仅仅删除hive中的表信息 不删除表的文件</li>
</ul>
</li>
</ul>
<ol start="3">
<li><strong><code>分区表</code></strong> <strong>partitioned by</strong></li>
</ol>
<p>在hive select查询中一般会扫描整个表内容 , 会消耗很多时间做没必要的工作 , 有时候只需要扫描表中关心的一部分数据 , 因此建表时引入了partition分区概念 .</p>
<p>分区表值得是在创建表时指定的partition的分区空间 . 一个表可以拥有一个或者多个分区 , 每个分区以文件夹的形式单独存在表文件的目录下 . 表和列名不区分大小写 . 分区是以字段的形式在表结构中存在 , 通过describe table命令可以查看到字段存在 , 但是该字段不存放实际的数据内容 , 仅仅是分区的表示.</p>
<p>分区建表分为两种: 一种是单分区 , 也就是说在表文件夹目录下只有一级文件夹目录 . 另一种是多分区 , 表文件夹下出现多文件夹嵌套模式 .</p>
<ul>
<li>
<p>单分区建表语句 : <code>create table day_table(id int,content string) partitioned by (dt string);</code> ==&gt;单分区表 , 按天分区 , 在表结构中存在id , content , dt三列</p>
<ul>
<li>导入数据 : <code>load data local inpath '/root/hivedata/dat_table.txt' into table day_table partition(dt='2017-07-07')</code></li>
<li>使用<code>select * from day_table where dt="xxx";</code></li>
</ul>
</li>
<li>
<p>双分区建表语句 : <code>create table day_hour_table (id int, content string) partitioned by (dt string, hour string);</code>==&gt; 双分区表，按天和小时分区，在表结构中新增加了dt和hour两列</p>
<ul>
<li>导入数据 : <code>load data local inpath '/root/hivedata/dat_table.txt' into table day_hour_table partition(dt='2017-07-07', hour='08');</code></li>
<li>使用<code>select * from day_table where dt="xxx" and hour="yyy";</code></li>
</ul>
</li>
<li>
<p>多分区表测试</p>
<p>创建</p>
<pre><code>create table t_user_duo(id int, name string,country string) partitioned by (guojia string, sheng string) row format delimited fields terminated by ',';
------
create table t_user_duo(id int, name string,city string) partitioned by (province string, xian string) row format delimited fields terminated by ',';
</code></pre>
<p>加载</p>
<pre><code>LOAD DATA local INPATH '/root/hivedata/china.txt' INTO TABLE t_user_duo PARTITION(guojia='zhongguo', sheng='hebei');
------------
load data local inpath '/root/hivedata/beijing.txt' into table t_user_duo partition(province='beijing', xian='shunyi');
</code></pre>
<p>使用</p>
<pre><code>select * from t_user_duo where guojia ="zhongguo" and sheng ="jiangsu";
</code></pre>
<p>总结</p>
<p>多分区当前只支持两个分区  后一个分区的意思是指在前一个分区的基础上再次细分。</p>
<p>体现的就是分区的文件夹下面继续创建第二个分区的文件夹</p>
<p>常见多分区使用：</p>
<p>(province, city)</p>
<p>(month ,day)</p>
</li>
<li>
<p>基于分区的查询 : <code>select day_table.* from day_table where day_table.dt = '2017-07-07';</code></p>
</li>
<li>
<p>查看分区 : <code>show partitions day_hour_table;</code></p>
</li>
<li>
<p>多分区当前只支持两个分区 , 后一个分区的意思是指在前一个分区的基础上再次划分</p>
</li>
</ul>
<p>注意 : dt后面的参数便是分区的文件的名字</p>
<p>实战 :</p>
<p>数据 , 分别创建三个数据文件</p>
<pre><code>vi china.txt
1,zhangsan,china
2,lisi,china
3,wangwu,china
----------
vi usa.txt
4,jack,usa
5,tom,usa
----------
vi japan.txt
6,haoo,japan
7,wood,japan
</code></pre>
<p>下面两个操作都是在node-3上执行的</p>
<p>创建一个表</p>
<p><code>create table t_user(id int,name string,country string) partitioned by (guojia string) row format delimited fields terminated by ","</code></p>
<p>导入数据</p>
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/root/hivedata/china.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_user1 <span class="token keyword">partition</span><span class="token punctuation">(</span>guojia<span class="token operator">=</span><span class="token string">'zhongguo'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/root/hivedata/usa.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_user1 <span class="token keyword">partition</span><span class="token punctuation">(</span>guojia<span class="token operator">=</span><span class="token string">'meiguo'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/root/hivedata/japan.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_user1 <span class="token keyword">partition</span><span class="token punctuation">(</span>guojia<span class="token operator">=</span><span class="token string">'riben'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<blockquote>
<p>tips : 直接put不行 , 分区字段没有指定 , 不能映射成功</p>
</blockquote>
<p>查询</p>
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_user <span class="token keyword">where</span> guojia<span class="token operator">=</span><span class="token string">"zhongguo"</span><span class="token punctuation">;</span> 使用分区字段查询 <span class="token punctuation">,</span> 只扫描分区字段对应的文件
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_user <span class="token keyword">where</span> country<span class="token operator">=</span><span class="token string">"china"</span><span class="token punctuation">;</span> 使用表中字段查询 <span class="token punctuation">,</span> 全表扫描查询
</code></pre>
<p>目录结构如下图 :</p>
<p><img src="https://img-blog.csdnimg.cn/20181120231936844.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NvZGVyQm9vbQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>查询结果如下图 :</p>
<p><img src="https://img-blog.csdnimg.cn/20181120231959747.png" alt="在这里插入图片描述"></p>
<blockquote>
<p><strong>分区表总结 :</strong></p>
<ul>
<li>分区表是一个查询优化手段 , 减少了查询时的全局扫描</li>
<li>分区字段不能跟表中字段重复!!</li>
<li>分区字段是虚拟字段 , 并不真正存在表数据中 , 它的显示数据来自于加载数据时的分区指定</li>
</ul>
<pre><code>load data local inpath '/root/hivedata/china.txt' into table t_user1 partition(guojia='zhongguo');
</code></pre>
<ul>
<li>分区字段可以直接用在sql中 , 单做查询条件 , 优化查询</li>
<li>分区的意义在于从文件夹层面把文件管理的更加精致</li>
<li>总的说来partition就是辅助查询，缩小查询范围，加快数据的检索速度和对数据按照一定的规格和条件进行管理。</li>
</ul>
<p>**扩展 : **企业中 , 如果创建分区表 , 使用什么作为分区字段 ?</p>
<ul>
<li>如果一天一个文件  <code>partitioned by (day string)</code></li>
<li>如果是每个省一个文件 <code>partitioned by (province string)</code></li>
</ul>
</blockquote>
<p>分区表作用如下图</p>
<p><img src="https://img-blog.csdnimg.cn/20181120232007392.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NvZGVyQm9vbQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ul>
<li><strong><code>分桶表(分簇表)</code></strong> <strong>clustered by xxx into N buckets</strong></li>
</ul>
<blockquote>
<p>clustered by xxx into N buckets</p>
<p>字面上 : 根据xxx分为N桶</p>
<p>通俗上 : 把表对应的文件按照xxx字段分为N个部分</p>
<p>​	根据谁分 : clustered by xxx  根据xxx分</p>
<p>​	分成几个部分 : N buckets   N就是几个buk</p>
<p>​	如何分 : 默认分桶规则   hashfunc()</p>
<p>​			如果分桶字段是数值类型  hashfunc(xxx) = xxx  xxx%N  余数是几  就分到哪个桶</p>
<p>​			如果分桶字段是字符串类型  hashfunc(xxx) = xxx.hashcode  xxx.hashcode%N 余数是几  就分到哪个桶</p>
</blockquote>
<ul>
<li>
<p>分桶表的创建</p>
<ul>
<li>准备数据<code>vi students.txt</code></li>
</ul>
<pre><code class="prism language-txt">95001,李勇,男,20,CS
95002,刘晨,女,19,IS
95003,王敏,女,22,MA
95004,张立,男,19,IS
95005,刘刚,男,18,MA
95006,孙庆,男,23,CS
95007,易思玲,女,19,MA
95008,李娜,女,18,CS
95009,梦圆圆,女,18,MA
95010,孔小涛,男,19,CS
95011,包小柏,男,18,MA
95012,孙花,女,20,CS
95013,冯伟,男,21,CS
95014,王小丽,女,19,CS
95015,王君,男,18,MA
95016,钱国,男,21,MA
95017,王风娟,女,18,IS
95018,王一,女,19,IS
95019,邢小丽,女,19,IS
95020,赵钱,男,21,IS
95021,周二,男,17,MA
95022,郑明,男,20,MA
</code></pre>
<ul>
<li>开启分桶的功能</li>
</ul>
<pre><code>set hive.enforce.bucketing = true;
</code></pre>
<ul>
<li>指定分为几桶</li>
</ul>
<pre><code>set mapreduce.job.reduces=4;
</code></pre>
<ul>
<li>分桶表创建</li>
</ul>
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> stu_buck<span class="token punctuation">(</span>Sno <span class="token keyword">int</span><span class="token punctuation">,</span>Sname string<span class="token punctuation">,</span>Sex string<span class="token punctuation">,</span>Sage <span class="token keyword">int</span><span class="token punctuation">,</span>Sdept string<span class="token punctuation">)</span>
<span class="token keyword">clustered</span> <span class="token keyword">by</span><span class="token punctuation">(</span>Sno<span class="token punctuation">)</span> 
<span class="token keyword">into</span> <span class="token number">4</span> buckets
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>
</code></pre>
<ul>
<li>
<p>分桶表导入数据</p>
</li>
<li>
<p>真正加载分桶表数据方式：<code>insert+select</code></p>
<pre><code>insert+values  插入的数据来自于values指定
insert+select  插入的数据来自于后select查询语句返回的结果
</code></pre>
</li>
</ul>
<pre><code class="prism language-sql">首先创建临时表student
<span class="token keyword">create</span> <span class="token keyword">table</span> student<span class="token punctuation">(</span>Sno <span class="token keyword">int</span><span class="token punctuation">,</span>Sname string<span class="token punctuation">,</span>Sex string<span class="token punctuation">,</span>Sage <span class="token keyword">int</span><span class="token punctuation">,</span>Sdept string<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>

然后给临时表加载数据
hadoop fs <span class="token operator">-</span>put students<span class="token punctuation">.</span>txt <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>itcast<span class="token punctuation">.</span>db<span class="token operator">/</span>student

最后查询临时表（student）数据 分桶插入到最终分桶表中（stu_buck）
<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> stu_buck <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student cluster <span class="token keyword">by</span><span class="token punctuation">(</span>Sno<span class="token punctuation">)</span><span class="token punctuation">;</span>
扩展 :
当两个字段一样时: 
cluster（分且排序，必须一样）<span class="token operator">=</span><span class="token operator">=</span>distribute（分） <span class="token operator">+</span> sort（排序）（可以不一样 <span class="token punctuation">,</span> 指的是条件可以不一样）
cluster 和 sort 不能共存
对某列进行分桶的同时，根据另一列进行排序
<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> stu_buck
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student distribute <span class="token keyword">by</span><span class="token punctuation">(</span>Sno<span class="token punctuation">)</span> sort <span class="token keyword">by</span><span class="token punctuation">(</span>Sage <span class="token keyword">asc</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<blockquote>
<p>tips:</p>
<p>直接put只能映射成功数据 , 但是并没有按照Sno分成4个桶 , 违背初衷</p>
<p>hive就不支持load语法</p>
</blockquote>
<p>成功后如下图所示</p>
</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20181120232033443.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NvZGVyQm9vbQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/20181120232045426.png" alt="在这里插入图片描述"></p>
<p>发现数据已经分好为4个部分了</p>
<blockquote>
<p>分桶表的总结 :</p>
<ul>
<li>分桶表的意思是把表的数据会按照指定的字段分成指定的几个桶（部分）</li>
<li>分桶的字段必须是表中已有的字段</li>
<li>分桶功能默认不开启 需要手动打开</li>
<li>分桶的好处  优化join查询   减少笛卡尔积</li>
<li>分桶需要创建一个中间表用于传递数据 , 因为分桶需要查询之后放入桶中</li>
</ul>
</blockquote>
<p>分桶的好处如下图</p>
<p><img src="https://img-blog.csdnimg.cn/20181120232051352.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NvZGVyQm9vbQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h4><a id="12__444"></a>1.2 修改表</h4>
<ul>
<li>
<p>增加分区 :</p>
<ul>
<li>一次添加一个分区</li>
</ul>
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> table_name <span class="token keyword">add</span> <span class="token keyword">partition</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'20170101'</span><span class="token punctuation">)</span> location <span class="token string">'/user/hadoop/warehouse/table_name/dt=20170101'</span><span class="token punctuation">;</span>
执行添加分区时   <span class="token operator">/</span>table_name文件夹下的数据不会被移动。并且没有分区目录dt<span class="token operator">=</span><span class="token number">2008</span><span class="token operator">-</span><span class="token number">08</span><span class="token operator">-</span><span class="token number">08</span> 
<span class="token comment">-----</span>
<span class="token keyword">alter</span> <span class="token keyword">table</span> t_u <span class="token keyword">add</span> <span class="token keyword">partition</span><span class="token punctuation">(</span>province<span class="token operator">=</span><span class="token string">'guangzhou'</span><span class="token punctuation">)</span> location <span class="token string">'/user/hive/warehouse/test01.db/t_u/province=guangzhou'</span><span class="token punctuation">;</span>
</code></pre>
<ul>
<li>一次添加多个分区</li>
</ul>
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> table_name <span class="token keyword">add</span> <span class="token keyword">partition</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'2008-08-08'</span><span class="token punctuation">,</span> country<span class="token operator">=</span><span class="token string">'us'</span><span class="token punctuation">)</span> location <span class="token string">'/path/to/us/part080808'</span> <span class="token keyword">partition</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'2008-08-09'</span><span class="token punctuation">,</span> country<span class="token operator">=</span><span class="token string">'us'</span><span class="token punctuation">)</span> location <span class="token string">'/path/to/us/part080809'</span><span class="token punctuation">;</span>
<span class="token comment">-----</span>
<span class="token keyword">alter</span> <span class="token keyword">table</span> t_user_duo <span class="token keyword">add</span> <span class="token keyword">partition</span> <span class="token punctuation">(</span>province<span class="token operator">=</span><span class="token string">'hainan'</span><span class="token punctuation">,</span>xian<span class="token operator">=</span><span class="token string">'haizhu'</span><span class="token punctuation">)</span> location <span class="token string">'/user/hive/warehouse/test01.db/t_user_duo/province=hainan/xian=haizhu'</span> <span class="token keyword">partition</span> <span class="token punctuation">(</span>province<span class="token operator">=</span><span class="token string">'shenzhen2'</span><span class="token punctuation">,</span>xian<span class="token operator">=</span><span class="token string">'shen'</span><span class="token punctuation">)</span>location <span class="token string">'/user/hive/warehouse/test01.db/t_user_duo/province=shenzhen2/xian=shen'</span><span class="token punctuation">;</span>
</code></pre>
<ul>
<li>删除分区</li>
</ul>
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> table_name <span class="token keyword">drop</span> <span class="token keyword">if</span> <span class="token keyword">exists</span> <span class="token keyword">partition</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'2008-08-08'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">alter</span> <span class="token keyword">table</span> table_name <span class="token keyword">drop</span> <span class="token keyword">if</span> <span class="token keyword">exists</span> <span class="token keyword">partition</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'2008-08-08'</span><span class="token punctuation">,</span> country<span class="token operator">=</span><span class="token string">'us'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<ul>
<li>修改分区</li>
</ul>
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> table_name <span class="token keyword">partition</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'2008-08-08'</span><span class="token punctuation">)</span> <span class="token keyword">rename</span> <span class="token keyword">to</span> <span class="token keyword">partition</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'20080808'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<ul>
<li>添加列</li>
</ul>
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> table_name <span class="token keyword">add</span><span class="token operator">|</span><span class="token keyword">replace</span> <span class="token keyword">columns</span> <span class="token punctuation">(</span>col_name string<span class="token punctuation">)</span><span class="token punctuation">;</span>
注： <span class="token keyword">ADD</span> 是代表新增一个字段，新增字段位置在所有列后面 <span class="token punctuation">(</span><span class="token keyword">partition</span> 列前 <span class="token punctuation">)</span>
<span class="token keyword">REPLACE</span> 则是表示替换表中所有字段。<span class="token comment">#少用</span>
</code></pre>
<ul>
<li>修改列</li>
</ul>
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> test_change change a a1 <span class="token keyword">int</span><span class="token punctuation">;</span> <span class="token comment">//修改 a 字段名==&gt;(a1 int,b int,c int);</span>
<span class="token keyword">alter</span> <span class="token keyword">table</span> test_change change a a1 string <span class="token keyword">after</span> b<span class="token punctuation">;</span> <span class="token comment">//修改a字段名及类型 , 并与字段b交换位置==&gt;(b int,a1 string,c int);</span>
<span class="token keyword">alter</span> <span class="token keyword">table</span> test_change change b b1 <span class="token keyword">int</span> <span class="token keyword">first</span><span class="token punctuation">;</span> <span class="token comment">//修改字段b为b1并放在第一个位置==&gt;(b1 int,a int,c int);</span>
<span class="token keyword">alter</span> <span class="token keyword">table</span> table_name <span class="token keyword">rename</span> <span class="token keyword">to</span> new_table_name<span class="token punctuation">;</span><span class="token comment">//表重命名</span>
</code></pre>
</li>
</ul>
<h4><a id="13__496"></a>1.3 显示命令</h4>
<ul>
<li>
<p><code>show tables;</code> : 显示当前数据库所有表</p>
</li>
<li>
<p><code>show databases|schemas;</code> : 显示所有数据库</p>
</li>
<li>
<p><code>show partitions table_name</code> : 显示表分区信息 , 不是分区表执行报错</p>
</li>
<li>
<p><code>show functions;</code> : 显示当前版本hive支持的所有方法</p>
</li>
<li>
<p><code>desc extended table_name</code> : 查看表信息</p>
<ul>
<li>hive中表类型</li>
</ul>
<pre><code>MANAGED_TABLE  内部表 
EXTERNAL_TABLE  外部表
</code></pre>
</li>
<li>
<p><code>desc formatted table_name</code> : 查看表信息(格式化美观)</p>
<ul>
<li>这里我们可以看到表的详细信息</li>
</ul>
</li>
<li>
<p><code>describe database database_name;</code> : 查看数据库相关信息</p>
</li>
</ul>
<p>hive解析数据</p>
<pre><code>	首先使用InputFormat去读文件（默认一行一行读），读取一行交给SerDe处理，SerDe按照分隔符进行切割，切割出来一个列，对应hvie中一个字段。
	
InputFormat:org.apache.hadoop.mapred.TextInputFormat  
SerDe：org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

LazySimpleSerDe就是语法中delimited 所代表的默认分隔符类
</code></pre>

            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>