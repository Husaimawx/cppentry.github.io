---
layout:     post
title:      HDFS部分：Hdfs的配置
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p><strong>在第一台上（没有配置</strong><strong>zookeeper的）</strong></p>

<p><strong>cd $HADOOP_HOME</strong></p>

<p><strong>然后将</strong></p>

<p><strong>Cp -r hadoop  hadoop-full</strong></p>

<p><strong>进入hadoop</strong></p>

<p><strong>修改hdfs.site</strong></p>

<p><strong>Ha模式</strong></p>

<p><strong>配置ha模式的</strong></p>

<p><strong>没有secondary的配置，所以删除</strong></p>

<p><strong>配置journalnode的配置</strong></p>

<p><strong>配置代理类和实现方式免密钥</strong></p>

<p><strong>配置第四种配置</strong></p>

<p><strong>配置coresite.xml</strong></p>

<p><strong>配置地址</strong></p>

<p><strong>配置zookeeper的队列</strong></p>

<p><strong>第一台上边配置完了之后，将第一台上的分别分发给其他的几台虚拟机</strong></p>

<p><strong>Scp  core-site.xml  hdfs-site.xml  node02:`pwd`</strong></p>

<p><strong>部署的前提是要启动journalnode。三台都要启动</strong></p>

<p><strong>从第一台格式化：</strong></p>

<p><strong>hdfs namenode -format</strong></p>

<p><strong>在第二台与第一台进程同步之前，启动第一台的namenode</strong></p>

<p><strong>在第二台上执行：</strong></p>

<p><strong>hdfs namenode -bootstrapStandby</strong></p>

<p><strong>想要启动start-dfs,就要启动zkfc，zkfc依赖于zookeeper，因此要对zookeeper做一次格式化</strong></p>

<p><strong>调出zkfc的客户端</strong></p>

<p><strong>Zkcli.sh</strong></p>

<p><strong>在第一台进行格式化：</strong></p>

<p><strong>Hdfs  zkfc  -formatZK</strong></p>

<p><strong>这下就可以启动dfs了：</strong></p>

<p><strong>Start-dfs.sh</strong></p>

<p><strong><img alt="" class="has" src="https://img-blog.csdn.net/2018080723072293?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d5cXdpbGxpYW0=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></strong></p>            </div>
                </div>