---
layout:     post
title:      Spark天堂之门笔记
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>一、Spark天堂之门：SparkContext <br>
1. Spark程序在运行时分为Driver和Executors两部分； <br>
2. Spark程序编写基于SparkContext，具体包含两个方面： <br>
   Spark编程的核心基础是RDD，第一个RDD一定是由SparkContext创建的； <br>
   Spark程序的调度优化也是基于SparkContext实现。 <br>
3. Spark程序注册时通过SparkContext实例化时产生的对象完成（实际上通过SchedulerBackend来注册程序）； <br>
4. Spark程序运行时通过Cluster Manager获得具体的计算资源，计算资源的获取也是通过SparkContext产生的对象来申请的（实际上通过SchedulerBackend来获取计算资源)； <br>
5. SparkContext崩溃或者结束时整个Spark程序就结束了。 <br>
SparkContext开启天堂之门：Spark程序通过SparkContext发布到Spark集群； <br>
SparkContext导演天堂世界：Spark程序的运行都是在SparkContext为核心的调度器指挥下进行的； <br>
SparkContext关闭天堂之门：SparkContext崩溃或者结束时整个Spark程序就结束。 <br>
二、SparkContext天堂内幕 <br>
1.SparkContext构建的顶级三大核心对象：DAGScheduler、TaskScheduler、SchedulerBackend，其中： <br>
   DAGScheduler是面向Job的Stage的高层调度器； <br>
   TaskSchedule是接口，根据具体的Cluster Manager的不同会有不同的实现，Standalone模式下具体的实现是TaskSchedulerlmpl； <br>
   SchedulerBackend也是接口，根据具体的Cluster Manager的不同会有不同的实现，Standalone模式下具体的实现是SparkDeploySchedulerBackend； <br>
2. 从整个程序运行的角度来讲，SparkContext包含四大核心对象：DAGScheduler、TaskScheduler、SchedulerBackend、MapOutputTrackerMaster。 <br>
<img src="https://img-blog.csdn.net/20180912161241658?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTA3NDkyOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
<img src="https://img-blog.csdn.net/20180912161512891?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTA3NDkyOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
<img src="https://img-blog.csdn.net/20180912162104436?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTA3NDkyOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>

<p>SparkContext内幕 <br>
<img src="https://img-blog.csdn.net/20180912185543709?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTA3NDkyOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
SparkDeploySchedulerBackend的三种核心功能： <br>
   负责与Master链接注册当前程序； <br>
   接收集群中为当前应用程序而分配的计算资源Executor的注册及管理； <br>
   负责发送Task到具体的Executor执行； <br>
        SparkDeploySchedulerBackend被TaskSchedulerlmpl管理。 <br>
   <img src="https://img-blog.csdn.net/20180912164609594?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTA3NDkyOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
   当通过SparkDeploySchedulerBackend注册程序给Master时把上述command提交给Master，Master发指令给Worker去启动Executor所在的进程的时候加载的main方法所在的入口类就是command中的CoarseGrainedExecutorBackend，也可以实现自己的ExecutorBackend。在CoarseGrainedExecutorBackend中启动Executor（Executor是先注册再实例化)，Executor通过线程池并发执行Task <br>
   <img src="https://img-blog.csdn.net/2018091218292137?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTA3NDkyOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>