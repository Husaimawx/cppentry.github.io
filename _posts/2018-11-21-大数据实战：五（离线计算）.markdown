---
layout:     post
title:      大数据实战：五（离线计算）
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/frostbite_Sword/article/details/81119009				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p style="margin-left:0cm;"><span style="color:#365f91;"><strong>目录</strong></span></p>

<p style="margin-left:0cm;"><a href="#_Toc439077207" rel="nofollow">课程大纲（HDFS详解）.............................................................................................................. 2</a></p>

<p style="margin-left:0cm;"><a href="#_Toc439077208" rel="nofollow">1. HDFS前言................................................................................................................................ 3</a></p>

<p style="margin-left:0cm;"><a href="#_Toc439077209" rel="nofollow">2. HDFS的概念和特性.................................................................................................................. 3</a></p>

<p style="margin-left:0cm;"><a href="#_Toc439077210" rel="nofollow">3. HDFS的shell(命令行客户端)操作............................................................................................ 4</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439077211" rel="nofollow">3.1 HDFS命令行客户端使用................................................................................................ 4</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439077212" rel="nofollow">3.2命令行客户端支持的命令参数...................................................................................... 4</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439077213" rel="nofollow">3.2 常用命令参数介绍......................................................................................................... 5</a></p>

<p style="margin-left:0cm;"><a href="#_Toc439077214" rel="nofollow">4. hdfs的工作机制....................................................................................................................... 8</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439077215" rel="nofollow">4.1 概述：............................................................................................................................ 8</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439077216" rel="nofollow">4.2 HDFS写数据流程............................................................................................................ 9</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439077217" rel="nofollow">4.2.1 概述..................................................................................................................... 9</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439077218" rel="nofollow">4.2.2 详细步骤图.......................................................................................................... 9</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439077219" rel="nofollow">4.2.3 详细步骤解析...................................................................................................... 9</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439077220" rel="nofollow">4.3. HDFS读数据流程......................................................................................................... 10</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439077221" rel="nofollow">4.3.1 概述................................................................................................................... 10</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439077222" rel="nofollow">4.3.2 详细步骤图：.................................................................................................... 10</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439077223" rel="nofollow">4.3.3 详细步骤解析.................................................................................................... 10</a></p>

<p style="margin-left:0cm;"><a href="#_Toc439077224" rel="nofollow">5. NAMENODE工作机制............................................................................................................. 11</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439077225" rel="nofollow">5.1 概述.............................................................................................................................. 11</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439077226" rel="nofollow">5.2元数据管理................................................................................................................... 11</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439077227" rel="nofollow">5.2.1 元数据存储机制................................................................................................ 11</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439077228" rel="nofollow">5.2.2 元数据手动查看................................................................................................ 11</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439077229" rel="nofollow">5.2.3 元数据的checkpoint......................................................................................... 12</a></p>

<p style="margin-left:0cm;"><a href="#_Toc439077230" rel="nofollow">6. DATANODE的工作机制........................................................................................................... 13</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439077231" rel="nofollow">6.1 概述.............................................................................................................................. 13</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439077232" rel="nofollow">6.2 观察验证DATANODE功能........................................................................................... 13</a></p>

<p style="margin-left:0cm;"><a href="#_Toc439077233" rel="nofollow">7. HDFS的java操作................................................................................................................... 13</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439077234" rel="nofollow">7.1 搭建开发环境.............................................................................................................. 13</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439077235" rel="nofollow">7.2 获取api中的客户端对象............................................................................................ 14</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439077236" rel="nofollow">7.3 DistributedFileSystem实例对象所具备的方法............................................................. 14</a></p>

<p style="margin-left:21pt;"><a href="#_Toc439077237" rel="nofollow">7.4 HDFS客户端操作数据代码示例：............................................................................... 15</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439077238" rel="nofollow">7.4.1 文件的增删改查................................................................................................ 15</a></p>

<p style="margin-left:42pt;"><a href="#_Toc439077239" rel="nofollow">7.4.2 通过流的方式访问hdfs.................................................................................... 18</a></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<h1 style="margin-left:0cm;"><strong><a name="_Toc439077207">课程大纲（HDFS</a>详解）</strong></h1>

<table border="1" cellspacing="0" style="width:568px;"><tbody><tr><td rowspan="7" style="vertical-align:top;width:119.7pt;">
			<p style="margin-left:0cm;"><span style="color:#000000;">Hadoop HDFS</span></p>
			</td>
			<td style="vertical-align:top;width:306.4pt;">
			<p style="margin-left:0cm;"><span style="color:#000000;">分布式文件系统</span><span style="color:#000000;">DFS</span><span style="color:#000000;">简介</span></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:306.4pt;">
			<p style="margin-left:0cm;"><span style="color:#000000;">HDFS</span><span style="color:#000000;">的系统组成介绍</span></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:306.4pt;">
			<p style="margin-left:0cm;"><span style="color:#000000;">HDFS</span><span style="color:#000000;">的组成部分详解</span></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:306.4pt;">
			<p style="margin-left:0cm;"><span style="color:#000000;">副本存放策略及路由规则</span></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:306.4pt;">
			<p style="margin-left:0cm;"><span style="color:#000000;">命令行接口</span></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:306.4pt;">
			<p style="margin-left:0cm;"><span style="color:#000000;">Java</span><span style="color:#000000;">接口</span></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:306.4pt;">
			<p style="margin-left:0cm;"><span style="color:#000000;">客户端与</span><span style="color:#000000;">HDFS</span><span style="color:#000000;">的数据流讲解</span></p>
			</td>
		</tr></tbody></table><p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">学习目标：</p>

<p style="margin-left:0cm;"><span style="color:#000000;">掌握</span><span style="color:#000000;">hdfs</span><span style="color:#000000;">的</span><span style="color:#000000;">shell</span><span style="color:#000000;">操作</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">掌握</span><span style="color:#000000;">hdfs</span><span style="color:#000000;">的</span><span style="color:#000000;">java api</span><span style="color:#000000;">操作</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">理解</span><span style="color:#000000;">hdfs</span><span style="color:#000000;">的工作原理</span></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p> </p>

<p style="margin-left:0cm;"> </p>

<h1 style="margin-left:0cm;"><strong><a name="_Toc439077208"></a><a name="_Toc8039"></a><a name="_Toc10331"></a><a name="_Toc29774"></a><a name="_Toc6590"></a><a name="_Toc421731819"></a><a name="_Toc7159"><span style="color:#000000;">******HDFS</span></a><span style="color:#000000;">基本概念篇******</span></strong></h1>

<h1 style="margin-left:0cm;"><strong><span style="color:#000000;">1. HDFS</span><span style="color:#000000;">前言</span></strong></h1>

<ol><li><span style="color:#000000;">设计思想</span></li>
</ol><p style="margin-left:0cm;"><span style="color:#000000;">分而治之：将大文件、大批量文件，分布式存放在大量服务器上，<strong>以便于采取分而治之的方式对海量数据进行运算分析；</strong></span></p>

<p style="margin-left:0cm;"> </p>

<ol><li><span style="color:#000000;">在大数据系统中作用：</span></li>
</ol><p style="margin-left:21pt;"><span style="color:#000000;">为各类分布式运算框架（如：</span><span style="color:#000000;">mapreduce</span><span style="color:#000000;">，</span><span style="color:#000000;">spark</span><span style="color:#000000;">，</span><span style="color:#000000;">tez</span><span style="color:#000000;">，</span><span style="color:#000000;">……</span><span style="color:#000000;">）提供数据存储服务</span></p>

<p style="margin-left:21pt;"> </p>

<ol><li><span style="color:#000000;">重点概念：文件切块，副本存放，元数据</span></li>
</ol><p style="margin-left:21pt;"> </p>

<h1 style="margin-left:0cm;"><strong><a name="_Toc421731821"></a><a name="_Toc24942"></a><a name="_Toc22308"></a><a name="_Toc17151"></a><a name="_Toc10548"></a><a name="_Toc439077209"></a><a name="_Toc20495">2. HDFS</a>的概念和特性</strong></h1>

<p style="margin-left:0cm;"><strong><span style="color:#000000;">首先，它是一个文件系统</span></strong><span style="color:#000000;">，用于存储文件，通过统一的命名空间——目录树来定位文件</span></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><strong><span style="color:#000000;">其次，它是分布式的</span></strong><span style="color:#000000;">，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色；</span></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><strong><span style="color:#000000;">重要特性如下：</span></strong></p>

<ol><li><span style="color:#000000;">HDFS</span><span style="color:#000000;">中的文件在物理上是<strong>分块存储（</strong></span><strong><span style="color:#000000;">block</span></strong><strong><span style="color:#000000;">）</span></strong><span style="color:#000000;">，块的大小可以通过配置参数</span><span style="color:#000000;">( dfs.blocksize)</span><span style="color:#000000;">来规定，默认大小在</span><span style="color:#000000;">hadoop2.x</span><span style="color:#000000;">版本中是</span><span style="color:#000000;">128M</span><span style="color:#000000;">，老版本中是</span><span style="color:#000000;">64M</span></li>
</ol><p style="margin-left:0cm;"> </p>

<ol><li><span style="color:#000000;">HDFS</span><span style="color:#000000;">文件系统会给客户端提供一个<strong>统一的抽象目录树</strong>，客户端通过路径来访问文件，形如：</span><span style="color:#000000;">hdfs://namenode:port/dir-a/dir-b/dir-c/file.data</span></li>
</ol><p style="margin-left:0cm;"> </p>

<ol><li><strong><span style="color:#000000;">目录结构及文件分块信息</span><span style="color:#000000;">(</span></strong><strong><span style="color:#000000;">元数据</span><span style="color:#000000;">)</span></strong><span style="color:#000000;">的管理由</span><span style="color:#000000;">namenode</span><span style="color:#000000;">节点承担</span></li>
</ol><p style="margin-left:0cm;"><span style="color:#000000;">——</span><span style="color:#000000;">namenode</span><span style="color:#000000;">是</span><span style="color:#000000;">HDFS</span><span style="color:#000000;">集群主节点，负责维护整个</span><span style="color:#000000;">hdfs</span><span style="color:#000000;">文件系统的目录树，以及每一个路径（文件）所对应的</span><span style="color:#000000;">block</span><span style="color:#000000;">块信息（</span><span style="color:#000000;">block</span><span style="color:#000000;">的</span><span style="color:#000000;">id</span><span style="color:#000000;">，及所在的</span><span style="color:#000000;">datanode</span><span style="color:#000000;">服务器）</span></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<ol><li><span style="color:#000000;">文件的各个</span><span style="color:#000000;">block</span><span style="color:#000000;">的存储管理由</span><span style="color:#000000;">datanode</span><span style="color:#000000;">节点承担</span></li>
</ol><p style="margin-left:0cm;"><span style="color:#000000;">---- datanode</span><span style="color:#000000;">是</span><span style="color:#000000;">HDFS</span><span style="color:#000000;">集群从节点，每一个</span><span style="color:#000000;">block</span><span style="color:#000000;">都可以在多个</span><span style="color:#000000;">datanode</span><span style="color:#000000;">上存储多个副本（副本数量也可以通过参数设置</span><span style="color:#000000;">dfs.replication</span><span style="color:#000000;">）</span></p>

<p style="margin-left:0cm;"> </p>

<ol><li><span style="color:#000000;">HDFS</span><span style="color:#000000;">是设计成适应一次写入，多次读出的场景，且不支持文件的修改</span></li>
</ol><p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><em><span style="color:#000000;">(</span></em><em><span style="color:#000000;">注：适合用来做数据分析，并不适合用来做网盘应用，因为，不便修改，延迟大，网络开销大，成本太高</span><span style="color:#000000;">)</span></em></p>

<h1 style="margin-left:0cm;"><strong><a name="_Toc15850"></a><a name="_Toc1367"></a><a name="_Toc32138"></a><a name="_Toc31321"></a><a name="_Toc25955"></a><a name="_Toc421731820"></a><a name="_Toc439077210">******HDFS</a>基本操作篇******</strong></h1>

<h1 style="margin-left:0cm;"><strong>3. HDFS的shell(命令行客户端)操作</strong></h1>

<h2 style="margin-left:0cm;"><strong><a name="_Toc439077211">3.1 HDFS</a>命令行客户端使用</strong></h2>

<p style="margin-left:0cm;">HDFS提供shell命令行客户端，使用方法如下：</p>

<p style="margin-left:0cm;"></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<h2 style="margin-left:0cm;"><strong><a name="_Toc439077212">3.2 </a>命令行客户端支持的命令参数</strong></h2>

<table border="1" cellspacing="0" style="width:568px;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><span style="color:#000000;">        [-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-cat [-ignoreCrc] &lt;src&gt; ...]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-checksum &lt;src&gt; ...]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-chgrp [-R] GROUP PATH...]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-chown [-R] [OWNER][:[GROUP]] PATH...]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-copyFromLocal [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-copyToLocal [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-count [-q] &lt;path&gt; ...]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-cp [-f] [-p] &lt;src&gt; ... &lt;dst&gt;]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-df [-h] [&lt;path&gt; ...]]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-du [-s] [-h] &lt;path&gt; ...]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-expunge]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-get [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-getfacl [-R] &lt;path&gt;]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-getmerge [-nl] &lt;src&gt; &lt;localdst&gt;]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-help [cmd ...]]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-ls [-d] [-h] [-R] [&lt;path&gt; ...]]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-mkdir [-p] &lt;path&gt; ...]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-moveToLocal &lt;src&gt; &lt;localdst&gt;]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-mv &lt;src&gt; ... &lt;dst&gt;]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-put [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-rm [-f] [-r|-R] [-skipTrash] &lt;src&gt; ...]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-setfacl [-R] [{-b|-k} {-m|-x &lt;acl_spec&gt;} &lt;path&gt;]|[--set &lt;acl_spec&gt; &lt;path&gt;]]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-stat [format] &lt;path&gt; ...]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-tail [-f] &lt;file&gt;]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-test -[defsz] &lt;path&gt;]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-text [-ignoreCrc] &lt;src&gt; ...]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-touchz &lt;path&gt; ...]</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        [-usage [cmd ...]]</span></p>
			</td>
		</tr></tbody></table><p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<h2 style="margin-left:0cm;"><strong><a name="_Toc439077213">3.2 </a>常用命令参数介绍</strong></h2>

<table border="1" cellspacing="0" style="width:568px;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><span style="color:#000000;">-help             </span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">功能：输出这个命令参数手册</span></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-ls                  </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：显示目录信息</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例： </span><span style="color:#000000;">hadoop fs -ls hdfs://hadoop-server01:9000/</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">备注：这些参数中，所有的</span><span style="color:#000000;">hdfs</span></em><em><span style="color:#000000;">路径都可以简写</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">--&gt;</span><span style="color:#000000;">hadoop fs -ls /   </span></em><em><span style="color:#000000;">等同于上一条命令的效果</span></em></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-mkdir              </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：在</span><span style="color:#000000;">hdfs</span></strong><strong><span style="color:#000000;">上创建目录</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;">hadoop fs  -mkdir  -p  /aaa/bbb/cc/dd</span></em></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-moveFromLocal            </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：从本地剪切粘贴到</span><span style="color:#000000;">hdfs</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;">hadoop  fs  - moveFromLocal  /home/hadoop/a.txt  /aaa/bbb/cc/dd</span></em></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-moveToLocal              </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：从</span><span style="color:#000000;">hdfs</span></strong><strong><span style="color:#000000;">剪切粘贴到本地</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;">hadoop  fs  - moveToLocal   /aaa/bbb/cc/dd  /home/hadoop/a.txt </span></em></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><strong><span style="color:#000000;">--appendToFile  </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：追加一个文件到已经存在的文件末尾</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;">hadoop  fs  -appendToFile  ./hello.txt  hdfs://hadoop-server01:9000/hello.txt</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">可以简写为：</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">Hadoop  fs  -appendToFile  ./hello.txt  /hello.txt</span></em></p>

			<p style="margin-left:0cm;"> </p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-cat  </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：显示文件内容</span>  </strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;">hadoop fs -cat  /hello.txt</span></em></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-tail                 </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：显示一个文件的末尾</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;">hadoop  fs  -tail  /weblog/access_log.1</span></em></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-text                  </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：以字符形式打印一个文件的内容</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;">hadoop  fs  -text  /weblog/access_log.1</span></em></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-chgrp </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-chmod</span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-chown</span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：</span><span style="color:#000000;">linux</span></strong><strong><span style="color:#000000;">文件系统中的用法一样，对文件所属权限</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">hadoop  fs  -chmod  666  /hello.txt</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">hadoop  fs  -chown  someuser:somegrp   /hello.txt</span></em></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-copyFromLocal    </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：从本地文件系统中拷贝文件到</span><span style="color:#000000;">hdfs</span></strong><strong><span style="color:#000000;">路径去</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;">hadoop  fs  -copyFromLocal  ./jdk.tar.gz  /aaa/</span></em></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-copyToLocal      </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：从</span><span style="color:#000000;">hdfs</span></strong><strong><span style="color:#000000;">拷贝到本地</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;">hadoop fs -copyToLocal /aaa/jdk.tar.gz</span></em></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-cp              </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：从</span><span style="color:#000000;">hdfs</span></strong><strong><span style="color:#000000;">的一个路径拷贝</span><span style="color:#000000;">hdfs</span></strong><strong><span style="color:#000000;">的另一个路径</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;"> hadoop  fs  -cp  /aaa/jdk.tar.gz  /bbb/jdk.tar.gz.2</span></em></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-mv                     </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：在</span><span style="color:#000000;">hdfs</span></strong><strong><span style="color:#000000;">目录中移动文件</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;"> hadoop  fs  -mv  /aaa/jdk.tar.gz  /</span></em></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-get              </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：等同于</span><span style="color:#000000;">copyToLocal</span></strong><strong><span style="color:#000000;">，就是从</span><span style="color:#000000;">hdfs</span></strong><strong><span style="color:#000000;">下载文件到本地</span></strong></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">示例：</span><span style="color:#000000;">hadoop fs -get  /aaa/jdk.tar.gz</span></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-getmerge             </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：合并下载多个文件</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span></em><em><span style="color:#000000;">比如</span><span style="color:#000000;">hdfs</span></em><em><span style="color:#000000;">的目录</span><span style="color:#000000;"> /aaa/</span></em><em><span style="color:#000000;">下有多个文件</span><span style="color:#000000;">:log.1, log.2,log.3,...</span></em></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">hadoop fs -getmerge /aaa/log.* ./log.sum</span></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-put                </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：等同于</span><span style="color:#000000;">copyFromLocal</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;">hadoop  fs  -put  /aaa/jdk.tar.gz  /bbb/jdk.tar.gz.2</span></em></p>

			<p style="margin-left:0cm;"> </p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-rm                </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：删除文件或文件夹</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;">hadoop fs -rm -r /aaa/bbb/</span></em></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-rmdir                 </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：删除空目录</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;">hadoop  fs  -rmdir   /aaa/bbb/ccc</span></em></p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-df               </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：统计文件系统的可用空间信息</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;">hadoop  fs  -df  -h  /</span></em></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-du </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：统计文件夹的大小信息</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">hadoop  fs  -du  -s  -h /aaa/*</span></em></p>

			<p style="margin-left:0cm;"> </p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-count         </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：统计一个指定目录下的文件节点数量</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;">hadoop fs -count /aaa/</span></em></p>

			<p style="margin-left:0cm;"> </p>
			</td>
		</tr><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><strong><span style="color:#000000;">-setrep                </span></strong></p>

			<p style="margin-left:0cm;"><strong><span style="color:#000000;">功能：设置</span><span style="color:#000000;">hdfs</span></strong><strong><span style="color:#000000;">中文件的副本数量</span></strong></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">示例：</span><span style="color:#000000;">hadoop fs -setrep 3 /aaa/jdk.tar.gz</span></em></p>

			<p style="margin-left:0cm;"> </p>
			</td>
		</tr></tbody></table><p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p> </p>

<p style="margin-left:0cm;"> </p>

<h1 style="margin-left:0cm;"><strong><a name="_Toc439077214"></a><a name="_Toc421731823"></a><a name="_Toc21978"></a><a name="_Toc27953"></a><a name="_Toc23129"></a><a name="_Toc16603">******HDFS</a>原理篇******</strong></h1>

<h1 style="margin-left:0cm;"><strong>4. hdfs的工作机制</strong></h1>

<p style="margin-left:0cm;"><em>（工作机制的学习主要是为加深对分布式系统的理解，以及增强遇到各种问题时的分析解决能力，形成一定的集群运维能力）</em></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><em>注：很多不是真正理解hadoop</em><em>技术体系的人会常常觉得HDFS</em><em>可用于网盘类应用，但实际并非如此。要想将技术准确用在恰当的地方，必须对技术有深刻的理解</em></p>

<h2 style="margin-left:0cm;"><strong><a name="_Toc439077215">4.1 </a>概述</strong></h2>

<ol><li><span style="color:#000000;">HDFS</span><span style="color:#000000;">集群分为两大角色：</span><span style="color:#000000;">NameNode</span><span style="color:#000000;">、</span><span style="color:#000000;">DataNode  (Secondary Namenode)</span></li>
	<li><span style="color:#000000;">NameNode</span><span style="color:#000000;">负责管理整个文件系统的元数据</span></li>
	<li><span style="color:#000000;">DataNode </span><span style="color:#000000;">负责管理用户的文件数据块</span></li>
	<li><span style="color:#000000;">文件会按照固定的大小（</span><span style="color:#000000;">blocksize</span><span style="color:#000000;">）切成若干块后分布式存储在若干台</span><span style="color:#000000;">datanode</span><span style="color:#000000;">上</span></li>
	<li><span style="color:#000000;">每一个文件块可以有多个副本，并存放在不同的</span><span style="color:#000000;">datanode</span><span style="color:#000000;">上</span></li>
	<li><span style="color:#000000;">Datanode</span><span style="color:#000000;">会定期向</span><span style="color:#000000;">Namenode</span><span style="color:#000000;">汇报自身所保存的文件</span><span style="color:#000000;">block</span><span style="color:#000000;">信息，而</span><span style="color:#000000;">namenode</span><span style="color:#000000;">则会负责保持文件的副本数量</span></li>
	<li><span style="color:#000000;">HDFS</span><span style="color:#000000;">的内部工作机制对客户端保持透明，客户端请求访问</span><span style="color:#000000;">HDFS</span><span style="color:#000000;">都是通过向</span><span style="color:#000000;">namenode</span><span style="color:#000000;">申请来进行</span></li>
</ol><p style="margin-left:0cm;"> </p>

<p> </p>

<p style="margin-left:0cm;"> </p>

<h2 style="margin-left:0cm;"><strong><a name="_Toc439077216">4.2 HDFS</a>写数据流程</strong></h2>

<h3 style="margin-left:0cm;"><strong><a name="_Toc439077217">4.2.1 </a>概述</strong></h3>

<p style="margin-left:0cm;">客户端要向HDFS写数据，首先要跟namenode通信以确认可以写文件并获得接收文件block的datanode，然后，客户端按顺序将文件逐个block传递给相应datanode，并由接收到block的datanode负责向其他datanode复制block的副本</p>

<h3 style="margin-left:0cm;"><strong><a name="_Toc439077218">4.2.2 </a>详细步骤图</strong></h3>

<p style="margin-left:0cm;"><span style="color:#000000;"></span></p>

<h3 style="margin-left:0cm;"><strong><a name="_Toc439077219">4.2.3 </a>详细步骤解析</strong></h3>

<p style="margin-left:0cm;"><span style="color:#000000;">1</span><span style="color:#000000;">、根</span><span style="color:#000000;">namenode</span><span style="color:#000000;">通信请求上传文件，</span><span style="color:#000000;">namenode</span><span style="color:#000000;">检查目标文件是否已存在，父目录是否存在</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">2</span><span style="color:#000000;">、</span><span style="color:#000000;">namenode</span><span style="color:#000000;">返回是否可以上传</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">3</span><span style="color:#000000;">、</span><span style="color:#000000;">client</span><span style="color:#000000;">请求第一个</span><span style="color:#000000;"> block</span><span style="color:#000000;">该传输到哪些</span><span style="color:#000000;">datanode</span><span style="color:#000000;">服务器上</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">4</span><span style="color:#000000;">、</span><span style="color:#000000;">namenode</span><span style="color:#000000;">返回</span><span style="color:#000000;">3</span><span style="color:#000000;">个</span><span style="color:#000000;">datanode</span><span style="color:#000000;">服务器</span><span style="color:#000000;">ABC</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">5</span><span style="color:#000000;">、</span><span style="color:#000000;">client</span><span style="color:#000000;">请求</span><span style="color:#000000;">3</span><span style="color:#000000;">台</span><span style="color:#000000;">dn</span><span style="color:#000000;">中的一台</span><span style="color:#000000;">A</span><span style="color:#000000;">上传数据（本质上是一个</span><span style="color:#000000;">RPC</span><span style="color:#000000;">调用，建立</span><span style="color:#000000;">pipeline</span><span style="color:#000000;">），</span><span style="color:#000000;">A</span><span style="color:#000000;">收到请求会继续调用</span><span style="color:#000000;">B</span><span style="color:#000000;">，然后</span><span style="color:#000000;">B</span><span style="color:#000000;">调用</span><span style="color:#000000;">C</span><span style="color:#000000;">，将真个</span><span style="color:#000000;">pipeline</span><span style="color:#000000;">建立完成，逐级返回客户端</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">6</span><span style="color:#000000;">、</span><span style="color:#000000;">client</span><span style="color:#000000;">开始往</span><span style="color:#000000;">A</span><span style="color:#000000;">上传第一个</span><span style="color:#000000;">block</span><span style="color:#000000;">（先从磁盘读取数据放到一个本地内存缓存），以</span><span style="color:#000000;">packet</span><span style="color:#000000;">为单位，</span><span style="color:#000000;">A</span><span style="color:#000000;">收到一个</span><span style="color:#000000;">packet</span><span style="color:#000000;">就会传给</span><span style="color:#000000;">B</span><span style="color:#000000;">，</span><span style="color:#000000;">B</span><span style="color:#000000;">传给</span><span style="color:#000000;">C</span><span style="color:#000000;">；</span><span style="color:#000000;">A</span><span style="color:#000000;">每传一个</span><span style="color:#000000;">packet</span><span style="color:#000000;">会放入一个应答队列等待应答</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">7</span><span style="color:#000000;">、当一个</span><span style="color:#000000;">block</span><span style="color:#000000;">传输完成之后，</span><span style="color:#000000;">client</span><span style="color:#000000;">再次请求</span><span style="color:#000000;">namenode</span><span style="color:#000000;">上传第二个</span><span style="color:#000000;">block</span><span style="color:#000000;">的服务器。</span></p>

<h2 style="margin-left:0cm;"><strong><a name="_Toc439077220">4.3. HDFS</a>读数据流程</strong></h2>

<h3 style="margin-left:0cm;"><strong><a name="_Toc439077221">4.3.1 </a>概述</strong></h3>

<p style="margin-left:0cm;">客户端将要读取的文件路径发送给namenode，namenode获取文件的元信息（主要是block的存放位置信息）返回给客户端，客户端根据返回的信息找到相应datanode逐个获取文件的block并在客户端本地进行数据追加合并从而获得整个文件</p>

<p style="margin-left:0cm;"> </p>

<h3 style="margin-left:0cm;"><strong><a name="_Toc439077222">4.3.2 </a>详细步骤图</strong></h3>

<p style="margin-left:0cm;"><span style="color:#000000;"></span></p>

<p style="margin-left:0cm;"> </p>

<h3 style="margin-left:0cm;"><strong><a name="_Toc439077223">4.3.3 </a>详细步骤解析</strong></h3>

<p style="margin-left:0cm;"><span style="color:#000000;">1</span><span style="color:#000000;">、跟</span><span style="color:#000000;">namenode</span><span style="color:#000000;">通信查询元数据，找到文件块所在的</span><span style="color:#000000;">datanode</span><span style="color:#000000;">服务器</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">2</span><span style="color:#000000;">、挑选一台</span><span style="color:#000000;">datanode</span><span style="color:#000000;">（就近原则，然后随机）服务器，请求建立</span><span style="color:#000000;">socket</span><span style="color:#000000;">流</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">3</span><span style="color:#000000;">、</span><span style="color:#000000;">datanode</span><span style="color:#000000;">开始发送数据（从磁盘里面读取数据放入流，以</span><span style="color:#000000;">packet</span><span style="color:#000000;">为单位来做校验）</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">4</span><span style="color:#000000;">、客户端以</span><span style="color:#000000;">packet</span><span style="color:#000000;">为单位接收，现在本地缓存，然后写入目标文件</span></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p> </p>

<p style="margin-left:0cm;"> </p>

<h1 style="margin-left:0cm;"><strong><a name="_Toc439077224"></a><a name="_Toc421731824">5. NAMENODE</a>工作机制</strong></h1>

<p style="margin-left:0cm;">学习目标：理解namenode的工作机制尤其是<strong>元数据管理</strong>机制，以增强对HDFS工作原理的理解，及培养hadoop集群运营中“性能调优”、“namenode”故障问题的分析解决能力</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><em>问题场景：</em></p>

<p style="margin-left:0cm;"><em>1</em><em>、集群启动后，可以查看文件，但是上传文件时报错，打开web</em><em>页面可看到namenode</em><em>正处于safemode</em><em>状态，怎么处理？</em></p>

<p style="margin-left:0cm;"><em>2</em><em>、Namenode</em><em>服务器的磁盘故障导致namenode</em><em>宕机，如何挽救集群及数据？</em></p>

<p style="margin-left:0cm;"><em>3</em><em>、Namenode</em><em>是否可以有多个？namenode</em><em>内存要配置多大？namenode</em><em>跟集群数据存储能力有关系吗？</em></p>

<p style="margin-left:0cm;"><em>4</em><em>、文件的blocksize</em><em>究竟调大好还是调小好？</em></p>

<p style="margin-left:0cm;"><em>……</em></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><em>诸如此类问题的回答，都需要基于对namenode</em><em>自身的工作原理的深刻理解</em></p>

<p style="margin-left:0cm;"> </p>

<h2 style="margin-left:0cm;"><strong><a name="_Toc505"></a><a name="_Toc439077225">5.1 <span style="color:#000000;">NAMENODE</span></a>职责</strong></h2>

<p style="margin-left:0cm;"><span style="color:#000000;">NAMENODE</span><span style="color:#000000;">职责：</span></p>

<p style="margin-left:0cm;"><a name="_Toc4721"><span style="color:#000000;">负责客户端请求的响应</span></a></p>

<p style="margin-left:0cm;"><a name="_Toc29702"><span style="color:#000000;">元数据的管理（查询，修改）</span></a></p>

<h2 style="margin-left:0cm;"><strong><a name="_Toc439077226">5.2 </a>元数据管理</strong></h2>

<p style="margin-left:0cm;">namenode对数据的管理采用了三种存储形式：</p>

<p style="margin-left:0cm;">内存元数据(NameSystem)</p>

<p style="margin-left:0cm;">磁盘元数据镜像文件</p>

<p style="margin-left:0cm;">数据操作日志文件（可通过日志运算出元数据）</p>

<h3 style="margin-left:0cm;"><strong><a name="_Toc11005"></a><a name="_Toc439077227">5.2.1 </a>元数据存储机制</strong></h3>

<p style="margin-left:0cm;"><a name="_Toc29922"><span style="color:#000000;">A</span></a><span style="color:#000000;">、内存中有一份完整的元数据</span><span style="color:#000000;">(</span><strong><span style="color:#FF0000;">内存</span><span style="color:#FF0000;">meta data</span></strong><span style="color:#000000;">)</span></p>

<p style="margin-left:0cm;"><a name="_Toc1289"><span style="color:#000000;">B</span></a><span style="color:#000000;">、磁盘有一个“准完整”的元数据镜像（</span><strong><span style="color:#FF0000;">fsimage</span></strong><span style="color:#000000;">）文件</span><span style="color:#000000;">(</span><span style="color:#000000;">在</span><span style="color:#000000;">namenode</span><span style="color:#000000;">的工作目录中</span><span style="color:#000000;">)</span></p>

<p style="margin-left:0cm;"><a name="_Toc7299"><span style="color:#000000;">C</span></a><span style="color:#000000;">、用于衔接内存</span><span style="color:#000000;">metadata</span><span style="color:#000000;">和持久化元数据镜像</span><span style="color:#000000;">fsimage</span><span style="color:#000000;">之间的操作日志（</span><strong><span style="color:#FF0000;">edits</span></strong><strong><span style="color:#FF0000;">文件</span></strong><span style="color:#000000;">）<em>注：当客户端对</em></span><em><span style="color:#000000;">hdfs</span></em><em><span style="color:#000000;">中的文件进行新增或者修改操作，操作记录首先被记入</span><span style="color:#000000;">edits</span></em><em><span style="color:#000000;">日志文件中，当客户端操作成功后，相应的元数据会更新到内存</span><span style="color:#000000;">meta.data</span></em><em><span style="color:#000000;">中</span></em></p>

<h3 style="margin-left:0cm;"><strong><a name="_Toc439077228">5.2.2 </a>元数据手动查看</strong></h3>

<p style="margin-left:0cm;"><a name="_Toc8756"><span style="color:#000000;">可以通过</span><span style="color:#000000;">hdfs</span></a><span style="color:#000000;">的一个工具来查看</span><span style="color:#000000;">edits</span><span style="color:#000000;">中的信息</span></p>

<pre style="margin-left:0cm;">
<span style="color:#000000;">bin/hdfs oev -i edits -o edits.xml</span><a name="_Toc439077229"></a></pre>

<pre style="margin-left:0cm;">
<span style="color:#000000;">bin/hdfs oiv -i fsimage_0000000000000000087 -p XML -o fsimage.xml</span></pre>

<h3 style="margin-left:0cm;"><strong>5.2.3 元数据的checkpoint</strong></h3>

<p style="margin-left:0cm;"><a name="_Toc2551"><span style="color:#000000;">每隔一段时间，会由</span><span style="color:#000000;">secondary namenode</span></a><span style="color:#000000;">将</span><span style="color:#000000;">namenode</span><span style="color:#000000;">上积累的所有</span><span style="color:#000000;">edits</span><span style="color:#000000;">和一个最新的</span><span style="color:#000000;">fsimage</span><span style="color:#000000;">下载到本地，并加载到内存进行</span><span style="color:#000000;">merge</span><span style="color:#000000;">（这个过程称为</span><span style="color:#000000;">checkpoint</span><span style="color:#000000;">）</span></p>

<p style="margin-left:0cm;"> </p>

<p><strong>checkpoint的详细过程</strong></p>

<p style="margin-left:0cm;"><span style="color:#000000;"></span></p>

<p style="margin-left:0cm;"><a name="_Toc17124"></a></p>

<p><strong>checkpoint操作的触发条件配置参数</strong></p>

<table border="1" cellspacing="0" style="width:568px;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><span style="color:#000000;">dfs.namenode.checkpoint.check.period=60  #</span><span style="color:#000000;">检查触发条件是否满足的频率，</span><span style="color:#000000;">60</span><span style="color:#000000;">秒</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">dfs.namenode.checkpoint.dir=file://${hadoop.tmp.dir}/dfs/namesecondary</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">#</span><span style="color:#000000;">以上两个参数做</span><span style="color:#000000;">checkpoint</span><span style="color:#000000;">操作时，</span><span style="color:#000000;">secondary namenode</span><span style="color:#000000;">的本地工作目录</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">dfs.namenode.checkpoint.edits.dir=${dfs.namenode.checkpoint.dir}</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">dfs.namenode.checkpoint.max-retries=3  #</span><span style="color:#000000;">最大重试次数</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">dfs.namenode.checkpoint.period=3600  #</span><span style="color:#000000;">两次</span><span style="color:#000000;">checkpoint</span><span style="color:#000000;">之间的时间间隔</span><span style="color:#000000;">3600</span><span style="color:#000000;">秒</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">dfs.namenode.checkpoint.txns=1000000 #</span><span style="color:#000000;">两次</span><span style="color:#000000;">checkpoint</span><span style="color:#000000;">之间最大的操作记录</span></p>
			</td>
		</tr></tbody></table><p><strong><a name="_Toc32115">checkpoint</a>的附带作用</strong></p>

<p style="margin-left:0cm;"><span style="color:#000000;">namenode</span><span style="color:#000000;">和</span><span style="color:#000000;">secondary namenode</span><span style="color:#000000;">的工作目录存储结构完全相同，所以，当</span><span style="color:#000000;">namenode</span><span style="color:#000000;">故障退出需要重新恢复时，可以从</span><span style="color:#000000;">secondary namenode</span><span style="color:#000000;">的工作目录中将</span><span style="color:#000000;">fsimage</span><span style="color:#000000;">拷贝到</span><span style="color:#000000;">namenode</span><span style="color:#000000;">的工作目录，以恢复</span><span style="color:#000000;">namenode</span><span style="color:#000000;">的元数据</span></p>

<p style="margin-left:0cm;"> </p>

<h3 style="margin-left:0cm;"><strong>5.2.4 元数据目录说明</strong></h3>

<p style="margin-left:0cm;"><span style="color:#000000;">在第一次部署好</span><span style="color:#000000;">Hadoop</span><span style="color:#000000;">集群的时候，我们需要在</span><span style="color:#000000;">NameNode</span><span style="color:#000000;">（</span><span style="color:#000000;">NN</span><span style="color:#000000;">）节点上格式化磁盘：</span></p>

<table border="1" cellspacing="0" style="width:568px;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><span style="color:#000000;">$HADOOP_HOME/bin/hdfs namenode -format</span></p>
			</td>
		</tr></tbody></table><p style="margin-left:0cm;"><span style="color:#000000;">格式化完成之后，将会在</span><span style="color:#000000;">$dfs.namenode.name.dir/current</span><span style="color:#000000;">目录下如下的文件结构</span></p>

<table border="1" cellspacing="0" style="width:568px;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<pre style="margin-left:0cm;">
<span style="color:#000000;">current/</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">|-- VERSION</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">|-- edits_*</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">|-- fsimage_0000000000008547077</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">|-- fsimage_0000000000008547077.md5</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">`-- seen_txid</span></pre>
			</td>
		</tr></tbody></table><p style="margin-left:0cm;"><span style="color:#000000;">其中的</span><span style="color:#000000;">dfs.name.dir</span><span style="color:#000000;">是在</span><span style="color:#000000;">hdfs-site.xml</span><span style="color:#000000;">文件中配置的，默认值如下：</span></p>

<table border="1" cellspacing="0" style="width:568px;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<pre style="margin-left:0cm;">
<span style="color:#000000;">&lt;property&gt;</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">  &lt;name&gt;dfs.name.dir&lt;/name&gt;</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">  &lt;value&gt;file://${hadoop.tmp.dir}/dfs/name&lt;/value&gt;</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">&lt;/property&gt;</span></pre>

			<pre style="margin-left:0cm;">

 </pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">hadoop.tmp.dir</span><span style="color:#000000;">是在</span><span style="color:#000000;">core-site.xml</span><span style="color:#000000;">中配置的，默认值如下</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">&lt;property&gt;</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">  &lt;value&gt;/tmp/hadoop-${user.name}&lt;/value&gt;</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">  &lt;description&gt;A base for other temporary directories.&lt;/description&gt;</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">&lt;/property&gt;</span></pre>
			</td>
		</tr></tbody></table><p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><span style="color:#000000;">dfs.namenode.name.dir</span><span style="color:#000000;">属性可以配置多个目录，</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">如</span><span style="color:#000000;">/data1/dfs/name,/data2/dfs/name,/data3/dfs/name,....</span><span style="color:#000000;">。各个目录存储的文件结构和内容都完全一样，相当于备份，这样做的好处是当其中一个目录损坏了，也不会影响到</span><span style="color:#000000;">Hadoop</span><span style="color:#000000;">的元数据，特别是当其中一个目录是</span><span style="color:#000000;">NFS</span><span style="color:#000000;">（网络文件系统</span><span style="color:#000000;">Network File System</span><span style="color:#000000;">，</span><span style="color:#000000;">NFS</span><span style="color:#000000;">）之上，即使你这台机器损坏了，元数据也得到保存。</span><br><span style="color:#000000;">下面对</span><span style="color:#000000;">$dfs.namenode.name.dir/current/</span><span style="color:#000000;">目录下的文件进行解释。</span><br><span style="color:#000000;">1</span><span style="color:#000000;">、</span><span style="color:#000000;">VERSION</span><span style="color:#000000;">文件是</span><span style="color:#000000;">Java</span><span style="color:#000000;">属性文件，内容大致如下：</span></p>

<table border="1" cellspacing="0" style="width:568px;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<pre style="margin-left:0cm;">
<span style="color:#000000;">#Fri Nov 15 19:47:46 CST 2013</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">namespaceID=934548976</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">clusterID=CID-cdff7d73-93cd-4783-9399-0a22e6dce196</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">cTime=0</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">storageType=NAME_NODE</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">blockpoolID=BP-893790215-192.168.24.72-1383809616115</span></pre>

			<pre style="margin-left:0cm;">
<span style="color:#000000;">layoutVersion=-47</span></pre>
			</td>
		</tr></tbody></table><p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><span style="color:#000000;">其中</span><br><span style="color:#000000;">　　（</span><span style="color:#000000;">1</span><span style="color:#000000;">）、</span><span style="color:#000000;">namespaceID</span><span style="color:#000000;">是文件系统的唯一标识符，在文件系统首次格式化之后生成的；</span><br><span style="color:#000000;">　　（</span><span style="color:#000000;">2</span><span style="color:#000000;">）、</span><span style="color:#000000;">storageType</span><span style="color:#000000;">说明这个文件存储的是什么进程的数据结构信息（如果是</span><span style="color:#000000;">DataNode</span><span style="color:#000000;">，</span><span style="color:#000000;">storageType=DATA_NODE</span><span style="color:#000000;">）；</span><br><span style="color:#000000;">　　（</span><span style="color:#000000;">3</span><span style="color:#000000;">）、</span><span style="color:#000000;">cTime</span><span style="color:#000000;">表示</span><span style="color:#000000;">NameNode</span><span style="color:#000000;">存储时间的创建时间，由于我的</span><span style="color:#000000;">NameNode</span><span style="color:#000000;">没有更新过，所以这里的记录值为</span><span style="color:#000000;">0</span><span style="color:#000000;">，以后对</span><span style="color:#000000;">NameNode</span><span style="color:#000000;">升级之后，</span><span style="color:#000000;">cTime</span><span style="color:#000000;">将会记录更新时间戳；</span><br><span style="color:#000000;">　　（</span><span style="color:#000000;">4</span><span style="color:#000000;">）、</span><span style="color:#000000;">layoutVersion</span><span style="color:#000000;">表示</span><span style="color:#000000;">HDFS</span><span style="color:#000000;">永久性数据结构的版本信息，</span> <span style="color:#000000;">只要数据结构变更，版本号也要递减，此时的</span><span style="color:#000000;">HDFS</span><span style="color:#000000;">也需要升级，否则磁盘仍旧是使用旧版本的数据结构，这会导致新版本的</span><span style="color:#000000;">NameNode</span><span style="color:#000000;">无法使用；</span><br><span style="color:#000000;">　　（</span><span style="color:#000000;">5</span><span style="color:#000000;">）、</span><span style="color:#000000;">clusterID</span><span style="color:#000000;">是系统生成或手动指定的集群</span><span style="color:#000000;">ID</span><span style="color:#000000;">，在</span><span style="color:#000000;">-clusterid</span><span style="color:#000000;">选项中可以使用它；如下说明</span></p>

<p style="margin-left:0cm;"> </p>

<ol><li><span style="color:#000000;">使用如下命令格式化一个</span><span style="color:#000000;">Namenode</span><span style="color:#000000;">：</span></li>
</ol><p style="margin-left:0cm;"><span style="color:#000000;">$HADOOP_HOME/bin/hdfs namenode -format [-clusterId &lt;cluster_id&gt;]</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">选择一个唯一的</span><span style="color:#000000;">cluster_id</span><span style="color:#000000;">，并且这个</span><span style="color:#000000;">cluster_id</span><span style="color:#000000;">不能与环境中其他集群有冲突。如果没有提供</span><span style="color:#000000;">cluster_id</span><span style="color:#000000;">，则会自动生成一个唯一的</span><span style="color:#000000;">ClusterID</span><span style="color:#000000;">。</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">b</span><span style="color:#000000;">、使用如下命令格式化其他</span><span style="color:#000000;">Namenode</span><span style="color:#000000;">：</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;"> $HADOOP_HOME/bin/hdfs namenode -format -clusterId &lt;cluster_id&gt;</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">c</span><span style="color:#000000;">、升级集群至最新版本。在升级过程中需要提供一个</span><span style="color:#000000;">ClusterID</span><span style="color:#000000;">，例如：</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">$HADOOP_PREFIX_HOME/bin/hdfs start namenode --config $HADOOP_CONF_DIR  -upgrade -clusterId &lt;cluster_ID&gt;</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">如果没有提供</span><span style="color:#000000;">ClusterID</span><span style="color:#000000;">，则会自动生成一个</span><span style="color:#000000;">ClusterID</span><span style="color:#000000;">。</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">　　（</span><span style="color:#000000;">6</span><span style="color:#000000;">）、</span><span style="color:#000000;">blockpoolID</span><span style="color:#000000;">：是针对每一个</span><span style="color:#000000;">Namespace</span><span style="color:#000000;">所对应的</span><span style="color:#000000;">blockpool</span><span style="color:#000000;">的</span><span style="color:#000000;">ID</span><span style="color:#000000;">，上面的这个</span><span style="color:#000000;">BP-893790215-192.168.24.72-1383809616115</span><span style="color:#000000;">就是在我的</span><span style="color:#000000;">ns1</span><span style="color:#000000;">的</span><span style="color:#000000;">namespace</span><span style="color:#000000;">下的存储块池的</span><span style="color:#000000;">ID</span><span style="color:#000000;">，这个</span><span style="color:#000000;">ID</span><span style="color:#000000;">包括了其对应的</span><span style="color:#000000;">NameNode</span><span style="color:#000000;">节点的</span><span style="color:#000000;">ip</span><span style="color:#000000;">地址。</span><br>
　　<br><span style="color:#000000;">2</span><span style="color:#000000;">、</span><span style="color:#000000;">$dfs.namenode.name.dir/current/seen_txid</span><span style="color:#000000;">非常重要，是存放</span><span style="color:#000000;">transactionId</span><span style="color:#000000;">的文件，</span><span style="color:#000000;">format</span><span style="color:#000000;">之后是</span><span style="color:#000000;">0</span><span style="color:#000000;">，它代表的是</span><span style="color:#000000;">namenode</span><span style="color:#000000;">里面的</span><span style="color:#000000;">edits_*</span><span style="color:#000000;">文件的尾数，</span><span style="color:#000000;">namenode</span><span style="color:#000000;">重启的时候，会按照</span><span style="color:#000000;">seen_txid</span><span style="color:#000000;">的数字，循序从头跑</span><span style="color:#000000;">edits_0000001~</span><span style="color:#000000;">到</span><span style="color:#000000;">seen_txid</span><span style="color:#000000;">的数字。所以当你的</span><span style="color:#000000;">hdfs</span><span style="color:#000000;">发生异常重启的时候，一定要比对</span><span style="color:#000000;">seen_txid</span><span style="color:#000000;">内的数字是不是你</span><span style="color:#000000;">edits</span><span style="color:#000000;">最后的尾数，不然会发生建置</span><span style="color:#000000;">namenode</span><span style="color:#000000;">时</span><span style="color:#000000;">metaData</span><span style="color:#000000;">的资料有缺少，导致误删</span><span style="color:#000000;">Datanode</span><span style="color:#000000;">上多余</span><span style="color:#000000;">Block</span><span style="color:#000000;">的资讯。</span></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><span style="color:#000000;">3</span><span style="color:#000000;">、</span><span style="color:#000000;">$dfs.namenode.name.dir/current</span><span style="color:#000000;">目录下在</span><span style="color:#000000;">format</span><span style="color:#000000;">的同时也会生成</span><span style="color:#000000;">fsimage</span><span style="color:#000000;">和</span><span style="color:#000000;">edits</span><span style="color:#000000;">文件，及其对应的</span><span style="color:#000000;">md5</span><span style="color:#000000;">校验文件。</span></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><span style="color:#FF0000;">补充：</span><span style="color:#FF0000;">seen_txid </span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">文件中记录的是</span><span style="color:#000000;">edits</span><span style="color:#000000;">滚动的序号，每次重启</span><span style="color:#000000;">namenode</span><span style="color:#000000;">时，</span><span style="color:#000000;">namenode</span><span style="color:#000000;">就知道要将哪些</span><span style="color:#000000;">edits</span><span style="color:#000000;">进行加载</span><span style="color:#000000;">edits</span></p>

<h1 style="margin-left:0cm;"><strong><a name="_Toc26969"></a><a name="_Toc439077230"></a><a name="_Toc10777"></a><a name="_Toc11613"></a><a name="_Toc13739"></a><a name="_Toc421731825"><span style="color:#000000;">6. DATANODE</span></a><span style="color:#000000;">的工作机制</span></strong></h1>

<p style="margin-left:0cm;"><em>问题场景：</em></p>

<p style="margin-left:0cm;"><em>1</em><em>、集群容量不够，怎么扩容？</em></p>

<p style="margin-left:0cm;"><em>2</em><em>、如果有一些datanode</em><em>宕机，该怎么办？</em></p>

<p style="margin-left:0cm;"><em>3</em><em>、datanode</em><em>明明已启动，但是集群中的可用datanode</em><em>列表中就是没有，怎么办？</em></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><em>以上这类问题的解答，有赖于对datanode</em><em>工作机制的深刻理解</em></p>

<h2 style="margin-left:0cm;"><strong><a name="_Toc439077231">6.1 </a>概述</strong></h2>

<p style="margin-left:0cm;"><span style="color:#000000;">1</span><span style="color:#000000;">、</span><span style="color:#000000;">Datanode</span><span style="color:#000000;">工作职责：</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">存储管理用户的文件块数据</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">定期向</span><span style="color:#000000;">namenode</span><span style="color:#000000;">汇报自身所持有的</span><span style="color:#000000;">block</span><span style="color:#000000;">信息（通过心跳信息上报）</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">（这点很重要，因为，当集群中发生某些</span><span style="color:#000000;">block</span><span style="color:#000000;">副本失效时，集群如何恢复</span><span style="color:#000000;">block</span><span style="color:#000000;">初始副本数量的问题）</span></p>

<p style="margin-left:0cm;"> </p>

<table border="1" cellspacing="0" style="width:568px;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><span style="color:#000000;">&lt;property&gt;</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          &lt;name&gt;dfs.blockreport.intervalMsec&lt;/name&gt;</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          &lt;value&gt;3600000&lt;/value&gt;</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          &lt;description&gt;Determines block reporting interval in milliseconds.&lt;/description&gt;</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">&lt;/property&gt;</span></p>
			</td>
		</tr></tbody></table><p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><span style="color:#000000;">2</span><span style="color:#000000;">、</span><span style="color:#000000;">Datanode</span><span style="color:#000000;">掉线判断时限参数</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">datanode</span><span style="color:#000000;">进程死亡或者网络故障造成</span><span style="color:#000000;">datanode</span><span style="color:#000000;">无法与</span><span style="color:#000000;">namenode</span><span style="color:#000000;">通信，</span><span style="color:#000000;">namenode</span><span style="color:#000000;">不会立即把该节点判定为死亡，要经过一段时间，这段时间暂称作超时时长。</span><span style="color:#000000;">HDFS</span><span style="color:#000000;">默认的超时时长为</span><span style="color:#000000;">10</span><span style="color:#000000;">分钟</span><span style="color:#000000;">+30</span><span style="color:#000000;">秒。如果定义超时时间为</span><span style="color:#000000;">timeout</span><span style="color:#000000;">，则超时时长的计算公式为：</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">          timeout  = 2 * heartbeat.recheck.interval + 10 * dfs.heartbeat.interval</span><span style="color:#000000;">。</span></p>

<p style="margin-left:0cm;">          <span style="color:#000000;">而默认的</span><span style="color:#000000;">heartbeat.recheck.interval </span><span style="color:#000000;">大小为</span><span style="color:#000000;">5</span><span style="color:#000000;">分钟，</span><span style="color:#000000;">dfs.heartbeat.interval</span><span style="color:#000000;">默认为</span><span style="color:#000000;">3</span><span style="color:#000000;">秒。</span></p>

<p style="margin-left:0cm;">          <span style="color:#000000;">需要注意的是</span><span style="color:#000000;">hdfs-site.xml </span><span style="color:#000000;">配置文件中的</span><span style="color:#000000;">heartbeat.recheck.interval</span><span style="color:#000000;">的单位为毫秒，</span><span style="color:#000000;">dfs.heartbeat.interval</span><span style="color:#000000;">的单位为秒。所以，举个例子，如果</span><span style="color:#000000;">heartbeat.recheck.interval</span><span style="color:#000000;">设置为</span><span style="color:#000000;">5000</span><span style="color:#000000;">（毫秒），</span><span style="color:#000000;">dfs.heartbeat.interval</span><span style="color:#000000;">设置为</span><span style="color:#000000;">3</span><span style="color:#000000;">（秒，默认），则总的超时时间为</span><span style="color:#000000;">40</span><span style="color:#000000;">秒。</span></p>

<p style="margin-left:0cm;"> </p>

<table border="1" cellspacing="0" style="width:568px;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><span style="color:#000000;">&lt;property&gt;</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        &lt;name&gt;heartbeat.recheck.interval&lt;/name&gt;</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        &lt;value&gt;2000&lt;/value&gt;</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">&lt;/property&gt;</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">&lt;property&gt;</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        &lt;name&gt;dfs.heartbeat.interval&lt;/name&gt;</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">        &lt;value&gt;1&lt;/value&gt;</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">&lt;/property&gt;</span></p>
			</td>
		</tr></tbody></table><p style="margin-left:0cm;"> </p>

<h2 style="margin-left:0cm;"><strong><a name="_Toc439077232">6.2 </a>观察验证DATANODE功能</strong></h2>

<p style="margin-left:0cm;"><span style="color:#000000;">上传一个文件，观察文件的</span><span style="color:#000000;">block</span><span style="color:#000000;">具体的物理存放情况：</span></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><span style="color:#000000;">在每一台</span><span style="color:#000000;">datanode</span><span style="color:#000000;">机器上的这个目录中能找到文件的切块：</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">/home/hadoop/app/hadoop-2.4.1/tmp/dfs/data/current/BP-193442119-192.168.2.120-1432457733977/current/finalized</span></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<h1 style="margin-left:0cm;"><strong><a name="_Toc19633"></a><a name="_Toc27866"></a><a name="_Toc421731822"></a><a name="_Toc30634"></a><a name="_Toc30142"></a><a name="_Toc439077233"></a><a name="_Toc3826"><span style="color:#000000;">******HDFS</span></a><span style="color:#000000;">应用开发篇</span><span style="color:#000000;">******</span></strong></h1>

<h1 style="margin-left:0cm;"><strong><span style="color:#000000;">7. HDFS</span><span style="color:#000000;">的</span><span style="color:#000000;">java</span><span style="color:#000000;">操作</span></strong></h1>

<p style="margin-left:0cm;"><em>hdfs</em><em>在生产应用中主要是客户端的开发，其核心步骤是从hdfs</em><em>提供的api</em><em>中构造一个HDFS</em><em>的访问客户端对象，然后通过该客户端对象操作（增删改查）HDFS</em><em>上的文件</em></p>

<h2 style="margin-left:0cm;"><strong><a name="_Toc439077234">7.1 </a>搭建开发环境</strong></h2>

<p style="margin-left:0cm;">1、引入依赖</p>

<table cellspacing="0" style="width:331px;"><tbody><tr><td style="vertical-align:top;width:248.25pt;">
			<table border="1" cellspacing="0" style="width:330px;"><tbody><tr><td style="vertical-align:top;width:247.5pt;">
						<p style="margin-left:0cm;"><span style="color:#000000;">&lt;dependency&gt;</span></p>

						<p style="margin-left:0cm;"><span style="color:#000000;">    &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</span></p>

						<p style="margin-left:0cm;">    <span style="color:#000000;">&lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;</span></p>

						<p style="margin-left:0cm;"><span style="color:#000000;">    &lt;version&gt;2.</span><span style="color:#000000;">6</span><span style="color:#000000;">.1&lt;/version&gt;</span></p>

						<p style="margin-left:0cm;"><span style="color:#000000;">&lt;/dependency&gt;</span></p>
						</td>
					</tr></tbody></table><p style="margin-left:0cm;"> </p>
			</td>
		</tr></tbody></table><p style="margin-left:0cm;"><em><span style="color:#000000;">注：如需手动引入</span><span style="color:#000000;">jar</span></em><em><span style="color:#000000;">包，</span><span style="color:#000000;">hdfs</span></em><em><span style="color:#000000;">的</span><span style="color:#000000;">jar</span></em><em><span style="color:#000000;">包</span><span style="color:#000000;">----hadoop</span></em><em><span style="color:#000000;">的安装目录的</span><span style="color:#000000;">share</span></em><em><span style="color:#000000;">下</span></em></p>

<p style="margin-left:0cm;"><span style="color:#000000;">2</span><span style="color:#000000;">、</span><span style="color:#000000;">window</span><span style="color:#000000;">下开发的说明</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">建议在</span><span style="color:#000000;">linux</span><span style="color:#000000;">下进行</span><span style="color:#000000;">hadoop</span><span style="color:#000000;">应用的开发，不会存在兼容性问题。如在</span><span style="color:#000000;">window</span><span style="color:#000000;">上做客户端应用开发，需要设置以下环境：</span></p>

<ol><li><span style="color:#000000;">在</span><span style="color:#000000;">windows</span><span style="color:#000000;">的某个目录下解压一个</span><span style="color:#000000;">hadoop</span><span style="color:#000000;">的安装包</span></li>
	<li><span style="color:#000000;">将安装包下的</span><span style="color:#000000;">lib</span><span style="color:#000000;">和</span><span style="color:#000000;">bin</span><span style="color:#000000;">目录用对应</span><span style="color:#000000;">windows</span><span style="color:#000000;">版本平台编译的本地库替换</span></li>
	<li><span style="color:#000000;">在</span><span style="color:#000000;">window</span><span style="color:#000000;">系统中配置</span><span style="color:#000000;">HADOOP_HOME</span><span style="color:#000000;">指向你解压的安装包</span></li>
	<li><span style="color:#000000;">在</span><span style="color:#000000;">windows</span><span style="color:#000000;">系统的</span><span style="color:#000000;">path</span><span style="color:#000000;">变量中加入</span><span style="color:#000000;">hadoop</span><span style="color:#000000;">的</span><span style="color:#000000;">bin</span><span style="color:#000000;">目录</span></li>
</ol><h2 style="margin-left:0cm;"><strong><a name="_Toc439077235">7.2 </a>获取api中的客户端对象</strong></h2>

<p style="margin-left:0cm;"><span style="color:#000000;">在</span><span style="color:#000000;">java</span><span style="color:#000000;">中操作</span><span style="color:#000000;">hdfs</span><span style="color:#000000;">，首先要获得一个客户端实例</span></p>

<table border="1" cellspacing="0" style="width:568px;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><span style="color:#000000;">Configuration conf = new Configuration()</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">FileSystem fs = FileSystem.get(conf)</span></p>
			</td>
		</tr></tbody></table><p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><span style="color:#000000;">而我们的操作目标是</span><span style="color:#000000;">HDFS</span><span style="color:#000000;">，所以获取到的</span><span style="color:#000000;">fs</span><span style="color:#000000;">对象应该是</span><span style="color:#000000;">DistributedFileSystem</span><span style="color:#000000;">的实例；</span></p>

<p style="margin-left:0cm;"><span style="color:#000000;">get</span><span style="color:#000000;">方法是从何处判断具体实例化那种客户端类呢？</span></p>

<p style="margin-left:0cm;"><strong><span style="color:#000000;">——从</span><span style="color:#000000;">conf</span></strong><strong><span style="color:#000000;">中的一个参数</span><span style="color:#000000;"> fs.defaultFS</span></strong><strong><span style="color:#000000;">的配置值判断；</span></strong></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><span style="color:#000000;">如果我们的代码中没有指定</span><span style="color:#000000;">fs.defaultFS</span><span style="color:#000000;">，并且工程</span><span style="color:#000000;">classpath</span><span style="color:#000000;">下也没有给定相应的配置，</span><span style="color:#000000;">conf</span><span style="color:#000000;">中的默认值就来自于</span><span style="color:#000000;">hadoop</span><span style="color:#000000;">的</span><span style="color:#000000;">jar</span><span style="color:#000000;">包中的</span><span style="color:#000000;">core-default.xml</span><span style="color:#000000;">，默认值为：</span> <span style="color:#0000FF;"><u><span style="color:#000000;">file:///</span></u></span><span style="color:#000000;">，则获取的将不是一个</span><span style="color:#000000;">DistributedFileSystem</span><span style="color:#000000;">的实例，而是一个本地文件系统的客户端对象</span></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<h2 style="margin-left:0cm;"><strong><a name="_Toc439077236"><span style="color:#000000;">7.3 DistributedFileSystem</span></a><span style="color:#000000;">实例</span>对象所具备的方法</strong></h2>

<p style="margin-left:0cm;"><span style="color:#000000;"></span></p>

<h2 style="margin-left:0cm;"><strong><a name="_Toc439077237">7.4 HDFS</a>客户端操作数据代码示例：</strong></h2>

<h3 style="margin-left:0cm;"><strong><a name="_Toc439077238">7.4.1 </a>文件的增删改查</strong></h3>

<table border="1" cellspacing="0" style="width:568px;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><span style="color:#000000;">public class HdfsClient {</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          FileSystem fs = null;</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          @Before</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          public void init() throws Exception {</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     // </span><span style="color:#000000;">构造一个配置参数对象，设置一个参数：我们要访问的</span><span style="color:#000000;">hdfs</span><span style="color:#000000;">的</span><span style="color:#000000;">URI</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     // </span><span style="color:#000000;">从而</span><span style="color:#000000;">FileSystem.get()</span><span style="color:#000000;">方法就知道应该是去构造一个访问</span><span style="color:#000000;">hdfs</span><span style="color:#000000;">文件系统的客户端，以及</span><span style="color:#000000;">hdfs</span><span style="color:#000000;">的访问地址</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     // new Configuration();</span><span style="color:#000000;">的时候，它就会去加载</span><span style="color:#000000;">jar</span><span style="color:#000000;">包中的</span><span style="color:#000000;">hdfs-default.xml</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     // </span><span style="color:#000000;">然后再加载</span><span style="color:#000000;">classpath</span><span style="color:#000000;">下的</span><span style="color:#000000;">hdfs-site.xml</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     Configuration conf = new Configuration();</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     conf.set("fs.defaultFS", "hdfs://hdp-node01:9000");</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     /**</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                      * </span><span style="color:#000000;">参数优先级：</span><span style="color:#000000;"> 1</span><span style="color:#000000;">、客户端代码中设置的值</span><span style="color:#000000;"> 2</span><span style="color:#000000;">、</span><span style="color:#000000;">classpath</span><span style="color:#000000;">下的用户自定义配置文件</span><span style="color:#000000;"> 3</span><span style="color:#000000;">、然后是服务器的默认配置</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                      */</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     conf.set("dfs.replication", "3");</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     // </span><span style="color:#000000;">获取一个</span><span style="color:#000000;">hdfs</span><span style="color:#000000;">的访问客户端，根据参数，这个实例应该是</span><span style="color:#000000;">DistributedFileSystem</span><span style="color:#000000;">的实例</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     // fs = FileSystem.get(conf);</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     // </span><span style="color:#000000;">如果这样去获取，那</span><span style="color:#000000;">conf</span><span style="color:#000000;">里面就可以不要配</span><span style="color:#000000;">"fs.defaultFS"</span><span style="color:#000000;">参数，而且，这个客户端的身份标识已经是</span><span style="color:#000000;">hadoop</span><span style="color:#000000;">用户</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     fs = FileSystem.get(new URI("hdfs://hdp-node01:9000"), conf, "hadoop");</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          }</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          /**</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * </span><span style="color:#000000;">往</span><span style="color:#000000;">hdfs</span><span style="color:#000000;">上传文件</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * </span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * @throws Exception</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           */</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          @Test</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          public void testAddFileToHdfs() throws Exception {</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     // </span><span style="color:#000000;">要上传的文件所在的本地路径</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     Path src = new Path("g:/redis-recommend.zip");</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     // </span><span style="color:#000000;">要上传到</span><span style="color:#000000;">hdfs</span><span style="color:#000000;">的目标路径</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     Path dst = new Path("/aaa");</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     fs.copyFromLocalFile(src, dst);</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     fs.close();</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          }</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          /**</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * </span><span style="color:#000000;">从</span><span style="color:#000000;">hdfs</span><span style="color:#000000;">中复制文件到本地文件系统</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * </span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * @throws IOException</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * @throws IllegalArgumentException</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           */</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          @Test</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          public void testDownloadFileToLocal() throws IllegalArgumentException, IOException {</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     fs.copyToLocalFile(new Path("/jdk-7u65-linux-i586.tar.gz"), new Path("d:/"));</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     fs.close();</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          }</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          @Test</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          public void testMkdirAndDeleteAndRename() throws IllegalArgumentException, IOException {</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     // </span><span style="color:#000000;">创建目录</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     fs.mkdirs(new Path("/a1/b1/c1"));</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     // </span><span style="color:#000000;">删除文件夹</span> <span style="color:#000000;">，如果是非空文件夹，参数</span><span style="color:#000000;">2</span><span style="color:#000000;">必须给值</span><span style="color:#000000;">true</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     fs.delete(new Path("/aaa"), true);</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     // </span><span style="color:#000000;">重命名文件或文件夹</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     fs.rename(new Path("/a1"), new Path("/a2"));</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          }</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          /**</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * </span><span style="color:#000000;">查看目录信息，只显示文件</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * </span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * @throws IOException</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * @throws IllegalArgumentException</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * @throws FileNotFoundException</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           */</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          @Test</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          public void testListFiles() throws FileNotFoundException, IllegalArgumentException, IOException {</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     // </span><span style="color:#000000;">思考：为什么返回迭代器，而不是</span><span style="color:#000000;">List</span><span style="color:#000000;">之类的容器</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(new Path("/"), true);</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     while (listFiles.hasNext()) {</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                               LocatedFileStatus fileStatus = listFiles.next();</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                               System.out.println(fileStatus.getPath().getName());</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                               System.out.println(fileStatus.getBlockSize());</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                               System.out.println(fileStatus.getPermission());</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                               System.out.println(fileStatus.getLen());</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                               BlockLocation[] blockLocations = fileStatus.getBlockLocations();</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                               for (BlockLocation bl : blockLocations) {</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                                         System.out.println("block-length:" + bl.getLength() + "--" + "block-offset:" + bl.getOffset());</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                                         String[] hosts = bl.getHosts();</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                                         for (String host : hosts) {</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                                                    System.out.println(host);</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                                         }</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                               }</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                               System.out.println("--------------</span><span style="color:#000000;">为</span><span style="color:#000000;">angelababy</span><span style="color:#000000;">打印的分割线</span><span style="color:#000000;">--------------");</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     }</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          }</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          /**</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * </span><span style="color:#000000;">查看文件及文件夹信息</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * </span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * @throws IOException</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * @throws IllegalArgumentException</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           * @throws FileNotFoundException</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">           */</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          @Test</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          public void testListAll() throws FileNotFoundException, IllegalArgumentException, IOException {</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     FileStatus[] listStatus = fs.listStatus(new Path("/"));</span></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     String flag = "d--             ";</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     for (FileStatus fstatus : listStatus) {</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                               if (fstatus.isFile())  flag = "f--         ";</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                               System.out.println(flag + fstatus.getPath().getName());</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">                     }</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">          }</span></p>

			<p style="margin-left:0cm;"><span style="color:#000000;">}</span></p>
			</td>
		</tr></tbody></table><p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<h3 style="margin-left:0cm;"><strong><a name="_Toc439077239">7.4.2 </a>通过流的方式访问hdfs</strong></h3>

<table border="1" cellspacing="0" style="width:568px;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><em><span style="color:#000000;">/**</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;"> * </span></em><em><span style="color:#000000;">相对那些封装好的方法而言的更底层一些的操作方式</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;"> * </span></em><em><span style="color:#000000;">上层那些</span></em><em><span style="color:#000000;">mapreduce   spark</span></em><em><span style="color:#000000;">等运算框架，去</span></em><em><span style="color:#000000;">hdfs</span></em><em><span style="color:#000000;">中获取数据的时候，就是调的这种底层的</span></em><em><span style="color:#000000;">api</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;"> * @author</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;"> *</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;"> */</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">public class StreamAccess {</span></em></p>

			<p style="margin-left:0cm;"><em>          </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          FileSystem fs = null;</span></em></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          @Before</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          public void init() throws Exception {</span></em></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     Configuration conf = new Configuration();</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     fs = FileSystem.get(new URI("hdfs://hdp-node01:9000"), conf, "hadoop");</span></em></p>

			<p style="margin-left:0cm;"> </p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          }</span></em></p>

			<p style="margin-left:0cm;"><em>          </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                    /**</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">           * </span></em><em><span style="color:#000000;">通过流的方式上传文件到</span></em><em><span style="color:#000000;">hdfs</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">           * @throws Exception</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">           */</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          @Test</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          public void testUpload() throws Exception {</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     FSDataOutputStream outputStream = fs.create(new Path("/angelababy.love"), true);</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     FileInputStream inputStream = new FileInputStream("c:/angelababy.love");</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     IOUtils.copy(inputStream, outputStream);</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          }</span></em></p>

			<p style="margin-left:0cm;"><em>          </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          @Test</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          public void testDownLoadFileToLocal() throws IllegalArgumentException, IOException{</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     //</span></em><em><span style="color:#000000;">先获取一个文件的输入流</span></em><em><span style="color:#000000;">----</span></em><em><span style="color:#000000;">针对</span></em><em><span style="color:#000000;">hdfs</span></em><em><span style="color:#000000;">上的</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     FSDataInputStream in = fs.open(new Path("/jdk-7u65-linux-i586.tar.gz"));</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     //</span></em><em><span style="color:#000000;">再构造一个文件的输出流</span></em><em><span style="color:#000000;">----</span></em><em><span style="color:#000000;">针对本地的</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     FileOutputStream out = new FileOutputStream(new File("c:/jdk.tar.gz"));</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     //</span></em><em><span style="color:#000000;">再将输入流中数据传输到输出流</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     IOUtils.copyBytes(in, out, 4096);</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          }</span></em></p>

			<p style="margin-left:0cm;"><em>          </em></p>

			<p style="margin-left:0cm;"><em>          </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          /**</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">           * hdfs</span></em><em><span style="color:#000000;">支持随机定位进行文件读取，而且可以方便地读取指定长度</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">           * </span></em><em><span style="color:#000000;">用于上层分布式运算框架并发处理数据</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">           * @throws IllegalArgumentException</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">           * @throws IOException</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">           */</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          @Test</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          public void testRandomAccess() throws IllegalArgumentException, IOException{</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     //</span></em><em><span style="color:#000000;">先获取一个文件的输入流</span></em><em><span style="color:#000000;">----</span></em><em><span style="color:#000000;">针对</span></em><em><span style="color:#000000;">hdfs</span></em><em><span style="color:#000000;">上的</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     FSDataInputStream in = fs.open(new Path("/iloveyou.txt"));</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     //</span></em><em><span style="color:#000000;">可以将流的起始偏移量进行自定义</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     in.seek(22);</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     //</span></em><em><span style="color:#000000;">再构造一个文件的输出流</span></em><em><span style="color:#000000;">----</span></em><em><span style="color:#000000;">针对本地的</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     FileOutputStream out = new FileOutputStream(new File("c:/iloveyou.line.2.txt"));</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     IOUtils.copyBytes(in,out,19L,true);</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          }</span></em></p>

			<p style="margin-left:0cm;"><em>          </em></p>

			<p style="margin-left:0cm;"><em>          </em></p>

			<p style="margin-left:0cm;"><em>          </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          /**</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">           * </span></em><em><span style="color:#000000;">显示</span></em><em><span style="color:#000000;">hdfs</span></em><em><span style="color:#000000;">上文件的内容</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">           * @throws IOException </span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">           * @throws IllegalArgumentException </span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">           */</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          @Test</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          public void testCat() throws IllegalArgumentException, IOException{</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     FSDataInputStream in = fs.open(new Path("/iloveyou.txt"));</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     IOUtils.copyBytes(in, System.out, 1024);</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          }</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">}</span></em></p>
			</td>
		</tr></tbody></table><p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<h3 style="margin-left:0cm;"><strong>7.4.3 场景编程</strong></h3>

<p style="margin-left:0cm;">在mapreduce 、spark等运算框架中，有一个核心思想就是将运算移往数据，或者说，就是要在并发计算中尽可能让运算本地化，这就需要获取数据所在位置的信息并进行相应范围读取</p>

<p style="margin-left:0cm;">以下模拟实现：获取一个文件的所有block位置信息，然后读取指定block中的内容</p>

<table border="1" cellspacing="0" style="width:568px;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><em><span style="color:#000000;">          @Test</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          public void testCat() throws IllegalArgumentException, IOException{</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     FSDataInputStream in = fs.open(new Path("/weblog/input/access.log.10"));</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     //</span></em><em><span style="color:#000000;">拿到文件信息</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     FileStatus[] listStatus = fs.listStatus(new Path("/weblog/input/access.log.10"));</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     //</span></em><em><span style="color:#000000;">获取这个文件的所有</span></em><em><span style="color:#000000;">block</span></em><em><span style="color:#000000;">的信息</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     BlockLocation[] fileBlockLocations = fs.getFileBlockLocations(listStatus[0], 0L, listStatus[0].getLen());</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     //</span></em><em><span style="color:#000000;">第一个</span></em><em><span style="color:#000000;">block</span></em><em><span style="color:#000000;">的长度</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     long length = fileBlockLocations[0].getLength();</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     //</span></em><em><span style="color:#000000;">第一个</span></em><em><span style="color:#000000;">block</span></em><em><span style="color:#000000;">的起始偏移量</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     long offset = fileBlockLocations[0].getOffset();</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     System.out.println(length);</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     System.out.println(offset);</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     //</span></em><em><span style="color:#000000;">获取第一个</span></em><em><span style="color:#000000;">block</span></em><em><span style="color:#000000;">写入输出流</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">//                 IOUtils.copyBytes(in, System.out, (int)length);</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     byte[] b = new byte[4096];</span></em></p>

			<p style="margin-left:0cm;"><em>                     </em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     FileOutputStream os = new FileOutputStream(new File("d:/block0"));</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     while(in.read(offset, b, 0, 4096)!=-1){</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                               os.write(b);</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                               offset += 4096;</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                               if(offset&gt;=length) return;</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     };</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     os.flush();</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     os.close();</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">                     in.close();</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#000000;">          }</span></em></p>
			</td>
		</tr></tbody></table><p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<h1 style="margin-left:0cm;"><strong>8. 案例1：开发shell采集脚本</strong></h1>

<h2 style="margin-left:0cm;"><strong>8.1需求说明</strong></h2>

<p style="margin-left:0cm;">点击流日志每天都10T，在业务应用服务器上，需要准实时上传至数据仓库（Hadoop HDFS）上</p>

<h2 style="margin-left:0cm;"><strong>8.2需求分析</strong></h2>

<p style="margin-left:0cm;">一般上传文件都是在凌晨24点操作，由于很多种类的业务数据都要在晚上进行传输，为了减轻服务器的压力<strong>，避开高峰期</strong>。</p>

<p style="margin-left:0cm;">如果需要伪实时的上传，则采用定时上传的方式</p>

<p style="margin-left:0cm;">         </p>

<h2 style="margin-left:0cm;"><strong>8.3技术分析</strong></h2>

<p style="margin-left:0cm;">           <strong>HDFS SHELL</strong>:  hadoop fs  –put   xxxx.tar  /data    还可以使用 Java Api</p>

<p style="margin-left:0cm;">                             满足上传一个文件，不能满足定时、周期性传入。</p>

<p style="margin-left:0cm;">           <strong>定时调度器</strong>：</p>

<p style="margin-left:0cm;">                     <strong>Linux crontab</strong></p>

<p style="margin-left:0cm;">                     crontab -e</p>

<p style="margin-left:0cm;">*/5 * * * * $home/bin/command.sh   //五分钟执行一次</p>

<p style="margin-left:0cm;">系统会自动执行脚本，每5分钟一次，执行时判断文件是否符合上传规则，符合则上传</p>

<h2 style="margin-left:0cm;"><strong>8.4实现流程</strong></h2>

<h3 style="margin-left:0cm;"><strong>8.4.1日志产生程序</strong></h3>

<p style="margin-left:0cm;">日志产生程序将日志生成后，产生一个一个的文件，使用滚动模式创建文件名。</p>

<p style="margin-left:18pt;"></p>

<p style="margin-left:18pt;">日志生成的逻辑由业务系统决定，比如在log4j配置文件中配置生成规则，如：当xxxx.log 等于10G时，滚动生成新日志</p>

<table border="1" cellspacing="0" style="width:568px;"><tbody><tr><td style="vertical-align:top;width:426.1pt;">
			<p style="margin-left:0cm;"><em>          </em><em><span style="color:#333333;">log4j.logger.msg=info,msg</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#333333;">log4j.appender.msg=cn.maoxiangyi.MyRollingFileAppender</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#333333;">log4j.appender.msg.layout=org.apache.log4j.PatternLayout</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#333333;">log4j.appender.msg.layout.ConversionPattern=%m%n</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#333333;">log4j.appender.msg.datePattern='.'yyyy-MM-dd</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#333333;">log4j.appender.msg.Threshold=info</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#333333;">log4j.appender.msg.append=true</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#333333;">log4j.appender.msg.encoding=UTF-8</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#333333;">log4j.appender.msg.MaxBackupIndex=100</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#333333;">log4j.appender.msg.MaxFileSize=10GB</span></em></p>

			<p style="margin-left:0cm;"><em><span style="color:#333333;">log4j.appender.msg.File=/home/hadoop/logs/log/access.log</span></em></p>
			</td>
		</tr></tbody></table><p style="margin-left:18pt;"> </p>

<p style="margin-left:18pt;">细节：</p>

<ol><li>如果日志文件后缀是1\2\3等数字，该文件满足需求可以上传的话。把该文件移动到准备上传的工作区间。</li>
	<li>工作区间有文件之后，可以使用hadoop put命令将文件上传。</li>
</ol><p style="margin-left:21pt;">阶段问题：</p>

<ol><li>待上传文件的工作区间的文件，在上传完成之后，是否需要删除掉。</li>
</ol><h3 style="margin-left:0cm;"><strong>8.4.2伪代码</strong></h3>

<p style="margin-left:0cm;">          使用ls命令读取指定路径下的所有文件信息，</p>

<p style="margin-left:0cm;">          ls  | while read  line</p>

<p style="margin-left:0cm;">           //判断line这个文件名称是否符合规则</p>

<p style="margin-left:0cm;">if        line=access.log.* (</p>

<p style="margin-left:0cm;">             将文件移动到待上传的工作区间</p>

<p style="margin-left:0cm;">   )</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">//批量上传工作区间的文件</p>

<p style="margin-left:0cm;">hadoop fs  –put   xxx</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">  </p>

<p style="margin-left:0cm;"><strong><span style="color:#FF0000;">脚本写完之后</span></strong>，配置linux定时任务，每5分钟运行一次。</p>

<p style="margin-left:0cm;">         </p>

<h2 style="margin-left:0cm;"><strong>8.5代码实现</strong></h2>

<p style="margin-left:0cm;">代码第一版本，实现基本的上传功能和定时调度功能</p>

<p style="margin-left:0cm;"></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">代码第二版本：增强版V2(基本能用，还是不够健全)</p>

<p style="margin-left:0cm;"></p>

<p style="margin-left:0cm;"></p>

<h2 style="margin-left:0cm;"><strong>8.6效果展示及操作步骤</strong></h2>

<p style="margin-left:0cm;">1、日志收集文件收集数据，并将数据保存起来，效果如下：</p>

<p style="margin-left:0cm;">          </p>

<p style="margin-left:0cm;">2、上传程序通过crontab定时调度</p>

<p style="margin-left:0cm;"></p>

<p style="margin-left:0cm;">3、程序运行时产生的临时文件</p>

<p style="margin-left:0cm;"></p>

<p style="margin-left:0cm;">4、Hadoo hdfs上的效果</p>

<p style="margin-left:0cm;"></p>

<p style="margin-left:0cm;"> </p>

<h1 style="margin-left:0cm;"><strong>9. 案例2：开发JAVA采集程序</strong></h1>

<h2 style="margin-left:0cm;"><strong>9.1 需求</strong></h2>

<p style="margin-left:0cm;">从外部购买数据，数据提供方会实时将数据推送到6台FTP服务器上，我方部署6台接口采集机来对接采集数据，并上传到HDFS中</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">提供商在FTP上生成数据的规则是以小时为单位建立文件夹(2016-03-11-10)，每分钟生成一个文件（00.dat,01.data,02.dat,........）</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">提供方不提供数据备份，推送到FTP服务器的数据如果丢失，不再重新提供，且FTP服务器磁盘空间有限，最多存储最近10小时内的数据</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">由于每一个文件比较小，只有150M左右，因此，我方在上传到HDFS过程中，需要将15分钟时段的数据合并成一个文件上传到HDFS</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">为了区分数据丢失的责任，我方在下载数据时最好进行校验</p>

<h2 style="margin-left:0cm;"><strong>9.2 设计分析</strong></h2>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>            </div>
                </div>