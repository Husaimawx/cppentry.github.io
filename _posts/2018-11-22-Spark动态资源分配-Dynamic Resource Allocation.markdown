---
layout:     post
title:      Spark动态资源分配-Dynamic Resource Allocation
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<h1 class="article-title" style="line-height:35px;"><a href="http://lxw1234.com/archives/2015/12/593.htm" rel="nofollow" style="line-height:60px;color:rgb(68,68,68);font-size:24px;font-weight:normal;text-decoration:none;">Spark动态资源分配-Dynamic
 Resource Allocation</a></h1>
<div class="meta"><span id="mute-category" class="muted" style="color:#999999;"><em class="fa fa-list-alt"></em><a href="http://lxw1234.com/archives/category/spark" rel="nofollow" style="color:rgb(0,166,124);text-decoration:none;"><span> </span>Spark</a></span>
<span class="muted" style="color:#999999;"><em class="fa fa-user"></em><span> </span><a href="http://lxw1234.com/archives/author/lxw1234qq-com" rel="nofollow" style="color:rgb(0,166,124);text-decoration:none;">lxw1234@qq.com</a></span><span> </span><em class="fa fa-clock-o"></em><span> </span>2个月前
 (12-31)<span> </span><span class="muted" style="color:#999999;"><em class="fa fa-eye"></em><span> </span>1429℃</span><span> </span><span class="muted" style="color:#999999;"><em class="fa fa-comments-o"></em><span> </span><a href="http://lxw1234.com/archives/2015/12/593.htm#comments" rel="nofollow" style="color:rgb(0,166,124);text-decoration:none;">2评论</a></span></div>
<p>关键字：spark、资源分配、dynamic resource allocation</p>
<p>Spark中，所谓资源单位一般指的是executors，和Yarn中的Containers一样，在Spark On Yarn模式下，通常使用–num-executors来指定Application使用的executors数量，而–executor-memory和–executor-cores分别用来指定每个executor所使用的内存和虚拟CPU核数。相信很多朋友至今在提交Spark应用程序时候都使用该方式来指定资源。</p>
<p>假设有这样的场景，如果使用Hive，多个用户同时使用hive-cli做数据开发和分析，只有当用户提交执行了Hive SQL时候，才会向YARN申请资源，执行任务，如果不提交执行，无非就是停留在Hive-cli命令行，也就是个JVM而已，并不会浪费YARN的资源。现在想用Spark-SQL代替Hive来做数据开发和分析，也是多用户同时使用，如果按照之前的方式，以yarn-client模式运行spark-sql命令行（<a title="" href="http://lxw1234.com/archives/2015/08/448.htm" rel="nofollow" style="color:rgb(0,166,124);text-decoration:none;">http://lxw1234.com/archives/2015/08/448.htm</a>），在启动时候指定–num-executors
 10，那么每个用户启动时候都使用了10个YARN的资源（Container），这10个资源就会一直被占用着，只有当用户退出spark-sql命令行时才会释放。</p>
<p>spark-sql On Yarn，能不能像Hive一样，执行SQL的时候才去申请资源，不执行的时候就释放掉资源呢，其实从Spark1.2之后，对于On Yarn模式，已经支持动态资源分配（Dynamic Resource Allocation），这样，就可以根据Application的负载（Task情况），动态的增加和减少executors，这种策略非常适合在YARN上使用spark-sql做数据开发和分析，以及将spark-sql作为长服务来使用的场景。</p>
<p>本文以Spark1.5.0和hadoop-2.3.0-cdh5.0.0，介绍在spark-sql On Yarn模式下，如何使用动态资源分配策略。</p>
<h2 style="border-left:rgb(0,166,124) 4px solid;line-height:18px;background-color:rgb(251,251,251);font-size:18px;">
YARN的配置</h2>
<p>首先需要对YARN的NodeManager进行配置，使其支持Spark的Shuffle Service。</p>
<ul style="list-style-type:none;"><li style="line-height:30px;text-indent:0px;">修改每台NodeManager上的yarn-site.xml：</li></ul><p>##修改<br>
&lt;property&gt;<br>
&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;<br>
&lt;value&gt;mapreduce_shuffle,<span><strong style="font-weight:bold;">spark_shuffle</strong></span>&lt;/value&gt;<br>
&lt;/property&gt;<br>
##增加<br>
&lt;property&gt;<br>
&lt;name&gt;<span>yarn.nodemanager.aux-services.spark_shuffle.class</span>&lt;/name&gt;<br>
&lt;value&gt;org.apache.spark.network.yarn.YarnShuffleService&lt;/value&gt;<br>
&lt;/property&gt;<br>
&lt;property&gt;<br>
&lt;name&gt;<span>spark.shuffle.service.port</span>&lt;/name&gt;<br>
&lt;value&gt;7337&lt;/value&gt;<br>
&lt;/property&gt;</p>
<ul style="list-style-type:none;"><li style="line-height:30px;text-indent:0px;">将$SPARK_HOME/lib/spark-1.5.0-yarn-shuffle.jar拷贝到每台NodeManager的${HADOOP_HOME}/share/hadoop/yarn/lib/下。</li><li style="line-height:30px;text-indent:0px;">重启所有NodeManager。</li></ul><h2 style="border-left:rgb(0,166,124) 4px solid;line-height:18px;background-color:rgb(251,251,251);font-size:18px;">
Spark的配置</h2>
<p>配置$SPARK_HOME/conf/spark-defaults.conf，增加以下参数：</p>
<pre class="prettyprint linenums" style="border-bottom:rgb(238,238,238) 1px solid;border-left:rgb(238,238,238) 1px solid;line-height:20px;background-color:rgb(248,248,248);display:block;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;color:rgb(68,68,68);font-size:14px;overflow:hidden;border-top:rgb(238,238,238) 1px solid;border-right:rgb(238,238,238) 1px solid;"></pre><ol class="linenums" style="list-style-type:none;"><li class="L0" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pln">spark</span><span class="pun">.</span><span class="pln">shuffle</span><span class="pun">.</span><span class="pln">service</span><span class="pun">.</span><span class="pln">enabled </span><span class="kwd" style="color:#f92659;">true</span><span class="pln">   </span><span class="com" style="color:#666666;">//启用External shuffle Service服务</span></li><li class="L1" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pln">spark</span><span class="pun">.</span><span class="pln">shuffle</span><span class="pun">.</span><span class="pln">service</span><span class="pun">.</span><span class="pln">port </span><span class="lit">7337</span><span class="pln"> </span><span class="com" style="color:#666666;">//Shuffle Service服务端口，必须和yarn-site中的一致</span></li><li class="L2" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pln">spark</span><span class="pun">.</span><span class="pln">dynamicAllocation</span><span class="pun">.</span><span class="pln">enabled </span><span class="kwd" style="color:#f92659;">true</span><span class="pln">  </span><span class="com" style="color:#666666;">//开启动态资源分配</span></li><li class="L3" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pln">spark</span><span class="pun">.</span><span class="pln">dynamicAllocation</span><span class="pun">.</span><span class="pln">minExecutors </span><span class="lit">1</span><span class="pln">  </span><span class="com" style="color:#666666;">//每个Application最小分配的executor数</span></li><li class="L4" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pln">spark</span><span class="pun">.</span><span class="pln">dynamicAllocation</span><span class="pun">.</span><span class="pln">maxExecutors </span><span class="lit">30</span><span class="pln">  </span><span class="com" style="color:#666666;">//每个Application最大并发分配的executor数</span></li><li class="L5" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pln">spark</span><span class="pun">.</span><span class="pln">dynamicAllocation</span><span class="pun">.</span><span class="pln">schedulerBacklogTimeout </span><span class="lit">1s</span><span class="pln"> </span></li><li class="L6" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pln">spark</span><span class="pun">.</span><span class="pln">dynamicAllocation</span><span class="pun">.</span><span class="pln">sustainedSchedulerBacklogTimeout </span><span class="lit">5s</span></li></ol>
<ul style="list-style-type:none;"><li style="line-height:30px;text-indent:0px;">动态资源分配策略：</li></ul><p>开启动态分配策略后，application会在task因没有足够资源被挂起的时候去动态申请资源，这种情况意味着该application现有的executor无法满足所有task并行运行。spark一轮一轮的申请资源，当有task挂起或等待spark.dynamicAllocation.schedulerBacklogTimeout(默认1s)时间的时候，会开始动态资源分配；之后会每隔spark.dynamicAllocation.sustainedSchedulerBacklogTimeout(默认1s)时间申请一次，直到申请到足够的资源。每次申请的资源量是指数增长的，即1,2,4,8等。<br>
之所以采用指数增长，出于两方面考虑：其一，开始申请的少是考虑到可能application会马上得到满足；其次要成倍增加，是为了防止application需要很多资源，而该方式可以在很少次数的申请之后得到满足。</p>
<ul style="list-style-type:none;"><li style="line-height:30px;text-indent:0px;">资源回收策略</li></ul><p>当application的executor空闲时间超过spark.dynamicAllocation.executorIdleTimeout（默认60s）后，就会被回收。</p>
<h2 style="border-left:rgb(0,166,124) 4px solid;line-height:18px;background-color:rgb(251,251,251);font-size:18px;">
使用spark-sql On Yarn执行SQL，动态分配资源</h2>
<pre class="prettyprint linenums" style="border-bottom:rgb(238,238,238) 1px solid;border-left:rgb(238,238,238) 1px solid;line-height:20px;background-color:rgb(248,248,248);display:block;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;color:rgb(68,68,68);font-size:14px;overflow:hidden;border-top:rgb(238,238,238) 1px solid;border-right:rgb(238,238,238) 1px solid;"></pre><ol class="linenums" style="list-style-type:none;"><li class="L0" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pun">./</span><span class="pln">spark</span><span class="pun">-</span><span class="pln">sql </span><span class="pun">--</span><span class="pln">master yarn</span><span class="pun">-</span><span class="pln">client \</span></li><li class="L1" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pun">--</span><span class="pln">executor</span><span class="pun">-</span><span class="pln">memory </span><span class="lit">1G</span><span class="pln"> \</span></li><li class="L2" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pun">-</span><span class="pln">e </span><span class="str" style="color:#c28f5b;">"SELECT COUNT(1) FROM ut.t_ut_site_log where pt &gt;= '2015-12-09' and pt &lt;= '2015-12-10'"</span></li></ol>
<p><img class="aligncenter" alt="spark" src="http://7xipth.com1.z0.glb.clouddn.com/1230-1.jpg" width="714" height="174" style="border-bottom:0px;text-align:center;border-left:0px;display:block;vertical-align:middle;border-top:0px;border-right:0px;"></p>
<p>该查询需要123个Task。</p>
<p><img class="aligncenter" alt="spark" src="http://7xipth.com1.z0.glb.clouddn.com/1230-2.jpg" width="771" height="429" style="border-bottom:0px;text-align:center;border-left:0px;display:block;vertical-align:middle;border-top:0px;border-right:0px;"></p>
<p>从AppMaster的WEB界面可以看到，总共有31个Executors，其中一个是Driver，既有30个Executors并发执行，而30，正是在spark.dynamicAllocation.maxExecutors参数中配置的最大并发数。如果一个查询只有10个Task，那么只会向Yarn申请10个executors的资源。</p>
<p><strong style="font-weight:bold;"><span>需要注意：</span></strong><br>
如果使用<br>
./spark-sql –master yarn-client –executor-memory 1G<br>
进入spark-sql命令行，在命令行中执行任何SQL查询，都不会执行，原因是spark-sql在提交到Yarn时候，已经被当成一个Application，而这种，除了Driver，是不会被分配到任何executors资源的，所有，你提交的查询因为没有executor而不能被执行。</p>
<p>而这个问题，我使用Spark的ThriftServer（HiveServer2）得以解决。</p>
<h2 style="border-left:rgb(0,166,124) 4px solid;line-height:18px;background-color:rgb(251,251,251);font-size:18px;">
使用Thrift JDBC方式执行SQL，动态分配资源</h2>
<p>首选以yarn-client模式，启动Spark的ThriftServer服务，也就是HiveServer2.</p>
<ul style="list-style-type:none;"><li style="line-height:30px;text-indent:0px;">配置ThriftServer监听的端口号和地址</li></ul><pre class="prettyprint linenums" style="border-bottom:rgb(238,238,238) 1px solid;border-left:rgb(238,238,238) 1px solid;line-height:20px;background-color:rgb(248,248,248);display:block;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;color:rgb(68,68,68);font-size:14px;overflow:hidden;border-top:rgb(238,238,238) 1px solid;border-right:rgb(238,238,238) 1px solid;"></pre><ol class="linenums" style="list-style-type:none;"><li class="L0" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pln">vi $SPARK_HOME</span><span class="pun">/</span><span class="pln">conf</span><span class="pun">/</span><span class="pln">spark</span><span class="pun">-</span><span class="pln">env</span><span class="pun">.</span><span class="pln">sh</span></li><li class="L1" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="kwd" style="color:#f92659;">export</span><span class="pln"> HIVE_SERVER2_THRIFT_PORT</span><span class="pun">=</span><span class="lit">10000</span></li><li class="L2" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="kwd" style="color:#f92659;">export</span><span class="pln"> HIVE_SERVER2_THRIFT_BIND_HOST</span><span class="pun">=</span><span class="lit">0.0</span><span class="pun">.</span><span class="lit">0.0</span></li></ol>
<ul style="list-style-type:none;"><li style="line-height:30px;text-indent:0px;">以yarn-client模式启动ThriftServer</li></ul><pre class="prettyprint linenums" style="border-bottom:rgb(238,238,238) 1px solid;border-left:rgb(238,238,238) 1px solid;line-height:20px;background-color:rgb(248,248,248);display:block;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;color:rgb(68,68,68);font-size:14px;overflow:hidden;border-top:rgb(238,238,238) 1px solid;border-right:rgb(238,238,238) 1px solid;"></pre><ol class="linenums" style="list-style-type:none;"><li class="L0" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pln">cd $SPARK_HOME</span><span class="pun">/</span><span class="pln">sbin</span><span class="pun">/</span></li><li class="L1" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pun">./</span><span class="pln">start</span><span class="pun">-</span><span class="pln">thriftserver</span><span class="pun">.</span><span class="pln">sh \</span></li><li class="L2" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pun">--</span><span class="pln">master yarn</span><span class="pun">-</span><span class="pln">client \</span></li><li class="L3" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pun">--</span><span class="pln">conf spark</span><span class="pun">.</span><span class="pln">driver</span><span class="pun">.</span><span class="pln">memory</span><span class="pun">=</span><span class="lit">3G</span><span class="pln"> \</span></li><li class="L4" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pun">--</span><span class="pln">conf spark</span><span class="pun">.</span><span class="pln">shuffle</span><span class="pun">.</span><span class="pln">service</span><span class="pun">.</span><span class="pln">enabled</span><span class="pun">=</span><span class="kwd" style="color:#f92659;">true</span><span class="pln"> \</span></li><li class="L5" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pun">--</span><span class="pln">conf spark</span><span class="pun">.</span><span class="pln">dynamicAllocation</span><span class="pun">.</span><span class="pln">enabled</span><span class="pun">=</span><span class="kwd" style="color:#f92659;">true</span><span class="pln"> \</span></li><li class="L6" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pun">--</span><span class="pln">conf spark</span><span class="pun">.</span><span class="pln">dynamicAllocation</span><span class="pun">.</span><span class="pln">minExecutors</span><span class="pun">=</span><span class="lit">1</span><span class="pln"> \</span></li><li class="L7" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pun">--</span><span class="pln">conf spark</span><span class="pun">.</span><span class="pln">dynamicAllocation</span><span class="pun">.</span><span class="pln">maxExecutors</span><span class="pun">=</span><span class="lit">30</span><span class="pln"> \</span></li><li class="L8" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pun">--</span><span class="pln">conf spark</span><span class="pun">.</span><span class="pln">dynamicAllocation</span><span class="pun">.</span><span class="pln">sustainedSchedulerBacklogTimeout</span><span class="pun">=</span><span class="lit">5s</span></li></ol>
<p>启动后，ThriftServer会在Yarn上作为一个长服务来运行：</p>
<p><img class="aligncenter" alt="spark" src="http://7xipth.com1.z0.glb.clouddn.com/1230-3.jpg" width="733" height="145" style="border-bottom:0px;text-align:center;border-left:0px;display:block;vertical-align:middle;border-top:0px;border-right:0px;"></p>
<ul style="list-style-type:none;"><li style="line-height:30px;text-indent:0px;">使用beeline通过JDBC连接spark-sql</li></ul><pre class="prettyprint linenums" style="border-bottom:rgb(238,238,238) 1px solid;border-left:rgb(238,238,238) 1px solid;line-height:20px;background-color:rgb(248,248,248);display:block;font-family:Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important;color:rgb(68,68,68);font-size:14px;overflow:hidden;border-top:rgb(238,238,238) 1px solid;border-right:rgb(238,238,238) 1px solid;"></pre><ol class="linenums" style="list-style-type:none;"><li class="L0" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pln">cd $SPARK_HOME</span><span class="pun">/</span><span class="pln">bin</span></li><li class="L1" style="line-height:20px;list-style-type:decimal;text-indent:0px;color:rgb(190,190,197);margin-left:0px;"><span class="pun">./</span><span class="pln">beeline </span><span class="pun">-</span><span class="pln">u jdbc</span><span class="pun">:</span><span class="pln">hive2</span><span class="pun">:</span><span class="com" style="color:#666666;">//localhost:10000 -n lxw1234</span></li></ol>
<p><img class="aligncenter" alt="spark" src="http://7xipth.com1.z0.glb.clouddn.com/1230-4.jpg" width="757" height="276" style="border-bottom:0px;text-align:center;border-left:0px;display:block;vertical-align:middle;border-top:0px;border-right:0px;"></p>
<p>执行查询：<br>
select count(1) from ut.t_ut_site_log where pt = ‘2015-12-10′;<br>
该任务有64个Task：</p>
<p><img class="aligncenter" alt="spark" src="http://7xipth.com1.z0.glb.clouddn.com/1230-5.jpg" width="756" height="160" style="border-bottom:0px;text-align:center;border-left:0px;display:block;vertical-align:middle;border-top:0px;border-right:0px;"></p>
<p>而监控页面上的并发数仍然是30：</p>
<p><img class="aligncenter" alt="spark" src="http://7xipth.com1.z0.glb.clouddn.com/1230-6.jpg" width="769" height="356" style="border-bottom:0px;text-align:center;border-left:0px;display:block;vertical-align:middle;border-top:0px;border-right:0px;"></p>
<p>执行完后，executors数只剩下1个，应该是缓存数据，其余的全部被回收：</p>
<p><img class="aligncenter" alt="spark" src="http://7xipth.com1.z0.glb.clouddn.com/1230-7.jpg" width="755" height="288" style="border-bottom:0px;text-align:center;border-left:0px;display:block;vertical-align:middle;border-top:0px;border-right:0px;"></p>
<p>这样，多个用户可以通过beeline，JDBC连接到Thrift Server，执行SQL查询，而资源也是动态分配的。</p>
<p>需要注意的是，在启动ThriftServer时候指定的spark.dynamicAllocation.maxExecutors=30，是整个ThriftServer同时并发的最大资源数，如果多个用户同时连接，则会被多个用户共享竞争，总共30个。</p>
<p> </p>
<p>这样，也算是解决了多用户同时使用spark-sql，并且动态分配资源的需求了。</p>
<p>Spark动态资源分配官方文档：http://spark.apache.org/docs/1.5.0/job-scheduling.html#dynamic-resource-allocation</p>
<h5 style="line-height:35px;">您可以关注<span> </span><a title="" href="http://lxw1234.com/" rel="nofollow" style="color:rgb(0,166,124);text-decoration:none;">lxw的大数据田地</a><span> </span>，或者<span> </span><a title="" href="http://163.fm/YHfRFnF" rel="nofollow" style="color:rgb(0,166,124);text-decoration:none;">加入邮件列表</a><span> </span>，随时接收博客更新的通知邮件。</h5>
<p> </p>
<p> </p>
<p>转载请注明：<a title="" href="http://lxw1234.com/" rel="nofollow" style="color:rgb(0,166,124);text-decoration:none;">lxw的大数据田地</a><span> </span>»<span> </span><a title="" href="http://lxw1234.com/archives/2015/12/593.htm" rel="nofollow" style="color:rgb(0,166,124);text-decoration:none;">Spark动态资源分配-Dynamic
 Resource Allocation</a></p>
            </div>
                </div>