---
layout:     post
title:      kafka(3) -- 连接导入、导出数据
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/u010472499/article/details/78356795				</div>
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>有些场景下Kafka需要使用其他来源的数据或导出Kafka的数据到其他系统，相对于许多系统需要编写定制集成的代码，使用Kafka连接到系统去导入或导出数据更加简单。</p>

<p>Kafka Connect是包括在Kafka中一个工具，用来导入导出数据到Kafka。它是connectors的一个可扩展工具，其执行定制逻辑，用于与外部系统交互。本文介绍如何使用Kafka Connect做一些简单的连接器从一个文件导入数据到Kafka的主题，和将主题数据导出到另一个文件，具体操作如下:</p>

<p><strong>1. 创建原始数据文件</strong></p>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-operator">-e</span> <span class="hljs-string">"foo/bar"</span> &gt; test.txt     <span class="hljs-comment">#文件名不要修改</span></code></pre>

<p>test.txt文件中的内容即要导入到kafka中的数据。</p>

<p><strong>2. 启动连接器</strong> <br>
启动两个运行在独立模式的连接器，连接器在一个单一的，局部的，专用的进程中运行。需要提供三个配置文件作为参数。第一个参数为Kafka连接过程中的公共配置文件，如要连接到的Kafka的代理服务器的配置和数据的序列化格式的配置。其余两个配置文件用来创建指定的连接器。这些文件包括一个唯一的连接器名称，需要实例化的连接器类，还有创建该连接器所需的其他配置:</p>



<pre class="prettyprint"><code class=" hljs lasso">bin/connect<span class="hljs-attribute">-standalone</span><span class="hljs-built_in">.</span>sh config/connect<span class="hljs-attribute">-standalone</span><span class="hljs-built_in">.</span>properties config/connect<span class="hljs-attribute">-file</span><span class="hljs-attribute">-source</span><span class="hljs-built_in">.</span>properties config/connect<span class="hljs-attribute">-file</span><span class="hljs-attribute">-sink</span><span class="hljs-built_in">.</span>properties</code></pre>

<p>用这些Kafka的示例配置文件，使用前面已经启动的本地群集的默认配置，建立两个连接器：第一是一个源连接器，其从输入文件中读取每行的内容，发布到的Kafka主题和第二个是一个sink连接器负责从Kafka主题读取消息，生产出的消息按行输出到文件。</p>

<p><strong>3. 检查数据导入、导出</strong> <br>
在启动过程中可以看到连接器被实例化的信息，一旦Kafka Connect进程已经起来，源连接器会从test.txt读取每行的消息，并将其生产发布到主题connect-test，而sink连接器会从主题connect-test读取消息，并将其写入文件test.sink.txt。可以通过检查输出文件的内容来验证数据都已通过整个管道输送：</p>



<pre class="prettyprint"><code class=" hljs vala"><span class="hljs-preprocessor">#cat test.sink.txt</span>
  foo
  bar</code></pre>

<p>由于数据被存储在Kafka topic connect-test中，所以我们也可以运行控制台消费者消费topic中的数据或者自定义消费者逻辑消费消息:</p>



<pre class="prettyprint"><code class=" hljs r"><span class="hljs-comment"># bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning</span>
{<span class="hljs-string">"schema"</span>:{<span class="hljs-string">"type"</span>:<span class="hljs-string">"string"</span>,<span class="hljs-string">"optional"</span>:false},<span class="hljs-string">"payload"</span>:<span class="hljs-string">"foo"</span>}
{<span class="hljs-string">"schema"</span>:{<span class="hljs-string">"type"</span>:<span class="hljs-string">"string"</span>,<span class="hljs-string">"optional"</span>:false},<span class="hljs-string">"payload"</span>:<span class="hljs-string">"bar"</span>}
<span class="hljs-keyword">...</span></code></pre>

<p>由于连接器不停的处理数据，因此我们可以继续将数据添加到test.txt文件，并能看到数据通过管道移动：</p>



<pre class="prettyprint"><code class=" hljs avrasm">echo <span class="hljs-number">111</span> &gt;&gt; test<span class="hljs-preprocessor">.txt</span>
cat test<span class="hljs-preprocessor">.sink</span><span class="hljs-preprocessor">.txt</span></code></pre>

<p>下一篇： <a href="http://blog.csdn.net/u010472499/article/details/78362922" rel="nofollow">使用Streams处理数据</a></p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>