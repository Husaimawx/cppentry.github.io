---
layout:     post
title:      Hadoop集群启动、初体验
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p><strong>1． <strong>启动方式</strong></strong></p>

<p><span style="color:#363636;">要启动Hadoop集群，需要启动HDFS和YARN两个集群。</span></p>

<p><span style="color:#363636;">注意：<strong>首次启动HDFS时，必须对其进行格式化操作</strong>。本质上是一些清理和准备工作，因为此时的HDFS在物理上还是不存在的。</span></p>

<p><span style="color:#363636;">hdfs namenode–format或者hadoop namenode –format</span></p>

<p><strong>1.1． <strong>单节点逐个启动</strong></strong></p>

<p><span style="color:#363636;">在主节点上使用以下命令启动HDFS NameNode：</span></p>

<p><span style="color:#363636;">        hadoop-daemon.sh <strong>start</strong> namenode</span></p>

<p><span style="color:#363636;">在每个从节点上使用以下命令启动HDFS DataNode：</span></p>

<p><span style="color:#363636;">        hadoop-daemon.sh <strong>start </strong>datanode</span></p>

<p><span style="color:#363636;">在主节点上使用以下命令启动YARN ResourceManager：</span></p>

<p><span style="color:#363636;">        yarn-daemon.sh  <strong>start</strong> resourcemanager</span></p>

<p><span style="color:#363636;">在每个从节点上使用以下命令启动YARN nodemanager：</span></p>

<p><span style="color:#363636;">        yarn-daemon.sh <strong>start</strong> nodemanager</span></p>

<p><span style="color:#363636;">以上脚本位于$HADOOP_PREFIX/sbin/目录下。如果想要停止某个节点上某个角色，只需要把命令中的<strong>start</strong>改为<strong>stop</strong>即可。</span></p>

<p><strong>1.2． <strong>脚本一键启动</strong></strong></p>

<p><span style="color:#363636;">如果配置了etc/hadoop/slaves和ssh免密登录，则可以使用程序脚本启动所有Hadoop两个集群的相关进程，在主节点所设定的机器上执行。</span></p>

<p><span style="color:#363636;">hdfs：$HADOOP_PREFIX/sbin/start-dfs.sh</span></p>

<p><span style="color:#363636;">yarn: $HADOOP_PREFIX/sbin/start-yarn.sh</span></p>

<p><span style="color:#363636;">停止集群：stop-dfs.sh、stop-yarn.sh</span></p>

<p><strong>2． <strong>集群web-ui</strong></strong></p>

<p><span style="color:#363636;">一旦Hadoop集群启动并运行，可以通过web-ui进行集群查看，如下所述：</span></p>

<p><span style="color:#363636;">NameNode        http://nn_host:port/        默认50070.</span></p>

<p><span style="color:#363636;">ResourceManager        http://rm_host:port/        默认 8088.</span></p>

<p><span style="color:#363636;"><img alt="" class="has" id="aimg_247934" src="http://bbs.itheima.com/data/attachment/forum/201808/30/145145d3p3947f95qa4if4.png.thumb.jpg"></span></p>

<p><span style="color:#363636;"><img alt="" class="has" id="aimg_247935" src="http://bbs.itheima.com/data/attachment/forum/201808/30/145153t86hue5luusuqnlo.png.thumb.jpg"></span></p>

<p> </p>

<p><strong>3． <strong>Hadoop初体验</strong></strong><strong>3.1． <strong>HDFS使用</strong></strong></p>

<p><span style="color:#363636;">从Linux本地上传一个文本文件到hdfs的/test/input目录下</span></p>

<p><span style="color:#363636;">hadoop fs -mkdir -p /wordcount/input</span></p>

<p><span style="color:#363636;">hadoop fs -put /root/somewords.txt  /test/input</span></p>

<p><strong>3.2． <strong>运行mapreduce程序</strong></strong></p>

<p><span style="color:#363636;">在Hadoop安装包的hadoop-2.7.4/share/hadoop/mapreduce下有官方自带的mapreduce程序。我们可以使用如下的命令进行运行测试。</span></p>

<p><span style="color:#363636;">示例程序jar:</span></p>

<p><span style="color:#363636;">hadoop-mapreduce-examples-2.7.4.jar</span></p>

<p><span style="color:#363636;">计算圆周率:</span></p>

<p><span style="color:#363636;">hadoop jar hadoop-mapreduce-examples-2.7.4.jar pi 20 50</span></p>

<p><span style="color:#363636;">关于圆周率的估算，感兴趣的可以查询资料Monte Carlo方法来计算Pi值。</span></p>            </div>
                </div>