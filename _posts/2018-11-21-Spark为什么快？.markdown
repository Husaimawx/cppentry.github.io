---
layout:     post
title:      Spark为什么快？
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p><span></span>Spark SQL比Hadoop Hive快，是有一定条件的，而且不是Spark SQL的引擎比Hive的引擎快，相反，Hive的HQL引擎还比Spark SQL的引擎更快。</p>
<p>其实，关键还是在于Spark 本身快。</p>
<p><br></p>
<p>Spark为什么快？</p>
<p><br></p>
<p>1、消除了冗余的HDFS读写</p>
<p><span></span>Hadoop每次shuffle操作后，必须写到磁盘，而Spark在shuffle后不一定落盘，可以cache到内存中，以便迭代时使用。如果操作复杂，很多的shufle操作，那么Hadoop的读写IO时间会大大增加。</p>
<p><br></p>
<p>2、消除了冗余的MapReduce阶段</p>
<p><span></span>Hadoop的shuffle操作一定连着完整的MapReduce操作，冗余繁琐。而Spark基于RDD提供了丰富的算子操作，且reduce操作产生shuffle数据，可以缓存在内存中。</p>
<p><br></p>
<p>3、JVM的优化</p>
<p><span></span>Hadoop每次MapReduce操作，启动一个Task便会启动一次JVM，基于进程的操作。而Spark每次MapReduce操作是基于线程的，只在启动Executor是启动一次JVM，内存的Task操作是在线程复用的。</p>
<p><br></p>
<p><span></span>每次启动JVM的时间可能就需要几秒甚至十几秒，那么当Task多了，这个时间Hadoop不知道比Spark慢了多少。</p>
<p><br></p>
<p>考虑一种极端查询：Select month_id,sum(sales) from T group by month_id;</p>
<p>这个查询只有一次shuffle操作，此时，也许Hive HQL的运行时间也许比Spark还快。</p>
<p><br></p>
<p>结论：Spark快不是绝对的，但是绝大多数，Spark都比Hadoop计算要快。这主要得益于其对mapreduce操作的优化以及对JVM使用的优化。</p>
<p><br></p>
            </div>
                </div>