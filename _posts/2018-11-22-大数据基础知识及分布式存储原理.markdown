---
layout:     post
title:      大数据基础知识及分布式存储原理
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-dracula">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p></p><div class="toc"><h3>大数据学习day01</h3><ul><li><a href="#Big_Data_1" rel="nofollow">什么是大数据(Big Data)</a></li><ul><li><a href="#_5" rel="nofollow">大数据概念</a></li></ul><li><a href="#_8" rel="nofollow">大数据技术：</a></li><ul><ul><li><a href="#_9" rel="nofollow">分布式存储</a></li><li><a href="#_10" rel="nofollow">分布式计算</a></li></ul></ul><li><a href="#_22" rel="nofollow">分布式存储</a></li><ul><ul><li><a href="#HDFS_23" rel="nofollow">HDFS</a></li></ul><li><a href="#HDFS_25" rel="nofollow">HDFS原理</a></li><ul><ul><li><a href="#Client_26" rel="nofollow">Client(客户端)</a></li><li><a href="#NameNode_32" rel="nofollow">NameNode</a></li><li><a href="#Secondary_NameNode_38" rel="nofollow">Secondary NameNode</a></li><ul><li><a href="#_40" rel="nofollow">合并机制过程</a></li></ul><li><a href="#DataNode_52" rel="nofollow">DataNode</a></li></ul><li><a href="#HDFS_55" rel="nofollow">HDFS读写流程</a></li><ul><li><a href="#_56" rel="nofollow">读流程</a></li><li><a href="#_62" rel="nofollow">写流程</a></li></ul><li><a href="#HDFS_68" rel="nofollow">HDFS备份机制</a></li><li><a href="#HDFS_72" rel="nofollow">HDFS权限</a></li><li><a href="#HDFS_74" rel="nofollow">HDFS安全模式</a></li></ul></ul></ul></div><p></p>
<h1><a id="Big_Data_1"></a>什么是大数据(Big Data)</h1>
<h2><a id="_5"></a>大数据概念</h2>
<p>大数据是指海量数据或巨量数据，其规模巨大到无法通过目前主流的计算机系统在合理时间内获取、存储、管理、处理并提炼以帮助使用者决策。<br>
短时间内快速的产生海量的多种多样的有价值的数据。</p>
<h1><a id="_8"></a>大数据技术：</h1>
<h3><a id="_9"></a>分布式存储</h3>
<h3><a id="_10"></a>分布式计算</h3>
<ol>
<li>
<p><strong>分布式批处理</strong><br>
攒一段时间的数据，然后再未来某一个时间来处理这批数据</p>
</li>
<li>
<p><strong>分布式流处理</strong>（实时处理）<br>
数据不需要积攒，直接处理，每产生一条数据，立马对这条数据进行处理，将结果推送到前端，如双十一的天猫大屏幕，qq实时在线分布情况</p>
</li>
<li>
<p><strong>机器学习</strong></p>
</li>
</ol>
<h1><a id="_22"></a>分布式存储</h1>
<h3><a id="HDFS_23"></a>HDFS</h3>
<p>HDFS（Hadoop Distributed File System）是Hadoop项目的核心子项目，是分布式计算中数据存储管理的基础，是基于流数据模式访问和处理超大文件的需求而开发的，可以运行于廉价的商用服务器上。它所具有的高容错、高可靠性、高可扩展性、高获得性、高吞吐率等特征为海量数据提供了不怕故障的存储，为超大数据集（Large Data Set）的应用处理带来了很多便利。</p>
<h2><a id="HDFS_25"></a>HDFS原理</h2>
<h4><a id="Client_26"></a>Client(客户端)</h4>
<ol>
<li>文件切分。文件上传 HDFS 的时候，Client 将文件切分成 一个一个的Block，然后进行存储。</li>
<li>与 NameNode 交互，获取文件的位置信息。</li>
<li>与 DataNode 交互，读取或者写入数据。</li>
<li>Client 提供一些命令来管理 HDFS，比如启动或者关闭HDFS。</li>
<li>Client 可以通过一些命令来访问 HDFS。</li>
</ol>
<h4><a id="NameNode_32"></a>NameNode</h4>
<p>Namenode存放文件系统树及所有文件、目录的元数据。就是 master，它是一个主管、管理者。<br>
6. 管理 HDFS 的名称空间。<br>
7. 管理数据块（Block）映射信息<br>
8. 配置副本策略<br>
9. 处理客户端读写请求。</p>
<h4><a id="Secondary_NameNode_38"></a>Secondary NameNode</h4>
<p>模拟执行edits文件，产生元数据，将元数据与fsimage合并完成后，将新的fsimage推送给namenode</p>
<h5><a id="_40"></a>合并机制过程</h5>
<p>Secondary NameNode节点的工作流程：<br>
1)、定期的通过远程方法获取NameNode节点上编辑日志（edits）的大小；<br>
2）、如果NameNode节点上编辑日很小，就不需要合并NameNode上的fsimage文件和编辑日志；<br>
3）、通过远程接口启动一次检查点过程，这时名字节点NameNode需要创建一个新的编辑日志文件edits.new，后续对文件系统的任何修改都记录到这个新编辑日志里；<br>
4）、SecondNameNode点将Namenode上的fsimage文件和原编辑日志下载到本地，并在内存中合并，合并的结果输出为fsimage.ckpt；<br>
5）、再次发起请求通知NameNode节点数据(fsimage.ckpt)已准备好，然后NameNode节点会下载fsimage.ckpt(并替换掉原来的fsimage)；<br>
6）、NameNode下载结束后，Secondary NameNode会通过远程调用（NameNodeProtocol.rollFsImage()）完成这次检查点，NameNode在响应该远程调用时，会用fsimage.ckpt覆盖原来的fsimage文件，形成新的命名空间镜像，同时将新的编辑日志edits.new改名为edits。<br>
并不是所有元数据都会持久化<br>
合并触发机制：</p>
<ol>
<li>超过3600ms</li>
<li>edits文件超过64mb</li>
</ol>
<h4><a id="DataNode_52"></a>DataNode</h4>
<p>主要功能：存储数据块（block）默认大小为128mb<br>
DN启动时会向NN汇报block信息，并且之后通过向NN发送心跳保持联系（3秒一次），如果NN在10分钟内没有收到DN的心跳，就认为该DN已经lost，并copy其上的block到其他DN。</p>
<h3><a id="HDFS_55"></a>HDFS读写流程</h3>
<h4><a id="_56"></a>读流程</h4>
<p><img alt="hdfs读流程" src="https://img-blog.csdn.net/20181009235231102?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RoeXl5eXl5eQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>
<ol>
<li>客户端发送请求</li>
<li>Namenode返回所有block的位置信息，并将这些信息返回给客户端</li>
<li>客户端拿到block的位置信息后调用方法读取block信息</li>
<li>datanode返回给客户端</li>
</ol>
<h4><a id="_62"></a>写流程</h4>
<p><img alt="hdfs写流程" src="https://img-blog.csdn.net/20181009235523248?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RoeXl5eXl5eQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>
<ol>
<li>客户端发送请求</li>
<li>namenode根据以上信息算出文件需要切成多少块block，以及block要存放在哪个datanode上，并将这些信息返回给客户端。</li>
<li>客户端调用方法首先将其中一个block写在datanode上，每一个block默认都有3个副本，并不是由客户端分别往3个datanode上写3份，而是由已经上传了block的datanode产生新的线程，由这个namenode按照放置副本规则往其它datanode写副本</li>
<li>写完后返回给客户端一个信息，然后客户端在将信息反馈给namenode</li>
</ol>
<h3><a id="HDFS_68"></a>HDFS备份机制</h3>
<ol>
<li>第一个block存储在负载不是很高的一台服务器</li>
<li>第一个备份的block存储在与第一个block不同的机架随机一条服务器上</li>
<li>第二个备份在与第一个备份相同的机架随机一台服务器</li>
</ol>
<h3><a id="HDFS_72"></a>HDFS权限</h3>
<p>依据Linux系统的用户系统 默认权限</p>
<h3><a id="HDFS_74"></a>HDFS安全模式</h3>
<ol>
<li>加载fsimage,加载到内存中</li>
<li>如果edits文件不为空，那么namenode自己来合并</li>
<li>检查DN的健康情况</li>
<li>如果有DN挂掉，指挥做备份<br>
处于安全模式过程中，如果fsimage已经加载到内存中，可以查看到文件目录，但是无法读取处于安全模式过程中，如果fsimage已经加载到内存中，可以查看到文件目录，但是无法读取</li>
</ol>

            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>