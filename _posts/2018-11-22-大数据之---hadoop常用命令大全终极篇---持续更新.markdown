---
layout:     post
title:      大数据之---hadoop常用命令大全终极篇---持续更新
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>软件环境</p><table cellspacing="0" cellpadding="2" width="401" border="1"><tbody><tr><td valign="top" width="133">RHEL6.8</td><td valign="top" width="133">hadoop2.8.1</td><td valign="top" width="133">apache-maven-3.3.9</td></tr><tr><td valign="top" width="133">findbugs-1.3.9</td><td valign="top" width="133">protobuf-2.5.0.tar.gz</td><td valign="top" width="133">jdk-8u45</td></tr></tbody></table><p><br>(操作环境root安装启动的hadoop)<br>hadoop fs == hdfs dfs </p><p>将文件上传至hadoop的根目录/下载至本地<br>hadoop dfs -put filename /     <br>hadoop dfs -get /filename    <br># '/'不是Linux的根目录，表示hadoop的根目录<br> <br>上传文件   下载<br>[root@hadoop01 software]# hdfs dfs -put apache-maven-3.3.9-bin.zip  /<br>[root@hadoop01 software]# hdfs  dfs -ls   /<br>[root@hadoop01 software]# hdfs dfs -put apache-maven-3.3.9-bin.zip  / <br>[root@hadoop01 software]# cd<br>[root@hadoop01 ~]# hdfs dfs -get /apache-maven-3.3.9-bin.zip<br></p><p>帮助</p><p>  [-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]<br>  [-moveToLocal &lt;src&gt; &lt;localdst&gt;]<br>查看hadoop里的文件内容<br>hadoop dfs -ls /<br>[root@hadoop01 ~]# hdfs dfs -ls /<br>Found 3 items<br>-rw-r--r--   3 root supergroup    8617253 2018-04-26 09:20 /apache-maven-3.3.9-bin.zip<br>-rw-r--r--   3 root supergroup      59776 2018-04-26 09:14 /install.log<br>-rw-r--r--   3 root supergroup      11067 2018-04-26 08:46 /install.log.syslog<br>查看hadoop里的文件的内容<br>hadoop fs -cat filename<br>[root@hadoop01 ~]# hadoop fs -cat   /file1<br>111</p><p>创建文件夹</p><p>  hadoop fs -mkdir -p /filename/filename<br>[root@hadoop01 ~]#   hadoop fs -mkdir -p /filename/filename</p><p>删除file 删除dir<br>[root@hadoop01 ~]# hadoop fs -rm -r -f /file1<br>Deleted /file1<br>[root@hadoop01 ~]# hadoop fs -rm -r -f /filename<br>Deleted /filename</p><p>  #  [-rm [-f] [-r|-R] [-skipTrash] [-safely] &lt;src&gt; ...]<br>  <br>  1.配置回收站<br>  vi core-site.xml<br>  &lt;property&gt;  <br>    &lt;name&gt;fs.trash.interval&lt;/name&gt;  <br>    &lt;value&gt;10080&lt;/value&gt;          # 回收站保留时间（分钟）<br>  &lt;/property&gt; <br>  <br>  <br>  2.测试<br><span style="color:#ff0000;">  hadoop fs -rm -r -f</span> /xxxx                              进入回收站，是可以恢复的<br><span style="color:#ff0000;">  hadoop fs -rm -r -f -skipTrash</span> /xxxx       不进入回收站，是不可以恢复的<br>  A.进入回收站<br>[root@hadoop01 ~]# hadoop fs -ls /<br>Found 4 items<br>-rw-r--r--   3 root supergroup    8617253 2018-04-26 09:20 /apache-maven-3.3.9-bin.zip<br>drwxr-xr-x   - root supergroup          0 2018-04-26 09:35 /dir<br>-rw-r--r--   3 root supergroup      59776 2018-04-26 09:14 /install.log<br>-rw-r--r--   3 root supergroup      11067 2018-04-26 08:46 /install.log.syslog<br>[root@hadoop01 ~]# hadoop fs -rm -r -f /install.log<br>18/04/26 09:38:28 INFO fs.TrashPolicyDefault: Moved: 'hdfs://172.16.18.133:9000/install.log' to trash at: hdfs://172.16.18.133:9000/user/root/.Trash/Current/install.log<br>[root@hadoop01 ~]# hadoop fs -ls<br>Found 1 items<br>drwx------   - root supergroup          0 2018-04-26 09:38 .Trash<br>[root@hadoop01 ~]# hadoop fs -ls<br>Found 1 items<br>drwx------   - root supergroup          0 2018-04-26 09:38 .Trash<br>[root@hadoop01 ~]# hadoop fs -ls .Trash/<br>Found 1 items<br>drwx------   - root supergroup          0 2018-04-26 09:38 .Trash/Current<br>[root@hadoop01 ~]# hadoop fs -ls .Trash/Current<br>Found 1 items<br>-rw-r--r--   3 root supergroup      59776 2018-04-26 09:14 .<span style="color:#ff0000;">Trash/Current/install.log</span><br>  恢复刚刚删除的文件<br>[root@hadoop01 ~]# hadoop fs -ls /user<br>Found 1 items<br>drwx------   - root supergroup          0 2018-04-26 09:38 /user/root<br>[root@hadoop01 ~]# hadoop fs -ls /user/root/<br>Found 1 items<br>drwx------   - root supergroup          0 2018-04-26 09:38 /user/root/.Trash<br>[root@hadoop01 ~]# <span style="color:#ff0000;">hadoop fs -mv /user/root/.Trash/Current/install.log  /</span><br>[root@hadoop01 ~]# hadoop fs -ls /<br>Found 5 items<br>-rw-r--r--   3 root supergroup    8617253 2018-04-26 09:20 /apache-maven-3.3.9-bin.zip<br>drwxr-xr-x   - root supergroup          0 2018-04-26 09:35 /dir<br>-rw-r--r--   3 root supergroup      59776 2018-04-26 09:14 <span style="color:#ff0000;">/install.log</span><br>-rw-r--r--   3 root supergroup      11067 2018-04-26 08:46 /install.log.syslog<br>drwx------   - root supergroup          0 2018-04-26 09:38 /user<br>  <br>  B.不进入回收站<br>[root@hadoop01 ~]# <span style="color:#ff0000;">hadoop fs -rm -r -f -skipTrash  /install.log.syslog</span><br>Deleted /install.log.syslog<br>[root@hadoop01 ~]# hadoop fs -ls <br>Found 1 items<br>drwx------   - root supergroup          0 2018-04-26 09:38 .Trash<br>[root@hadoop01 ~]# hadoop fs -ls .Trash/Current<br>[root@hadoop01 ~]#         </p><p><br><span style="color:#ff0000;">hdfs fs -moveFromLocal /input/xx.txt /input/xx.txt  ---从本地剪切粘贴到hdfs<br><br>hdfs fs -moveToLocal /input/xx.txt /input/xx.txt  --从hdfs剪切粘贴到本地<br><br>hdfs fs -appedToFile ./hello.txt /input/hello.txt  ---追加一个文件到另一个文件到末尾</span></p><p><span style="color:#ff0000;">注意：appedToFile  moveToLocal moveFromLocal  大小写严格</span></p><p><br><span style="color:#ff0000;">hdfs fs -cat /input/hello.txt   ---查看文件内容<br><br>hdfs fs -tail /input/hello.txt   ---显示一个文件到末尾<br><br>hdfs fs -text /input/hello.txt  ---以字符串的形式打印文件的内容</span></p><p><br><span style="color:#ff0000;">hdfs fs -chmod 666 /input/hello.txt   ---修改文件权限</span><br><br><span style="color:#ff0000;">hdfs fs -chown ruoze.ruoze  /input/hello.txt   --修改文件所属</span></p><p><br><span style="color:#ff0000;">hdfs fs -copyFromLocal /input/hello.txt /input/   --从本地文件系统拷贝到hdfs里</span><br><br><span style="color:#ff0000;">hdfs fs -copyToLocal /input/hello.txt /input/     --从hdfs拷贝到本地</span></p><p><br><span style="color:#ff0000;">hdfs fs -cp /input/xx.txt /output/xx.txt              ---从hdfs到一个路径拷贝到另一个路径</span><br><br><span style="color:#ff0000;">hdfs fs -mv /input/xx.txt /output/xx.txt            ---从hdfs到一个路径移动到另一个路径</span></p><p><span style="color:#ff0000;">hdfs fs -df -h /                                                              ----统计文件系统的可用空间信息</span><br><br><span style="color:#ff0000;">hdfs fs -du -s -h /                                                         ----统计文件夹的大小信息</span><br><br><span style="color:#ff0000;">hadoop  fs -count /aaa  -                                             ---统计一个指定目录下的文件节点数量<br><span style="color:#ff0000;"></span></span></p><p><span style="color:#ff0000;">hadoop fs -setrep 3 /input/xx.txt                           --设置hdfs的文件副本数量</span></p><p><span style="color:#ff0000;"><br></span></p><p><span style="color:#ff0000;">修改hdfs默认位置 迁移数据</span></p><p><span style="color:#ff0000;">hdfs-site.xml</span></p><p><span style="color:#ff0000;">增加</span></p><p><span style="color:#ff0000;">        &lt;property&gt;<br>            &lt;name&gt;dfs.namenode.secondary.https-address&lt;/name&gt;<br>                &lt;value&gt;hadoop01:50091&lt;/value&gt;<br><span style="white-space:pre;">	</span>&lt;/property&gt;<br>       &lt;property&gt;<br>        &lt;name&gt;dfs.name.dir&lt;/name&gt;<br>              &lt;value&gt;/opt/software/hadoop/name&lt;/value&gt;<br>         &lt;/property&gt;<br></span></p><p><span style="color:#ff0000;">重启hdfs </span></p><p><span style="color:#ff0000;"><span style="color:rgb(255,0,0);">[root@hadoop01 hadoop]#</span>sbin/stop-dfs.sh <br></span></p><p><span style="color:#ff0000;">[root@hadoop01 hadoop]# bin/hdfs namenode -format  ---格式化新hdfs目录<br></span></p><p><span style="color:#ff0000;"><span style="color:rgb(255,0,0);"><span style="color:rgb(255,0,0);">[root@hadoop01 hadoop]#</span>sbin/start-dfs.sh</span><br></span></p><p><span style="color:#ff0000;"><span style="color:rgb(255,0,0);">设置权限</span></span></p><p></p><p><span style="color:rgb(255,0,0);">[root@hadoop000 ~]# su - hadoop -c "hdfs dfs -put /tmp/test.log /"</span></p><p><span style="color:rgb(255,0,0);">[root@hadoop000 ~]# su - hadoop -c "hdfs dfs -ls /"</span></p><span style="color:rgb(255,0,0);"><span style="color:rgb(255,0,0);">Found 6 items<br>-rw-r--r--   1 hadoop supergroup         18 2018-05-19 20:47 /rz.log<br>-rw-r--r--   2 hadoop supergroup         18 2018-05-19 21:20 /rz.log1<br>-rw-r--r--   1 hadoop supergroup         18 2018-05-20 20:04 /rz.log123<br>-rw-r--r--   1 hadoop supergroup          0 2018-05-20 20:10 /test.log<br>drwx------   - hadoop supergroup          0 2018-05-16 22:49 /tmp<br>drwxr-xr-x   - hadoop supergroup          0 2018-05-16 22:49 /user<br>[hadoop@hadoop000 ~]$ hdfs dfs -mkdir /root<br>[hadoop@hadoop000 ~]$ hdfs dfs -chown -R root:root /root<br>[hadoop@hadoop000 ~]$ hdfs dfs -ls /<br></span></span><p><span style="color:#ff0000;"><span style="color:rgb(255,0,0);"><br></span></span></p><p><span style="color:#ff0000;"><span style="color:rgb(255,0,0);"><br></span></span></p><p><span style="color:#ff0000;">yarn常用命令</span></p><p>命令:yarn application –list<br>yarn application –kill -applicationId  &lt;application Id &gt;<br>yarn logs -applicationId &lt;application ID&gt;<br></p><p><span style="color:#ff0000;"><span style="color:rgb(255,0,0);"><br></span></span></p>            </div>
                </div>