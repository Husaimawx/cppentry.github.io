---
layout:     post
title:      Spark项目之环境搭建（单机）二 hive-2.3.3安装
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/lx1309244704/article/details/83862333				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>上传hive架包，然后解压：</p>

<pre class="has">
<code>tar -zxf apache-hive-2.3.3-bin.tar.gz hive</code></pre>

<p>重命名 </p>

<pre class="has">
<code>mv apache-hive-2.3.3-bin hive</code></pre>

<p>将mysql的驱动包加入hive的lib文件下面</p>

<p><img alt="" class="has" height="374" src="https://img-blog.csdnimg.cn/20181108161053946.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x4MTMwOTI0NDcwNA==,size_16,color_FFFFFF,t_70" width="1200"></p>

<p>进入hive目录下的conf</p>

<pre class="has">
<code>cd /home/hive/conf/</code></pre>

<p><img alt="" class="has" height="138" src="https://img-blog.csdnimg.cn/20181108154157286.png" width="1200"></p>

<p style="margin-left:0cm;">把初始化的文件 复制一份出来 并且改名</p>

<pre class="has">
<code>cp hive-env.sh.template hive-env.sh
cp hive-default.xml.template hive-site.xml
cp hive-log4j2.properties.template hive-log4j2.properties
cp hive-exec-log4j2.properties.template hive-exec-log4j2.properties
</code></pre>

<p>修改hive-env.sh</p>

<pre class="has">
<code>#jdk
export JAVA_HOME=/home/jdk
#hadoop
export HADOOP_HOME=/home/hadoop
#hive
export HIVE_HOME=/home/hive
</code></pre>

<p style="margin-left:0cm;">在hdfs 中创建下面的目录 ，并且授权</p>

<pre class="has">
<code>hdfs dfs -mkdir -p /user/hive/warehouse
hdfs dfs -mkdir -p /user/hive/tmp
hdfs dfs -mkdir -p /user/hive/log
hdfs dfs -chmod -R 777 /user/hive/warehouse
hdfs dfs -chmod -R 777 /user/hive/tmp
hdfs dfs -chmod -R 777 /user/hive/log
</code></pre>

<p>修改hive-site.xml </p>

<pre class="has">
<code>vi hive-site.xml</code></pre>

<p style="margin-left:0cm;">将 hive-site.xml 文件中以下几个配置项的值设置成上一步中创建的几个路径。</p>

<p style="margin-left:0cm;">&lt;property&gt;</p>

<p style="margin-left:0cm;">    &lt;name&gt;hive.exec.scratchdir&lt;/name&gt;</p>

<p style="margin-left:0cm;">    &lt;value&gt;/user/hive/tmp&lt;/value&gt;</p>

<p style="margin-left:0cm;">&lt;/property&gt;</p>

<p style="margin-left:0cm;">&lt;property&gt;</p>

<p style="margin-left:0cm;">    &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;</p>

<p style="margin-left:0cm;">    &lt;value&gt;/user/hive/warehouse&lt;/value&gt;</p>

<p style="margin-left:0cm;">&lt;/property&gt;</p>

<p style="margin-left:0cm;">&lt;property&gt;</p>

<p style="margin-left:0cm;">    &lt;name&gt;hive.querylog.location&lt;/name&gt;</p>

<p style="margin-left:0cm;">    &lt;value&gt;/user/hive/log&lt;/value&gt;</p>

<p style="margin-left:0cm;">&lt;/property&gt;</p>

<pre class="has">
<code>&lt;property&gt;
    &lt;name&gt;hive.exec.scratchdir&lt;/name&gt;
    &lt;value&gt;/user/hive/tmp&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;
    &lt;value&gt;/user/hive/warehouse&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hive.querylog.location&lt;/name&gt;
    &lt;value&gt;/user/hive/log&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p style="margin-left:0cm;">创建tmp文件，然后在配置文件 hive-site.xml 里面</p>

<p style="margin-left:0cm;">把{system:java.io.tmpdir} 改成 /home/hive/tmp/</p>

<p style="margin-left:0cm;">把 {system:user.name} 改成 {user.name}</p>

<pre class="has">
<code>mkdir /home/hive/tmp</code></pre>

<p style="margin-left:0cm;"> javax.jdo.option.ConnectionUserName:你数据库的名称</p>

<p> javax.jdo.option.ConnectionPassword:你数据库的密码</p>

<pre class="has">
<code>&lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
    &lt;value&gt;jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&amp;amp;characterEncoding=UTF-8&amp;amp;useSSL=false&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
    &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
    &lt;value&gt;root&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
    &lt;value&gt;root&lt;/value&gt;
  &lt;/property&gt;</code></pre>

<p> 配置环境变量</p>

<pre class="has">
<code> vi /etc/profile
</code></pre>

<pre class="has">
<code>#hive
export HIVE_HOME=/home/hive
export PATH=$HIVE_HOME/bin:$HIVE_HOME/conf:$PATH
</code></pre>

<p>然后保存，执行一下命令使其生效</p>

<pre class="has">
<code>source /etc/profile</code></pre>

<p style="margin-left:0cm;">从 Hive 2.1 版本开始, 我们需要先运行 schematool 命令来执行初始化操作。</p>

<pre class="has">
<code>schematool -dbType mysql -initSchema</code></pre>

<p>先启动hadoop，然后输入 hive</p>

<pre class="has">
<code>hive</code></pre>

<p><img alt="" class="has" height="278" src="https://img-blog.csdnimg.cn/20181108160704142.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x4MTMwOTI0NDcwNA==,size_16,color_FFFFFF,t_70" width="1200"></p>

<p>项目地址：<a href="https://github.com/LX1309244704/sparkDemo" rel="nofollow">https://github.com/LX1309244704/sparkDemo</a></p>            </div>
                </div>