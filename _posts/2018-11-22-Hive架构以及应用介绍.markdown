---
layout:     post
title:      Hive架构以及应用介绍
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/a2011480169/article/details/51482799				</div>
								            <div id="content_views" class="markdown_views prism-tomorrow-night">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<p>Hive这个框架在Hadoop的生态体系结构中占有及其重要的地位，在实际的业务当中用的也非常多，可以说Hadoop之所以这么流行在很大程度上是因为Hive的存在。那么Hive究竟是什么，为什么在Hadoop家族中占有这么重要的地位，本篇文章将围绕Hive的体系结构(架构)、Hive的操作、Hive与Hbase的区别等对Hive进行全方面的阐述。 <br>
   在此之前，先给大家介绍一个业务场景，让大家感受一下为什么Hive如此的受欢迎： <br>
   业务描述：统计业务表consumer.txt中北京的客户有多少位？下面是相应的业务数据：</p>



<pre class="prettyprint"><code class=" hljs applescript"><span class="hljs-property">id</span>      city    <span class="hljs-property">name</span>    sex           
<span class="hljs-number">0001</span>    beijing zhangli man 
<span class="hljs-number">0002</span>    guizhou lifang  woman 
<span class="hljs-number">0003</span>    tianjin wangwei man 
<span class="hljs-number">0004</span>    chengde wanghe  woman 
<span class="hljs-number">0005</span>    beijing lidong  man 
<span class="hljs-number">0006</span>    lanzhou wuting  woman 
<span class="hljs-number">0007</span>    beijing guona   woman 
<span class="hljs-number">0008</span>    chengde houkuo  man </code></pre>

<p>首先我先用大家所熟悉的MapReduce程序来实现这个业务分析，完整代码如下：</p>



<pre class="prettyprint"><code class=" hljs avrasm">package IT<span class="hljs-comment">;</span>

import java<span class="hljs-preprocessor">.io</span><span class="hljs-preprocessor">.IOException</span><span class="hljs-comment">;</span>
import java<span class="hljs-preprocessor">.net</span><span class="hljs-preprocessor">.URI</span><span class="hljs-comment">;</span>

import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.conf</span><span class="hljs-preprocessor">.Configuration</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.fs</span><span class="hljs-preprocessor">.FSDataInputStream</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.fs</span><span class="hljs-preprocessor">.FileSystem</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.fs</span><span class="hljs-preprocessor">.Path</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.io</span><span class="hljs-preprocessor">.IOUtils</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.io</span><span class="hljs-preprocessor">.LongWritable</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.io</span><span class="hljs-preprocessor">.Text</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.mapreduce</span><span class="hljs-preprocessor">.Job</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.mapreduce</span><span class="hljs-preprocessor">.Mapper</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.mapreduce</span><span class="hljs-preprocessor">.Reducer</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.mapreduce</span><span class="hljs-preprocessor">.lib</span><span class="hljs-preprocessor">.input</span><span class="hljs-preprocessor">.FileInputFormat</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.mapreduce</span><span class="hljs-preprocessor">.lib</span><span class="hljs-preprocessor">.input</span><span class="hljs-preprocessor">.TextInputFormat</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.mapreduce</span><span class="hljs-preprocessor">.lib</span><span class="hljs-preprocessor">.output</span><span class="hljs-preprocessor">.FileOutputFormat</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.mapreduce</span><span class="hljs-preprocessor">.lib</span><span class="hljs-preprocessor">.output</span><span class="hljs-preprocessor">.TextOutputFormat</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.mapreduce</span><span class="hljs-preprocessor">.lib</span><span class="hljs-preprocessor">.partition</span><span class="hljs-preprocessor">.HashPartitioner</span><span class="hljs-comment">;</span>

public class Consumer
{
    public static String path1 = <span class="hljs-string">"hdfs://192.168.80.80:9000/consumer.txt"</span><span class="hljs-comment">;</span>
    public static String path2 = <span class="hljs-string">"hdfs://192.168.80.80:9000/dir"</span><span class="hljs-comment">;</span>
    public static void main(String[] args) throws Exception
    {
          FileSystem fileSystem = FileSystem<span class="hljs-preprocessor">.get</span>(new URI(path1) , new Configuration())<span class="hljs-comment">;</span>
          if(fileSystem<span class="hljs-preprocessor">.exists</span>(new Path(path2)))
          {
              fileSystem<span class="hljs-preprocessor">.delete</span>(new Path(path2), true)<span class="hljs-comment">;</span>
          }

          Job job = new Job(new Configuration(),<span class="hljs-string">"Consumer"</span>)<span class="hljs-comment">;</span>
          FileInputFormat<span class="hljs-preprocessor">.setInputPaths</span>(job, new Path(path1))<span class="hljs-comment">;</span>
          job<span class="hljs-preprocessor">.setInputFormatClass</span>(TextInputFormat<span class="hljs-preprocessor">.class</span>)<span class="hljs-comment">;</span>
          job<span class="hljs-preprocessor">.setMapperClass</span>(MyMapper<span class="hljs-preprocessor">.class</span>)<span class="hljs-comment">;</span>
          job<span class="hljs-preprocessor">.setMapOutputKeyClass</span>(Text<span class="hljs-preprocessor">.class</span>)<span class="hljs-comment">;</span>
          job<span class="hljs-preprocessor">.setMapOutputValueClass</span>(LongWritable<span class="hljs-preprocessor">.class</span>)<span class="hljs-comment">;</span>

          job<span class="hljs-preprocessor">.setNumReduceTasks</span>(<span class="hljs-number">1</span>)<span class="hljs-comment">;</span>
          job<span class="hljs-preprocessor">.setPartitionerClass</span>(HashPartitioner<span class="hljs-preprocessor">.class</span>)<span class="hljs-comment">;</span>

          job<span class="hljs-preprocessor">.setReducerClass</span>(MyReducer<span class="hljs-preprocessor">.class</span>)<span class="hljs-comment">;</span>
          job<span class="hljs-preprocessor">.setOutputKeyClass</span>(Text<span class="hljs-preprocessor">.class</span>)<span class="hljs-comment">;</span>
          job<span class="hljs-preprocessor">.setOutputValueClass</span>(LongWritable<span class="hljs-preprocessor">.class</span>)<span class="hljs-comment">;</span>
          job<span class="hljs-preprocessor">.setOutputFormatClass</span>(TextOutputFormat<span class="hljs-preprocessor">.class</span>)<span class="hljs-comment">;</span>
          FileOutputFormat<span class="hljs-preprocessor">.setOutputPath</span>(job, new Path(path2))<span class="hljs-comment">;</span>
          job<span class="hljs-preprocessor">.waitForCompletion</span>(true)<span class="hljs-comment">;</span>
          //查看执行结果
          FSDataInputStream fr = fileSystem<span class="hljs-preprocessor">.open</span>(new Path(<span class="hljs-string">"hdfs://hadoop80:9000/dir/part-r-00000"</span>))<span class="hljs-comment">;</span>
          IOUtils<span class="hljs-preprocessor">.copyBytes</span>(fr, System<span class="hljs-preprocessor">.out</span>, <span class="hljs-number">1024</span>, true)<span class="hljs-comment">;</span>
     }
    public static class MyMapper extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt;
    {      
            public static long sum = <span class="hljs-number">0</span>L<span class="hljs-comment">;</span>
            protected void map(LongWritable k1, Text v1,Context context) throws IOException, InterruptedException
            {
                  String[] splited = v1<span class="hljs-preprocessor">.toString</span>()<span class="hljs-preprocessor">.split</span>(<span class="hljs-string">"\t"</span>)<span class="hljs-comment">;</span>
                  if(splited[<span class="hljs-number">1</span>]<span class="hljs-preprocessor">.equals</span>(<span class="hljs-string">"beijing"</span>))
                  {
                      sum++<span class="hljs-comment">;</span>
                  }
            }
            protected void cleanup(Context context)throws IOException, InterruptedException
            {
                  String str = <span class="hljs-string">"beijing"</span><span class="hljs-comment">;</span>
                  context<span class="hljs-preprocessor">.write</span>(new Text(str),new LongWritable(sum))<span class="hljs-comment">;</span>
            }
    }
    public static class MyReducer extends Reducer&lt;Text, LongWritable, Text, LongWritable&gt;
    {
            protected void reduce(Text k2, Iterable&lt;LongWritable&gt; v2s,Context context)throws IOException, InterruptedException
            {
                  for (LongWritable v2 : v2s)
                 {
                     context<span class="hljs-preprocessor">.write</span>(k2, v2)<span class="hljs-comment">;</span>
                 }
            }   
    }   
}</code></pre>

<p>MapReduce程序代码运行结果如下： <br>
<img src="https://img-blog.csdn.net/20160522172138924" alt="这里写图片描述" title=""> <br>
从运行结果可以看出：在consumer.txt业务表中，北京的客户共有三位。下面我们将用Hive来实现相同的功能，即统计业务表consumer.txt中北京的客户有多少位？ <br>
Hive操作如下： <br>
<img src="https://img-blog.csdn.net/20161109114127945" alt="这里写图片描述" title=""> <br>
Hive运行结果如下：</p>



<pre class="prettyprint"><code class=" hljs livecodeserver">OK
beijing <span class="hljs-number">3</span>
Time taken: <span class="hljs-number">19.768</span> <span class="hljs-built_in">seconds</span>, Fetched: <span class="hljs-number">1</span> row(s)</code></pre>

<p>到这里，是不是感觉Hive这个运行框架很神奇—–对于相同的业务逻辑只需要写几行Sql命令就可以获取我们所需要的结果，这也恰恰是Hive为什么这么流行的原因，Hive的优势主要体现在： <br>
①Hive支持标准的SQL语法，免去了用户编写MapReduce程序的过程，大大减少了公司的开发成本 <br>
②Hive的出现可以让那些精通SQL技能、但是不熟悉MapReduce 、编程能力较弱与不擅长Java语言的用户能够在HDFS大规模数据集上很方便地利用SQL 语言查询、汇总、分析数据，毕竟精通SQL语言的人要比精通Java语言的多得多 <br>
③Hive是为大数据批量处理而生的，Hive的出现解决了传统的关系型数据库(MySql、Oracle)在大数据处理上的瓶颈 <br>
       好了，上面通过一个简单的小业务场景说明了Hive的巨大优势，接下来将进入本篇文章的正题。 <br>
（一）Hive体系结构(架构)的介绍 <br>
1、Hive的概念： <br>
①Hive是为了简化用户编写MapReduce程序而生成的一种框架，使用MapReduce做过数据分析的人都知道，很多分析程序除业务逻辑不同外，程序流程基本一样。在这种情况下，就需要Hive这样的用户编程接口。Hive提供了一套类SQL的查询语言，称为QL，而在创造Hive框架的过程中之所以使用SQL实现Hive是因为大家对SQL语言非常的熟悉，转换成本低，可以大大普及我们Hadoop用户使用的范围，类似作用的Pig就不是通过SQL实现的。 <br>
Hive是基于Hadoop的一个开源数据仓库系统，可以将结构化的数据文件映射为一张数据库表，并提供完整的sql查询功能，Hive可以把SQL中的表、字段转换为HDFS中的目录、文件。 <br>
②Hive是建立在Hadoop之上的数据仓库基础构架、是为了减少MapReduce编写工作的批处理系统，Hive本身不存储和计算数据，它完全依赖于HDFS和MapReduce。Hive可以理解为一个客户端工具，将我们的sql操作转换为相应的MapReduce jobs，然后在Hadoop上面运行。 <br>
在开始为大家列举的consumer.txt小业务当中，从编写Sql到最后得出Beijing  3的分析结果实际上中间走的是MapReduce程序， 只不过这个MapReduce程序不用用户自己编写，而是由Hive这个客户端工具将我们的sql操作转化为了相应的MapReduce程序，下面是我们运行sql命令时显示的相关日志：</p>



<pre class="prettyprint"><code class=" hljs lasso">hive<span class="hljs-subst">&gt;</span> <span class="hljs-keyword">select</span> city,count(<span class="hljs-subst">*</span>)
    <span class="hljs-subst">&gt;</span> from t4    
    <span class="hljs-subst">&gt;</span> <span class="hljs-keyword">where</span> city<span class="hljs-subst">=</span><span class="hljs-string">'beijing'</span>
    <span class="hljs-subst">&gt;</span> <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> city;
Total MapReduce jobs <span class="hljs-subst">=</span> <span class="hljs-number">1</span>
Launching Job <span class="hljs-number">1</span> out of <span class="hljs-number">1</span>
Number of reduce tasks <span class="hljs-literal">not</span> specified<span class="hljs-built_in">.</span> Estimated from input <span class="hljs-built_in">data</span> size: <span class="hljs-number">1</span>
<span class="hljs-keyword">In</span> <span class="hljs-keyword">order</span> <span class="hljs-keyword">to</span> change the <span class="hljs-keyword">average</span> load for a reducer (<span class="hljs-keyword">in</span> <span class="hljs-built_in">bytes</span>):
  <span class="hljs-built_in">set</span> hive<span class="hljs-built_in">.</span>exec<span class="hljs-built_in">.</span>reducers<span class="hljs-built_in">.</span><span class="hljs-built_in">bytes</span><span class="hljs-built_in">.</span>per<span class="hljs-built_in">.</span>reducer<span class="hljs-subst">=&lt;</span>number<span class="hljs-subst">&gt;</span>
<span class="hljs-keyword">In</span> <span class="hljs-keyword">order</span> <span class="hljs-keyword">to</span> limit the maximum number of reducers:
  <span class="hljs-built_in">set</span> hive<span class="hljs-built_in">.</span>exec<span class="hljs-built_in">.</span>reducers<span class="hljs-built_in">.</span><span class="hljs-keyword">max</span><span class="hljs-subst">=&lt;</span>number<span class="hljs-subst">&gt;</span>
<span class="hljs-keyword">In</span> <span class="hljs-keyword">order</span> <span class="hljs-keyword">to</span> <span class="hljs-built_in">set</span> a constant number of reducers:
  <span class="hljs-built_in">set</span> mapred<span class="hljs-built_in">.</span>reduce<span class="hljs-built_in">.</span>tasks<span class="hljs-subst">=&lt;</span>number<span class="hljs-subst">&gt;</span>
Starting Job <span class="hljs-subst">=</span> job_1478233923484_0902, Tracking URL <span class="hljs-subst">=</span> http:<span class="hljs-comment">//hadoop22:8088/proxy/application_1478233923484_0902/</span>
Kill Command <span class="hljs-subst">=</span> /usr/<span class="hljs-built_in">local</span>/hadoop/bin/hadoop job  <span class="hljs-attribute">-kill</span> job_1478233923484_0902
Hadoop job information for Stage<span class="hljs-subst">-</span><span class="hljs-number">1</span>: number of mappers: <span class="hljs-number">1</span>; number of reducers: <span class="hljs-number">1</span>
<span class="hljs-number">2016</span><span class="hljs-subst">-</span><span class="hljs-number">11</span><span class="hljs-subst">-</span><span class="hljs-number">09</span> <span class="hljs-number">11</span>:<span class="hljs-number">36</span>:<span class="hljs-number">36</span>,<span class="hljs-number">688</span> Stage<span class="hljs-subst">-</span><span class="hljs-number">1</span> <span class="hljs-built_in">map</span> <span class="hljs-subst">=</span> <span class="hljs-number">0</span><span class="hljs-subst">%</span>,  reduce <span class="hljs-subst">=</span> <span class="hljs-number">0</span><span class="hljs-subst">%</span>
<span class="hljs-number">2016</span><span class="hljs-subst">-</span><span class="hljs-number">11</span><span class="hljs-subst">-</span><span class="hljs-number">09</span> <span class="hljs-number">11</span>:<span class="hljs-number">36</span>:<span class="hljs-number">42</span>,<span class="hljs-number">018</span> Stage<span class="hljs-subst">-</span><span class="hljs-number">1</span> <span class="hljs-built_in">map</span> <span class="hljs-subst">=</span> <span class="hljs-number">100</span><span class="hljs-subst">%</span>,  reduce <span class="hljs-subst">=</span> <span class="hljs-number">0</span><span class="hljs-subst">%</span>, Cumulative CPU <span class="hljs-number">1.21</span> sec
<span class="hljs-number">2016</span><span class="hljs-subst">-</span><span class="hljs-number">11</span><span class="hljs-subst">-</span><span class="hljs-number">09</span> <span class="hljs-number">11</span>:<span class="hljs-number">36</span>:<span class="hljs-number">43</span>,<span class="hljs-number">062</span> Stage<span class="hljs-subst">-</span><span class="hljs-number">1</span> <span class="hljs-built_in">map</span> <span class="hljs-subst">=</span> <span class="hljs-number">100</span><span class="hljs-subst">%</span>,  reduce <span class="hljs-subst">=</span> <span class="hljs-number">0</span><span class="hljs-subst">%</span>, Cumulative CPU <span class="hljs-number">1.21</span> sec
<span class="hljs-number">2016</span><span class="hljs-subst">-</span><span class="hljs-number">11</span><span class="hljs-subst">-</span><span class="hljs-number">09</span> <span class="hljs-number">11</span>:<span class="hljs-number">36</span>:<span class="hljs-number">44</span>,<span class="hljs-number">105</span> Stage<span class="hljs-subst">-</span><span class="hljs-number">1</span> <span class="hljs-built_in">map</span> <span class="hljs-subst">=</span> <span class="hljs-number">100</span><span class="hljs-subst">%</span>,  reduce <span class="hljs-subst">=</span> <span class="hljs-number">0</span><span class="hljs-subst">%</span>, Cumulative CPU <span class="hljs-number">1.21</span> sec
<span class="hljs-number">2016</span><span class="hljs-subst">-</span><span class="hljs-number">11</span><span class="hljs-subst">-</span><span class="hljs-number">09</span> <span class="hljs-number">11</span>:<span class="hljs-number">36</span>:<span class="hljs-number">45</span>,<span class="hljs-number">149</span> Stage<span class="hljs-subst">-</span><span class="hljs-number">1</span> <span class="hljs-built_in">map</span> <span class="hljs-subst">=</span> <span class="hljs-number">100</span><span class="hljs-subst">%</span>,  reduce <span class="hljs-subst">=</span> <span class="hljs-number">0</span><span class="hljs-subst">%</span>, Cumulative CPU <span class="hljs-number">1.21</span> sec
<span class="hljs-number">2016</span><span class="hljs-subst">-</span><span class="hljs-number">11</span><span class="hljs-subst">-</span><span class="hljs-number">09</span> <span class="hljs-number">11</span>:<span class="hljs-number">36</span>:<span class="hljs-number">46</span>,<span class="hljs-number">193</span> Stage<span class="hljs-subst">-</span><span class="hljs-number">1</span> <span class="hljs-built_in">map</span> <span class="hljs-subst">=</span> <span class="hljs-number">100</span><span class="hljs-subst">%</span>,  reduce <span class="hljs-subst">=</span> <span class="hljs-number">0</span><span class="hljs-subst">%</span>, Cumulative CPU <span class="hljs-number">1.21</span> sec
<span class="hljs-number">2016</span><span class="hljs-subst">-</span><span class="hljs-number">11</span><span class="hljs-subst">-</span><span class="hljs-number">09</span> <span class="hljs-number">11</span>:<span class="hljs-number">36</span>:<span class="hljs-number">47</span>,<span class="hljs-number">237</span> Stage<span class="hljs-subst">-</span><span class="hljs-number">1</span> <span class="hljs-built_in">map</span> <span class="hljs-subst">=</span> <span class="hljs-number">100</span><span class="hljs-subst">%</span>,  reduce <span class="hljs-subst">=</span> <span class="hljs-number">0</span><span class="hljs-subst">%</span>, Cumulative CPU <span class="hljs-number">1.21</span> sec
<span class="hljs-number">2016</span><span class="hljs-subst">-</span><span class="hljs-number">11</span><span class="hljs-subst">-</span><span class="hljs-number">09</span> <span class="hljs-number">11</span>:<span class="hljs-number">36</span>:<span class="hljs-number">48</span>,<span class="hljs-number">283</span> Stage<span class="hljs-subst">-</span><span class="hljs-number">1</span> <span class="hljs-built_in">map</span> <span class="hljs-subst">=</span> <span class="hljs-number">100</span><span class="hljs-subst">%</span>,  reduce <span class="hljs-subst">=</span> <span class="hljs-number">0</span><span class="hljs-subst">%</span>, Cumulative CPU <span class="hljs-number">1.21</span> sec
<span class="hljs-number">2016</span><span class="hljs-subst">-</span><span class="hljs-number">11</span><span class="hljs-subst">-</span><span class="hljs-number">09</span> <span class="hljs-number">11</span>:<span class="hljs-number">36</span>:<span class="hljs-number">49</span>,<span class="hljs-number">329</span> Stage<span class="hljs-subst">-</span><span class="hljs-number">1</span> <span class="hljs-built_in">map</span> <span class="hljs-subst">=</span> <span class="hljs-number">100</span><span class="hljs-subst">%</span>,  reduce <span class="hljs-subst">=</span> <span class="hljs-number">100</span><span class="hljs-subst">%</span>, Cumulative CPU <span class="hljs-number">3.7</span> sec
<span class="hljs-number">2016</span><span class="hljs-subst">-</span><span class="hljs-number">11</span><span class="hljs-subst">-</span><span class="hljs-number">09</span> <span class="hljs-number">11</span>:<span class="hljs-number">36</span>:<span class="hljs-number">50</span>,<span class="hljs-number">384</span> Stage<span class="hljs-subst">-</span><span class="hljs-number">1</span> <span class="hljs-built_in">map</span> <span class="hljs-subst">=</span> <span class="hljs-number">100</span><span class="hljs-subst">%</span>,  reduce <span class="hljs-subst">=</span> <span class="hljs-number">100</span><span class="hljs-subst">%</span>, Cumulative CPU <span class="hljs-number">3.7</span> sec
MapReduce Total cumulative CPU time: <span class="hljs-number">3</span> seconds <span class="hljs-number">700</span> msec
Ended Job <span class="hljs-subst">=</span> job_1478233923484_0902
MapReduce Jobs Launched: 
Job <span class="hljs-number">0</span>: <span class="hljs-built_in">Map</span>: <span class="hljs-number">1</span>  Reduce: <span class="hljs-number">1</span>   Cumulative CPU: <span class="hljs-number">3.7</span> sec   HDFS Read: <span class="hljs-number">419</span> HDFS Write: <span class="hljs-number">10</span> SUCCESS
Total MapReduce CPU Time Spent: <span class="hljs-number">3</span> seconds <span class="hljs-number">700</span> msec
OK
beijing <span class="hljs-number">3</span>
Time taken: <span class="hljs-number">19.768</span> seconds, Fetched: <span class="hljs-number">1</span> row(s)</code></pre>

<p>从日志可以看出，Hive将我们的sql命令解析成了相应的MapReduce任务，最后得到了我们的分析结果。 <br>
③Hive可以认为是MapReduce的一个封装、包装。Hive的意义就是在业务分析中将用户容易编写、会写的Sql语言转换为复杂难写的MapReduce程序，从而大大降低了Hadoop学习的门槛，让更多的用户可以利用Hadoop进行数据挖掘分析。 <br>
       为了让大家容易理解Hive的实质——-“Hive就是一个SQL解析引擎，将SQL语句转化为相应的MapReduce程序”这句话，博主用一个图示进行示例： <br>
<img src="https://img-blog.csdn.net/20160523094118859" alt="这里写图片描述" title=""> <br>
从图示可以看出，Hive从某种程度上讲就是很多“SQL—MapReduce”框架的一个封装，可以将用户编写的Sql语言解析成对应的MapReduce程序，最终通过MapReduce运算框架形成运算结果提交给Client。 <br>
2、Hive体系结构的介绍 <br>
下面是Hive的体系结构图： <br>
<img src="https://img-blog.csdn.net/20160523104110689" alt="这里写图片描述" title=""> <br>
Hive的体系结构可以分为以下几个部分： <br>
①用户接口：包括shell命令、Jdbc/Odbc和WebUi，其中最常用的是shell这个客户端方式对Hive进行相应操作 <br>
②Hive解析器(驱动Driver)：Hive解析器的核心功能就是根据用户编写的Sql语法匹配出相应的MapReduce模板，形成对应的MapReduce job进行执行。 <br>
③Hive元数据库(MetaStore)：Hive将表中的元数据信息存储在数据库中，如derby(自带的)、Mysql(实际工作中配置的)，Hive中的元数据信息包括表的名字、表的列和分区、表的属性(是否为外部表等)、表的数据所在的目录等。Hive中的解析器在运行的时候会读取元数据库MetaStore中的相关信息。 <br>
在这里和大家说一下为什么我们在实际业务当中不用Hive自带的数据库derby，而要重新为其配置一个新的数据库Mysql，是因为derby这个数据库具有很大的局限性：derby这个数据库不允许用户打开多个客户端对其进行共享操作，只能有一个客户端打开对其进行操作，即同一时刻只能有一个用户使用它，自然这在工作当中是很不方便的，所以我们要重新为其配置一个数据库。 <br>
④Hadoop：Hive用HDFS进行存储，用MapReduce进行计算——-Hive这个数据仓库的数据存储在HDFS中，业务实际分析计算是利用MapReduce执行的。 <br>
      从上面的体系结构中可以看出，在Hadoop的HDFS与MapReduce以及MySql的辅助下，Hive其实就是利用Hive解析器将用户的SQl语句解析成对应的MapReduce程序而已，即Hive仅仅是一个客户端工具，这也是为什么我们在Hive的搭建过程中没有分布与伪分布搭建的原因。(Hive就像是刘邦一样，合理的利用了张良、韩信与萧何的辅助，从而成就了一番大事!) <br>
3、Hive的运行机制 <br>
Hive的运行机制如下图所示： <br>
<img src="https://img-blog.csdn.net/20160523142553377" alt="这里写图片描述" title=""> <br>
Hive的运行机制正如图所示：创建完表之后，用户只需要根据业务需求编写Sql语句，而后将由Hive框架将Sql语句解析成对应的MapReduce程序，通过MapReduce计算框架运行job，便得到了我们最终的分析结果。 <br>
       在Hive的运行过程中，用户只需要创建表、导入数据、编写Sql分析语句即可，剩下的过程将由Hive框架自动完成，而创建表、导入数据、编写Sql分析语句其实就是数据库的知识了，Hive的运行过程也说明了为什么Hive的存在大大降低了Hadoop的学习门槛以及为什么Hive在Hadoop家族中占有着那么重要的地位。 <br>
（二）Hive的操作 <br>
Hive的操作对于用户来说实际上就是表的操作、数据库的操作。下面我们将围绕两个方面进行介绍： <br>
1、Hive表——内部表、外部表、分区表的创建</p>

<p>所谓内部表就是普通表，创建语法格式为： <br>
<img src="https://img-blog.csdn.net/20161109112526243" alt="这里写图片描述" title=""> <br>
实际操作: <br>
<img src="https://img-blog.csdn.net/20161109191018203" alt="这里写图片描述" title=""></p>

<p>外部表(external  table)的创建语法格式为： <br>
<img src="https://img-blog.csdn.net/20161109112757984" alt="这里写图片描述" title=""> <br>
注意：最后一行写到的是目录dir，文件就不用写了，Hive表会自动到dir目录下读取所有的文件file <br>
<strong>我在实际的操作过程当中发现，location关联到的目录下面必须都是文件，不能含有其余的文件夹，不然读取数据的时候会报错。</strong> <br>
<img src="https://img-blog.csdn.net/20170427151323324?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYTIwMTE0ODAxNjk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
实际操作: <br>
<img src="https://img-blog.csdn.net/20161109191443438" alt="这里写图片描述" title=""></p>

<p>内部表与外部表的区别： <br>
内部表在加载数据的过程中，实际数据会被移动到数据仓库目录中(hive.metastore.warehouse.dir),之后用户对数据的访问将会直接在数据仓库目录中完成；删除内部表时，内部表中的数据和元数据信息会被同时删除。 <br>
外部表在加载数据的过程中，实际数据并不会被移动到数据仓库目录中，只是与外部表建立一个链接(相当于文件的快捷方式一样)；删除外部表时，仅删除该链接。 <br>
补充：在工作中发现，对于外部表，即使hive中的表删除了，但是在HDFS中表的location仍然存在。 <br>
分区表的概念：指的是我们的数据可以分区，即按照某个字段将文件划分为不同的标准，分区表的创建是通过在创建表时启用partitioned   by来实现的。</p>

<p>分区表的创建语法格式为： <br>
<img src="https://img-blog.csdn.net/20161109112950890" alt="这里写图片描述" title=""> <br>
注意：分区表在加载数据的过程中要指定分区字段，否则会报错，正确的加载方式如下： <br>
load data local inpath ‘/usr/local/consumer.txt’ into table t1 partition (day=2) ; <br>
其余的操作和内部表、外部表是一样的。 <br>
实际操作: <br>
<img src="https://img-blog.csdn.net/20161109192250223" alt="这里写图片描述" title=""> <br>
2、将数据文件加载(导入)到Hive表中 <br>
在Hive中创建完表之后，我们随后自然要向表中导入数据，但是在导入数据的时候和我们的传统数据库(MySql、Oracle)是不同的：Hive不支持一条一条的用insert语句进行插入操作，也不支持update的操作。Hive表中的数据是以load的方式，加载到建立好的表中。数据一旦导入，则不可修改。要么drop掉整个表，要么建立新的表，导入新的数据。 <br>
导入数据的语法格式为： <br>
<img src="https://img-blog.csdn.net/20161109213539363" alt="这里写图片描述" title=""> <br>
导入数据时要注意一下几点： <br>
①local inpath表示从本地linux中向Hive表中导入数据，inpath表示从HDFS中向Hive表中导入数据 <br>
②默认是向原Hive表中追加数据，overwrite表示覆盖表中的原数据进行导入 <br>
③partition是分区表特有的，而且在导入数据数据时是必须添加的，否则会报错 <br>
④load 操作只是单纯的复制/移动操作，将数据文件复制/移动到 Hive 表对应的位置,即Hive 在加载数据的过程中不会对数据本身进行任何修改，而只是将数据内容复制或者移动到相应的表中</p>

<p>（三）Hive与Hbase的区别 <br>
其实从严格意义上讲，Hive与Hbase就不应该谈区别，谈区别的原因无非就是Hive与Hbase本身都涉及到了表的创建、向表中插入数据等等。所以我们希望找到Hive与Hbase的区别，但是为什么两者谈不上区别呢，原因如下： <br>
1、根据上文分析，Hive从某种程度上讲就是很多“SQL—MapReduce”框架的一个封装，即Hive就是MapReduce的一个封装，Hive的意义就是在业务分析中将用户容易编写、会写的Sql语言转换为复杂难写的MapReduce程序。 <br>
2、Hbase可以认为是hdfs的一个包装。他的本质是数据存储，是个NoSql数据库；hbase部署于hdfs之上，并且克服了hdfs在随机读写方面的缺点。 <br>
因此若要问Hive与Hbase之前的区别，就相当于问HDFS与MapReduce之间的区别，而HDFS与MapReduce两者之间谈区别意义并不大。 <br>
但是当我们非要谈Hbase与Hive的区别时，可以从以下几个方面进行讨论： <br>
      Hive和Hbase是两种基于Hadoop的不同技术–Hive是一种类SQL的引擎，并且运行MapReduce任务，Hbase是一种在Hadoop之上的NoSQL 的Key/vale数据库。当然，这两种工具是可以同时使用的。就像用Google来搜索，用FaceBook进行社交一样，Hive可以用来进行统计查询，HBase可以用来进行实时查询，数据也可以从Hive写到Hbase，设置再从Hbase写回Hive。 <br>
      Hive适合用来对一段时间内的数据进行分析查询，例如，用来计算趋势或者网站的日志。Hive不应该用来进行实时的查询。因为它需要很长时间才可以返回结果。 <br>
      Hbase非常适合用来进行大数据的实时查询。Facebook用Hive进行消息和实时的分析。它也可以用来统计Facebook的连接数。 <br>
      Hbase与Hive的区别就谈到此，同时Hive入门笔记也写到此处，如有问题欢迎留言。</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>