---
layout:     post
title:      Flume 基础知识
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h3 id="1-flume-简介">1. Flume 简介</h3>

<blockquote>
  <p>Flume 是一个分布式的海量日志采集，聚合，转移工具。</p>
</blockquote>

<p>大数据常用数据处理框架</p>

<pre class="prettyprint"><code class=" hljs brainfuck"><span class="hljs-comment">graph</span> <span class="hljs-comment">LR</span>
<span class="hljs-comment">实时流数据采集</span><span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">flume</span><span class="hljs-string">,</span><span class="hljs-comment">kafka</span>
<span class="hljs-comment">实时流数据处理</span><span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">spark</span><span class="hljs-string">,</span><span class="hljs-comment">storm</span>
<span class="hljs-comment">实时数据查询处理</span><span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">impala</span>
<span class="hljs-comment">批数据导入导出</span><span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt;<span class="hljs-comment">Sqoop</span>
<span class="hljs-comment">批数据查询处理</span><span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">hive</span>
</code></pre>

<p>这里只是给flume一个定位，清楚flume适合做哪方面的数据处理。</p>

<p><strong>即：flume是基于数据流的组件来实现分布式的数据采集</strong></p>

<p>flume使用简单，仅需写一个配置文件，即可完成一个分布式，高可用，可靠的实时数据流采集任务。</p>



<h3 id="2数据流模型">2.数据流模型</h3>

<p><img src="http://ok7mrfi5x.bkt.clouddn.com/flume01.png" alt="Data Flow Model" title=""></p>

<p>重要概念：</p>

<ul>
<li>event:被定义为flume数据传输的基本单元，有消息头和消息体组成。</li>
<li>flow：指数据从源头到目的地的数据迁移过程。</li>
<li>Agent:一个独立的Flume进程，包含组件Source,Channel,Sink.(Agent使用JVM运行flume,每台机器运行一个agent,但可以在一个agent中包含多个sources和sinks)</li>
<li>Source:数据搜集组件。(source从client收集数据，传递给Channel)</li>
<li>Channel:连接source和Sink,类似一个队列</li>
<li>Sink:从Channel 中读取并移除event,将数据写到下一个目标源，可以是下一个source，也可以是HDFS。</li>
</ul>

<p><strong>Flume运行的核心是Agent.Flume以agent为最小的独立运行单位。一个agent包含三个核心组件，source,channel,sink.</strong></p>



<h4 id="21-source">2.1 Source</h4>

<ul>
<li>Source 负责数据的收集，将数据捕捉后进行处理，封装成event,传递给Channel。Flume提供了很多内置的source,支持Avro,log4j,syslog和http post,还支持自定义Source。</li>
</ul>

<p>这里主要看下Avro,Spooling,Netcat，kafka</p>

<table>
<thead>
<tr>
  <th>Source类型</th>
  <th>说明</th>
</tr>
</thead>
<tbody><tr>
  <td>Avro</td>
  <td>支持avro 协议</td>
</tr>
<tr>
  <td>Spooling</td>
  <td>监听本地文件夹，把新增的文件采集到flume</td>
</tr>
<tr>
  <td>netcat</td>
  <td>从网络端口接受文本数据（多用于测试调试）</td>
</tr>
<tr>
  <td>kafka</td>
  <td>用于从kafka中读取数据</td>
</tr>
</tbody></table>




<h4 id="22-channel">2.2 Channel</h4>

<ul>
<li>Channel 是连接Source和Sink的组件，可以看做是一个数据的缓冲区，可以将数据暂存到内存中也可以持久化到本地磁盘上，直到Sink处理完该事件。比较常用的是Memory和File 两种类型的Channel.</li>
</ul>

<table>
<thead>
<tr>
  <th>Channel类型</th>
  <th>说明</th>
</tr>
</thead>
<tbody><tr>
  <td>Memory</td>
  <td>Event 数据存储在内存中</td>
</tr>
<tr>
  <td>File</td>
  <td>Event数据存储在磁盘文件中</td>
</tr>
</tbody></table>




<h4 id="23-sink">2.3 Sink</h4>

<ul>
<li>Sink从Channel中取出event,然后将数据发送到别处，可以是另一个agent的Source，或HDFS。</li>
</ul>

<table>
<thead>
<tr>
  <th>Sink 类型</th>
  <th>说明</th>
</tr>
</thead>
<tbody><tr>
  <td>logger</td>
  <td>把数据输出成logger日志(测试调试)</td>
</tr>
<tr>
  <td>hdfs</td>
  <td>把数据写入hdfs</td>
</tr>
<tr>
  <td>avro</td>
  <td>发送到此接收器的flume event将转化为avro event 并发送至配置的主机名：端口号</td>
</tr>
<tr>
  <td>kafka</td>
  <td>将数据发送至kafka</td>
</tr>
</tbody></table>


<hr>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>