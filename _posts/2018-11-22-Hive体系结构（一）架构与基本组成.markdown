---
layout:     post
title:      Hive体系结构（一）架构与基本组成
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<blockquote>
  <p><a href="http://blog.csdn.net/lnho2015/article/details/51383717" rel="nofollow">Hive体系结构（一）架构与基本组成</a> <br>
  <a href="http://blog.csdn.net/lnho2015/article/details/51417880" rel="nofollow">Hive体系结构（二）Hive的执行原理、与关系型数据库的比较</a> <br>
  <a href="http://blog.csdn.net/lnho2015/article/details/51417996" rel="nofollow">Hive体系结构（三）元数据库与基本操作</a> <br>
  <a href="http://blog.csdn.net/lnho2015/article/details/51418125" rel="nofollow">Hive体系结构（四）注意事项与扩展特性</a></p>
</blockquote>

<h1 id="1-hive的体系结构划分">1 Hive的体系结构划分</h1>

<p>下面是Hive的架构图： <br>
<img src="https://img-blog.csdn.net/20160515164528242" alt="Hive架构图" title=""> <br>
1. 用户接口主要有三个：CLI，Client 和 WUI。其中最常用的是CLI，Cli启动的时候，会同时启动一个Hive副本。Client是Hive的客户端，用户连接至Hive Server。在启动 Client模式的时候，需要指出Hive Server所在节点，并且在该节点启动Hive Server。 WUI是通过浏览器访问Hive。 <br>
2. Hive将元数据存储在数据库中，如mysql、derby。Hive中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。 <br>
3. 解释器、编译器、优化器完成HQL查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在HDFS中，并在随后有MapReduce调用执行。 <br>
4. Hive的数据存储在HDFS中，大部分的查询、计算由MapReduce完成（包含*的查询，比如select * from tbl不会生成MapRedcue任务）。</p>



<h1 id="2-连接到数据库的模式">2 连接到数据库的模式</h1>



<h2 id="21-单用户模式">2.1 单用户模式</h2>

<p>此模式连接到一个In-memory 的数据库Derby，一般用于Unit Test。 <br>
<img src="https://img-blog.csdn.net/20160515164608055" alt="单用户模式" title=""></p>



<h2 id="22-多用户模式">2.2 多用户模式</h2>

<p>通过网络连接到一个数据库中，是最经常使用到的模式。 <br>
<img src="https://img-blog.csdn.net/20160515164635681" alt="多用户模式" title=""></p>



<h2 id="23-远程服务器模式">2.3 远程服务器模式</h2>

<p>用于非Java客户端访问元数据库，在服务器端启动MetaStoreServer，客户端利用Thrift协议通过MetaStoreServer访问元数据库。 <br>
<img src="https://img-blog.csdn.net/20160515164656462" alt="远程服务器模式" title=""></p>



<h1 id="3-hive的数据模型">3 Hive的数据模型</h1>

<p>对于数据存储，Hive没有专门的数据存储格式，也没有为数据建立索引，用户可以非常自由的组织Hive中的表，只需要在创建表的时候告诉Hive数据中的列分隔符和行分隔符，Hive就可以解析数据。</p>

<p>Hive中所有的数据都存储在HDFS中，存储结构主要包括数据库、文件、表和视图。</p>

<p>Hive中包含以下数据模型：Table内部表，External Table外部表，Partition分区，Bucket桶。Hive默认可以直接加载文本文件，还支持sequence file 、RCFile。</p>



<h2 id="31-hive数据库">3.1 Hive数据库</h2>

<p>类似传统数据库的DataBase，在第三方数据库里实际是一张表。简单示例命令行 <code>hive &gt; create database test_database;</code></p>



<h2 id="32-内部表">3.2 内部表</h2>

<p>Hive的内部表与数据库中的Table在概念上是类似。每一个Table在Hive中都有一个相应的目录存储数据。例如一个表pvs，它在HDFS中的路径为<code>/wh/pvs</code>，其中wh是在hive-site.xml中由<code>${hive.metastore.warehouse.dir}</code> 指定的数据仓库的目录，所有的Table数据（不包括External Table）都保存在这个目录中。删除表时，元数据与数据都会被删除。</p>

<p>内部表简单示例：</p>



<pre class="prettyprint"><code class=" hljs sql">创建数据文件：test_inner_table.txt
创建表：<span class="hljs-operator"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> test_inner_table (<span class="hljs-keyword">key</span> string)
加载数据：<span class="hljs-keyword">LOAD</span> DATA <span class="hljs-keyword">LOCAL</span> INPATH <span class="hljs-string">'filepath'</span> <span class="hljs-keyword">INTO</span> <span class="hljs-keyword">TABLE</span> test_inner_table
查看数据：<span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> test_inner_table;</span>  <span class="hljs-operator"><span class="hljs-keyword">select</span> <span class="hljs-aggregate">count</span>(*) <span class="hljs-keyword">from</span> test_inner_table
删除表：<span class="hljs-keyword">drop</span> <span class="hljs-keyword">table</span> test_inner_table</span></code></pre>



<h2 id="33-外部表">3.3 外部表</h2>

<p>外部表指向已经在HDFS中存在的数据，可以创建Partition。它和内部表在元数据的组织上是相同的，而实际数据的存储则有较大的差异。内部表的创建过程和数据加载过程这两个过程可以分别独立完成，也可以在同一个语句中完成，在加载数据的过程中，实际数据会被移动到数据仓库目录中；之后对数据对访问将会直接在数据仓库目录中完成。删除表时，表中的数据和元数据将会被同时删除。而外部表只有一个过程，加载数据和创建表同时完成（CREATE EXTERNAL TABLE ……LOCATION），实际数据是存储在LOCATION后面指定的 HDFS 路径中，并不会移动到数据仓库目录中。当删除一个External Table时，仅删除该链接。</p>

<p>外部表简单示例：</p>



<pre class="prettyprint"><code class=" hljs sql">创建数据文件：test_external_table.txt
创建表：<span class="hljs-operator"><span class="hljs-keyword">create</span> <span class="hljs-keyword">external</span> <span class="hljs-keyword">table</span> test_external_table (<span class="hljs-keyword">key</span> string)
加载数据：<span class="hljs-keyword">LOAD</span> DATA INPATH ‘filepath’ <span class="hljs-keyword">INTO</span> <span class="hljs-keyword">TABLE</span> test_inner_table
查看数据：<span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> test_external_table;</span>  
<span class="hljs-operator"><span class="hljs-keyword">select</span> <span class="hljs-aggregate">count</span>(*) <span class="hljs-keyword">from</span> test_external_table
删除表：<span class="hljs-keyword">drop</span> <span class="hljs-keyword">table</span> test_external_table</span></code></pre>



<h2 id="34-分区">3.4 分区</h2>

<p>Partition对应于数据库中的Partition列的密集索引，但是Hive中Partition的组织方式和数据库中的很不相同。在Hive中，表中的一个Partition对应于表下的一个目录，所有的Partition的数据都存储在对应的目录中。</p>

<p>例如pvs表中包含ds和city两个Partition，则对应于ds = 20090801, ctry = US 的HDFS子目录为/wh/pvs/ds=20090801/ctry=US；对应于 ds = 20090801, ctry = CA 的HDFS子目录为/wh/pvs/ds=20090801/ctry=CA。</p>

<p>分区表简单示例：</p>



<pre class="prettyprint"><code class=" hljs sql">创建数据文件：test_partition_table.txt
创建表：<span class="hljs-operator"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> test_partition_table (<span class="hljs-keyword">key</span> string) partitioned <span class="hljs-keyword">by</span> (dt string)
加载数据：<span class="hljs-keyword">LOAD</span> DATA INPATH <span class="hljs-string">'filepath'</span> <span class="hljs-keyword">INTO</span> <span class="hljs-keyword">TABLE</span> test_partition_table partition (dt=<span class="hljs-string">'2006'</span>)
查看数据：<span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> test_partition_table;</span>  <span class="hljs-operator"><span class="hljs-keyword">select</span> <span class="hljs-aggregate">count</span>(*) <span class="hljs-keyword">from</span> test_partition_table
删除表：<span class="hljs-keyword">drop</span> <span class="hljs-keyword">table</span> test_partition_table</span></code></pre>



<h2 id="35-桶">3.5 桶</h2>

<p>Buckets是将表的列通过Hash算法进一步分解成不同的文件存储。它对指定列计算hash，根据hash值切分数据，目的是为了并行，每一个Bucket对应一个文件。</p>

<p>例如将user列分散至32个bucket，首先对user列的值计算hash，对应hash值为0的HDFS目录为/wh/pvs/ds=20090801/ctry=US/part-00000；hash值为20的HDFS目录为/wh/pvs/ds=20090801/ctry=US/part-00020。如果想应用很多的Map任务这样是不错的选择。</p>

<p>桶的简单示例：</p>



<pre class="prettyprint"><code class=" hljs sql">创建数据文件：test_bucket_table.txt
创建表：<span class="hljs-operator"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> test_bucket_table (<span class="hljs-keyword">key</span> string) clustered <span class="hljs-keyword">by</span> (<span class="hljs-keyword">key</span>) <span class="hljs-keyword">into</span> <span class="hljs-number">20</span> buckets
加载数据：<span class="hljs-keyword">LOAD</span> DATA INPATH <span class="hljs-string">'filepath'</span> <span class="hljs-keyword">INTO</span> <span class="hljs-keyword">TABLE</span> test_bucket_table
查看数据：<span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> test_bucket_table;</span>  
<span class="hljs-operator"><span class="hljs-keyword">set</span> hive.enforce.bucketing = <span class="hljs-keyword">true</span>;</span></code></pre>



<h2 id="36-hive的视图">3.6 Hive的视图</h2>

<p>视图与传统数据库的视图类似。视图是只读的，它基于的基本表，如果改变，数据增加不会影响视图的呈现；如果删除，会出现问题。</p>

<p>如果不指定视图的列，会根据select语句后的生成。 <br>
示例：</p>



<pre class="prettyprint"><code class=" hljs sql"><span class="hljs-operator"><span class="hljs-keyword">create</span> <span class="hljs-keyword">view</span> test_view <span class="hljs-keyword">as</span> <span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> test</span></code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>