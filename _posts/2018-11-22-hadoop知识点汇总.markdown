---
layout:     post
title:      hadoop知识点汇总
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h3 id="一hadoop的主要模块">一、Hadoop的主要模块</h3>

<ul>
<li>Hadoop Common: 基础模块</li>
<li>Hadoop Distributed File System (HDFS): 分布式文件系统</li>
<li>Hadoop YARN:hadoop的资源管理平台[Yet Another Resource Negotiator，另一种资源协调者]</li>
<li><p>Hadoop MapReduce: 一个分布式的并行计算框架.</p>

<pre><code>主要分两步：map阶段和reduce阶段
map:运行在多台服务器上进行计算
reduce：默认运行在一台 机器中，对map运行的结果进行合并分析
</code></pre></li>
</ul>

<h4 id="1hdfs架构存储数据">1、HDFS架构：存储数据</h4>

<ul>
<li>NameNode:存放元数据[数据的基本属性]</li>
<li>DataNode:存放具体文件数据</li>
<li><p>SecondaryNameNode:辅助NameNode的</p>

<pre><code>注意：采用备份机制保证数据的安全性，并且文件按块存放，默认每块的大小为128M 
</code></pre></li>
</ul>



<h4 id="2yarn架构资源管理平台在hadoop1x中没有的这是hadoop2x与hadoop1x最大的区别">2、YARN架构:资源管理平台[在hadoop1.x中没有的，这是hadoop2.x与hadoop1.x最大的区别]</h4>

<ul>
<li>ResourceManager：资源管理节点</li>
<li>NodeManager：数据处理节点</li>
<li>Container:资源对象封装</li>
<li><p>Application Master:当前job的管理者</p>

<pre><code>注意：每一个job都需要通过RM分配资源并且将资源对象封装成Container,然后RM选择一个NM启动App Mstr，App Mstr负责该job的运行过程，并将最后的执行结果汇报给RM
</code></pre></li>
</ul>

<h3 id="二hdfs架构">二、HDFS架构</h3>

<p><img src="https://img-blog.csdn.net/20171110135719458?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjg5MDYyNjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<ol>
<li>主从架构【NameNode/DataNodes】</li>
<li>NameNode存放元数据【文件名、文件的存放位置、文件的副本个数。。。】</li>
<li>DataNode存放数据【以块的形式进行存储，默认每个块的大小为128M】,真正响应客户端读取数的</li>
<li>在一个HDFS文件系统中一般NameNode只有一个，DataNode可以存在多个，并且每一个服务器中只启动对应一个进程.</li>
<li>DataNode会周期性的向NameNode发送心跳机制、NameNode管理文件和DataNode服务的对应关系(内存)</li>
<li>NameNode整个集群的访问入口、会监听DataNode节点的存活状态(DataNode <br>
3秒钟发送一次，10分钟如果NameNode接受不到某一个DataNode节点心跳信息，那么NameNode就</li>
<li><p>认为该DataNode节点失效，NameNode就需要将该DataNode节点中数据进行备份)。一个数据块在DataNode以文件存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳</p>

<pre><code>/opt/modules/hadoop-2.5.0/data/dfs/data/current/BP-1950595699-192.168.17.100-1487039906884/current/finalized
hdfs的DataNode中数据在物理磁盘中的具体存储位置
</code></pre></li>
<li><p>副本存放策略</p>

<pre><code>1. 第一个副本存放在本机架某一个DataNode节点中
2. 第二个副本放在同一个机架的另外一个DataNode节点中
3. 第三副本放在另外一个机架的节点中
4. 客户端读取数据的原则：就近原则
5. 机架感知(RackAwareness)
</code></pre></li>
</ol>

<h3 id="三namenode启动流程">三、NameNOde启动流程</h3>

<p><img src="https://img-blog.csdn.net/20171110151654745?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjg5MDYyNjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<ol>
<li>Name启动的时候首先将fsimage（镜像）载入内存，并执行（replay）编辑日志editlog的的各项操作；</li>
<li>一旦在内存中建立文件系统元数据映射，则创建一个新的fsimage文件（这个过程不需SecondaryNameNode）和一个空的editlog；</li>
<li>在安全模式下，各个datanode会向namenode发送块列表的最新情况；</li>
<li>此刻namenode运行在安全模式。即NameNode的文件系统对于客服端来说是只读的。(显示目录，显示文件内容等。写、删除、重命名都会失败)；</li>
<li>NameNode开始监听RPC和HTTP请求 <br>
**解释RPC:**RPC（Remote Procedure Call Protocol）——远程过程通过协议，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议；</li>
<li>系统中数据块的位置并不是由namenode维护的，而是以块列表形式存储在datanode中；</li>
<li>在系统的正常操作期间，namenode会在内存中保留所有块信息的映射信息。</li>
</ol>



<h4 id="namenode存放元数据">NameNode存放元数据</h4>

<pre><code>** fsimage  文件系统的镜像
** edits    编辑日志
    客户端操作文件的一些行为：put get cat rmr ...
</code></pre>

<ol>
<li><p>加载fsimage，并重新执行edits文件，然后加载到内存中</p>

<ul><li>如果edits文件比较大的话，合并会非常耗费时间</li>
<li>解决办法：SecondaryNameNode【时间、大小】</li></ul></li>
<li>产生一个新的fsimage和edits</li>
<li>等待DataNode注册与发送Block Report</li>
<li><p>SencondayNameNode</p>

<pre><code>1. 辅助NameNode,进行fsimage和edits文件合并
2. 避免NameNode下一期重启fsimage和edits文件合并时间过长的问题
3. SencodaryNameNode不是NameNode的热备
</code></pre></li>
</ol>

<h3 id="四yarn架构剖析hadoop2x版本">四、YARN架构剖析【hadoop2.x版本】</h3>

<p><img src="https://img-blog.csdn.net/20171110152228167?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjg5MDYyNjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<ol>
<li><p>ResourceManager</p>

<ol><li>接受客户端的请求【./bin/yarn jar xxx.jar wordcount /input  /output】</li>
<li>启动、监控[ApplicationMaster]</li>
<li>监控NodeManager</li>
<li>资源分配和任务调度</li></ol></li>
<li><p>NodeManager</p>

<ol><li>单个节点上的资源管理</li>
<li>处理来自ResourceManager的命令</li>
<li>处理来自ApplicationMaster的命令</li></ol></li>
<li><p>ApplicationMaster[AM]</p>

<ol><li>当前任务的管理者,任务运行结束后自动消失</li>
<li>数据切分</li>
<li>为当前程序申请资源，并分配给内部任务</li>
<li>任务的监控和容错</li></ol></li>
<li><p>Container</p>

<ul><li>对当前任务运行环境的一个抽象，封装了CPU、内存、网络带宽等等和任务相关的信息</li></ul></li>
</ol>

<p><img src="https://img-blog.csdn.net/20171110152904358?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjg5MDYyNjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>



<h3 id="五mapreduce的运行流程">五、MapReduce的运行流程</h3>

<p><img src="https://img-blog.csdn.net/20171110153004543?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjg5MDYyNjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
1. client向集群提交一个 job任务，ResourceManager接收到任务请求 <br>
2. ResourceManager接收到该任务请求后，选择一台NodeManager启动一个ApplicationMaster <br>
3. ApplicationMaster向ResourceManager申请资源（运行当前任务需要哪些NodeManager、每一个NodeManager需要多少CPU、内存） <br>
4. ResourceManager把对应的资源信息响应给 ApplicationMaster <br>
5. ApplicationMaster收到后，调度指挥其他NodeManager运行任务 <br>
6. 相关NodeManager接收任务并运行(Map\Reduce) <br>
7. NodeManager运行结束后会向ApplicationManater汇报 <br>
8. ApplicationMaster向ResourceManager报告，并将结果反馈给Client</p>



<h4 id="hadoop读文件流程">hadoop读文件流程</h4>

<p><img src="https://img-blog.csdn.net/20171110153400876?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjg5MDYyNjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
1. 打开分布式文件 <br>
  调用 分布式文件 DistributedFileSystem.open()方法 <br>
2. 从 NameNode 获得 DataNode 地址 <br>
  DistributedFileSystem 使用 RPC 调用 NameNode，NameNode   返回存有该副本的 DataNode 地址，DistributedFileSystem 返  回一个输入流 FSDataInputStream对象，该对象封存了输入流   DFSInputStream <br>
3. 连接到DataNode <br>
  调用 输入流 FSDataInputStream 的 read() 方法，从而   输入流 DFSInputStream 连接 DataNodes <br>
4. 读取DataNode <br>
  反复调用 read()方法，从而将数据从 DataNode   传输到客户端 <br>
5. 读取另外的DataNode直到完成 <br>
  到达块的末端时候，输入流 DFSInputStream 关闭与DataNode 连接，       寻找下一个 DataNode <br>
6. 完成读取，关闭连接 <br>
  即调用输入流 FSDataInputStream.close()</p>

<h4 id="hadoop写文件流程">hadoop写文件流程</h4>

<p><img src="https://img-blog.csdn.net/20171110153924280?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjg5MDYyNjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
1. 发送创建文件请求：调用分布式文件系统DistributedFileSystem.create()方法 <br>
2. NameNode中创建文件记录：分布式文件系统DistributedFileSystem 发送 RPC 请求给namenode，namenode 检查权限后创建一条记录，返回输出流 FSDataOutputStream，封装了输出流 DFSOutputDtream <br>
3. 客户端写入数据：输出流 DFSOutputDtream 将数据分成一个个的数据包，并写入内部队列。DataStreamer 根据 DataNode 列表来要求 namenode 分配适合的新块来存储数据备份。一组DataNode 构成管线(管线的 DataNode 之间使用 Socket 流式通信) <br>
4. 使用管线传输数据：DataStreamer 将数据包流式传输到管线第一个DataNode，第一个DataNode 再传到第二个DataNode ,直到完成。 <br>
5. 确认队列：DataNode 收到数据后发送确认，管线的DataNode所有的确认组成一个确认队列。所有DataNode 都确认，管线数据包删除。 <br>
6. 关闭：客户端对数据量调用close（）方法。将剩余所有数据写入DataNode管线，并联系NameNode且发送文件写入完成信息之前等待确认。 <br>
7. NameNode确认</p>

<pre><code>故障处理：
    若过程中发生故障，则先关闭管线， 把队列中所有数据包添加回去队列，确保数据包不漏。为另一个正常DataNode的当前数据块指定一个新的标识，并将该标识传送给NameNode, 一遍故障DataNode在恢复后删除上面的不完整数据块. 从管线中删除故障DataNode 并把余下的数据块写入余下正常的DataNode。NameNode发现复本两不足时，会在另一个节点创建一个新的复本
</code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>