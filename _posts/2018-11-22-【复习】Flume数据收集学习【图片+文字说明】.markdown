---
layout:     post
title:      【复习】Flume数据收集学习【图片+文字说明】
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>一.Hadoop业务的整体框架流程介绍 </p>

<p><img alt="" class="has" src="https://img-blog.csdn.net/20180731120142883?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d5cXdpbGxpYW0=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>

<p>以上是hadoop整体的一个开发流程，我们可以看出flume在整个大数据开发过程中的位置：做最前期数据的收集工作。</p>

<p>二.Flume架构介绍</p>

<p><img alt="" class="has" src="https://img-blog.csdn.net/20180731122252451?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d5cXdpbGxpYW0=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>

<p>本文将围绕Flume的架构、Flume的应用(日志采集)进行详细的介绍：</p>

<p> flume是分布式的日志收集系统，它将各个服务器中的数据收集起来并送到指定的地方去，比如说送到图中的HDFS，简单来说flume就是收集日志的。</p>

<p>三.Event数据流向图</p>

<p><img alt="" class="has" src="https://img-blog.csdn.net/2018073112351260?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d5cXdpbGxpYW0=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>

<p>flume的核心是把数据从数据源(source)收集过来，在将收集到的数据送到指定的目的地(sink)。为了保证输送的过程一定成功，在送到目的地(sink)之前，会先缓存数据(channel),待数据真正到达目的地(sink)后，flume在删除自己缓存的数据。 <br>
在整个数据的传输的过程中，流动的是event，即事务保证是在event级别进行的。那么什么是event呢？—–event将传输的数据进行封装，是flume传输数据的基本单位，如果是文本文件，通常是一行记录，event也是事务的基本单位。event从source，流向channel，再到sink，本身为一个字节数组，并可携带headers(头信息)信息。event代表着一个数据的最小完整单元，从外部数据源来，向外部的目的地去。 </p>

<p>一个完整的event包括：event headers、event body、event信息(即文本文件中的单行记录。</p>

<p>flume架构介绍 <br>
flume之所以这么神奇，是源于它自身的一个设计，这个设计就是agent，agent本身是一个java进程，运行在日志收集节点—所谓日志收集节点就是服务器节点。 <br>
agent里面包含3个核心的组件：source—-&gt;channel—–&gt;sink,类似生产者、仓库、消费者的架构。 <br>
source：source组件是专门用来收集数据的，可以处理各种类型、各种格式的日志数据,包括avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy、自定义。 <br>
channel：source组件把数据收集来以后，临时存放在channel中，即channel组件在agent中是专门用来存放临时数据的——对采集到的数据进行简单的缓存，可以存放在memory、jdbc、file等等。 <br>
sink：sink组件是用于把数据发送到目的地的组件，目的地包括hdfs、logger、avro、thrift、ipc、file、null、hbase、solr、自定义。 <br>
flume的运行机制 <br>
flume的核心就是一个agent，这个agent对外有两个进行交互的地方，一个是接受数据的输入——source，一个是数据的输出sink，sink负责将数据发送到外部指定的目的地。source接收到数据之后，将数据发送给channel，chanel作为一个数据缓冲区会临时存放这些数据，随后sink会将channel中的数据发送到指定的地方—-例如HDFS等，注意：只有在sink将channel中的数据成功发送出去之后，channel才会将临时数据进行删除，这种机制保证了数据传输的可靠性与安全性。</p>

<blockquote>
<p>二、Flume 的 一些核心概念：</p>
</blockquote>

<table><thead><tr><th>组件名称</th>
			<th>功能介绍</th>
		</tr></thead><tbody><tr><td>Agent代理</td>
			<td>使用JVM 运行Flume。每台机器运行一个agent，但是可以在一个agent中包含多个sources和sinks。</td>
		</tr><tr><td>Client客户端</td>
			<td>生产数据，运行在一个独立的线程。</td>
		</tr><tr><td>Source源</td>
			<td>从Client收集数据，传递给Channel。</td>
		</tr><tr><td>Sink接收器</td>
			<td>从Channel收集数据，进行相关操作，运行在一个独立线程。</td>
		</tr><tr><td>Channel通道</td>
			<td>连接 sources 和 sinks ，这个有点像一个队列。</td>
		</tr><tr><td>Events事件</td>
			<td>传输的基本数据负载。</td>
		</tr></tbody></table><p><br>
谢谢您的鼓励！</p>

<p><img alt="" class="has" src="https://img-blog.csdn.net/20180731162417203?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d5cXdpbGxpYW0=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>            </div>
                </div>