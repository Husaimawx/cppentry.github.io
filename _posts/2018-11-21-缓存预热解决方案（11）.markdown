---
layout:     post
title:      缓存预热解决方案（11）
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h1 id="一基于nginxlua完成商品详情页访问流量实时上报kafka的开发">一、基于nginx+lua完成商品详情页访问流量实时上报kafka的开发</h1>

<p>在nginx这一层，接收到访问请求的时候，就把请求的流量上报发送给kafka</p>

<p>这样的话，storm才能去消费kafka中的实时的访问日志，然后去进行缓存热数据的统计</p>

<p>用得技术方案非常简单，从lua脚本直接创建一个kafka producer，发送数据到kafka</p>

<pre class="prettyprint"><code class=" hljs avrasm">wget https://github<span class="hljs-preprocessor">.com</span>/doujiang24/lua-resty-kafka/archive/master<span class="hljs-preprocessor">.zip</span>

yum install -<span class="hljs-built_in">y</span> unzip

unzip lua-resty-kafka-master<span class="hljs-preprocessor">.zip</span>

<span class="hljs-keyword">cp</span> -rf /usr/local/lua-resty-kafka-master/lib/resty /usr/hello/lualib

nginx -s reload

local cjson = require(<span class="hljs-string">"cjson"</span>)  
local producer = require(<span class="hljs-string">"resty.kafka.producer"</span>)  

local broker_list = {  
    { host = <span class="hljs-string">"192.168.31.187"</span>, port = <span class="hljs-number">9092</span> },  
    { host = <span class="hljs-string">"192.168.31.19"</span>, port = <span class="hljs-number">9092</span> },  
    { host = <span class="hljs-string">"192.168.31.227"</span>, port = <span class="hljs-number">9092</span> }
}

local log_json = {}  
log_json[<span class="hljs-string">"headers"</span>] = ngx<span class="hljs-preprocessor">.req</span><span class="hljs-preprocessor">.get</span>_headers()  
log_json[<span class="hljs-string">"uri_args"</span>] = ngx<span class="hljs-preprocessor">.req</span><span class="hljs-preprocessor">.get</span>_uri_args()  
log_json[<span class="hljs-string">"body"</span>] = ngx<span class="hljs-preprocessor">.req</span><span class="hljs-preprocessor">.read</span>_body()  
log_json[<span class="hljs-string">"http_version"</span>] = ngx<span class="hljs-preprocessor">.req</span><span class="hljs-preprocessor">.http</span>_version()  
log_json[<span class="hljs-string">"method"</span>] =ngx<span class="hljs-preprocessor">.req</span><span class="hljs-preprocessor">.get</span>_method() 
log_json[<span class="hljs-string">"raw_reader"</span>] = ngx<span class="hljs-preprocessor">.req</span><span class="hljs-preprocessor">.raw</span>_header()  
log_json[<span class="hljs-string">"body_data"</span>] = ngx<span class="hljs-preprocessor">.req</span><span class="hljs-preprocessor">.get</span>_body_data()  

local message = cjson<span class="hljs-preprocessor">.encode</span>(log_json)<span class="hljs-comment">;  </span>

local productId = ngx<span class="hljs-preprocessor">.req</span><span class="hljs-preprocessor">.get</span>_uri_args()[<span class="hljs-string">"productId"</span>]

local async_producer = producer:new(broker_list, { producer_type = <span class="hljs-string">"async"</span> })   
local ok, err = async_producer:send(<span class="hljs-string">"access-log"</span>, productId, message)  

if not ok then  
    ngx<span class="hljs-preprocessor">.log</span>(ngx<span class="hljs-preprocessor">.ERR</span>, <span class="hljs-string">"kafka send err:"</span>, err)  
    return  
end</code></pre>

<p>两台机器上都这样做，才能统一上报流量到kafka</p>



<pre class="prettyprint"><code class=" hljs brainfuck"><span class="hljs-comment">bin/kafka</span><span class="hljs-literal">-</span><span class="hljs-comment">topics</span><span class="hljs-string">.</span><span class="hljs-comment">sh</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">zookeeper</span> <span class="hljs-comment">192</span><span class="hljs-string">.</span><span class="hljs-comment">168</span><span class="hljs-string">.</span><span class="hljs-comment">31</span><span class="hljs-string">.</span><span class="hljs-comment">187:2181</span><span class="hljs-string">,</span><span class="hljs-comment">192</span><span class="hljs-string">.</span><span class="hljs-comment">168</span><span class="hljs-string">.</span><span class="hljs-comment">31</span><span class="hljs-string">.</span><span class="hljs-comment">19:2181</span><span class="hljs-string">,</span><span class="hljs-comment">192</span><span class="hljs-string">.</span><span class="hljs-comment">168</span><span class="hljs-string">.</span><span class="hljs-comment">31</span><span class="hljs-string">.</span><span class="hljs-comment">227:2181</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">topic</span> <span class="hljs-comment">access</span><span class="hljs-literal">-</span><span class="hljs-comment">log</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">replication</span><span class="hljs-literal">-</span><span class="hljs-comment">factor</span> <span class="hljs-comment">1</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">partitions</span> <span class="hljs-comment">1</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">create</span>

<span class="hljs-comment">bin/kafka</span><span class="hljs-literal">-</span><span class="hljs-comment">console</span><span class="hljs-literal">-</span><span class="hljs-comment">consumer</span><span class="hljs-string">.</span><span class="hljs-comment">sh</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">zookeeper</span> <span class="hljs-comment">192</span><span class="hljs-string">.</span><span class="hljs-comment">168</span><span class="hljs-string">.</span><span class="hljs-comment">31</span><span class="hljs-string">.</span><span class="hljs-comment">187:2181</span><span class="hljs-string">,</span><span class="hljs-comment">192</span><span class="hljs-string">.</span><span class="hljs-comment">168</span><span class="hljs-string">.</span><span class="hljs-comment">31</span><span class="hljs-string">.</span><span class="hljs-comment">19:2181</span><span class="hljs-string">,</span><span class="hljs-comment">192</span><span class="hljs-string">.</span><span class="hljs-comment">168</span><span class="hljs-string">.</span><span class="hljs-comment">31</span><span class="hljs-string">.</span><span class="hljs-comment">227:2181</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">topic</span> <span class="hljs-comment">access</span><span class="hljs-literal">-</span><span class="hljs-comment">log</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">from</span><span class="hljs-literal">-</span><span class="hljs-comment">beginning</span></code></pre>

<p>（1）kafka在187上的节点死掉了，可能是虚拟机的问题，杀掉进程，重新启动一下</p>

<p>nohup bin/kafka-server-start.sh config/server.properties &amp;</p>

<p>（2）需要在nginx.conf中，http部分，加入resolver 8.8.8.8;</p>

<p>（3）需要在kafka中加入advertised.host.name = 192.168.31.187，重启三个kafka进程</p>

<p>（4）需要启动eshop-cache缓存服务，因为nginx中的本地缓存可能不在了</p>



<h1 id="二基于stormkafka完成商品访问次数实时统计拓扑的开发">二、基于storm+kafka完成商品访问次数实时统计拓扑的开发</h1>

<p>maven构建出的一些问题，直接从maven中央仓库可能下载不到jar包，自己去百度一下jar，下载下来</p>

<p>根据错误提示，拷贝到maven本地仓库对应的目录中去，然后手工安装一下</p>

<p>1、kafka consumer spout</p>

<p>单独的线程消费，写入队列</p>

<p>nextTuple，每次都是判断队列有没有数据，有的话再去获取并发射出去，不能阻塞</p>

<p>2、日志解析bolt</p>

<p>3、商品访问次数统计bolt</p>

<p>基于LRUMap完成统计</p>



<h1 id="三基于storm完成lrumap中topn热门商品列表的算法讲解与编写">三、基于storm完成LRUMap中topn热门商品列表的算法讲解与编写</h1>

<p><strong>topn list生成算法讲解</strong> <br>
<img src="//img-blog.csdn.net/20180319061103227?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L3FxMTEzNzYyMzE2MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
1、storm task启动的时候，基于分布式锁将自己的taskid累加到一个znode中</p>

<p>2、开启一个单独的后台线程，每隔1分钟算出top3热门商品list</p>

<p>3、每个storm task将自己统计出的热数据list写入自己对应的znode中</p>

<p>4、task初始化</p>

<p>5、热门商品list保存</p>



<h1 id="四基于双重zookeeper分布式锁完成分布式并行缓存预热的代码开发">四、基于双重zookeeper分布式锁完成分布式并行缓存预热的代码开发</h1>

<p>1、服务启动的时候，进行缓存预热</p>

<p>2、从zk中读取taskid列表</p>

<p>3、依次遍历每个taskid，尝试获取分布式锁，如果获取不到，快速报错，不要等待，因为说明已经有其他服务实例在预热了</p>

<p>4、直接尝试获取下一个taskid的分布式锁</p>

<p>5、即使获取到了分布式锁，也要检查一下这个taskid的预热状态，如果已经被预热过了，就不再预热了</p>

<p>6、执行预热操作，遍历productid列表，查询数据，然后写ehcache和redis</p>

<p>7、预热完成后，设置taskid对应的预热状态 <br>
代码地址：<a href="https://download.csdn.net/download/qq1137623160/10294323" rel="nofollow">https://download.csdn.net/download/qq1137623160/10294323</a></p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>