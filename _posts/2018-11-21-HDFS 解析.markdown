---
layout:     post
title:      HDFS 解析
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>介绍<br></p>
<p>         HDFS是Hadoop的存储组件，HDFS分布式文件系统是在Google 2003年发表的论文文件系统GFS（<a href="http://www.open-open.com/lib/view/open1328763454608.html" rel="nofollow">中文</a>）这篇论文后实现的。</p>
<p>HDFS的特点：</p>
<p>        HDFS利用超大数据块和数据局部性优化来减少网络输入/输出(I/O)</p>
<p>        可扩展性和可使用性</p>
<p>        HDFS按照配置的副本数（3个副本）复制文件，可容忍硬件和软件的错误，并能自动重新复制坏节点上的数据块</p>
<p><img src="https://img-blog.csdn.net/20151031194422544?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
<p>        Hadoop通过多个块存储文件，对每一个块而言，NameNode用于确定那个DataNode用于存储这个块数据。当确定块的DataNode后，NameNode开始尝试连接本地节点，如果客户端在DataNode上运行，节点按照以下顺序执行:</p>
<p>        1:本地磁盘：网络（I/O）代价昂贵，所以本地节点直接的网络阐述速度比跨机器的节点之间的网络传输速度要快</p>
<p>        2：本地机器：在一个机器中的节点之间的网络传输速度要比跨机器的节点之间的网络传输速度快</p>
<p>      HDFS通过管道完成副本写操作。当客户端收到来自NameNode的DataNode列表，客户端将块数据形成的数据流后传输给第一个DataNode（图上2），之后轮流将数据传输给下一个DataNode（图3）这样数据就达到了所有的DataNode（图4）最后一个DataNode执行完打包后，返回一个ack给前一个DataNode，直到达到客户端（5,6,7）。客户端收到所有的ack后，继续写下一个块。当每个DataNode完成本地快时，这些块将从临时存储转换为永久存储，并且每个DataNode异步通知存储这个块的NameNode。最后当所有块被写入之后，客户端关闭数据流，NameNode被告知它不许持久化与文件相关的快。（图8）</p>
<p><br></p>
<p>HFDS读取数据</p>
<p><img src="https://img-blog.csdn.net/20151031200208098?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
<p>HDFS读取文件的交互过程</p>
<p>          DFSClient包含于NameNode和DataNode通信相关的所有的客户端逻辑。当数据流传输到已经存在的HDFS文件被请求时，DFSClient创建一个DFSInputStream，DFSInputStream会从NameNOde获取文件前10个块的元数据（图1），对于每一个块，NameNode根据DataNode与客户端的远近来对DataNode进行排序；本地DataNode（在同一物理机器上）比远程DataNode有优势，</p>
<p>         当客户端接收到来之NameNode的块列表，它会从每个块挑选第一个DataNode，然后为那个DataNode开通一个数据流（图2），当库虎的请求数据流中的字节时，DFSInputStream紧接着会读取DataNode的数据流知道最后一个块（图3），之后关闭与当前DdataNode的连接，并在后面的DataNode重复同样的操作（图4， 5），如果文件比10个块大，他会请求NameNode获取接下来10个块信息（图 6），继续之前的操作，直到文件读取完毕<br></p>
            </div>
                </div>