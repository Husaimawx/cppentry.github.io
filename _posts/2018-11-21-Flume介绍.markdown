---
layout:     post
title:      Flume介绍
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                [b]一、	Flume系统简介[/b]<br>Flume是一个由Cloudera提供的分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。<br>Flume支持在日志系统中定制各类数据发送方，用于收集数据;同时，Flume提供对数据进行简单处理，并写到各种数据接受方(可定制)的能力<br>[b]二、	Flume系统基本组件[/b]<br>1、	Agent: <br>采集数据，agent是flume中产生数据流的地方<br>2、	Collector:<br>收集anent发送过来的数据，汇集更大的数据流<br>3、	Master:<br>负责管理数据流的配置，支持多master节点<br>4、	ZooKeeper:<br>保存配置数据，ZooKeeper本身可保证配置数据的一致性和高可用，另外，在配置数据发生变化时，ZooKeeper可以通知Flume Master节点<br>[b]三、	Flume运行机制[/b]<br><br>虚线代表的是节点间通信。作为收集日志的每个agent节点定期通过RPC方式向master节点发起心跳，master节点通过监听与回调处理RPC请求，并将配置的更改信息发送给agent，collector与master的通信原理与agent相同。<br>实线代表的是数据流的流向。Agent节点按照配置定期的收集日志并将数据发送给collect节点，collector节点可以接收多个anent节点的数据并按照配置中指定的时间间隔，将汇集后的数据流转到目标节点(通常是HDFS)。<br>上述流程中如果anent或者collector节点在指定的间隔时间内未能发送消息给master，master将其视为“死亡”，如果是collector A死亡，则master可以按照配置将collector A负责收集的 agent A agent B 两个节点的数据发送给collector B。<br>[b]四、	Flume安装介绍[/b]<br>1、	下载与hadoop匹配的flume-0.9.4-cdh3u2.tar.gz<br>2、	解压至某目录 (/d1/soft/flume)<br>3、	配置环境变量 （vim .bash_profile）\<br>在PATH末尾追加     :$FLUME_HOME/bin<br>添加变量             export FLUME_HOME=/d1/soft/flume<br>添加变量            export FLUME_CONF_DIR=$FLUME_HOME/conf<br>添加变量            export FLUME_LOG_DIR=$FLUME_HOME/log<br>添加变量            export FLUME_PID_DIR=$FLUME_HOME/pid<br>4、	配置flume-site.conf<br>	在flume集群各节点的$FLUME_HOME  的conf目录下新建flume-site.conf<br>	并加入如下值：<br>[i]&lt;?xml version="1.0"?&gt;<br>&lt;?xml-stylesheet type="text/xsl"  href="configuration.xsl"?&gt;<br>&lt;configuration&gt;<br><br>  &lt;property&gt;<br>    &lt;name&gt;flume.master.servers&lt;/name&gt;<br>    &lt;value&gt;h253018&lt;/value&gt;<br>    &lt;description&gt;This is the address for the config servers status<br>    server (http)<br>    &lt;/description&gt;<br>  &lt;/property&gt;<br>  &lt;property&gt;<br>    &lt;name&gt;flume.collector.event.host&lt;/name&gt;<br>    &lt;value&gt;h253017&lt;/value&gt;<br>    &lt;description&gt;This is the host name of the default "remote" collector. &lt;/description&gt;<br>  &lt;/property&gt;<br>  &lt;property&gt;<br>    &lt;name&gt;flume.collector.port&lt;/name&gt;<br>    &lt;value&gt;35853&lt;/value&gt;<br>    &lt;description&gt;This default tcp port that the collector listens to in order to receive events it is collecting.<br>    &lt;/description&gt;<br>  &lt;/property&gt;<br>&lt;property&gt;<br>  &lt;name&gt;flume.collector.output.format&lt;/name&gt;<br>    &lt;value&gt;raw&lt;/value&gt;<br>      &lt;description&gt;This default value is 'json'.<br>    &lt;/description&gt;<br>&lt;/property&gt;<br>&lt;/configuration&gt;[/i]<br><br>[b]五、	Flume启动[/b]<br>/d1/soft/flume/bin/flume-daemon.sh start master<br>/d1/soft/flume/bin/flume-daemon.sh start node -n collector<br>/d1/soft/flume/bin/flume-daemon.sh start node -n agent_16<br>/d1/soft/flume/bin/flume-daemon.sh start node -n agent_15<br>[b]六、	配置示例[/b]<br>配置前的环境介绍：<br>h253014 为非flume集群的hadoop节点master<br>h253018 为flume集群 master节点<br>h253017 为flume集群 collentor节点<br>h253016 为flume集群 agent节点<br>h253015 为flume集群 agent节点<br><br>通过页面配置如下：<br><br>agent_15 : tail("/tmp/flume_text") | agentSink;<br>agent_16 : tail("/tmp/flume_text") | agentSink;<br>collector : collectorSource | collectorSink("hdfs://h253014:9000/flume/","test_data");<br>[b]七、	Flume两种工作模式[/b]<br>1、	Push Sources：<br>外部系统会主动地将数据推送到Flume中，如RPC、syslog。<br>2、	Polling Sources：<br>Flume到外部系统中获取数据，一般使用轮询的方式，如text和exec。<br>注意，在Flume中，agent和collector对应，而source和sink对应。Source和sink强调发送、接受方的特性(如数据格式、编码等)，而agent和collector关注功能。<br>[b]八、	Source与Sink[/b]<br>Flume提供了从console(控制台)、RPC(Thrift-RPC)、text(文件)、tail(UNIX tail)、syslog(syslog日志系统，支持TCP和UDP等2种模式)，exec(命令执行)等数据源上收集数据的能力。同时，Flume的数据接受方，可以是console(控制台)、text(文件)、dfs(HDFS文件)、RPC(Thrift-RPC)和syslogTCP(TCP syslog日志系统)等。<br>[b]九、	Flume的几个特性[/b]<br>Reliability：<br>Flume提供3中数据可靠性选项，包括End-to-end、Store on failure和Best effort。其中End-to-end使用了磁盘日志和接受端Ack的方式，保证Flume接受到的数据会最终到达目的。Store on failure在目的不可用的时候，数据会保持在本地硬盘。和End-to-end不同的是，如果是进程出现问题，Store on failure可能会丢失部分数据。Best effort不做任何QoS保证。<br>Scalability：<br>Flume的3大组件：collector、master和storage tier都是可伸缩的。需要注意的是，Flume中对事件的处理不需要带状态，它的Scalability可以很容易实现。<br>Manageability：<br>Flume利用ZooKeeper和gossip，保证配置数据的一致性、高可用。同时，多Master，保证Master可以管理大量的节点。<br>Extensibility：<br>基于Java，用户可以为Flume添加各种新的功能，如通过继承Source，用户可以实现自己的数据接入方式，实现Sink的子类，用户可以将数据写往特定目标，同时，通过SinkDecorator，用户可以对数据进行一定的预处理。            </div>
                </div>