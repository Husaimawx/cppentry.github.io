---
layout:     post
title:      Spark简介
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/qustqustjay/article/details/46874071				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<h1><span style="font-size:10px;">详细内容参照Spark官网：http://spark.apache.org/</span></h1>
<h1>Spark<span style="font-family:'宋体';">相关项目：</span></h1>
<p><span></span>Spark SQL <span style="font-family:'宋体';">、</span><span style="font-family:'Times New Roman';">Spark Streaming </span><span style="font-family:'宋体';">、</span><span style="font-family:'Times New Roman';">Machine Learning </span><span style="font-family:'宋体';">、</span><span style="font-family:'Times New Roman';">GraphX</span></p>
<p>1、Spark SQL ：用<span style="font-family:'Times New Roman';">Spark</span><span style="font-family:'宋体';">编写的混合</span><span style="font-family:'Times New Roman';">SQL</span><span style="font-family:'宋体';">查询，能在分布式数据集中查询结构化数据，使得复杂分析算法的查询更容易。</span></p>
<p>2、Spark Streaming ：Spark Streaming <span style="font-family:'宋体';">容易去建立一个可扩展的容错式流媒体应用，使得流处理应用与批处理工作一样。</span></p>
<p>3、Machine Learning：Machine Learning Lib<span style="font-family:'宋体';">是</span><span style="font-family:'Times New Roman';">Apache</span><span style="font-family:'宋体';">的可扩展机器学习库，实现了一些机器学习算法，算法运行效率高，其实现的算法有：</span></p>
<p><span></span>基础：数据类型、概要统计<br><span></span>分类与回归：线性支持向量机（<span style="font-family:'Times New Roman';">SVM</span><span style="font-family:'宋体';">）、逻辑回归、线性最小二乘法、套索和岭回归、决策树、朴素贝叶斯</span></p>
<p><span></span>协同过滤：交替最小二乘法（<span style="font-family:'Times New Roman';">ALS</span><span style="font-family:'宋体';">）</span></p>
<p><span></span>聚类：<span style="font-family:'Times New Roman';">K-means</span></p>
<p><span></span>最优化：随即梯度下降法、<span style="font-family:'Times New Roman';">L-BFGS</span></p>
<p>4、GraphX：GraphX<span style="font-family:'宋体';">是对图标并行计算。</span></p>
<h1>Spark<span style="font-family:'宋体';">官网例子：</span></h1>
<p>1、Text Search<span style="font-family:'宋体';">：从日志文件中搜索错误</span></p>
<p>2、Word Count<span style="font-family:'宋体';">：统计单词</span></p>
<p>3、Estimateing PI<span style="font-family:'宋体';">：估计</span><span style="font-family:'Times New Roman';">PI</span><span style="font-family:'宋体';">值</span></p>
<p>4、Logical Regression<span style="font-family:'宋体';">：寻找一个超平面，在多维空间中区分点集</span><br></p>
<h1>Spark<span style="font-family:'宋体';">两种工作模式：</span></h1>
<p></p>
<p>1、Spark Shell<span style="font-family:'宋体';">：运用</span><span style="font-family:'Times New Roman';">scala</span><span style="font-family:'宋体';">命令交互式分析处理</span></p>
<p>2、在<span style="font-family:'Times New Roman';">scala</span><span style="font-family:'宋体';">中独立工作：编写完</span><span style="font-family:'Times New Roman';">scala</span><span style="font-family:'宋体';">程序后用工具</span><span style="font-family:'Times New Roman';">sbt</span><span style="font-family:'宋体';">将其打成</span><span style="font-family:'Times New Roman';">jar</span><span style="font-family:'宋体';">包，再运行。</span></p>
<p></p>
<h1>Spark<span style="font-family:'宋体';">的弹性分布式数据集</span><span style="font-family:'Times New Roman';">RDD</span><span style="font-family:'宋体';">：</span></h1>
1<span style="font-family:'宋体';">、并行集合：接收一个已经存在的</span><span style="font-family:'Times New Roman';">scala</span><span style="font-family:'宋体';">集合，然后进行各种并行计算；</span>
<p></p>
<p>2、Hadoop<span style="font-family:'宋体';">数据集：从</span><span style="font-family:'Times New Roman';">Hadoop</span><span style="font-family:'宋体';">的文件存储系统</span><span style="font-family:'Times New Roman';">HDFS</span><span style="font-family:'宋体';">中获取数据</span></p>
<h1>Spark<span style="font-family:'宋体';">对于数据集</span><span style="font-family:'Times New Roman';">RDD</span><span style="font-family:'宋体';">的两种操作</span>：转换和动作：</h1>
<p>1、transformations<span style="font-family:'宋体';">：从现有数据集上创建一个新的数据集，如</span><span style="font-family:'Times New Roman';">Map</span><span style="font-family:'宋体';">操作就是一种转换，另外还有</span><span style="font-family:'Times New Roman';">filter</span><span style="font-family:'宋体';">、</span><span style="font-family:'Times New Roman';">flatmap</span><span style="font-family:'宋体';">、</span><span style="font-family:'Times New Roman';">diatinct</span><span style="font-family:'宋体';">、</span><span style="font-family:'Times New Roman';">join</span><span style="font-family:'宋体';">等操作；</span></p>
<p>2、Action<span style="font-family:'宋体';">：在数据集上运行，并返回一个值给驱动程序，如</span><span style="font-family:'Times New Roman';">reduce</span><span style="font-family:'宋体';">操作就是一种动作，另外还有</span><span style="font-family:'Times New Roman';">collect</span><span style="font-family:'宋体';">（）、</span><span style="font-family:'Times New Roman';">count</span><span style="font-family:'宋体';">（）等</span></p>
<h1>Spark<span style="font-family:'宋体';">的两种共享变量</span>（该变量在不同节点任务上被共享）：</h1>
<p>1、广播变量：可在内存的所有节点上缓存变量</p>
<p>2、累加器：用于做加法的变量</p>
<h1><span style="font-size:24px;">Spark: Cluster Computing with Working Sets</span></h1>
<p><br>
 <span> </span><span style="font-size:18px;">Spark<span style="font-family:'宋体';">是一个集群计算工作集，能对大规模数据进行快速处理，和</span><span style="font-family:'Times New Roman';">Hadoop</span><span style="font-family:'宋体';">一样，对大量数据进行分布并行处理。实际上，</span><span style="font-family:'Times New Roman';">spark</span><span style="font-family:'宋体';">是对</span><span style="font-family:'Times New Roman';">Hadoop</span><span style="font-family:'宋体';">的补充，</span><span style="font-family:'Times New Roman';">spark</span><span style="font-family:'宋体';">在某些工作负载方面更加优越，应用性更广。它可以像操作本地集合对象一样轻松地操作分布式数据集，也可以在</span><span style="font-family:'Times New Roman';">Hadoop</span><span style="font-family:'宋体';">的文件系统</span><span style="font-family:'Times New Roman';">HDFS</span><span style="font-family:'宋体';">中并行运行。</span><span style="font-family:'Times New Roman';">Spark</span><span style="font-family:'宋体';">能更好的解决</span><span style="font-family:'Times New Roman';">Hadoop</span><span style="font-family:'宋体';">中不能实现的迭代计算和交互式计算问题。</span><span style="font-family:'Times New Roman';">Spark</span><span style="font-family:'宋体';">和</span><span style="font-family:'Times New Roman';">Hadoop</span><span style="font-family:'宋体';">最大的不同是</span><span style="font-family:'Times New Roman';">Spark</span><span style="font-family:'宋体';">可以重用存储在</span><span style="font-family:'Times New Roman';">cache</span><span style="font-family:'宋体';">中的数据，极大提高运行效率，而</span><span style="font-family:'Times New Roman';">Hadoop</span><span style="font-family:'宋体';">每次迭代都需要重新从硬盘读取数据。</span><span style="font-family:'Times New Roman';">Spark</span><span style="font-family:'宋体';">在迭代机器学习的算法时速度是</span><span style="font-family:'Times New Roman';">Hadoop</span><span style="font-family:'宋体';">的</span><span style="font-family:'Times New Roman';">10</span><span style="font-family:'宋体';">倍以上。</span></span></p>
<p></p>
<h1>一、Spark<span style="font-family:'宋体';">简介</span></h1>
<span></span><span style="font-size:18px;">Mapreduce<span style="font-family:'宋体';">编程模型实现他们的可扩展性和容错性是通过提供一个用户创建的编程模型，该编程模型操作的是无环数据流图。在大型应用程序中，无环数据流工作模式效率不高。</span><span style="font-family:'Times New Roman';">Spark</span><span style="font-family:'宋体';">可以通过多路并行操作重用工作集中的数据。</span></span>
<p></p>
<p><span style="font-size:18px;"><span></span>在下列两个用例中可以看出<span style="font-family:'Times New Roman';">spark</span><span style="font-family:'宋体';">比</span><span style="font-family:'Times New Roman';">mapreduce</span><span style="font-family:'宋体';">更有效：</span></span></p>
<p><span style="font-size:18px;"><span></span>1、迭代工作<br><span></span>很多机器学习算法需要在同一数据集上进行多次运算来寻找最优参数，<span style="font-family:'Times New Roman';">mapreduce</span><span style="font-family:'宋体';">每次运行都要从硬盘重新加载这些数据，而</span><span style="font-family:'Times New Roman';">spark</span><span style="font-family:'宋体';">可以重用这些数据。</span></span></p>
<p><span style="font-size:18px;"><span></span>2、迭代分析</span></p>
<p><span style="font-size:18px;"><span></span>在数据库查询时需要加载有用的数据，spark<span style="font-family:'宋体';">是把数据缓存</span>到内存，而mapreduce<span style="font-family:'宋体';">运行程序</span>是从硬盘上加载数据，导致很大的时间延迟。</span></p>
<p><span style="font-size:18px;"><span></span>Spark<span style="font-family:'宋体';">的一个主要抽象概念是</span><span style="font-family:'Times New Roman';">RDD(</span><span style="font-family:'宋体';">弹性数据集</span><span style="font-family:'Times New Roman';">)</span><span style="font-family:'宋体';">，</span><span style="font-family:'Times New Roman';">RDD</span><span style="font-family:'宋体';">是一个元素集合，</span>即spark<span style="font-family:'宋体';">操作的特殊格式的数据集。</span><span style="font-family:'Times New Roman';">RDD</span>划分到集群的各个节点上，用户可以明确的缓存<span style="font-family:'Times New Roman';">RDD</span><span style="font-family:'宋体';">到内存中，并可以重用这些数据集进行并行操作。</span><span style="font-family:'Times New Roman';">RDD</span><span style="font-family:'宋体';">通过一个称为</span><span style="font-family:'Times New Roman';">lineage</span><span style="font-family:'宋体';">的概念来实现数据集容错：如果</span><span style="font-family:'Times New Roman';">RDD</span><span style="font-family:'宋体';">中部分数据丢失，可以在其他</span><span style="font-family:'Times New Roman';">RDD</span><span style="font-family:'宋体';">中重建这部分数据。</span></span></p>
<p><span style="font-size:18px;"><span></span>目前有两种类型的<span style="font-family:'Times New Roman';">RDD</span><span style="font-family:'宋体';">：</span></span></p>
<p><span style="font-size:18px;"><span></span>1、并行集合（<span style="font-family:'Times New Roman';">Parallelized Collections</span><span style="font-family:'宋体';">）：</span>通过调用SparkContext<span style="font-family:'宋体';">的</span><span style="font-family:'Times New Roman';">parallelize</span><span style="font-family:'宋体';">方法，在一个已经存在的</span><span style="font-family:'Times New Roman';">scala</span><span style="font-family:'宋体';">集合上创建的集合，</span><span style="font-family:'Times New Roman';">scala</span><span style="font-family:'宋体';">集合的对象将会被拷贝，创建出一个可以被并行操作的分布式数据集</span><span style="font-family:'Times New Roman';">,</span>例：<span style="font-family:'Times New Roman';">val distData=sc.parallelize(data);</span><br><span></span>2<span style="font-family:'宋体';">、</span>Hadoop<span style="font-family:'宋体';">数据集（</span><span style="font-family:'Times New Roman';">Hadoop Datasets</span><span style="font-family:'宋体';">）： </span>Spark<span style="font-family:'宋体';">从</span><span style="font-family:'Times New Roman';">HDFS</span><span style="font-family:'宋体';">上创建的分布式数据集，</span>通过调用SparkContext<span style="font-family:'宋体';">的</span><span style="font-family:'Times New Roman';">textFile</span><span style="font-family:'宋体';">方法。</span>例：<span style="font-family:'Times New Roman';">val distFile=sc.textFile(</span>“hdfs://10.0.2.15:8080/user/input”)<span style="font-family:'宋体';">；</span></span></p>
<p><span style="font-size:18px;"><span></span>另外还有两种方式来创建RDD<span style="font-family:'宋体';">：</span></span></p>
<p><span style="font-size:18px;"><span></span>3、从已存在的<span style="font-family:'Times New Roman';">RDD</span><span style="font-family:'宋体';">中转换而来，通过</span><span style="font-family:'Times New Roman';">flatMap</span><span style="font-family:'宋体';">操作，把类型</span><span style="font-family:'Times New Roman';">A</span><span style="font-family:'宋体';">数据转换成类型</span><span style="font-family:'Times New Roman';">B</span><span style="font-family:'宋体';">数据；</span></span></p>
<p><span style="font-size:18px;"><span></span>4、RDD<span style="font-family:'宋体';">的持久化</span>：<span style="font-family:'Times New Roman';">Spark</span><span style="font-family:'宋体';">最重要的一个功能，就是在不同操作间，持久化（或缓存）一个数据集在内存中。当你持久化一个</span><span style="font-family:'Times New Roman';">RDD</span><span style="font-family:'宋体';">，每一个结点都将把它的计算分块结果保存在内存中，并在对此数据集（或者衍生出的数据集）进行的其它动作中重用。这将使得后续的动作</span><span style="font-family:'Times New Roman';">(Actions)</span><span style="font-family:'宋体';">变得更加迅速（通常快</span><span style="font-family:'Times New Roman';">10</span><span style="font-family:'宋体';">倍）。缓存是用</span><span style="font-family:'Times New Roman';">Spark</span><span style="font-family:'宋体';">构建迭代算法的关键。</span></span></p>
<p></p>
<h1>二、Spark<span style="font-family:'宋体';">的编程模型</span></h1>
<span></span><span style="font-size:18px;">应用<span style="font-family:'Times New Roman';">spark</span><span style="font-family:'宋体';">时，开发人员编写一个驱动程序来完成高级应用程序的控制流和发布各种并行操作</span>，实际上就是对分布式数据集进行操作。对于RDD<span style="font-family:'宋体';">的操作</span>，<span style="font-family:'Times New Roman';">spark</span><span style="font-family:'宋体';">提供了两个抽象概念：转换（</span><span style="font-family:'Times New Roman';">transformation</span><span style="font-family:'宋体';">）和动作</span><span style="font-family:'Times New Roman';">(action)</span><span style="font-family:'宋体';">，另外</span><span style="font-family:'Times New Roman';">spark</span><span style="font-family:'宋体';">有两种共享变量：广播变量和累加器。</span></span>
<p></p>
<h2>2.1 <span style="font-family:'宋体';">转换</span><span style="font-family:'Times New Roman';">transformation</span><span style="font-family:'宋体';">：</span></h2>
<p><span style="font-size:18px;"><span></span>对输入的数据集进行的格式上的转换，如表为一系列<span style="font-family:'Times New Roman';">transformation</span><span style="font-family:'宋体';">操作：</span></span></p>
<table><tbody><tr><td valign="top">
<p><span style="color:rgb(54,46,43);"> <span style="font-family:'宋体';">转换</span></span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">含义</span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">map</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">func</span><span style="color:rgb(54,46,43);">)</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">返回一个新分布式数据集，由每一个输入元素经过</span><span style="color:rgb(54,46,43);">func</span><span style="color:rgb(54,46,43);">函数转换后组成</span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">filter</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">func</span><span style="color:rgb(54,46,43);">)</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">返回一个新数据集，由经过</span><span style="color:rgb(54,46,43);">func</span><span style="color:rgb(54,46,43);">函数计算后返回值为<span style="font-family:Arial;">true</span><span style="font-family:'宋体';">的输入元素组成</span></span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">flatMap</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">func</span><span style="color:rgb(54,46,43);">)</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">类似于<span style="font-family:Arial;">map</span><span style="font-family:'宋体';">，但是每一个输入元素可以被映射为</span><span style="font-family:Arial;">0</span><span style="font-family:'宋体';">或多个输出元素（因此</span></span><span style="color:rgb(54,46,43);">func</span><span style="color:rgb(54,46,43);">应该返回一个序列，而不是单一元素）</span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">mapPartitions</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">func</span><span style="color:rgb(54,46,43);">)</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">类似于<span style="font-family:Arial;">map</span><span style="font-family:'宋体';">，但独立地在</span><span style="font-family:Arial;">RDD</span><span style="font-family:'宋体';">的每一个分块上运行，因此在类型为</span><span style="font-family:Arial;">T</span><span style="font-family:'宋体';">的</span><span style="font-family:Arial;">RDD</span><span style="font-family:'宋体';">上运行时，</span></span><span style="color:rgb(54,46,43);">func</span><span style="color:rgb(54,46,43);">的函数类型必须是<span style="font-family:Arial;">Iterator[T] =&gt; Iterator[U]</span></span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">mapPartitionsWithSplit</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">func</span><span style="color:rgb(54,46,43);">)</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">类似于<span style="font-family:Arial;">mapPartitions, </span><span style="font-family:'宋体';">但</span></span><span style="color:rgb(54,46,43);">func<span style="font-family:'宋体';">带有</span></span><span style="color:rgb(54,46,43);">一个整数参数表示分块的索引值。因此在类型为<span style="font-family:Arial;">T</span><span style="font-family:'宋体';">的</span><span style="font-family:Arial;">RDD</span><span style="font-family:'宋体';">上运行时，</span><span style="font-family:Arial;">func</span><span style="font-family:'宋体';">的函数类型必须是</span><span style="font-family:Arial;">(Int, Iterator[T]) =&gt; Iterator[U]</span></span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">sample</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">withReplacement</span><span style="color:rgb(54,46,43);">,</span><span style="color:rgb(54,46,43);">fraction</span><span style="color:rgb(54,46,43);">, </span><span style="color:rgb(54,46,43);">seed</span><span style="color:rgb(54,46,43);">)</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">根据</span><span style="color:rgb(54,46,43);">fraction</span><span style="color:rgb(54,46,43);">指定的比例，对数据进行采样，可以选择是否用随机数进行替换，<span style="font-family:Arial;">seed</span><span style="font-family:'宋体';">用于指定随机数生成器种子</span></span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">union</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">otherDataset</span><span style="color:rgb(54,46,43);">)</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">返回一个新的数据集，新数据集是由源数据集和参数数据集联合而成</span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">distinct</span><span style="color:rgb(54,46,43);">([</span><span style="color:rgb(54,46,43);">numTasks</span><span style="color:rgb(54,46,43);">]))</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">返回一个包含源数据集中所有不重复元素的新数据集</span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">groupByKey</span><span style="color:rgb(54,46,43);">([</span><span style="color:rgb(54,46,43);">numTasks</span><span style="color:rgb(54,46,43);">])</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">在一个（<span style="font-family:Arial;">K,V</span><span style="font-family:'宋体';">）对的数据集上调用，返回一个（</span><span style="font-family:Arial;">K</span><span style="font-family:'宋体';">，</span><span style="font-family:Arial;">Seq[V])</span><span style="font-family:'宋体';">对的数据集</span></span><span style="color:rgb(54,46,43);"><br></span><span style="color:rgb(54,46,43);">注意：</span><span style="color:rgb(54,46,43);">默认情况下，只有<span style="font-family:Arial;">8</span><span style="font-family:'宋体';">个并行任务来做操作，但是你可以传入一个可选的</span></span><span style="color:rgb(54,46,43);">numTasks</span><span style="color:rgb(54,46,43);">参数来改变它</span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">reduceByKey</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">func</span><span style="color:rgb(54,46,43);">, [</span><span style="color:rgb(54,46,43);">numTasks</span><span style="color:rgb(54,46,43);">])</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">在一个（<span style="font-family:Arial;">K</span><span style="font-family:'宋体';">，</span><span style="font-family:Arial;">V)</span><span style="font-family:'宋体';">对的数据集上调用时，返回一个（</span><span style="font-family:Arial;">K</span><span style="font-family:'宋体';">，</span><span style="font-family:Arial;">V</span><span style="font-family:'宋体';">）对的数据集，使用指定的</span></span><span style="color:rgb(54,46,43);">reduce</span><span style="color:rgb(54,46,43);">函数，将相同<span style="font-family:Arial;">key</span><span style="font-family:'宋体';">的值聚合到一起。类似</span></span><span style="color:rgb(54,46,43);">groupByKey</span><span style="color:rgb(54,46,43);">，</span><span style="color:rgb(54,46,43);">reduce</span><span style="color:rgb(54,46,43);">任务个数是可以通过第二个可选参数来配置的</span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">sortByKey</span><span style="color:rgb(54,46,43);">([</span><span style="color:rgb(54,46,43);">ascending</span><span style="color:rgb(54,46,43);">], [</span><span style="color:rgb(54,46,43);">numTasks</span><span style="color:rgb(54,46,43);">])</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">在一个（<span style="font-family:Arial;">K</span><span style="font-family:'宋体';">，</span><span style="font-family:Arial;">V)</span><span style="font-family:'宋体';">对的数据集上调用，</span><span style="font-family:Arial;">K</span><span style="font-family:'宋体';">必须实现</span><span style="font-family:Arial;">Ordered</span><span style="font-family:'宋体';">接口，返回一个按照</span><span style="font-family:Arial;">Key</span><span style="font-family:'宋体';">进行排序的（</span><span style="font-family:Arial;">K</span><span style="font-family:'宋体';">，</span><span style="font-family:Arial;">V</span><span style="font-family:'宋体';">）对数据集。升序或降序由</span></span><span style="color:rgb(54,46,43);">ascending</span><span style="color:rgb(54,46,43);">布尔参数决定</span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">join</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">otherDataset</span><span style="color:rgb(54,46,43);">, [</span><span style="color:rgb(54,46,43);">numTasks</span><span style="color:rgb(54,46,43);">])</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">在类型为（<span style="font-family:Arial;">K,V)</span><span style="font-family:'宋体';">和（</span><span style="font-family:Arial;">K,W)</span><span style="font-family:'宋体';">类型的数据集上调用时，返回一个相同</span><span style="font-family:Arial;">key</span><span style="font-family:'宋体';">对应的所有元素对在一起的</span><span style="font-family:Arial;">(K, (V, W))</span><span style="font-family:'宋体';">数据集</span></span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">cogroup</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">otherDataset</span><span style="color:rgb(54,46,43);">, [</span><span style="color:rgb(54,46,43);">numTasks</span><span style="color:rgb(54,46,43);">])</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">在类型为（<span style="font-family:Arial;">K,V)</span><span style="font-family:'宋体';">和（</span><span style="font-family:Arial;">K,W)</span><span style="font-family:'宋体';">的数据集上调用，返回一个</span><span style="font-family:Arial;"> (K, Seq[V], Seq[W])</span><span style="font-family:'宋体';">元组的数据集。这个操作也可以称之为</span></span><span style="color:rgb(54,46,43);">groupwith</span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">cartesian</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">otherDataset</span><span style="color:rgb(54,46,43);">)</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">笛卡尔积，在类型为 <span style="font-family:Arial;">T </span><span style="font-family:'宋体';">和 </span><span style="font-family:Arial;">U </span><span style="font-family:'宋体';">类型的数据集上调用时，返回一个</span><span style="font-family:Arial;"> (T, U)</span><span style="font-family:'宋体';">对数据集</span><span style="font-family:Arial;">(</span><span style="font-family:'宋体';">两两的元素对</span><span style="font-family:Arial;">)</span></span></p>
</td>
</tr></tbody></table><h2>2.2<span style="font-family:'宋体';">动作</span><span style="font-family:'Times New Roman';">action</span><span style="font-family:'宋体';">：</span></h2>
<p><span></span><span style="font-size:18px;">在转换完的数据集上进行的各种操作，返回结果给驱动程序，其操作有：<span style="font-family:'Times New Roman';">reduce()</span><span style="font-family:'宋体';">、</span><span style="font-family:'Times New Roman';">collect()</span><span style="font-family:'宋体';">、</span><span style="font-family:'Times New Roman';">foreach()</span><span style="font-family:'宋体';">等。</span></span></p>
<p><span style="font-size:18px;"><span></span>如表为一系列<span style="font-family:'Times New Roman';">action</span><span style="font-family:'宋体';">操作：</span></span></p>
<table><tbody><tr><td valign="top">
<p><span style="color:rgb(54,46,43);"> <span style="font-family:'宋体';">动作</span></span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">含义</span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">reduce</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">func</span><span style="color:rgb(54,46,43);">)</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">通过函数</span><span style="color:rgb(54,46,43);">func</span><span style="color:rgb(54,46,43);">（接受两个参数，返回一个参数）聚集数据集中的所有元素。这个功能必须可交换且可关联的，从而可以正确的被并行执行。</span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">collect</span><span style="color:rgb(54,46,43);">()</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">在驱动程序中，以数组的形式，返回数据集的所有元素。这通常会在使用<span style="font-family:Arial;">filter</span><span style="font-family:'宋体';">或者其它操作并返回一个足够小的数据子集后再使用会比较有用。</span></span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">count</span><span style="color:rgb(54,46,43);">()</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">返回数据集的元素的个数。</span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">first</span><span style="color:rgb(54,46,43);">()</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">返回数据集的第一个元素（类似于<span style="font-family:Arial;">take</span><span style="font-family:'宋体';">（</span><span style="font-family:Arial;">1</span><span style="font-family:'宋体';">））</span></span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">take</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">n</span><span style="color:rgb(54,46,43);">)</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">返回一个由数据集的前</span><span style="color:rgb(54,46,43);">n</span><span style="color:rgb(54,46,43);">个元素组成的数组。注意，这个操作目前并非并行执行，而是由驱动程序计算所有的元素</span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">takeSample</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">withReplacement</span><span style="color:rgb(54,46,43);">,</span><span style="color:rgb(54,46,43);">num</span><span style="color:rgb(54,46,43);">, </span><span style="color:rgb(54,46,43);">seed</span><span style="color:rgb(54,46,43);">)</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">返回一个数组，在数据集中随机采样</span><span style="color:rgb(54,46,43);">num</span><span style="color:rgb(54,46,43);">个元素组成，可以选择是否用随机数替换不足的部分，<span style="font-family:Arial;">Seed</span><span style="font-family:'宋体';">用于指定的随机数生成器种子</span></span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">saveAsTextFile</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">path</span><span style="color:rgb(54,46,43);">)</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">将数据集的元素，以<span style="font-family:Arial;">textfile</span><span style="font-family:'宋体';">的形式，保存到本地文件系统，</span><span style="font-family:Arial;">HDFS</span><span style="font-family:'宋体';">或者任何其它</span><span style="font-family:Arial;">hadoop</span><span style="font-family:'宋体';">支持的文件系统。对于每个元素，</span><span style="font-family:Arial;">Spark</span><span style="font-family:'宋体';">将会调用</span></span><span style="color:rgb(54,46,43);">toString</span><span style="color:rgb(54,46,43);">方法，将它转换为文件中的文本行</span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">saveAsSequenceFile</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">path</span><span style="color:rgb(54,46,43);">)</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">将数据集的元素，以<span style="font-family:Arial;">Hadoop sequencefile</span><span style="font-family:'宋体';">的格式，保存到指定的目录下，本地系统，</span><span style="font-family:Arial;">HDFS</span><span style="font-family:'宋体';">或者任何其它</span><span style="font-family:Arial;">hadoop</span><span style="font-family:'宋体';">支持的文件系统。这个只限于由</span><span style="font-family:Arial;">key-value</span><span style="font-family:'宋体';">对组成，并实现了</span><span style="font-family:Arial;">Hadoop</span><span style="font-family:'宋体';">的</span><span style="font-family:Arial;">Writable</span><span style="font-family:'宋体';">接口，或者隐式的可以转换为</span><span style="font-family:Arial;">Writable</span><span style="font-family:'宋体';">的</span><span style="font-family:Arial;">RDD</span><span style="font-family:'宋体';">。（</span><span style="font-family:Arial;">Spark</span><span style="font-family:'宋体';">包括了基本类型的转换，例如</span><span style="font-family:Arial;">Int</span><span style="font-family:'宋体';">，</span><span style="font-family:Arial;">Double</span><span style="font-family:'宋体';">，</span><span style="font-family:Arial;">String</span><span style="font-family:'宋体';">，等等）</span></span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">countByKey</span><span style="color:rgb(54,46,43);">()</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">对<span style="font-family:Arial;">(K,V)</span><span style="font-family:'宋体';">类型的</span><span style="font-family:Arial;">RDD</span><span style="font-family:'宋体';">有效，返回一个</span><span style="font-family:Arial;">(K</span><span style="font-family:'宋体';">，</span><span style="font-family:Arial;">Int)</span><span style="font-family:'宋体';">对的</span><span style="font-family:Arial;">Map</span><span style="font-family:'宋体';">，表示每一个</span><span style="font-family:Arial;">key</span><span style="font-family:'宋体';">对应的元素个数</span></span></p>
</td>
</tr><tr><td valign="top">
<p><span style="color:rgb(54,46,43);">foreach</span><span style="color:rgb(54,46,43);">(</span><span style="color:rgb(54,46,43);">func</span><span style="color:rgb(54,46,43);">)</span></p>
</td>
<td valign="top">
<p><span style="color:rgb(54,46,43);">在数据集的每一个元素上，运行函数</span><span style="color:rgb(54,46,43);">func</span><span style="color:rgb(54,46,43);">进行更新。这通常用于边缘效果，例如更新一个累加器，或者和外部存储系统进行交互，例如<span style="font-family:Arial;">HBase</span></span></p>
</td>
</tr></tbody></table><h2>2.3 Spark<span style="font-family:'宋体';">创建两种共享变量</span></h2>
<p><span style="font-size:18px;"><span></span>该变量在不同节点任务上被共享使用：</span></p>
<p><span style="font-size:18px;"><span></span>1、广播变量：允许程序员保留一个只读的变量，缓存在每一台机器上，而非每个任务保存一份拷贝。<span style="font-family:'Times New Roman';">Spark</span><span style="font-family:'宋体';">会尝试使用一种高效的广播算法来传播广播变量，从而减少通信的代价。</span></span></p>
<p><span style="font-size:18px;"><span></span>2<span style="font-family:'宋体';">、累加器：</span>是一种只能通过关联操作进行“加”操作的变量，因此可以高效被并行支持。它们可以用来实现计数器和求和器。</span></p>
<p></p>
<h1>三、spark<span style="font-family:'宋体';">分布式计算模型</span></h1>
<span style="font-size:18px;"><span></span>Spark<span style="font-family:'宋体';">通过</span><span style="font-family:'Times New Roman';">Mesos</span><span style="font-family:'宋体';">进行分布式计算，</span><span style="font-family:'Times New Roman';">spark</span><span style="font-family:'宋体';">将</span><span style="font-family:'Times New Roman';">RDDs</span><span style="font-family:'宋体';">和并行操作函数进行一次转换，变成标准的</span><span style="font-family:'Times New Roman';">job</span><span style="font-family:'宋体';">和一系列</span><span style="font-family:'Times New Roman';">task,</span><span style="font-family:'宋体';">提交给</span><span style="font-family:'Times New Roman';">SparkScheduler</span><span style="font-family:'宋体';">，</span><span style="font-family:'Times New Roman';">SparkScheduler</span><span style="font-family:'宋体';">将</span><span style="font-family:'Times New Roman';">task</span><span style="font-family:'宋体';">提交给</span><span style="font-family:'Times New Roman';">MesoMaster</span><span style="font-family:'宋体';">，由</span><span style="font-family:'Times New Roman';">master</span><span style="font-family:'宋体';">分配给不同的</span>workers.<span style="font-family:'宋体';">最终由</span>worker中的<span style="font-family:'Times New Roman';">SparkExecutor</span><span style="font-family:'宋体';">将分配到的任务一一执行，并返回结果或直接写入到分布式文件系统。</span></span>
<p></p>
<p></p>
<h1>四、例子</h1>
<h3>1<span style="font-family:'宋体';">、</span><span style="font-family:'Times New Roman';">text search</span><span style="font-family:'宋体';">：</span>从存储在<span style="font-family:'Times New Roman';">hdfs</span><span style="font-family:'宋体';">中的日志文件中找出里面的错误信息</span></h3>
<pre><code class="language-cpp">val file = spark.textFile("hdfs://...")//创建一个分布式数据集
val errs = file.filter(_.contains("ERROR"))//RDDs转换的过程，找出日志中包含错误的行
Val cacheErrs=errs.cache();//RDD持久化
val ones = errs.map(_ =&gt; 1)//转换的过程，将这些行映射成1
val count = ones.reduce(_+_)//动作的过程，将这些行累加起来，worker节点扫描这些1，并将结果发给驱动程序。</code></pre><br><p></p>
<h3>2、Logistic Regression<span style="font-family:'宋体';">（逻辑回归）：</span>通过迭代一个分类算法来寻找一个超平面<span style="font-family:'Times New Roman';">w</span><span style="font-family:'宋体';">将两类点分开</span></h3>
<p></p>
<pre><code class="language-cpp">val points = spark.textFile(...).map(parsePoint).cache()// 从文件中读取数据，并缓存在内存中，有利于提高运行效率
var w = Vector.random(D)//给w一个随机值
for (i &lt;- 1 to ITERATIONS) {//迭代，寻找最优w
val grad = spark.accumulator(new Vector(D))//使用累加器，对各节点上的梯度累加
for (p &lt;- points) { //牛顿迭代法进行迭代计算
val s = (1/(1+exp(-p.y*(w dot p.x)))-1)*p.y
grad += s * p.x}
w -= grad.value}</code></pre><br><br><p></p>
<p>完整代码：见后面 六、代码</p>
<h3>3、Spark<span style="font-family:'宋体';">实现完整的</span><span style="font-family:'Times New Roman';">WordCount</span><span style="font-family:'宋体';">程序</span></h3>
<div><span style="font-family:'宋体';"></span><pre><code class="language-java">import spark.SparkContextimport SparkContext._//导入spark开发包
object SparkTest {  def main( args: Array[String]) {    
if (args.length == 0) {      
System.err.println("Usage: SparkTest &lt;host&gt; [&lt;slices&gt;]")      
System.exit(1)    
}   
 val spark = new SparkContext(args(0), "SparkTest")//创建SparkContext对象，告诉spark如何访问spark集群    
val slices = if (args.length &gt; 1) args(1).toInt else 2//定义数据集分为几块    
val myFile = spark.textFile("test.txt")//创建一个分布式数据集   
 val counts = myFile.flatMap(line =&gt; line.split(" ")//文件中每一行单词以空格分隔，转换的过程                        
	.map(word =&gt; (word, 1))//数据集转换成（word,1）键值对，也是数据集转换的过程                        
	.reduceByKey(_ + _)//统计单词个数，动作的过程     
	counts.saveAsTextFile("out.txt")//输出文件   
} 
}
 SparkTest.main(args)//设置main函数参数</code></pre><br><br></div>
<h1>五、spark<span style="font-family:'宋体';">未来工作</span> </h1>
<span style="font-size:18px;">1<span style="font-family:'宋体';">、标准化</span><span style="font-family:'Times New Roman';">RDDs</span><span style="font-family:'宋体';">的属性和特征，及</span><span style="font-family:'Times New Roman';">Spark</span><span style="font-family:'宋体';">的其他抽象概念，使其在其他应用和工作中有更好的适应性；</span></span>
<p></p>
<p><span style="font-size:18px;">2、减少程序员在存储和重构<span style="font-family:'Times New Roman';">RDDs</span><span style="font-family:'宋体';">方面的花销；</span></span></p>
<p><span style="font-size:18px;">3、定义新的关于<span style="font-family:'Times New Roman';">RDDs</span><span style="font-family:'宋体';">转换方面的操作，如</span><span style="font-family:'Times New Roman';">shuffle</span><span style="font-family:'宋体';">操作，可以根据给定的键值重新分配</span><span style="font-family:'Times New Roman';">RDD</span><span style="font-family:'宋体';">；</span></span></p>
<p><span style="font-size:18px;">4、对于<span style="font-family:'Times New Roman';">spark</span><span style="font-family:'宋体';">解释器提供更高水平的交互接口，如跟</span><span style="font-family:'Times New Roman';">SQL</span><span style="font-family:'宋体';">的交互接口。</span></span></p>
<h1> 六、代码</h1>
<div>
<h2><span style="color:rgb(51,51,51);"><span></span>1、用<span style="font-family:Tahoma;">Scala</span><span style="font-family:'宋体';">语言实现</span><span style="font-family:Tahoma;">Logistic Regression Classifier</span><span style="font-family:'宋体';">的完整代码：</span></span></h2>
</div>
<div><span style="color:rgb(51,51,51);"><span style="font-family:'宋体';"></span></span><pre><code class="language-java">import java.util.Random  
import java.lang.Math  
import scala.collection.mutable.HashMap  import scala.io.Source  
import org.apache.spark.SparkContext //创建SparkContext对象，告诉spark如何访问spark集群
import org.apache.spark.rdd.RDD;  //RDDs
import org.apache.spark.util.Vector  //spark容器
import org.apache.spark.broadcast.Broadcast  //广播变量
import spark.ml.utils.SparserVector  
object SparseLR {  //定义一个类：LR分类器  
val labelNum = 2; // 类别数    
val dimNum = 124; // 维度   
val iteration = 10; // 迭代次数    
val alpha = 0.1 // 迭代步长   
val lambda = 0.1    
val rand = new Random(42)  //取一随机数  
var w = Vector(dimNum, _ =&gt; rand.nextDouble) //用随机数初始化参数 ，w为一124维的容器变量    
//定义一个数据点    
case class DataPoint(x: SparserVector, y: Int) //整形y，SparserVector类型的x(124维)  
// 解析一个读入的训练样本，构造DataPoint结构    
def parsePoint(line: String): DataPoint = {  //line为传入的训练样本数据    
var features = new SparserVector(dimNum)      
val fields = line.split(" ") //transformation过程，将原RDDs数据集转换为以空格分割后的数据集     
val y = fields(0).toInt      
fields.filter(_.contains(":")).foreach(f =&gt; {        
val feature = f.split(":")        
features.insert(feature(0).toInt, feature(1).toDouble)      
})     
DataPoint(features, y)    
}   

//读样本文件，构造训练数据   
def genearteDataPoints(filename: String): Array[DataPoint] = {      
val dataPoints = Source.fromFile(filename).getLines.map(parsePoint).toArray     
dataPoints    
}   

//定义sigmod函数  
def sigmod(x: SparserVector): Double = {      
val features = x.elements      
val s = features.keySet.map(k =&gt; w(k) * features.get(k).get).reduce(_ + _)//权值和训练数据乘积之和     
1 / (1 + Math.exp(-s))  //逻辑函数  
}     

// train函数，根据样本训练参数   
def train(sc: SparkContext, dataPoints: RDD[DataPoint]) {      
val sampleNum = dataPoints.count        //开始迭代      
for (i &lt;- 0 until iteration) {        
val g = dataPoints.map(p =&gt; p.x * (sigmod(p.x) - p.y)).reduce(_ + _) + lambda * w        
w -= alpha * g  //牛顿－拉斐森(Newton-Raphson)方法进行迭代求解。  	
println("iteration " + i + ": g = " + g)  	
println("iteration " + i + ": w = " + w)      
}    
}    

//根据训练出的参数进行预测   
def predict(dataPoints: RDD[DataPoint]): Double = {      
val correct = dataPoints.map(p =&gt; {       
val label = if (sigmod(p.x) &gt; 0.5) 1 else 0       
if (label == p.y) 1 else 0      
}).reduce(_ + _)        
(correct * 1.0) / dataPoints.count  
  }    
  
  //main函数  
  def main(args: Array[String]): Unit = {      
  val trainfile = "data/a8a.train";        
  //val sc = new SparkContext(args(0), "LR")     
  val sc = new SparkContext("local", "LR")      
  val trainset = sc.textFile(trainfile, 2).map(parsePoint).cache       
  train(sc, trainset)  //训练样本，得到最优参数      
  val testfile = "data/a8a.test";     
  val testset = sc.textFile(testfile, 2).map(parsePoint).cache      
  val accuracy = predict(testset)  //测试数据，得到分类结果     
  println(accuracy)    
  }  
  }  </code></pre><br><h2><span style="color:rgb(51,51,51);"><span></span>2、Spark<span style="font-family:'宋体';">的</span><span style="font-family:Tahoma;">LR</span><span style="font-family:'宋体';">分类器</span></span></h2>
<div><span style="color:rgb(51,51,51);"><span style="font-family:'宋体';"></span></span><pre><code class="language-java">package spark.examples
Import scala.io.Source
import java.util.Random
import scala.math.exp
import spark.util.Vector
import spark._
*******************************************************************
object SparkLR {
  val N = 10000  // Number of data points
  val D = 10   // Numer of dimensions
  val R = 0.7  // Scaling factor
  val ITERATIONS = 5
  val rand = new Random(42)
  case class DataPoint(x: Vector, y: Double)
  case class DataPoint1(x: Vector)
********************************************************************
  def generateData = {     //自己构建了训练数据
    def generatePoint(i: Int) = {
      val y = if(i % 2 == 0) -1 else 1
      val x = Vector(D, _ =&gt; rand.nextGaussian + y * R)
      DataPoint(x, y)
    }
    Array.tabulate(N)(generatePoint)
  }
*************************************************************************
//fang该部分是对上面的数据结构改进，方便从文件中读入数据
def generateData = {     //自己构建了训练数据
Val src=Source.fromFile(“/home/jay/file01”)
Val iter=src.getLines()
    def generatePoint(i: Int) = {
      val y = if(i % 2 == 0) -1 else 1
      val x = Vector(D, iter.next().split(“ ”).map(w=&gt;w.toDouble))
      DataPoint(x, y)
    }
Array.tabulate(N)(generatePoint)
  }

def generateData = {     //自己构建测试数据
Val src1=Source.fromFile(“/home/jay/file02”)
Val iter1=src1.getLines()
    def generatePoint1(i: Int) = {
      val x = Vector(D, iter1.next().split(“ ”).map(w=&gt;w.toDouble))
      DataPoint1(x)
    }
Array.tabulate(N)(generatePoint1)
  }
//fang
*******************************************************************************
  def main(args: Array[String]) {
    Val conf = new SparkConf().setAppName(“SparkLR”)
    val sc = new SparkContext(conf)
    val numSlices = if (args.length &gt; 1) args(1).toInt else 2
val points = sc.parallelize(generateData, numSlices).cache()
val points1 = sc.parallelize(generateData1, numSlices).cache()
    // Initialize w to a random value
    var w = Vector(D, _ =&gt; 2 * rand.nextDouble - 1)
    println("Initial w: " + w)

    for (i &lt;- 1 to ITERATIONS) {//运用牛顿迭代法实现LR分类器
      println("On iteration " + i)
      val gradient = points.map { p =&gt;
        (1 / (1 + exp(-p.y * (w dot p.x))) - 1) * p.y * p.x
      }.reduce(_ + _)
      w -= gradient
    }
println("Final w: " + w)
Val y=points1.map{p=&gt;(1/(1+exp(w dot p.x)))}
var Y = Vector(N,  y.take(N)
Println(“result: ”, + Y)
    System.exit(0)
  }
}</code></pre><br><br></div>
<p class="p" style="line-height:19.5pt;"><span style="font-family:'宋体';font-size:10.5pt;">训练数据模型：</span><span style="font-family:'宋体';font-size:10.5pt;"></span></p>
<p class="p" style="line-height:19.5pt;"><span style="font-family:'宋体';font-size:10.5pt;">xxx   xxx  xxx  xxx  xxx  xxx  xxx  xxx  xxx  xxx  yyy</span><span style="font-family:'宋体';font-size:10.5pt;"></span></p>
详细逻辑回归分类器参考博客：http://blog.csdn.net/qustqustjay/article/details/46874527</div>
            </div>
                </div>