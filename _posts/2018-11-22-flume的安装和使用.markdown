---
layout:     post
title:      flume的安装和使用
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <div id="content_views" class="markdown_views prism-atom-one-dark">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h2 id="flume的安装及配置">flume的安装及配置</h2>



<h3 id="flume概述">flume概述:</h3>

<ul>
<li>Flume是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。</li>
<li>Flume可以采集文件，socket数据包等各种形式源数据，又可以将采集到的数据输出到HDFShbase、hive、kafka等众多外部存储系统中</li>
<li>一般的采集需求，通过对flume的简单配置即可实现</li>
<li>Flume针对特殊场景也具备良好的自定义扩展能力，因此，flume可以适用于大部分的日常数据采集场景 <br>
<hr></li>
</ul>

<h3 id="flume的运行机制">flume的运行机制:</h3>

<ul>
<li>1、Flume分布式系统中最核心的角色是agent，flume采集系统就是由一个个agent所连接起来形成</li>
<li>每一个agent相当于一个数据传递员(Source 到 Channel 到 Sink之间传递数据的形式是Event事件,Event事件是一个数据流单元)，内部有三个组件： <br>
<ul><li>Source：采集源，用于跟数据源对接，以获取数据</li>
<li>Sink：下沉地，采集数据的传送目的，用于往下一级agent传递数据或者往最终存储系统传递数据</li>
<li>Channel：angent内部的数据传输通道，用于从source将数据传递到sink <br>
<img src="https://img-blog.csdn.net/20180416225203587?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phZG9vcA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""> <br>
<hr></li></ul></li>
</ul>

<h2 id="flume的安装与部署">flume的安装与部署</h2>

<ul>
<li>1、Flume的安装非常简单，只需要解压即可，当然，前提是已有hadoop环境 <br>
上传安装包到<strong>数据源</strong>所在节点上 <br>
然后解压  tar -zxvf apache-flume-1.6.0-bin.tar.gz <br>
然后进入flume的目录，修改conf下的flume-env.sh  ，在里面配置JAVA_HOME</li>
<li>2、根据数据采集的需求配置采集方案，描述在配置文件中(文件名可任意自定义)</li>
<li>3、指定采集方案配置文件，在相应的节点上启动flume agent  </li>
</ul>

<h5 id="1先在flume的conf目录下新建一个文件">1、先在flume的conf目录下新建一个文件</h5>

<p>vi netcat-logger.conf</p>

<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor"># 定义这个agent中各组件的名字</span>
a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span>
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.channels</span> = c1

<span class="hljs-preprocessor"># 描述和配置source组件：r1的采集类型为 netcat 采集的主机是本机 端口是44444  </span>
<span class="hljs-preprocessor">#如果想采集其他的主机上bind那写0.0.0.0绑定本机的所有ip。相当于与那个主机开了一个tcp socket通信 服务器是绑定的这台主机，主机端口是44444 客户端主机只需要telnet min1 44444即可  </span>

<span class="hljs-preprocessor">#flume的netcat source会自动创建一个socket  Server，只需将数据发送到此socket，flume的netcat source 就能获取数据。</span>
配置bind是绑定服务器主机和端口可以是localhost min1 <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = netcat
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.bind</span> = localhost
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.port</span> = <span class="hljs-number">44444</span>

<span class="hljs-preprocessor"># 描述和配置sink组件：k1</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = logger

<span class="hljs-preprocessor"># 描述和配置channel组件，此处使用是内存缓存的方式</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = memory
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.capacity</span> = <span class="hljs-number">1000</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.transactionCapacity</span> = <span class="hljs-number">100</span>

<span class="hljs-preprocessor"># 描述和配置source  channel   sink之间的连接关系</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1    </code></pre>



<h5 id="2启动agent去采集数据">2、启动agent去采集数据</h5>

<pre class="prettyprint"><code class=" hljs lasso">bin/flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-attribute">-c</span> conf <span class="hljs-attribute">-f</span> conf/netcat<span class="hljs-attribute">-logger</span><span class="hljs-built_in">.</span>conf <span class="hljs-attribute">-n</span> a1  <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>INFO,console</code></pre>

<p>-c conf   指定flume自身的配置文件所在目录  </p>

<p>-f conf/netcat-logger.con  指定我们所描述的采集方案  </p>

<p>-n a1  指定我们这个agent的名字 <br>
-Dflume.root.logger=INFO,console 这里是传给打log日志的参数，如果sink不是logger则不要写这个参数</p>

<h5 id="3测试">3、测试：</h5>

<p>输入 telnet localhost 44444 <br>
telnet就是往屏幕上打字然后flume去采集 <br>
可以看到数据已经打到屏幕上了 <br>
如果没有telnet则需要安装 telnet的客户端和服务端: <br>
- 1.rpm -qa | grep telnet 查看有没有安装telnet的rpm包如果没有则: <br>
- 2.sudo yum install telnet #这是安装客户端 <br>
- 3.sudo yum install telnet-server #这是安装服务端 <br>
- 4.重启xinetd服务 <br>
sudo service xinetd restart </p>

<h5 id="总结">总结：</h5>

<ul>
<li>flume的关键是配置source channel sink</li>
<li>其中source里面的type是指定采集的类型是什么采集的类型有很多种 有telnet exec 等等。bind是指定采集的主机 port是端口</li>
<li>sink是采集到的数据放在哪里去 下沉地可以是hdfs logger hive等等。</li>
<li>注意启动flume的命令。 <br>
<img src="https://img-blog.csdn.net/20180416225228515?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phZG9vcA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述" title=""></li>
</ul>

<p>问题:source里面bind min2没用出错: <br>
org.apache.flume.FlumeException: java.net.BindException: Cannot assign requested address <br>
但是绑定所有主机则有用为什么? <br>
原因是 安装flume的是<strong>服务端</strong> 里面绑定的一定是本机地址 可以是localhost或min1</p>

<hr>

<h2 id="flume进阶">flume进阶</h2>



<h3 id="1spooldir-logger">1、spooldir-logger</h3>



<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor">#定义三大组件的名称</span>
agent1<span class="hljs-preprocessor">.sources</span> = source1
agent1<span class="hljs-preprocessor">.sinks</span> = sink1
agent1<span class="hljs-preprocessor">.channels</span> = channel1

<span class="hljs-preprocessor"># 配置source组件</span>
agent1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.type</span> = spooldir
agent1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.spoolDir</span> = /home/hadoop/logs/
agent1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.fileHeader</span> = false

<span class="hljs-preprocessor"># Use a channel which buffers events in memory</span>
agent1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.channel</span>1<span class="hljs-preprocessor">.type</span> = memory
agent1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.channel</span>1<span class="hljs-preprocessor">.keep</span>-alive = <span class="hljs-number">120</span>
agent1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.channel</span>1<span class="hljs-preprocessor">.capacity</span> = <span class="hljs-number">500000</span>
agent1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.channel</span>1<span class="hljs-preprocessor">.transactionCapacity</span> = <span class="hljs-number">600</span>

<span class="hljs-preprocessor">#配置sink</span>
agent1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.sink</span>1<span class="hljs-preprocessor">.type</span> = logger

<span class="hljs-preprocessor"># Bind the source and sink to the channel</span>
agent1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.source</span>1<span class="hljs-preprocessor">.channels</span> = channel1
agent1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.sink</span>1<span class="hljs-preprocessor">.channel</span> = channel1</code></pre>

<p><strong>source为spooldir跟踪一个目录/home/hadoop/logs这个目录必须存在 采集到之后logs文件夹中的文件名将带有.complete后缀(这个.complete后缀可以在配置文件中修改) logs里面的文件名不能重复</strong>  </p>

<h3 id="2tail-hdfs">2、tail-hdfs</h3>

<p>采集数据到hdfs source是exex </p>



<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor"># Name the components on this agent</span>
a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span>
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.channels</span> = c1

<span class="hljs-preprocessor"># 配置source</span>
<span class="hljs-preprocessor">#exec 指的是命令</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = exec
<span class="hljs-preprocessor">#F根据文件名追踪, f根据文件的nodeid追踪</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.command</span> = tail -F /home/hadoop/logs/test<span class="hljs-preprocessor">.log</span>

<span class="hljs-preprocessor"># 配置sink</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = hdfs
<span class="hljs-preprocessor">#指定下沉到hdfs的目录, flume帮我们做目录的替换</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.path</span> = /flume/events/%<span class="hljs-built_in">y</span>-%m-%d/%H%M/
<span class="hljs-preprocessor">#文件的命名, 前缀</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.filePrefix</span> = events-

<span class="hljs-preprocessor">#10 分钟就改目录 这是目录滚动的配置 </span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.round</span> = true
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.roundValue</span> = <span class="hljs-number">10</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.roundUnit</span> = minute


<span class="hljs-preprocessor">#下面sink的3个配置都是文件的滚动设置</span>

<span class="hljs-preprocessor">#文件滚动之前的等待时间(秒)</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.rollInterval</span> = <span class="hljs-number">3</span>
<span class="hljs-preprocessor">#文件滚动的大小限制(bytes)</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.rollSize</span> = <span class="hljs-number">500</span>
<span class="hljs-preprocessor">#写入多少个event数据后滚动文件(事件个数)</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.rollCount</span> = <span class="hljs-number">20</span>


<span class="hljs-preprocessor">#5个事件从channel就往里面sink地点(hdfs)里写入</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.batchSize</span> = <span class="hljs-number">5</span>

<span class="hljs-preprocessor">#用本地时间格式化目录</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.useLocalTimeStamp</span> = true

<span class="hljs-preprocessor">#下沉后, 生成的文件类型，默认是Sequencefile，可用DataStream，则为普通文本</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.fileType</span> = DataStream

<span class="hljs-preprocessor"># Use a channel which buffers events in memory</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = memory
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.capacity</span> = <span class="hljs-number">1000</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.transactionCapacity</span> = <span class="hljs-number">100</span>

<span class="hljs-preprocessor"># Bind the source and sink to the channel</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1</code></pre>

<p>启动命令:</p>

<pre class="prettyprint"><code class=" hljs lasso">bin/flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-attribute">-c</span> conf <span class="hljs-attribute">-f</span> conf/tail<span class="hljs-attribute">-hdfs</span><span class="hljs-built_in">.</span>conf <span class="hljs-attribute">-n</span> a1</code></pre>

<ul>
<li>1.在/home/hadoop/logs/test.log文件创建这个文件</li>
<li>2.在test.log下产生数据  </li>
</ul>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-keyword">while</span> <span class="hljs-literal">true</span>
<span class="hljs-keyword">do</span>
<span class="hljs-built_in">echo</span> <span class="hljs-number">111111</span> &gt;&gt; /home/hadoop/logs/test.log
sleep <span class="hljs-number">0.5</span>
<span class="hljs-keyword">done</span></code></pre>

<ul>
<li>3.启动flume启动hdfs 可以看到hdfs中产生的数据</li>
</ul>



<h3 id="3多级agent的串联">3.多级agent的串联:</h3>

<ul>
<li>1.有两个配置文件，第一个配置文件tail-avro.conf配置的是从exec往avro上发:</li>
<li>2.第二个配置文件是avro-logger.conf 配置的是从avro往logger上发。</li>
<li>3.在min2上启动 avro-logger.conf 在 min1上启动tail-avro.conf 这样就实现了多级agent的串联。  </li>
</ul>



<h4 id="tail-avroconf">tail-avro.conf</h4>



<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor"># Name the components on this agent</span>
a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span>
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.channels</span> = c1

<span class="hljs-preprocessor"># Describe/configure the source</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = exec
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.command</span> = tail -F /home/hadoop/logs/test<span class="hljs-preprocessor">.log</span>

<span class="hljs-preprocessor"># Describe the sink</span>
<span class="hljs-preprocessor"># 绑定的不是本机, 是另外一台机器的服务地址, sink端的avro是一个发送端avro的客户端</span>
<span class="hljs-preprocessor"># 将数据发送到min2上的4141端口</span>
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = avro
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hostname</span> = min2
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.port</span> = <span class="hljs-number">4141</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.batch</span>-size = <span class="hljs-number">2</span>



<span class="hljs-preprocessor"># Use a channel which buffers events in memory</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = memory
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.capacity</span> = <span class="hljs-number">1000</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.transactionCapacity</span> = <span class="hljs-number">100</span>

<span class="hljs-preprocessor"># Bind the source and sink to the channel</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1</code></pre>



<h4 id="avro-loggerconf">avro-logger.conf</h4>



<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor"># Name the components on this agent</span>
a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span>
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.channels</span> = c1

<span class="hljs-preprocessor"># Describe/configure the source</span>
<span class="hljs-preprocessor">#source中的avro组件是接收者服务端, 绑定本机</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = avro
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.bind</span> = <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span> <span class="hljs-preprocessor">#绑定本机所有ip</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.port</span> = <span class="hljs-number">4141</span>

<span class="hljs-preprocessor"># Describe the sink</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = logger

<span class="hljs-preprocessor"># Use a channel which buffers events in memory</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = memory
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.capacity</span> = <span class="hljs-number">1000</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.transactionCapacity</span> = <span class="hljs-number">100</span>

<span class="hljs-preprocessor"># Bind the source and sink to the channel</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1</code></pre>

<p>启动flume：先启动服务端后启动客户端 <br>
- min2上: </p>



<pre class="prettyprint"><code class=" hljs lasso">bin/flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-attribute">-c</span> conf <span class="hljs-attribute">-f</span> conf/avro<span class="hljs-attribute">-logger</span><span class="hljs-built_in">.</span>conf <span class="hljs-attribute">-n</span> a1  <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>INFO,console</code></pre>

<ul>
<li>min1 上</li>
</ul>



<pre class="prettyprint"><code class=" hljs bash">bin/flume-ng agent -c conf <span class="hljs-operator">-f</span> conf/tail-avro.conf -n a1
<span class="hljs-comment"># 往/home/hadoop/logs/test.log里打数据</span>
<span class="hljs-keyword">while</span> <span class="hljs-literal">true</span>
<span class="hljs-keyword">do</span>
<span class="hljs-built_in">echo</span> <span class="hljs-number">111111</span> &gt;&gt; /home/hadoop/logs/test.log
sleep <span class="hljs-number">0.5</span>
<span class="hljs-keyword">done</span></code></pre>

<hr>

<p>总结: <br>
在source端的绑定的主机和端口都是服务端、服务端只能绑定本机ip <br>
在sink绑定的主机和端口都是客户端 sink是数据的发送者 注意agent的名字一定不能写错</p>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>