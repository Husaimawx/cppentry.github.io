---
layout:     post
title:      大数据学习——Flume介绍与安装
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：（谢厂节的博客）博主文章绝大部分非原创，转载望留链接。					https://blog.csdn.net/xundh/article/details/70257426				</div>
								            <div id="content_views" class="markdown_views prism-tomorrow-night">
							<!-- flowchart 箭头图标 勿删 -->
							<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path></svg>
							<h1 id="flume">Flume</h1>

<hr>

<p>实验环境： <br>
<em>shiyanlou</em> <br>
 - CentOS6.6 64 <br>
 - JDK 1.7.0_55 64 <br>
 - Hadoop 1.1.2</p>



<h2 id="flume-介绍">Flume 介绍</h2>

<p>Flume是Cloudera提供的日志收集系统。Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。 <br>
Flume是一个分布式、可靠、高可用的海量日志采集、聚合和传输的系统。</p>



<h3 id="flume特点">Flume特点</h3>

<ul>
<li>Reliability：数据可靠性，包括End-to-end，Store on failure和Best effort</li>
<li>Scalability：Flume的3大组件collector、master和storage tier都是可伸缩的</li>
<li>Manageability：利用ZooKeeper和gossip，保证配置数据的一致性、高可用，同时多Master</li>
<li>Extensibility：基于Java，用户可以为Flume添加各种新的功能。</li>
</ul>



<h3 id="flume架构">Flume架构</h3>

<p><img src="https://img-blog.csdn.net/20170420113447638?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHVuZGg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>其中最重要的抽象是data flow，描述了数据从产生、传输、处理并最终写入目标的一条路径。 <br>
上图实线是data flow。 <br>
Agent用于采集数据，agent是flume中产生数据流的地方，同时，agent会将产生的数据流传输到collector。对应的，collector用于对数据进行聚合，往往产生一个更大的流。</p>

<p>Flume提供了从console（控制台）、RPC（Thrift-RPC）、text（文件）、tail（UNIX tail）、syslog（syslog日志系统，支持TCP和UDP等2种模式），exec（命令执行）等数据源上收集数据的能力。 <br>
同时，Flume的数据接受方，可以是console（控制台）、text（文件）、dfs（HDFS文件）、RPC（Thrift-RPC）和syslogTCP（TCP syslog日志系统）等。</p>

<p>其中，收集数据有2种主要工作模式： <br>
 - Push Sources：外部系统会主动地将数据推送到Flume中，如RPC、syslog <br>
 - Polling Sources：Flume到外部系统中获取数据，一般使用轮询的方式，如text和exec <br>
注意，在Flume中，agent和collector对应，而source和sink对应。 <br>
Source和sink强调发送、接受方的特性（如数据格式、编码等），而agent和collector关注功能。</p>

<p>Flume Master用于管理数据流的配置。Flume Master间使用gossip协议同步数据。</p>

<h2 id="安装部署flume">安装部署Flume</h2>

<h3 id="下载地址">下载地址</h3>

<p><a href="http://flume.apache.org/download.html" rel="nofollow">http://flume.apache.org/download.html</a></p>

<pre class="prettyprint"><code class=" hljs lasso">cd /home/shiyanlou/install<span class="hljs-attribute">-pack</span>
tar <span class="hljs-attribute">-xzf</span> flume<span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.2</span><span class="hljs-attribute">-bin</span><span class="hljs-built_in">.</span>tar<span class="hljs-built_in">.</span>gz
mv apache<span class="hljs-attribute">-flume</span><span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.2</span><span class="hljs-attribute">-bin</span> /app/flume<span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.2</span>
sudo vi /etc/profile</code></pre>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-keyword">export</span> FLUME_HOME=/app/flume-<span class="hljs-number">1.5</span>.<span class="hljs-number">2</span>
<span class="hljs-keyword">export</span> FLUME_CONF_DIR=<span class="hljs-variable">$FLUME_HOME</span>/conf
<span class="hljs-keyword">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$FLUME_HOME</span>/bin</code></pre>



<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">source</span> /etc/profile
<span class="hljs-built_in">echo</span> <span class="hljs-variable">$PATH</span>

<span class="hljs-built_in">cd</span> /app/flume-<span class="hljs-number">1.5</span>.<span class="hljs-number">2</span>/conf
cp flume-env.sh.template flume-env.sh
<span class="hljs-built_in">sudo</span> vi flume-env.sh
</code></pre>

<pre class="prettyprint"><code class=" hljs ini"><span class="hljs-setting">JAVA_HOME= <span class="hljs-value">/app/lib/jdk1.<span class="hljs-number">7.0</span>_55</span></span>
<span class="hljs-setting">JAVA_OPTS=<span class="hljs-value"><span class="hljs-string">"-Xms100m -Xmx200m -Dcom.sun.management.jmxremote"</span></span></span></code></pre>



<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-keyword">cp</span> flume-conf<span class="hljs-preprocessor">.properties</span><span class="hljs-preprocessor">.template</span> flume-conf<span class="hljs-preprocessor">.properties</span>
sudo vi flume-conf<span class="hljs-preprocessor">.properties</span></code></pre>



<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor"># The configuration file needs to define the sources, the channels and the sinks.</span>
<span class="hljs-preprocessor"># Sources, channels and sinks are defined per agent, in this case called 'a1'</span>
a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span>
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.channels</span> = c1

<span class="hljs-preprocessor"># For each one of the sources, the type is defined</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = netcat
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.bind</span> = localhost
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.port</span> = <span class="hljs-number">44444</span>

<span class="hljs-preprocessor">#The channel can be defined as follows.</span>
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1
<span class="hljs-preprocessor"># Each sink's type must be defined</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = logger

<span class="hljs-preprocessor">#Specify the channel the sink should use</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1

<span class="hljs-preprocessor"># Each channel's type is defined.</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = memory
<span class="hljs-preprocessor"># Other config values specific to each type of channel(sink or source)</span>
<span class="hljs-preprocessor"># can be defined as well</span>
<span class="hljs-preprocessor"># In this case, it specifies the capacity of the memory channel</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.capacity</span> = <span class="hljs-number">1000</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.transactionCapacity</span> = <span class="hljs-number">100</span></code></pre>

<pre class="prettyprint"><code class=" hljs lasso">cd /app/flume<span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.2</span>
<span class="hljs-built_in">.</span>/bin/flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-subst">--</span>conf <span class="hljs-built_in">.</span>/conf<span class="hljs-subst">/</span> <span class="hljs-subst">--</span>conf<span class="hljs-attribute">-file</span> <span class="hljs-built_in">.</span>/conf/flume<span class="hljs-attribute">-conf</span><span class="hljs-built_in">.</span>properties <span class="hljs-subst">--</span>name a1 <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>INFO,console</code></pre>

<p>下面的测试在shiyanlou无法进行： <br>
另开一个终端</p>

<pre class="prettyprint"><code class=" hljs vala"><span class="hljs-preprocessor">#sudo yum install telnet</span>
telnet localhost <span class="hljs-number">44444</span>
hello world</code></pre>

<p>在原来的终端上，可以收到来自于telnet发出的消息。</p>

<pre class="prettyprint"><code class=" hljs avrasm">cd /app/flume-<span class="hljs-number">1.5</span><span class="hljs-number">.2</span>/conf
<span class="hljs-keyword">cp</span> flume-conf<span class="hljs-preprocessor">.properties</span><span class="hljs-preprocessor">.template</span> flume-conf2<span class="hljs-preprocessor">.properties</span>
sudo vi flume-conf2<span class="hljs-preprocessor">.properties</span></code></pre>



<pre class="prettyprint"><code class=" hljs avrasm">a1<span class="hljs-preprocessor">.sources</span> = <span class="hljs-built_in">r1</span>
a1<span class="hljs-preprocessor">.sinks</span> = k1
a1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.type</span> = exec
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.channels</span> = c1
a1<span class="hljs-preprocessor">.sources</span><span class="hljs-preprocessor">.r</span>1<span class="hljs-preprocessor">.command</span> = tail -F /app/hadoop-<span class="hljs-number">1.1</span><span class="hljs-number">.2</span>/logs/hadoop-shiyanlou-namenode-b393a04554e1<span class="hljs-preprocessor">.log</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.type</span> = hdfs
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.channel</span> = c1
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.path</span> = hdfs://hadoop:<span class="hljs-number">9000</span>/class12/out_flume
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.filePrefix</span> = events-
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.round</span> = true
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.roundValue</span> = <span class="hljs-number">10</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.roundUnit</span> = minute
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.rollSize</span> = <span class="hljs-number">4000000</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.rollCount</span> = <span class="hljs-number">0</span>
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.writeFormat</span> = Text
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.fileType</span> = DataStream
a1<span class="hljs-preprocessor">.sinks</span><span class="hljs-preprocessor">.k</span>1<span class="hljs-preprocessor">.hdfs</span><span class="hljs-preprocessor">.batchSize</span> = <span class="hljs-number">10</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.type</span> = memory
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.capacity</span> = <span class="hljs-number">1000</span>
a1<span class="hljs-preprocessor">.channels</span><span class="hljs-preprocessor">.c</span>1<span class="hljs-preprocessor">.transactionCapacity</span> = <span class="hljs-number">100</span></code></pre>

<pre class="prettyprint"><code class=" hljs lasso">cd /app/flume<span class="hljs-subst">-</span><span class="hljs-number">1.5</span><span class="hljs-number">.2</span>
<span class="hljs-built_in">.</span>/bin/flume<span class="hljs-attribute">-ng</span> agent <span class="hljs-subst">--</span>conf <span class="hljs-built_in">.</span>/conf<span class="hljs-subst">/</span> <span class="hljs-subst">--</span>conf<span class="hljs-attribute">-file</span> <span class="hljs-built_in">.</span>/conf/flume<span class="hljs-attribute">-conf2</span><span class="hljs-built_in">.</span>properties <span class="hljs-subst">--</span>name a1 <span class="hljs-attribute">-Dflume</span><span class="hljs-built_in">.</span>root<span class="hljs-built_in">.</span>logger<span class="hljs-subst">=</span>INFO,console</code></pre>

<p>这时会不断收集hadoop-hadoop-namenode-hadoop1.log的数据写入HDFS中。</p>

<p>查看hdfs中/class12/out_flume中的文件</p>

<pre class="prettyprint"><code class=" hljs lasso">hadoop fs <span class="hljs-attribute">-ls</span> /class12/out_flume
hadoop fs <span class="hljs-attribute">-cat</span> /class12/out_flume/events<span class="hljs-subst">-</span><span class="hljs-number">.1433921305493</span></code></pre>            </div>
						<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-9e5741c4b9.css" rel="stylesheet">
                </div>