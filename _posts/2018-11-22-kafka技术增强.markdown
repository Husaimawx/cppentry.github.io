---
layout:     post
title:      kafka技术增强
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/zuochang_liu/article/details/81697761				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p id="main-toc"><strong>目录</strong></p>

<p id="-toc" style="margin-left:0px;"> </p>

<p id="1%20kafka%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84%E5%9B%BE-toc" style="margin-left:0px;"><a href="#1%20kafka%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84%E5%9B%BE" rel="nofollow">1 kafka整体结构图</a></p>

<p id="2%20Consumer%E4%B8%8Etopic%E5%85%B3%E7%B3%BB-toc" style="margin-left:0px;"><a href="#2%20Consumer%E4%B8%8Etopic%E5%85%B3%E7%B3%BB" rel="nofollow">2 Consumer与topic关系</a></p>

<p id="3%20kafka%E6%B6%88%E6%81%AF%E7%9A%84%E5%88%86%E5%8F%91-toc" style="margin-left:0px;"><a href="#3%20kafka%E6%B6%88%E6%81%AF%E7%9A%84%E5%88%86%E5%8F%91" rel="nofollow">3 kafka消息的分发</a></p>

<p id="4%20Consumer%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1-toc" style="margin-left:0px;"><a href="#4%20Consumer%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1" rel="nofollow">4 Consumer的负载均衡</a></p>

<p id="5%20kafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6-toc" style="margin-left:0px;"><a href="#5%20kafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6" rel="nofollow">5 kafka文件存储机制</a></p>

<p id="5.1%20kafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84-toc" style="margin-left:40px;"><a href="#5.1%20kafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84" rel="nofollow">5.1 kafka文件存储基本结构</a></p>

<p id="5.2%20kafka%20Partition%20Segment-toc" style="margin-left:40px;"><a href="#5.2%20kafka%20Partition%20Segment" rel="nofollow">5.2 kafka Partition Segment</a></p>

<p id="5.3%20kafka%E6%9F%A5%E6%89%BEmessage-toc" style="margin-left:40px;"><a href="#5.3%20kafka%E6%9F%A5%E6%89%BEmessage" rel="nofollow">5.3 kafka查找message</a></p>

<p id="5.3.1%20%E6%9F%A5%E6%89%BEsegment%20file-toc" style="margin-left:80px;"><a href="#5.3.1%20%E6%9F%A5%E6%89%BEsegment%20file" rel="nofollow">5.3.1 查找segment file</a></p>

<p id="5.3.2%20%E9%80%9A%E8%BF%87segment%20file%E6%9F%A5%E6%89%BEmessage-toc" style="margin-left:80px;"><a href="#5.3.2%20%E9%80%9A%E8%BF%87segment%20file%E6%9F%A5%E6%89%BEmessage" rel="nofollow">5.3.2 通过segment file查找message</a></p>

<p id="6%20%E9%99%84%E5%8A%A0(broker%E5%AD%98%E5%82%A8%E6%B6%88%E6%81%AF)-toc" style="margin-left:0px;"><a href="#6%20%E9%99%84%E5%8A%A0(broker%E5%AD%98%E5%82%A8%E6%B6%88%E6%81%AF)" rel="nofollow">6 附加(broker存储消息)</a></p>

<p id="6.1%20%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F-toc" style="margin-left:40px;"><a href="#6.1%20%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F" rel="nofollow">6.1 消息存储方式</a></p>

<p id="6.2%20%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8%E7%AD%96%E7%95%A5-toc" style="margin-left:40px;"><a href="#6.2%20%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8%E7%AD%96%E7%95%A5" rel="nofollow">6.2 消息存储策略</a></p>

<p id="6.3%20kafka%20log%E7%9A%84%E5%AD%98%E5%82%A8%E8%A7%A3%E6%9E%90-toc" style="margin-left:40px;"><a href="#6.3%20kafka%20log%E7%9A%84%E5%AD%98%E5%82%A8%E8%A7%A3%E6%9E%90" rel="nofollow">6.3 kafka log的存储解析</a></p>

<hr id="hr-toc"><h1 id="1%20kafka%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84%E5%9B%BE">1 kafka整体结构图</h1>

<p style="margin-left:0pt;">Kafka名词解释和工作方式</p>

<ul><li>Producer ：消息生产者，就是向kafka broker发消息的客户端。</li>
	<li>Consumer ：消息消费者，向kafka broker取消息的客户端</li>
	<li>Topic ：咋们可以理解为一个队列。</li>
	<li>Consumer Group （CG）：这是kafka用来实现一个topic消息的广播（发给所有的consumer）和单播（发给任意一个consumer）的手段。一个topic可以有多个CG。topic的消息会复制（不是真的复制，是概念上的）到所有的CG，但每个partion只会把消息发给该CG中的一个consumer。如果需要实现广播，只要每个consumer有一个独立的CG就可以了。要实现单播只要所有的consumer在同一个CG。用CG还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic。</li>
	<li>Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。</li>
	<li>Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体（多个partition间）的顺序。</li>
	<li>Offset：kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。当然the first offset就是00000000000.kafka</li>
</ul><h1 id="2%20Consumer%E4%B8%8Etopic%E5%85%B3%E7%B3%BB">2 Consumer与topic关系</h1>

<p style="margin-left:0pt;">本质上kafka只支持Topic；</p>

<ul><li>每个group中可以有多个consumer，每个consumer属于一个consumer group；</li>
</ul><p style="margin-left:0pt;">        通常情况下，一个group中会包含多个consumer，这样不仅可以提高topic中消息的并发消费能力，而且还能提高"故障容              错"性，如果group中的某个consumer失效那么其消费的partitions将会有其他consumer自动接管。</p>

<ul><li>对于Topic中的一条特定的消息，只会被订阅此Topic的每个group中的其中一个consumer消费，此消息不会发送给一个group的多个consumer；</li>
</ul><p style="margin-left:0pt;">        那么一个group中所有的consumer将会交错的消费整个Topic，每个group中consumer消息消费互相独立，我们可以认为一           个group是一个"订阅"者。</p>

<ul><li>在kafka中,一个partition中的消息只会被group中的一个consumer消费<strong><span style="color:#ff0000;"><strong>(同一时刻)</strong></span></strong>；</li>
</ul><p style="margin-left:0pt;">        一个Topic中的每个partions，只会被一个"订阅者"中的一个consumer消费，不过一个consumer可以同时消费多个partitions          中的消息。</p>

<ul><li>kafka的设计原理决定,对于一个topic，同一个group中不能有多于partitions个数的consumer同时消费，否则将意味着某些consumer将无法得到消息。</li>
</ul><p style="margin-left:0pt;"><strong><span style="color:#ff0000;"><strong>       kafka只能保证一个partition中的消息被某个consumer消费时是顺序的；事实上，从Topic角度来说,当有多个partitions时,         消息仍不是全局有序的。</strong></span></strong></p>

<h1 id="3%20kafka%E6%B6%88%E6%81%AF%E7%9A%84%E5%88%86%E5%8F%91" style="margin-left:0pt;">3 kafka消息的分发</h1>

<p style="margin-left:0pt;"><strong><span style="color:#ff0000;"><strong>Producer客户端负责消息的分发</strong></span></strong></p>

<ul><li>kafka集群中的任何一个broker都可以向producer提供metadata信息,这些metadata中包含"集群中存活的servers列表"/"partitions leader列表"等信息；</li>
	<li>当producer获取到metadata信息之后, producer将会和Topic下所有partition leader保持socket连接；</li>
	<li>消息由producer直接通过socket发送到broker，中间不会经过任何"路由层"，事实上，消息被路由到哪个partition上由producer客户端决定；比如可以采用"random""key-hash""轮询"等,<strong><span style="color:#ff0000;"><strong>如果一个topic中有多个partitions,那么在producer端实现"消息均衡分发"是必要的。</strong></span></strong></li>
	<li>在producer端的配置文件中,开发者可以指定partition路由的方式。</li>
</ul><p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;"><strong>Producer消息发送的应答机制</strong></p>

<blockquote>
<p style="margin-left:0pt;">设置发送数据是否需要服务端的反馈,有三个值0,1,-1</p>

<p style="margin-left:0pt;">0: producer不会等待broker发送ack</p>

<p style="margin-left:0pt;">1: 当leader接收到消息之后发送ack</p>

<p style="margin-left:0pt;">-1: 当所有的follower都同步消息成功后发送ack</p>

<p style="margin-left:0pt;">request.required.acks=0</p>
</blockquote>

<h1 id="4%20Consumer%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1" style="margin-left:0pt;">4 Consumer的负载均衡</h1>

<p style="margin-left:0pt;">当一个group中,有consumer加入或者离开时,会触发partitions均衡.均衡的最终目的,是提升topic的并发消费能力，步骤如下：</p>

<ol><li>假如topic1,具有如下partitions: P0,P1,P2,P3</li>
	<li>加入group中,有如下consumer: C1,C2</li>
	<li>首先根据partition索引号对partitions排序: P0,P1,P2,P3</li>
	<li>根据consumer.id排序: C0,C1</li>
	<li>计算倍数: M = [P0,P1,P2,P3].size / [C0,C1].size,本例值M=2(向上取整)</li>
	<li>然后依次分配partitions: C0 = [P0,P1],C1=[P2,P3],即Ci = [P(i * M),P((i + 1) * M -1)]</li>
</ol><p><img alt="" class="has" height="252" src="https://img-blog.csdn.net/20180815085741709?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p1b2NoYW5nX2xpdQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="474"></p>

<h1 id="5%20kafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6">5 kafka文件存储机制</h1>

<h2 id="5.1%20kafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84">5.1 kafka文件存储基本结构</h2>

<p>1.在Kafka文件存储中，同一个topic下有多个不同partition，每个partition为一个目录，partiton命名规则为topic名称+有序序号，第一个partiton序号从0开始，序号最大值为partitions数量减1。</p>

<p>2.每个partion(目录)相当于一个巨型文件被平均分配到多个大小相等segment(段)数据文件中。<strong><span style="color:#ff0000;"><strong>但每个段segment file消息数量不一定相等</strong></span></strong>，这种特性方便old segment file快速被删除。默认保留7天的数据。</p>

<p><img alt="" class="has" height="155" src="https://img-blog.csdn.net/20180815085913728?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p1b2NoYW5nX2xpdQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="320"></p>

<p>3.每个partiton只需要支持顺序读写就行了，segment文件生命周期由服务端配置参数决定。（什么时候创建，什么时候删除）</p>

<p><img alt="" class="has" height="168" src="https://img-blog.csdn.net/20180815085948831?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p1b2NoYW5nX2xpdQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="344"></p>

<blockquote>
<p>数据有序的讨论？</p>

<p>一个partition的数据是否是有序的？ 间隔性有序，不连续</p>

<p>针对一个topic里面的数据，只能做到partition内部有序，不能做到全局有序。</p>

<p>特别加入消费者的场景后，如何保证消费者消费的数据全局有序的？伪命题。</p>

<p>只有一种情况下才能保证全局有序？就是只有一个partition。</p>
</blockquote>

<h2 id="5.2%20kafka%20Partition%20Segment">5.2 kafka Partition Segment</h2>

<p><span style="color:#000000;">1.Segment</span><span style="color:#000000;"> file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀".index"和“.log”分别表示为segment索引文件、数据文件。</span></p>

<p><img alt="" class="has" height="173" src="https://img-blog.csdn.net/20180815115830892?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p1b2NoYW5nX2xpdQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="275"></p>

<p><span style="color:#000000;">2.Segment</span><span style="color:#000000;">文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。数值最大为64位long大小，19位数字字符长度，没有数字用0填充。</span></p>

<p><span style="color:#3e3e3e;">3.索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中message的物理偏移地址。</span></p>

<p><img alt="" class="has" height="201" src="https://img-blog.csdn.net/20180815115920111?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p1b2NoYW5nX2xpdQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="333"></p>

<p><span style="color:#3e3e3e;">上述图中索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中message的物理偏移地址。</span></p>

<p><span style="color:#3e3e3e;">其中以索引文件中元数据3,497为例，依次在数据文件中表示第3个message(在全局partiton表示第368772个message)、以及该消息的物理偏移地址为497。</span></p>

<p><span style="color:#3e3e3e;">segment data file由许多message组成， qq物理结构如下</span></p>

<table align="right" border="1" cellspacing="0" style="width:427.3pt;"><tbody><tr><td style="background-color:#f7f7f7;width:130.6pt;">
			<p style="margin-left:0pt;"><strong><span style="color:#3e3e3e;"><strong>关键字</strong></span></strong></p>
			</td>
			<td style="background-color:#f7f7f7;width:296.7pt;">
			<p style="margin-left:0pt;"><strong><span style="color:#3e3e3e;"><strong>解释说明</strong></span></strong></p>
			</td>
		</tr><tr><td style="background-color:#ffffff;width:130.6pt;">
			<p style="margin-left:0pt;"><span style="color:#3e3e3e;">8 byte offset</span></p>
			</td>
			<td style="background-color:#ffffff;width:296.7pt;">
			<p style="margin-left:0pt;"><span style="color:#3e3e3e;">在parition(分区)内的每条消息都有一个有序的id号，这个id号被称为偏移(offset),它可以唯一确定每条消息在parition(分区)内的位置。即offset表示partiion的第多少message</span></p>
			</td>
		</tr><tr><td style="background-color:#f8f8f8;width:130.6pt;">
			<p style="margin-left:0pt;"><span style="color:#3e3e3e;">4 byte message size</span></p>
			</td>
			<td style="background-color:#f8f8f8;width:296.7pt;">
			<p style="margin-left:0pt;"><span style="color:#3e3e3e;">message大小</span></p>
			</td>
		</tr><tr><td style="background-color:#ffffff;width:130.6pt;">
			<p style="margin-left:0pt;"><span style="color:#3e3e3e;">4 byte CRC32</span></p>
			</td>
			<td style="background-color:#ffffff;width:296.7pt;">
			<p style="margin-left:0pt;"><span style="color:#3e3e3e;">用crc32校验message</span></p>
			</td>
		</tr><tr><td style="background-color:#f8f8f8;width:130.6pt;">
			<p style="margin-left:0pt;"><span style="color:#3e3e3e;">1 byte “magic"</span></p>
			</td>
			<td style="background-color:#f8f8f8;width:296.7pt;">
			<p style="margin-left:0pt;"><span style="color:#3e3e3e;">表示本次发布Kafka服务程序协议版本号</span></p>
			</td>
		</tr><tr><td style="background-color:#ffffff;width:130.6pt;">
			<p style="margin-left:0pt;"><span style="color:#3e3e3e;">1 byte “attributes"</span></p>
			</td>
			<td style="background-color:#ffffff;width:296.7pt;">
			<p style="margin-left:0pt;"><span style="color:#3e3e3e;">表示为独立版本、或标识压缩类型、或编码类型。</span></p>
			</td>
		</tr><tr><td style="background-color:#f8f8f8;width:130.6pt;">
			<p style="margin-left:0pt;"><span style="color:#3e3e3e;">4 byte key length</span></p>
			</td>
			<td style="background-color:#f8f8f8;width:296.7pt;">
			<p style="margin-left:0pt;"><span style="color:#3e3e3e;">表示key的长度,当key为-1时，K byte key字段不填</span></p>
			</td>
		</tr><tr><td style="background-color:#ffffff;width:130.6pt;">
			<p style="margin-left:0pt;"><span style="color:#3e3e3e;">K byte key</span></p>
			</td>
			<td style="background-color:#ffffff;width:296.7pt;">
			<p style="margin-left:0pt;"><span style="color:#3e3e3e;">可选</span></p>
			</td>
		</tr><tr><td style="background-color:#f8f8f8;width:130.6pt;">
			<p style="margin-left:0pt;"><span style="color:#3e3e3e;">value bytes payload</span></p>
			</td>
			<td style="background-color:#f8f8f8;width:296.7pt;">
			<p style="margin-left:0pt;"><span style="color:#3e3e3e;">表示实际消息数据。</span></p>
			</td>
		</tr></tbody></table><p><br>
 </p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>

<h2 id="5.3%20kafka%E6%9F%A5%E6%89%BEmessage">5.3 kafka查找message</h2>

<p style="margin-left:0pt;">读取offset=368776的message，需要通过下面2个步骤查找。</p>

<p style="margin-left:0pt;"><img alt="" class="has" height="173" src="https://img-blog.csdn.net/20180815120240981?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p1b2NoYW5nX2xpdQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="275"></p>

<h3 id="5.3.1%20%E6%9F%A5%E6%89%BEsegment%20file" style="margin-left:0pt;">5.3.1 查找segment file</h3>

<p style="margin-left:0pt;">00000000000000000000.index表示最开始的文件，起始偏移量(offset)为0</p>

<p style="margin-left:0pt;">00000000000000368769.index的消息量起始偏移量为368770 = 368769 + 1</p>

<p style="margin-left:0pt;">00000000000000737337.index的起始偏移量为737338=737337 + 1</p>

<p style="margin-left:0pt;">其他后续文件依次类推。</p>

<p style="margin-left:0pt;">以起始偏移量命名并排序这些文件，只要根据offset **二分查找**文件列表，就可以快速定位到具体文件。当offset=368776时定位到00000000000000368769.index和对应log文件。</p>

<h3 id="5.3.2%20%E9%80%9A%E8%BF%87segment%20file%E6%9F%A5%E6%89%BEmessage" style="margin-left:0pt;">5.3.2 通过segment file查找message</h3>

<p style="margin-left:0pt;">当offset=368776时，依次定位到00000000000000368769.index的元数据物理位置和00000000000000368769.log的物理偏移地址</p>

<p style="margin-left:0pt;">然后再通过00000000000000368769.log顺序查找直到offset=368776为止。</p>

<p style="margin-left:0pt;"> </p>

<h1 id="6%20%E9%99%84%E5%8A%A0(broker%E5%AD%98%E5%82%A8%E6%B6%88%E6%81%AF)" style="margin-left:0pt;">6 附加(broker存储消息)</h1>

<h2 id="6.1%20%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F">6.1 消息存储方式</h2>

<p style="margin-left:0pt;">物理上把 topic 分成一个或多个 partition（对应 server.properties 中的 num.partitions=3 配置），每个 partition 物理上对应一个文件夹（该文件夹存储该 partition 的所有消息和索引文件），如下：</p>

<p><img alt="" class="has" height="235" src="https://img-blog.csdn.net/2018081512223664?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p1b2NoYW5nX2xpdQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="586"></p>

<h2 id="6.2%20%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8%E7%AD%96%E7%95%A5">6.2 消息存储策略</h2>

<p style="margin-left:0pt;">无论消息是否被消费，kafka 都会保留所有消息。有两种策略可以删除旧数据：</p>

<blockquote>
<p style="margin-left:0pt;">log.retention.hours=168 #基于时间</p>

<p style="margin-left:0pt;">log.retention.bytes=1073741824 #基于大小</p>
</blockquote>

<h2 id="6.3%20kafka%20log%E7%9A%84%E5%AD%98%E5%82%A8%E8%A7%A3%E6%9E%90" style="margin-left:0pt;">6.3 kafka log的存储解析</h2>

<p style="margin-left:0pt;">Partition中的每条Message由offset来表示它在这个partition中的偏移量，这个offset不是该Message在partition数据文件中的实际存储位置，而是逻辑上一个值，它唯一确定了partition中的一条Message。因此，可以认为offset是partition中Message的id。partition中的每条Message包含了以下三个属性：</p>

<ul><li>offset</li>
	<li>MessageSize</li>
	<li>data</li>
</ul><p style="margin-left:0pt;">其中offset为long型，MessageSize为int32，表示data有多大，data为message的具体内容。</p>

<p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;"><em><em>我们来思考一下，如果一个partition只有一个数据文件会怎么样？</em></em></p>

<ol><li><em><em>新数据是添加在文件末尾，不论文件数据文件有多大，这个操作永远都是高效的。</em></em></li>
	<li><em><em>查找某个offset的Message是顺序查找的。因此，如果数据文件很大的话，查找的效率就低。</em></em></li>
</ol><p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;"><strong><span style="color:#f33b45;">那Kafka是如何解决查找效率的的问题呢？有两大法宝：1) 分段 2) 索引。</span></strong></p>

<ul><li><strong><strong>数据文件的分段</strong></strong></li>
</ul><p style="margin-left:0pt;">Kafka解决查询效率的手段之一是将数据文件分段，比如有100条Message，它们的offset是从0到99。假设将数据文件分成5段，第一段为0-19，第二段为20-39，以此类推，每段放在一个单独的数据文件里面，数据文件以该段中最小的offset命名。这样在查找指定offset的Message的时候，用二分查找就可以定位到该Message在哪个段中。</p>

<ul><li><strong><strong>为数据文件建索引</strong></strong></li>
</ul><p style="margin-left:0pt;">数据文件分段使得可以在一个较小的数据文件中查找对应offset的Message了，但是这依然需要顺序扫描才能找到对应offset的Message。为了进一步提高查找的效率，Kafka为每个分段后的数据文件建立了索引文件，文件名与数据文件的名字是一样的，只是文件扩展名为.index。</p>

<p style="margin-left:0pt;">索引文件中包含若干个索引条目，每个条目表示数据文件中一条Message的索引。索引包含两个部分，分别为相对offset和position。</p>

<ul><li>相对offset：因为数据文件分段以后，每个数据文件的起始offset不为0，相对offset表示这条Message相对于其所属数据文件中最小的offset的大小。举例，分段后的一个数据文件的offset是从20开始，那么offset为25的Message在index文件中的相对offset就是25-20 = 5。存储相对offset可以减小索引文件占用的空间。</li>
	<li>position，表示该条Message在数据文件中的绝对位置。只要打开文件并移动文件指针到这个position就可以读取对应的Message了。</li>
</ul><p style="margin-left:0pt;">index文件中并没有为数据文件中的每条Message建立索引，而是采用了稀疏存储的方式，每隔一定字节的数据建立一条索引。这样避免了索引文件占用过多的空间，从而可以将索引文件保留在内存中。但缺点是没有建立索引的Message也不能一次定位到其在数据文件的位置，从而需要做一次顺序扫描，但是这次顺序扫描的范围就很小了。</p>

<p style="margin-left:0pt;">我们以几张图来总结一下Message是如何在Kafka中存储的，以及如何查找指定offset的Message的。</p>

<p style="margin-left:0pt;">Message是按照topic来组织，每个topic可以分成多个的partition，比如：有5个partition的名为为page_visits的topic的目录结构为：</p>

<p style="margin-left:0pt;"><img alt="" class="has" height="55" src="https://img-blog.csdn.net/20180815122632236?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p1b2NoYW5nX2xpdQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="304"></p>

<p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;">partition是分段的，每个段叫Segment，包括了一个数据文件和一个索引文件，下图是某个partition目录下的文件：</p>

<p style="margin-left:0pt;"><img alt="" class="has" height="139" src="https://img-blog.csdn.net/20180815122644462?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p1b2NoYW5nX2xpdQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="139"></p>

<p style="margin-left:0pt;">可以看到，这个partition有4个Segment。</p>

<p style="margin-left:0pt;"> </p>

<p style="margin-left:0pt;"><strong>图示Kafka是如何查找Message的。</strong></p>

<p style="margin-left:0pt;"><img alt="" class="has" height="343" src="https://img-blog.csdn.net/20180815122658551?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p1b2NoYW5nX2xpdQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="505"></p>

<p style="margin-left:0pt;">比如：要查找绝对offset为7的Message：</p>

<blockquote>
<p style="margin-left:0pt;">首先是用二分查找确定它是在哪个LogSegment中，自然是在第一个Segment中。</p>

<p style="margin-left:0pt;">打开这个Segment的index文件，也是用二分查找找到offset小于或者等于指定offset的索引条目中最大的那个offset。自然offset为6的那个索引是我们要找的，通过索引文件我们知道offset为6的Message在数据文件中的位置为9807。</p>

<p style="margin-left:0pt;">打开数据文件，从位置为9807的那个地方开始顺序扫描直到找到offset为7的那条Message。</p>

<p style="margin-left:0pt;">这套机制是建立在offset是有序的。索引文件被映射到内存中，所以查找的速度还是很快的。</p>
</blockquote>

<p style="margin-left:0pt;">一句话，Kafka的Message存储采用了分区(partition)，分段(LogSegment)和稀疏索引这几个手段来达到了高效性。</p>            </div>
                </div>