---
layout:     post
title:      Hadoop初探学习（1）——hadoop的简史
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/milhua/article/details/78977669				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p><span style="font-family:'Courier New';font-size:16px;">初探hadoop,去了解hadoop的简史对于我们学习hadoop有很大的帮助，下面我们来看看什么是hadoop？</span></p><h4 style="line-height:90%;margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-size:12px;"><span style="font-family:'Courier New';">一. What Is Apache Hadoop?</span></span></h4><p style="line-height:90%;margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">（1）The Apache™ Hadoop® project developsopen-source software for reliable, scalable, distributed computing.</span></p><p style="line-height:90%;margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">（2）hadoop要去解决的问题：<span style="text-indent:-.38in;">①海量数据的存储（HDFS）</span><span style="text-indent:-.38in;">②海量数据的分析（MapperReduce）</span><span style="text-indent:-.38in;">③资源管理调度（YARN）。</span></span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">（3）始于apache项目Nutch</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;"><span></span>2003年Google发表了关于GFS的论文</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;"><span></span>2004年Nutch的开发者开发了NDFS</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;"><span></span>2004年Google发表了关于MapReduce的论文</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;"><span></span>2005年MapReduce被引入了NDFS</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;"><span></span>2006年改名为Hadoop，NDFS的创始人加入Yahoo，Yahoo成立了一个专门的小组发展Hadoop</span></p><p style="vertical-align:baseline;"><span style="text-indent:-.38in;"><span style="font-family:'Courier New';font-size:16px;">（4）Hadoop大事记</span></span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">2004年-- 最初的版本(现在称为HDFS和MapReduce)由Doug Cutting和Mike Cafarella开始实施。</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">2005年12月-- Nutch移植到新的框架，Hadoop在20个节点上稳定运行。</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">2006年01月-- Doug Cutting加入雅虎。</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">2006年02月-- Apache Hadoop项目正式启动以支持MapReduce和HDFS的独立发展。</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">2006年02月-- 雅虎的网格计算团队采用Hadoop。</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">2006年04月-- 标准排序(10 GB每个节点)在188个节点上运行47.9个小时。</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">2006年05月-- 雅虎建立了一个300个节点的Hadoop研究集群。</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">2006年05月-- 标准排序在500个节点上运行42个小时(硬件配置比4月的更好)。</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">2006年11月-- 研究集群增加到600个节点。</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">2006年12月-- 标准排序在20个节点上运行1.8个小时，100个节点3.3小时，500个节点5.2小时，900个节点7.8个小时。</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">2007年01月-- 研究集群到达900个节点。</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">2007年04月-- 研究集群达到两个1000个节点的集群。</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">2008年04月-- 赢得世界最快1TB数据排序在900个节点上用时209秒。</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">2008年10月-- 研究集群每天装载10 TB的数据。</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">2009年03月-- 17个集群总共24 000台机器。</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">2009年04月-- 赢得每分钟排序，59秒内排序500 GB(在1400个节点上)和173分钟内排序100 TB数据(在3400个节点上)。</span></p><p style="vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;"><br></span></p><h3 style="line-height:90%;margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'FangSong_GB2312';">二. 作者介绍</span></h3><p></p><p style="line-height:90%;margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;"><span></span>hadoop的作者是Doug Cutting，<span style="text-indent:-.38in;">受Google三篇论文的启发(GFS、MapReduce、BigTable)，Doug </span></span></p><p style="line-height:90%;margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;"><span style="text-indent:-.38in;">Cutting开源的实现hadoop这个超级工程。</span></span></p><h3><span style="font-family:'Courier New';font-size:16px;">三. hadoop具体能干什么？</span></h3><span style="font-family:'Courier New';font-size:16px;">（1）<span style="text-indent:-.38in;">hadoop</span><span style="text-indent:-.38in;">擅长日志分析，</span><span style="text-indent:-.38in;">facebook</span><span style="text-indent:-.38in;">就用</span><span style="text-indent:-.38in;">Hive</span><span style="text-indent:-.38in;">来进行日志分析，</span><span style="text-indent:-.38in;">2009</span><span style="text-indent:-.38in;">年时</span><span style="text-indent:-.38in;">facebook</span><span style="text-indent:-.38in;">就有非编程人员的</span><span style="text-indent:-.38in;">30%</span><span style="text-indent:-.38in;">的人使用</span><span style="text-indent:-.38in;">HiveQL</span><span style="text-indent:-.38in;">进行数据分析；淘宝搜索中的自定</span></span><span style="font-family:'Courier New';font-size:18px;text-indent:-.38in;"><span style="text-indent:-.38in;">义</span></span><span style="font-family:'Courier New';font-size:18px;text-indent:-.38in;">筛选也使用的</span><span style="font-family:'Courier New';font-size:18px;text-indent:-.38in;">Hive</span><span style="font-family:'Courier New';font-size:18px;text-indent:-.38in;">；利用</span><span style="font-family:'Courier New';font-size:18px;text-indent:-.38in;">Pig</span><span style="font-family:'Courier New';font-size:18px;text-indent:-.38in;">还可以做高级的数据处理，包括</span><span style="font-family:'Courier New';font-size:18px;text-indent:-.38in;">Twitter</span><span style="font-family:'Courier New';font-size:18px;text-indent:-.38in;">、</span><span style="font-family:'Courier New';font-size:18px;text-indent:-.38in;">LinkedIn</span><span style="font-family:'Courier New';font-size:18px;text-indent:-.38in;">上用于发现您可能认识的人，可以实现类似</span><span style="font-family:'Courier New';font-size:18px;text-indent:-.38in;">Amazon.com</span><span style="font-family:'Courier New';font-size:18px;text-indent:-.38in;">的协同过滤的推荐</span><p style="line-height:90%;margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;"><span style="text-indent:-.38in;">效</span><span style="text-indent:-.38in;">果。淘宝的商品推荐也是！在</span><span style="text-indent:-.38in;">Yahoo</span><span style="text-indent:-.38in;">！的</span><span style="text-indent:-.38in;">40%</span><span style="text-indent:-.38in;">的</span><span style="text-indent:-.38in;">Hadoop</span><span style="text-indent:-.38in;">作业是用</span><span style="text-indent:-.38in;">pig</span><span style="text-indent:-.38in;">运行的，包括垃圾邮件的识别和过滤，还有</span></span></p><p style="line-height:90%;margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;"><span style="text-indent:-.38in;">用户特征建模。（</span><span style="text-indent:-.38in;">2012</span><span style="text-indent:-.38in;">年</span><span style="text-indent:-.38in;">8</span><span style="text-indent:-.38in;">月</span><span style="text-indent:-.38in;">25</span><span style="text-indent:-.38in;">新更新，天</span><span style="text-indent:-.38in;">猫</span></span></p><p style="line-height:90%;margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;"><span style="text-indent:-.38in;">的推荐系统是</span><span style="text-indent:-.38in;">hive</span><span style="text-indent:-.38in;">，少量尝试</span><span style="text-indent:-.38in;">mahout</span><span style="text-indent:-.38in;">！）</span></span></p><h3>四. 哪些公司使用hadoop？</h3><div><div style="margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'FangSong_GB2312';font-size:12px;">（</span><span style="font-family:'Courier New';font-size:16px;">1）Hadoop被公认是一套行业大数据标准开源软件，在分布式环境下提供了海量数据的处理能力。几乎所有主流厂商都围绕Hadoop开发工具、开源软件、商业化工具<span style="text-indent:-.38in;">和技术服务。今年大型</span><span style="text-indent:-.38in;">IT</span><span style="text-indent:-.38in;">公司，如</span><span style="text-indent:-.38in;">EMC</span><span style="text-indent:-.38in;">、</span><span style="text-indent:-.38in;">Microsoft</span><span style="text-indent:-.38in;">、</span><span style="text-indent:-.38in;">Intel</span><span style="text-indent:-.38in;">、</span><span style="text-indent:-.38in;">Teradata</span><span style="text-indent:-.38in;">、</span><span style="text-indent:-.38in;">Cisco</span><span style="text-indent:-.38in;">都明显增加了</span><span style="text-indent:-.38in;">Hadoop</span><span style="text-indent:-.38in;">方面的投入。</span></span></div><span style="font-family:'Courier New';font-size:16px;">（2）hadoop在淘宝：</span></div><div><div style="margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;"><span></span>a. 从09年开始，用于对海量数据的离线处理，例如对日志的分析，交易记录的分析等</span></div><div style="margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;"><span></span>b. 规模从当初的3~4百台节点，增加到现在的一个集群有3000个节点，淘宝现在已经有2~3个这样的集群</span></div><div style="margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;"><span></span>c .在支付宝的集群规模也有700台节点，使用Hbase对用户的消费记录可以实现毫秒级查询</span></div><h3 style="margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'Courier New';font-size:16px;">五. 架构总览</span></h3><div><span style="font-family:'FangSong_GB2312';font-size:12px;"><img src="https://img-blog.csdn.net/20180105101105252?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbWlsaHVh/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></div><h3><span style="font-family:'FangSong_GB2312';font-size:12px;">六. hadoop EcoSystem Map</span></h3><div><span style="font-family:'FangSong_GB2312';"><span style="font-size:16px;">（1）说明图</span></span></div><div style="margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'FangSong_GB2312';font-size:12px;"><img src="https://img-blog.csdn.net/20180105101559927?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbWlsaHVh/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""><br></span></div><div style="margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'FangSong_GB2312';font-size:12px;">（</span><span style="font-family:'FangSong_GB2312';"><span style="font-size:16px;">2）说明图阐述</span></span></div><div style="margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-size:16px;"><span style="font-family:'FangSong_GB2312';"></span></span><p style="vertical-align:baseline;"><span style="font-size:16px;"><span style="font-family:'Times New Roman';">       </span>1. 这一切是如何开始的—Web上庞大的数据!</span></p><p style="vertical-align:baseline;"><span style="font-size:16px;">　　2.使用Nutch抓取Web数据</span></p><p style="vertical-align:baseline;"><span style="font-size:16px;">　　3.要保存Web上庞大的数据——HDFS应运而生</span></p><p style="vertical-align:baseline;"><span style="font-size:16px;">　　4.如何使用这些庞大的数据?</span></p><p style="vertical-align:baseline;"><span style="font-size:16px;">　　5.采用Java或任何的流/管道语言构建MapReduce框架用于编码并进行分析</span></p><p style="vertical-align:baseline;"><span style="font-size:16px;">　　6.如何获取Web日志，点击流，Apache日志，服务器日志等非结构化数据——fuse,webdav,chukwa, flume, Scribe</span></p><p style="vertical-align:baseline;"><span style="font-size:16px;">　　7.Hiho和sqoop将数据加载到HDFS中，关系型数据库也能够加入到Hadoop队伍中</span></p><p style="vertical-align:baseline;"><span style="font-size:16px;">　　8.MapReduce编程需要的高级接口——Pig,Hive, Jaql</span></p><p style="vertical-align:baseline;"><span style="font-size:16px;">　　9.具有先进的UI报表功能的BI工具- Intellicus</span></p><p style="vertical-align:baseline;"><span style="font-size:16px;">　　10.Map-Reduce处理过程使用的工作流工具及高级语言</span></p><p style="vertical-align:baseline;"><span style="font-size:16px;">　　11.监控、管理hadoop，运行jobs/hive，查看HDFS的高级视图—Hue,karmasphere, eclipse plugin, cacti, ganglia</span></p><p style="vertical-align:baseline;"><span style="font-size:16px;">　　12.支持框架—Avro(进行序列化), Zookeeper (用于协同)</span></p><p style="vertical-align:baseline;"><span style="font-size:16px;">　　13.更多高级接口——Mahout,Elastic map Reduce</span></p><p style="vertical-align:baseline;"><span style="font-size:16px;">　　14.同样可以进行OLTP——Hbase</span></p><h3 style="vertical-align:baseline;">七. 集群存储和计算的主要瓶颈</h3><br></div><div style="margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'FangSong_GB2312';font-size:12px;"><img src="https://img-blog.csdn.net/20180105104205345" alt=""><br></span></div><h3 style="margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-size:12px;"><span style="font-family:'FangSong_GB2312';">八. <span style="color:rgb(51,102,102);">Hadoop和虚拟化的差异点</span></span></span></h3><div style="margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'FangSong_GB2312';font-size:12px;"><img src="https://img-blog.csdn.net/20180105104415973" alt=""><br></span></div><h3 style="margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'FangSong_GB2312';">九. hadoop核心</span></h3><div><span style="font-family:'FangSong_GB2312';"></span><div style="margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-size:16px;">lHDFS: Hadoop Distributed File System 分布式文件系统 </span></div><div style="margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-size:16px;">lYARN: Yet Another Resource Negotiator <span style="text-indent:-.38in;">资源管理调度系统</span></span></div><h3 style="margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="text-indent:-.38in;"><span style="font-size:16px;">十. hadoop的特点</span></span></h3><div><span style="font-size:16px;"><span style="text-indent:-.38in;"></span></span><div style="line-height:80%;margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'FangSong_GB2312';"><span style="font-size:16px;">（1）扩容能力（Scalable）：能可靠地（reliably）存储和处理千兆字节（PB）数据。</span></span></div><div style="line-height:80%;margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'FangSong_GB2312';"><span style="font-size:16px;">（2）成本低（Economical）：可以通过普通机器组成的服务器群来分发以及处理数据。这些服务器群总计可达数</span></span></div><div style="line-height:80%;margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'FangSong_GB2312';"><span style="font-size:16px;">千个节点。</span></span></div><div style="line-height:80%;margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'FangSong_GB2312';"><span style="font-size:16px;">（3）高效率（Efficient）：通过分发数据，hadoop可以在数据所在的节点上并行地（parallel）处理它们，这使</span></span></div><div style="line-height:80%;margin-left:.38in;text-indent:-.38in;vertical-align:baseline;"><span style="font-family:'FangSong_GB2312';"><span style="font-size:16px;">得处理非常的快速。</span></span></div><span style="font-size:16px;"><span style="font-family:'FangSong_GB2312';">（4）可靠性（Reliable）：hadoop能自动地维护数据的多份副本，并且在任务失败后能自动地重新部署（redeploy）计算任务。</span><br></span></div><div><span style="font-size:16px;">十一. hadoop1.0跟hadoop2.0对比</span></div><div><img src="https://img-blog.csdn.net/20180105110502938" alt=""><br></div></div></div>            </div>
                </div>