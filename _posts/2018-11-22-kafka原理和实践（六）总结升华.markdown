---
layout:     post
title:      kafka原理和实践（六）总结升华
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <div class="blogpost-body"><a></a><div><p style="font-size:18px;"><b>目录</b></p><ul><li><a href="#_label0" rel="nofollow">总结篇</a></li><li><a href="#_label1" rel="nofollow">1.官方介绍</a></li><li><a href="#_label2" rel="nofollow">2.特点</a></li><li><a href="#_label3" rel="nofollow">3.Kafka的设计</a></li><li><a href="#_label4" rel="nofollow">4.Kayka的应用场景</a></li><li><a href="#_label5" rel="nofollow">5.总结</a></li></ul></div><p> </p><p style="font-size:18px;"><b>正文</b></p><p>系列目录</p>
<p><a class="singleposttitle" href="http://www.cnblogs.com/dennyzhangdd/p/7759869.html" rel="nofollow">kafka原理和实践（一）原理：10分钟入门</a></p>
<p><a href="http://www.cnblogs.com/dennyzhangdd/p/7759875.html" rel="nofollow">kafka原理和实践（二）spring-kafka简单实践</a></p>
<p><a class="singleposttitle" href="http://www.cnblogs.com/dennyzhangdd/p/7827564.html" rel="nofollow">kafka原理和实践（三）spring-kafka生产者源码</a></p>
<p><a href="http://www.cnblogs.com/dennyzhangdd/p/7759876.html" rel="nofollow">kafka原理和实践（四）spring-kafka消费者源码</a></p>
<p><a class="singleposttitle" href="http://www.cnblogs.com/dennyzhangdd/p/7834143.html" rel="nofollow">kafka原理和实践（五）spring-kafka配置详解</a></p>
<p><a href="http://www.cnblogs.com/dennyzhangdd/p/7759878.html" rel="nofollow">kafka原理和实践（六）总结升华</a></p>
<p> =========正文分割线==============</p>
<div style="text-align:right;"><a href="#_labelTop" rel="nofollow">回到顶部</a><a></a></div><h2>总结篇</h2>
<p>本系列spring-kafka文章，分别从入门、简单实践、生产者和消费源码、配置详解、乃至最后本文的总结共六个章节，从不同角度分析原理和实践。</p>
<p>只能算是入门级简单分析，很多kafka特性并没有拓展开来分析，下面我们总结一下kafka应用和重要特性：</p>
<div style="text-align:right;"><a href="#_labelTop" rel="nofollow">回到顶部</a><a></a></div><h2>1.官方介绍</h2>
<p><strong>Kafka™ is <em>a distributed streaming platform</em>,官方这样描述kafka,即分布式流处理平台</strong></p>
<p>1.系统具备<span style="color:#ff0000;">发布和订阅</span>流数据的能力, 在这方面, 它类似于消息队列或企业消息总线--》消息系统</p>
<p>2.系统具备在存储数据时具备<span style="color:#ff0000;">容错</span>能力--》储存系统</p>
<p>3.系统具备在数据流<span style="color:#ff0000;">触发</span>时进行<span style="color:#ff0000;">实时处理<span style="color:#000000;">--》数据流处理</span></span></p>
<div style="text-align:right;"><a href="#_labelTop" rel="nofollow">回到顶部</a><a></a></div><h2>2.特点</h2>
<ol><li>同时为发布和订阅提供高吞吐量。据了解，Kafka每秒可以生产约25万消息（50 MB），每秒处理55万消息（110 MB）。</li>
<li>可进行持久化操作。将消息持久化到磁盘，因此可用于批量消费，例如ETL，以及实时应用程序。通过将数据持久化到硬盘以及replication防止数据丢失。</li>
<li>分布式系统，易于向外扩展。所有的producer、broker和consumer都会有多个，均为分布式的。无需停机即可扩展机器。</li>
<li>消息被处理的状态是在consumer端维护，而不是由server端维护。当失败时能自动平衡。</li>
<li>支持online和offline的场景。</li>
</ol><div style="text-align:right;"><a href="#_labelTop" rel="nofollow">回到顶部</a><a></a></div><h2>3.Kafka的设计</h2>
<p><strong>1、吞吐量</strong></p>
<p>高吞吐是kafka需要实现的核心目标之一，为此kafka做了以下一些设计：</p>
<ol><li>数据磁盘持久化：消息不在内存中cache，直接写入到磁盘，充分利用磁盘的顺序读写性能</li>
<li>zero-copy：减少IO操作步骤</li>
<li>数据批量发送</li>
<li>数据压缩</li>
<li>Topic划分为多个partition，提高parallelism</li>
</ol><p><strong>2.负载均衡</strong></p>
<ol><li>producer根据用户指定的算法，将消息发送到指定的partition</li>
<li>存在多个partiiton，每个partition有自己的replica，每个replica分布在不同的Broker节点上</li>
<li>多个partition需要选取出lead partition，lead partition负责读写，并由zookeeper负责fail over</li>
<li>通过zookeeper管理broker与consumer的动态加入与离开</li>
</ol><div style="text-align:right;"><a href="#_labelTop" rel="nofollow">回到顶部</a><a></a></div><h2>4.Kayka的应用场景</h2>
<p>1.消息队列</p>
<p>比起大多数的消息系统来说，Kafka有更好的吞吐量，内置的分区，冗余及容错性，这让Kafka成为了一个很好的大规模消息处理应用的解决方案。 消息系统一般吞吐量相对较低，但是需要更小的端到端延时，并尝尝依赖于Kafka提供的强大的持久性保障。在这个领域，Kafka足以媲美传统消息系统， 如<a href="http://activemq.apache.org/" rel="nofollow">ActiveMR</a>或<a href="https://www.rabbitmq.com/" rel="nofollow">RabbitMQ</a>。</p>
<p>2.行为跟踪</p>
<p>Kafka的另一个应用场景是跟踪用户浏览页面、搜索及其他行为，以发布-订阅的模式实时记录到对应的topic里。那么这些结果被订阅者拿到后，就可以做进一步的实时处理，或实时监控，或放到hadoop/离线数据仓库里处理。</p>
<p>3.元信息监控</p>
<p>作为操作记录的监控模块来使用，即汇集记录一些操作信息，可以理解为运维性质的数据监控吧。</p>
<p>4.日志收集</p>
<p>日志收集方面，其实开源产品有很多，包括Scribe、Apache Flume。很多人使用Kafka代替日志聚合（log aggregation）。日志聚合一般来说是从服务器上收集日志文件，然后放到一个集中的位置（文件服务器或HDFS）进行处理。然而Kafka忽略掉 文件的细节，将其更清晰地抽象成一个个日志或事件的消息流。这就让Kafka处理过程延迟更低，更容易支持多数据源和分布式数据处理。比起以日志为中心的 系统比如Scribe或者Flume来说，Kafka提供同样高效的性能和因为复制导致的更高的耐用性保证，以及更低的端到端延迟。</p>
<p>5.流处理</p>
<p>这个场景可能比较多，也很好理解。保存收集流数据，以提供之后对接的Storm或其他流式计算框架进行处理。很多用户会将那些从原始topic来的 数据进行阶段性处理，汇总，扩充或者以其他的方式转换到新的topic下再继续后面的处理。例如一个文章推荐的处理流程，可能是先从RSS数据源中抓取文 章的内容，然后将其丢入一个叫做“文章”的topic中；后续操作可能是需要对这个内容进行清理，比如回复正常数据或者删除重复数据，最后再将内容匹配的 结果返还给用户。这就在一个独立的topic之外，产生了一系列的实时数据处理的流程。<a href="http://storm.incubator.apache.org/" rel="nofollow">Strom</a>和<a href="http://samza.incubator.apache.org/" rel="nofollow">Samza</a>是非常著名的实现这种类型数据转换的框架。</p>
<p>6.事件源</p>
<p>事件源是一种应用程序设计的方式，该方式的状态转移被记录为按时间顺序排序的记录序列。Kafka可以存储大量的日志数据，这使得它成为一个对这种方式的应用来说绝佳的后台。比如动态汇总（News feed）。</p>
<p>7.持久性日志（commit log）</p>
<p>Kafka可以为一种外部的持久性日志的分布式系统提供服务。这种日志可以在节点间备份数据，并为故障节点数据回复提供一种重新同步的机制。Kafka中日志压缩功能为这种用法提供了条件。在这种用法中，Kafka类似于Apache BookKeeper项目。</p>
<p><span style="color:#ff0000;">实际应用中，适用最多最广泛的自然是MQ的功能。</span></p>
<div style="text-align:right;"><a href="#_labelTop" rel="nofollow">回到顶部</a><a></a></div><h2>5.总结</h2>
<p>kafka官方认为是一个分布式流处理平台，然而现实很残酷，在互联网领域，它顶多也就是个MQ，<span style="color:#ff0000;">终极一句话总结：一个吞吐量还不错的MQ，一个应用于各种场景的MQ。</span></p>
<p> </p></div>            </div>
                </div>