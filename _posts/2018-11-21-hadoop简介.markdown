---
layout:     post
title:      hadoop简介
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/struct_slllp_main/article/details/74426916				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p align="left">1、Hadoop定义</p>
<p align="left"><span></span>Hadoop是一个由Apache基金会所开发的分布式系统基础架构。</p>
<p align="left"></p>
<p align="left">2、Hadoop有什么</p>
<p align="left"><span></span>Hadoop的框架最核心的设计就是：HDFS和MapReduce。</p>
<p align="left"><span></span>HDFS是一个分布式文件系统（Hadoop DistributedFile System）。HDFS有高容错性的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问应用程序的数据，适合那些有着超大数据集（large data set）的应用程序，而且可以以流的形式访问（streamingaccess）文件系统中的数据。</p>
<p align="left">HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算。</p>
<p align="left">3、<span> </span>Hadoop的优点：<br><span></span>高可靠性。Hadoop假设计算元素和存储会失败，因此它维护多个工作数据副本，确保能够针对失败的节点重新分布处理。<br><span></span>高扩展性。Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。<br><span></span>高效性。Hadoop以并行的方式工作，能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。<br><span></span>低成本。与一体机、商用数据仓库以及QlikView、Yonghong Z-Suite等数据集市相比，hadoop是开源的，项目的软件成本因此会大大降低<br>
4、HDFS为什么不适合存储海量小文件？<br><span></span>HDFS中，namenode将文件系统中的元数据存储在内存中，因此，HDFS所能存储的文件数量会受到namenode内存的限制。一般来说，每个文件、目录、数据块的存储信息大约占150个字节，根据当前namenode的内存空间的配置，就可以计算出大约能容纳多少个文件了。<br>
有一种误解就是，之所以HDFS不适合大量小文件，是因为即使很小的文件也会占用一个块的存储空间。这是错误的，HDFS与其它文件系统不同，小于一个块大小的文件，不会占用一个块的空间。<br>
5、HDFS的机架感知策略<br><span></span>分布式的集群通常包含非常多的机器，由于受到机架槽位和交换机网口的限制，通常大型的分布式集群都会跨好几个机架，由多个机架上的机器共同组成一个分布式集群。机架内的机器之间的网络速度通常都会高于跨机架机器之间的网络速度，并且机架之间机器的网络通信通常受到上层交换机间网络带宽的限制。 具体到Hadoop集群，由于hadoop的HDFS对数据文件的分布式存放是按照分块block存储，每个block会有多个副本(默认为3)，并且为了数据的安全和高效，所以hadoop默认对3个副本的存放策略为：<br>
第一个block副本放在和client所在的node里（如果client不在集群范围内，则这第一个node是随机选取的）。<br>
第二个副本放置在与第一个节点不同的机架中的node中（随机选择）。 <br>
第三个副本似乎放置在与第一个副本所在节点同一机架的另一个节点上<br>
如果还有更多的副本就随机放在集群的node里。<br>
这样的策略可以保证对该block所属文件的访问能够优先在本rack下找到，如果整个rack发生了异常，也可以在另外的rack上找到该block的副本。这样足够的高效，并且同时做到了数据的容错。<br>
但是，hadoop对机架的感知并非是自适应的，亦即，hadoop集群分辨某台slave机器是属于哪个rack并非是智能感知的，而是需要hadoop的管理者人为的告知hadoop哪台机器属于哪个rack，这样在hadoop的namenode启动初始化时，会将这些机器与rack的对应信息保存在内存中，用来作为对接下来所有的HDFS的写块操作分配datanode列表时（比如3个block对应三台datanode）的选择datanode策略，做到hadoop allocate block的策略：尽量将三个副本分布到不同的rack。<br>
6、record，split，map，reduce：<br><span></span>RecordRead作用:把我们输入数据文本文件中每一行转换为一个个的键值对.行数据从hdfs中数据中来,在hdfs中存的数据是海量数据,上T的规模,RecordRead到底取哪些数据?我们在对hdfs原始数据进行处理的时候还需要对原始数据做一下划分,划分成一个个的小单位,一个小单位供一个map来处理,这个小单位就叫做InputSplit.<br>
InputSplit就是我们mapreduce对hdfs数据的划分.一个InputSplit默认情况下对应一个block,,每一个InputSplit对应一个map. <br>
一个DataNode上面有多个map，一个map处理一个split，map之前可以有setup函数，之后可以有cleanup函数（以日志处理中统计多IP为例）<br>
中间会有shuffle过程：自定义partition，sort，Merge，combiner(解释)<br>
一个reduce产生一个文件<br>
7、hdfs文件的数据结构<br><span></span>SequenceFile的存储类似于Log文件，所不同的是Log File的每条记录的是纯文本数据，而SequenceFile的每条记录是可序列化的字符数组，所以，每条记录以键值对的方式进行组织，但前提是Key和Value需具备序列化和反序列化的功能，在存储结构上，SequenceFile主要由一个Header后跟多条Record组成<br>
MapFile是排序后的SequenceFile,通过观察其目录结构可以看到MapFile由两部分组成，分别是data和index。<br>
index作为文件的数据索引，主要记录了每个Record的key值，以及该Record在文件中的偏移位置。在MapFile被访问的时候,索引文件会被加载到内存，通过索引映射关系可迅速定位到指定Record所在文件位置，因此，相对SequenceFile而言，MapFile的检索效率是高效的，缺点是会消耗一部分内存来存储index数据。<br>
需注意的是，MapFile并不会把所有Record都记录到index中去，默认情况下每隔128条记录存储一个索引映射。当然，记录间隔可人为修改，通过MapFIle.Writer的setIndexInterval()方法，或修改io.map.index.interval属性；<br>
另外，与SequenceFile不同的是，MapFile的KeyClass一定要实现WritableComparable接口,即Key值是可比较的。<br></p>
<br>            </div>
                </div>