---
layout:     post
title:      flume的原理
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p style="background:#FEFEFE;"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">Flume </span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">作为 cloudera </span>开发的实时日志收集系统，受到了业界的认可与广泛应用。Flume 初始的发行版本目前被统称为 Flume OG（original generation），属于 cloudera。但随着 FLume 功能的扩展，Flume OG 代码工程臃肿、核心组件设计不合理、核心配置不标准等缺点暴露出来，尤其是在 Flume OG 的最后一个发行版本 0.94.0 中，日志传输不稳定的现象尤为严重，为了解决这些问题，2011 年 10 月 22 号，cloudera 完成了 Flume-728，对 Flume 进行了里程碑式的改动：重构核心组件、核心配置以及代码架构，重构后的版本统称为 Flume NG（next generation）；改动的另一原因是将 Flume 纳入 apache 旗下，clouderaFlume 改名为 Apache Flume。IBM 的这篇文章：《 <span style="font-weight:bold;"><em><span style="background:rgb(254,254,254);color:rgb(148,148,148);"><a href="http://www.ibm.com/developerworks/cn/data/library/bd-1404flumerevolution/index.html" rel="nofollow"><u><span style="color:rgb(148,148,148);">Flume NG</span><span style="color:rgb(148,148,148);">：</span></u></a></span><span style="color:rgb(148,148,148);">Flume </span><span style="color:rgb(148,148,148);">发展史上的第一次革命</span></em></span><span style="background:rgb(254,254,254);color:rgb(51,51,51);"> </span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">》，从基本组件以及用户体验的角度阐述 Flume OG </span>到 Flume NG 发生的革命性变化。本文就不再赘述各种细枝末节了，不过这里还是简要提下 Flume NG （1.x.x）的主要变化：</p><p><span style="color:#000000;">·    </span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">sources</span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">和sinks </span>使用channels 进行链接</p><p><span style="color:#000000;">·    </span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">两个主要channel</span>。1，  in-memory channel 非持久性支持，速度快。2 ， JDBC-basedchannel 持久性支持。</p><p><span style="color:#000000;">·    </span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">不再区分逻辑和物理node</span>，所有物理节点统称为 “agents”,每个agents 都能运行0个或多个sources 和sinks</p><p><span style="color:#000000;">·    </span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">不再需要master</span>节点和对zookeeper的依赖，配置文件简单化。</p><p><span style="color:#000000;">·    </span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">插件化，一部分面对用户，工具或系统开发人员。</span></p><p><span style="color:#000000;">·    </span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">使用Thrift</span>、Avro Flume sources 可以从flume0.9.4 发送 events  到flume 1.x</p><p style="background:#FEFEFE;"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">注：本文所使用的 Flume </span>版本为 flume-1.4.0-cdh4.7.0，不需要额外的安装过程，解压缩即可用。 </p><h2 style="background:rgb(254,254,254);"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">1</span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">、Flume </span>的 一些核心概念：</h2><table style="background:rgb(254,254,254);" border="1" cellspacing="3" cellpadding="0"><tbody><tr><td valign="top"><p align="left"><span><span style="color:rgb(51,51,51);">组件</span></span></p></td>  <td valign="top"><p align="left"><span><span style="color:rgb(51,51,51);">功能</span></span></p></td> </tr><tr><td valign="top"><p align="left"><span style="color:rgb(51,51,51);">Agent</span></p></td>  <td valign="top"><p align="left"><span style="color:rgb(51,51,51);">使用JVM </span>运行Flume。每台机器运行一个agent，但是可以在一个agent中包含多个sources和sinks。</p></td> </tr><tr><td valign="top"><p align="left"><span style="color:rgb(51,51,51);">Client</span></p></td>  <td valign="top"><p align="left"><span style="color:rgb(51,51,51);">生产数据，运行在一个独立的线程。</span></p></td> </tr><tr><td valign="top"><p align="left"><span style="color:rgb(51,51,51);">Source</span></p></td>  <td valign="top"><p align="left"><span style="color:rgb(51,51,51);">从Client</span>收集数据，传递给Channel。</p></td> </tr><tr><td valign="top"><p align="left"><span style="color:rgb(51,51,51);">Sink</span></p></td>  <td valign="top"><p align="left"><span style="color:rgb(51,51,51);">从Channel</span>收集数据，运行在一个独立线程。</p></td> </tr><tr><td valign="top"><p align="left"><span style="color:rgb(51,51,51);">Channel</span></p></td>  <td valign="top"><p align="left"><span style="color:rgb(51,51,51);">连接 sources </span>和 sinks ，这个有点像一个队列。</p></td> </tr><tr><td valign="top"><p align="left"><span style="color:rgb(51,51,51);">Events</span></p></td>  <td valign="top"><p align="left"><span style="color:rgb(51,51,51);">可以是日志记录、 avro </span>对象等。</p></td> </tr></tbody></table><h2 style="background:rgb(254,254,254);"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">1.1 </span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">数据流模型</span></h2><p style="background:#FEFEFE;"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">Flume</span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">以agent</span>为最小的独立运行单位。一个agent就是一个JVM。单agent由Source、Sink和Channel三大组件构成，如下图：</p><p style="background:#FEFEFE;"></p><p></p><div><span style="background:rgb(254,254,254);color:rgb(51,51,51);">  <img src="https://img-blog.csdn.net/20180702000210555?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYW9sb25nXzRfMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></span></div><div><span style="background:rgb(254,254,254);color:rgb(51,51,51);"><br></span></div><p style="background:#FEFEFE;"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">Flume</span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">的数据流由事件(Event)</span>贯穿始终。事件是Flume的基本数据单位，它携带日志数据(字节数组形式)并且携带有头信息，这些Event由Agent外部的Source，比如上图中的Web Server生成。当Source捕获事件后会进行特定的格式化，然后Source会把事件推入(单个或多个)Channel中。你可以把Channel看作是一个缓冲区，它将保存事件直到Sink处理完该事件。Sink负责持久化日志或者把事件推向另一个Source。</p><p style="background:#FEFEFE;"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">很直白的设计，其中值得注意的是，Flume</span>提供了大量内置的Source、Channel和Sink类型。不同类型的Source,Channel和Sink可以自由组合。组合方式基于用户设置的配置文件，非常灵活。比如：Channel可以把事件暂存在内存里，也可以持久化到本地硬盘上。Sink可以把日志写入HDFS, HBase，甚至是另外一个Source等等。</p><p style="background:#FEFEFE;"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">如果你以为Flume</span>就这些能耐那就大错特错了。Flume支持用户建立多级流，也就是说，多个agent可以协同工作，并且支持Fan-in、Fan-out、ContextualRouting、Backup Routes。如下图所示：</p><p style="background:#FEFEFE;"><span style="font-family:'宋体';color:#001000;"><img src="https://img-blog.csdn.net/20180702000113514?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYW9sb25nXzRfMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></span></p><h2 style="background:rgb(254,254,254);"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">1.2 </span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">高可靠性</span></h2><p><span style="background:rgb(254,254,254);color:rgb(51,51,51);">作为生产环境运行的软件，高可靠性是必须的。</span></p><p><span style="background:rgb(254,254,254);color:rgb(51,51,51);">从单agent</span>来看，Flume使用基于事务的数据传递方式来保证事件传递的可靠性。Source和Sink被封装进一个事务。事件被存放在Channel中直到该事件被处理，Channel中的事件才会被移除。这是Flume提供的点到点的可靠机制。</p><p><span style="background:rgb(254,254,254);color:rgb(51,51,51);">从多级流来看，前一个agent</span>的sink和后一个agent的source同样有它们的事务来保障数据的可靠性。</p><h2 style="background:rgb(254,254,254);"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">1.3 </span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">可恢复性</span></h2><p><span style="background:rgb(254,254,254);color:rgb(51,51,51);">还是靠Channel</span>。推荐使用FileChannel，事件持久化在本地文件系统里(性能较差)。</p><h2 style="background:rgb(254,254,254);"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">2</span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">、Flume </span>整体架构介绍</h2><p style="background:#FEFEFE;"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">Flume</span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">架构整体上看就是  source --&gt;c hannel --&gt; sink  </span>的三层架构（参见最上面的图一），类似生成者和消费者的架构，他们之间通过queue（channel）传输，解耦。</p><p style="background:#FEFEFE;"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">Source:</span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">完成对日志数据的收集，分成 transtion </span>和 event 打入到channel之中。 </p><p style="background:#FEFEFE;"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">Channel:</span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">主要提供一个队列的功能，对source</span>提供中的数据进行简单的缓存。 </p><p style="background:#FEFEFE;"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">Sink:</span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">取出Channel</span>中的数据，进行相应的存储文件系统，数据库，或者提交到远程服务器。 </p><p style="background:#FEFEFE;"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">对现有程序改动最小的使用方式是使用是直接读取程序原来记录的日志文件，基本可以实现无缝接入，不需要对现有程序进行任何改动。 </span></p><p style="background:#FEFEFE;"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">对于直接读取文件Source, </span>主要有两种方式： </p><h2 style="background:rgb(254,254,254);"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">2.1 Exec source</span></h2><p><span style="background:rgb(254,254,254);color:rgb(51,51,51);">可通过写Unix command</span>的方式组织数据，最常用的就是tail -F [file]。</p><p><span style="background:rgb(254,254,254);color:rgb(51,51,51);">可以实现实时传输，但在flume</span>不运行和脚本错误时，会丢数据，也不支持断点续传功能。因为没有记录上次文件读到的位置，从而没办法知道，下次再读时，从什么地方开始读。特别是在日志文件一直在增加的时候。flume的source挂了。等flume的source再次开启的这段时间内，增加的日志内容，就没办法被source读取到了。不过flume有一个execStream的扩展，可以自己写一个监控日志增加情况，把增加的日志，通过自己写的工具把增加的内容，传送给flume的node。再传送给sink的node。要是能在tail类的source中能支持，在node挂掉这段时间的内容，等下次node开启后在继续传送，那就更完美了。</p><h2 style="background:rgb(254,254,254);"><span style="background:rgb(254,254,254);color:rgb(51,51,51);">2.2 Spooling Directory Source</span></h2><p><span style="background:rgb(254,254,254);color:rgb(51,51,51);">SpoolSource:</span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">是监测配置的目录下新增的文件，并将文件中的数据读取出来，可实现准实时。需要注意两点：1</span>、拷贝到spool目录下的文件不可以再打开编辑。2、spool目录下不可包含相应的子目录。在实际使用的过程中，可以结合log4j使用，使用log4j的时候，将log4j的文件分割机制设为1分钟一次，将文件拷贝到spool的监控目录。log4j有一个TimeRolling的插件，可以把log4j分割的文件到spool目录。基本实现了实时的监控。Flume在传完文件之后，将会修改文件的后缀，变为.COMPLETED（后缀也可以在配置文件中灵活指定） </p><p><span style="background:rgb(254,254,254);color:rgb(51,51,51);">ExecSource</span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">，SpoolSource</span>对比：ExecSource可以实现对日志的实时收集，但是存在Flume不运行或者指令执行出错时，将无法收集到日志数据，无法何证日志数据的完整性。SpoolSource虽然无法实现实时的收集数据，但是可以使用以分钟的方式分割文件，趋近于实时。如果应用无法实现以分钟切割日志文件的话，可以两种收集方式结合使用。 </p><p><span style="background:rgb(254,254,254);color:rgb(51,51,51);">Channel</span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">有多种方式：有MemoryChannel, JDBC Channel, MemoryRecoverChannel, FileChannel</span>。MemoryChannel可以实现高速的吞吐，但是无法保证数据的完整性。MemoryRecoverChannel在官方文档的建议上已经建义使用FileChannel来替换。FileChannel保证数据的完整性与一致性。在具体配置FileChannel时，建议FileChannel设置的目录和程序日志文件保存的目录设成不同的磁盘，以便提高效率。 </p><p><span style="background:rgb(254,254,254);color:rgb(51,51,51);">Sink</span><span style="background:rgb(254,254,254);color:rgb(51,51,51);">在设置存储数据时，可以向文件系统中，数据库中，hadoop</span>中储数据，在日志数据较少时，可以将数据存储在文件系中，并且设定一定的时间间隔保存数据。在日志数据较多时，可以将相应的日志数据存储到Hadoop中，便于日后进行相应的数据分析。 </p><p><span style="color:#000000;"> </span></p>            </div>
                </div>