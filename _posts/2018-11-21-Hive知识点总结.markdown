---
layout:     post
title:      Hive知识点总结
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>以hive 1.2.1版本为例。</p>

<h1>1 Hive的安装</h1>

<h2>1.1 关于Hadoop</h2>

<p>首先需要注意的是，Hive是一个基于Hadoop的数据仓库工具。所有要安装Hive，首先需要安装Hadoop。要使用Hive，首先需要保证Hadoop正常运行，然后再使用Hive。</p>

<p>在安装其他组件的时候，一定要注意软件版本的匹配问题。不然会报一堆摸不到头脑的错误。</p>

<h2>1.2 关于元数据库</h2>

<p>Hive默认的元数据是derby。但是许多人觉得derby不够方便，不如mysql更好，所以一般都将hive的元数据库换成mysql。</p>

<p>换成什么数据库都可以，必须注意的问题是，</p>

<p>1、在目标数据库中应该首先建立一个属于hive的数据库。然后在数据库中设置hive可以访问的权限。这样，在hive启动的时候，就可以使用配置的数据库进行初始化。所谓的初始化，就是hive将自己的元数据信息写入目标数据库。</p>

<p>2、在hive的配置文件中，指定配置数据库的连接信息。</p>

<p>3、还有一点需要注意的是，需要在hive的lib目录下面加入对应的数据库驱动的jar包，这样hive才可以顺利加载对应的类，才可以连接上对应的数据库。</p>

<h2>1.3 关于jline</h2>

<p><a href="https://blog.csdn.net/windsor575/article/details/50977003?locationNum=1&amp;fps=1" rel="nofollow">https://blog.csdn.net/windsor575/article/details/50977003?locationNum=1&amp;fps=1</a></p>

<p>jline的包在hive是2.12版本的，但是在hadoop中是0.x版本的。把hadoop的jline，替换为hive中的jline即可。</p>

<h1>2 Hive的体系结构</h1>

<h2>2.1 用户接口</h2>

<p>Hive的用户接口主要有3个，命令行、JDBC和web。</p>

<p>一张经典的结构图。</p>

<p><img alt="" class="has" height="316" src="https://images2017.cnblogs.com/blog/1233200/201710/1233200-20171017205214177-782883965.png" width="356"></p>

<p>在客户端启动命令行连接hive的时候，该节点会启动一个单独的驱动实例。</p>

<p>Hive的JDBC接口启动时，需要一个Thrift服务。</p>

<p>Hive的元数据存储在指定的数据库中，Hive的数据存储在HDFS上。</p>

<p>Hive的驱动完成HQL语句的词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在HDFS上，随后由MapReduce执行。</p>

<h2>2.2 Web界面的安装</h2>

<p>安装hive软件的包里面是没有web包的。需要自己去下载web的源码包。</p>

<p>1、去下载apache-hive-1.2.1-src.tar.gz.</p>

<p>2、打成war包。将源码解压，将hwi/web目录下面的文件使用jar cvf hive-hwi-1.2.1.war ./*命令打成war包。</p>

<p>3、将打成的war包放入lib目录。具体的位置为${HIVE_HOME}/lib。</p>

<p>4、修改配置。就是修改${HIVE_HOME}/conf/hive-site.xml文件。</p>

<p>指定hwi监听的ip地址，端口号和war包的位置。</p>

<p>就是指定hive.hwi.listen.host、hive.hwi.listen.port、hive.hwi.war.file的属性，hive.hwi.war.file需要指定的位置为相对路径。</p>

<p>5、将${JAVA_HOME}/lib/tools.jar拷贝到${HIVE_HOME}/lib目录下。</p>

<p>6、启动服务。${HIVE_HOME}/bin/hive --service hwi。</p>

<p>7、访问。在浏览器中输入http://localhost:9999/hwi。即可访问。浏览器输入的ip和端口号和第四步中配置的属性一致。并且不要被节点的其他应用使用即可。需要注意的是，一定要在访问的url后面加上hwi才可以。</p>

<p>tips:修改xml完成以后，可以使用xmllint -noout FILENAME来检查修改的xml文件是否有错误。当然这个检查只是xml文件语法层面的。如果你的xml文件配置的属性和值有问题，还是可能检查不出来的。</p>

<h2>2.3 命令行的使用</h2>

<h3>2.3.1 启动hive命令行可以使用的参数</h3>

<p>进入hive的命令行，使用hive命令，或者使用hive --service cli，这两者是等价的。</p>

<p>hive -H :显示hive的帮助信息，该命令和hive --help是等效的。</p>

<p>hive -d &lt;key=value&gt;:指定进入命令行的变量和值(这个变量可以是自己定义的)。这个命令和hive --define &lt;key,value&gt;是等效的。和hive --hivevar &lt;key=value&gt;也是等效的，这三个命令的效果是一样的。当然也可以进入命令行以后使用set设置属性的值。</p>

<p> 比如：</p>

<pre class="has">
<code class="language-bash">$ hive -d hive.exec.dynamic.partition=true</code></pre>

<p>hive --database &lt;databasename&gt;:指定进入hive命令行时进入的数据库，当然进行以后，再使用use命令切换也可以。例如：（我这里是多此一举，因为直接使用hive进入的数据库就是默认的dafault数据库）</p>

<pre class="has">
<code class="language-bash">$ hive --database default</code></pre>

<p>hive -e &lt;quoted-query-string&gt;:执行一个sql语句。比如（执行这个语句的前提是你的hive里面有一个名为hivetest的数据库，该数据库下面有一个test表。）：</p>

<pre class="has">
<code class="language-bash">$ hive -e 'select * from hivetest.test'</code></pre>

<p>hive -f &lt;filename&gt; :执行文件中的HQL语句。</p>

<p>hive --hiveconf &lt;property=value&gt; : 设置hive命令行的运行时配置参数。</p>

<p>hive -i &lt;filename&gt;: 进入命令行时，先执行文件中的HQL语句。</p>

<p>hive -S:静默模式，不显示执行的进度，只显示最后的结果。和hive --silent的效果是一样的。</p>

<p>hive -v: 冗余模式，额外打印出执行的HQL语句。和hive --verbose的效果是一样的。</p>

<p>hive -h:连接hostname指定的远程hive服务。</p>

<p>tips 1：hive -f &lt;filename&gt;和hive -i &lt;filename&gt;都可以执行文件中的HQL语句，他们有什么区别呢? 他们的区别就是，前者执行完成以后，不进行hive的命令行，后者执行完毕以后是要进入hive的命令行的。</p>

<p>tips 2：使用命令行时，hive运行时配置参数的优先级。</p>

<p>首先需要知道hive的运行时参数可以在哪几个地方配置。</p>

<p>第一个地方就是${HIVE_HOME}/conf/hive-default.xml文件。</p>

<p>第二个地方是${HIVE_HOME}/conf/hive-site.xml。</p>

<p>第三个地方是启动hive命令行时配置的运行时参数。</p>

<p>第四个地方是在hive中使用set命令设置的运行时参数。</p>

<p>知道了这几个地方，然后就要了解hive的运行。hive运行的时候，首先加载hive的默认配置，就是hive-default.xml文件中的参数。然后加载用户的配置，就是hive-site.xml，然后随着启动命令行时，使用hive --hiveconf &lt;property=value&gt;配置的参数，最后是在命令行中使用set设置的参数。记住一点即可，越靠后的配置，优先级越高。也就是说，如果配置的值有重复的。以最后面的为准。后面设置的值会覆盖掉前面配置的值。</p>

<h3>2.3.2 进入命令行可以使用的参数</h3>

<p>进入hive的命令行以后，可以使用：</p>

<p>1、quit、exit。退出命令行模式。</p>

<p>2、reset：重置所有的hive运行时配置参数。会将配置参数的值恢复成hive-site.xml文件中的值。</p>

<p>3、set &lt;key&gt;=&lt;value&gt;:设置运行时配置参数。</p>

<p>4、set：输出当前的hive参数设置。和set -v命令是等效的。</p>

<p>5、add FILE[S]/JAR[S]/ARCHIVE[S] &lt;filepath&gt;+:向hive的分布式缓存中添加一个或者多个文件、jar包或者归档。添加以后，可以在后面使用。比如添加自定义udf函数的时候，使用add jar命令。</p>

<p>比如使用add jar命令添加一个自定义udf函数。</p>

<pre class="has">
<code class="language-bash">hive&gt; add jar /home/ancony/udf.jar;</code></pre>

<p>6、list FILE[S]/JAR[S]/ARCHIVE[S] ：列出分布式缓存中的资源。</p>

<p>7、list FILE[S]/JAR[S]/ARCHIVE[S] &lt;filepath&gt;+ ：检查分布式缓存中是否存在资源。</p>

<p>8、delete FILE[S]/JAR[S]/ARCHIVE[S] : 从分布式缓存中删除指定的资源。</p>

<p>9、!&lt;command&gt; ：在命令行模式中执行一个Linux Shell命令。</p>

<p>例如列出当前文件夹中的文件：</p>

<pre class="has">
<code class="language-bash">hive&gt; !ls;</code></pre>

<p>10、dfs &lt;command&gt; : 在命令行模式中执行一个Hadoop dfs命令。</p>

<p>11、query ：执行一个HQL。</p>

<p>12、source &lt;filename&gt; : 在命令行中执行filepath指定的hive脚本文件。</p>

<p> </p>            </div>
                </div>