---
layout:     post
title:      hadoop2.6完全分布式安装
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								<div class="article-copyright">
					版权声明：本文为博主原创文章，未经博主允许不得转载。					https://blog.csdn.net/u014034934/article/details/73350788				</div>
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p><span style="font-size:18px;">192.168.0.110 master</span></p>
<p><span style="font-size:18px;">192.168.0.111 slave1</span></p>
<p><span style="font-size:18px;">192.168.0.112 slave2</span></p>
<p><span style="font-size:18px;">1.配置jdk</span></p>
<p><span style="font-size:18px;">另一博客里，三台都要配。</span></p>
<p><span style="font-size:18px;">2.添加用户hadoop</span></p>
<p></p>
<pre><code class="language-java"><span style="font-size:18px;">groupadd hadoop
useradd -g hadoop hadoop
passwd hadoop
vi /etc/sudoers
配置hadoop  ALL=(ALL)        NOPASSWD: ALL</span></code></pre><span style="font-size:18px;">3.ssh无密码登录</span>
<p></p>
<p></p>
<pre><code class="language-java"><span style="font-size:18px;">ssh localhost
cd ~
ssh-keygen -t rsa -P '' -f .ssh/id_rsa
cat .ssh/id_rsa.pub &gt;&gt; .ssh/authorized_keys
chmod 600  .ssh/authorized_keys </span></code></pre><span style="font-size:18px;">把master上的id_rsa.pub传到slave</span>
<p></p>
<p></p>
<pre><code class="language-java"><span style="font-size:18px;">scp id_rsa.pub  hadoop@slave1:/home/hadoop/.ssh
</span></code></pre><pre><code class="language-java"><span style="font-size:18px;">cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span></code></pre><span style="font-size:18px;">slave中.ssh的权限为700，authorized_keys的权限为744.</span>
<p></p>
<p><span style="font-size:18px;">4.配置hadoop集群</span></p>
<p><span style="font-size:18px;">修改slaves文件</span></p>
<p></p>
<pre><code class="language-java"><span style="font-size:18px;">slave1
slave2
</span></code></pre><span style="font-size:18px;"><br>
core-site.xml</span>
<p></p>
<p></p>
<pre><code class="language-java"><span style="font-size:18px;">&lt;configuration&gt;
&lt;property&gt;
&lt;name&gt;fs.defaultFS&lt;/name&gt;
&lt;value&gt;hdfs://master:9000&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
&lt;value&gt;/usr/hadoop/tmp&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</span></code></pre><span style="font-size:18px;"><br>
hdfs-site.xml</span>
<p></p>
<p></p>
<pre><code class="language-java"><span style="font-size:18px;">&lt;configuration&gt;
        &lt;property&gt;
                &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
                &lt;value&gt;master:50090&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;dfs.replication&lt;/name&gt;
                &lt;value&gt;2&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
                &lt;value&gt;/usr/hadoop/dfs/name&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
                &lt;value&gt;/usr/hadoop/dfs/data&lt;/value&gt;
        &lt;/property&gt;
&lt;/configuration&gt;
</span></code></pre><span style="font-size:18px;"><br>
mapred-site.xml     没有的话把mapred-site.xml.template改为mapred-site.xml</span>
<p></p>
<p></p>
<pre><code class="language-java"><span style="font-size:18px;">&lt;configuration&gt;
        &lt;property&gt;
                &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
                &lt;value&gt;yarn&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
                &lt;value&gt;master:10020&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
                &lt;value&gt;master:19888&lt;/value&gt;
        &lt;/property&gt;
&lt;/configuration&gt;</span></code></pre><span style="font-size:18px;"><br>
yarn-site.xml</span>
<p></p>
<p></p>
<pre><code class="language-java"><span style="font-size:18px;">&lt;configuration&gt;

&lt;!-- Site specific YARN configuration properties --&gt;
&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
&lt;value&gt;master&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;</span>
</code></pre><span style="font-size:18px;"><br>
压缩hadoop文件夹传到slave1和slave2中</span>
<p></p>
<p><span style="font-size:18px;"><br></span></p>
<p><span style="font-size:18px;">5.启动</span></p>
<p><span style="font-size:18px;"></span></p>
<pre><code class="language-java"><span style="font-size:18px;">hdfs namenode -format </span></code></pre>
<p></p>
<p><span style="font-size:18px;">在master中启动</span></p>
<p><span style="font-size:18px;"></span></p>
<pre><code class="language-java"><span style="font-size:18px;">start-dfs.sh
start-yarn.sh
mr-jobhistory-daemon.sh start historyserver</span></code></pre><br><br><p><span style="font-size:18px;">用jps查看</span></p>
<p><span style="font-size:18px;"></span></p>
<pre><code class="language-java">[hadoop@master sbin]$ jps
6208 JobHistoryServer
5617 NameNode
6242 Jps
5930 ResourceManager
5791 SecondaryNameNode
</code></pre><pre><code class="language-java">[hadoop@slave1 hadoop]$ jps
3616 DataNode
3715 NodeManager
3811 Jps
</code></pre><pre><code class="language-java">[hadoop@slave2 hadoop]$ jps
5216 DataNode
5315 NodeManager
5412 Jps</code></pre>
<p></p>
<p><span style="font-size:18px;"><br></span></p>
用hdfs dfsadmin -report查看
<p><span style="font-size:18px;"></span></p>
<pre><code class="language-java">[hadoop@master sbin]$ hdfs dfsadmin -report
Configured Capacity: 37492883456 (34.92 GB)
Present Capacity: 32955469824 (30.69 GB)
DFS Remaining: 32955461632 (30.69 GB)
DFS Used: 8192 (8 KB)
DFS Used%: 0.00%
Under replicated blocks: 0
Blocks with corrupt replicas: 0
Missing blocks: 0

-------------------------------------------------
Live datanodes (2):

Name: 192.168.0.111:50010 (slave1)
Hostname: slave1
Decommission Status : Normal
Configured Capacity: 18746441728 (17.46 GB)
DFS Used: 4096 (4 KB)
Non DFS Used: 2447355904 (2.28 GB)
DFS Remaining: 16299081728 (15.18 GB)
DFS Used%: 0.00%
DFS Remaining%: 86.94%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 1
Last contact: Fri Jun 16 21:58:20 CST 2017


Name: 192.168.0.112:50010 (slave2)
Hostname: slave2
Decommission Status : Normal
Configured Capacity: 18746441728 (17.46 GB)
DFS Used: 4096 (4 KB)
Non DFS Used: 2090057728 (1.95 GB)
DFS Remaining: 16656379904 (15.51 GB)
DFS Used%: 0.00%
DFS Remaining%: 88.85%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 1
Last contact: Fri Jun 16 21:58:22 CST 2017

</code></pre>这样完全分布式就搭好了
<p></p>
<p></p>
            </div>
                </div>