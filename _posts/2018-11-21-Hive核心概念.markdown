---
layout:     post
title:      Hive核心概念
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <h1>Hive核心概念</h1>

<p>转自：</p>

<p><a href="https://blog.csdn.net/weixin_41756009/article/details/82461525" rel="nofollow">https://blog.csdn.net/weixin_41756009/article/details/82461525</a></p>

<h1><a name="t0"></a>1.什么是hive</h1>

<p><br>
基于 Hadoop 的一个数据仓库工具：<br>
hive本身不提供数据存储功能，使用HDFS做数据存储，<br>
hive也不分布式计算框架，hive的核心工作就是把sql语句翻译成MR程序<br>
hive也不提供资源调度系统，也是默认由Hadoop当中YARN集群来调度<br>
可以将结构化的数据映射为一张数据库表，并提供 HQL(Hive SQL)查询功能</p>

<h1><a name="t1"></a><a></a>2.hive和Hadoop关系</h1>

<p> </p>

<p>Hive利用HDFS存储数据，利用MapReduce查询数据</p>

<p> </p>

<h1><a name="t2"></a><a></a>3.hive和传统数据库的区别</h1>

<p> </p>

<p><em>总结：hive具有sql数据库的外表，但应用场景完全不同，hive只适合用来做批量数据统计分析</em></p>

<p> </p>

<h1><a name="t3"></a><a></a><em>4.hive数据的存储</em></h1>

<p> </p>

<p>1、Hive中所有的数据都存储在 HDFS 中，没有专门的数据存储格式（可支持Text，SequenceFile，ParquetFile，RCFILE等）</p>

<p>2、只需要在创建表的时候告诉 Hive 数据中的列分隔符和行分隔符，Hive 就可以解析数据。</p>

<p>3、Hive 中包含以下数据模型：DB、Table，External Table，Partition，Bucket。</p>

<p>²  db：在hdfs中表现为${hive.metastore.warehouse.dir}目录下一个文件夹</p>

<p>²  table：在hdfs中表现所属db目录下一个文件夹</p>

<p>²  external table：与table类似，不过其数据存放位置可以在任意指定路径</p>

<p>²  partition：在hdfs中表现为table目录下的子目录</p>

<p>²  bucket：在hdfs中表现为同一个表目录下根据hash散列之后的多个文件</p>

<h1><a name="t4"></a><a></a>5.hive架构</h1>

<p> </p>

<p> </p>

<p>Hive架构，Driver是核心，Driver可以解析语法，最难的就是解析sql的语法，只要把SQL的语法解析知道怎么做了，它内部用MapReduce模板程序，它很容易把它组装起来，比如做一个join操作，最重要的是识别语法，认识你的语法，知道你语法有什么东西，解析出来会得到一个语法树，根据一些语法树，去找一些MapReduce模板程序，把它组装起来</p>

<p>例如：有二个表去join，内部有一个优化机制，有一个默认值，如果小表小于默认值，就采用map—join ，如果小表大于默认值，就采用reduce——join（其中map——join是先把小表加载到内存中）,组装时候就是输入一些参数：比如：你的输入数据在哪里，你的表数据的分隔符是什么，你的文件格式是什么：然而这些东西是我们建表的时候就指定了，所以这些都知道了，程序就可以正常的跑起来</p>

<p>Hive有了Driver之后，还需要借助一个非常重要的东西，他就是Metastore，Metastore里边记录了hive中所建的：库，表，分区，分桶他的一些信息，描述信息都在Metastore，如果用了MySQL作为hive的Metastore：需要注意的是：你建的表不是直接建在MySQL里边了，而是把这个表的很多描述信息分在了MySQL里边记录了，什么tables表，字段表。你建的hive里边的表存在HDFS上，hive会自动把他的目录规划/usr/hive/warehouse/库文件/库目录/表目录  你的数据就在目录下，</p>

<h1><a name="t5"></a><a></a> 6.内部表和外部表</h1>

<p>内部表：删除表的时候，会删除元数据和数据</p>

<p>外部表：删除表的时候，只删除元数据，不删除数据        </p>

<p>内部表和外部表使用场景</p>

<p><img alt="" class="has" src="https://img-blog.csdn.net/20170814094510420?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnJlZWZpc2hfeXp4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center"></p>

<h1><a name="t6"></a><a></a> 7.分桶</h1>

<p> </p>

<p>分桶操作：按照用户创建表时指定的分桶字段进行hash散列</p>

<p>         跟MR中的HashPartitioner的原理一模一样</p>

<p> </p>

<p>         MR中：按照key的hash值去模除以reductTask的个数</p>

<p>         Hive中：按照分桶字段的hash值去模除以分桶的个数</p>

<p> </p>

<p>         hive分桶操作的效果：</p>

<p>         把一个文件按照某个特定的字段和桶数 散列成多个文件</p>

<p> </p>

<p>         好处：</p>

<p>         1、方便抽样</p>

<p>         2、提高join查询效率   </p>

<p> </p>

<h1><a name="t7"></a><a></a>8.分区</h1>

<p>Hive分区表的作用：让你做统计的时候少统计，把我们的数据放在多个文件夹里边，我们统计时候，可以指定分区，这样范围就会小一些，这样就减少了运行的时间</p>

<p> </p>

<h1><a name="t8"></a><a></a>9 .简短理解Hive概念</h1>

<p><br>
Hive是由Facebook开源<br>
Hive是基于Hadoop的一个开源数据仓库工具<br>
能够将结构化数据映射成为一张数据库表（二维表），提供类SQL查询语言（支持绝大多数SQL标准语法）<br>
底层依赖于HDFS存储数据，Hive的本质是HQL语句转化成MR程序，提交给Hadoop运行<br>
Hive的适应场景：只适合做海量离线数据的统计分析<br><br><br>
Hive核心组件<br>
解释器：把HQL语句转换成一颗抽象语法树<br>
编译器：把抽象语法树转换成一系列MR程序<br>
Hive的底层有一系列的MR模板（Operation：GroupByOperation， JoinOperation）<br>
优化器：执行这一系列MR程序的优化<br>
执行器：组织相应的资源提交给Hadoop集群</p>            </div>
                </div>