---
layout:     post
title:      Hadoop-2.5.0 Mapreduce例程实现
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p>打开hadoop目录</p>
<p></p>
<pre><code class="language-html">$ cd hadoop/hadoop-2.5.0</code></pre>
<p></p>
<p>用你喜欢的编辑器写WordCount.java文件</p>
<p>这里直接给出官方的程序代码</p>
<p></p>
<pre><code class="language-html">import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCount {

  public static class TokenizerMapper
       extends Mapper&lt;Object, Text, Text, IntWritable&gt;{

    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(Object key, Text value, Context context
                    ) throws IOException, InterruptedException {
      StringTokenizer itr = new StringTokenizer(value.toString());
      while (itr.hasMoreTokens()) {
        word.set(itr.nextToken());
        context.write(word, one);
      }
    }
  }

  public static class IntSumReducer
       extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt; {
    private IntWritable result = new IntWritable();

    public void reduce(Text key, Iterable&lt;IntWritable&gt; values,
                       Context context
                       ) throws IOException, InterruptedException {
      int sum = 0;
      for (IntWritable val : values) {
        sum += val.get();
      }
      result.set(sum);
      context.write(key, result);
    }
  }

  public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf, "word count");
    job.setJarByClass(WordCount.class);
    job.setMapperClass(TokenizerMapper.class);
    job.setCombinerClass(IntSumReducer.class);
    job.setReducerClass(IntSumReducer.class);
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    System.exit(job.waitForCompletion(true) ? 0 : 1);
  }
}</code></pre>
<p></p>
<p>具体程序步骤我会在之后的补上，现在先对这个程序进行实现。</p>
<h3>1. 修改环境变量</h3>
<p></p>
<pre><code class="language-html">export JAVA_HOME=/usr/java/default
export PATH=$JAVA_HOME/bin:$PATH
export HADOOP_CLASSPATH=$JAVA_HOME/lib/tools.jar</code></pre>      其中，JAVA_HOME与HADOOP_CLASSPATH 在hadoop目录下etc/hadoop/hadoop-env.sh中修改，PATH在根目录下/etc/profile中。
<p></p>
<h3>2. 打开工作节点</h3>
<p></p>
<pre><code class="language-html">$ ./sbin/start-all.sh</code></pre>运行“jps”可以检测当前工作的节点数。
<p></p>
<h3>3.译WordCount文件</h3>
<p></p>
<pre><code class="language-html">$ ./bin/hadoop com.sun.tools.javac.Main WordCount.java
$ jar cf wc.jar WordCount*.class</code></pre>
<p></p>
<h3>4. 在文件系统中生成要计算的对象</h3>
<pre><code class="language-html">$ ./bin/hadoop dfs -mkdir -p /user/i/wordcount/input
$ nano file0
$ nano file1
$ echo 'Hello Hadoop Goodbye Hadoop' &gt;&gt; file0
$ echo 'Hello world bye world' &gt;&gt; file1
$ ./bin/hadoop dfs -put file0 /user/i/wordcount/input
$ ./bin/hadoop dfs -put file1 /user/i/wordcount/input</code></pre>
<h3>5. 运行程序</h3>
<p></p>
<pre><code class="language-html">$ ./bin/hadoop jar wc.jar WordCount /user/i/wordcount/intput /user/i/wordcount/output
</code></pre>
<p></p>
<h3>6. 检测结果</h3>
<p></p>
<pre><code class="language-html">$ ./bin/hdfs dfs -cat /user/i/wordcount/output/*
</code></pre><br>
8. 关闭节点
<p></p>
<p></p>
<pre><code class="language-html">$ ./sbin/stop-all.sh</code></pre><br>
 <br><p></p>
<p><br></p>
            </div>
                </div>