---
layout:     post
title:      Spark的那些外部框架
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                
<p class="blog-summary" style="font-size:16px;line-height:32px;color:rgb(51,51,51);table-layout:fixed;overflow:hidden;font-family:PingFangSC, 'helvetica neue', 'hiragino sans gb', arial, 'microsoft yahei ui', 'microsoft yahei', simsun, sans-serif;background:rgb(249,249,249);">
<span style="font-weight:700;"><a href="http://click.aliyun.com/m/23423/" rel="nofollow"></a></span></p>
<p><a href="http://click.aliyun.com/m/23423/" rel="nofollow"><span>摘要：</span> Spark社区提供了大量的框架和库。其规模及数量都还在不断增加。本文我们将介绍不包含在Spark核心源代码库的各种外部框架。Spark试图解决的问题涵盖的面很广，跨越了很多不同领域，使用这些框架能帮助降低初始开发成本，充分利用开发人员已有的知识。</a></p>
<a href="http://click.aliyun.com/m/23423/" rel="nofollow"><span id="OSC_h1_1"></span><span style="color:rgb(61,70,77);font-family:'Pingfang SC', STHeiti, 'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', SimSun, sans-serif;font-size:16px;line-height:28px;background-color:rgb(248,248,248);"></span></a>
<h1 id="h1_0"><a href="http://click.aliyun.com/m/23423/" rel="nofollow">Spark Package</a></h1>
<p><a href="http://click.aliyun.com/m/23423/" rel="nofollow">　　要使用Spark库，你首先必须了解的东西是Spark package。它有点像Spark的包管理器。当你给Spark集群提交job时，你可以到存放Spark package的网站下载任何package。所有package都存放在这个站点。<br>
　　<span style="color:#4466bb;"><span>http://spark-packages.org/</span></span><br>
　　当你想用一个Spark package时，可以在spark-submit命令或者spark- shell命令中增加包选项：</a></p>
<pre class="hljs elixir"><code class="hljs elixir"><a href="http://click.aliyun.com/m/23423/" rel="nofollow"><span class="hljs-variable">$ </span><span class="hljs-variable">$Spark_HOME</span>/bin/Spark-shell \
    -packages com.<span class="hljs-symbol">databricks:</span>Spark-avro_2.<span class="hljs-number">10</span><span class="hljs-symbol">:</span><span class="hljs-number">2.0</span>.<span class="hljs-number">1</span>
</a></code></pre>
<p><a href="http://click.aliyun.com/m/23423/" rel="nofollow">　　如果使用了--packages选项，Spark package就会自动把它的JAR包添加到你指定的路径下。你不仅能在Spark集群上使用社区的库，还能到公开发布自己的库。如果要把一个Spark package发布到这个托管服务下，必须遵守下列规则：</a></p>
<ul><li><a href="http://click.aliyun.com/m/23423/" rel="nofollow">源代码必须放在Github上。</a></li><li><a href="http://click.aliyun.com/m/23423/" rel="nofollow">代码库的名字必须与包名相同。</a></li><li><a href="http://click.aliyun.com/m/23423/" rel="nofollow">代码库的主分支必须有README.md文件，在根目录下必须有LICENSE文件。</a></li></ul><p><a href="http://click.aliyun.com/m/23423/" rel="nofollow">换句话说，你不需要编译自己的package。即使你用Spark Packages的模板，编译、发布以及版本更新都将由这项服务完成。sbt插件sbt-spark-package（<span style="color:#4466bb;"><span>https://github.com/databricks/sbt-spark-packages）对于生成package也非常有用。如果要在你的项目中包含此插件，请务必在sbt项目的project/plugins.sbt文件中写入下面的代码：</span></span></a></p>
<pre class="hljs lisp"><code class="hljs lisp"><a href="http://click.aliyun.com/m/23423/" rel="nofollow">resolvers += <span class="hljs-string">"bintray-Spark-packages"</span> at <span class="hljs-string">"https://dl.bintray.com/
Spark-packages/maven/"</span>
    addSbtPlugin(<span class="hljs-string">"org.Spark-packages"</span> % <span class="hljs-string">"sbt-Spark-packages"</span> % <span class="hljs-string">"0.2.3"</span>)
</a></code></pre>
<p><a href="http://click.aliyun.com/m/23423/" rel="nofollow">　　发布Spark包时必须提供如下信息，应该把它们写到build.sbt中：</a></p>
<ul><li><a href="http://click.aliyun.com/m/23423/" rel="nofollow">spName——package的名称。</a></li><li><a href="http://click.aliyun.com/m/23423/" rel="nofollow">sparkVersion——package所依赖的Spark版本。</a></li><li><a href="http://click.aliyun.com/m/23423/" rel="nofollow">sparkComponents——package所依赖的Spark组件列表，例如SQL、MLlib。</a></li><li><a href="http://click.aliyun.com/m/23423/" rel="nofollow">spShortDescription——package的一句话描述。</a></li><li><a href="http://click.aliyun.com/m/23423/" rel="nofollow">spDescription——关于package的完整描述。</a></li><li><a href="http://click.aliyun.com/m/23423/" rel="nofollow">spHomePage——用于描述package的Web页面的URL。</a></li></ul><p><a href="http://click.aliyun.com/m/23423/" rel="nofollow">上述6项是你在发布package之前需要提供的信息。一定要发布到package的代码库的主分支上。你可以使用Spark package的托管站点（<span style="color:#4466bb;"><span>https://spark-packages.org/）的Web</span></span> UI来完成这项工作。<br>
　　　　　　　　　　　　<span style="color:#4466bb;"><span><img alt="图片描述" src="https://img-blog.csdn.net/20170615091437259?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnJvYWR2aWV3MjAwNg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></span></span><br>
　　在Spark package站点上注册了Github账号后，可以从“name”下拉菜单中选择你的代码库。<br>
　　　　　　　　　　　　　<span style="color:#4466bb;"><span><img alt="图片描述" src="https://img-blog.csdn.net/20170615091629259?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnJvYWR2aWV3MjAwNg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></span></span><br>
　　上面的简短描述和主页最好与build.sbt中的描述和主页URL一致。一旦你提交了package，验证过程就开始了。这个过程通常需要几分钟。当验证完成后，你会收到一封邮件，告诉你验证是否成功。如果成功，就可以用前面描述的--package选项下载你的package了。截至2015年11月，Spark package站点上已经有153个package了。下一节将介绍一些库，它们也是支持Spark package形式的，即它们也以Spark package格式分发。</a></p>
<p><a href="http://click.aliyun.com/m/23423/" rel="nofollow"><img alt="" height="152" src="https://static.oschina.net/uploads/space/2017/0616/132224_W047_3472227.png" width="564"></a></p>
<p><a href="http://click.aliyun.com/m/23423/" rel="nofollow">原文链接</a></p>
            </div>
                </div>